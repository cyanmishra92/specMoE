# üî¨ Reproducibility Guide

Complete guide to reproduce the **47.55% Top-1 accuracy** results for Qwen1.5-MoE-A2.7B expert prediction.

## üéØ Key Results to Reproduce

| Model | Top-1 Accuracy | Top-5 Accuracy | Training Time | Hardware |
|-------|---------------|---------------|---------------|----------|
| **Simple** | **47.55%** | **73.85%** | 40 minutes | RTX 3090 |
| **Hybrid** | TBD | TBD | ~2 hours | RTX 3090 |

## üìã Environment Setup

### Required Hardware
- **GPU**: RTX 3090 (24GB), A6000 (48GB), or RTX 4090 (24GB)
- **RAM**: 32GB system RAM minimum  
- **Storage**: 100GB free space for traces and models

### Software Dependencies
```bash
# Python 3.8+ with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Core dependencies
pip install transformers==4.35.0
pip install datasets==2.14.5  
pip install accelerate==0.24.0
pip install bitsandbytes==0.41.0
pip install tqdm numpy scipy matplotlib seaborn
pip install GPUtil

# HuggingFace authentication (required for Qwen model access)
pip install huggingface_hub
huggingface-cli login  # Enter your HF token
```

### Model Access
```bash
# Ensure you have access to Qwen1.5-MoE-A2.7B
# May require requesting access from Qwen team on HuggingFace
# Model ID: "Qwen/Qwen1.5-MoE-A2.7B"
```

## üöÄ Step-by-Step Reproduction

### Step 1: Clone Repository
```bash
git clone <your-repo-url>
cd specMoE/qwen15_moe_a27b
```

### Step 2: Data Collection (Critical for Results)
```bash
# Navigate to scripts directory
cd scripts

# Collect exactly 5000 traces with streaming (matches our setup)
python collection/collect_qwen15_moe_traces_streaming.py \
  --target_traces 5000 \
  --shard_size 500 \
  --batch_size 8 \
  --max_length 256

# This creates 10 shard files (~500 traces each)
# Total collection time: ~20-30 minutes on RTX 3090
# Output: ../routing_data/shards/shard_000_500_traces.pkl to shard_009_500_traces.pkl
```

### Step 3: Train Simple Model (47.55% Result)
```bash
# Train with exact hyperparameters that achieved 47.55%
python train_simple_predictor.py \
  --shards-per-group 4 \
  --batch-size 8 \
  --lr 5e-5 \
  --epochs 20

# Expected training time: ~40 minutes
# Expected memory usage: ~20GB VRAM
# Target result: 47.55% Top-1, 73.85% Top-5
```

### Step 4: Validate Results
```bash
# Run coverage analysis to verify performance
python validate_coverage_analysis.py \
  --checkpoint ../models/simple_checkpoints/best_checkpoint.pth \
  --model-type simple \
  --batch-size 16

# Expected results:
# Top-1: 47.55% (¬±2%)
# Top-5: 73.85% (¬±3%)  
# Coverage analysis with Top-10, Top-15, Top-20 metrics
```

## üéõÔ∏è Critical Hyperparameters

### Data Collection Parameters (EXACT MATCH REQUIRED):
```python
TARGET_TRACES = 5000           # Exact number
SHARD_SIZE = 500              # 500 traces per shard  
BATCH_SIZE = 8                # Processing batch size
MAX_LENGTH = 256              # Sequence length
QUANTIZATION = "4bit"         # Memory efficiency
BALANCED_SAMPLING = True      # Equal samples per dataset
```

### Training Parameters (EXACT MATCH REQUIRED):
```python
SHARDS_PER_GROUP = 4          # Load 4 shards together (~16GB)
BATCH_SIZE = 8                # Training batch size
LEARNING_RATE = 5e-5          # Conservative LR (critical!)
EPOCHS = 20                   # Sufficient for convergence
SEQUENCE_LENGTH = 128         # Model max sequence length  
WEIGHT_DECAY = 0.01          # AdamW regularization
```

### Model Architecture (Simple Predictor):
```python
INPUT_DIM = 2048              # Qwen hidden dimension
HIDDEN_DIM = 256              # Compressed representation
NUM_EXPERTS = 60              # Qwen2-MoE has 60 experts
EXPERTS_PER_TOKEN = 4         # Top-4 routing
DROPOUT = 0.1                 # Regularization
ACTIVATION = "ReLU"           # Simple activation
NORMALIZATION = "LayerNorm"   # Stable training
```

## üîç Key Success Factors

### 1. Data Quality (CRITICAL)
- **Balanced sampling**: Equal traces from 6 datasets
- **Proper sequence length**: 256 tokens during collection
- **Clean tensor shapes**: No dimension mismatches
- **Streaming collection**: Prevents OOM during collection

### 2. Model Architecture (CRITICAL)  
- **Simple MLP**: 3 layers with LayerNorm, avoid transformers
- **Conservative parameters**: 256 hidden dim, not larger
- **Single loss function**: Cross-entropy only, no multi-loss
- **Proper initialization**: Xavier uniform for stability

### 3. Training Strategy (CRITICAL)
- **Conservative learning rate**: 5e-5, not higher
- **Stable batch size**: 8 samples, avoid larger batches
- **Sufficient data**: 4 shards per group for good mixing
- **Early convergence**: Model reaches 32% by epoch 2

### 4. Hardware Configuration
- **Memory management**: 4 shards √ó 4GB = 16GB data + model
- **GPU utilization**: RTX 3090 sweet spot configuration
- **Automatic cleanup**: Aggressive memory management between shards

## üìä Expected Training Progression

| Epoch | Expected Top-1 | Expected Top-5 | Status |
|-------|---------------|---------------|---------|
| 1 | ~25-30% | ~50-55% | Initial learning |
| 2 | ~32% | ~58% | Fast convergence |
| 5 | ~38-42% | ~65-68% | Steady improvement |
| 10 | ~44-46% | ~70-72% | Near optimal |
| 20 | **47.55%** | **73.85%** | **Final result** |

## üö® Common Issues & Solutions

### Issue 1: Lower Accuracy (<40% Top-1)
**Causes**: Wrong hyperparameters, data quality issues
```bash
# Solution: Verify exact parameters
--lr 5e-5          # Not 1e-4 or 1e-5  
--batch-size 8     # Not 16 or 4
--shards-per-group 4  # Not 1 or 2
```

### Issue 2: Training Instability (NaN losses)
**Causes**: Learning rate too high, tensor shape issues
```bash
# Solution: Use conservative settings
--lr 1e-5          # Even more conservative
--batch-size 4     # Smaller batches
```

### Issue 3: Out of Memory
**Causes**: Too many shards loaded, batch size too large
```bash
# Solution: Reduce memory usage
--shards-per-group 2   # Reduce to 2 shards
--batch-size 4         # Smaller batches
```

### Issue 4: Different Data Distribution
**Causes**: Different trace collection, model version mismatch
```bash
# Solution: Exact reproduction
# Use exact same model: "Qwen/Qwen1.5-MoE-A2.7B"
# Use exact same datasets: IMDB, Yelp, AG News, Squad, Amazon, DBpedia
# Use exact same sampling: 833 traces per dataset
```

## üîÑ Alternative Approaches

### Quick Test (5 minutes):
```bash
# Smaller scale test
python collection/collect_qwen15_moe_traces_small.py  # 500 traces
python train_simple_predictor.py --epochs 5 --shards-per-group 1
# Expected: ~35-40% Top-1 (lower due to less data)
```

### High-Memory Setup (A6000):
```bash
# More aggressive settings for 48GB VRAM
python train_simple_predictor.py \
  --shards-per-group 6 \
  --batch-size 16 \
  --epochs 20
# Expected: Similar results, faster training
```

## üìù Result Validation

### Success Criteria:
- ‚úÖ **Top-1 Accuracy**: 45-50% (target: 47.55%)
- ‚úÖ **Top-5 Accuracy**: 70-75% (target: 73.85%)  
- ‚úÖ **Training Stability**: No NaN losses, smooth convergence
- ‚úÖ **Memory Usage**: <21GB VRAM on RTX 3090
- ‚úÖ **Training Time**: 35-45 minutes total

### Validation Commands:
```bash
# Check final checkpoint
ls -la models/simple_checkpoints/best_checkpoint.pth

# Verify results with coverage analysis
python validate_coverage_analysis.py \
  --checkpoint models/simple_checkpoints/best_checkpoint.pth \
  --model-type simple

# Expected coverage probabilities:
# Top-10: ~85-90% coverage of all 4 experts
# Top-15: ~93-97% coverage of all 4 experts  
# Top-20: ~96-99% coverage of all 4 experts
```

## üìà Performance Baselines

### Random Baseline:
- **Top-1**: 1.67% (1/60 experts)
- **Top-4**: 6.67% (4/60 experts)  
- **Top-10**: 16.67% (10/60 experts)

### Our Achievement:
- **Top-1**: **47.55%** (28.5x better than random!)
- **Top-5**: **73.85%** (44x better than random!)
- **Practical Impact**: Highly effective for expert prefetching

## üéØ Advanced Reproduction (Optional)

### Hybrid Model Comparison:
```bash
# After simple model, test hybrid approach
python train_hybrid_predictor.py \
  --shards-per-group 2 \
  --batch-size 12 \
  --lr 3e-5 \
  --epochs 30

# Compare: Does temporal prediction help?
# Expected: Similar or slightly better performance
```

### Ablation Studies:
```bash
# Test different learning rates
for lr in 1e-5 3e-5 1e-4; do
  python train_simple_predictor.py --lr $lr --epochs 10
done

# Test different architectures  
# Modify hidden_dim in models/simple_qwen_predictor.py: 128, 256, 512
```

## üìö References & Citations

- **ExpertFlow Paper**: Optimized Expert Activation and Token Allocation (2024)
- **Qwen Model**: Qwen1.5-MoE-A2.7B HuggingFace Model
- **Our Innovation**: Simple MLP outperforms complex transformers for expert prediction

## ‚úÖ Reproduction Checklist

- [ ] Environment setup complete (CUDA, dependencies)
- [ ] HuggingFace authentication configured
- [ ] Data collection: 5000 traces in 10 shards
- [ ] Training: Simple predictor with exact hyperparameters  
- [ ] Validation: 47.55% ¬± 2% Top-1 accuracy achieved
- [ ] Coverage analysis: Top-10/15/20 coverage probabilities
- [ ] Memory usage: <21GB on RTX 3090
- [ ] Training time: 35-45 minutes

**Target: 47.55% Top-1 accuracy with stable, reproducible training on RTX 3090!** üéØ