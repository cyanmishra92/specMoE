[
  {
    "text": "´as  closely tracks oracle, where as DaDianNao [ 16 ] falls short. execute (using a capacitor/ battery). We quantitatively compare the effective training, i.e.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "USENIX Association. [170] Wei Xu, E-Sheng Peh, and Edward Wong. Fusing kernels for higher performance deep learning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Also, to utilize temporal locality, we propose an inter-frame compression scheme which further increases the compression efﬁciency. •  We implement and evaluate our proposals on an edge device – NVIDIA Jetson AGX Xavier board [ 58 ]. Our extensive experimental results show that, compared to a state-of-the-art intra-frame PCC technique [ 56 ], our intra- frame proposal can accelerate the PCC by  43 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "URL https://arxiv.org/abs/2303.05760 . International Telecommunication Union, June 2019a. ITU-T. Advanced video coding for generic audiovisual services.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Since the Relaxed  workload has much lower accuracy constraints, smaller models are able to singularly achieve the accuracy requirements at lower latency. Accuracy violations : The accuracy is mea- sured as a moving window average with size 200 for all the requests in the workload. Accuracy Met (%) Scheme Strict Relaxed InFaas 21 71 Clipper 47 89 Cocktail 56 96 \nTable 6:  Requests meeting target accuracy averaged for both Trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "2018. [8]  Liang Wang, Mengyuan Li, Yinqian Zhang, Thomas Ristenpart, and Michael Swift. Peeking Behind the Curtains of Serverless Plat- forms.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "(Giga MACs/s) /Power utilization \n1 50 0/Power failure/0/0% 0/Power failure/0/0% 2 100 0/Power failure/0/0% 80/25 × 1 × 1/0.312/80% 3 500 480/25 × 6 × 1/1.872/96% 480/25 × 6 × 1/1.872/96% 4 200 0/Power failure/0/0% 160/25 × 2 × 1/0.624/80% 5 250 0/Power failure/0/0% 240/25 × 3 × 1/0.936/96% 6 750 480/25 × 6 × 1/1.872/64% 720/25 × 3 × 3/2.808/96% 7 650 480/25 × 6 × 1/1.872/74% 640/25 × 2 × 4/2.496/98% 8 350 0/Power failure/0/0% 320/25 × 2 × 2/1.248/91% \n100 \n0.4 \n1.2 \n1.6 \n2.0 \n2.4 \n2.8 \nPower ( ­ W) \nThroughput (Giga MACs/s) \nPower consumption with full-size activation \nPower consumption with tile-size activation \nThroughput with full-size activation Throughput with tile-size activation \nPower trace \nAverage harvested power Average power consumption with full-size activation Average power consumption with tile-size activation \nAverage throughput with full-size activation \nAverage throughput with tile-size activation \n356.3 \n180 \n330 \n1.3 \n200 \n300 \n400 \n500 \n600 \n700 \n800 \n0.8 0.7 \nPC1 \nPC2 \nPC3 \nPC4 \nPC5 \nPC6 \nPC7 \nPC8 \n0 \n0 0 0 80 480 480 0 160 0 240 480 \n480 640 0 320 \n0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 \nFig. 1. Comparisons on power consumption and throughput with tile-size over full-size activation \nFrom the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 501,
    "augmented": true
  },
  {
    "text": "Thelatency modelfordataloadforoneconvolution operationis Lat load = Bits input /BW ld .Theterm Lat load \nrepresentsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.Theterm BW ld denotesthebandwidthof eachloadoperation.Themodelsof P store and Lat store can bederivedinasimilarfashion. 2) ComputationonReRAMs: P comp isthedominantand mostcomplicatedpartwheretheanaloganddigitalsignals aremixed.Theenergyofone-cycle MACoperationsforan activationsizeof m×n andactualduplicationaG, P comp−tile \ndividesintothefollowingparts:1) E DAC   denotestheenergy consumedforconvertingthedigitalinputsignaltotheanalog signalinabit-serialfashion;2) E MAC   denotestheenergy forperforming MACoperationsonReRAMs;and3) E ADC \nconsistsofthreepartsasshowninFigure5:3i) E BL   denoting theenergyforactivatingbitlines;3ii) E SA−Ref   denotingthe energyforsensingandamplifyingthe MACresultsignaland thenreferencinganalogsignalstodigitalsignals;and,3iii) E S+A   denotingtheenergyofShift&Addparttocomposethe ﬁnaloutput. IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisﬁxedas Lat comp = T comp ,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 425,
    "augmented": false
  },
  {
    "text": "Further, based on our profiling of the communication behavior across chiplets and chips, we will consider performant and adaptive interconnect designs [80, 81, 110, 116, 127] to co-optimize for latency, bandwidth, and fault tolerance. Task-3.4: Going beyond with Hardware Software Co-optimization Achieving 100% effectiveness in SLO metrics will not be possible just with the algorithms and system tech- niques mentioned in Thrusts 1 and 2 unless the underlying hardware is  co-designed  with the software. In this design space, we plan to expose various “knobs” from hardware via which software can better monitor and control the execution.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Practical Hyperparameter Tuning Strategies \n1. Baseline Ratios:  Start with ratios that link  γ  to typical accuracy gains and set  δ, η  based on fractions or multiples of  γ  ·  ∆ A min  or  γ  ·  ∆ A max . 2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Second, for different head orientations, their distance vectors plotted in Fig. 6b and Fig. 6c retain the same ellipse behavior but different shapes.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "We plan to provide hands-on computer architecture experience to students and show them how modern computer systems can address important societal challenges, specifically how LLMs can be used in many such domains. Participants carry out hands-on design activities with faculty and students. PI Das has been involved with organizing the  Visit In Engineering Weekend  (VIEW) program for students entering their junior and senior years of high school, which fosters interest in engineering.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Fig. 3: Three scenarios: Scenario1: An existing object is moving. Scenario2: An object was not captured by the previous frame, but captured by the current frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Due to this inherent nature of compute, the pattern between left eye and right eye can be easily  captured  by proﬁling the distance vector for only the ﬁrst row on the screens:  Δ = \u0002 ⃗x 0 r   − ⃗x 0 l   , ⃗y 0 r   − ⃗y 0 l \u0003 , as shown in line number  2  in Algorithm 1. With the learned pattern, the remaining  i th rows for the right- eye ( i  ∈ [1 , n  − 1] , where  n  is the  height  of the VR screen) can be  reconstructed  by using the projection computation results of the left-eye ( [ ⃗x i l , ⃗y i l ] ) and the pattern  Δ , as shown in line  6  in Algorithm 1. Note that, as discussed above, 2 .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 198,
    "augmented": false
  },
  {
    "text": "The edge node is implemented on Raspberry Pi development boards and the cloud is emulated via a desktop class Intel corei9 10900k CPU (with 64GB DDR4 RAM). Figure 3 shows the accuracy and latency of different policies with different numbers of machines. Key Observations: 1) If data is shared with (a third party) cloud, the accuracy of the model generated using all data from different machines is significantly higher than the models generated for the edge using their own data.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "The equilibrium ensures  D  remains stable, allowing classi- cal stochastic optimization theory to hold. The regularizers, being convex and with bounded gradients, integrate seam- lessly into the backpropagation and SGD updates, shaping the optimization landscape but not invalidating convergence properties. Proper selection and tuning of  λ 1 , λ 2  help main- tain stable and robust training dynamics.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Finally, we prove that the equilibrium is reached under the given assumptions. Algorithm 3  Hyperparameter Exploration for Reward Pa- rameters \n1:  Inputs: Estimates  ∆ A min ,  ∆ A max , energy costs e max cap   , e inf , e comm , initial guesses  γ 0 , δ 0 , η 0 , and tuning increments  ∆ γ ,  ∆ δ ,  ∆ η . 2:  Compute  e max total   =  e max cap   +  e inf   +  e comm .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "IEEE, 2011. [42] William Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Kube-Knots: Resource Harvesting through Dynamic Container Orchestration in GPU-based Datacenters. In  CLUSTER , 2019. [76]  Guido Urdaneta, Guillaume Pierre, and Maarten Van Steen.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "Foloowing are the outline of the requirements: \n1. The function is designed to handle energy constraints by decomposing the convolution loops into smaller quanta tasks. Define ‘QuantaTask‘ as the minimum iterations that can run.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "These are functions within a DAG that have a high number of descendant functions that are linked to it and we use the \n155 \nSoCC ’21, November 1–4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. SEARCH \nNGINX \nMAKE_POST \nREAD_TIMELINE \nFOLLOW \nTEXT \nMEDIA \nUSER_TAG \nURL_SHORTENER \nCOMPOSE_POST \nPOST_STORAGE \n(a) Social Network. NGINX ID \nMOVIE_ID \nTEXT_SERVICE \nUSER_SERVICE \nRATING \nCOMPOSE_REVIEW \nMOVIE_REVIEW \nUSER_REVIEW \nREVIEW_STORAGE \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "ACM Interna- tional Symposium on Eye Tracking Research and Applications (ETRA) . 1–9. [59]  Stereolabs.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "SPIE, 2016, pp. A. S. Awwal, M. G. V´azquez, A. M´arquez, and M. A. Matin, Eds., International Society for Optics and Photonics. [62] V. Zakharchenko, K. P. Choi, and J. H. Park, “Quality metric for spherical panoramic video,” in  Optics and Photonics for Information Processing X , K. M. Iftekharuddin, A.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "Variance feature of different power sources \nIII-ADC \nBL \nWL \nSL \n͙ \n͙ \n͙ \nColumn 1 \n͙ \nCSA + \n- \nSAR \n͙ Ref \nShift&Add \n͙ \nDriver \n͙ \nRow 1 \nRow 2 \nRow m \nDriver \nDriver \nI-DAC ͙ \n͙ \n͙ ͙ \nII-Comp \n4-bit inputs 1-bit resolution \n1-bit weights \n4-bit outputs \nbit- serial \nInput  Reg. 4-bit \nOutput  Reg. C \nC \nC controlling circuit \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Us. ´as  was designed on a intermittency friendly approach, and was never designed to hit the best throughput. The unit compute (only a 3  ×  3 convolution per tile) that  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Towards this, we propose  HoloAR , an opportunistic and edge- friendly framework to speed up the AR holographic computation \n(a) An app. (b) HW components [20, 29]. (c) SW pipeline [19, 50].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2310.16795 , 2023. Hottiles: Ac- celerating spmm with heterogeneous accelerator architectures. [47] Gerasimos Gerogiannis, Sriram Aananthakrishnan, Josep Torrellas, and Ibrahim Hur.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "The key components of the design are explained in detail below. 4.1 Dynamic Model Selection Policy \nWe use a window-based dynamic model selection policy using two objective functions as described below. Objective functions : In order to reduce cost and latency while maximizing the accuracy, we deﬁne a latency-accuracy metric ( µ AL ) and cost metric ( µ c ): \nµ AL  =   Acc target \nLat target µ C  =  k  × N ∑ m = 1 \ninst _ cost \nP f m \nwhere  N  is the number of models used to ensemble and inst _ cost  is the VM cost.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "To- wards addressing these challenges, we design and evalu- ate  Kraken , a DAG workflow-aware resource management framework, for efficiently running such applications by uti- lizing minimum resources, while remaining SLO-compliant. Kraken  employs proactive weighted scaling of functions, where the weights are calculated using function invocation probabilities and other parameters pertaining to the appli- cation’s DAG structure. Our experimental evaluation on a 160-core cluster using  Deathstarbench  workload suite and real-world traces demonstrate that  Kraken  spawns up to 76% fewer containers, thereby improving container utilization and cluster-wide energy savings by up to 4 ×  and 48%, respec- tively, compared to state-of-the art schedulers employed in serverless platforms.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 189,
    "augmented": false
  },
  {
    "text": "edu/kriz/learning-features-2009-TR. pdf , 2009. Arduino.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "We also conducted an empirical study on number of clusters required, and found out that the bearing set data needs about 15 to 20 clusters to maintain the inference accuracy. The data volume communicated for different number of clusters is represented in Figure 13. B APPENDIX \n16 \n-0.45 \n-0.24 \n-0.02 \n-0.07 \n-0.14 \n-0.19 \n-0.50 \n-0.40 \n-0.30 \n-0.20 \n-0.10 \n0.00 \n0 \n50 \n100 \nWalking Climbing Cycling Running Jogging Jumping Geo Mean \nError \nAccuracy (%) \nCoreset: Compressed Coreset: Reconstructed Reconstructed with Larger Model Seeker Baseline: EAP Baseline: Origin Baseline: Large DNN Error vs Fully Powered \n(a) Accuracy with MHEALTH dataset \n-0.26 \n-0.19 \n-0.76 \n-0.28 \n-0.04 \n-0.80 \n-0.60 \n-0.40 \n-0.20 \n0.00 \n0 \n20 \n40 \n60 \n80 \n100 \nWalking Climbing Cycling Running Jumping Geo Mean \nError \nAccuracy (%) \nCoreset: Compressed Coreset: Reconstructed Reconstructed with Larger Model Seeker Baseline: EAP Baseline: Origin Baseline: Large DNN Error vs Fully Powered \n(b) Accuracy with PAMAP2 dataset \nFigure 17: Accuracy and communication efficiency of  Seeker  with different data sets and sensitivity study.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 321,
    "augmented": false
  },
  {
    "text": "2020. [35]  Kate Keahey, Jason Anderson, Zhuo Zhen, Pierre Riteau, Paul Ruth, Dan Stanzione, Mert Cevik, Jacob Colleran, Haryadi S. Gunawi, Cody Hammock, Joe Mambretti, Alexander Barnes, François Halbach, Alex Rocha, and Joe Stubbs. Lessons Learned from the Chameleon Testbed.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "[91] N. A. W. . Sun, “Us solar insolation maps,”  https://www.solar-electric. com/learning-center/solar-insolation-maps.html/#Map1 , (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Palm: Scaling language modeling with pathways. Journal of Machine Learning Research , 24(240):1–113, 2023. [28] Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Machine learning at facebook: Understanding inference at the edge. In  2019 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 331–344. [82]  Carole-Jean Wu, David Brooks, Kevin Chen, Douglas Chen, Sy Choud- hury, Marat Dukhan, Kim Hazelwood, Eldad Isaac, Yangqing Jia, Bill Jia, et al.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "The HSPM accelerator’s architecture, as illustrated in Fig. 3a, comprises three pipelined stages. These stages include the data loading phase, the modular polynomial multiplication via the SDMM unit, and the final accumulation registers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "The high-pass component is quantized and entropy encoded, while the low-pass component proceeds to the next level (level n − 1 ) and serves as a prediction for the voxel’s attribute in this upper level [ 14 ]. Note that, this step also needs to be performed sequentially across the tree layers. performs linear transformations on the attribute data of each voxel pair (the voxel in level n  and its siblings along x, y, and z dimensions) to obtain a low-pass component and a high- pass component.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé Jégou. 1221–1230, 2013. The faiss library.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "In contrast, this paper attempts to exploit available approximation opportunities unique in AR holo- graphic applications, and proposes a two-stage  HoloAR  scheme to speed up the execution and save energy. Specifically, we leverage the existing foveated rendering in  Inter-Holo  to track the user’s eye movements and approximate the holograms of the objects that are outside the user interest. We also propose  Intra-Holo  to further approximate each of the object holograms, by analyzing its cur- rent distance from the user.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "These clusters represent the classes in the high dimensional feature space. When the classiﬁer sees new data ( x ), it calculates its distance from all the cluster centers as y ∗ =  min y = 1 ... t  || Φ ( x ) − μ y || . There are three cases: Case-1:  If the data is close to one of the cluster centers and belongs to its cluster boundary, then it falls into the bucket of that particular class.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "2018. Peeking Behind the Curtains of Serverless Plat- forms. In  ATC .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "Experimental results with six videos show that the combined compression schemes provide 34.0 ×  speedup compared to a state-of-the-art scheme, with minimal impact on quality and compression ratio. Keywords -point cloud compression; edge computing; video processing; energy-efﬁciency; \nI. I NTRODUCTION \nAs the world is increasingly becoming virtual and moving closer towards automation, accurate 3D representation of real-life objects in the virtual domain, be it for life-like graphics or efﬁcient autonomous driving, is becoming es- sential. Recently,  Point Cloud  (PC) consisting of millions of points, which capture the 3D geometry and attributes (e.g.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "A low latency router supporting adaptivity for on-chip interconnects. In  Proceedings of the 42nd annual Design Automation Conference , pages 559–564, 2005. [82] Youngjae Kim, Brendan Tauras, Aayush Gupta, and Bhuvan Urgaonkar.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "2020. Objectron Dataset Annotation: cup. \"https://github.com/google- research-datasets/Objectron/blob/master/index/cup_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "[8] M. Xu, M. Zhu, Y. Liu, F. X. Lin, and X. Liu, “DeepCache: Principled Cache for Mobile Deep Vision,” in  Proceedings of the Annual Interna- tional Conference on Mobile Computing and Networking (MobiCom) , 2018, p. 129–144. [9] Y. Zhu, A. Samajdar, M. Mattina, and P. Whatmough, “Euphrates: Algorithm-SoC Co-Design for Low-Power Mobile Continuous Vision,” in  Proceedings of the International Symposium on Computer Architec- ture , 2018, p. 547–560. [10] M. Riera, J.-M. Arnau, and A. Gonz´alez, “Computation Reuse in DNNs by Exploiting Input Similarity,” in  Proceedings of the International Symposium on Computer Architecture , 2018, p. 57–68.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 230,
    "augmented": false
  },
  {
    "text": "We will conduct the following research to incorporate the availability of expert accelerators, memory constraints, and workload balance to inform our algorithmic choices: Selecting Experts based on Available Expert Accelerators. As the above tasks develop optimal algorithms for dynamic morphable LLMs, they introduce many types of “affinities” (listed in Table 2) to facilitate our system and architectural level opti- mizations, which are investigated in Thrusts 2 and 3, respectively. Notably, the reverse is also true, and thus, this task will investigate the influence of resource constraints and execution environments on our algorith- mic choices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "This can be done by periodically transporting the data by swapping out storage bays. Our goal is to maximize storage at edge so that the frequency of maintenance decreases. 4 \nThe main reason these algorithms consume significant resources is because of the amount of data they handle.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "2019. Peak Signal-to-Noise Ratio as an Image Quality Metric. \"https://www.ni.com/en-us/innovations/white-papers/11/peak- signal-to-noise-ratio-as-an-image-quality-metric.html\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Vss: A storage system for video analytics. In  Proceedings of the 2021 International Conference on Management of Data , pp. 685–696, 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "We have 10 (therefore N = 10) such models and among them the least accurate model is MobileNetV1 (accuracy 70%, therefore a = 0.70). This is a standard binomial distribution problem and can be solved by using the following formula: \nP head  = N ∑ i = ⌊ N \n2   ⌋ + 1 \n\u0012 N i \n\u0013 a i   ( 1 − a ) ( N − i ) . To further quantify, let us consider the case where we need to determine if we can reach the accuracy of NasNetLarge (82%) by combining rest of the smaller models which have lesser latency than NasNetLarge.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "EC2 C5 Instances., February 2018. https://aws.amazon.com/ec2/instance-types/c5/ . [9]  Amazon. Google Preemptible VMs., February 2018. https://cloud.google.com/preemptible-vms .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Similar to the intra- frame proposals discussed in Sec. IV , we again use a simple \n290 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Motivated by the observation that the ATW transform matrix generated by rotation on a 2D image is shared by both eyes, PIMVR [57] calculated the transform matrix only once, and scheduled two tiles (one for left-eye one for right-eye) with the same coordinate to the same vault in HMC. However, in contrast to the  360 ° VR video streaming, ATW is in 2D planar format, and share the same compute results across eyes. These two characterizations indicate that such optimizations in the planar world are infeasible to be applied in 3D PT-rendering.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "[22]  A. Colin, E. Ruppel, and B. Lucia, “A reconﬁgurable energy storage architecture for energy-harvesting devices,” in  Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018 , pp. 767–781, 2018. [23]  X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, “A high- efﬁciency dual-channel photovoltaic power system for nonvolatile sensor nodes,” in  2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "We use AWS as the testbed for conducting extensive experiments. Implementation Methodology:  We developed a proto- type on top of Amazon EC2 and Lambda services to evaluate the some of the benefits of our proposed design choices. The types of instance used in our evaluation include all the c5 and m5 instances for EC2.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Model compression is typically achieved by tensor decomposition or low rank compression, i.e., by representing the higher dimensional parameter matrix in a compressed low rank form. In contrast, pruning looks at the contribution of each individual weight. While some of the weights contribute more towards accuracy, some contribute less; and the ones contributing less are dropped to reduce the parameter size as well as compute and memory footprints.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Why Coresets? Coresets, primarily used in computational geometry [ 7 ], have been recently used [ 36 ,  37 ] for machine learning and sensor networks. The aforementioned requirements moti- vate us to consider  coresets  for forming representations of the original data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "2019. CoRR (2017). [51]  Murad Qasaimeh, Kristof Denolf, Jack Lo, Kees A. Vissers, Joseph Zambreno, and Phillip H. Jones.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "The PI technique can further save  6%  more energy on average, as shown in Fig. 8a, the YOLOv3 inference with the proposed FI+SI scheme only consumes  50% energy on average, with respect to the baseline, due to the fact that  53%  of the inferences can be skipped. 2) Energy Savings:  As shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "DRQ: dynamic region-based quantization for deep neural network acceleration. In  ISCA . IEEE.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 24,
    "augmented": false
  },
  {
    "text": "We evaluate these designs using the NVPROF tool [ 37 ] and hardware power management unit on the edge GPU platform [ 36 ]. Our exper- imental results reveal that,  HoloAR  provides 29% reduction in power consumption and 2 . •  We implement both the designs on an edge GPU platform [ 36 ], without the need for any hardware modification.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "In  2018 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS) , pp. 403–406. IEEE, 2018.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "267–274. IEEE, 2003. Peter Foster, Siddharth Sigtia, Sacha Krstulovic, Jon Barker, and Mark D Plumbley.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Thus, the DNN architectures to infer these data are also different. 0 \n50 \n100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nChest Left Ankle Right Wrist Majority Voting \nFig. 2:  Accuracy of the individual DNNs and with a majority voting ensemble for different activities.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Second, How do we maintain high power efficiency of PUs during runtime? In some cases where a small amount of hologram computation required, not all of the PUs on-board are needed to be active. We plan to design and imple- ment a clock/power gating technology to switch off the un-utilized PUs and save power/energy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Yet, the expansion of these technologies to encompass large-scale storage stacks and the integration of CSDs into conventional storage systems, particularly for ML applications, remains a significant challenge and an open area of research. Bridging the Gap in Storage System Design:  There is a discernible gap in the design and concep- tualization of storage drives, systems and servers, especially in the context of ML applications. Historically, researchers have investigated these components individually, often focusing on high- performance computing, scientific computing, and database applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "[61]  Nikunj C Oza. Online bagging and boosting. In  2005 IEEE interna- tional conference on systems, man and cybernetics , volume 3, pages 2340–2345.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "In  Proceedings. RTAS 2004. 10th IEEE Real-Time and Embedded Technology and Applications Symposium, 2004. , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "At the same time, right-sizing the number of requests in VMs and correctly configuring serverless functions  is quintessential to satisfy the three pri- mary application constraints: cost, latency, and accuracy. 3.1 Model Selection \nIn accordance with  Observation 1 , model selection should be a function of any two parameters which optimize the remain- ing (third) parameter. Prior work [ 9 ] solves an optimization problem such that the input parameters are model_type, hardware_type (CPU or GPU), and the output parameter is response latency.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles  PC6, PC7  and  PC8 . Parallel computations across multiple ReRAMs and loop tiling-based computation for each ReRAM are orthogonal optimizations. Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "446–460. In  Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication . [60]  Fernando Moya Rueda, René Grzeszick, Gernot A. Fink, Sascha Feld- horst, and Michael ten Hompel.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Speciﬁcally, given two blocks with K-points, we use 2-norm attribute distances (see Equ. 2 ) to measure their difference: \nDi f f ( I block , P block ) =  ∑ K i = 1 ( r iP  − r iI ) 2  +( g iP  − g iI ) 2  +( b iP  − b iI ) 2  (2) \nwhere  P block  =  { ( x iP , y iP , z iP , r iP , g iP , b iP ) } ,  I block  =  { ( x iI , y iI , z iI , r iI , g iI , b iI ) } , for  i  =  { 1 ,..., K } . Finally, the candidate I-block which differs minimally with the P-block is picked as its “best-matched/reference” block.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 259,
    "augmented": true
  },
  {
    "text": "[65]  Atul Rahman, Jongeun Lee, and Kiyoung Choi. In  2016 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pages 1393–1398. Efﬁcient fpga acceler- ation of convolutional neural networks using logical-3d compute array.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "It leverages the PCIe interface for efficient “peer-to-peer communication”, substantially reducing communication latency and energy requirements. This setup alleviates the host CPU from handling frequent data movement interruptions. A storage platform entirely designed with CSDs is not pragmatic at the current time because of their exorbitant cost and power consumption (AMD, b; Cao et al., 2020) .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "This challenge can be addressed through proper  exemplar selection  algorithms employing representation learning techniques [ 31 ], [ 74 ], ca- pable of learning new classes in real-time. However, these compute-intensive algorithms can be optimized further through dedicated hardware acceleration. Such non-IID data distributions, evident in tasks like standard trafﬁc monitoring with varied class observations (e.g., more cars than buses, all frames having  STOP  signs), may introduce sampling bias  [ 70 ], [ 74 ] in the network.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "This aids us in the calculation of function invocation probabilities. In this section, we model the function probability estimation problem using a Variable Order Markov Model (VOMM) [ 21 ]. VOMMs are effective in capturing the invo- cation patterns of functions within each application while simultaneously isolating the effects of other applications that share them.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "0 \n200 \n400 \n600 \n0 \n0.6 \n1.2 \n1.8 \n2.4 \n3 \nCost ($) \nModel Type \nexec_time(ms) \nMemory(GB) Cost($) \nFigure 7. Cost variation for different allocations in  serverless func- tions . Compute time (seconds) and Memory allocated (GB) is shown on left Y-axis.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "the baseline) is smaller than that in YOLOv4-tiny ( 4 . 8% ), resulting in a similar reduction in the overall execution time. Note that, the reason why the overhead in YOLOv4-tiny is higher is because, YOLOv4-tiny is already a very light-weight model, and consequently, the time spent on decision making is not negligible compared to the extremely fast inference it performs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "However, to achieve this, we need some extra information about the clus- ters. In the process of coreset construction we only preserve the coordinates of the centers and the radii of the clusters, and hence miss the coordinates of the points inside the clus- ters. However, any random distribution of the lost points in the cluster could provide us with a 2 𝑟 − approximate repre- sentation of the original distribution (where  𝑟 is the radius of the cluster; refer Figure 7a for a toy example).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Google and kairos power nuclear energy agreement. [53] Google Blog. https://notebooklm.google/ \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Association for Computational Linguistics. [187] Yusen Zhang, Ruoxi Sun, Yanfei Chen, Tomas Pfister, Rui Zhang, and Sercan Ö Arik. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1592–1604, Dublin, Ireland, May 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "Gemino: Practical and robust neural compression for video conferencing. Vibhaalakshmi Sivaraman, Pantea Karimi, Vedantha Venkatapathy, Mehrdad Khani, Sadjad Fouladi, Mohammad Alizadeh, Frédo Durand, and Vivienne Sze. 730–741, 2005.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "K-means++ the advantages of careful seeding. David Arthur and Sergei Vassilvitskii. URL  https://doi.org/ 10.1145/3517207.3526973 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "9: Normalized energy consumption and savings with different conﬁgurations and video inputs. % Total Energy Saving \nCompute Energy  Consumption \nL \nR %TotalEnergySaving \nFig. The left y-axis shows the compute energy consumption normalized to the compute energy consumption in Baseline (the lower, the better).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Peter Foster, Siddharth Sigtia, Sacha Krstulovic, Jon Barker, and Mark D Plumbley. Chime-home: A dataset for sound source recognition in a domestic environment. In  2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Given a power supply level, we can derive the optimal tile size and actual duplication granularity to form the activation solution  ⟨ m, n, aG ⟩ for sequential or pipelined computation modes, respectively. Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "[37]  N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A. Wood, “The Gem5 Simulator,” SIGARCH Comput. Archit.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "This dynamic routing reduces computational overhead and energy consumption, helping in addressing the power efficiency concerns. Complementing the modular models and systems, we advocate for the use of “chiplet-based” hardware accelerators. These hardware components are designed to be flex- ible and scalable, allowing customization to specific computational needs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Intuitively, model ensem- bling can address the accuracy gap by intelligently combining different models in parallel. However, selecting the appro- priate models dynamically at runtime to meet the desired accuracy with low latency at minimal deployment cost is a nontrivial problem. Towards this, we propose  Cocktail , a cost effective ensembling-based model serving framework.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Motivated by these observations, we propose  Kraken , a workflow-aware resource management framework that minimizes the number of containers provisioned for an ap- plication DAG while ensuring SLO-compliance. We design and implement  Kraken  on  OpenFaaS  and evaluate it on a multi-node  Kubernetes -managed cluster. This is further exacerbated in the case of dynamic DAGs, where the function chain for an application is not known a pri- ori.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "K-means++ the advantages of careful seeding. In  Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms , pp. 1027–1035, 2007.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 21st International Middleware Conference . 280–295. [33]  Eric Jonas, Johann Schleier-Smith, Vikram Sreekanti, Chia-Che Tsai, Anurag Khandelwal, Qifan Pu, Vaishaal Shankar, Joao Carreira, Karl Krauth, Neeraja Yadwadkar, et al .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "•  EA  (SW) : We evaluate the  InterFrame, IntraEye ( EA ) design on a GPU, as shown in the  EA  block in Fig. In contrast, as explained earlier in Sec. IV, our design skips a huge amount of computations by exploiting the  EA  and  AE .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "However, it results in almost twice the latency and energy consumption with respect to our approach. Different from the three prior works discussed above, which mainly focus on one model, MCDNN targets a multi-model system and proposes a runtime scheduler to improve the accuracy as much as possible within a limited energy budget. This high latency/energy consumption is due to the imprecise down-sampled feature vector, and this further indicates that, a strategy that is based on feature vector memoization can still miss a lot of optimization opportunities.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Exploiting Intermittent Computing:  An obvious solution to the power problem is to run the training in a self-sustained way, i.e., without depending on the power grid and by relying on a renewable energy source like solar power; opportunities for harvesting renewables naturally scale alongside a greater number of deployment locations and solar power, even though not always available, is in abundance. Thus,  attaining a sustain- able solution for privacy-preserving, distributed continuous learning remains an ongoing pursuit. Similarly, other applications with diverse data modalities, such as LiDAR and Camera for autonomous driving, IMU, bio-sensors, and Speech for IoT, face similar issues.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "12th International Conference on Civil and Architecture Engineering. Military Technical College, 2018, pp. 12, no.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "Frame-2 needs to be carefully processed and full inference needs to be employed, as indicated by  4  in Fig. 3b. iii  Entering/Exiting Object(s) : Another scenario is where one or more objects are moving into or out from a frame (refer Frame-2 in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "75 ×  of the baseline latency to perform the PI on a frame in video HC1 [43], whereas YOLOv4-tiny takes only  ∼ 0 . 48 ×  of the baseline latency. 5) Video-Speciﬁc Analysis:  To investigate how the perfor- mance and energy behavior varies with video salient features such as the object count, objects’ motions, the fraction of area occupied by objects in an entire frame, etc., we have studied the six videos summarized in Table II.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "8b and Fig. On the other hand, our FI+SI+PI scheme can save  55% / 61%  of the execution time for YOLOv3/YOLOv4-tiny. More speciﬁcally, \nas shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "IV-B2, the RoIs are essen- tial to the out- put results. 5: Back-tracing from  out  to  in  for CONV. As discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "Inadequately provisioning containers for such functions causes requests to queue up as containers are spawned in the background. Moreover, this additional request load trickles down to all the descendants, adversely affecting their response times as well. We refer to this effect as  Cold Start Spillover .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "The current scheduler is activity aware, i.e. Furthermore, the AASR poses negligible overhead both in terms of compute and memory. while performing an inference it always tries to choose the best available sensor to perform the task at hand.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Yang, A. Howard, B. Chen, X. Zhang, A. Go, M. Sandler, V. Sze, and H. Adam, “Netadapt: Platform-aware neural network adaptation for mobile applications,” in  ECCV , September 2018. [4] “Google assistant for wearables,” 2020, https://assistant.google.com/platforms/wearables/.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "First, we use a synthetic Poisson-based request arrival rate with an average rate  𝜇 =  100. Load Generator:  We provide different traces as inputs to a load generator, which is based on Hey, an HTTP Load generator tool [ 7 ]. For energy measurements, we use an open-source version of Intel Power Gadget [ 16 ] that measures the energy consumed by all sockets in a node.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Broader Impacts: This project initiates several aspiring education and outreach activities supported by project research outcomes to involve, mentor, and empower female, underrepresented, disabled, and interdisciplinary students. Major Results: No publication yet as the project started in September 2024. References \n[1] NVIDIA A100 Tensor Core GPU., 2023.  https://www.nvidia.com/en-us/data-center/ a100/ .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "The Primary Y-axis denotes the Av- erage End-to-End Response Time, the Secondary Y-axis represents the percentage of SLOs satisfied and the X-axis indicates the Appli- cation under consideration. term  Connectivity  to denote the ratio of number of descen- dant functions to the total number of functions. Inadequately provisioning containers for such functions causes requests to queue up as containers are spawned in the background.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "Moreover, some static objects (trafﬁc light, stop sign, etc.) might be present in all frames. This creates a sampling “bias” [ 70 ] while performing the training, and often leads to catastrophic forgetting.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "VI-E ). A. Finally, we provide detailed insights on how to tailor the PCC pipeline to cater to various application preferences (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "number of depth planes. #depthPlanes \n(b) Avg. Figure 8: (a): Profiling the power breakdown on the edge GPU prototype [36]; and (b): Average number of depth planes required for four design configurations.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "75 ×  of the baseline latency to perform the PI on a frame in video HC1 [43], whereas YOLOv4-tiny takes only  ∼ 0 . 48 ×  of the baseline latency. 5) Video-Speciﬁc Analysis:  To investigate how the perfor- mance and energy behavior varies with video salient features such as the object count, objects’ motions, the fraction of area occupied by objects in an entire frame, etc., we have studied the six videos summarized in Table II.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Six student teaching labs are equipped to host digital design, FPGA, circuit design, programming, robotics/drone, and related curricula. Funded research efforts support 5 High-Performance Computing Clusters, totaling over 300 compute nodes sharing IBA, Myrinet, and GigE interconnection. The clusters offer researchers HPC and GPU con- figuration 9both A 100 and H 100)agility to target highly specialized use-cases.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 9 , the address generation stage for storing P-blocks’ deltas/residuals consumes 32 %  of total energy, while the computation for the 2-norm attribute distance consumes 51 %  energy, which dominates the total energy consumption, and is, therefore, our target for next-step optimization. Speciﬁcally, to compute the 2-norm attribute distance, two kernel functions are invoked ( Diff Squared  and Squared Sum ), which consume 35 %  and 16 % , respectively of the total energy.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "In  Eighth International Conference on Database Systems for Advanced Applications, 2003. (DASFAA 2003). Proceedings.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": ",  Q m  such that, for each subset  Q j ,   P q i ∈Q j   E q i   ≤ E b , and  m  is minimized. This reduces the number of checkpoints and the overhead associated with task switching. For example, Consider two convolution operations  C 1  and  C 2  with energy requirements  E C 1  and  E C 2 , respectively.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 ×  compared to a baseline RCA with intermittency-unaware scheduling. One can make the following observations and analyses from these results: •  For each workload with each power source,  ResiSchedule always achieves the highest throughput because it combines the best activation solution in each power cycle. The results of Naive1  are the worst because it lacks both adequate hardware resources and scheduling ﬂexibility.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "As they are less prone to drift, they need occasional updates. These teacher models are often factory trained. However, the teacher models are typically large, and with a wide parameter space can generalize the learning process better than the students.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "We detail the design of the hardware accelerated encryption and maximize the resource reuse between the exemplar selection and encryption. •  Finally we perform an in-depth exploration of this integration, supported by real-world data from domains such as autonomous driving and urban mobility, to illustrate its effectiveness in continuous learning scenarios. The proposed design provides  ≈ 2 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Restrictions apply. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. •  Our Intra-Inter-V2 (Compression efﬁciency-oriented):  Sim- ilarly, our Intra-Inter-V2 scheme (oriented towards high \n293 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Comparing the ideal latencies with practical latencies, we make the following conclusions: In our practical setting,  Pose Estimation tracks user’s motion and viewing scene to estimate the current body pose [ 53 ], and it takes around 13 . 2, respectively, for an ILLIXR playground scenario [15, 19]. 8 ms .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Although the prior works do add value to video analytics, each comes with its own problems and costs. In comparing these prior approaches with ours, we consider ﬁve critical features of DNN-based video optimization, shown in Table I: high accuracy, high performance improvement and energy sav- ings, the hardware enhancement needed, generality of decision making logic for proper approximation and correspondingly, the adaptation to various runtime conditions. Speciﬁcally, with limited energy budget or available models, MCDNN suffers from accuracy drops.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Ev- ery inference event presents a binary decision for sensor  s i : a i ( t )  ∈{ Participate (P) ,  Not Participate (NP) } . Choosing P  involves selecting an SNR level, incurring energy costs, and aiming to improve global accuracy. Choosing  NP  con- serves energy but forfeits any contribution or associated reward.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "In  ATC , 2019. [87]  Honglei Zhuang, Chi Wang, and Yifan Wang. Identifying outlier arms in multi-armed bandit.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "Moreover, CSDs hold the potential to undertake critical machine learning tasks like feature extraction and clustering, streamlining tasks like neural compression. Decoupling compute tasks needed for storing the data from the host CPU and embedding them directly within storage devices, particularly through CSDs, has demonstrated significant performance and energy benefits. Tasks traditionally performed at the storage controller level are now being offloaded to CSDs, often accelerated using FPGA primitives (Kim et al., 2021; AMD & Xilinx; AMD, a).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "general, robust and larger model (typically with hundreds of millions of parameters [ 43 ], [ 99 ]) helps in annotating the data. However, because of the heavy compute requirements, the teacher model runs with a much slower frame rate and annotates only some (important) frames. There has been a signiﬁcant body of work on frame similarity and saliency [ 45 ], [ 84 ], [ 101 ], [ 105 ], [ 107 ], [ 108 ], and those details remain beyond the scope of this work.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "We took a history (years 2019 and 2020; from Seattle, WA; Sterling, VA; and Oak Ridge, TN) of solar energy traces from SOLRAD [ 25 ], [ 91 ] and built a weight matrix which looks into a window of 1 hour at 1 minute (average power) intervals to predict the power for next 10 minutes (1 minute granularity). We use regression to ﬁnd the weights (exponents and coefﬁcients) to the prediction curve followed by exponential smoothing to decay the weights. The rate of exponential smoothing depends on the scheduler used - while for the conservative scheduler the predictor always underestimated the power (shallow smoothing), the eager scheduling uses the direct output of the predictor (steeper smoothing).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 170,
    "augmented": false
  },
  {
    "text": "[4] Discovery, “Caring for Rhinos: Discovery VR (360 Video).” ”https:// www.youtube.com/watch?v=7IWp875pCxQ”, 2019. [5] Discovery, “Elephants on the Brink.” ”https://www.youtube.com/watch? 199–204.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Note that  Us. Instead of simulating the CPU, we tested the K-means clustering and cluster optimization on a mobile SoC with 8 ×  ARM Cortex A78 series CPU. Table  II gives the key attributes of the implemented hardware against some of the prior accelerators.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "[74] Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bam- ford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. arXiv preprint arXiv:2401.04088 , 2024. Mixtral of experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "ﬁnish training on the exemplars (described in § III-B ) as soon as possible and also reach the desired accuracy – but to do this within the harvested budget. Prior works [ 34 ], [ 48 ], [ 68 ] suggest that selecting the right hyper-parameters (like batch size, learning rate, number of layers to train etc.) have a huge impact on the convergence and accuracy of the models.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "[39]  Objectron. 2020. \"https://github.com/google- research-datasets/Objectron/blob/master/index/bike_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "2020. In  2020  { USENIX }  Annual Technical Conference ( { USENIX }{ ATC }  20) . 205–218.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "For brevity in explana- tion, the results are averaged across Wiki and Twitter traces for strict workload. 6.2.1 Beneﬁts from dynamic model selection \nFigure  9a  plots the average number of models used for queries falling under the ﬁrst four different constraint (const) types. Here,  Cocktail  reduces the number of models by up to 55% for all four query types.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors,  Pro- ceedings of the 40th International Conference on Machine Learning , volume 202 of  Proceedings of Machine Learning Research , pages 38087–38099. PMLR, 23–29 Jul 2023. [168] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Figure  5  depicts the high-level design of  Cocktail . 4 Overall Design of Cocktail \nMotivated by our observations, we design a novel model- serving framework,  Cocktail , that can deliver high-accuracy and low-latency predictions at reduced cost. Aggregator \nMaster VM \nUser Requests \n… … … … … \nQueries Cost aware Procurement \nImportance Sampling \nModel-1  Model-2  Model-3  Model-4  Model-n  \noutput \nHeterogeneity \nPrediction Policy \nAutoscaler \nResource Controller \nLoad Balancer \n argmax O 1  (latency)  argmin O 2  (accuracy) \nCPU GPU CPU GPU \nObjectives \n1a \n3 \n4b \n1b \n2 4 \n4a \n4b \n1 \n6 \n6b \n6a \nw1 w2 w3 wk w4 \n3 \n5  Bin-Packing \nWeight Matrix \nL \nN \nFigure 5:  High-level overview of  Cocktail  design.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 204,
    "augmented": true
  },
  {
    "text": "Therefore, the standard data compression techniques are not very useful, let alone their energy efficient (such as quantized versions [ 33 ]) counterparts. And we will not achieve a sufficient com- pression ratio from lossless approaches either. images), inference on low-dimensional sensor data (such as inertial measure- ment unit or IMU vibration data) is much more sensitive to lossy compression as separating between features might be difficult to do.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "However, this poses a chicken and egg problem – to know which sensor is the best for classifying an activity we need to know what activity is going to be performed beforehand. Intuitively, human activities do not usually stop abruptly, i.e. However, while perfect future knowledge remains impossible, in the context of HAR, we can anticipate the next activity from the previous activity with high conﬁdence.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. #depthPlanes \n(b) Avg. baseline InterHolo IntraHolo InterIntraHolo \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "3388–3392. [74]  R. Schnabel and R. Klein, “Octree-based point-cloud compres- sion,” in  Proceedings of the 3rd Eurographics / IEEE VGTC Conference on Point-Based Graphics , 2006, p. 111–121. [75]  S. Schwarz, M. Preda, V. Baroncini, M. Budagavi, P. Cesar, P. A. Chou, R. A. Cohen, M. Krivoku ´ ca, S. Lasserre, Z. Li, J. Llach, K. Mammou, R. Mekuria, O. Nakagami, E. Siahaan, A. Tabatabai, A. M. Tourapis, and V. Zakharchenko, “Emerging mpeg standards for point cloud compression,”  IEEE Journal on Emerging and Selected Topics in Circuits and Systems , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 225,
    "augmented": false
  },
  {
    "text": "This is because it uses statically assigned function weights, which prevents it from being able to proactively spawn con- tainers according to the varying user input. DProb and  SProb  exhibit higher overall end-to-end response times compared to  Kraken , with  SProb  experiencing a dispropor- tionately high queueing delay compared to its cold start delay. This results in the majority of requests getting queued at the containers.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2211.05100 , 2022. Mixture of lora experts. [166] Xun Wu, Shaohan Huang, and Furu Wei.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "Deep- Holo: Recognizing 3D Objects Using a Binary-Weighted Computer-Generated Hologram. In  SIGGRAPH Asia 2017 Posters . [34]  NASA.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "For  N  models, where each model has a minimum accuracy ‘ a ’, we model the ensemble as a coin-toss problem, where  N  biased coins (with probability of head being  a ) are tossed together, and we need to ﬁnd the probability of major- ity of them being heads. For this, we need at least  ⌊ N \n2   ⌋ +  1 models to give the same results. The probability of correct prediction is given by \nN ∑ i = ⌊ N \n2   ⌋ + 1 \n\u0012 N i \n\u0013 a i   ( 1 − a ) ( N − i ) \nModel Selection Algorithm:  To minimize  µ C , we design a policy to downscale the number of models, if more than N/2+1 models vote for the same classiﬁcation result.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 178,
    "augmented": true
  },
  {
    "text": "Then the optimal solution can be selected from among them. It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode. The solution space is actually very small because of the constraints that tile size candidates and aG  are all bounded in the integer domain.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "In addition, we design a scheme named Paragon on top of AWS platform, which incorporates some of the proposed design choices. 2 Characterization and Motivation \n2.1 Variability across model types \nDepending on the accuracy and latency requirements of an end-user application, multiple models (shown in Figure  1 ) might satisfy a given constraint. Our initial results show that Paragon can reduce cost of hosting ML prediction serving by up to 20% when compared to the state-of-the-art prior works, for diverse accuracy and latency constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "Typically, these online service ap- plications are user-facing and hence, are administered under strict Service Level Objectives (SLOs) [ 47 ,  48 ] and response latency requirements. Ex- pedia [ 15 ] and Airbnb [ 2 ]). Many of these real-world services often comprise of tens or even hundreds of loosely-coupled microservices [ 42 ] (e.g.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "The discriminator tries to discriminate between the actual data and the synthesized data. Considering the fact that we do have access to the sensor data to train the learning algorithm, we can use the same data to train the GAN and with sufficient data, the discriminator could generate the lost signal with minimum error. We fine-tune the network until the discriminator is fooled sufficiently to distinguish between the original data and the recovered data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "[80] A. Sarma, S. Singh, H. Jiang, A. Pattnaik, A. K. Mishra, V. Narayanan, \nM. T. Kandemir, and C. R. Das, “Exploiting activation based gradient output sparsity to accelerate backpropagation in cnns,”  arXiv preprint arXiv:2109.07710 , 2021. [79] A. Samajdar, Y. Zhu, P. Whatmough, M. Mattina, and T. Kr- \nishna, “Scale-sim: Systolic cnn accelerator simulator,”  arXiv preprint arXiv:1811.02883 , 2018. 1041– 1044.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 189,
    "augmented": true
  },
  {
    "text": "% Total Energy Saving \nCompute Energy  Consumption \nL \nR %TotalEnergySaving \nFig. 9: Normalized energy consumption and savings with different conﬁgurations and video inputs. The left y-axis shows the compute energy consumption normalized to the compute energy consumption in Baseline (the lower, the better).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Seeker  (RF) \nAll compute at edge Partial compute at edge \nDesign space of  “Seeker” \n(b) Current state-of-the-art of EH-WSN. Figure 1: A primer on energy harvesting systems: Fig- ure 1a shows the basic building blocks of an EH node equipped with sensing and computation. Some of the units change according to the harvested energy source.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "4) Finally, we provide a detailed evaluation of  Origin , and show that, even when powered by an unreliable EH source, the efﬁciency achieved by the this system results in better accuracy than that of a fully powered system running state of the art classiﬁers optimized for energy efﬁciency. Origin reaches 83.88% top-1 accuracy compared to the 81.16% accuracy of the baseline system. II.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Moreover, most of the ex- isting solutions targeting such applications demand specialized hardware and/or compiler support, and it is not straightforward for a developer to deploy them without multi-domain expertise across the optimization, compilers and hardware spectrum. In fact, the inference of VGG-16 [31], which is a popular DNN model, takes 240  ms  to execute on an embedded Adreno 640 [32] GPU, which is far from  real-time . However, in the speciﬁc context of video applications, the “temporal continuity nature” of the video data presents itself as an opportunity that is yet to be fully exploited.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "This observation reveals an opportunity to perform partial inference (PI)  by operating only on the bounding boxes and MV regions. Next, we study the following three questions in detail: (i) for which frames can we opt for the PI?, (ii) how to maintain the accuracy?, and ﬁnally, (iii) how to do the PI? 2) High-level Idea:  To answer the above questions, we propose region-level partial inference (PI) to ﬁrst determine \nAlgorithm 2:  Region Level Reuse Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "Their seamless integration into everyday life across diverse domains—such as virtual assistants [12,16,51], customer service chatbots [6,121], code generation tools like GitHub Copi- lot [48], and knowledge management systems like NotebookLM [52]—has profoundly impacted how we interact with technology. According to the 2023 McKinsey Global Survey on AI [4], 65% of respondents indicated that their organizations are now utilizing generative AI technologies powered by LLMs, a fig- ure that has nearly doubled from a survey conducted ten months earlier. In healthcare for instance, more than 40% of institutions are leveraging LLMs to enhance patient care through improvements in diagnos- tics, patient support, and documentation efficiency [122, 130, 142, 176].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "), we utilize the octree-based method to compress the geometry data losslessly, while the attributes are compressed by the predictive RAHT lossily. Especially, by tuning the parameters (e.g., octree depth, compression algorithm, etc. Video Redandblack Longdress Loot Soldier Andrew10 Phil10 #Frames 300 300 300 300 318 245 #Points/Frame 727070 834315 793821 1075299 1298699 1486648 \nB. PCC Design Conﬁgurations \nTo demonstrate the effectiveness of our proposal, we evaluate the following ﬁve PCC designs: •  TMC13  [ 56 ]: We use TMC13 (G-PCC codec from MPEG), as the  state-of-the-art  approach for  intra-frame compression .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 183,
    "augmented": true
  },
  {
    "text": "0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 RR3 with AAS RR6 RR6 with AAS RR9 RR9 with AAS RR12 RR12 with AAS Fig. 4:  Accuracy results for AAS combined with ER-r. Even though AAS provides signiﬁcantly better results com- pared to standard round-robin, it is still unable to incorporate ensemble learning.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "TABLE IV: Comparison against Potluck and MCDNN \nmAP Latency Energy MCDNN 36.9% 33% 35% Potluck 51.6% 63% 61% This Work 50.3% 35% 34% in Fig. 8d and Fig. 9d, DeepCache can only save  38% and  45%  on execution time for YOLOv3 and YOLOv4-tiny, respectively, which are less than both FI+SI (e.g., 52% for YOLOv3; 53% for YOLOv4-tiny) and FI+SI+PI (e.g., 55% for YOLOv3; 61% for YOLOv4-tiny) schemes.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "He has an extensive research background and publication record in efficient methods for LLMs such as LLM pruning (NAACL 2024), LLM parameter-efficient finetuning (ACL 2022, EMNLP 2023), long-context LLMs (ACL 2022, NeurIPS 2024), data selection for LLM in-context learning (ICLR 2023). All the three PIs will work in close coordination on the individual research topics as well as the overall integration of the project. In the context of this project, he will lead Thrust-1 and also co-lead Thrust-4 with Kandemir and Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Perform the forward pass with the updated dropout mask to obtain the output  Y . Otherwise, maintain or reduce the dropout rate to improve accuracy. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "An FSM transition can happen between any pair of power levels. Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy. Activation solution under power level  l: <m l , n l , aG l > \nActivation solution under power level  h: <m h , n h , aG h > \nSmooth transition l->h without power prediction \nSmooth transition l->h \nwith power prediction \nSmooth transition h->l without power prediction \nSmooth transition h->l \nwith power prediction \n1 \n2 \n3 \n4 \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication . Polymorphic radios: A new design paradigm for ultra- low power communication. 2018.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "To support user programs (  P1  ), we implement a moving window-based power predictor (  P2  ) which takes its input from the on-board EH capacitor. Considering the energy available, the predictor makes an informed decision on how to proceed. Recover(IS#)   Infer(RData) \nRdf4mFRAM(#3) \nret 2 //T=task_next ret -1 //pwr emgncy \nret 1 //Coreset ret 2 //T=task_next \nInt Pred_Pwr(task_next)    ...    ret 2 //T=task_next    ret 1 //save to coreset    ret 0 //backup    ret -1 //pwr emgncy \nPower  Emergency \nHardware Supported Monitoring, Backup and Restore \nP1 P2 L1 \nC1 C2 \nCn \nT1 T2 T3 \nLb \nLr \nL3 \nT4 \nT5 \nL3 \nFigure 2: Software-Compiler-Hardware Driven DynInfer Flow.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 247,
    "augmented": true
  },
  {
    "text": "A survey on hallucination in large lan- guage models: Principles, taxonomy, challenges, and open questions. arXiv preprint arXiv:2311.05232 , 2023. [67] Shaomang Huang, Jianfeng Pan, and Hanzhong Zheng.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Considering the power proﬁle of Fig. 11b ,  Us. ´as  maintains a high duty cycle across power variance, whereas DaDianNao [ 16 ] could not be active for all the power cycles.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "This ﬂexible reconﬁgurability enables ﬁne-grained activations to exploit the harvested power. Fine-grained reconﬁguration:  The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes. While execution is relatively straightforward when maintaining a speciﬁc conﬁguration of tiling and pipelining strategy, transitions between conﬁgurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Observation 3:  Only-VM based resource procurement should not be used during dynamic load as it leads to over-provisioned resources and increased cost. 0 \n500 \n1000 \n1500 \nwiki WITS berkley Twitter \nRequest Rate \nAvg Req \nMax Req \nFigure 6. 2.4 Using  serverless functions  with VMs \nThe provisioning latency is a major contributor for VM over-provisioning during request surges be- cause the increased time to provision new VMs results in the increase of response latencies which in-turn leads to provisioning more VMs in advance.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "II. M OTIVATION \nA major challenge while executing a DNN inference on an energy harvesting sensor is the power budget. The conventional \nmethod, where the sensors collect the data and send it to the cloud or any other host device (such as connected mobile phones) is not an effective option as communicating large data demands more power, which is both highly variable and scarce in EH systems.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "3. Layered Encoding:  Each layer of the neural codec can be implemented using parallel processing units in FPGA, allowing simultaneous processing of different frame parts or different quality layers. 4.Data Flow Management:  Design efficient data paths to handle the high throughput of video data and intermediate results between the FPGA blocks, ensuring that bandwidth and memory access bottlenecks are minimized.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "4 ms  and achieves 2 . 06 °  of accuracy [ 26 ]. Thus, both of these two tasks are able to meet the performance re- quirements shown in Table 1.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Next, we study the following three questions in detail: (i) for which frames can we opt for the PI?, (ii) how to maintain the accuracy?, and ﬁnally, (iii) how to do the PI? This observation reveals an opportunity to perform partial inference (PI)  by operating only on the bounding boxes and MV regions. 2) High-level Idea:  To answer the above questions, we propose region-level partial inference (PI) to ﬁrst determine \nAlgorithm 2:  Region Level Reuse Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "However,  Clipper-X  does not scale down models as frequently as  Cocktail , while ensuring similar accuracy. Clipper  is less accurate than  Cocktail  and further it uses all 10 models throughout. 6.2.2 Beneﬁts from Autoscaling \nFigure  11  plots the reduction in the number of VMs used by all four schemes.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Qunying Huang and Chen Xu. A data-driven framework for archiving and exploring social media data. 685–696, 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "[2] “Use fall detection with apple watch,” 2020, https://support.apple.com/en- us/HT208944. [3] T.-J. Yang, A. Howard, B. Chen, X. Zhang, A.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Yang, J. Emer, and V. Sze, “Eyeriss v2: A ﬂexible \naccelerator for emerging deep neural networks on mobile devices,” IEEE Journal on Emerging and Selected Topics in Circuits and Systems , vol. 9, no. 2, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "B ´ edorf, E. Gaburov, and S. P. Zwart, “A sparse octree gravitational n-body code that runs entirely on the GPU processor,”  Journal of Computational Physics , pp. 2825–2839, 2012. [6]  M. Beg, Y. C. Chang, and T. F. Tang, “Performance evaluation of error resilient tools for mpeg-4 video transmission over a mobile channel,” in  2002 IEEE International Conference on Personal Wireless Communications , 2002, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "However, existing serverless providers are un- aware of the workflow characteristics of application DAGs, leading to container over-provisioning in many cases. This is further exacerbated in the case of dynamic DAGs, where the function chain for an application is not known a pri- ori. Serverless functions, hav- ing short resource provisioning times and instant scalability, are suitable candidates for developing such latency-critical applications.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Additionally, we compare  Kraken  against policies with (a) statically assigned function probabilities ( SProb ) and (b) func- tion probabilities that dynamically adapt to changing invoca- tion patterns ( DProb ). These policies use all the components of  Kraken  except  Commonality  and  Connectivity . 5.3 Large Scale Simulation To evaluate the effectiveness of  Kraken  in large-scale sys- tems, we built a high fidelity, multi-threaded simulator in Python using container cold start latencies and function execution times profiled from our real-system counterpart.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. of the scheduled training without any intermittency support.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "The bars are all normalized to  ResiSchedule . A. Throughput \nFigure 8 shows the throughput comparison of the ﬁve exe- cution strategies. We also study the sensitivity of our proposed approach to available ReRAM hardware resources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "We see that, the number \n4 Due to space limitation, we chose six representative categories that cover diversity across multiple video parameters. 502 \nMICRO ’21, October 18–22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 4413.87 4243.51 3190.25 3135.99 \n0 1000 2000 3000 4000 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": ". , c n } 3:  Initialize MobileNet Model  M 4:  Initialize Autoencoder Decoder  D 5:  Initialize Motion Vector Extractor  V 6:  procedure  E XTRACT F EATURES ( frame ) 7: features  ← M ( frame ) ▷ Extract features using MobileNet 8: return  features 9:  end procedure 10:  procedure  C OMPRESS F EATURES ( features ) 11: compressed  ← D ( features ) ▷ Compress using autoencoder 12: return  compressed 13:  end procedure 14:  procedure  C ALCULATE M OTION V ECTORS ( frame current , frame previous ) 15: motion _ vectors  ← V  ( frame current , frame previous ) 16: return  motion _ vectors 17:  end procedure 18:  procedure  S TACK C OMPRESSION ( current _ compressed, motion _ vectors ) 19: return  some compression algorithm using  current _ compressed  and  motion _ vectors 20:  end procedure 21:  for  i  ← 1  to  n  do 22: features i  ← E XTRACT F EATURES ( f i ) 23: c i  ← C OMPRESS F EATURES ( features i ) 24: if  i >  1  then 25: m i  ← C ALCULATE M OTION V ECTORS ( f i , f i − 1 ) 26: c i  ← S TACK C OMPRESSION ( c i , m i ) 27: end if 28: C [ i ]  ← c i 29:  end for \nBy exploiting the temporal correlations between consecutive frames, our codec can significantly reduce the required bitrate while maintaining high video quality. The primary innovation lies in leveraging motion vectors to identify and encode only the changes between frames, rather than re-encoding entire frames.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 442,
    "augmented": false
  },
  {
    "text": "Un- derstanding energy efficiency in iot app executions. In  2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS) , pages 742–755, 2019. [190] Shulin Zhao, Prasanna Venkatesh Rengasamy, Haibo Zhang, Sandeepa Bhuyan, Nachiappan Chi- dambaram Nachiappan, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "On the other hand, the YOLOv4-tiny inference with the FI+SI scheme saves  53%  energy w.r.t. the baseline, as shown in Fig. 9a.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Viewer in-consumption engagement in pro- environmental tourism videos: A video analytics approach. URL https://doi.org/10.1145/3466752.3480056 . Jingjie Zhu, Mingming Cheng, and Ying Wang.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "2 Yaw: vertical; Pitch: side-to-side; Roll: front-to-back. 27 ×  the power compared to its planar counter- parts (1.5  Watts ). We also observe that, unlike conventional planar video processing where  memory  is the main bottleneck ( 43% ), in  360 ° VR video processing,  compute  dominates the \n1 Pupillary distance is the distance, typically measured in millimeters, between the centers of the pupils of the eyes.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "To address these challenges, we propose  Kraken , a DAG workflow-aware resource management framework specifi- cally catered to dynamic DAGs, that minimizes resource con- sumption, while remaining SLO compliant. However, not proportionately allocating containers to all functions in the application can lead to under-provisioning containers for some functions when requests deviate from the predicted path. This results in container provisioning along a single function chain.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. 51% \n32% \n17% \n2-Norm Attri.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "1: Data drift on different data modalities. Sampling window size: 4hours for video, 20 minutes for audio for urban trafﬁc video and audio data. 1hour for 3D Point Cloud simulated data.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "HPG ’16, 2016, pp. 163–171. [49] C.-H. Tsai, H.-T. Wang, C.-L. Liu, Y. Li, and C.-Y.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Yang, J. Emer, and V. Sze, “Eyeriss v2: A ﬂexible \naccelerator for emerging deep neural networks on mobile devices,” IEEE Journal on Emerging and Selected Topics in Circuits and Systems , vol. 2, pp. 9, no.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Fortunately, these computations are light-weight, and can be performed in parallel. •  Quantization:  Finally, these small residual values are quantized to further improve the compression ratio. Therefore, instead of recording the exact attribute values for all the points within a segment, we only need to ﬁnd the “ median value ” of these attributes (as base) and then compute and compress the  residual values (as deltas) for these points.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "URL https://doi.org/10.1145/3466752.3480056 . Associa- tion for Computing Machinery. ISBN 9781450385572. doi: 10.1145/3466752.3480056.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "2020. [40]  Objectron. \"https://github.com/ google-research-datasets/Objectron/blob/master/index/book_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "This, in turn, triggers autoscaling to provision extra containers to service the load surge. Algorithm 2  Reactive Scaling \n1:  for  Every Monitor_Interval= DR  do 2: Reactive_Resource_Manager ( ∀ 𝑓𝑢𝑛𝑐𝑡𝑖𝑜𝑛𝑠 ) 3:  procedure  Reactive_Resource_Manager( func ) 4: cl  ← 𝐶𝑢𝑟𝑟𝑒𝑛𝑡 _ 𝐿𝑜𝑎𝑑 ( 𝑓𝑢𝑛𝑐 ) 5: func.existing_con  ← 𝐶𝑢𝑟𝑟𝑒𝑛𝑡 _ 𝑅𝑒𝑝𝑙𝑖𝑐𝑎𝑠 ( 𝑓𝑢𝑛𝑐 ) 6: if l c 𝑙 f 𝑢𝑛𝑐.𝑏𝑎𝑡𝑐ℎ _ 𝑠𝑖𝑧𝑒 m ≤ func.existing_con  then  a \n7: reqd_con  ← l c 𝑙 f 𝑢𝑛𝑐.𝑏𝑎𝑡𝑐ℎ _ 𝑠𝑖𝑧𝑒 m \n8: else 9: #_delayed_requests  ← Delay_Estimator ( 𝑓𝑢𝑛𝑐 )  b 10: extra_con  ← l  #_delayed_requests \nf 𝑢𝑛𝑐.𝑏𝑎𝑡𝑐ℎ _ 𝑠𝑖𝑧𝑒 m \nc 11: reqd_con  ← func.existing_con + extra_con 12: Scale_Containers ( 𝑓𝑢𝑛𝑐,𝑟𝑒𝑞𝑑 _ 𝑐𝑜𝑛 ) \nOpenFaaS  is deployed on top of  Kubernetes  [ 9 ], which acts as the chief container orchestrator. OpenFaaS , by default, comes packaged with an Alert Manager module which is re- sponsible for alerting the underlying orchestrator of request surges by using metrics scraped by  Prometheus , which is an open-source systems monitoring toolkit [ 12 ].",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 375,
    "augmented": true
  },
  {
    "text": "In this section, we model the function probability estimation problem using a Variable Order Markov Model (VOMM) [ 21 ]. One key driver for the design lies in a  Probability Estimation Model  for individual functions, which is explained below. 3 Function Probability Estimation Model As elucidated in  Opportunity-1 , to specifically address the container over-provisioning problem for DDAs, we need to estimate the weights to be assigned to their composite func- tions, a key component of which is the function invocation probability.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "X \nS ⊆N\\{ i } \n| S | ! ( |N| −| S | − 1)! |N| [ L ( S  ∪{ i } )  −L ( S )] \nwhere  N  is the set of all neurons,  S  is a subset of neurons not containing  i , and  L ( · )  denotes the loss function.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "4 DESIGN IMPLEMENTATION OF  SEEKER \nBy leveraging the coreset construction techniques discussed in Section 3, we design  Seeker: A synergistic sensor host ecosys- tem . Seeker  lever- ages the concept of NVP, and employs a flexible store and execute method using the state of the art ReRAM crossbar architecture [ 47 ] to perform inference at the edge. Figure 5 gives a pictorial representation of the overall design of  Seeker  and its various components.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \nKitti Vision nuScenes Chime Cityscapes Waymo \nNormalized Latency \nCompute Server CSD Alveo FPGA \nFigure 4: Latency analysis of  Salient Store  on the commercial Xilinx CSD on a workstation class machine (lower is better). The configuration of the server with Xilinx CSD has a 12-core Xeon bronze CPU with 128GB memory,  2 × 3.84TB CSDs, and  2 × 2TB SSDs. Similarly, the AWS server has 24 cores, with 192GB memory, one Alveo FPGA and 2TB SSDs.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "As shown in Fig. 9 , a single teacher, even with the augmented heuristics, typically fails to select the right exemplar set. The exemplar set signiﬁcantly impacts the accuracy in two ways: 1. missing valid exemplars will result in the student model missing out in learning vital information, increasing its drift, and 2. a wrong annotation by the teacher can also result in the student learning wrong labels, resulting in increased mis-predictions.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "The ReRAM devices are programmed to have different resistance values, which are used to store the weights. During the multiplication-addition operation, the input signals are applied to the rows of the x-bar, and the weights are applied to the columns. The output of each ReRAM device is the product of the input and weight signals, which are added together using the crossbar wires.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Figure  7  shows the computation time and cost for executing 1 million infer- ence queries for three different model types with different memory allocations. We vary the memory allocation, starting from least required memory for the model to the maximum available limit in AWS (3GB) 1 . It can be clearly seen that the computation time reduces with increased memory alloca- tion but also results in higher cost of deployment for every model type.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Along this trend, prior approaches have targeted improving either accuracy or performance. C ONCLUDING  R EMARKS \nPushing DNN-assisted video analysis into edge is the cur- rent trend in applications like surveillance, assisted surgery, and VR/AR [23]. In contrast, this paper revisits the  < accuracy, energy, performance >  design space, and tunes the design knobs adaptively with the changing constraints of applications over time.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Cognitive computing and wireless communications on the edge for healthcare service robots. Shaohua Wan, Zonghua Gu, and Qiang Ni. https://github.com/edge-video-services/ekya#urban-traffic-dataset.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "We leverage data memoization to skip unnecessary compute saving inference execution time and energy. •  Efficient Hardware:  We propose simple, low power, and low latency hardware to efficiently build coresets, further increasing the number of samples that can be inferred or transmitted under EH budget, and thereby significantly improving the accuracy over the state-of-the-art ( ≈ 5%). We develop a non-volatile hardware accelerator, with mul- tiple quantization support, for efficient DNN inference.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "19 \nD.4 Learning Sparse Masks Dropout with QuantaTask Optimization \nLearning Sparse Masks Dropout adapts dropout masks as learnable parameters within the network, inspired by Wen et al. (2016), combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Mathematical Formulation:  Let  W  be the weight matrix of a layer.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication. This execution strategy is referred as Naive2 . None of  Naive1  and  Naive2  executions can go through power cycle  PC-i  and the power utilization is very low, as there is a signiﬁcant mismatch between the power producer and consumer.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Rationale Behind Method Design:  The overall method design of NExUME is motivated by the need to enable DNNs to function reliably in environments with intermittent and unpredictable energy supply. By integrating energy variability into both training and inference, we allow the DNN to adapt its computational load dynamically, ensuring that critical tasks are completed within energy constraints. This holistic approach addresses the limitations of existing methods that treat training and inference separately or do not account for real-time energy fluctuations.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Since these inference requests are often user-facing, it is imperative to administer them under a strict service level ob- jective (SLO). We deﬁne SLO as the end-to-end response latency required by an application. Services like Ads and News Feed [ 39 , 44 ] would require SLOs within 100ms, while facial tag recommendation [ 83 ] can tolerate up to 1000ms.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "We observe that the system used in [ 47 ] does not aggressively employ quantization, which is a commonly used technique [ 64 ] to reduce both compute and transmission energy in DNN tasks. Al- though accuracy can increase by further tuning duty-cycle, as shown in Figure 2b, the returns are diminishing, and in- definite increase of duty cycle is also not an option as that might lead to skipping important data to infer. 7% of the inferences scheduled on a sensor.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "In  Cock- tail , we leverage these transient VMs such as spot instances to drastically reduce the cost of deploying ensembling model framework. Although dynamic model selection poli- cies can signiﬁcantly reduce the resource footprint as shown in Figure  3b , the cost is still 20-30% higher when compared to a single model inference. Most cloud providers offer tran- sient VMs such as Amazon Spot instances [ 69 ], Google Pre- emptible VMs [ 9 ], and Azure Low-priority VMs [ 7 ], that can reduce cloud computing costs by as much as 10 ×  [ 3 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "On the other hand, the two  P 2  points are relatively far away from each other and their attribute inputs are quite different, offering little reuse opportunity. 2) How to Capture the Temporal Opportunity? To summarize, in this example, the ﬁrst two points in I-Frame,  P 0  and  P 1 , could be reused for compressing the P-Frame, thus reducing the compressed output size.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "9a; viewing an entire hologram (in Fig. 9b); and a partial \n5 The data is from our estimation based on [ 51 ], rather than real-hardware measurements. 503 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ’21, October 18–22, 2021, Virtual Event, Greece \n(a) Viewing W-CGH from different eye-center positions.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "As a result, by exploiting the  AE  scheme on the ﬁrst frame in Fig. Therefore, only for this small number of pixel coordinates, the entire coordinate projection computations need to be processed. Algorithm 1  Algorithm to capture and utilize the pattern  Δ \nInput:  [ ⃗x 0: n − 1 l , ⃗y 0: n − 1 l ] : left-eye projection (all rows) Input:  [ ⃗x 0 r , ⃗y 0 r ] : right-eye ﬁrst-row’s projection Output:  [ ⃗x 1: n − 1 r , ⃗y 1: n − 1 r ] : right-eye projection \n1:  procedure  C APTURE P ATTERN ( ⃗x 0 r ,  ⃗y 0 r ,  ⃗x 0 l   ,  ⃗y 0 l   ) \n2: [Δ x ,  Δ y ]  :=  [ ⃗x 0 r   − ⃗x 0 l   ,  ⃗y 0 r   − ⃗y 0 l   ] 3: return  Δ = [Δ x ,  Δ y ] \n4:  end procedure \n5:  procedure  U TILIZE P ATTERN ( ⃗x 1: n − 1 l ,  ⃗y 1: n − 1 l ,  Δ ) 6: [ ⃗x 1: n − 1 r ,  ⃗y 1: n − 1 r ]  :=  [ ⃗x 1: n − 1 l +  Δ x  ,  ⃗y 1: n − 1 l +  Δ y ] \n7: return  [ ⃗x 1: n − 1 r ,  ⃗y 1: n − 1 r ] 8:  end procedure \nThe Effect of AE:  with this  AE  optimization, for the right eye, the intensive projective transformation computations can now be short-circuited by light-weight  Add  operations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 494,
    "augmented": true
  },
  {
    "text": "Hence, it is evident that there is a large optimization space where different models can be selected based upon the needs of the applications. Prior work  [ 9 ] tries to solve model selection only from a through- put perspective where different sized batching of multiple inference queries together results in varied throughput. Observation 1:  Model selection should be focused on meeting the cost requirement of an application without compromising on the accuracy and/or latency constraint.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "2. L -smoothness of  ℓ . There exists a constant  L >  0 such that for all  θ, θ ′ , \n∥∇ L ( θ )  −∇ L ( θ ′ ) ∥≤ L ∥ θ  − θ ′ ∥ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "83 538–83 547, 2020. [32]  J. Kim, J. Im, S. Rhyu, and K. Kim, “3d motion estima- tion and compensation method for video-based point cloud compression,”  IEEE Access , pp. [31]  T. Karras, “Maximizing parallelism in the construction of bvhs, octrees, and k-d trees,” in  Proceedings of the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics , 2012, p. 33–37.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "In  Information Security Practice and Experience: 11th International Conference, ISPEC 2015, Beijing, China, May 5-8, 2015, Proceedings , pp. 454–468. Springer, 2015.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "For example, by using the ensembling   1 \ntechnique, images can be classiﬁed using multiple models  in parallel  and results can be combined to give a ﬁnal prediction. This signiﬁcantly boosts accuracy compared to single-models, and for this obvious advantage, frameworks like Clipper [ 27 ] leverage ensembling techniques. Unlike single-model inferences, more sophisticated tech- niques like  ensemble learning  [ 15 ] have been instrumental in allowing model-serving to further improve accuracy with multiple models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Survey on wireless sensor network applications and energy efficient routing protocols. Wireless Personal Communications 101, 2 (2018), 1019–1055. 2018.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "IEEE Access , 10:101999–102008, 2022. Kaisheng Ma, Xueqing Li, Karthik Swaminathan, Yang Zheng, Shuangchen Li, Yongpan Liu, Yuan Xie, John Jack Sampson, and Vijaykrishnan Narayanan. Nonvolatile processor architectures: Efficient, reliable progress with unstable power.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "[31] Reetuparna Das, Onur Mutlu, Thomas Moscibroda, and Chita R Das. ACM SIGARCH computer architecture news , 38(3):106–116, 2010. Aergia: Exploiting packet latency slack in on-chip networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": ": Battery, Bonito [ 22 ], Chinchilla [ 43 ], ResiRCA [56], Origin [47]) \ncompute are not energy efficient to run with all modali- ties of harvested energy since all of them do not have the same energy income (see Figure 1b). For example, there has been significant work on enabling solar powered smart farm- ing [ 63 ,  67 ], but the same can not be done for smart manufac- turing due to the lack of solar exposure and the low fidelity of the available EH sources such as vibration and RF (from WiFi or other sources). To estimate the required energy, we ran simple HAR inferences (optimized version of [ 26 ] for edge deployment using [ 68 ]) on an Adafruit ItsyBitsy nRF52840 Express - Bluetooth LE [ 2 ] and found it to be consuming from 550mJ to 1.6J of energy (depending on the quantiza- tion).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 230,
    "augmented": false
  },
  {
    "text": "In our EoE , two unique KV cache challenges arise: i) Loading experts and their KV caches onto GPUs for a user can cause high latency and memory consumption due to the initial “prefill” stage, leading to a  cold start  problem. To address this, we plan to prefetch experts  and their KV caches (leveraging hot and cold experts) or GPU load balancing to select devices with sufficient memory; and ii) Each expert has specific memory requirements for model weights and past KV caches, and must reserve space for future KV caches to prevent out-of-memory errors, which depends on the expert’s response length—from single words to thousands of tokens. We plan to address this in two ways.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2001.08023 , 2020. Announcing trillium, the sixth generation of google cloud tpu, 2024. [50] Google.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Neurons with lower Shapley values are more likely to be dropped: \np i  = δ ϕ i  +  ϵ where  δ  is a scaling factor to adjust the overall dropout rate, and  ϵ  is a small constant to avoid division by zero. . Define a binary dropout mask  m  = [ m 1 , m 2 , .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "00472875231219634, 2024. Viewer in-consumption engagement in pro- environmental tourism videos: A video analytics approach. Journal of Travel Research , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Traditional neural codecs, while innovative, typically encode and decode video streams in a monolithic fashion, which often results in suboptimal utilization of computational resources and inflexibility (Ma et al., 2019). This inherent inefficiency stems from their design which does not allow incremental improvements in video quality and often leads to either over-utilization or under-utilization of bandwidth. To address these shortcomings, the advent of layered neural codecs marks a significant advancement (Dasari et al., 2022a).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Restrictions apply. [62] N. Muralimanohar, R. Balasubramonian, and N. P. Jouppi, “Cacti 6.0: \nA tool to model large caches,”  HP laboratories , vol. 27, p. 28, 2009.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "1, the neural network video inference software pipeline can be summarized as follows: Input:  The raw video data is ﬁrst stored in memory (usually in the H.264/MPEG format). 1, a typical mobile neural network video inference system has two major hardware components: (i) an SoC with a CPU/GPU/NPU for processing the intensive computations, and an intermediate buffer in DRAM for storing the video frames as well as the intermediate data between layers of DNNs, and (ii) a video decoder communicating with the SoC ,typically via the memory bus. Running on top of the hardware, as shown in the “Application” layer in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "The system can turn off individual compute-tiles to accommodate runtime power variability (see § IV-B ) and enable seamless operation during power reductions. Overall, Us.´as demonstrates the viability of sustainable con- tinuous learning at edge servers, encompassing advancements in energy harvesting, algorithmic techniques, and hardware adaptation. ´as  optimizes the entire solution space, maximizing hardware reuse for exemplar selection and micro- proﬁling while addressing the training task.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers. Inter-layer parallelism  means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion. This pipeline parallelism provides us with another dimension to aggressively exploit the harvested energy.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Utility Function Definition \nWe define a utility function  U i ( t )  for each sensor  s i  that en- capsulates the trade-off between accuracy gains and energy \nexpenditures, as well as future opportunities. The utility function is designed to reflect both immediate rewards and long-term sustainability. Immediate Rewards and Penalties: Let  γ >  0  be a scal- ing factor that translates accuracy gains into utility rewards.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "´as 11 17.2 3.54 8.33 DaDianNao (persistent) 6 6.4 10.8 128.0712 DaDianNao (Software Only) 4 5.8 12.46 135.964 DaDianNao (actual) 2 2.09 24.73 199.70 Edge Cloud 0 0 – Cloud 1 200 0 2233.8 Max Power = 32W; Min Power = 12W; Training Scheduled = 12 \nTABLE IV: Comparing  Us. ´as  hardware with other state of the art offerings for both performance and sustainability. Deployment Training Completed \nMean Power Consumed (W) \nMean Power \nWasted (W) \nCarbon Footprint (lbs/yr) Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "While response is being generated for some prior expert, this predictive loading can take place concurrently for the experts ahead in the path to minimize resource idleness and ensure seamless transition for subsequent pro- cessing. Specifically, leveraging the observed pat- terns of expert reuse (“hotness” patterns) at different locations in the EoE , our system can intelligently predict and load the experts likely needed in subsequent layers to the main memory. Task-2.4: KV Cache Management Key-Value (KV) caches in LLMs store past activations to  accelerate  inference by avoiding redundant com- putations [7, 35, 43, 73, 99, 146, 148, 163, 167, 168, 171, 172, 188, 189, 193].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "[9]  Neeraja J. Yadwadkar, Francisco Romero, Qian Li, and Christos Kozyrakis. A Case for Managed and Model-Less Inference Serv- ing. 2019.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Compute server indicates a software only classical storage solution without CSDs. 5.1 Evaluation of Encoding, Scaling and Accuracy \nIn evaluating the  Salient Store  storage system, particularly for continuous learning scenarios video analytics applications, we selected data-sets that are not only dense but also necessitate continuous learning due to their dynamic nature. Autonomous driving and urban mobility applications, generating over 400TB of data annually (Wright\"; \"premioinc\"; Bhardwaj et al., 2022), predominantly comprise video and 3D point cloud data, making them ideal for our evaluation.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Furthermore, it can measure the peak-to-median ratio in sampling windows, which can be used to decide if  serverless functions  are re- quired to balance the load. However, during flash-crowds, where load-prediction fails to accurately estimate the load, \nserverless functions  can inherently be used to handle requests to meet the response latency, but by incurring higher costs. 3.2.3 Provisioning Time vs Execution Time  We know that new VMs take a few hundred seconds to start-up.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "It also shows the number of exemplar frames per 100 frame, i.e., of any 100 frame encountered, how many of those will contain a relatively new data. Over 10 iterations of retraining, \n901 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. Scenario-3, it indicates that the object(s) in the current frame are different from the last inference outputs (i.e., “missed” in Scenario-2, or “entering/exiting” in Scenario-3) and hence, requires full inference (refer to Line  5  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:1905.03854 , 2019. Zygarde: Time-sensitive on-device deep inference and adaptation on intermittently-powered systems. Bashima Islam and Shahriar Nirjon.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Palm: Scaling language modeling with pathways. , 8(1), February 2024. [27] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Brad- bury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, San- jay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexan- der Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 422,
    "augmented": true
  },
  {
    "text": "edu/~kriz/cifar.html . [51]  Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gim- pel, Piyush Sharma, and Radu Soricut. Albert: A lite bert for self-supervised learning of language representations.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "[26] H. Sharma, J. Park, N. Suda, L. Lai, B. Chau, V. Chandra, and H. Esmaeilzadeh, “Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Networks,” in  Proceedings of the International Symposium on Computer Architecture , 2018, p. 764–775. [27] S. Han, H. Mao, and W. J. Dally, “Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding,”  arXiv preprint arXiv:1510.00149 , 2015.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "The rate of exponential smoothing depends on the scheduler used - while for the conservative scheduler the predictor always underestimated the power (shallow smoothing), the eager scheduling uses the direct output of the predictor (steeper smoothing). In either case, the predictor predicts the power with  ≈ 95% (peak of 98 . 72 (with real solar power trace) and minimum of 89 .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "´as  plays a crucial role in efﬁciently handling varying energy income and workloads. D. Towards Other Applications and Domains \nThe morphable hardware design of  Us. ´as  hardware with other state of the art offerings for both performance and sustainability.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "As has been highlighted in Table 2, we plan to exploit the expert-router affinity to reduce the training com- plexity of the router at initial training time and even while fine-tuning as the ensemble of experts evolve. We intend to co-locate the expert and routers physically in the system during both training and inference time to leverage this affinity and reduce expensive data movement cost. This would ensure that these routers can be fine-tuned in isolation, causing minimum to none ripple effects on to other expert branches, lowering the computational complexity and cost.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "2. These devices are designed to collect energy from their surround- ings—light, mechanical vibrations, or heat, respectively. Power Conditioning : Once energy is harvested, it often needs to be converted and stabilized for use.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "The recon- struction feature at the host comes with little to no overhead for the host (given the host devices have considerably more compute than the sensor nodes). The addition of the recovery parameter (number of points per cluster) needs  4 more bits (in our experiments, we never observe any clusters having more than 16 data points) of data per cluster, bringing the total data communication volume to  42 Bytes , which is still a significant 5 . based coresets can achieve an accuracy of  ≈ 85%.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Combining Inter-frame and Intra-frame Compression \nSimply put, our intra-frame compression proposal can sig- niﬁcantly reduce the execution latency, while the inter-frame compression proposal can further improve the compression efﬁciency. We emphasize here that, these two proposals can work in an interleaved fashion (with a frame-level granularity) for a PC video stream. Speciﬁcally, in our design, the PC frames are encoded in an “IPP” fashion, where each I-frame is followed by two P-frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "Choosing  c  relative to typical gains, say  c  ≈ 0 . 1 · γ · ∆ A max , helps maintain a moderate deterrent against non-participation without forcing sensors to always participate. 7 \n385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 \nEnergy Preservation: If  γ  is too large, sensors might not value future energy at all.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 183,
    "augmented": false
  },
  {
    "text": "Figure 1b shows the capabilities of the current SOTA. The size of the circle representing the solutions de- picts the compute capabilities of the sensor nodes, the shade shows the available power, and their position on the axes approximates the amount of compute done on the node and the amount of reliability on external communication. Some of the units change according to the harvested energy source.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Perform the forward pass with the updated dropout mask to obtain the output  Y . If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Otherwise, maintain or reduce the dropout rate to improve accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "This is because, the Piezo  source is very weak and and the total completed number of inferences is quite small. Percentages of additional inferences with power prediction over all inferences and additional inferences with the  Transition keep \nstrategy \nThe portion of inferences added with power prediction are signiﬁcant for  Piezo  for most workloads. 11.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "For instance, InFaas [ 83 ] can choose variants among a same model to maintain accu- racy and latency requirements. In this paper, we focus on improving the accuracy and latency from the model selection perspective and consider instances types from a cost perspective. A majority of the model serving systems [ 6 , 83 , 86 ] in public cloud support individual model selection from available models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "In such a case, as the pixel values of the identiﬁed object have changed, Frame i + 1  cannot reuse the result (LED bulb) from Frame i  even though it should ideally be able to do so in an object detection application. Hence, rather than relying on low-level raw pixel values, most DNN applications leverage high-level features, where “new events” or “motions” make more sense to employ in determining whether we can reuse the results from previous \n1076 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Such non-IID data distributions, evident in tasks like standard trafﬁc monitoring with varied class observations (e.g., more cars than buses, all frames having  STOP  signs), may introduce sampling bias  [ 70 ], [ 74 ] in the network. This challenge can be addressed through proper  exemplar selection  algorithms employing representation learning techniques [ 31 ], [ 74 ], ca- pable of learning new classes in real-time. However, these compute-intensive algorithms can be optimized further through dedicated hardware acceleration.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "ACM SIGPLAN Notices  53, 6 (2018), 31–43. [66]  Texas Instrument Micro-controller with FRAM 2022. 16 MHz MCU with 64KB FRAM, 2KB SRAM, AES, 12-bit ADC, comparator, DMA, \n14 \nUART/SPI/I2C, timer.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Compute the activations  a  and apply the dropout mask: \nm i  =  σ ( z i ) \na dropout i =  a i  ·  m i \nCompute the loss  L ( Y ,   ˆ Y ) . Inference with Learning Sparse Masks Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. Calculate the gradients of the loss with respect to the weights and dropout mask parameters: ∂ L ∂W ij , ∂ L ∂z i For each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ← DynAgent.estimateEnergy ( L, i, l i ) If  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ← DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask parameters  z  based on the gradients: \nz i  ← z i  − η  ∂ L \n∂z i \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ← W  − η  ∂ L \n∂ W   ⊙ m \n20 \nwhere  η  is the learning rate and  ⊙ denotes element-wise multiplication.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 363,
    "augmented": true
  },
  {
    "text": "8. Throughput of CNNs across the power sources normalized to ResiSchedule \nPiezo WiFi-home WiFi-office Thermal TV-RF \nFig. 9.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "A. Methodology \n1) Evaluation Platform:  To evaluate and compare the proposed intra- and inter-compression designs with the state-of-the-art works, we use the NVIDIA Jetson AGX Xavier board [ 58 ], which is an edge development board, and is well-known to simulate the realistic edge development environment. Speciﬁcally, it is equipped with a 512-core Volta GPU, a 8-core ARMv8 64-bit CPU, and 32GB 256- Bit LPDDR4x Memory.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Compared to the cloud for online processing, the preference for local compute over ofﬂoad can stem from security, con- nectivity and latency concerns as well as power and energy constraints. This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efﬁciency when active is high. In our work, local computation across the CNN applications is  ∼ 50x more efﬁcient than transmission over Bluetooth with 3Mbps and 2.5mW.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "2020. 181–192. [46]  Ali Tariq, Austin Pahl, Sharat Nimmagadda, Eric Rozner, and Siddharth Lanka.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "These super-tiles Each tile, individually switchable ON or OFF based on power availability, houses 64 16-bit ﬂoating point MAC units conﬁgured in an 8  ×  8 systolic array for convolution operations. A modular computational approach is adopted where each tile is accountable for one CNN kernel, necessitating  ⌈ [ C  × H  × W ] / 64 ⌉ iterations for a kernel of size [ C  × H  × W ] . Data streaming and partial compute storage are facilitated by four double buffered SRAM structures, with the \nweights residing in a double buffered multi-banked SRAM.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Each such de- viation strictly increases  Φ( a ( t )) . Suppose, for contradiction, that there exists an infinite se- quence of unilateral profitable deviations. Because  Φ  is bounded above by  Φ max , only a finite number of increments can occur before no further improvements are possible.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "WoSC’20, December 7ś11, 2020, Delft, Netherlands J.R. Gunasekaran, et al. Therefore, it is  non-trivial for an application to choose the right model that can collectively optimize for all requirements together . To ensure a required accuracy with given latency, applications have to choose from a confounding array of different types of models (shown in Figure  1 ).",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "V for more details). ii Missing Object(s) : Another scenario is one in which the object(s), which have not been identiﬁed in the previous frames, are detected in the current frame, as shown in Fig. 3b.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "The students will work on separate thrusts in the beginning (one student will be the primary contact for each thrust), but they will works together in the last year for integrating the different compo- nents of the research for a comprehensive evaluation and refinements of the proposed models, algorithms, compiler and system support. We will seek REU supplements to support the undergraduate students for working on this project. In addition, we will also include undergraduates from the Schreyer Honors College at Penn State, and specifically draw undergraduate students from underrepresented groups, who are interested in pursuing graduate studies.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "Restrictions apply. compression ratio) takes  121 ms  ( 43 ms  for geometry and 78 ms  for attribute compression), which represents about 35 ×  speedup w.r.t. CWIPC.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Also, as opposed to Euphrates, one may prefer to use existing hardware, due to considerable development effort and associated cost with customization. Additionally, sometimes sudden changes in subsequent frames (e.g., with a new object in the frame), require adaptive decisions, which cannot be achieved by Euphrates [9] and DeepCache [8]. Unlike the work presented in this paper, none of the four prior schemes mentioned in Table I performs well in all features listed in the table.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Sören Becker, Johanna Vielhaben, Marcel Ackermann, Klaus-Robert Müller, Sebastian Lapuschkin, and Wojciech Samek. Springer, 2014. 91–98.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "This occurs as a result of reusing the memoized results which have been computed and stored previously, ranging from 21 . 63%  ( Rollercoaster  video) to  50 . 28%  ( Paris video).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Our results from exhaustive experimental analysis demon- strate that  Cocktail  can minimize deployment cost by 1.4 × while meeting the accuracy for up-to 96% of the requests and providing 2 ×  reduction in latency, when compared to state-of-the-art model serving systems. 4. We implement a prototype of  Cocktail  using both CPU and GPU instances on AWS EC2 [ 5 ] platform and ex- tensively evaluate it using different request-arrival traces.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "PSNR (%) \nEnergy Savings (%) \n(b) Trade-offs. Figure 10: Sensitivity studies. hologram (in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "CWIPC. There is not much perfor- mance difference between V2 and V1, because we have to run the block matching algorithm on all the blocks before making the “direct-reuse” decision, which dominates the entire pipeline in both the design variants. Energy Consumption:  Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "[70] Rishabh Jain, Vivek M Bhasi, Adwait Jog, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita R Das. Pushing the performance envelope of dnn-based recommendation systems inference on gpus. In  To be presented in proceedings of the 57th Annual IEEE/ACM International Symposium on Microarchitecture , pages 62–76, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Thus,  Cocktail  is inherently fault-tolerant owing to the parallel nature in computing multiple inferences for a single request. We observe similar accuracy loss or lower for different probability failures of 5%, 10% and 25%, respectively (results/charts omitted in the interest of space). Discussion:  For applications that are latency tolerant, we can potentially redirect requests from failed instances to existing instances, which would lead to increased tail latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "We also design an autoscaler  6  , which utilizes a prediction pol- icy  6a  to forecast the request load and scale instances for every model pool, thereby minimizing over-provisioning of resources. First, it maintains dedicated instance pools to serve indi- vidual models which simpliﬁes the management and load balancing overheads for every model. Next, the resource con- troller  4  handles instance procurement, by exploiting both CPU and GPU instances  4a  in a cost-aware  4b  fashion, while the load balancer  5  ensures all procured instances are bin- packed by assigning queries to appropriate instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Better refers to the improvement over iNAS+PT baseline. Datasets Full Power Arduino on RF AP PT iNAS+PT NExUME Better FMNIST 98.70 74.44 79.63 83.61 90.44 8.17% CIFAR10 89.81 58.11 63.91 65.01 79.60 22.44% MHEALTH 89.62 63.52 67.40 74.30 83.86 12.87% PAMAP 87.30 61.39 67.24 69.45 77.00 10.87% AudioMNIST 88.20 66.11 74.28 76.60 78.87 2.97% Table 6: Accuracy of NExUME on Arduino nano board using WiFi based RF harvester. Better refers to the improvement over iNAS+PT baseline.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 205,
    "augmented": true
  },
  {
    "text": "Sailong Fan, Weiqiang Liu, James Howe, Ayesha Khalid, and Maire O’Neill. Lightweight hardware implementation of r-lwe lattice-based cryptography. In  2018 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Express  (2021), 1412–1427. Adaptive Weighted Gerchberg-Saxton Algorithm for Generation of Phase- only Hologram with Artifacts Suppression. Opt.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "2 is invoked to decide how to process this frame (FI, PI, or SI). As one can see from Line  2  of this algorithm, if the frame has been labeled as “Skip” by Algo. 1, it can be safely bypassed.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "A comparative study on machine learning algorithms for smart manufacturing: tool wear prediction using random forests. IEEE, 2021. [7] Dazhong Wu, Connor Jennings, Janis Terpenny, Robert X Gao, and Soundar Kumara.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "The SDMM also offers a simpler controller design for multiplication and in-place product term reduction after vector-vector multiplications. The MR, in conjunction with the multiplier, delivers the output within 2 clock cycles. 3b, consists of a single shift block, a subtractor, and a adder, consuming much less hardware then the state-of-the-art (Fan et al., 2018).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Here,  δ >  0  penalizes incorrect participation, discourag- ing sensors from submitting low-quality data, while  η >  0 penalizes non-participation to prevent perpetual abstention. Importantly, we set  η > δ , ensuring that consistently opting out is more detrimental than occasionally providing inaccu- rate data. Energy Costs and Future Utility: Participation incurs energy costs, reducing the sensor’s capacity for future tasks.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "2 \nData Task Algorithm % CPU Utilization % DRAM Utilization 16 Core Xeon Peak Average All Encryptions RSA512 2.18 14.56 5.85 All Decryptions RSA512 3.45 17.2 6.12 \n3D PC Compression OctTree 26.78 78.2 32.54 Inflation OctTree 29.24 81.56 36.18 \nVideo \nCompression ZStd 24.7 62.54 24.5 Inflation ZStd 22.6 79.18 29.43 Compression H264 12.85 52.46 21.4 Inflation H264 14.2 69.46 26.18 All (un)RAID Unraid 11.25 29.4 19.24 Table 1: Resource utilization while running different algorithms under classical data archival pipeline for multiple data modalities in an AWS h1.4xlarge storage-optimized instance. (e.g., systems with CPUs having a thermal design power of 145W and 64GB of DRAM as noted in Table 1) and requiring larger form factors, which exceed the capabilities of intermittent systems and challenge sustainability goals. Therefore, there is an urgent need to  minimize compute and power requirements  in archival processes.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 268,
    "augmented": false
  },
  {
    "text": "As shown in Fig. More speciﬁcally, the  360 ° video processing pipeline can be summarized as follows: Video Decoder:  The HMD receives encoded  360 ° video bitstream from the network (YouTube [61], Facebook-360 [7], etc). 1, a typical VR HMD [39] has two major components: (i) an SoC with a video decoder, a GPU for processing projection computation, and a display controller, and (ii) a video buffer in DRAM for storing the decoded  360 ° frames and projected frames for both the left and right eyes.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "[10] Google, “More Ways to Watch and Play with AR and VR.” ”https:// blog.google/products/google-vr/more-ways-watch-and-play-ar-and-vr”. [11] Google, “Build Virtual Worlds.” ”https://developers.google.com/vr”, 2019. google.com/project/360-videos”.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "To ensemble the \nAR pipeline with generic state-of-the-art components shown in Fig. To collect performance metrics such as the streaming multiprocessor (SM) utilization, memory traffic, and CUDA kernel execution latency, we utilized the open-source Nvidia NVPROF tool [37] on the GPU platform. 1c, we implemented an open-source full-system extended real- ity testbed, ILLIXR [ 19 ], on the edge GPU platform [ 36 ], and built our  HoloAR  design on top of it.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "[46]  Mayank Raj, “Point Clouds and its signiﬁcance in AR,”  ”https: //bit.ly/3uknBjT” , 2020. [47]  D. Meagher, “Geometric modeling using octree encoding,” Computer Graphics and Image Processing , pp. 129–147, 1982.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "In fact, there is a mathematical concept called  Morton Code  [ 30 ] (essentially, a space ﬁlling curve that maps a multidimensional data to one dimension while preserving the locality of the data points), which describes the geometrical location relationships between points, and thus can serve this purpose perfectly. As a result, these points can processed in  parallel . There have been prior works like N-body application [ 5 ] which utilize the Morton code for parallel octree construction 4 ; however, we believe ours is the ﬁrst work that tries to apply such technique in the PCC pipeline.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "This hybrid \n5 \n275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 \napproach mitigates the high communication overhead and energy consumption, making it more suitable for resource- constrained EH-WSNs. While traditional methods require persistent communication between sensors and the aggre- gator, our framework leverages the established equilibrium strategies to determine optimal times for model updates. By aligning update events with periods when sensors are most likely to participate meaningfully, we ensure that the global model is refined efficiently without imposing excessive en- ergy demands on the sensors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 214,
    "augmented": false
  },
  {
    "text": "We hypothesize that the dropped sample should con- tain, although not important, sensor specific artifacts. Importance Sampling Coreset Recovery:  Unlike cluster- ing, when we construct a coreset with importance sampling, we typically have no information regarding the lost data points. However, since clustering based coreset construction is more expensive than the importance sampling based coreset construction, it is not always possible to build a recoverable coreset at the edge, unless we figure out a to recover the lost points while we perform importance sampling.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911 , 2024. [45] Giorgio Franceschelli and Mirco Musolesi. Ac- cessed: 2024-10-20.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Note that, we set the bidding price conser- vatively to 40% of OD. Although,  Cocktail  spawns about 50% more VMs than  InFaas , the high  P f  of small models and spot-instance price reductions combined with autoscaling policies lead to the overall 30-40% cost savings. 6.3 Sensitivity Analysis \nIn this section, we analyze the sensitivity of  Cocktail  with respect to various design choices which include (i) sampling interval of the accuracy measurements, (ii) spot-instance fail- ure rate and (iii) type of datasets and applications.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "CoRR , abs/1804.03230, 2018. [85]  Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V Le. Xlnet: Generalized autoregressive pre- training for language understanding.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Data Archival:  The answer is straightforward, especially for mission-critical public records like urban mobility and surveillance data: these need to be archived in a local storage to avoid under- mining the benefits of edge computation, i.e. minimizing communication and preserving privacy. However, managing such data requires substantial storage infrastructure.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed. Note that, if the row- wise tiling factor is less than the ReRAM row number, this tiled execution strategy will introduce partial sums. When the traversal completes, an  Adder Tree  will be used to merge the partial sums for ReRAM columns and obtain the ﬁnal MAC result.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "\"https://github.com/google- research-datasets/Objectron/blob/master/index/cup_annotations\". [42]  Objectron. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "Let \n∥∇ Ω SNR ( θ ) ∥≤ G 1 , ∥∇ Ω complexity ( θ ) ∥≤ G 2 ∀ θ. The regularizers  Ω SNR  and  Ω complexity  are convex in  θ , and their gradients are bounded. 4.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "[34]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Björn B. Brandenburg. Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efﬁciency. In  USENIX Middleware Conference , 2017.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Llm-mq: Mixed-precision quantization for efficient llm deployment. [95] Shiyao Li, Xuefei Ning, Ke Hong, Tengxuan Liu, Luning Wang, Xiuhong Li, Kai Zhong, Guohao Dai, Huazhong Yang, and Yu Wang. Accessed: 2023-10-20.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 1037–1050. [11]  Yu Feng, Paul Whatmough, and Yuhao Zhu.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Hence, the distance between the user and the objects ( Cam2ObjDist  shown in black color in Fig. 3a), as well as the size of how the object seems/appears to the user ( ObjSize shown in red color in Fig. 3a) affect the amount of computations actually required to provide just enough yet necessary virtual holo- grams.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "(a) Scenario1: moving. (b) Scenario2: capturing a previously missed object. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Our proposal is fundamentally different from prior optimizations targeting various architectures or execution environments, such as customized hardware accelerators [ 35 ], cloud assistance [ 16 ,  27 ,  67 ], or neural network training/inferencing [ 33 ,  54 ]. Note that since the other option – first  Intra-Holo , then  Inter-Holo  – is theoreti- cally identical to the proposed  Inter-Intra-Holo , we skip its detailed discussion due to space limitation. 4.5 Design and Implementation \nOptimization Choices:  Our main goal in this paper is to reduce the amount of hologram computation by appropriate approxima- tion, in order to speed up hologram processing, to satisfy the real- time requirement as well as to reduce the energy consumption and prolong the battery life of the AR device, while maintaining the QoS.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 192,
    "augmented": true
  },
  {
    "text": ". We plan to address these questions using 6 different tasks. To enhance the performance of EoE , we propose system optimizations that exploit the spatio-temporal locality/affinity of its components – data, experts, routers, composition functions, and hardware.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "5.2 Evaluation Methodology \nWe evaluate our prototype implementation on AWS EC2 [ 8 ] platforms. Speciﬁcally, we use  C5.xlarge, 2xlarge, 4xlarge, 8xlarge  for CPU instances and  p2.xlarge  for GPU instances. Load Generator:  We use different traces which are given as input to the load generator.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "[19]  M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, “Redesigning software and systems for non-volatile processors on self-powered devices,” in  2016 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC) , pp. 1–6, Sep. 2016. [20]  L. Ni, Z. Liu, H. Yu, and R. V. Joshi, “An energy-efﬁcient digital ReRAM-crossbar-based cnn with bitwise parallelism,”  IEEE Journal on Exploratory Solid-State Computational Devices and Circuits , vol.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "2020. ViVo: Visibility-aware Mobile Volumetric Video Streaming. [16]  Bo Han, Yu Liu, and Feng Qian.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "These jobs form the functional program execution DAG. Considering the energy available, the predictor makes an informed decision on how to proceed. The compiler deconstructs the program into jobs to perform seamless program execution.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "https://mikhail.io/serverless/ coldstarts/azure/. Azure Functions Cold Starts. [15]  2021.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "Consequently, the mere presence of numerous EH sensors does not guaran- tee robust and reliable performance for complex tasks such as image recognition, acoustic surveillance, or precision agriculture monitoring. Achieving accurate inference in these complex scenarios de- pends on effective coordination. Multiple sensors observing the same phenomenon from different angles can collectively provide more comprehensive and reliable insights than any single sensor could.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "These prior approaches either incorpo- rate additional memory for maintaining a lookup table for compu- tation reduction, or build an application-specific integrated circuit (ASIC) chip specifically for holographic processing, which is more power-efficient than generic processors. While such approaches im- prove the hologram execution to some extent, they do not consider the unique features of the AR applications. Recall that, in the AR holographic application discussed above in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Task fusion to minimize checkpointing overhead, which is critical in intermittent environments. 3. Dynamic adjustment of computational tasks based on both energy and task criticality.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "On the other hand, for knowledge integrity and resource efficiency, we will also explore innovative directions for expert shrinking by unlearning outdated knowledge that is no longer required. To maximize the unlearning effectiveness, given a seed forget dataset, we will perform deductive reasoning based on our previous work [62] to generate a larger forget dataset to account for the ripple effect of knowledge update [28]. We will then perform “unlearning” by parameter-efficient fine-tuning to update the most relevant parameters.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2303.18223 , 2023. [193] Youpeng Zhao, Di Wu, and Jun Wang. Alisa: Accelerating large language model inference via sparsity-aware kv caching.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Sensors focus on inference using their local copies of  f θ . However, the sub- sequent training framework, discussed in Section  5 , allows for occasional fine-tuning of  θ  based on equilibrium-driven participation, thereby refining the model to better suit the operational dynamics of the network. In each inference event, sensors decide whether to partic- ipate.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Octopai: Automated data lineage, data catalog and discovery. com/ . https://www.octopai.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "In  SysML Conference , pp. Graham Gobieski, Nathan Beckmann, and Brandon Lucia. Intermittent deep neural network inference.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "We acknowledge that all product names used are for identiﬁcation purposes only and may be trademarks of their respective companies. R EFERENCES \n[1] S. M. Abhay S, “Autonomous vehicle market by level of au- \ntomation,”  https://www.alliedmarketresearch.com/autonomous-vehicle- market , Feb 2022, (Accessed on 08/04/2023). [2] “Achieving Compliant Data Residency and Security with Azure,” \nhttps://azure.microsoft.com/mediahandler/ﬁles/resourceﬁles/achieving- compliant-data-residency-and-security-with-azure/Achieving Compliant Data Residency and Security with Azure.pdf .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 168,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2303.14177 , 2023. [61] Linley Gwennap. Groq rocks neural networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Component Spec Power Area(mm 2 ) SRAM Buffers 1kB*256+8kB*256+64kB+16*256kB 10.372W 117.164 MAC Unit (8*8)*256 8.46W 32.72 Adder Tree and Comparator 16*16bit + 256 2.4W 21.556 Control – 0.96W 12.2 Host ∼ Cortex A78 series 11W – Design at 592MHz with Synopsys AED 32nm library Total 256 tiles 33.192W 183.64 \nTABLE I: Area and power estimation of our design. (e.g. Ekya [ 12 ] using ResNeXt101) to annotate the data or used a heuristic on top of the teacher model (e.g.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 186,
    "augmented": false
  },
  {
    "text": "6) using clustering based techniques. Going above 12 \nclusters did not significantly improve accuracy. This further motivates us to look for opportunities in the data distribution to improve the compression ratio.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "Initialize the loop iteration parameters  l . Compute the activations a  and apply the dropout mask: a dropout i =  a i  ·  m i \nCompute the loss  L ( Y ,   ˆ Y )  where  Y  is the output of the network and   ˆ Y  is the target output. Calculate the gradients of the loss with respect to the weights: \n∂ L ∂W ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ← DynAgent.estimateEnergy ( L, i, l i ) \n16 \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ← DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the L2 norm of the weights: \np i  = α ∥ W i ∥ 2  +  ϵ \nm i  = \u001a 0 if Bernoulli (1  − p i ) = 0 1 otherwise Perform the backward pass to update the network weights, considering the dropout mask: \nW  ← W  − η  ∂ L \n∂ W   ⊙ m \nwhere  η  is the learning rate and  ⊙ denotes element-wise multiplication.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 360,
    "augmented": false
  },
  {
    "text": "References \n[1]  Martín Abadi. Tensorﬂow: learning functions at scale. In  Acm Sigplan Notices .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "We quantitatively compare the effective training, i.e. ´as  closely tracks oracle, where as DaDianNao [ 16 ] falls short. execute (using a capacitor/ battery).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "As opposed to the prior work, in this paper, we target the video data that are processed by edge devices, and study the similarity between frames. Based on that, we propose two runtime approaches to boost the performance of the inference process, while achieving high accuracy. Speciﬁcally, considering the similarities between successive video frames, we propose a frame-level compute reuse algorithm based on the motion vectors of each frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Prior works  [ 5 ,  10 ] try to hide the pro- visioning latency of VMs by using  server- less functions  as a handover mechanism when starting new VMs. We name this scheme as  mixed  pro- curement. However, these schemes do not address the holis- tic problem by taking into account model selection, resource selection, and resource scaling to cope up with user-specified constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Motivated by this, we next explore the entire design space for the AR holographic applications running on edge GPUs, and try to ex- ploit potential opportunities for reducing computations to improve both performance and energy efficiency in hologram processing. 498 \nMICRO ’21, October 18–22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 4 PROPOSED STRATEGIES \nAs discussed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Even for the same types of activity, some attributes will vary from user to user. 70 75 80 85 90 \n70 75 80 85 90 \nIter 1 Iter 10 Iter 100 Iter 1000 \nAccuracy % \nUser 1 User 2 User 3 Base Model Fig. It is obvious that it is not feasible to train a DNN for all types and variances of human actions.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "For building scalable and sustainable infrastructure of battery-free EH-WSNs, the former is more feasible and will be our focus for this work. The fickle nature of harvested energy has posed a major chal- lenge in performing any useful computation, as any useful forward progress gets lost when the traditional computing systems lose power. To tackle this, a significant amount of work has been done on check-pointing, and compiler level tweaks, which help maximize the forward progress on such devices [ 39 ,  43 ,  44 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "a bottleneck in data movement and sharing, creating hurdles in high quality-low latency streaming/analysis. Therefore, there have been several works focusing on compressing the PC, as discussed next. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "based on application require- ments, and evaluate both PSNR and user-experience metrics such as satisfaction and dizziness [ 66 ]. Second, How do we maintain high power efficiency of PUs during runtime? To answer this, we plan to characterize the number of depth planes needed in various AR applications, and guide the optimal design choices (i.e., number of PUs, frequency, input and output buffer size, etc.)",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "How much data do autonomous vehicles generate? Springer, 2021. \"premioinc\".",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "In addition to the individual tasks in each thrust, Figure 2 also shows the inter-task dependencies as well as interactions between them, highlighting our cross-layer co-design aspect. 2.1 Thrust-1: Algorithmic Support for Ensemble of Experts The main focus of this thrust is to investigate different models and algorithms for Ensemble-of-Experts (EoE) systems, paying special attention to search space optimization for “morphable” LLM expert ecosys- tems, “dynamic” expert networks, and obtaining new experts from existing ones. Our research tasks in Thrust 1 are illustrated in Figure 3.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "With this, the RCA can be active in a very large power range and ﬁnd more opportunities to make execution progress. Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles  PC6, PC7  and  PC8 . With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "1, a typical mobile neural network video inference system has two major hardware components: (i) an SoC with a CPU/GPU/NPU for processing the intensive computations, and an intermediate buffer in DRAM for storing the video frames as well as the intermediate data between layers of DNNs, and (ii) a video decoder communicating with the SoC ,typically via the memory bus. As shown in the “HW” (Hardware) layer in Fig. Video Inference on Mobile Platforms \nThe key difference between a video-based DNN application and other popular DNN inferencing applications like natural language processing (NLP) or speech-to-text is that, the former interacts with video frames which are either captured from the camera or downloaded/streamed from internet and hence, has a strict latency requirement for performing inferencing within the frame deadline.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 199,
    "augmented": true
  },
  {
    "text": "292 \nAuthorized licensed use limited to: Penn State University. 7 We decide the parameters for intra- and inter-compression by proﬁling several frames in the 8iVFB [ 18 ] dataset, to obtain a relatively balanced design point between compressed size and quality. Speciﬁcally, we choose to segment each PC frame into 30000 blocks 7 , and use a 2-layer encoder (more speciﬁcally, we ﬁrst encode the attributes via the proposed intra-frame encoder \n6 Based on our proﬁling, the provided attribute compression APIs (e.g., JPEG- Turbo-based) would degrade the quality of PC signiﬁcantly; thus, we do not use such APIs/Libs in our evaluations.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "Unlike existing techniques that use sequential algorithms, our ﬁrst design, intra-frame compression, exploits parallelism for boosting the performance of both geometry and attribute compression. The proposed parallelism brings around 43.7 ×  performance improvement and 96.6 % energy savings at a cost of 1.01 ×  larger compressed data size. To further improve the compression efﬁciency, our second scheme, inter-frame compression, considers the temporal similarity among the video frames and reuses the attribute data from the previous frame for the current frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Power Conditioning : Once energy is harvested, it often needs to be converted and stabilized for use. This is done using a rectifier, which transforms alternating current (AC) into a more usable direct current (DC). 3.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "In  ACM Symposium on Cloud Computing (SoCC ’21), November 1–4, 2021, Seattle, WA, USA. ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3472883.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "Since the data size is limited, with increasing numbers of machines, the training data-per-machine decreases, and hence gives us the opportunity to also study the impact of data availability. We implemented a random forest based regression model to predict the surface roughness value and tested our partitioning policies. The edge node is implemented on Raspberry Pi development boards and the cloud is emulated via a desktop class Intel corei9 10900k CPU (with 64GB DDR4 RAM).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Both these schemes suffer from over- provisioning VMs because (i) we cannot always accurately predict the future load, and (ii) resource utilization is not always the right indicator for increased load. We name the former autoscaling scheme as  util_aware  and the later as  exascale . These autoscaling mechanisms can be of two types: (i) spawn VMs if the resource utilization of existing VMs reaches a certain threshold (80% in most cases) [ 9 ], and (ii) spawn additional VMs than predicted request demand [ 6 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "Asaresult,thesepartialsumsneedtobe mergedoncethe (tile)traversalofanentireReRAMiscomplete.Thesum mergingoperationisperformedbyanAdderTreeasillustrated inFigure3. Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint of P merg   <P budget shouldbealways met.Therefore,the power P merge   andlatency Lat merge   ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofﬂine. Component Energyequation DAC E DAC =e DAC ×m×aG Computation E M AC =e MAC   ×m×n×aG \nADC BL E BL =e BL ×n×aG SA-Ref E SA−Ref =e SA−Ref ×n×aG S+A E S+A =e S+A ×n×aG \n3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 276,
    "augmented": true
  },
  {
    "text": "19 \nD.4 Learning Sparse Masks Dropout with QuantaTask Optimization \nLearning Sparse Masks Dropout adapts dropout masks as learnable parameters within the network, inspired by Wen et al. (2016), combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Mathematical Formulation:  Let  W  be the weight matrix of a layer.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "In exemplar selection, the entire dataset is analyzed to detect classes with unique features, i.e., the images that are much different from the training data distribution or new classes that were not included in the training data. This is typically achieved through representation learning (Rebuffi et al., 2017) where the data is first converted into a feature vectors using the convolution layers of a large DNN model (or multiples of them), and then performing an unsupervised learning based classification, e.g., k-means++ (Arthur & Vassilvitskii, 2007; Bahmani et al., 2012), to cluster the data. It is noteworthy that, the process of neural compression as well as inference/representation learning use the feature extraction method.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 179,
    "augmented": false
  },
  {
    "text": ": As discussed in Sec. IV-A 2 , the  octree Construction  step returns several arrays containing the relationship among octree nodes; e.g., the  code array contains the Morton codes for all the nodes, while the  parent array  contains the index of the current node’s parent in the code array (e.g., in Fig. 5 , - 1  in the parent array means that the root node has no parent, whereas  parent [ 7 ] =  4  means that for the  7 th  node (whose code is  code [ 7 ] =  511 ), the index for its parent node in the code array is 4 (whose code is  code [ 4 ] =  63 )).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 168,
    "augmented": false
  },
  {
    "text": "The  PTU+EA+AE  implementation combines the  PTU  and our  EA+AE  optimizations together. Experimental Platforms and Datasets \nEvaluation Platforms:  The  Baseline  GPU platform described in Fig. B.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "Note that the tail latency of  Clipper  is still higher than  Cocktail  because  Clipper ensembles more models than  Cocktail , thereby resulting in straggler tasks in the VMs. The difference in latency between Cocktail  and  InFaas  is lower for  Relaxed  workload when compared to  Strict  workload (20% lower in tail). Since the Relaxed  workload has much lower accuracy constraints, smaller models are able to singularly achieve the accuracy requirements at lower latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "The results will be disseminated through timely scientific publications in respected conferences and journals throughout the project period. Our simulation testbed will be tested, refined if necessary, and will be updated in the public domain (Github). By the end of the project, the entire framework along with sample expert models, algorithms, system support and documentation will be in the public domain.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "4a and Algo. 1 as two ma- jor steps (more details on the depthmap hologram algorithm can be found elsewhere [ 4 ,  18 ,  55 ,  63 ]). As shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "[63] Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, and Alexandra Peste. Journal of Ma- chine Learning Research , 22(241):1–124, 2021. Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "2019. 1–13. [17]  Zehao He, Xiaomeng Sui, Guofan Jin, and Liangcai Cao.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "In  CIDR , 2021. Romil Bhardwaj, Zhengxu Xia, Ganesh Ananthanarayanan, Junchen Jiang, Yuanchao Shu, Nikolaos Karianakis, Kevin Hsieh, Paramvir Bahl, and Ion Stoica. Ekya: Continuous learning of video analytics models on edge compute servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "9. First, by comparing YOLOv3 (see Fig. 8b) and YOLOv4-tiny (see Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Fig. 5a shows the accuracy results on the MHEALTH dataset, and Fig. 5b shows the results for the PAMAP2 dataset.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Intuitively, if the inputs of the transformation computation do not change, the output of the transformation will also be same. In fact, we observe the \n3 We use “projection transformation” and “ 360 ° video projection” inter- changeably. 243 \nFig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "[71]  Richard Durant, “Pointerra: Attractive Opportunity If Growth Can Be Sustained,”  ”https://bit.ly/3nvfRrx” , 2021. [72]  R. B. Rusu and S. Cousins, “3D is here: Point Cloud Library (PCL),” in  IEEE International Conference on Robotics and Automation (ICRA) , 2011. [70]  Ricci Rox, “Power-hungry Snapdragon 8 Gen 1 gets trounced by the Apple A15 Bionic in real-world gaming test,”  ”https: //bit.ly/3P086pp” , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "However, while inferring at the host, if we are able to recover the data or reconstruct it with minimum error, the accuracy can easily be increased. Clustering Coreset Recovery:  Clustering preserves the geometry of the original data by representing them as a set of N-spherical clusters represented with a center and a ra- dius. In the process of coreset construction we only preserve the coordinates of the centers and the radii of the clusters, and hence miss the coordinates of the points inside the clus- ters.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "The interplay of multiple sensors making similar decisions un- der uncertainty and energy constraints naturally suggests a game-theoretic framework for modeling their interactions. 4. Game-Theoretic Modeling \n4.1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "767–781, 2018. [23]  X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, “A high- efﬁciency dual-channel photovoltaic power system for nonvolatile sensor nodes,” in  2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA) , pp. [22]  A. Colin, E. Ruppel, and B. Lucia, “A reconﬁgurable energy storage architecture for energy-harvesting devices,” in  Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018 , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "Consequently, this exemplar set becomes the training data for the continuous learning, which consequently minimizes the drift. Once the student model is trained with the exemplar set, the data is discarded and the feature space for the teacher models is updated. By doing this,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Tbp-former: Learning temporal bird’s-eye-view pyramid for joint perception and prediction in vision-centric autonomous driving, 2023. URL  https://arxiv.org/abs/2303.09998 . Manuel J Fonseca and Joaquim A Jorge.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "NetAdapt: Platform- Aware Neural Network Adaptation for Mobile Applications. 2018. [68]  Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, and Hartwig Adam.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Cirrus: A Serverless Framework for End-to-End ML Workflows. In  Proceedings of the ACM Symposium on Cloud Computing (Santa Cruz, CA, USA)  (SoCC ’19) . 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "These applications typically have diverse requirements in terms of accuracy and response latency, that can be satisfied by a myriad of ML models. Abstract \nWe are witnessing an increasing trend towards using Ma- chine Learning (ML) based prediction systems, spanning across different application domains, including product rec- ommendation systems, personal assistant devices, facial recognition, etc. However, the deployment cost of prediction serving primarily depends on the type of resources being procured, which by them- selves are heterogeneous in terms of provisioning latencies and billing complexity.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "0 200 400 600 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers \nNGINX Check_Reservation \nGet_Profiles Search \nMake_Reservation \n(c) Hotel Reservation. The reduction in the number of containers spawned by Kraken  in comparison to other policies is roughly propor- tional to the total number of application workflows and the slack available for each function within a workflow (see Ta- ble 2 and Figure 7). Figure 8: Real System: Stage-wise Breakdown of Containers spawned by each policy.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "2023. [38] Nan Du, Yanping Huang, Andrew M. Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten Bosma, Zong- wei Zhou, Tao Wang, Yu Emma Wang, Kellie Webster, Marie Pellat, Kevin Robinson, Kathy Meier- Hellstern, Toju Duke, Lucas Dixon, Kun Zhang, Quoc V. Le, Yonghui Wu, Zhifeng Chen, and Claire Cui. Glam: Efficient scaling of language models with mixture-of-experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 167,
    "augmented": false
  },
  {
    "text": "Learning Approach: Our approach diverges from classi- cal Learning paradigms. Over time, this induces a stationary, albeit non-trivial, effec- tive data distribution  D . At equilibrium, sensors strike a balance between accurate data contribution and energy conservation, result- ing in a stable pattern of participation and SNR choices.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "[24] D. A. Palmer and M. Florea, “Neural Processing Unit,” 2014, uS Patent 8,655,815. [25] Z. 331–344.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Motivated by this, we designed a GANs to regenerate the lost data points while performing importance sampling. The latent space takes the activity, and the first and second order moments of the data sample to recreate the signal, and the Discriminator tried to distinguish between the generated sig- nal and the actual signal. The generator is tuned repeatedly until the discriminator could not distinguish the original and the generated signal.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. 1084 \nAuthorized licensed use limited to: Penn State University. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "It can be concluded from these results that, memoizing the last  two  frames is sufﬁcient for most of the cases. Memoizing more frames may not bring much additional beneﬁts because of the high sensitivity of the IMU sensors. Storing only  two \nhead orientations (in registers) and their associated  P buff  in the DRAM occupies only  ≈ 16 MB  memory space.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Compared to classical inference, DynInfer introduces additional overhead for scheduling and task fusion, but this is offset by the gains in reliability and efficiency under intermittent power. Handling Extremely Low or Sporadic Energy Levels:  In environments with extremely low or sporadic energy levels where consistent dropout and quantization adjustments may not be feasible, NExUME handles this by: 1. Implementing a minimum viable model configuration that operates at the lowest acceptable energy consumption, achieved by maximizing dropout rates and using the lowest quantization bit-widths.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "The immediate reward for sensor  s i  is defined as: \nR i ( t ) = \n     \n    \nγ  ·  ∆ A i ( t ) , if  a i ( t ) =  P and inference is correct , \n− δ, if  a i ( t ) =  P and inference is incorrect , \n− η, if  a i ( t ) =  NP . Here,  γ >  0  scales the reward for correct participation, δ >  0  penalizes incorrect inference, and  η >  0  penalizes non-participation, with  η > δ  ensuring that remaining idle \n8 \n440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 \nis more penalizing than at least attempting participation. The cost incorporates energy consumption and future op- portunities.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 315,
    "augmented": false
  },
  {
    "text": "The intuition is that any importance sampling scheme produces an unbiased estimator [ 8 ]. To preserve the temporal and frequency features, we ensure sampling data which are far enough from each other to build a better representation. The entire process of importance sampling uses simple arithmetic operations and is therefore viable in energy-scarce situations.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "The above discussion has explored the opportunity of utilizing Morton codes to speedup the geometry compression. Recall from Fig. Figure 6: Intra-Frame attribute compression example.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Chaos monkey: Increasing sdn reliability through systematic network destruction. In  Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication , pages 371–372, 2015. [20] Lingjiao Chen, Matei Zaharia, and James Zou.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Restrictions apply. optimizations such as compile-time instruction fusion for better parallelism, or provide additional architectural support for our proposal by investigating the hardware designs with respect to FPGA modules or customized ASICs, to optimize the bottleneck stage and make PCC on edge devices even faster/more efﬁcient (e.g.,  ≈ 33 ms  for  30  f ps  display refresh rate). A CKNOWLEDGMENT \nWe thank the anonymous reviewers for their helpful feedback and suggestions towards improving the paper content.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "Rather than capturing the reuse opportunities in raw input data, Potluck [12] ﬁrst extracts the feature vector (i.e., a vector generated from input image, such as SURF [47], HoG [48], Down-sampling [16], etc.) Apart from the above mentioned optimizations at the layer- level (DeepCache) and the frame-level (Euphrates), recall that, in Table I, we indicated (in the last column) the Decision Making Logic (DM) the previously proposed optimization strategies employ. Now, in Table IV, we present the mAP, latency and energy efﬁciency results with those prior schemes.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "[75]  S. Schwarz, M. Preda, V. Baroncini, M. Budagavi, P. Cesar, P. A. Chou, R. A. Cohen, M. Krivoku ´ ca, S. Lasserre, Z. Li, J. Llach, K. Mammou, R. Mekuria, O. Nakagami, E. Siahaan, A. Tabatabai, A. M. Tourapis, and V. Zakharchenko, “Emerging mpeg standards for point cloud compression,”  IEEE Journal on Emerging and Selected Topics in Circuits and Systems , pp. 133–148, 2019. [76]  J. Shao, H. Zhang, Y. Mao, and J. Zhang, “Branchy-gnn: A device-edge co-inference framework for efﬁcient point cloud processing,” in  ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , 2021, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 241,
    "augmented": false
  },
  {
    "text": "2017. CoRR (2017). InfiniTAM v3: A Framework for Large-Scale 3D Reconstruction with Loop Closure.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Even if we were able to design a proper scheduling policy, for a conventional ensemble, all the sensors involved need to ﬁnish their computation. Therefore, we cannot always expect inference outcomes from all the sensors while doing HAR on EH-WSN. However, our preliminary results using the hardware setup of [6] and the DNN from [11] on the MHEALTH [12], [13] dataset suggests that only 10% of inferences could be completed in a WiFi powered system (Fig.1a).",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "´as  works completely using intermittent power, it is imperative to compare and contrast it with other possible solutions. TABLE  III  depicts some of such possible comparison points. Alternate Solutions:  Although  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems , pp. 199–213, 2019. Transforma Insights.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "The added recall functionality enables ensemble learning. policy in use. Further, the scheduling strategy was modiﬁed using activity aware scheduling with extended round-robin such that all the sensors get enough time to harvest and also the best possible sensor works on the classiﬁcation task at hand instead of any arbitrary sensor.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "8: Measure key indicators: participation rate, average energy depletion rate, frequency of incorrect infer- ences, and overall inference accuracy. 11: else if  participation is too high, leading to frequent energy depletion  then 12: Decrease  γ k  ← γ k − ∆ γ  or increase  δ k  ← δ k +∆ δ to discourage high-risk attempts. 9: if  participation is too low (e.g.,  < p min ) or sensors remain idle too often  then 10: Increase  γ k  ← γ k  + ∆ γ  or decrease  η k  ← η k  − ∆ η .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "[7]  W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y. 494–496, 2018. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, “A 65nm 1mb nonvolatile computing-in-memory ReRAM macro with sub-16ns multiply-and-accumulate for binary DNN AI edge processors,” in  2018 IEEE International Solid - State Circuits Conference (ISSCC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "[72] K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, \nJ. Sampson, M. T. Kandemir, and V. Narayanan, “Resirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent em- bedded processors,” in  2020 IEEE International Symposium on High Performance Computer Architecture (HPCA) . IEEE, 2020, pp. 315– 327.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Next, as discussed in Sec. IV-B3, the FI-output (the neighbors of the partial inference outputs – pink color) from the previous frame is critical to maintain the accuracy of the output for the current frame. Thus, the full inference outputs are accordingly padded around the partial inference outputs via memory copy (Step  5  ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2012.09988  (2020). [2]  Rachel Albert, Anjul Patney, David Luebke, and Joohwan Kim. 2017.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "This statement should be in an unnumbered section at the end of the paper (co- located with Acknowledgments – the two may appear in either order, but both must be before References), and does not count toward the paper page limit. In many cases, where the ethical impacts and expected societal implications are those that are well established when advancing the field of Machine Learning, substantial discussion is not required, and a simple statement such as the following will suffice: \n“This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.” \nThe above statement can be used verbatim in such cases, but we encourage authors to think about whether there is content which does warrant further discussion, as this statement will be apparent if the paper is later flagged for ethics review.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 187,
    "augmented": false
  },
  {
    "text": "[35]  M. D. Lam, E. E. Rothberg, and M. E. Wolf, “The cache performance and optimizations of blocked algorithms,” in  Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp. 63–74, 1991. [36]  K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Spendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,” in  2017 22nd Asia and South Paciﬁc Design Automation Conference (ASP-DAC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 167,
    "augmented": false
  },
  {
    "text": "[110] Asit K Mishra, Narayanan Vijaykrishnan, and Chita R Das. A case for heterogeneous on-chip inter- connects for cmps. ACM SIGARCH Computer Architecture News , 39(3):389–400, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "This may be due to change in user behavior manifesting itself as variable function input patterns. Commonality:  As described in Section 2, in addition to cold start spillovers, incorrect probability estimations may arise due to variability in workflow activation patterns. Bringing  Connectivity  into the weight estimation process helps  Kraken  assign a higher weight to critical func- tions, in turn, ensuring that more containers are assigned to them, resulting in improved response times for the functions themselves, as well as their descendants.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "In  USENIX Middleware Conference , 2017. [35]  Arpan Gujarati, Reza Karimi, Safya Alzayat, Antoine Kaufmann, Ymir Vigfusson, and Jonathan Mace. Serving dnns like clockwork: Perfor- mance predictability from the bottom up.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "On the other hand,  DProb  and  SProb  spawn fewer containers than  Kraken  as a consequence of not using  Commonality  and Connectivity  to augment function weights, while making container allocation decisions. As a result,  Kraken  provisions up to 21% more containers than both  DProb  and  SProb  for the three applications. Note that, these additional containers are necessary to reduce SLO violations.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "[13] AMD. Infinity fabric. \" https://www.amd.com/content/dam/amd/en/documents/ instinct-tech-docs/data-sheets/amd-instinct-mi300x-platform-data-sheet.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "However, one power cycle of the other power sources can usually process thousands or hundreds of inferences. TABLE V T HE RATIO OF ADDITIONAL INFERENCES ENABLED BY THE SMOOTH TRANSITION STRATEGY VS . TOTAL INFERENCES \nPiezo WiFi-h WiFi-o Thermal TV-RF \nLeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 \nE. Power predictor \nWith an accurate power predictor [ 45 ], [ 36 ], we can make more smooth transitions among different power levels.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 199,
    "augmented": true
  },
  {
    "text": "In fact, for training GPT-3, on an average, 5.4 million liters of water is consumed! Clearly, such extensive requirements create barriers for academic institutions and smaller enterprises for advancing the state-of-the-art in LLM cost-effective training, inference, and adaptability. In addition, the availability of clean and high-quality data is reaching physical limits.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "We use an idle-timeout limit for 10 minutes to recycle unused \ninstances from every model pool. Hence, greedily assigning requests enables early scale down of lightly loaded instances. This is similar to an online bin-packing algorithm.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "\"https://github.com/ google-research-datasets/Objectron/blob/master/index/bottle_annotations\". Objectron Dataset Annotation: bottle. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "This research was partially supported by NSF grants #1931531, #1955815, #1763681, #1908793, #1526750, #2116962, #2122155, #2028929 ,and we thank NSF Chameleon Cloud project CH-819640 for their generous compute grant. All product names used in this publication are for identiﬁcation purposes only and may be trademarks of their respective companies. References \n[1]  Martín Abadi.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Apart from compression, the de-compression stage can also be run in parallel after applying our proposal, and can be even faster than the compression stage due to its reduced complexity (note that, this also applies for the attribute compression proposals as discussed later in Sec. IV-C 1 and Sec. VI , our results indicate  37 ×  speedup for the geometry compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Abstract — Intelligent edge sensors that augment legacy ”un- intelligent” manufacturing systems provides cost-effective func- tional upgrades. However, the limited compute at these edge devices requires trade-offs in efficient edge-cloud partitioning and raises data privacy issues. This work explores policies for partitioning random forest approaches, which are widely used for inference tasks in smart manufacturing, among sets of devices with different resources and data visibility.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 37th International Conference on Neural Information Processing Systems , NIPS ’23, Red Hook, NY, USA, 2024. Curran Associates Inc. \n[100] Andrew J. Lohn and Micah Musser. Ai and compute: How much longer can computing power drive artificial intelligence progress ?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Furthermore, these changes between consecutive frames need not be explicitly calculated as they can be extracted from the hardware codecs directly, giving us a chance to capitalize on an existing funda- mental component, instead of adding new hardware blindly. Leveraging inter-frame similarity, intra-frame redundancies, and the RoIs have been investigated for different purposes, e.g., exploring pixel-similarity to encode frames and reduce bandwidth consumption [17], utilizing RoIs to reduce the com- putational footprint [18], [19], analyzing inter-frame similarity to skip inferences [9], and caching the intermediate results to avoid redundant computation [8]. However, the granularity of similarity explored in these prior works is  static , and either too coarse (e.g., skips the entire frame [9]) or too strict (e.g., still needs to compute despite very few changes).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 205,
    "augmented": false
  },
  {
    "text": "It is obvious that it is not feasible to train a DNN for all types and variances of human actions. D. Adaptive Ensemble Learner \nAs discussed earlier in Section III-D, origin uses a lightweight and adaptive ensemble learner that performs weighted majority voting based on a conﬁdence matrix. The conﬁdence matrix adapts and learns from the user pattern.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "IEEE, 2022b. In  2022 IEEE Symposium on High-Performance Interconnects (HOTI) , pp. 5–12.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Soft merging of experts with adaptive routing. arXiv preprint arXiv:2306.03745 , 2023. [112] Sai Prashanth Muralidhara, Lavanya Subramanian, Onur Mutlu, Mahmut Kandemir, and Thomas Moscibroda.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "In order to maintain high accuracy, we also propose an adaptive technique to dynamically adjust the reuse window size based on the runtime statistics by comparing the MVs in consequent frames. •  We then propose a frame-level motion vector based scheme to leverage the frame-level similarity to opportunistically skip the inference by reusing the compute results memoized by the previous frame. We identify  online-pruning opportunities for inferences, which can also be exploited at  frame-level ,  region-level , and  pixel-level.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "[11] S. Ha and S. Choi, “Convolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors,” in IJCNN , 2016. [12] O. Banos, C. Villalonga, R. Garc´ıa, A. Saez, M. Damas, J. Holgado- Terriza, S. Lee, H. Pomares, and I. Rojas, “Design, implementation and validation of a novel open framework for agile development of mobile health applications,”  BioMedical Engineering OnLine , 2015. [13] O. Ba˜nos, R. Garc´ıa, J.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture , pages 489–500, 2011. [184] Yuanrui Zhang, Wei Ding, Jun Liu, and Mahmut Kandemir. Optimizing data layouts for parallel computation on multicores.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "6 Analysis of Results \nThis section discusses the experimental results of  Cocktail using the Wiki and Twitter traces. To summarize the overall results, Cocktail providing 2 ×  reduction in latency, while meeting the accuracy for up-to 96% of the requests under reduced deployment cost by 1.4 × , when compared to  InFaaS and  Clipper . 6.1 Latency, Accuracy and Cost Reduction \nLatency Distribution : Figure  7  shows the distribution of to- tal response latency in a standard box-and-whisker plot.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "In the ISAAC design [ 3 ], the inputs, weights and outputs are all 16 bits, where the DAC, ReRAM cell and ADC resolutions are, respectively, 1-bit, 2-bit and 8-bit. To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed. Also, a similar composition scheme is employed to organize the input, weight and output data.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "[61]  Rachid Saadane, Abdellah Chehri, Seunggil Jeon, et al . 2022. AI-based modeling and data-driven evaluation for smart farming-oriented big data architecture using IoT with energy harvesting capabilities.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Because  Φ  is bounded above by  Φ max , only a finite number of increments can occur before no further improvements are possible. This contradiction shows that no infinite improvement sequence can occur. Existence of a Nash Equilibrium \nSince no infinite sequence of profitable unilateral deviations can occur, the best-response dynamics must terminate in a state where no sensor can unilaterally improve its utility.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "E Workings of Re-RAM Crossbar \nE.1 Re-RAM cross-bar for DNN inference: \nReRAM x-bars are an emerging class of computing devices that leverage resistive random-access memory (ReRAM) technology for efficient and low-power computing. These devices can perform multiplication and addition operations in a single operation, making them ideal for many signal pro- cessing and machine learning applications. Moreover, these devices can also be used for performing convolution operations, which are widely used in image and signal processing applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "More speciﬁcally, the  360 ° video processing pipeline can be summarized as follows: Video Decoder:  The HMD receives encoded  360 ° video bitstream from the network (YouTube [61], Facebook-360 [7], etc). Similar to 2D videos, the  360 ° video bitstreams are encoded in H.264/MPEG formats [19] for network efﬁciency. The next step is to decode the original frame from the bitstream, and today, this is mostly done using a hardware- based h264/MPEG decoder for more energy efﬁciency.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "From this figure, one can observe the following: First, in general, these two steps take similar times to execute, due to the similar procedures they \nAlgorithm 1:  Depthmap Hologram Algorithm [4, 18]. Input : M : Number of depth planes Input : DP [ i ] : Pixels in the  i th   depth plane Output: Holoдram : Generated hologram \n1  procedure  Depthmap _ Holoдram ( M ,  DP ) // main \n2 // Step-1: Forward-propagate \n3 for  i  in  [ 1 ,  M ]  do // planes in parallel \n4 for  p  in  DP[i]  do // pixels in parallel \n5 IntraPlane i  =  HP 2 DP ( i ,  p ) \n6 IntraBlockSync (IntraPlane[i]) \n7 Inter BlockSync () \n8 // Step-2: Backward-propagate \n9 for  i  in  [ 1 ,  M ]  do // in parallel \n10 for  p ′   in  IntraPlane[i]  do // in parallel \n11 Hologram[ p ′ ] +=  DP 2 HP ( i ,  p ′ ) \n12 Inter BlockSync () \n13 return  { Holoдram } \nemploy, as shown in Algo. 1.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 302,
    "augmented": false
  },
  {
    "text": "overhead, as discussed in Sec. From this ﬁgure, we observe that: •  Baseline:  In  Baseline , since there are no optimizations, the projection operations for both eyes consume equal energy (on GPU), i.e., each eye’s compute consumes  50%  energy. •  EA:  With our proposed  EA  scheme, we fully exploit the temporal compute reuse  across frames with head orien- tations unchanged, with a negligible overhead ( 1%  extra \n6 Due to space limitation, here we only present 5 videos and 20 users.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "D1 \nD2 \nD3 \nD4 \nD5 \nD6 \nD7 \nD8 \nE1 \nE2 \nE3 \nE4 \nE5 \nE6 \nE7 \nE8 \nStep-1: {E1, E5, E7} use {D1, D2, D5} \nStep-2: {E2, E3, E6} use {D3, D6, D7} \nStep-3: {E4, E8} use {D4, D8} \n(a) \n(b) \nFigure 4 :  Bipartite graph to perform data locality- aware expert training. In this case, the training is completed in 3 steps. As depicted in Figure 4(b), we train E1, E5, and E7 together as they share datasets, followed by E2, E3, and E6, and the remaining experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 172,
    "augmented": false
  },
  {
    "text": "(Accessed on 11/13/2023). gov/news/0728-storage-device/ . Shiju Li, Kevin Tang, Jin Lim, Chul-Ho Lee, and Jongryool Kim.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "However, this leads to another potential issue - what if the current inference is running on the best sensor, and the sensor does not have enough energy to run the next inference? In this case, the current sensor chooses the next best sensor for the job and signals it. After a sensor detects an activity, it anticipates the next activity to be the current classiﬁed activity, looks up for the best sensor, and signals to activate it for the upcoming inference.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "The use of FPGA not only accelerates the processing speed but also provides flexibility to adapt to various codec configurations. Training the Neural Codecs to Utilize Inference Pipeline:  The enhancement of our layered neural codec involves a joint training regimen that integrates the model used in inferecne pipeline, specifically MobileNet, as a static feature extractor within the compression framework. This strategy capitalizes on the robust, pre-trained features of MobileNet, which are frozen during training to ensure their integrity and to leverage their proven capability in capturing essential visual features.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Designing SDMM Hardware on CSD FPGA:  The SDMM hardware is innovatively designed to perform two modular multiplications per DSP Slice. In this signed representation, the Gaussian distribution ranges from  [0 , ks )  to  [ q  − ks,  0) , where  k  takes integer values  1 ,  2 ,  3 , . This is achieved through the implementation of signed Gaussian sampling (Liu et al., 2019), for the error-vector  e 1  and the secret-key  r 2 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "[57] C. Xie, X. Zhang, A. Li, X. Fu, and S. Song, “PIM-VR: Erasing Motion Anomalies In Highly-Interactive Virtual Reality World with Customized Memory Cube,” in  Proceedings of the International Symposium on High- Performance Computer Architecture (HPCA) , 2019, pp. 609–622. [58] Xilinx, “Vivado Design Hub - Installation and Licensing,” ”https://www.xilinx.com/support/documentation-navigation/design- hubs/dh0013-vivado-installation-and-licensing-hub.html”.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 165,
    "augmented": false
  },
  {
    "text": "The discount factor  β  ∈ [0 ,  1)  captures how sensors value future utility, with  V i ( t  + 1)  representing the expected fu- ture utility given current decisions and predicted energy availability   ˆ E i ( t  + 1) . Let  C i ( t )  represent the cost component: \nC i ( t ) =  e i ( t ) +  βV i ( t  + 1) , \nwhere  e i ( t )  is the total energy expenditure for participa- tion, encompassing data capture, inference computation, and communication: \ne i ( t ) =  e cap ( SNR i ( t )) +  e inf  +  e comm . Overall Utility Function: Combining immediate rewards and costs, the overall utility function for sensor  s i  at time  t is: U i ( t ) =  R i ( t )  − C i ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 228,
    "augmented": true
  },
  {
    "text": "4.Data Flow Management:  Design efficient data paths to handle the high throughput of video data and intermediate results between the FPGA blocks, ensuring that bandwidth and memory access bottlenecks are minimized. By optimizing each component for FPGA execution and taking advantage of the hardware’s ability to execute multiple operations in parallel, the proposed codec can achieve real-time performance even for high-resolution video streams. The use of FPGA not only accelerates the processing speed but also provides flexibility to adapt to various codec configurations.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Intuitively,  InFaas  has the least number of VMs spawned because it does not ensemble models. Cocktail  spawns upto 50% more VMs than  InFaas , but in turns reduces accuracy loss by up to 96%. To further capture the beneﬁts of the weighted autoscal- ing policy, Figure  12a  plots the number of VMs spawned over time for the top-3 most used models in the ensemble for  Const1 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2309.05444 , 2023. [179] Haibo Zhang, Shulin Zhao, Ashutosh Pattnaik, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. Distilling the essence of raw video to reduce memory usage and energy at edge devices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Overall, the entire PCC pipeline takes around 3.5 seconds 3 , which prevents one from employing such techniques in an edge device. Further, among the ﬁve stages in the pipeline, octree construction & serialization for geometry compression and RAHT for attribute compression are the two major bottlenecks which take  1 s  and  2 s , respectively. Driven by these observations, we investigate the reasons behind such inefﬁciencies, and further explore the potential opportunities for speeding up the PC compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Large language models in healthcare and medical domain: A review. Informatics , 11(3):57, 2024. [131] Raghu Prabhakar, Ram Sivaramakrishnan, Darshan Gandhi, Yun Du, Mingran Wang, Xiangyu Song, Kejie Zhang, Tianren Gao, Angela Wang, Karen Li, Yongning Sheng, Joshua Brot, Denis Sokolov, Apurv Vivek, Calvin Leung, Arjun Sabnis, Jiayu Bai, Tuowen Zhao, Mark Gottscho, David Jackson, Mark Luttrell, Manish K. Shah, Edison Chen, Kaizhao Liang, Swayambhoo Jain, Urmish Thakker, Dawei Huang, Sumti Jairath, Kevin J.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 196,
    "augmented": false
  },
  {
    "text": "5.3). 5.3 Experimental Results We present the power and energy consumption, as well as the execution latency of the hologram computation in Fig. 7, when processing the six videos listed in Tab.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "8525. Virtual, Augmented and Mixed Reality: Designing and Developing Augmented and Virtual Environments: 6th International Conference, VAMR 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014, Proceedings, Part I . Vol.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode. In this case, we choose the activation solution with larger tiling size by taking into account the transition cost. If the tiling sizes of output solutions are the same, we choose larger  m because larger  m  implies fewer partial sum adds.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Moreover, in large-scale systems where failure is common, replacing failed CSDs would further increase the cost. From our evaluation, we found an 8:1 ratio of SSD to CSD (capacity ratio) provides the best possible cost-to-acceleration benefit. Integrating more number of CSDs into the standard storage server will significantly increase the cost of the server.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "A selected group of undergraduate students and volunteers from CRA-W, ACM, and Girls Who Code programs will be trained to go to these schools and talk to students. In this context, we plan to show them how Generative AI are being used in different application domains (e.g., LLM-powered story generation and creative writing, interactive chatbots for math learning and problem solving, etc). We have also participated in the annual Exploration-U Science day events, organized by Penn State.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "This hardware-driven adaptive scheduling signiﬁcantly impacts different data modal- ities, from large-scale to small-scale, and various magnitudes of energy income, as depicted in Fig. For scenarios with larger and predictable energy income, software-based backup and restore mechanisms can offer signiﬁcant beneﬁts, as the energy consumed for such operations is typically a small fraction of the overall energy income. 10c .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "The hardware design details will be presented in Section V. \nIV. A  HARVESTING - COMPATIBLE ,  LOW - \nPOWER  R ESI RCA \nSupporting the necessary features for adapting RCAs to a harvested power supply will require optimizations in both RCA circuit design and the development of variable-power-optimized loop-tiling strategies. First, feasible implementations of ﬂexible activation options require a low power and reconﬁgurable RCA.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "2019. Holographic Near- Eye Displays Based on Overlap-Add Stereograms. ACM Trans.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "If there exists a simple mechanism to describe the difference between the two projection matrices of the two eyes ( P L  and  P R ), one can simplify the computation from matrix  multiplications  to matrix  additions . To leverage this opportunity, we next study the coordinate projection results relationship between left-eye and right-eye. Distance Vector Study:  Let us further look into the detailed mapping of a  360 ° frame (in equirectangular format) onto a 2 D  FoV frame in the Projection Mapping stage (refer  c  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "2019. Architectural implications of function-as-a-service computing. 166 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ’21, November 1–4, 2021, Seattle, WA, USA \n[41]  Mohammad Shahrad, Jonathan Balkind, and David Wentzlaff.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "In  2018 USENIX Annual Technical Conference . 173– 186. 167",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 20,
    "augmented": false
  },
  {
    "text": "An overview of chatbot technology. In  IFIP interna- tional conference on artificial intelligence applications and innovations , pages 373–383. Springer, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "•  Post Processing:  Using these relationship arrays, the ﬁnal step is to post-process them to obtain the occupy bits for each node, and output the compressed geometry stream. Proposed Intra-Frame Attribute Compression:  As shown in Fig. 3  and discussed in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "In our experiments we assume the hardware to be powered by a solar panel of one square-meter, and the powers are scaled accordingly (data is available as  W / m 2 ). Since our dataset is from Bellevue, WA, we took the SOLRAD solar radiation data [ 25 ] (managed and published by National Oceanic and Atmospheric Administra- tion, NOAA) of Seattle, WA (the SOLRAD center closest to Bellevue and hence we believe is a good approximation). Finally, we assume the exact same setup of the Urban trafﬁc dataset and hence have 5 different MobileNetV2 models trying to classify the trafﬁc they are facing, and learning from the streaming data.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "This is because the latter only approximates the objects outside of the current region of focus (still requiring full compute for the objects inside), whereas the scope of the former is much larger, i.e., including all the objects in the current viewing window and approximating each of them based on its location. Another interest- ing observation is that,  Intra-Holo  saves more execution time than Inter-Holo . In addition, from an individual video’s perspective, we further observe that the  shoe  video achieves the maximum performance benefits from our schemes (specifically, 23%, 69% and 73% latency reduction with Inter-Holo ,  Intra-Holo  and  Inter-Intra-Holo , respectively, compared to the baseline).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 172,
    "augmented": true
  },
  {
    "text": "1:  Fraction of inference completed on harvested energy using na¨ıve scheduling. Each of the sensors in a multi-device HAR deployment receives different data depending on its location and the current human activity in progress. Therefore, different DNNs are needed to process data from these different locations.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "7 ×  speedup and 73% energy savings. CCS CONCEPTS \n•  Computing methodologies  → Ray tracing ;  •  Computer sys- tems organization  → Embedded software ;  •  Human-centered computing  → Visual analytics . ∗ Work was done as a student at Penn State.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "This can be achieved by deleting its vector in the gating function  g ; (2) Combine, combining several experts in one EoE layer. This can be achieved by adding several expert functions (e.g., FFNN) and their corresponding gating functions; (3) Quantize, reducing the memory requirement of experts through quantization [34]. Once the user specifies target domains, the algorithm locates the most irrelevant domains in the graph (either branch or leaf) until the number of experts fits within the memory constraints or the relevance reaches a threshold.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "3  ×  S sbb ). Such large MV indicates that an object (of similar size to that of the other objects which have been already identiﬁed), which was supposed to be captured, but failed due to the inaccuracy of DNN models (such as YOLOv4-tiny [37] used by the detection application as discussed in Sec. V).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "1041–1057. [29] U. Gupta, Y. G. Kim, S. Lee, J. Tse, H.-H. S. Lee, G.-Y. [28] J. R. Gunasekaran, C. S. Mishra, P. Thinakaran, B. Sharma, M. T. \nKandemir, and C. R. Das, “Cocktail: A multidimensional optimization for model serving in cloud,” in  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , 2022, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "In  2019 International Conference on Robotics and Automation (ICRA) , pp. 8234–8240. IEEE Press, 2019. doi: 10.1109/ICRA.2019.8794073.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "In  Proceedings. RTAS 2004. 10th IEEE Real-Time and Embedded Technology and Applications Symposium, 2004. , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "[25] Tianqi Chen, Benjamin Moreau, Chunting Zheng, Yutian Tang, Zijian Yan, Yanan Song, Yuhao Jia, Maximilian Seeger, Lingfeng Wang, and Hai Bian. Tvm: An automated end-to-end optimizing com- piler for deep learning. Proceedings of the ACM on Programming Languages , 2(4):1–25, 2018.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "2018. Fast Generation of Mesh Based CGH in Head-Mounted Displays using Foveated Rendering Technique, In Imaging and Applied Optics 2018 (3D, AO, AIO, COSI, DH, IS, LACSEA, LS&C, MATH, pcAOP). Imaging and Applied Optics 2018 (3D, AO, AIO, COSI, DH, IS, LACSEA, LS&C, MATH, pcAOP) , DTu5F.6.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "Figure 8. Comparison of the resource procurement cost for two different traces using five different schemes. The cost is normalized to reactive scaling scheme.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "In fact, the inference of VGG-16 [31], which is a popular DNN model, takes 240  ms  to execute on an embedded Adreno 640 [32] GPU, which is far from  real-time . Moreover, most of the ex- isting solutions targeting such applications demand specialized hardware and/or compiler support, and it is not straightforward for a developer to deploy them without multi-domain expertise across the optimization, compilers and hardware spectrum. However, in the speciﬁc context of video applications, the “temporal continuity nature” of the video data presents itself as an opportunity that is yet to be fully exploited.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "Urban Traffic Dataset. https://github.com/edge-video-services/ekya#urban-traffic-dataset. IEEE, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "Figure 4: Function Hit Rate for an Evenly Distributed Load across all Paths in each Application. NGINX \nSearch \nMake_Post \nRead_Timeline \nFollow \nText \nMedia \nUser_tag \nURL_Shortener \nCompose_Post \nPost_Storage User_Tag URL Compose_Post \nFollow Text \nend \nSearch Make_Post Read_Timeline \nNGINX \nPost_Storage \n0.08 \n0.4 \n0.32 \n0.2 \n0.5 \n0.3 \n0.1 \n0.1 \n1 \n1 \n1 \n1 1 \n1 \nFigure 5: Transforming the Social Network DAG into a Transition Matrix. behavior [ 19 ,  20 ].",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "6: Weight stationary compute mapping. The PE-level shows how the input ﬂows and the convolutions are computed with a 3x3 convolution toy example. The tile-level shows how each tile consists of multiple such PEs and will be working on one kernel at a time.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Energy Savings:  The above power and latency reductions pro- vided by  HoloAR  eventually translates to energy savings for the hologram processing. As shown in Fig. 2), thereby gaining more opportunities to reduce the amount of computations for all the objects in the current frame.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "They have also advised a couple of female undergraduate students. PI Das has worked with several high school students and teachers in summer for the completed NSF Expeditions project. In addition, he had co-organized a summer workshop for visually-impaired students as a part of their Expeditions project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "1b, e.g., CPUs for generic processing, GPUs for graphics computing, vision processing units (VPUs) for rendering, and tensor processing units (TPUs) for learning infer- ences. Recently, state-of-the-art AR headsets such as HoloLens [ 31 ] have even been planning to integrate the holographic processing units (HPUs) for processing the information coming from all of the on-board sensors (currently under development) [32]. On-board Battery:  It is to be noted that all of the sensors and the processing engines mentioned above are  battery-backed , as shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "3  shows a typical trafﬁc distribution from Urban Trafﬁc data [ 97 ]) and the impact of sampling bias on class distribution. This creates a sampling “bias” [ 70 ] while performing the training, and often leads to catastrophic forgetting. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "In a sense, our annotations will make the data originating from this project more actionable and easily repro- ducible. To generate such annotations, where appropriate, we plan to use well-established data lineage tools such as Keboola [78] and Octopai [120]. The data lineage information will also help the project to reduce its “storage footprint”.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Salient Store  on CSDs perform  ≈ 1 . 99 ×  better than the implementation on classical storage systems. To further mimic realwold scenarios of multiple cameras sending multiple streams with various stream rate, we  distributed  video data into across two CSDs in different ratio, as shown in TABLE 2.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "(Sec. 4.3) and found to work well (in Sec. 2.2) •  To capture these two approximation opportunities from both the user and object perspectives, first, the prior  foveated ren- dering  idea (denoted as  Inter-Holo  design) has been imple- mented (in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Considering the power proﬁle of Fig. 11b ,  Us. ´as  can ﬁnish about 50 cycles of retraining (50 complete training cycles) and DaDianNao can only ﬁnish 22 training cycles, even assuming a zero overhead, seamless save-restore of the partial computes of DaDianNao during a power failure/emergency.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "5 Implementation and Evaluation \nTo implement and evaluate  Salient Store  , we chose two different platforms – 1) Using a server- grade system with two Xilinx-Samsung computational storage drive (AMD, b), and 2) Using amazon web services (AWS) F1 instances, which have AMD Alveo FPGA which can work as the compute capable of peer-to-peer communication and thereby enabling a computational storage platform. The SDMM also offers a simpler controller design for multiplication and in-place product term reduction after vector-vector multiplications. Notably, the SDMM can be easily reconfigured to support any modulus.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "B ACKGROUND AND  M OTIVATION \nBefore getting into the details of the existing issues and possible solutions, we ﬁrst outline the computation pipeline of the state-of-the-art  360 ° VR streaming (Fig. 1). Further, we describe the existing energy inefﬁciencies in processing  360 ° VR systems, to motivate our design for mitigating the com- putational inefﬁciencies by avoiding redundant computations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "None of  Naive1  and  Naive2  executions can go through power cycle  PC-i  and the power utilization is very low, as there is a signiﬁcant mismatch between the power producer and consumer. Figure 6(c) presents a ﬂexible scheduling strategy applied to ResiRCA. In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "8 Acknowledgement We are indebted to the anonymous reviewers for their in- sightful comments. Our experimental evaluation on a 160-core cluster using  Deathstarbench  workload suite and real-world traces demonstrate that  Kraken  spawns up to 76% fewer containers, thereby improving container utilization and cluster-wide energy savings by up to 4 ×  and 48%, respec- tively, compared to state-of-the art schedulers employed in serverless platforms. This research was partially supported by NSF grants #1931531, #1955815, #1763681, #2116962, #2122155 and #2028929.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "[38]  B. Li, “3d fully convolutional network for vehicle detection in point cloud,” in  2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2017, pp. 1513–1518. [39]  L. Li, Z. Li, V. Zakharchenko, J. Chen, and H. Li, “Advanced 3d motion prediction for video-based dynamic point cloud compression,”  IEEE Transactions on Image Processing , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "3b. In this scenario, the area of the MV  S mv  is similar to or even larger than the area of the smallest bounding box  S sbb  from the previous frame (in this case,  S mv  = 1 . 3  ×  S sbb ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "2020. OpenHolo: Open Source Library for Hologram Generation, Reconstruction and Signal Pro- cessing. In  Imaging and Applied Optics Congress .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "In this case,  P 0 is located in the  7 th  child of the  root  node, and the  root  node now stores the occupy information, which is  00000001  (the right-most  1  indicates a “child” in  7 th  leaf node). Similarly, P 1  is located inside the current bounding box and inserted into the octree as the 6 th  child of the  root . Interestingly, in order to include  P 2 , the current bounding box has to expand its side length by  4 × , i.e., enlarging from  2  to  8 , and now the octree also contains more levels with all three points being in its leaf level.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "2020. Im- plications of Public Cloud Resource Heterogeneity for Inference Serving. In  Workshop on Serverless Computing (WoSC’20), December 7ś11, 2020, Delft, Netherlands.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Decomposable loops: Each ‘QuantaTask‘ runs a certain part of the loop. 3. Check for sufficient energy before launching a ‘QuantaTask‘.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Figure 6: The proposed  HoloAR  which includes  Inter-Holo leveraging foveated rendering, and  Intr-Holo  further ap- proximating holograms for far objects. uses the  Intra-Holo  scheme (denoted  c  ), to identify the number of depth planes required for a particular object by analyzing the rela- tive camera-to-object distance as well as the shape/size of the target object. Note that, both the  Inter-Holo  and the  Intra-Holo  schemes are complementary to each other, when both the eye tracking and pose estimation inputs are available at the same time.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "While recent works [ 12 ], [ 46 ] have attempted to tackle this concern through student-teacher paradigms, efﬁciently deploying such approaches in complex data modalities (e.g., multi-class video, 3D point cloud) remains a formidable challenge. Ensuring adherence to Service Level Agreements (SLAs), where in- ference typically utilizes a lower-resource model [ 51 ], [ 75 ] and labeling is performed using a larger teacher model [ 44 ], \n891 \n2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) \n2378-203X/24/$31.00 ©2024 IEEE DOI 10.1109/HPCA57654.2024.00073 \n2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) | 979-8-3503-9313-2/24/$31.00 ©2024 IEEE | DOI: 10.1109/HPCA57654.2024.00073 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 249,
    "augmented": false
  },
  {
    "text": "[17] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the dan- gers of stochastic parrots: Can language models be too big? com / research / introducing-apple-foundation-models \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Speciﬁcally, given a PC video stream, V-PCC ﬁrst performs 3D to 2D projection on each frame [ 29 ], [ 32 ], [ 39 ], [ 75 ], and then encodes these 2D projections via traditional 2D image codec. Both G-PCC and V-PCC are widely adopted in MPEG standard [ 53 ], and since our proposals begin with G-PCC, thus, is also compliant with the MPEG PCC standard. V-PCC 2   targets compressing PC videos.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Then, we discuss and present the validity of our results on the smartphones. Execution Latency:  We ﬁrst compare two SOTA schemes (TMC13 [ 56 ] for intra-frame compression, and CWIPC [ 13 ] for inter-frame compression) with our three proposals (intra- only, (better) quality-oriented Intra-Inter-V1, and (better) compression-oriented Intra-Inter-V2), and present the col- lected execution latencies in Fig. 8a .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Instead of simulating the CPU, we tested the K-means clustering and cluster optimization on a mobile SoC with 8 ×  ARM Cortex A78 series CPU. Table  I  lists the estimated power consumption and area of the major components. To correctly estimate accelerator power and area, we implemented a register-transfer level model using System Verilog and syn- thesized using Synopsys Design Compiler [ 93 ] with a 32nm library [ 94 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "This example illustrates 3 consecutive frames processing, each of which consists of two projection matrices ( P L and  P R ) for both eyes. However,  T 2  can change at runtime, and if any element in  T 2 is changed, the transformation matrix needs re-computation \nFig. 4: InterFrame-IntraEye ( EA ) and IntraFrame-InterEye ( AE ) reuse opportunities.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "This gives us a unique platform to think of intermittency beyond embedded systems and energy. While many of the prior works have designed their systems around inference using intermittent systems, we are one of the few works which focuses on learning, and the only work which does it on a large scale of data. The proposed system is not only energy intermittent, but also memory intermittent, interconnect intermittent and most importantly data intermittent (we don’t know how much data and what data).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Task-3.1: Expert/Hardware Co-Characterization To efficiently serve various application needs, the question we ask is  what are the intelligent ways to execute EoEs? The core of our architectural investigation is “expert–accelerator affinity” (Table 2), which involves dy- namically mapping “experts” to the most suitable accelerators with configurations such as  one-to-one ,  one- to-many ,  many-to-one  and  many-to-many , each providing unique benefits for scalability and efficiency. .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "time \nFig. time \n0% \n20% \n40% \n60% \n80% \n(c) FI+SI+PI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead Partial \n(d) FI+SI+PI exec. 8: Performance and energy improvements for YOLOv3 w.r.t.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Chaos monkey: Increasing sdn reliability through systematic network destruction. In  Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication , pages 371–372, 2015. [20] Lingjiao Chen, Matei Zaharia, and James Zou.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "11  shows its ability to maximize the instantaneous power utilization and scale the number of tiles. Fig. ´as  hardware’s most important feature is its ability to  morph  according to power availability.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "The participating models are made available in a model cache  1b for faster access and avoid re-computation for requests having similar constraints. Then, individual queries are dispatched to instances pools  2  dedicated for each model. The results from the workers are  ensembled  using an weighted majority voting aggregator  3  to agree upon a correct prediction.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Both  Cocktail  and  Clipper  deliver the same overall accuracy (96%, 94.5%, 93.5%, and 92%)). Since sentiment analysis only has 2-3 classes, there are no additional accuracy gains by using the class-based weighted voting. However, the model selection policy effectively switches between differ- ent models based on the structure of input text (equivalent to classes in images).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "2   To un- derstand the impact of DVFS on energy savings and dynamic compute scaling, we implemented a simple multi-arm bandit algorithm to select the right bucket of compute frequencies (SM frequency for NVIDIA GPUs), and memory frequencies to match the power-demands of the intermittent solar source. 4  even with DVFS, commercial off the shelf GPUs could only ﬁnish  <  50% of the scheduled training task. As shown in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "The resultant energy savings of  Kraken  are a direct consequence of the savings in computation and memory usage from the fewer containers spawned. Only  DProb  and SProb  consume lesser energy than  Kraken  (4% lesser), due to their more aggressive container reduction approach. These savings can go up to 48% compared to  Arch  for applications like  Social Network .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Task-2.1: Data Locality and Parallelism–Aware LLM Training Unlike traditional monolithic LLMs, our EoE -based LLM opens up new opportunities to optimize train- ing for both performance and energy efficiency. Each expert in our EoE can be trained independently and faster, significantly reducing the overall training time compared to monolithic models. Additionally, by clustering and scheduling experts that share training datasets, we propose a “locality-aware” training strat- egy that minimizes the frequency and volume of data transfers between experts, memory and storage– a key factor in improving both performance and energy efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Continuous Learning at the Edge: Continuous learning, wherein the model continually learns from new samples over time, adapting to seen and previously unseen classes, has \n892 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "We store ground truth sensor data pattern for all possible labels, and when new data arrives, we find the correlation of the sampled data against the ground truth data, and if any of the correlation coefficient \n6 \nPower-Pred \n+ Decision Logic (MCU) \nCorrelation \nSensor Data \n16bit DNN (x-bar) \n12bit DNN (x-bar \nCoreset: Imp \nSmp/Clust. 95, we choose to ignore further infer- ence computation and only communicate the classification result to the host for further processing. Wireless \nCommunication \nH S/C \nM Harvestor \nSensor Node \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nHost \nSeeker Ecosystem \nCoreset Reconstruct \nDNN for Recovery \nDNN for Inference \nEnsemble \nEngine \nCluster Recovery \nClassfied Results \nFigure 5: Overall system design of Seeker \ncomes out to be  ≥ 0 .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 197,
    "augmented": true
  },
  {
    "text": "[108] Asit K Mishra, Xiangyu Dong, Guangyu Sun, Yuan Xie, Narayanan Vijaykrishnan, and Chita R Das. Architecting on-chip interconnects for stacked 3d stt-ram caches in cmps. ACM SIGARCH Computer Architecture News , 39(3):69–80, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "A low output variance of the estimator means the predicted values are tightly concentrated, i.e., different estimators, even after learning different features, give similar answers. Relying on how different the answers from each estimators are, we can quantify the prediction quality of the random-forest. Simi- larly, a high variance indicates that the predicted values are discrete and there is no consensus.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "In the proposed AE  design, the  Δ  pattern buffer is ﬁrst initialized by subtract- ing  Result [1] .R  from  Result [1] .L , as shown in the  AE  block in Fig. 7. After the pattern between left eye and right eye is captured, an external signal is propagated to the OCE to bypass the further original projection computations.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "The critical challenge of deploying ML prediction serving applications in public cloud is to combine both model and resource heterogeneity towards optimizing for application constraints. 5 Conclusion \nThere is wide-spread prominence in the adoption of ML- based prediction systems spanning across a wide range of application domains. This is because the  Paragon  scheme jointly considers all three parameters and chooses the least costing model.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "(Accessed on 11/13/2023). Lizhou Fan, Zhanyuan Yin, Huizi Yu, and Anne J Gilliland. Using machine learning to enhance archival processing of social media archives.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "1–11, 2009. Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, Vijaykrishnan Narayanan, and Chita R Das. Usas: A sustainable continuous-learning´ framework for edge servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "2018. [52]  Yiming Zhang, Jon Crowcroft, Dongsheng Li, Chengfen Zhang, Huiba Li, Yaozheng Wang, Kai Yu, Yongqiang Xiong, and Guihai Chen. In  Computer Architecture News .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Real-time energy availability into scheduling decisions. 2. Task fusion to minimize checkpointing overhead, which is critical in intermittent environments.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "Moreover, communicating and storing such high volume data will also require energy. Our solu- tion decentralizes this massive compute using a sustainable approach and hence has its own merits. Further, this can help build future solutions using these decentralised nodes for other applications.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "V-A. These energy results are normalized w.r.t. the  Baseline  method.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "9 that, the compute consumes less energy than the  Baseline , i.e., only  72%  on average. This occurs as a result of reusing the memoized results which have been computed and stored previously, ranging from 21 . In this scheme, one can observe from Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Instead, we focus exclusively on a typical edge GPU to execute the hologram, and present our three techniques, namely,  Inter-Holo  (as  Reference ),  Intra-Holo  and  Inter- Intra-Holo , which capture various approximation opportunities in the AR hologram applications to improve both performance and energy efficiency. Framework Prototype:  To prototype a real-life AR headset, a proper codebase and a hardware platform are essential. Thus, our proposal does not rely on any assistance from hardware accelerators, cloud platforms, or neural networks.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "2337–2346. He and F. Zhu, “Online continual learning for visual food classiﬁ- \ncation,” in  Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021, pp. [32] K. He, X. Zhang, S. Ren, and J.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. [107] S. Zhao, H. Zhang, S. Bhuyan, C. S. Mishra, Z. Ying, M. T. Kandemir, \nA. Sivasubramaniam, and C. R. Das, “D´eja view: Spatio-temporal compute reuse for ‘energy-efﬁcient 360 vr video streaming,” in  2020 ACM/IEEE 47th Annual International Symposium on Computer Archi- tecture (ISCA) .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication. In the remainder of this paper, this execution strategy is referred to as  Naive1 . We assume that  Naive1  is also designed with the proposed lightweight circuits.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "2016. 629–642. [66]  Hiroshi Yoshikawa, Takeshi Yamaguchi, and Hiroki Uetake.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "[51] M Sandler, A Howard, Menglong Zhu, Andrey Zhmoginov, Liang- \nChieh Chen , “Mobilenetv2: Inverted residuals and linear bottlenecks,” in  CVPR , 2018. [52] K. Maeng and B. Lucia, “Adaptive dynamic checkpointing for safe \nefﬁcient intermittent computing,” in  OSDI . USENIX Association, 2018.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "We present a detailed analysis of data movement challenges within the archival workflows and demonstrate how the strategic integration of CSDs can significantly optimize data compression, encryption, as well as other data management tasks, to improve overall system performance. We proposes a framework that aligns more closely with the growing data demands. Our research, gos beyond the compute domain, and identifies the gaps in current storage system designs.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Finetune \n(b) Recovering a sub-sampling with GAN. Clustering Recovery \nOriginal Data Coreset Recovered Data \n(a) Recovering a cluster with uniform random re-distribution. Latent Space \nG \n \nGenerator \nNoise D \n \nDiscriminator \nGenerated Sample \nActual Sample \nRecovered Signal \nClose to \nactual?",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. 1, it can be safely bypassed. Additionally, if the frame is in either Scenario-2 or \n1078 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": ", q k }  be a set of QuantaTasks with in- dividual energy requirements  E q i . . .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "https://ai.googleblog.com/2018/05/custom-on-device-ml-models. Custom On-Device ML Models with Learn2Compress. Custom on-device ml models with learn2compress.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "2019. [63]  Himanshu Sharma, Ahteshamul Haque, and Zainul Abdin Jaffery. Maximization of wireless sensor network lifetime using solar energy harvesting for smart agriculture monitoring.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "However, in some pathological cases, the error at times goes close to 60%, and we believe them to be generated artifacts which are common side effects of the GANs[ 11 ]. Our experi- ments suggests that inference on the GAN recovered signal is almost as good as (about 2%  − 4% difference in accuracy) the inference on the recovered cluster signal. The recovery policy can be implemented as a simple generator network in the host.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Min-Han Tsai, Nalini Venkatasubramanian, and Cheng-Hsin Hsu. Analytics-aware storage of surveillance videos: Implementation and optimization. In  2020 IEEE International Conference on Smart Computing (SMARTCOMP) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Mixed Reality with HoloLens: Where Virtual Reality Meets Augmented Reality in the Operating Room. Plastic and reconstructive surgery  (2017), 1066–1070. [62]  Lingjie Wei and Yuji Sakamoto.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "C. Results \nWe ﬁrst compare the execution latency, energy con- sumption, quality (PSNR [peak signal-to-noise ratio]), and compression efﬁciency (compressed size) in Fig. 8 , when using various designs explained in Sec. Other settings are not changed (they remain the same as in the Intra-Inter-V1 version).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "13 \n0 \n20 \n40 \n60 \n80 \n100 \nKitti Vision nuScenes CHIME Cityscapes Waymo \n% Accuracy \nCompute Server VSS Storage Server \n(a) Accuracy. 0 \n0.5 \n1 \n1.5 \n2 \n2.5 \n3 \n3.5 \nKittiVision nuScenes CHIME Cityscapes Waymo \nNormazed Compute Latency \nCompute Server VSS Storage Server \n(b) Latency. Data Location kernel Execution SpeedUp CSD1 CPU 1 CSD1 CSD1 3.9 CSD1 (0.1X), CSD2(0.9X) CSD1 (0.1X), CSD2(0.9X) 4.46 CSD1 (0.3X), CSD2(0.7X) CSD1 (0.3X), CSD2(0.7X) 5.608 CSD1 (0.4X), CSD2(0.6X) CSD1 (0.4X), CSD2(0.6X) 6.67 CSD1 (0.5X), CSD2(0.5X) CSD1 (0.5X), CSD2(0.5X) 7.7 Table 2: Effect of Data distribution on compute speed-up.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 248,
    "augmented": true
  },
  {
    "text": "University of Chicago, Tech. Cerebras systems: Journey to the wafer-scale engine. Rep , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "We then compare this distance with a preset threshold (e.g., 300 7 ) to determine if this segment can be approximated by  direct reuse ; otherwise, we mark it as an post-intra-encoded block. Especially, for each P-block, we ﬁrst calculate its 2-Norm distance to its  best matched block  in I-frame. Also, the total number of blocks is 50000, and the search step is set to be the size of the current P-block (i.e., to ﬁnd the best matched block for current P-block, each time, we traverse the search region in the reference frame by this step size).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "1c) on a typical edge prototype [ 36 ] running a set of state-of-the-art AR-related tasks [ 19 ,  26 ,  49 ,  50 , 53 ], and compared the collected results against ideal execution latencies for the same set of tasks (i.e., the maximum latency within which the task needs to finish before its next invocation). The ideal latencies and our collected latencies are given in Table 1 and Fig. 2, respectively, for an ILLIXR playground scenario [15, 19].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "1414–1419. IEEE, 2021. Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, Vijaykrishnan Narayanan, and Chita R Das.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "The caveat is to have a model trained on the sub-sampled data, which can be done as an one-time step. Although the sub-sampling might lead to poor inference accuracy, in our experiments, with iso-compression ratio, importance sampling based coresets still outperforms classical compression techniques. Figure 4 shows a toy example of importance sampling in a 2D data set.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "[93] Lei Li, Yankai Lin, Shuhuai Ren, Peng Li, Jie Zhou, and Xu Sun. Dynamic knowledge distillation for pre-trained language models. arXiv preprint arXiv:2109.11295 , 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "5 ×  larger than that of TMC13 [ 56 ]. C. Intra-Frame Attribute Compression \n289 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Therefore, simpler paradigms, like random forests, still remain popular for embedded sensors [7]. techniques that bal- ance communication and computation costs while partitioning the compute between the edge and a resource-rich server have been deployed. Additionally.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "The primary goal of DynFit is to \n3 \nadapt the DNN’s training process to operate efficiently under unpredictable energy budgets while maintaining acceptable accuracy and adhering to predefined service level objectives (SLOs). DynFit introduces key mechanisms to dynamically adjust computational complexity based on energy availability, thereby enabling energy-efficient execution of DNN models in constrained environments. These mechanisms include: (i)  Dynamic Dropout , which adjusts the dropout rates based on available energy to reduce computational load; (ii)  Dynamic Quantization , which modifies quantization levels in response to energy constraints to save energy; and (iii)  QuantaTask  design, which defines atomic computational units that can be executed without interruption given the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 170,
    "augmented": false
  },
  {
    "text": ": As discussed in Sec. 5 , - 1  in the parent array means that the root node has no parent, whereas  parent [ 7 ] =  4  means that for the  7 th  node (whose code is  code [ 7 ] =  511 ), the index for its parent node in the code array is 4 (whose code is  code [ 4 ] =  63 )). IV-A 2 , the  octree Construction  step returns several arrays containing the relationship among octree nodes; e.g., the  code array contains the Morton codes for all the nodes, while the  parent array  contains the index of the current node’s parent in the code array (e.g., in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 168,
    "augmented": true
  },
  {
    "text": "3 as three stages (detailed background of this projection transformation can be found in [21], [27]). The ﬁrst stage,  Transformation  (denoted  a in Fig. 3, is to determine a transformation matrix by com- bining ﬁve different transforms.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Index Terms —Virtual Reality, Edge Computing, IoT,  360 ° Video Processing \nI. I NTRODUCTION \nRecent developments in technology, computing and com- munication have brought signiﬁcant changes to the lifestyle of common people by providing them access to increasingly sophisticated devices. Experimental results show that  D´ej`a View  can provide  34%  computation reduction and  17%  energy saving, compared to the state-of-the-art design. Especially, VR and AR are now gaining traction because of their versatile nature of providing an immersive sensory experience, which is not possible with the conventional systems – especially in the domain of video streaming.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "Funded research efforts support 5 High-Performance Computing Clusters, totaling over 300 compute nodes sharing IBA, Myrinet, and GigE interconnection. The clusters offer researchers HPC and GPU con- figuration 9both A 100 and H 100)agility to target highly specialized use-cases. Six student teaching labs are equipped to host digital design, FPGA, circuit design, programming, robotics/drone, and related curricula.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "Data Location kernel Execution SpeedUp CSD1 CPU 1 CSD1 CSD1 3.9 CSD1 (0.1X), CSD2(0.9X) CSD1 (0.1X), CSD2(0.9X) 4.46 CSD1 (0.3X), CSD2(0.7X) CSD1 (0.3X), CSD2(0.7X) 5.608 CSD1 (0.4X), CSD2(0.6X) CSD1 (0.4X), CSD2(0.6X) 6.67 CSD1 (0.5X), CSD2(0.5X) CSD1 (0.5X), CSD2(0.5X) 7.7 Table 2: Effect of Data distribution on compute speed-up. 13 \n0 \n20 \n40 \n60 \n80 \n100 \nKitti Vision nuScenes CHIME Cityscapes Waymo \n% Accuracy \nCompute Server VSS Storage Server \n(a) Accuracy. 0 \n0.5 \n1 \n1.5 \n2 \n2.5 \n3 \n3.5 \nKittiVision nuScenes CHIME Cityscapes Waymo \nNormazed Compute Latency \nCompute Server VSS Storage Server \n(b) Latency.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 248,
    "augmented": false
  },
  {
    "text": "Consequently, during extended periods of energy scarcity, the system lacks mechanisms for computational approximation, such as dynamic dropouts (neuron skipping) and dynamic quantization. Moreover, while the DNN is designed to operate within a specific power window, it is  not  trained to adapt to these fluctuations. Essentially, the DNN is trained to manage within a static resource budget, ignoring the “dynamism” of the resources .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Consequently,  Xanadu , when subject to moderate/heavy load, over-provisions containers by 32% compared to the Probability-based policy (from Figure 2) as a result of being locked into provisioning containers for the MLP until it is able to recalculate it. Our probability-based policy, on the other hand, provisions containers for func- tions along  every possible path in proportion to their assigned weights . Note that variability in application usage patterns can lead to changes in function probabilities within each DDA, which the policy will have to account for.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "The edge node is implemented on Raspberry Pi development boards and the cloud is emulated via a desktop class Intel corei9 10900k CPU (with 64GB DDR4 RAM). Figure 3 shows the accuracy and latency of different policies with different numbers of machines. Key Observations: 1) If data is shared with (a third party) cloud, the accuracy of the model generated using all data from different machines is significantly higher than the models generated for the edge using their own data.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "The importance of each weight at index  i , denoted as  I W i , can be approximated by: I W i  =  |L ( D )  −L W i =0 ( D ) | , where  L W i =0 ( D )  is the loss, by setting parameter  W i  to zero. Our solution will leverage our previous work on LLM structured pruning [140], unstructured pruning [181], and parameter- efficient fine-tuning [32,33]. We will explore several directions for estimating  I W i  efficiently such as using a memory-efficient zeroth-order optimizer to estimate gradients using only forward passes [101].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "To this end, we explore two different kinds of coreset construction techniques. 3.1 Coreset Construction Techniques \nCoreset Construction Using Importance Sampling:  An easy way to build a representation from a data distribution is to perform importance sampling [ 7 ,  8 ], i.e. give more importance in choosing the data which are unique and, in our case, contribute significant to the inference (i.e.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "The paper makes the following key contributions: 1) We design a scheduling policy that chooses the salient sensor for performing the inference depending on the an- ticipated activity, i.e. the scheduler is  activity aware . 2) We leverage temporal continuity of human activity, and persist the last successful classiﬁcation result of a sensor.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "The proposed scalable cross-layer framework will enable the exploration of novel architectural and system-level solutions in addressing the LLM design challenges. It will lead to a more systematic, scalable, robust, cus- tomized and cost-effective LLM models for various application domains. In this context, our project takes an ambitious step to  democratize  LLM models by exploring the design space of morphable EoEs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Even if we were able to design a proper scheduling policy, for a conventional ensemble, all the sensors involved need to ﬁnish their computation. However, our preliminary results using the hardware setup of [6] and the DNN from [11] on the MHEALTH [12], [13] dataset suggests that only 10% of inferences could be completed in a WiFi powered system (Fig.1a). Therefore, we cannot always expect inference outcomes from all the sensors while doing HAR on EH-WSN.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "3) How to Further Improve the Compression Efﬁciency for Attributes? Although the  48 ×  speedup brought by our proposal is promising in terms of performance gain, the observed 2 ×  compression inefﬁciency needs to be addressed. 6 , the storage size after our compression is larger than RAHT, since each segment requires one vector storage to store its median/base and (quantized) delta values.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "This is due to  Kraken ’s load/path probability miscalculations and the usage of  Commonality and  Connectivity  to cope with this. It is seen that  Kraken spawns 10% more containers for  Media Service  and 6% more for  Hotel Reservation  and  Social Network . This may be due to Media Service  having higher path unpredictability than  Hotel Reservation  (Table 2) as well as lower slack per function than Social Network  (Figure 7).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "However, unlike planar videos, the 360° VR video streaming demands signiﬁcantly more compute power from a battery-operated headset. Thus, prior research has proposed using accelerators for optimizing the computations. In contrast, this paper attempts to exploit available “re- dundancies” in computation by analyzing the VR projection computation pipeline.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "9c and Fig.9d, where the latency is further decreased by  36%  (V1P) and  35%  (V2P), while the energy saving is increased by  41%  and  40% , indicating that our PI technique is quite effective. The improvement brought by PI for YOLOv4-tiny model is more signiﬁcant as shown in Fig. 6) Tradeoffs between Accuracy and Energy Consumption: So far in our evaluation, we wanted to minimize the accuracy impact (see Table III).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Specifically, during training, we simulate energy variability by incorporating energy traces into the training loop. At each training iteration, the available energy  E b  is sampled from these traces. Based on  E b , we adjust the dropout rate  d i  for each layer  i  according to: \nd i  =  d max \n\u0012 1  − E b \nE max \n\u0013 , (1) \nwhere  d max  is the maximum allowable dropout rate, and  E max  is the maximum energy observed in the traces.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Algorithm 2  Reactive Scaling \n1:  for  Every Monitor_Interval= DR  do 2: Reactive_Resource_Manager ( ∀ 𝑓𝑢𝑛𝑐𝑡𝑖𝑜𝑛𝑠 ) 3:  procedure  Reactive_Resource_Manager( func ) 4: cl  ← 𝐶𝑢𝑟𝑟𝑒𝑛𝑡 _ 𝐿𝑜𝑎𝑑 ( 𝑓𝑢𝑛𝑐 ) 5: func.existing_con  ← 𝐶𝑢𝑟𝑟𝑒𝑛𝑡 _ 𝑅𝑒𝑝𝑙𝑖𝑐𝑎𝑠 ( 𝑓𝑢𝑛𝑐 ) 6: if l c 𝑙 f 𝑢𝑛𝑐.𝑏𝑎𝑡𝑐ℎ _ 𝑠𝑖𝑧𝑒 m ≤ func.existing_con  then  a \n7: reqd_con  ← l c 𝑙 f 𝑢𝑛𝑐.𝑏𝑎𝑡𝑐ℎ _ 𝑠𝑖𝑧𝑒 m \n8: else 9: #_delayed_requests  ← Delay_Estimator ( 𝑓𝑢𝑛𝑐 )  b 10: extra_con  ← l  #_delayed_requests \nf 𝑢𝑛𝑐.𝑏𝑎𝑡𝑐ℎ _ 𝑠𝑖𝑧𝑒 m \nc 11: reqd_con  ← func.existing_con + extra_con 12: Scale_Containers ( 𝑓𝑢𝑛𝑐,𝑟𝑒𝑞𝑑 _ 𝑐𝑜𝑛 ) \nOpenFaaS  is deployed on top of  Kubernetes  [ 9 ], which acts as the chief container orchestrator. OpenFaaS , by default, comes packaged with an Alert Manager module which is re- sponsible for alerting the underlying orchestrator of request surges by using metrics scraped by  Prometheus , which is an open-source systems monitoring toolkit [ 12 ]. This, in turn, triggers autoscaling to provision extra containers to service the load surge.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 375,
    "augmented": false
  },
  {
    "text": "A. ResiRCA overview \nFigure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system. The baseline, battery-powered MCU system samples data at a ﬁxed rate, supported by the provisioned battery, and transmits either sensor data or the results of RCA processing \nDAC DAC DAC DAC DAC DAC \nMCU \nMemory I/O Ports \nInterconnected Bus \nClock \nPower \nIntelligent Embedded System \n... \n... \nADC&S+A \nDAC \nInput Reg. Output Reg.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "First, feasible implementations of ﬂexible activation options require a low power and reconﬁgurable RCA. Second, a dynamic loop tiling strategy alongside a coordinated parallelism scheme should be devised to match execution power consumption as closely as possible to power income to maximize efﬁciency. This section addresses the ﬁrst of these challenges, and Section V discusses our approach to the second.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Accessed: 2024-04-27. Minillm: Knowledge distillation of large language models. [55] Yuxian Gu, Li Dong, Furu Wei, and Minlie Huang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, Vijaykrishnan Narayanan, and Chita R Das. 1414–1419. IEEE, 2021.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "For a given baseline model, we combine all models whose latency is lower than that of the baseline, and call it full- ensemble. We perform ensembling on the predictions using a simple majority voting policy. The latency numbers for the baseline models and the corresponding ensemble models along with the size of the ensemble are shown in Table  3 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Moreover, applications like Record3D [ 44 ] enable seamless PC media streaming from phone to a wearable, encouraging a perpetually increasing PC content generation and consumption. However, the sheer volume of the data captured in these PC applications coupled with the limited compute and storage capabilities of these handheld devices pose a challenge in high quality PC media capture, storage and consumption [ 26 ]. To understand these challenges, we analyze an end-to-end PC pipeline.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "[7] 2020. hey HTTP Load Testing Tool. https://github.com/rakyll/hey. [8]  2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Ω SNR ( θ )  encourages the model to perform reasonably well across varying SNR levels, while  Ω complexity ( θ )  penalizes overly complex models that might demand excessive energy or communication costs. The expected loss is L ( θ ) =  E ( x,y ) ∼D [ ℓ ( f θ ( x ) , y )] . To enhance robustness and efficiency, we introduce two regularizers: \nΩ SNR ( θ ) and Ω complexity ( θ ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "C ONCLUSION \nMAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs. This paper proposes ResiRCA, a resilient energy harvesting accelerator. Considering the application sce- narios where the accelerator is supported by harvested energy, we ﬁnd that the previous designs cannot well accommodate the RCA to the changing power sources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "0 \n1 \n2 \n3 \n4 \n5 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nNorm. Since majority of the storage systems are not limited to one storage server, but are spread across multiple servers, we scaled  Salient Store  by deploying it in a distributed fashion. Encryption Latency \nRSA Software RSA FPGA Lattice Software \nFigure 7: Proposed encryption vs the state-of-the-art normalized to the FPGA implementation of the lattice based encryption.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "2019. Nvgaze: An Anatomically-informed Dataset for Low-latency, Near-eye Gaze Estimation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Thus, it can be concluded that, without any optimization, a state- of-the-art edge GPU is only able to compute for  <  4 depth planes in real-time [ 36 ]. 2.1, the 16 depth planes required by most of the AR applications (typically 10 to 100 depth planes are sufficient) [ 19 ,  49 ] consume more than 300 ms , which is 10 ×  larger than the real-time (QoS) requirement. As also mentioned in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "With increasing the number of CSDs per SSD (or other storage element) does show significant improvement because of increase in parallelism. However, a typical CSD is  ≈ 15 ×  expensive than a standard SSD and  ≈ 25 ×  expensive than a classical HDD. Integrating more number of CSDs into the standard storage server will significantly increase the cost of the server.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "•  Fig. 3  c  illustrates an example with 20 segments in I-Frame and P-Frame. Due to the limited number of segments, one can observe that some highlighted blocks are not well matched.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Furthermore, these accelerators have been designed to operate under constantly available power. Although our pro- posed representation learning (§ III ) and micro-proﬁler (§ III-C ) help us ﬁnd a better training conﬁguration that can minimize the compute if deployed in the aforementioned accelerators, it does not solve sustainability: That is, with variable solar power, can we scale compute alongside power to continue to make “forward progress”, even when minimum amount of power is available. The systolic array structure of the DNN accelerators is well suited for this as we can change the com- pute size, as well as the number of memory channels feeding to those compute units as per the power availability.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "We illustrate the generic pipelines (for  1  geometry compression, and for 2  attribute compression) employed by the state-of- the-art intra-frame compression techniques in Fig. 4  a  and 4  b  . Speciﬁcally, the SOTA geometry compression pipeline includes ﬁve stages which can be summarized as follows: •  Raw Frame (Input):  The input raw PC frame contains several (usually millions of) points, carrying both geometry and attribute information.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "[2]  Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang. In  Proceedings of the 7th ACM international conference on Web search and data mining , pages 173–182, 2014. Laser: A scalable response prediction platform for online advertising.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Corne Lukken and Animesh Trivedi. Past, present and future of computational storage: A survey. arXiv preprint arXiv:2112.09691 , 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "With these inputs,  ❷ Perception  stage understands the current surrounding environment such as pose estimation for head rotations/directions, eye tracking for pupil centers, and scene reconstruction for the current view analysis. Finally,  ❸ Visual  stage combines the physical world with the virtual information (which is generated in real-time) together, and renders the final images (both the physical scene as well as the virtual frame augmented with it) for the user to view. We want to emphasize that, compared to virtual reality (VR), the AR video processing typically incurs additional computational \nTable 1: Ideal latency requirements [19].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "The missing piece in complex analytics: Low latency, scalable model man- agement and serving with velox. [26]  Daniel Crankshaw, Gur-Eyal Sela, Corey Zumar, Xiangxi Mo, Joseph E. Gonzalez, Ion Stoica, and Alexey Tumanov. arXiv preprint arXiv:1409.3809 , 2014.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "In fact, only one input argument, i.e., the number of depth planes, requires to be changed based on the approximation factor  α , when the object is outside of RoF. Here, we set  α  to 0 . 5, as our detailed profiling (discussed later in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "[8]  Amazon. EC2 C5 Instances., February 2018. https://aws.amazon.com/ec2/instance-types/c5/ . Azure Low priority batch VMs., February 2018. https://docs.microsoft.com/en-us/azure/batch/batch-low-pri-vms .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "b \n0% 25% 50% 75% 100% \n0 50 100 150 200 Delta(red) \n#blocks=20,best #blocks=20,worst #blocks=1000,best #blocks=1000,worst \n0% 25% 50% 75% 100% \n0 100 200 Range(Delta) \n#blocks=10 #blocks=100 #blocks=10000 #blocks=100000 \na \nc \nFigure 3: a) Spatial locality within one frame. b) Temporal locality among two frames. c) An example of macro blocks segmented using Morton codes in two frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 7th ACM international conference on Web search and data mining , pages 173–182, 2014. [3]  Ahmed Ali-Eldin, Jonathan Westin, Bin Wang, Prateek Sharma, and Prashant Shenoy. Spotweb: Running latency-sensitive distributed web services on transient cloud servers.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "As the above tasks develop optimal algorithms for dynamic morphable LLMs, they introduce many types of “affinities” (listed in Table 2) to facilitate our system and architectural level opti- mizations, which are investigated in Thrusts 2 and 3, respectively. Notably, the reverse is also true, and thus, this task will investigate the influence of resource constraints and execution environments on our algorith- mic choices. We will conduct the following research to incorporate the availability of expert accelerators, memory constraints, and workload balance to inform our algorithmic choices: Selecting Experts based on Available Expert Accelerators.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "0 25 50 75 Time interval (10s) \n79 \n80 \n81 \n82 \nAccuracy \nBL1 BL2 \nBL3 const1 \nconst2 const3 \n(b)  Failure Analysis. 0 1000 2000 3000 Time interval (10s) \n0 \n50 \n100 \n#VMs \nBline model1 model2 model3 \n(a)  Cumulative #VMs. Figure 12:  Sensitivity analysis of VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "It can be seen that smaller models  (MNet, NASMob ) can be packed 2-5 ×  more when compared to larger models  (IRV2, NASLarge) . Thus, the ensembles with models of higher  P f have signiﬁcantly lower cost. The beneﬁts of  P f  is contingent upon the models chosen by the model selection policy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "8: Performance and energy improvements for YOLOv3 w.r.t. the baseline;  XX:our  are the results achieved by our proposed FI+PI+SI scheme;  XX:dc  are the results for DeepCache [8];  V1P  and  V2P  are part of V1 and V2, respectively; and  AVG  is the weighted average (weight is the # of frames in each video). 0% \n20% \n40% \n60% \n80% \n(a) FI+SI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead \n(b) FI+SI exec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "[55]  Rohan Paul, Dan Feldman, Daniela Rus, and Paul Newman. 2014. Visual precis generation using coresets.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "V). 3  ×  S sbb ). Such large MV indicates that an object (of similar size to that of the other objects which have been already identiﬁed), which was supposed to be captured, but failed due to the inaccuracy of DNN models (such as YOLOv4-tiny [37] used by the detection application as discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "EC2 C5 Instances., February 2018. https://aws.amazon.com/ec2/instance-types/c5/ . [9]  Amazon. Google Preemptible VMs., February 2018. https://cloud.google.com/preemptible-vms .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Motion Estimation: Utilize dedicated hardware blocks for calculating motion vectors between consecutive frames. This step can leverage FPGA’s DSP slices for fast cross-correlation or block matching algorithms. 2.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n81.0 \n81.2 \n81.4 \nAccuracy \n(b)  Queries under Constraint-2. 10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n79.0 \n79.2 \n79.4 \nAccuracy \n(c)  Queries under Constraint-3. USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1051 \n10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n82.25 \n82.50 \n82.75 \nAccuracy \n(a)  Queries under Constraint-1.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "In  Social Informatics: 9th International Conference, SocInfo 2017, Oxford, UK, Septem- ber 13-15, 2017, Proceedings, Part II 9 , pages 378–390. A hierarchical topic modelling approach for tweet clustering. [160] Bo Wang, Maria Liakata, Arkaitz Zubiaga, and Rob Procter.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "The 8 × 8 systolic array in each tile executes multiply-accumulate operations in a pipelined and parallel fashion, abiding by the Weight Stationary approach, thereby optimizing the throughput and efﬁciency of the train- ing operations within this hardware architecture. Power Control Logic:  Power emergency prediction in  Us. ´as is always conservative, and the solar power predictor has a mean accuracy of 92%, limiting false positives and helping the control unit select appropriate tile counts.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "However, the  Paragon  scheme is 10% more cost-effective than mixed and at the same time ensures similar SLOs. Therefore, this results in reduced cost and at the same time does not violate SLOs. This is because the  Paragon  scheme is aware of the latency requirements of individual queries and does not blindly offload queries to lambdas when there is increase in load.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Vector databases typically extract features from the video data to form index and those indices are then sorted using various metrics like neighborhood, maximum similarity, etc. (Fonseca & Jorge, 2003; Cao et al., 2013; Tian et al., 2023; Douze et al., 2024) for faster retrieval. The vector index are used to point to the meta-data of the video file and then the actual video data is retrieved from the storage (Shen et al., 2005).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "It also leverages the continu- ous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve ﬁnal classiﬁcation accuracy. Further,  Origin  proposes an adaptive ensemble learner to personalize the optimizations based on each individual user. Experimental results using two different HAR data-sets show Origin , while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classiﬁer continuously operating at the same average power.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "ACM, 2019. [8] K. Maeng and B. Lucia, “Adaptive dynamic checkpointing for safe efﬁcient intermittent computing,” in  OSDI . USENIX Association, 2018.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "; ii)  How can we dynamically shape the morphology of EoE systems by identifying the best design points in the search space? ; iii)  How can we continually adapt experts through expert merging, splitting, growing, and shrinking? ; and iv)  How do compute and memory resource constraints and runtime environments influence our algorithmic decisions?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "2 Background and Motivation \nWe start by providing a brief overview of model-serving in public cloud and ensembling, followed by a detailed analysis of their performance to motivate the need for  Cocktail . 2.1 Model Serving in Public Cloud \nFigure  2  shows the overall architecture of a model-serving framework. There are diverse applications that are typically developed, trained and hosted as web services.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type. In CNNs, for instance, MACs between the feature map data and kernel weights comprise nearly 90% of the total operations [ 2 ], [ 3 ]. Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efﬁciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "Complexity Analysis of DynInfer:  The time complexity of the scheduling algorithm is  O ( N  log  N ) due to sorting tasks, and the space complexity is  O ( N )  for storing task parameters. Complexity Analysis : The heuristic has a time complexity of O ( N  log  N )  due to sorting tasks based on  P   eff i   , which is acceptable for real-time applications. Compared to classical inference, DynInfer introduces additional overhead for scheduling and task fusion, but this is offset by the gains in reliability and efficiency under intermittent power.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "The absence of comprehensive library functions along with the need for computational efficiency frequently necessitates the development of in-line assembly code for certain computational kernels. 5 Conclusions \nThis study presents NExUME, an advanced framework designed to optimize the training and inference phases of deep neural networks within the constraints of intermittently powered, energy-harvesting devices. By integrating adaptive neural architecture and energy-aware training techniques, NExUME significantly enhances the viability of deploying machine learning models in environments with limited and unreliable energy sources.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Media Service  suffers from higher end-to-end response times, further exacerbating this effect. This ef- fect is highlighted in applications such as  Social Network  and Media Service  which have relatively high MLP misprediction rates (80% and 50%, respectively 2 )) due to the presence of multiple possible paths (Table 2). Xanadu  has only a 34% misprediction rate for  Hotel Reservation , due to the lower number of workflows, and is seen to match  Kraken  in terms of SLOs satisfied (99.87%).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "For energy measurements, we use an open-source version of Intel Power Gadget [ 16 ] that measures the energy consumed by all sockets in a node. Load Generator:  We provide different traces as inputs to a load generator, which is based on Hey, an HTTP Load generator tool [ 7 ]. First, we use a synthetic Poisson-based request arrival rate with an average rate  𝜇 =  100.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "0 \n2 \n4 \n6 \n8 \n60 \n70 \n80 \n90 \n60 70 100 120 150 350 \nAverage #Models \nAccuracy (%) \nLatency (ms) \naccuracy Average #Model \n(b)  Fixed Latency. Figure 14:  Sensitivity Constraints under ﬁxed latency and accuracy. Bar graphs (latency) plotted using primary y-axis and line graph (#models) plotted using secondary y-axis.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "This problem has not been explored in details, as coresets are typically considered as an  𝛼 − approximate representation of the data ( 𝛼 being the error/approximation parameter) [ 7 ] and never needed proper recovery. However, thanks to the low dimensional nature of many sensor data, reconstruction of original data from coresets becomes an essential step. 3.2.1 Data Memoization:  Given our focus on ultra low power energy harvesting devices, any opportunities to re- duce computation and communication can noticeably aug- ment the performance and efficiency of the entire system.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency. In  USENIX Middleware Conference . [31]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Mahmut Tay- lan Kandemir, Bhuvan Urgaonkar, George Kesidis, and Chita Das.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Motivated by these opportunities, we propose and evaluate a two-pronged compression approach, where the  intra-frame approach leverages the opportunities described in 1  and 2  , and the  inter-frame  approach takes advantage of 3  . The intra-frame approach speeds up the geometry and attribute compression by  37 ×  and  49 ×  respectively, while the inter- frame approach further improves the compression ratio by ≈ 1 . 75 ×  by reusing the matched blocks in reference frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "3) Point Cloud Compression (PCC):  The prior PCC works can be classiﬁed as follows: G-PCC  utilizes special structures like octree or kd-tree to represent and compress the geometry [ 17 ], [ 23 ], [ 74 ]. Therefore, there have been several works focusing on compressing the PC, as discussed next. For example, with octree-based PCC, considering a PC is con- tained in a  D × D × D  cube, the cube is recursively divided into 8  D / 2 × D / 2 × D / 2  sub-cubes until  D = 1 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "We collect the display traces from a 5-inch (130 mm) 16:9 1080p (1920 × 1080) AMOLED display [54], which is similar to the Samsung Gear VR display [45]. Fig. 8: Evaluation proto- type – Nvidia Jetson TX2 GPU board [36] (PMU: Power Management Unit).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "V, we perform a detailed comparison of our work against these prior works. I, DeepCache does not take advantage of frame-wise data reuse opportunities (e.g., reuse the inference result for similar frames). As mentioned in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Our proposal, Origin , holistically looks into multiple aspects of deploying a DNN on an EH-WSN for the purpose of HAR. However, the compute heavy DNNs make it challenging because of their \npower requirements, especially in EH-WSNs. V. C ONCLUSION \nEnabling DNN inference on edge devices has been gaining recent traction, especially for tasks like HAR.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "7: Update model parameters: \nθ k +1  =  θ k  − α k   b ∇ J ( θ k ) . 9:  end for \nRegularizers and SGD Convergence: The chosen reg- ularizers  Ω SNR ( θ )  and  Ω complexity ( θ )  are both convex and smooth, with known closed-form gradients. 8: Broadcast  θ k +1  to all sensors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Note that each func- tion triggers only one other function in the application at a time. Therefore, there is considerable variation in the functions that can be invoked in DDAs, thus, negating the inherent assumption in many frameworks [ 32 ,  42 ,  44 ,  50 ] that all functions will be invoked with the same frequency as the application. The decision to trigger the next function typically depends on the input to the current function, although there are cases like  Media Service  where this decision may de- pend on previous function inputs as well.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "[63]  Himanshu Sharma, Ahteshamul Haque, and Zainul Abdin Jaffery. Design of an RFID-based battery- free programmable sensing platform. IEEE transactions on instrumen- tation and measurement  57, 11 (2008), 2608–2615.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Gradually increase them if the model relies too heavily on high-SNR data or becomes too complex. Start with small values of  λ 1  and  λ 2  to avoid over- whelming the primary loss  L ( θ ) . 2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "As they are less prone to drift, they need occasional updates. For each sampled frame, the classiﬁcation results and the conﬁdence matrix (output of the last layer) are sent for annotation. If the student (or the edge model) is conﬁdent about the classiﬁcation (e.g.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Figure 1 illustrates QuantaTask execution with a simple example. A3 B3 \nB2 \nB1 \nX X X \nA2 \nA1 \nX \nFigure 1: An example of variable QuantaTask in a matrix multiplication scenario. Depending on the available energy, the task (vector inner product) can be divided into multiple iterations such that each QuantaTask is guaranteed to finish given the energy availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "I. This also determines the “order of computation”, which is ﬁrst  T  , then  P , and ﬁnally  F . We have two important takeaways: •  Computation Dependence Chain: We note that there exists a data dependence from the  360 ° frame to generate the ﬁnal FoV frame, where  F  depends on  P , which in turn depends on  T  .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Finally, we provide a sensitivity analysis to understand the effect of different hyper-parameters on the accuracy and latency. (3) Evaluation of these policies on a publicly-available data set and also on data from real industrial grinding machines. We show that our privacy preserving partitioning approach outperforms edge- local prediction accuracy and achieves much of the accuracy in a data-sharing model.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "The EoE graph pruning process, involving removing and merging experts, can sometimes result in imbalanced branches, where one branch contains significantly more experts than another. This imbalance can lead to inefficiency in workload distribution among different parts of computing resources. To solve this issue, we propose to re-construct the expert graph automatically to balance the workload.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Sensors employ this best-response mechanism, continuously updating their participation decisions based on the evolving network state and the actions of other sensors. 6:  After all sensors decide, the action profile  a ( t )  is real- ized, and energies are updated: \nB i ( t  + 1) =  B i ( t ) +  E i ( t )  − e i ( t ) . 7:  Sensors iterate this process at each inference event, re- fining their estimates and converging to stable action patterns.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. baseline InterHolo IntraHolo InterIntraHolo \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "While some of these applications rely on collecting the video data and processing them offline, many need real-time analytics for the seamless integration, operation and effectiveness of the task at hand (Bramberger et al., 2004; Apostolo et al., 2022; Grulich & Nawab, 2018). Moreover, depending on the deployment, scenario and requirements, some of these applications also demand learning to keep up with the data drift (Bhardwaj et al., 2022; Mishra et al., 2024; Kim et al., 2024; Rebuffi et al., 2017). However, regulations, resource limitations and privacy concerns often mandate these applications (both learning and inference) to be performed at the edge (Bhardwaj et al., 2022; Mishra et al., 2024).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 199,
    "augmented": false
  },
  {
    "text": "2. Prediction and Residual Calculation:  Implement pipelined architectures for the  predict ( · )  function and subsequent residual calculation to minimize latency. 3.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2002.08155 , 2020. [33]  Mikel Galar, Alberto Fernandez, Edurne Barrenechea, Humberto Bustince, and Francisco Herrera. A review on ensembles for the class imbalance problem: Bagging-, boosting-, and hybrid-based ap- proaches.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "It is obvious that the raw data sensed by each sensor would be different, even for the same activity, because of the difference in move- ment and dynamics. III. Origin : A N INTELLIGENT SCHEDULER MEETS A LIGHT WEIGHT AND ADAPTIVE ENSEMBLE LEARNER \nWe design a EH-WSN setup for HAR, where the user has three EH inertial measurement units (IMUs), at the \nchest, left ankle and right wrist 1 .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "The same function belonging to multiple applications can, therefore, have distinct weights in each application. To analyze the benefits of using invocation frequency, we designed a probability-based policy that employs weighted container scaling. The relative invocation frequency of a function is measured with respect to the application it consti- tutes.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "2446–2454, 2020. In  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. Yao Tian, Xi Zhao, and Xiaofang Zhou.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "[28] Y. Leng, C.-C. Chen, Q. Sun, J. Huang, and Y. Zhu, “Energy-efﬁcient Video Processing for Virtual Reality,” in  Proceedings of the International Symposium on Computer Architecture (ISCA) , 2019, pp. 91–103.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "In this section, we model the function probability estimation problem using a Variable Order Markov Model (VOMM) [ 21 ]. VOMMs are effective in capturing the invo- cation patterns of functions within each application while simultaneously isolating the effects of other applications that share them. This aids us in the calculation of function invocation probabilities.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "5.3 Evaluation of Lattice Based Encryption \nOne of the major contribution of  Salient Store  is accelerating the lattice-based encryption with the help of FPGAs on the storage nodes. Fig. 7 shows the comparison of our FPGA-accelerated lattice-based encryption against other state-of-the-art-techniques.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Targeting them, prior efforts have proposed to optimize their compression ratio, processing performance, and energy efficiency [ 8 – 10 ,  16 ,  27 ,  67 – 70 ]. These display quality optimizations are orthogonal to our approximation-based proposal, and our approach can be used along with such optimizations. Volumetric Video Streaming, Compression, and Other Opti- mizations:  Volumetric sensor inputs such as LiDAR have large vol- ume and require significant computational power and bandwidth to process/transmit.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Moreover, these devices can also be used for performing convolution operations, which are widely used in image and signal processing applications. E.1.1 Simple Single Cell Example: \nconsider a simple example of a ReRAM crossbar array with two cells, where V1 and V2 are the input voltages, G1 and G2 are the conductance values of the ReRAM devices, and I1 and I2 are the resulting output currents. To perform multiplication-addition, we first apply the input voltages V1 and V2 to the rows of the crossbar array.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "Data Annotation \nPicking the Important Ones:  Typically, edge models are ca- pable of inferring at the frame rate of the camera (at times, 30fps to 60fps) [ 19 ]. However, the teacher model used to label the incoming data cannot match this in a resource- constrained environment where performing training is going to be even more resource consuming. Therefore, we employ an intelligent “data sampling mechanism” to select the frames that might contain new information and a potential candidate for learning.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "Our method differs from standard approaches by integrating energy constraints directly into the optimization, ensuring that the network learns to adapt its parameters based on energy availability. 4 \n3.1.1 Adaptive Regularization Strategy \nDynFit introduces an adaptive regularization strategy to address potential overfitting and under- training due to uneven weight updates caused by dynamic dropout and quantization. We monitor the update frequency  F p  of each weight  w p  over a window of  T  iterations: \nF p  =  1 \nT \nT X \nt =1 U p ( t ) , U p ( t ) = \u001a 1 , if  w p  is updated at iteration  t 0 , otherwise (4) \nWeights with  F p  < θ low  are considered under-trained, and those with  F p  > θ high  are considered overfitting.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 194,
    "augmented": false
  },
  {
    "text": "Hourly thermal load prediction for the next 24 hours by arima, ewma, lr and \n1054    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nan artiﬁcial neural network. Technical report, American Society of Heating, Refrigerating and Air-Conditioning Engineers ... , 1995. [48]  Abeer Abdel Khaleq and Ilkyeun Ra.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "2020. { FIRM } : An Intelligent Fine-grained Resource Management Framework for SLO-Oriented Microservices. In  14th  { USENIX }  Symposium on Operating Systems Design and Imple- mentation ( { OSDI }  20) .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": ";  ii)  What types of chiplet-based architectures are suitable for EoE-based LLMs, and what is the search space for chiplets? The specific questions we would like to address in this thrust compris- ing of 4 tasks include: i)  Which parts of the EoE network are most preferable for custom hardware acceleration from the performance, power, and accuracy standpoints? Chiplet-based designs have shown great promise for integrating a variety of modular chips, both homogeneous and heterogeneous, on a silicon interposer [72,152] and is a great fit for our envisioned modular and fault-tolerant design.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "Takeaway : The Morton codes generated as an intermediate result during geometry compression not only improve the geometry compression by increasing pipeline parallelism, but also help to capture/identify the attribute similarities within a frame as well as across frames. This again conﬁrms that a ﬁner segment can yield a better temporal locality, as also discussed above. Due to the limited number of segments, one can observe that some highlighted blocks are not well matched.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "8% ), resulting in a similar reduction in the overall execution time. the baseline) is smaller than that in YOLOv4-tiny ( 4 . Note that, the reason why the overhead in YOLOv4-tiny is higher is because, YOLOv4-tiny is already a very light-weight model, and consequently, the time spent on decision making is not negligible compared to the extremely fast inference it performs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Secondly, we introduce a novel dataset aimed at advancing research in predictive maintenance and Industry 4.0 (Lasi et al., 2014), and test NExUME on a real manufacturing testbed (§4.3) with COTS hardware. These datasets represent typical use cases in embedded systems where energy efficiency and minimal computational overhead are crucial. We use both commercial-off-the-shelf (COTS) hardware and state-of-the-art ReRAM Xbar- based hardware for this evaluation.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Given a memory budget that limits the number of experts the system can host, the EoE network must  adapt  its structure to meet user needs. This can be achieved by deleting its vector in the gating function  g ; (2) Combine, combining several experts in one EoE layer. To this end, we can  prune  the network to a smaller number of experts by using three operations: (1) Remove, eliminating an expert from the graph.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "4.1 Development and Profiling of NExUME \nNExUME uses a combination of programming languages and technologies to optimize its functional- ity in intermittent and low-power computing environments. We have developed a first-of-its-kind machine status monitoring dataset, available at  https://hackmd.io/@Galben/rk7YN6jmR , which involves mounting multiple types of sensors at various locations on a Bridgeport machine to monitor its activity status. Secondly, we introduce a novel dataset aimed at advancing research in predictive maintenance and Industry 4.0 (Lasi et al., 2014), and test NExUME on a real manufacturing testbed (§4.3) with COTS hardware.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "[49] Mohammad Gokaslan, Girish Mishra, and Andrea Madotto. Openwebtext corpus: Extracting web- content using reddit links. arXiv preprint arXiv:2001.08023 , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Otherwise, continue refine- ment. 18:  end for \nRestatement of the Utility Function and Assumptions \nRecall that at each inference event  t , each sensor  s i  chooses an action  a i ( t )  ∈{ P ,  NP } . The chosen action profile is a ( t ) = ( a 1 ( t ) , .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "It keeps track of the number of requests served per model in the past 5 minutes. Load Balancer : The master VMs runs a separate thread to monitor the importance sampling of all individual model pools. This information is used for cal- culating the weights per model for autoscaling decisions.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "SProb  does worse than  DProb  at the tail because of its lack of adaptive probability estimation. Kraken  makes use of 21% more containers to achieve the improved latencies. Xanadu  experiences a sudden rise in tail latency, with it being 100ms more than that of  Kraken , while using 96% more containers.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "OpenHolo Database. \"http://openholo.org/database/depth\". 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "Segmentation:  The next step is to partition the sorted PCs (i.e., I-frame and P-frame) into several blocks/segments (similar to the term “macro-blocks” in 2D image encoding). Block/segment match (BM):  for each block in the P-frame, we iterate through all the candidate blocks in the I-frame and calculate the difference between these  <  I , P  >  block pairs. Finally, the candidate I-block which differs minimally with the P-block is picked as its “best-matched/reference” block.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "[11] Google, “Build Virtual Worlds.” ”https://developers.google.com/vr”, 2019. [12] Google, “GVR Android SDK Samples - Video360.” ”https://github.com/ googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/ java/com/google/vr/sdk/samples/video360/VrVideoActivity.java#L257”, 2019. [13] M. Ham, I. Dae, and C. Choi, “LPD: Low Power Display Mechanism for Mobile and Wearable Devices,” in  Proceedings of the USENIX Conference on Usenix Annual Technical Conference (ATC) , 2015, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 194,
    "augmented": false
  },
  {
    "text": "However, in some pathological cases, the error at times goes close to 60%, and we believe them to be generated artifacts which are common side effects of the GANs[ 11 ]. Our experi- ments suggests that inference on the GAN recovered signal is almost as good as (about 2%  − 4% difference in accuracy) the inference on the recovered cluster signal. The recovery policy can be implemented as a simple generator network in the host.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "In  2005 IEEE interna- tional conference on systems, man and cybernetics , volume 3, pages 2340–2345. Online bagging and boosting. [61]  Nikunj C Oza.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Our evaluation of Us. ´as on a real-world trafﬁc dataset indicates that our continuous learning approach simultaneously improves both accuracy and efﬁciency: Us. ´as offers a 4.96% greater mean accuracy than prior approaches while our morphable accelerator that adapts to solar variance can save up to  { 234.95kWH, 2.63MWH } /year/edge-server compared to a  { DNN accelerator, data center scale GPU } , respectively.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "2 \n110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 \n2.3. Game-Theoretic Models in Sensor Networks \nGame theory provides a powerful framework for modeling and analyzing strategic interactions in distributed systems, including sensor networks ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "These shortcomings collectively motivate the central premise of this work:  how to solve the complex optimiza- tion problem of cost, accuracy and latency for an ensem- bling framework? In this paper, we present and evaluate Cocktail 2 , which to our knowledge is the ﬁrst work that pro- poses a cost-effective model-serving system by exploiting ensembling techniques for classiﬁcation-based inference, to deliver high accuracy and low latency predictions. Cocktail adopts a three-pronged approach to solve the optimization problem.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "It can so happen that dropping models can lead to drop in accuracy for certain intervals, because the class of images being predicted are different. In such cases, we up-size the models (one at a time) by adding most accurate model from the remaining unused models. Algorithm 1  Model Selection and Weighted Majority Voting \n1:  procedure  F ULL _E NSEMBLE (M ODEL L IST , SLO) 2: for  model  ∈ ModelList  do 3: if  model.latency  ≤ SLO.latency  then 4: Model.add(model) 5: end if 6: end for O 1 7:  end procedure 8:  procedure  D YNAMIC _M ODEL _S CALING ( Models ) 9: if  curr_accuracy  ≥ accuracy_threshold  then \n10: if  max vote  >   N \n2   + 1  then  O 2 \n11: to _ be _ dropped  ← max vote  − N \n2   + 1 12: Models .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 230,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2024 Conference on Human Information Interaction and Retrieval , pages 391–395, 2024. [122] Journal of the American Medical Informatics Association. Efficient healthcare with large language models: optimizing clinical workflow and enhancing patient care.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "A 128kB SRAM serves as a scratchpad for storing activations, transposes, and intermediate differentials during the backward pass. For smaller DNNs without 256 kernels in any layer, a batching mode is operational with a batch size of  B  =  ⌊ A / L ⌋ images, where  L  denotes the layer with the fewest channels, and  A  the number of active tiles. The accelerator also houses 256  ×  256 compactor-mux combinational logic units (256 units per tile) for ReLU activation (forward pass) and inverse activation (backward pass).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "2935– 2947, 2017. [51] M Sandler, A Howard, Menglong Zhu, Andrey Zhmoginov, Liang- \nChieh Chen , “Mobilenetv2: Inverted residuals and linear bottlenecks,” in  CVPR , 2018. 12, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Additionally, a Load Pre- dictor module  2b  makes use of the system metrics to predict \n1 Kraken is a legendary sea monster with tentacles akin to multiple paths/chains in a Serverless DAG. Commonality  and  Connectivity  (parameters in  2a  ) are additional parameters used in weight estimation to account for critical and common functions. Containers \nRequest  \nQueue \nFunction 1 \nFunction 2 \nFunction n \n.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Each sensor has a data buffer that collects the data points for classification (implemented using a 60  × 3 FIFO structure of 4Byte cells to store the floating point data. The × 3 caters towards the multiple channels of the sensor. The moving window is designed using a counter to shift the streaming data.)",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "•  Finally, we evaluate Us.´as in depth on a  real-world trafﬁc \ndata set  [ 97 ] and perform sensitivity studies on other classes (audio, IMU) of data. Our algorithmic framework for performing continuous learning has a 4.96% greater mean accuracy than a na¨ıve continuous learner. Power estimations of our hardware design, modeled by Design Compiler [ 93 ], indicate that the proposed morphable accelerator approach can save up to 234.95kWH/year/edge-server, compared to running continuous learning on a state of the art DNN accelerator and 2.63MWH/year/edge-server, compared to utilizing a datacenter-scale GPU for learning on the edge.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 166,
    "augmented": false
  },
  {
    "text": "Accessed: 05/19/2024. Texas Instruments. https://www.ti.com/ product/MSP430FR5994 , 2024a.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Further, this can help build future solutions using these decentralised nodes for other applications. We do encourage the use of green data centers for other centralized compute applications. VII.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "DNN inference for YOLOv3). To implement these three possible decisions (FI, SI, and PI) that can be made by the  Decision Maker , the  Inference Engine  in Fig. 5%  w.r.t.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "These clusters represent the classes in the high dimensional feature space. There are three cases: Case-1:  If the data is close to one of the cluster centers and belongs to its cluster boundary, then it falls into the bucket of that particular class. When the classiﬁer sees new data ( x ), it calculates its distance from all the cluster centers as y ∗ =  min y = 1 ... t  || Φ ( x ) − μ y || .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "[38]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Cyan Subhra Mishra, Mahmut Taylan Kandemir, and Chita R. Das. Towards designing a self-managed machine learning inference serving system inpublic cloud, 2020. In  IEEE CLOUD , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "VI-B . •  Our Intra-Inter-V2 (Compression efﬁciency-oriented):  Sim- ilarly, this design further reduces the compressed data size by 2 % , by adjusting the threshold for “direct-reuse decision making”, as discussed in Sec. At the same time, the quality further drops by  2 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "The ﬂexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization. Extending this single-ReRAM toy architecture to a practical multi-ReRAM architecture to process multi-layer convolutions for real-world CNNs introduces a new source of power variation in terms of the different time and power costs of different convolution layers. In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efﬁciency.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "Us. ´as  emerges as a promising solution, effectively achieving sustainable and carbon-neutral continuous learning at the edge, addressing critical challenges related to power constraints and environmental impact. Alternate Solutions:  Although  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "The expected loss is L ( θ ) =  E ( x,y ) ∼D [ ℓ ( f θ ( x ) , y )] . To enhance robustness and efficiency, we introduce two regularizers: \nΩ SNR ( θ ) and Ω complexity ( θ ) . Ω SNR ( θ )  encourages the model to perform reasonably well across varying SNR levels, while  Ω complexity ( θ )  penalizes overly complex models that might demand excessive energy or communication costs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "With the RoF attained from the eye tracking, the next question we need to answer is how to deploy the approximation opportuni- ties discussed above in Sec. 2.2.3 on top of the existing hologram pipeline. As shown by  Line#5  and  Line#7  in Algo.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "This is because low precision leads to a mis-projection, which fails to reﬂect the current head orientation. In this work, we do not want to distort video quality and thus explore the ground-truth only. The Effect of EA:  With this  EA  memoization, once a new head orientation is received, we ﬁrst search it in the two head orientation registers.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Decomposable loops: Each ‘QuantaTask‘ runs a certain part of the loop. Define ‘QuantaTask‘ as the minimum iterations that can run. 2.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "For example, let us consider two DNN classiﬁers ( C 1  and C 2 ) classifying between 4 different classes  ( o 1 , o 2 , o 3 , o 4 ) . Although accuracy is a close measurement of the conﬁdence of the classiﬁcation, it does not truly reﬂect it. The ﬁnal probability vector from the last layer (soft- max function)  V C 1 = [0 .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Note that, as discussed above, 2 . 7%  exclusive  pixel coordinates for the right-eye cannot be reconstructed by this algorithm. Therefore, only for this small number of pixel coordinates, the entire coordinate projection computations need to be processed.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "(c) illustrates the trade-off between the precision level and reuse ratio. -5 5 15 25 \n1 225 449 673 897 1121 1345 1569 1793 2017 2241 \nDistance \nPixel ID \ndistanceY distanceX \n-10 \n-5 \n0 \n5 \n10 \n0 10 20 \nDistance-x \nDistance-y \n(b) (0.00, 1.57, -0.73) \n-20 0 20 40 60 \n1 202 403 604 805 1006 1207 1408 1609 1810 2011 2212 \nDistance \nPixel ID \ndistanceY distanceX \n-10 -5 0 5 10 \n0 20 40 60 \nDistance-x \nDistance-y \n(c) (0.52, 1.05, -0.73) \nFig. (a) Distance vector.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "ACM, 2019. [7] G. Gobieski, B. Lucia, and N. Beckmann, “Intelligence beyond the edge: Inference on intermittent embedded systems,” in  ASPLOS . 315–327.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Achieving Compliant Data Res- idency and Security with Azure. https://azure.microsoft.com/mediahandler/files/ resourcefiles/achieving-compliant-data-residency-and-security-with-azure/ Achieving_Compliant_Data_Residency_and_Security_with_Azure.pdf . Miklós Ajtai.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Perform the forward pass with the updated dropout mask to obtain the output  Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the Shapley values of the neurons, along with the QuantaTask optimization to handle energy constraints. Otherwise, maintain or reduce the dropout rate to improve accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "USENIX Association, 2018. [53] B. Makuza, Q. Tian, X. Guo, K. Chattopadhyay, and D. Yu, “Py- \nrometallurgical options for recycling spent lithium-ion batteries: A comprehensive review,”  Journal of Power Sources , vol. 491, p. 229622, 2021.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs. However, for other functional units, we assign a ﬁxed latency. We perform cycle-accurate simulation for the MAC computations based on tile activation and the data load/store process.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 2nd European Workshop on Machine Learning and Systems , EuroMLSys ’22, pp. 37–44, New York, NY, USA, 2022. Association for Computing Machinery.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "The Shown storage pipeline is the preliminary focus of  Salient Store  . analytics and learning tasks related to urban mobility at the edge. This has lead to a significant development in the direction of enabling video analytics and learning with edge servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "311–327. In  Proceedings of the 11th ACM Symposium on Cloud Computing . [47]  Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R. Das.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "282–299, 2022a. doi: 10.1109/MICRO56248. 2022.00031.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "Hence, even though both of them are located inside the RoF (and, of course, inside the viewing window), intuitively, the  soccer ball hologram does not need as much information as the  football hologram to compute. Inspired by this observation, another level of approximation can be explored based on the relative camera- to-object distance as well as the object range/size. 4.2 HoloAR Overview \nDriven by the above discussion and the potential approximation opportunities presented by the  Inter-Holo  and  Intra-Holo  scenarios, we propose  HoloAR , a novel framework for holographic process- ing in AR applications to improve  both  the performance and en- ergy consumption of the hologram processing, without affecting user experience.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "To address this, energy harvesting (EH) technolo- gies have emerged as a viable solution, enabling sensors to convert ambient energy (e.g., solar, thermal, or vibration) into electrical power. 1 Anonymous Institution, Anonymous City, Anonymous Region, Anonymous Country. This approach promises perpetual, maintenance-free operation, significantly reducing environ- mental impact and long-term operational costs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Each MAC unit within the HSPM architecture is capable of conducting two parallel modular multiplications. Designing HSPM Accelerator on CSD FPGA:  The HSPM hardware is characterized by its fully parallelized design, incorporating 128 Multiply-Accumulate (MAC) units for handling polynomials of degree  n  = 256 . This is achieved through the use of a single Digital Signal Processing (DSP) block that operates on signed data representation.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "Prioritizing essential tasks and deferring non-critical computations. 3. Employing predictive energy harvesting models to anticipate energy availability and adjust computations proactively.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "2.4.1–2.4.4, 2017. [40]  X. Dong, C. Xu, Y. Xie, and N. P. Jouppi, “NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory,” IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) , vol. 31, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Cloud programming sim- plified: A berkeley view on serverless computing. arXiv preprint arXiv:1902.03383  (2019). [34]  Ram Srivatsa Kannan, Lavanya Subramanian, Ashwin Raju, Jeongseob Ahn, Jason Mars, and Lingjia Tang.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "In 2012 16th international symposium on wearable computers , pp. Introducing a new benchmarked dataset for activity monitoring. Attila Reiss and Didier Stricker.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "GL1 and HC1 are other two videos from the CAMPUS [43] dataset. GL1 is also a parking lot video, but with many more objects and movements than V1 and V2. HC1 on the other hand is a garden video, with people walking around, riding \nbike, etc.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "(2016). [48]  Yifan Peng, Suyeon Choi, Nitish Padmanaban, Jonghyun Kim, and Gordon Wet- zstein. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "USENIX Association. Serving dnns like clockwork: Perfor- mance predictability from the bottom up. In  14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20) , Banff, Alberta, November 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "). ). In the context of EH-WSNs, game-theoretic models have been employed to design dis- tributed algorithms for resource allocation, power control, and cooperative communication ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "[17]  Rich Caruana, Alexandru Niculescu-Mizil, Geoff Crew, and Alex Ksikes. Ensemble selection from libraries of models. In  Proceedings of the twenty-ﬁrst international conference on Machine learning , page 18, 2004.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "In addition, he had co-organized a summer workshop for visually-impaired students as a part of their Expeditions project. As the department Head, PI Das has been closely associated with many such activities. PI Kandemir is an adviser/co-adviser of 5 female students, and PI Zhang has been advising 1 female PhD student, 4 female undergraduate stu- dents for their honors thesis projects, and serving on PhD dissertation committee for 9 female PhD students including 1 African American student.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Suppose, for contradiction, that there exists an infinite se- quence of unilateral profitable deviations. Thus, any unilateral profitable deviation increases  Φ( a ( t )) . Boundedness and Impossibility of Infinite Improvement Sequences \nSince all utilities are bounded (due to finite  γ, δ, η,  bounded ∆ A i ( t ) , and bounded energy resources), there exists a finite upper bound  Φ max  such that: \nΦ( a ( t ))  ≤ Φ max ∀ a ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "Here’s a simplified breakdown of the process: \n1. Better refers to the improvement over iNAS+PT baseline. B Details on Energy Harvesting \nA typical energy harvesting (EH) setup captures and converts environmental energy into usable electrical power, which can then support various electronic devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 4599–4604. Association for Computational Linguistics, 2020. [196] Yanqi Zhou, Nan Du, Yanping Huang, Daiyi Peng, Chang Lan, Da Huang, Siamak Shakeri, David So, Andrew Dai, Yifeng Lu, Zhifeng Chen, Quoc Le, Claire Cui, James Laudon, and Jeff Dean.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "However, if the student is not conﬁdent on the classiﬁcation, the frame is then saved as a potential exemplar (we will further reﬁne this in § III-B ). The potential exemplars \n894 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "V1 has fewer objects and less movements, and thus, compared to V2, the savings on execution time and energy consumption for V1 are slightly higher, as shown in Fig. 5) Video-Speciﬁc Analysis:  To investigate how the perfor- mance and energy behavior varies with video salient features such as the object count, objects’ motions, the fraction of area occupied by objects in an entire frame, etc., we have studied the six videos summarized in Table II. V1 and V2 are parking lot videos.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "For instance, DeepHolo [ 33 ] proposes a binary-weighted computer- generated hologram model to recognize 3D objects. Apart from neural network techniques, foveated rendering is another promising performance optimization for reducing computational costs [ 2 ,  22 ,  24 ,  25 ,  30 ,  47 ,  62 ], as summarized in Sec. Furthermore, another convolution neural network (CNN) model is trained and deployed on mobile devices to synthesize a photorealistic colour 3D hologram from a single RGB-depth image in real time [ 54 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "[89] E. Strubell, A. Ganesh, and A. McCallum, “Energy and policy con- \nsiderations for deep learning in nlp,”  arXiv preprint arXiv:1906.02243 , 2019. [90] J. S.-M. studyﬁnds.org, “Trafﬁc cameras become more popular when \nthey cut down on interactions with police,”  https://studyﬁnds.org/ trafﬁc-cameras-interactions-police/ , (Accessed on 04/28/2023). [91] N. A. W. .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "Designing a learning platform that can adapt to intermittent renewable energy sources (e.g., solar power) and maintain a minimal operational carbon footprint [ 29 ] is paramount. Such a platform should continuously make progress on unsupervised labeling, exem- plar building, and continuous learning, and maximize  drift mitigation  while minimizing power consumption. Moreover, the system must accommodate  support for intermittency inherent in sustainable power sources like solar and wind.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "[99] P. with Code, “Object detection on coco test-dev,” https://paperswithcode.com/sota/object-detection-on-coco , (Accessed on 11/21/2022). [97] Urban Trafﬁc Dataset, “https://github.com/edge-video- services/ekya#urban-trafﬁc-dataset.” [98] O. Wayman, “How urban mobility will change by 2030,” https://www.oliverwyman.com/our-expertise/insights/2022/jun/how- urban-mobility-will-change-by-2030.html , 2022, (Accessed on 08/04/2023). [100] www.dlapiperdataprotection.com, “Sweden data collection & process- \ning,”  https://www.dlapiperdataprotection.com/index.html?t=collection- and-processing&c=SE , (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 233,
    "augmented": true
  },
  {
    "text": "Octopai: Automated data lineage, data catalog and discovery. https://www.octopai. com/ .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "[16]  C. Dorea and R. L. de Queiroz, “Block-based motion estima- tion speedup for dynamic voxelized point clouds,” in  2018 25th IEEE International Conference on Image Processing (ICIP) , 2018, pp. 2964–2968. [17]  J. Elseberg, D. Borrmann, and A. N ¨ uchter, “One billion points in the cloud – an octree for efﬁcient processing of 3d laser scans,”  ISPRS Journal of Photogrammetry and Remote Sensing , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "[16]  X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, “RF-powered systems using steep-slope devices,” in  2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS) , pp. 73– 76, 2014. [17]  K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Architecture exploration for ambient energy harvesting nonvolatile processors,” in  2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "905 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Moreover,  Us. We believe it will not be fair to compare the energy efﬁciency and throughput of a system like ours, which in- herently has more memory, I/O and reconﬁguration operation with a pure compute based systems mentioned in the hardware baseline. ´as  needs more I/O operations to store the streaming data to compute the exemplars.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "•  EE  offers little chance of reuse, and can only be leveraged in rare occasions, where we have oracular knowledge of head movements. Furthermore, in such cases of head movement, there is likely to be some reuse from inter-eye reusability within a frame, rather than inter-frame reusability. B.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "5: A subset of sensors, determined by the equilibrium, send their gradient estimates to the aggregator. 6: The aggregator forms an unbiased estimate of the full gradient: \nb ∇ J ( θ k ) =  b ∇ L ( θ k ) +  λ 1 ∇ Ω SNR ( θ k ) \n+ λ 2 ∇ Ω complexity ( θ k ) . 7: Update model parameters: \nθ k +1  =  θ k  − α k   b ∇ J ( θ k ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Texas Instruments. Msp dsp library: Low energy accelerator (lea) user’s guide. https://software-dl.ti.com/msp430/msp430_public_sw/mcu/msp430/DSPLib/ 1_30_00_02/exports/html/usersguide_lea.html , 2024b.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "In  To be presented in proceedings of the 57th Annual IEEE/ACM International Symposium on Microarchitecture , pages 62–76, 2024. Pushing the performance envelope of dnn-based recommendation systems inference on gpus. [70] Rishabh Jain, Vivek M Bhasi, Adwait Jog, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Furthermore, we also present a qualitative com- parison on the maintenance cycle needed for these solutions. While a completely grid based solution is best in terms of reliability, it is not feasible because of the power demands. Any battery backed system will be limited to the charging cycle of the batteries ( ≈ 500 cycles for Li-ion batteries) which leads to a typical 18 to 24 months of life for such devices (compared to this, a super capacitor have a life of more than 100 years).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "2012. Creating and benchmarking a new dataset for physical activity monitoring. In  PETRA , Fillia Makedon (Ed. ).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "The PIs will leverage their complementary experience in developing appropriate research thrust areas within the scope of LLM to attract and engage a new cohort set of minority undergraduate students in research. •  Broad Reach to K-12 students:  We will partner with CSATS (Center for Science and the Schools) in the College of Education at Penn State to leverage their ongoing Penn State STEM-oriented outreach pro- grams. We have had continuous partnership with the CSATS faculty for over 5 years and have hosted \nday-long seminars for middle school and high school teachers as part of our prior NSF funded outreach efforts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "GL1 and HC1 are other two videos from the CAMPUS [43] dataset. Also, V1 can save  7%  more execution time and 6%  more energy than V2 when using the FI+SI+PI scheme. 8a.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Define the energy budget  E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l . Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ·  m i \nTraining with L2 Dynamic Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  α .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "changes. Therefore, by running a few iterations of the SGD algorithms with various other hyperparameters, we can easily  predict  the con- vergence of the models. Note that this needs to be done every time one of the constraints (accuracy, power etc.)",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Still, the savings in terms of cost will be signiﬁcant because even removing one model from the ensemble amounts to  ∼ 20% cost savings in the long run ( Clipper  vs  Clipper-X  ensemble in Figure  8 ). Thus, the beneﬁts of  Cocktail  are substantial for large ensembles while reducing the number of models for medium-sized ensembles. Figure  9b  shows the breakdown of the percentage of re- quests ( Const1 ) served by the each model.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "This speedup comes from: 1). •  Our Intra-Inter-V1 (Quality-oriented):  This design favors the quality over compression efﬁciency, and it only takes  124 ms  ( 41 ms  for geometry compression, and  83 ms for attribute compression), contributing to around  34 × speedup w.r.t. CWIPC.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "32  TiB of raw video data, which compresses to approximately 60  GiB to  400  GiB of encoded data per day. Including redundancy, this requires an additional  33% to  100%  more storage capacity. Furthermore, given the plug-and-play nature of storage media like HDDs and SSDs, securing this data becomes even more critical.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "They will be made available to the broad research community and other interested parties via a GitHub license. The educational materials, characterization and experimental data, and the representative LLM/expert models will also be maintained in machines at Penn State, and will be shared with the user community via a website dedicated to the project (as discussed earlier). 2.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "ACM SIGARCH Computer Architecture News , 34(2):4–15, 2006. [81] Jongman Kim, Dongkook Park, and Chita R Das. A low latency router supporting adaptivity for on-chip interconnects.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Compared to classical training, DynFit adds minimal overhead, with a tradeoff of  ≤ 5%  additional compute for significant gains in accuracy under intermittent power conditions. The space complexity is  O ( N )  for storing the update frequencies and additional parameters. 3.2 DynInfer: Intermittency-Aware Inference Scheduling \nDynInfer  optimizes the inference phase of DNNs operating under intermittent power conditions.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "In our proposal shown in the lower ﬁgure, instead of constructing the octree in a point-by-point fashion, we process all three points as one “batch” in the  Morton Code Generation step in parallel, and output the ﬁnal bounding box cuboid with side lengths 4 × 3 × 3 (x-axis: 3-(-1) =4, y-axis: 3-0 =3, and z-axis  3 - 0  = 3 ). With the Morton code in place, next we invoke the parallel octree construction technique (for more details, please refer to [ 31 ], [ 64 ]) to construct the octree. Note that this step is also amenable to parallelism.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "[33] IBM, “Data labeling,”  https://www.ibm.com/cloud/learn/data-labeling , \n(Accessed on 11/21/2022). [34] I. Ilievski, T. Akhtar, J. Feng, and C. Shoemaker, “Efﬁcient hyperpa- \nrameter optimization for deep learning algorithms using deterministic rbf surrogates,” in  Proceedings of the AAAI Conference on Artiﬁcial Intelligence , vol. 31, no.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "1 and Algo. Although we have an intuitive feeling on the how the thresholds in Algo. 2 affect the accuracy and performance, e.g., a larger  T moving  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Output:  Following the inference stage, the resulting Feature- Maps (FMs) are used to generate the ﬁnal tags/bounding-boxes and ﬁnally report to the application (e.g., a cow has been identiﬁed in the image with 95% conﬁdence). As a result, this stage is the main bottleneck in the NN applications. Numerous prior studies (e.g., see [21]– [23] and the references therein) have clearly shown that, regardless of the type of the compute hardware employed, the NN inferences are both compute and memory intensive.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "Both the baseline setups run on a fully powered system equipped with a steady power source. A majority voting en- semble method is used in both of these baselines to mimic ensemble learning. Origin  uses the DNNs of Baseline-2 for the classiﬁcation tasks.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Yao Tian, Xi Zhao, and Xiaofang Zhou. Db-lsh 2.0: Locality-sensitive hashing with query-based dynamic bucketing. IEEE Transactions on Knowledge and Data Engineering , 2023.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Our proposal,  Salient Store  , highlights the need for a paradigm shift in storage architecture to accommodate the dynamic and computationally intensive nature of modern ML applications. Salient Store  , with its intelligent data orchestration and acceleration, can provide up to  6 . By reducing unnecessary data movement and enabling near-data processing, CSDs enhance the efficiency, performance, and sustainability of storage servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Transitions between functions are done using function calls on the basis of pre-assigned inter-function transition proba- bilities. The probabilities vary by approximately  ± 20% of a seed. Note that these probabilities are not visible to  Kraken , but are only used to model function invocation patterns.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Abstract —Edge servers have recently become very popular for performing localized analytics, especially on video, as they reduce data trafﬁc and protect privacy. However, due to their resource constraints, these servers often employ compressed models, which are typically prone to data drift. Consequently, for edge servers to provide cloud-comparable quality, they must also perform continuous learning to mitigate this drift.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": ": As discussed in Sec. 2) How to Apply to PCC? Note that this step is also amenable to parallelism.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "The sporadic nature of har- vested energy and the lossy nature of EH based storage and charging circuits calls for using the harvested energy di- rectly to perform intermittent compute rather than storing energy for some distant future use. On this front, recent works [ 43 ,  44 ,  47 ] have specifically optimized DNN infer- ence execution at the EH-edge nodes by utilizing adaptive dynamic check pointing, intelligent scheduling and ensem- ble learning. Given the limitations of the EH budget, such approaches typically end up dropping many samples and not inferring from them locally.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Large language models: A survey. arXiv preprint arXiv:2402.06196 , 2024. [108] Asit K Mishra, Xiangyu Dong, Guangyu Sun, Yuan Xie, Narayanan Vijaykrishnan, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , 39(11):3479–3491, 2020. Chih-Kai Kang, Hashan Roshantha Mendis, Chun-Han Lin, Ming-Syan Chen, and Pi-Cheng Hsiu. More is less: Model augmentation for intermittent deep inference.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "46%, compared to an oracle parameter selection. Along with that, the micro-proﬁler selects correct batch size 82 . Observation over 40 hours of continuous learning on the dataset suggest that the micro-proﬁler has, on average, an accuracy deviation of 2 .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Workload- 1 consists of a mix of queries which have both strict and relaxed latency requirements. We compare the execution of this workload against the following resource procure- ment schemes: (i)  util_aware , (ii)  exascale , (iii)  mixed  and (iv) Paragon . Evaluation:  We evaluate our results by comparing the cost, latency and accuracy for two different workloads.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "A CKNOWLEDGEMENTS \nThis work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants #1822923 \n(SPX: SOPHIA), #1763681, #1629915, #1629129, #1317560, #1526750, National Natural Science Foundation of China [NSFC Project No. 61872251] and Beijing Advanced Innova- tion Center for Imaging Technology. This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "Designing any sophisticated ensemble learning technique will either consume more resources of the host device, or need more information and computation at the edge, thus making our effort of ﬁnishing the inference at the edge not viable. C. Designing an Adaptive Ensemble Learner AASR scheduling solves most of the issues on the sensor side without burdening host device, yet the host device still per- forms a na¨ıve majority voting-based ensemble. Hence, there is an opportunity to also improve the ensemble technique.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "[48]  Abeer Abdel Khaleq and Ilkyeun Ra. Hourly thermal load prediction for the next 24 hours by arima, ewma, lr and \n1054    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nan artiﬁcial neural network. Technical report, American Society of Heating, Refrigerating and Air-Conditioning Engineers ... , 1995.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "2019. [23]  Jyothi Prasad Buddha and Reshma Beesetty. In  NSDI .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "Abstract — There is an increasing demand for performing machine learning tasks, such as human activity recognition (HAR) on emerging ultra-low-power internet of things (IoT) platforms. Recent works show substantial efﬁciency boosts from performing inference tasks directly on the IoT nodes rather than merely transmitting raw sensor data. However, the computation and power demands of deep neural network (DNN) based inference pose signiﬁcant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN).",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. Figure 7: Inter-Frame attribute compression example.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "Interestingly, in order to include  P 2 , the current bounding box has to expand its side length by  4 × , i.e., enlarging from  2  to  8 , and now the octree also contains more levels with all three points being in its leaf level. Similarly, P 1  is located inside the current bounding box and inserted into the octree as the 6 th  child of the  root . In this case,  P 0 is located in the  7 th  child of the  root  node, and the  root  node now stores the occupy information, which is  00000001  (the right-most  1  indicates a “child” in  7 th  leaf node).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "15 \nC.1.3 Loop Tiling \nThe algorithm uses loop tiling to divide the computation into smaller blocks that can be managed between power interruptions. This tiling not only makes the computation manageable but also optimizes memory usage and cache performance, which is critical in constrained environments. C.1.4 Check-pointing Mechanism \nBefore each power interruption, detected through an energy monitoring system, the algorithm saves the current state using the  SAVE_STATE  function.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "The cost metric is the billing cost from AWS, and the accuracy metric is measured as the percentage of requests that meet the target accuracy requirements. We compare these metrics for  Cocktail  against (i)  In- Faas  [ 83 ], which is our baseline that employs single model selection policy; (ii)  Clipper  [ 27 ], which uses static full model selection policy (analogous to AWS AutoGluon); and (iii) Clipper-X  which is an enhancement to  Clipper  with a simple model selection (drop one model at a time) that does not uti- lize the  mode -based policy enforced in  Cocktail . Both  InFaas and  Clipper  share  Cocktail ’s implementation setup to ensure a fair comparison with respect to our design and execution environment.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 179,
    "augmented": false
  },
  {
    "text": "Since the clustering based coreset is typically more accurate then those formed by importance sampling, the former is pre- ferred, when possible. If energy is insufficient for DNN inference, the sensor will use coreset formation to communicate the important features to the host, which completes the inference. Oth- erwise, the sensor prioritizes local computation and, with the help of a moving average power predictor [ 47 ], predicts whether it can finish the quantized DNN inference with the combination of stored energy and expected income (  2a  and \n2b  ).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Additionally, as the step- size of full-inference is ﬁxed, it cannot adaptively update its cache based on the video content. On the other hand, Euphrates makes use of the motion information collected from the Image Signal Processor (ISP), and search the RoIs by combining the MVs of the current frame with the inference result of reference frame, and consequently, decrease the number of inference. Different from these two prior works where approximation decisions are dictated by reuse distance (e.g., the distance between two fully-inferenced frames), Potluck [12] utilized the feature vector extracted from input frames to adaptively trade off computation with reuse of the cached results.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "In A. Oh, T. Nau- mann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,  Advances in Neural Information Processing Systems , volume 36, pages 34661–34710. H2o: Heavy-hitter oracle for efficient generative inference of large language models. [189] Zhenyu Zhang, Ying Sheng, Tianyi Zhou, Tianlong Chen, Lianmin Zheng, Ruisi Cai, Zhao Song, Yuandong Tian, Christopher Ré, Clark Barrett, Zhangyang \"Atlas\" Wang, and Beidi Chen.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "Prediction Policy : To effectively capture the \nModel RMSE MWA 77.5 EWMA 88.25 Linear R. 87.5 Logsitic R. 78.34 Simple FF. This captures SLO violations due to mis-predictions. In addition, we sample SLO violations for every 10s interval and reactively spawn additional instances to every pool based on aggregate resource utilization of all instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2403.07816 , 2024. [152] Masahiro Sunohara, Takayuki Tokunaga, Takashi Kurihara, and Mitsutoshi Higashi. Silicon inter- poser with tsvs (through silicon vias) and fine multilayer wiring.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "R EDUCING  P ROJECTION  C OMPUTATION \nAs discussed in Sec. II, computations dominate the energy consumption in  360 ° VR video processing. Further, we also observed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Container overprovisioning is inflated 15% more than the corresponding real system re- sult, due to the large-scale traces. Table 6 shows the median and tail latencies of each policy averaged across all appli- cations for the three traces. The trend we observe is that traces with higher variability, such as the Twitter trace, af- fect the tail latencies of policies more harshly than the other, more predictable, traces.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "3a, one of the most common cases in videos is that the object(s) (which have been identiﬁed in previous frames, i.e., Frame-1) move around in the current frame (i.e., Frame-2 , Frame-3). 3 Then for Frame-2, we obtain the its motion vectors from the codec (with a minimal overhead, as discussed in Sec. In such scenarios, to explore the reusability exposed by motion vectors,  1  we ﬁrst process the full inference in CPU 1   for Frame-1, and  2  identify the objects as well as their positions (i.e., bounding boxes).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "As shown in Fig. VI-B . 10b , with fewer “direct-reuse” blocks (e.g., only  31%  of the I-blocks are directly reused in the left-most bar), the PSNR drops slightly when compared to the intra- frame compression, while the compression ratio is also the worst.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "In a typical convolutional neural network (CNN), each kernel is convoluted over the entire input feature map, and hence there is an “inter-kernel parallelism” (all kernels of a single layer can be executed in parallel) and “intra-kernel parallelism” (multiple computes in a convolution can happen in parallel). This property is true both for the forward pass and the backward pass of the standard CNN training. or decomposed as multiple units called “kernels” (or “ﬁlters”).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "1c. At a high level, this AR pipeline has three major stages:  ❶ Inputs  stage first collects the real-time information from all the on-board sensors such as IMU, IR, camera and depth image sensors. With these inputs,  ❷ Perception  stage understands the current surrounding environment such as pose estimation for head rotations/directions, eye tracking for pupil centers, and scene reconstruction for the current view analysis.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "IEEE, 2024. [174] Ziyu Ying, Sandeepa Bhuyan, Yan Kang, Yingtian Zhang, Mahmut T. Kandemir, and Chita R. Das. Edgepc: Efficient deep learning analytics for point clouds on edge devices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "1 s  and  4 . 2 s , respectively, to compress one PC frame on an edge platform, which are signiﬁcantly higher than the real-time requirement ( ≈ 100 ms  [ 19 ]), making them even more challenging to employ in emerging edge devices. To address this, we study the SOTA compression pipelines and observe that the main reason behind their performance inefﬁciencies is their  sequential updates  to the global result with each intermediate local runtime state  in a  point-by-point fashion.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "Sensors strategically decide when to ex- pend energy on local model updates and when to engage in inference tasks, ultimately maximizing their long-term contribution to the network’s performance. •  Joint Optimization of Training and Inference:  Our unified solution aligns training participation decisions with inference needs. Unlike con- tinuous on-edge training, we employ periodic or triggered fine-tuning sessions aligned with equilibrium strategies, en- suring robust and progressively improving global models.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "If the number of experts is still larger than needed, a clustering algorithm (e.g., AGNES [139], and topic clus- tering [160]) can be employed to combine experts with the highest cluster scores, thus reducing the total number of experts. Automatic EoE Graph Construction for Workload Balance. The EoE graph pruning process, involving removing and merging experts, can sometimes result in imbalanced branches, where one branch contains significantly more experts than another.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "(2019), 212:1–212:13. [25]  Jonghyun Kim, Youngmo Jeong, Michael Stengel, Kaan Akşit, Rachel Albert, Ben Boudaoud, Trey Greer, Joohwan Kim, Ward Lopes, Zander Majercik, Peter Shirley, Josef Spjut, Morgan McGuire, and David Luebke. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": ". The immediate reward for sensor  s i  is defined as: \nR i ( t ) = \n     \n    \nγ  ·  ∆ A i ( t ) , if  a i ( t ) =  P and inference is correct , \n− δ, if  a i ( t ) =  P and inference is incorrect , \n− η, if  a i ( t ) =  NP . , a N ( t )) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "9: Impact of multiple teachers on exemplar selection. Having an ensemble provides robust exemplar selection and improves accuracy over a single teacher. X- axis shows #exemplars/100 inferred frames over a 2hr window.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "presents simulation results and Section  ? ? concludes with a discussion of limitations and future work.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "Perform the forward pass with the updated dropout mask to obtain the output  Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the reconstruction error of the feature maps, along with the QuantaTask optimization to handle energy constraints. 19 \nD.4 Learning Sparse Masks Dropout with QuantaTask Optimization \nLearning Sparse Masks Dropout adapts dropout masks as learnable parameters within the network, inspired by Wen et al.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "He will lead Thrust-3 and also co-lead Thrust-4 with Co-PIs Zhang and Kandemir. Mahmut Taylan Kandemir (Co-PI):  Kandemir’s expertise includes optimizing compilers, storage sys- tems, HPC, and workload characterization. He will lead Thrust-2 and collaborate with Das and Zhang in Thrust-4.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "IL- LIXR already contains several AR software components (some of them are shown in Fig. 1c), including head tracking, IMU integra- tion, reprojection, and sound processing. On top of the ILLIXR codebase, we implemented three new components – eye tracking, pose estimation, and hologram processing.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Similarly, it took 384 A100 GPUs to train BLOOM over 3.5 months [165] and 6144 TPU v4 chips were used to train PaLM-540B model over 50 days [27]. The elaborate resources and the extensive times that these training tasks entail are indicative of severe financial im- plications of running these models. In fact, a recent study from CSET [100] estimates that the cost of building LLMs will move to trillions in roughly 36 months!",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "The equilibrium participa- tion strategies induce a stationary effective distribution D . Over sufficiently large timescales, the system does not drift away from this equilibrium, and samples  ( x, y ) can be considered drawn i.i.d. from  D .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "However, such performance gain from foveated rendering is still insufficient to close the 10 ×  gap discussed above. Thus, in this paper, we want to go beyond the prior foveated rendering for further optimizations, by investigating the potential opportunities which are unique to the AR use cases and may have been missed out before. 2.2.3 What are the Potential Opportunities?",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "One can observe that the mAP in our FI+SI scheme only drops by  0 . 075%  on average for YOLOv3, and  0 . 1%  for YOLOv4-tiny – both w.r.t.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Since majority of the storage systems are not limited to one storage server, but are spread across multiple servers, we scaled  Salient Store  by deploying it in a distributed fashion. We used  5 × AWS EC2 F1 instances with Alveo FPGAs as storage nodes, along with one EC2 P4 instance with A100 GPUs as the compute server. We do not observe much change in the data volume.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the Shapley values of the neurons, along with the QuantaTask optimization to handle energy constraints. D.6 Taylor Expansion Dropout with QuantaTask Optimization \nTaylor Expansion Dropout uses Taylor expansion (Li et al., 2016) to evaluate the impact of neurons on loss for dropout adjustments, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Mathematical Formulation:  Let  W  be the weight matrix of a layer.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "[76]  J. Shao, H. Zhang, Y. Mao, and J. Zhang, “Branchy-gnn: A device-edge co-inference framework for efﬁcient point cloud processing,” in  ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , 2021, pp. 8488–8492. [77]  R. Shumaker and L. Stephanie,  Virtual, Augmented and Mixed Reality: Designing and Developing Augmented and Virtual Environments: 6th International Conference, VAMR 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014, Proceedings, Part I .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "Additionally, the students will be encouraged to attend career and professional development workshops offered by Penn State. Career Counseling/Advising \nThe PIs will provide – on a regular basis – career counseling and advising to the PhD students in the project as part of the mentorship. The students will also have access to individual career counseling appointments with Penn State, who specialize in career and professional development.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "This feature can only be used as an add-on, along with other inputs to further improve compute reuse scope. For example, if the  360 ° video frame rate increases from the typical 30 fps to 60 fps, then one can potentially leverage this enhanced compute frequency in conjunction with the head orientation, to further expand the compute reuse window. Note however that, this meta- information is not on the data-dependence chain, and we do not consider it for memoization.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Chime-home: A dataset for sound source recognition in a domestic environment. In  2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) , pp. Peter Foster, Siddharth Sigtia, Sacha Krstulovic, Jon Barker, and Mark D Plumbley.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Copyrights for components of this work owned by others than ACM must be honored.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "abs/1510.00149, 2015. [27]  S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan, “Deep learning with limited numerical precision,” in  Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37 , ICML’15, pp. 1737–1746, 2015.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Thus, it can be concluded that, without any optimization, a state- of-the-art edge GPU is only able to compute for  <  4 depth planes in real-time [ 36 ]. These observations motivate us to investigate the reasons behind such low performance on GPU: is it because of the intrinsic software/algorithm characteristics, or is it primarily a hardware mapping issue? Towards this, we profiled the hologram processing on the edge GPU [ 36 ] using the NVPROF tool [ 37 ], and observed the follow- ing: First, the SM utilization for both the steps is very high, i.e., 74% for  Forward-Propagation  and 90% for  Backward-Propagation .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "NExUME achieves the highest energy efficiency across all platforms and datasets. This demonstrates that NExUME not only improves accuracy but also enhances energy utilization, making it highly suitable for deployment in energy-constrained intermittent environments. The improvements in energy efficiency are due to NExUME’s ability to adjust computational workload dynamically, minimizing energy wastage and ensuring that computa- tions are matched to the available energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "No token left behind: Reliable kv cache compression via importance-aware mixed precision quantization, 2024. Trapezoid: A versatile accelerator for dense and sparse matrix multiplications. [173] Yifan Yang, Joel S Emer, and Daniel Sanchez.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Additionally, even with our proposed PI technique, the improvements for GL1 and HC1 with YOLOv3 model are not very signiﬁcant (e.g., the latency reduction is improved by  4% for GL1 as shown in Fig. 8d). This is because, compared with the whole frame, RoIs in these two videos are large (e.g., ratio of RoI/whole frame is 4x of that ratio in V1), which increases the computation for the PI and thus decreases the its beneﬁts.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "1–13. [17]  Zehao He, Xiaomeng Sui, Guofan Jin, and Liangcai Cao. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "This is because the single model inference have up to 2x higher latency to achieve higher accuracy. Consequently, this leads to 35% SLO violations for  InFaas  in the case of Strict workload. In contrast, both Cocktail  and  Clipper  can reach the accuracy at lower latency due to ensembling, thus minimizing SLO violations to 1%.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "A full seat Vivado design suite [58], [59] is utilized to synthesize the design and report the power and timing numbers. To evaluate our design implementation in hardware, we use an FPGA platform, which is the same as the state-of-the-art PTU [28], with a 100MHz system clock, onboard conﬁguration circuitry, 2x16MB Quad SPI Flash, 1GB DDR2 Component Memory, and also a hardware PMU. We collect the display traces from a 5-inch (130 mm) 16:9 1080p (1920 × 1080) AMOLED display [54], which is similar to the Samsung Gear VR display [45].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "A Modular Reduction (MR) circuitry based on approximation (Kundi et al., 2020). Our MR unit achieves consumes  ≈ 82%  less hardware compared to classical implementation. This process is constant time, requiring only a single subtraction of  q .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "VI. For example, ATW [38] is a post-render technique, which sits between rendering (our focus) and display. R ELATED  W ORK \nOptimizations in Planar Video Streaming:  Pixel-similarity based optimizations [38], [57] have been exploited to improve \nperformance in 2D rendering.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Given enough time even na¨ıve low power hardware can ﬁnish training, but will have longer periods where the drift is exposed. A more preferable solution is to get rid of drift as quickly as possible, i.e. ﬁnish training on the exemplars (described in § III-B ) as soon as possible and also reach the desired accuracy – but to do this within the harvested budget.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "108–109. In 2012 16th international symposium on wearable computers , pp. IEEE, 2012.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 24,
    "augmented": true
  },
  {
    "text": "In addition, he had co-organized a summer workshop for visually-impaired students as a part of their Expeditions project. As the department Head, PI Das has been closely associated with many such activities. PI Kandemir is an adviser/co-adviser of 5 female students, and PI Zhang has been advising 1 female PhD student, 4 female undergraduate stu- dents for their honors thesis projects, and serving on PhD dissertation committee for 9 female PhD students including 1 African American student.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "While execution is relatively straightforward when maintaining a speciﬁc conﬁguration of tiling and pipelining strategy, transitions between conﬁgurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures. The hardware design details will be presented in Section IV. As part of compiling a CNN to ResiRCA, we build a proﬁling table relating each potential tiling and pipeline conﬁguration \nthat might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "This was motivated from the observation that as we selected more number of points in importance sampling, the accuracy of the inference on the compressed data increased significantly (at times by 2%). Hence, the points which were not selected while performing importance sampling still had some impor- tance and can be represented as a function containing the low level nuances of the activity performed and the sensor state. The challenge was to learn this function, i.e.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "This repre- sents  𝑁𝐶 𝑑 𝑡 (Section 3) for all possible depths,  𝑑 . It can be ob- served that, existing policies, namely,  Arch ,  Fifer  and  Xanadu spawn, respectively, 2.41x, 76% and 30% more containers than  Kraken , on average, across all applications. Overallo- cation of containers in case of  Arch  is due to two reasons: (i) it assumes that all functions in the application will be invoked at runtime; and (ii) it spawns one container per in- vocation request.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Technologies, “Aeromine technologies,” https://www. 1–28. [96] A.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "Furthermore, we plan to make this comprehensive full-stack development envi- ronment open-sourced, enabling the community to leverage it for informed design decision-making. 3 Related Work \nLLMs have gained significant momentum in recent years and are being used in domains like virtual as- sistants [12,16,56], website chatbots [121], tools [48,123], notetaking/summarization [52], etc. The insights gained from these simulations and modeling efforts will be instrumental in refining run- time performance and providing informed estimates regarding the system and hardware demands of emerging applications.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "Discussion of Results:  1. Dynamic Adaptation:  NExUME’s DynFit and DynInfer components enable real-time adjustments of dropout rates and quantization levels during training and inference based on instantaneous energy availability. This allows the DNN to maintain high accuracy even under severe energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7. Since a power predictor itself consumes power, it makes sense to employ it for large-scale applications under weak power sources where discarding a portion of computations may impose a big loss or for the scenarios where power level transitions happen frequently. VI.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "As shown in Figure 2, if loop tiling is applied to the unrolled MAC operations, only a tile of ReRAM cells along with their peripheral circuits is enabled to perform MAC operations. After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed. 1) Computation tiling:  In this work, we use loop tiling [ 35 ] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "3b. A single DSP unit includes a multiplier, with the lowest 18 bits of the \n12 \nDSP output representing the first product  d 0  and the highest 18 bits indicating the second product  d 1 , corresponding to  b 0  and  b 1  respectively, as depicted in Fig. 3b.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Generating hard instances of lattice problems. In  Proceedings of the twenty-eighth annual ACM symposium on Theory of computing , pp. Miklós Ajtai.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "[51]  Hailong Yang, Quan Chen, Moeiz Riaz, Zhongzhi Luan, Lingjia Tang, and Jason Mars. In  ATC . 2017.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Without any smartness built into them, these classical machines often suffer from unforeseeable failures. Therefore, retrofitting such classical machines with smart sensors will help in preventing such failures and will allow taking predictive measures to increase production efficiency. Moreover, a majority of the machines in operation, comprising much of the modern supply chain, are classical machines without any sensing or intelligence built into them.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "287 \nAuthorized licensed use limited to: Penn State University. With these inputs, the  Transform  step \n5 We consider the octree-based technique [ 56 ], [ 72 ] and RAHT [ 14 ], [ 56 ] as SOTAs for geometry and attribute compression respectively. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "[80]  Wei Wang, Jinyang Gao, Meihui Zhang, Sheng Wang, Gang Chen, Teck Khim Ng, Beng Chin Ooi, Jie Shao, and Moaz Reyad. SIGMETRICS , June 2017. Using burstable instances in the public cloud: Why, when and how?",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "The above observations from these two figures explain the power benefits of our proposed designs. Execution Latency:  Clearly, the reduction in the number of depth planes when using our approximation schemes can reduce the hologram execution latency as well. As shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "We assume a monotonic relationship: higher SNR increases both the capture cost and the expected ac- curacy contribution. High-SNR data capture improves the sensor’s con- tribution to global accuracy but consumes more energy. Let e cap ( SNR )  denote the energy required for capture at a given SNR level.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "The obvious solution is to reduce the communication data volume by compress- ing the data before transmitting. This also reduces energy footprint and the probability of data packet loss. Challenges with Data Compression: Using standard compression algorithms, like discrete cosine transform, dis- crete wavelet transform, and Fourier decomposition etc., to minimize the communication overhead is not a viable solu- tion [ 45 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": ":  To preserve accuracy, we back-trace the output feature map (FM) to investigate how the different regions of the input FM affect the the output for convolution layer 2 , as shown in Fig. 3) How to Maintain Accuracy? 5 and carefully consider our design decisions.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "This design is more concise even than the SINWP [ 6 ], because we target low power as the primary goal. Speciﬁcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows. To increase efﬁciency further our design supports aggressive power gating and other circuit techniques to dynamically reconﬁgure active tile sizes and shut-off inactive ReRAMs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Here,  Cocktail  reduces the number of models by up to 55% for all four query types. For brevity in explana- tion, the results are averaged across Wiki and Twitter traces for strict workload. 6.2.1 Beneﬁts from dynamic model selection \nFigure  9a  plots the average number of models used for queries falling under the ﬁrst four different constraint (const) types.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "1, a typical mobile neural network video inference system has two major hardware components: (i) an SoC with a CPU/GPU/NPU for processing the intensive computations, and an intermediate buffer in DRAM for storing the video frames as well as the intermediate data between layers of DNNs, and (ii) a video decoder communicating with the SoC ,typically via the memory bus. Running on top of the hardware, as shown in the “Application” layer in Fig. 1, the neural network video inference software pipeline can be summarized as follows: Input:  The raw video data is ﬁrst stored in memory (usually in the H.264/MPEG format).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "Hot experts are those that are more frequently invoked for generating responses because of common or recurring query topics, whereas cold experts are the ones which are less frequently utilized. Note that this categorization is  dynamic , adapting to the temporal nature of the incoming requests which can have \nvariations based on user demand. As shown in Figure 5, one way of utilizing this hot/cold expert separa- tion is to store their respective model parameters at different levels in the memory hierarchy, dictated by the degree of hotness, so as to optimize the response generation pipeline.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "3479–3491, 2020. [41] C.-K. Kang, H. R. Mendis, C.-H. Lin, M.-S. Chen, and P.-C. Hsiu, \n“More is less: Model augmentation for intermittent deep inference,” ACM Transactions on Embedded Computing Systems (TECS) , vol. 21, no.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "This website will have both “external” and “internal” inter- faces. The external interface will contain links to the publicly-available LLM/expert models and algorithms, compiler, system software and simulator codes and experimental data as they become available, whereas the internal link will be used to facilitate code sharing among the students and the PIs, as well as tracking the progress of code development and publication-related efforts. Broadening Participation in Computing (BPC) Plan: Connected \nSince this is a connected BPC plan, we only discuss the planned activities for the PIs, as specified in the submission guidelines.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 136,
    "augmented": false
  },
  {
    "text": "This threshold is exceeded in  Media Service  for the majority of functions. Due to the difference in container provisioning, the difference in response times between the three schemes is evident at the tail of the response time distribution (Figure 13b). Comm Only  and  Conn Only  are seen to exceed the target SLO at the 99th percentile.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Therefore, as shown in Fig. 9, our proposed  AE  optimization alone saves  37% compute energy compared to the  Baseline , translating to 19%  total energy saving. •  EA+AE:  With both  EA  and  AE  optimizations deployed, as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "Each layer of the neural network encodes progressively finer details of  R t . If  L k ( R t )  represents the  k -th layer’s encoding of the residual frame, the overall encoding of the frame can be expressed as: \nE t  = \nK X \nk =1 L k ( R t ) \nwhere  K  is the total number of layers, and each  L k  encodes different levels of detail or different regions of the frame, based on the motion information and the prediction error. Algorithm 1 shows the details of the layered neural codec.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "2.4 Thrust-4: Evaluation And Fine Tuning In order to evaluate the efficacy our EoE-based cross-layer design framework in terms of performance, en- ergy efficiency and accuracy metrics, we propose to develop a comprehensive evaluation platform that consists of an in-depth simulation infrastructure, analytical models and appropriate measurements on available systems. In this project, we will investigate the fault-tolerance behavior of the chiplet architecture by injecting different types of faults. Specifically, this thrust targets at answering the following questions: i)  What kind of simulation-emulation system is needed to carry out our experiments?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "[195] Zeyang Zhong, Urvashi Khandelwal, Omer Levy, and Dan Jurafsky. In  Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 4599–4604. Beyond common sense: The story of hellaswag.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "ACM Transactions on Embedded Computing Systems (TECS) , 20(5s):1–27, 2021. Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "[48] L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, \n“Hyperband: A novel bandit-based approach to hyperparameter opti- mization,”  The Journal of Machine Learning Research , vol. 1, pp. 18, no.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "It is also equally important to note the impact of LLMs on the environment. An LLM like PaLM- 540B to be trained in a data center facility operated on 89% carbon-free energy still produces 271.43 tCO2e, which is compared to be similar to emissions of a direct round trip of a single passenger jet between San Francisco and NYC [27]. A critical but often overlooked aspect of these compute-intensive operations are usage of water in cooling mechanisms in the data centers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Or, having a fine-grained pro- grammer control via pragmas/annotations can help to efficiently utilize the caches. For example, in cases of large working footprint or streaming accesses, the caches can be instructed to bypass low reuse data and store only the high reuse data. To support faster inter-chip communication, which is essential for training, the chips can be interconnected using a fast fabric like NVLink [119], Infinity Fabric [13], or any newer technologies, and to cater inter-chiplet communication, which is essential for both training and inference, the chips can benefit from high-performance on-chip interconnect designs [10, 18, 31, 41, 108, 110, 116, 143].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "While these software optimizations and judicious use of persistent storage works for smaller workloads like keyword spotting (e.g  \"Ok Google\" detection), they are inefficient for complex workloads (e.g. multi-sensor HAR, predictive maintenance etc.). These software-based solutions exhibit inefficiencies with respect to energy and time due to performing multiple save- and-restore cycles [ 23 ,  56 ]: while some of these operations are necessary, unnecessary checkpoints will also be conser- vatively performed to ensure forward-progress.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Because of this, in current designs, the projection transformation is invoked  twice as it needs to generate two different transformation matrices for the left eye and the right eye. On the other hand, the distance between the two eyes is small and is constant for a particular user 4 . The two transformation matrices are very “similar” as they inherit a relationship between them as a function of the small pupillary distance.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "569–590, 2024. In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pp. Gemino: Practical and robust neural compression for video conferencing.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "In  16th USENIX Symposium on Networked Systems Design and Implementa- tion (NSDI 19) , pages 699–718, Boston, MA, February 2019. Alem- bic: Automated model inference for stateful network functions. [58]  Soo-Jin Moon, Jeffrey Helt, Yifei Yuan, Yves Bieri, Sujata Banerjee, Vyas Sekar, Wenfei Wu, Mihalis Yannakakis, and Ying Zhang.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "[48] L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, \n“Hyperband: A novel bandit-based approach to hyperparameter opti- mization,”  The Journal of Machine Learning Research , vol. 18, no. 1, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "), and the compute mode of Jetson AGX Xavier board is set to be 15W. 2) Point Cloud Dataset:  We use two dynamic PC video datasets – the 8i Voxelized Full Bodies (8iVFB) [ 18 ] and the Microsoft Voxelized Upper Bodies (MVUB) [ 8 ] datasets in our evaluations. Speciﬁcally, we pick four videos from 8iVFB, and two videos from MVUB.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "7 , the ﬁrst frame, I- Frame, contains three points –  P 0  with geometry data  [ 0 , 0 , 0 ] and an attribute value  50 ,  P 1  with  [ 12 , 8 , 13 ]  for geometry and 52  for attribute, and  P 2  with  [ 19 , 26 , 58 ]  for geometry and 20  for attribute. Obviously, the two  P 0  points in I-Frame and P-Frame are exactly the same, which could be completely reused during the compression of the P-Frame. Moreover, the two  P 1  points are located closely (i.e.,  [ 12 , 8 , 13 ]  vs  [ 12 , 8 , 12 ] ), and contain very similar attribute values ( 52  vs  51 ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 184,
    "augmented": false
  },
  {
    "text": "correlation for 4-home setup). The accuracy improvement in the 4-home setup is significant and the reason for the lower edge accuracy of the 4-home setup is the limitation in number of training samples (2 home setup has twice the amount of data than the 4 home setup to train with). Considering the scale of the problem, the execution time on a desktop machine is almost same as a larger cluster that we typically find in a cloud.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "7, pp. 650–657, May 2007. [16]  X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, “RF-powered systems using steep-slope devices,” in  2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "These policies use all the components of  Kraken  except  Commonality  and  Connectivity . Additionally, we compare  Kraken  against policies with (a) statically assigned function probabilities ( SProb ) and (b) func- tion probabilities that dynamically adapt to changing invoca- tion patterns ( DProb ). 5.3 Large Scale Simulation To evaluate the effectiveness of  Kraken  in large-scale sys- tems, we built a high fidelity, multi-threaded simulator in Python using container cold start latencies and function execution times profiled from our real-system counterpart.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Copyrights for components of this work owned by others than ACM must be honored. ∗ Work was done as a student at Penn State. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "However, prior works do not consider other avenues for optimizing the computation. This heavy computation has become an acceleration candi- date/target in previous works, by ofﬂoading the entire compu- tation, as is, to an accelerator (GPU [39], or FPGA [28]). Since the head mounted VR devices are battery-backed, the computations that draw high power from the battery greatly hinder the experience of watching long  360 ° videos [39].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "[6] Alibaba, “MNN: Mobile Neural Network,” ”https://github.com/alibaba/ MNN”, 2019. [7] S. Han, H. Shen, M. Philipose, S. Agarwal, A. Wolman, and A. Krishna- murthy, “Mcdnn: An approximation-based execution framework for deep stream processing under resource constraints,” in  Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services , 2016, p. 123–136. [8] M. Xu, M. Zhu, Y. Liu, F. X. Lin, and X. Liu, “DeepCache: Principled Cache for Mobile Deep Vision,” in  Proceedings of the Annual Interna- tional Conference on Mobile Computing and Networking (MobiCom) , 2018, p. 129–144.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 211,
    "augmented": true
  },
  {
    "text": "7. After the pattern between left eye and right eye is captured, an external signal is propagated to the OCE to bypass the further original projection computations. In the proposed AE  design, the  Δ  pattern buffer is ﬁrst initialized by subtract- ing  Result [1] .R  from  Result [1] .L , as shown in the  AE  block in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "[100] www.dlapiperdataprotection.com, “Sweden data collection & process- \ning,”  https://www.dlapiperdataprotection.com/index.html?t=collection- and-processing&c=SE , (Accessed on 11/21/2022). [101] J. Xu and X. Wang, “Rethinking self-supervised correspondence learn- \ning: A video frame-level similarity perspective,” in  Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021, pp. 10 075–10 085.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "135–149, 1984. [35]  G. G. Langdon, “An introduction to arithmetic coding,”  IBM Journal of Research and Development , pp. [36]  D. Le Gall, “Mpeg: A video compression standard for multimedia applications,”  Commun.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "0 \n100 \n200 \n300 \n1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 \n# TIles Utilized \nTraning Iteration \n#Tiles-Oracle ηdŝůĞƐͲhƔĄƐ DadianNao ŵĞĂŶͲhƔĄƐ Mean-DaDianNao \n(a) Monotonically increasing \n0 \n50 \n100 \n1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46 49 \n#Tiles Utilized \nTraining Iteration \n#Tiles-Oracle dŝůĞƐͲhƔĄƐ DaDianNao DĞĂŶͲhƔĄƐ Mean-DaDianNao \n(b) Rapidly varying \nFig. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 189,
    "augmented": true
  },
  {
    "text": "However, certain jobs could be too big to execute atomically on harvested en- ergy. Therefore, we profile the tasks using the compute platform (in this case using the MSP-EXP430FR5994 and the LEA in it) to further divide the jobs into Power Atomic Tasks (QuantaTasks). These QuantaTasks are carefully coded with optimized assembly language to maximize their efficiency.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Random sampling of decision trees, albeit a na¨ıve way, has been empirically shown to work well in preserving model characteristics and providing accurate predictions. III. E XPERIMENTAL  E VALUATION AND  R ESULTS \nIn this section, we describe our evaluation methodology and evaluate both privacy-preserving and data-sharing partitioning strategies compared with a traditional random-forest approach.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "2 affect the accuracy and performance, e.g., a larger  T moving  in Algo. 1 has a preference on FI and is accuracy-friendly, while decreasing  T moving  will skip more frames and improve the performance, the speciﬁc impact of the selected thresholds on accuracy drop, performance improvement, and energy reduction deserves further study. Also, as discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "As shown in Figure  2a , four differ- ent models can satisfy the response latency, but each model comes with a different prediction accuracy. Similarly, if the \nImplications of Public Cloud Resource Heterogeneity for Inference Serving WoSC’20, December 7ś11, 2020, Delft, Netherlands \n0 \n10 \n20 \nCost($) \nVM cost \nLambda Cost \ninception                   nasnet densenet mobilenet \n(a)  Cost for ISO-latency models. 0 \n10 \n20 \nCost($) \nVM cost \nLambda Cost \ninception          resnet-200 resnext-50 nasnet \n(b)  Cost for ISO-accuracy models.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "2a. Overall,  360 ° VR video processing consumes 3.4  Watts , which is  2 . 27 ×  the power compared to its planar counter- parts (1.5  Watts ).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "5.2 Evaluation Methodology We evaluate the  Kraken  prototype on a 5 node  Kuber- netes  cluster with a dedicated manager node. Each node is equipped with, 32 cores (Intel CascadeLake), 256GB of RAM, 1 TB of storage and a 10 Gigabit Ethernet interconnect [ 35 ]. For energy measurements, we use an open-source version of Intel Power Gadget [ 16 ] that measures the energy consumed by all sockets in a node.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "We observe that  Cocktail  can effectively scale up and scale down the mod- els while maintaining the cumulative accuracy well within the threshold. More than 50% of the time the number of models are maintained between 4 to 5, because the dynamic policy is quick in detecting accuracy failures and recovers immediately \n1050    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \n(a)  Clipper \n(b)  Clipper-X \n(c)  Cocktail \nFigure 10:  Figures (a), (b) and (c) shows the number of models used in ensemble with corresponding cumulative accuracy and window accuracy over a 1 hour period for requests under  Const1 . Figure (d) shows the effects of distributed autoscaling with importance sampling.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "IEEE, 154–161. [38]  Anup Mohan, Harshad Sane, Kshitij Doshi, Saikrishna Edupuganti, Naren Nayak, and Vadim Sukhomlinov. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "This results in the majority of requests getting queued at the containers. 6.1.3 Analysis of Key Improvements : This subsection fo- cuses on the key improvements offered by  Kraken  in terms of Container Utilization, Response Latency Distribution and Energy Efficiency. Although we use specific combinations of applications and traces to highlight the improvements, the results are similar for other workload mixes as well.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "techniques that bal- ance communication and computation costs while partitioning the compute between the edge and a resource-rich server have been deployed. However, sharing data with as server makes data privacy a key constraint, especially when the server is an external service provider. Although model sharing, instead of data sharing, solves some of the challenges [5], such approaches are not trivial to deploy in classical learning paradigms, like random forests.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Cocktail adopts a three-pronged approach to solve the optimization problem. First, it uses a dynamic model selection policy to signiﬁcantly reduce the number of models used in an ensem- ble, while meeting the latency and accuracy requirements. Figure 1:  Beneﬁts of  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "This dynamic allocation allows for a flexible working set of experts hosted in the main memory, tailored to the specific needs of the batch of requests currently being processed. When a new batch of requests is introduced into the system, an initial selection of the top-k experts is conducted for each request in the initial layer of processing. By loading these selected potentially useful and relevant experts into the main memory, we propose to optimize the response time and computational efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "The accelerator-level shows that the entire accelerator is made of multiple such tiles (4x4 in the toy example). The tile-level shows how each tile consists of multiple such PEs and will be working on one kernel at a time. Inputs are broadcast into each tile so that each tile can work on a kernel.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "In Step  1  , same as our FL scheme discussed in Sec. IV-A, the bounding boxes (BBoxes, in red) are extracted by the “full-inferenced” previous frame, and the MVs are obtained from the current frame (Frame-3). 4.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Then, the iterative best-response updates described in Algorithm  1  converge to a Nash equi- librium action profile  a ∗ ( t ) . Proof of Theorem  4.1 : The proof constructs a potential function  Φ( a ( t )) =   P N i =1   U i ( a i ( t ) ,  a − i ( t ))  that strictly in- creases whenever a sensor makes a profitable unilateral deviation. Since utilities are bounded (due to finite en- ergy and limited accuracy gains) and returns diminish over time, no infinite sequence of profitable deviations is possi- ble.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 177,
    "augmented": false
  },
  {
    "text": "Further, in some specific cases of unknown constraints, the software can indicate an expert to  migrate  to another chiplet. Additionally, the hardware can expose various performance counters to the software. For example, a per- formance counter exposing data movement traffic in NoC can be used by runtime support to shuffle the expert to chiplet mappings.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Therefore, there has been a significant body of work [ 40 ,  42 ,  47 ,  56 ] on developing appropriate next generation hardware (most of \n3 \nthem on simulation). To estimate the required energy, we ran simple HAR inferences (optimized version of [ 26 ] for edge deployment using [ 68 ]) on an Adafruit ItsyBitsy nRF52840 Express - Bluetooth LE [ 2 ] and found it to be consuming from 550mJ to 1.6J of energy (depending on the quantiza- tion). Compared to this, body movement and WiFi sources (the possible modalities of harvesting for HAR) harvests in order of milliwatts [ 22 ,  56 ], making it almost impossible to have a feasible EH-WSN deployment, with the capabilities to perform modest learning tasks, using the CotS.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 197,
    "augmented": true
  },
  {
    "text": "This problem has not been explored in details, as coresets are typically considered as an  𝛼 − approximate representation of the data ( 𝛼 being the error/approximation parameter) [ 7 ] and never needed proper recovery. 3.2.1 Data Memoization:  Given our focus on ultra low power energy harvesting devices, any opportunities to re- duce computation and communication can noticeably aug- ment the performance and efficiency of the entire system. However, thanks to the low dimensional nature of many sensor data, reconstruction of original data from coresets becomes an essential step.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "[48] F. Suard, A. Rakotomamonjy, A. Bensrhair, and A. Broggi, “Pedestrian detection using infrared images and histograms of oriented gradients,” in  2006 IEEE Intelligent Vehicles Symposium , 2006, pp. 206–212. 1084 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. time support and hardware-based enhancements, performance- and energy-efﬁcient execution of DNN pipelines for videos on mobile devices are still open problems.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Fig. Therefore, we employ an intelligent “data sampling mechanism” to select the frames that might contain new information and a potential candidate for learning. 2  shows the different components of the student-teacher data annotation model adapted in  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "We have developed a prototype of  Kraken  using  OpenFaaS , an open source serverless framework [ 11 ], and extensively evaluated it using real-world datacenter traces on a 160 core Kubernetes  cluster. Our results show that  Kraken  spawns up to 76% fewer containers on average, thereby improving container utilization and cluster-wide energy savings by up to 4 ×  and 48%, respectively, when compared to state-of-the art serverless schedulers. Furthermore,  Kraken  guarantees SLO requirements for up to 99.97% of requests.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": ", 32(C):82–98, March 2014. Syst. [41]  Aaron Harlap, Andrew Chung, Alexey Tumanov, Gregory R. Ganger, and Phillip B. Gibbons.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "In  The Twelfth International Conference on Learning Representations , 2023. [133] Zhenting Qi, Hongyin Luo, Xuliang Huang, Zhuokai Zhao, Yibo Jiang, Xiangjun Fan, Himabindu Lakkaraju, and James Glass. Quantifying generalization complexity for large language models, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "This motivates us to develop an  activity-aware scheduling  (AAS) policy which aims to activate the best suited sensor for the anticipated activity. B. Therefore, to classify the next possible activity, we activate the sensor which is most accurate for classifying the anticipated activity.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "[192] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models. arXiv preprint arXiv:2303.18223 , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "To be sure that the combination will give us the desired accuracy of the larger model, we try to theoretically analyse the scenario. We formulate the problem conservatively as following. We perform an inference by ensembling ’N’ models, and each of these models have accuracy ’a’.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Therefore, depending on the latency re- quirements of the user applications,  serverless functions  need to be allocated the appropriate memory. However, this might result in increased cost when using  serverless functions  along with VMs for varying latency requirements. Hence, the over- all cost incurred by  mixed  procurement can be higher or lower than VM-only autoscaling policies.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "•  T 3  transforms the  360 ° coordinates from a  monocular view to a  stereoscopic view . Since each eye sees the same object differently , this transformation matrix is different for each eye to give the user a more realistic experience. •  T 4 , also known as the  perspective transformation  ma- trix, maps all  360 ° coordinates onto 2D coordinates.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "This is because the starting power requirement of the RCA is reduced, and the system can thus get through power failures and translate even the low input energy into forward progress. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation \nIf we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve “continuous progress” under lower power supply. If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles  PC2, PC4, PC5  and  PC8  under limited power budget, as depicted in Table II and Figure 1.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 211,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the Twenty-Fourth International Conference on Archi- tectural Support for Programming Languages and Operating Systems . 3–18. [30]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Björn B. Brandenburg.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "CCS Concepts:  ·  Computer systems organization  → Real-time system architecture . Keywords:  serverless, resource-management, inference \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Even though the sensors are running in the round-robin fashion, the non-participating sensors can still impact the classiﬁcation result by virtue of  recalling their most recent classiﬁcation. Hence, by memorizing or  recalling  the most recent classiﬁcation result, we can get the inference result of a sensor even without activating it. Combining the  Recall  with AAS (which we term as AASR - Activity Aware Scheduling with Recall) opens possibilities for getting a more accurate classiﬁcation.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Further, each point in the PC is associated with 3 coordinates (x, y, z) for the geometry and 3 colors (R, G, B) for the attribute. Thus, to represent one point,  4 byte × 3  +  1 byte × 3 = 15 bytes  are needed ( 4 byte s per coordinate and  1 byte  per color component). Thus, a typical PC frame containing  10 6 \npoints [ 49 ] require  120 M  bits of data, which is impossible to transmit in real-time to the end-user’s display, from both the latency and energy standpoints, considering a \nsteady  30 - 60  f ps  requirement.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "Define the dropout probability  p i  for neuron  i  based on the Taylor expansion approximation of its impact on the loss: \np i  = λ \f\f\f  ∂ L \n∂ a i   a i \f\f\f  +  ϵ \nwhere  λ  is a scaling factor to adjust the overall dropout rate, and  ϵ  is a small constant to avoid division by zero. Define a binary dropout mask  m  = [ m 1 , m 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "1b). RR3 has 3 nodes with no no-ops and RR6 has 3 nodes with 3 no-ops. Even using a round robin execution, we observe that only 28% of the inferences are completed (shown in Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "The potential exemplars \n894 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. However, if the student is not conﬁdent on the classiﬁcation, the frame is then saved as a potential exemplar (we will further reﬁne this in § III-B ).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Figure 4: Intra-frame PCC pipelines. 1) Prior Intra-Frame Compression Inefﬁciencies:  State- of-the-Art Intra-Geometry Compression 5 :  As discussed in Fig. 2  and Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "This calls for finding further opportunities for optimization. 2), we profiled a set of applications and found that the  hologram  processing is the primary bottleneck in terms of computation, energy consumption, and execution latency. To under- stand the computing requirements in a typical AR pipeline consists of many stages (refer Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Definitions of different affinities:  Expert–Expert:  the tendency of certain experts to be used more frequently together to serve a request;  Expert–Data:  the tendency of similar experts to use a common subset of training data;  Expert–Router:  the tendency of given experts and routers to be used together frequently to serve different requests and to share a subset of training data. ;  Expert–Composition Function:  the tendency of some experts to use the same composition function frequently across different requests; Expert–Accelerator:  the tendency of some experts to utilize the same chiplet or different chiplets in the same chip. experts are equally relevant, we will prioritize those with available accelerators to improve performance.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "Some sensors may frequently become inactive or produce low-quality data due to energy scarcity or environmental noise. Ambi- ent energy availability varies over time and space, leading to fluctuating sensor activity levels and intermittent participa- tion in both training and inference tasks. Consequently, the mere presence of numerous EH sensors does not guaran- tee robust and reliable performance for complex tasks such as image recognition, acoustic surveillance, or precision agriculture monitoring.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Note that, within the LBC algorithm, certain components, specifically polynomial multiplications, exhibit similarities to operations performed in CNNs. These similarities open up the possibility of reusing hardware designed for CNN operations to accelerate LBC computations. The most common algorithms used fod the said operations are High-Speed Schoolbook Polynomial Multiplication (HSPM) and Pipelined Systolic Dimension Modular Multiplier (SDMM), and we propose to accelrate the same using the FPGAs in the CSDs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "Mathematical Formulation:  The Shapley value  ϕ i  of neuron  i  is a measure of its contribution to the overall network performance. It is calculated by considering all possible subsets of neurons and computing the marginal contribution of neuron  i  to the network’s output: \nϕ i  = 1 |N| ! X \nS ⊆N\\{ i } \n| S | !",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "As shown for  Const1 ,  Cocktail  shows similar reduction (as image-classiﬁcation) with only using 4.8 models on average, which is 40% and 26% lower than Clipper  and  Clipper-X , respectively. The results reported are averaged across both the datasets. Figure  15b  plots the average number of models used by the three policies for the top four constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "In  11th  { USENIX }  Workshop on Hot Topics in Cloud Computing (HotCloud 19) . [39]  Edward Oakes, Leon Yang, Dennis Zhou, Kevin Houck, Tyler Harter, Andrea Arpaci-Dusseau, and Remzi Arpaci-Dusseau. 2018.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "4.2 HoloAR Overview \nDriven by the above discussion and the potential approximation opportunities presented by the  Inter-Holo  and  Intra-Holo  scenarios, we propose  HoloAR , a novel framework for holographic process- ing in AR applications to improve  both  the performance and en- ergy consumption of the hologram processing, without affecting user experience. Inspired by this observation, another level of approximation can be explored based on the relative camera- to-object distance as well as the object range/size. Hence, even though both of them are located inside the RoF (and, of course, inside the viewing window), intuitively, the  soccer ball hologram does not need as much information as the  football hologram to compute.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "However, the number of skipped inferences there is  static . We believe that, by looking deeper into the frame similarities and identify- ing reuse opportunities at a “ﬁner level”, we can signiﬁcantly reduce the number of inferences, thereby reduce the burden on the hardware. Further, if we can  dynamically  exploit this opportunistic similarity (i.e., the inference is invoked based on runtime contents), the solution can encompass most vision applications without affecting the current hardware stack.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "10a  iv  ) which has the worst quality, the absolute PSNR is close to  40 dB, which is sufﬁcient for many of the video applications that do not require very high resolution [ 6 ]. Still, we argue that, even with the Intra-Inter-V2 option (see one demo in Fig. For other high-demanding applications like AR-based surgery [ 11 ], our proposals may jeopardize the video quality, and consequently, we may need further software and/or hardware optimizations for improved user experience.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": ", m n ]  where  m i  ∈{ 0 ,  1 } . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  − p i : \nm i  ∼ Bernoulli (1  − p i ) \nApply the dropout mask during the forward pass. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ·  m i \nTraining with Optimal Brain Damage Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  β .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "6. Recall that, Frame-1, as the base frame, has to do the full inference (Step  1  ), and output the feature maps for each layer (Step  2  ). 3a, and give the details of the proposed partial inference (PI) scheme in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Containers \nRequest  \nQueue \nFunction 1 \nFunction 2 \nFunction n \n. . .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 20,
    "augmented": false
  },
  {
    "text": "The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiﬁcations. B. Mapping inference tasks to ResiRCA To achieve both generally low power and intermittency- compatible execution, the proposed ResiRCA architecture has the following two features that impact the software management of the RCA: Lightweight:  From the perspective of the ReRAM circuit at the core of the RCA, the precision and resolution of inputs, weights and outputs are kept low to yield low power. This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 169,
    "augmented": false
  },
  {
    "text": "´as uses a 2 level exemplar selection algorithm (one using the conﬁdence matrix, and then further reﬁned by the representa- tion learning). We observe that, with representation learning, Us. ´as  is  ≈ 4 .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "TMC13, while our Intra- Inter-V1 and Intra-Inter-V2 only consume  0 . 6%  energy saving w.r.t. 38 J  per PC frame, which represents  96 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "[19]  Muhammad Huzaifa, Rishi Desai, Samuel Grayson, Xutao Jiang, Ying Jing, Jae Lee, Fang Lu, Yihan Pang, Joseph Ravichandran, Finn Sinclair, Boyuan Tian, Hengzhi Yuan, Jeffrey Zhang, and Sarita V. Adve. 2021. Exploring Extended Reality with ILLIXR: A new Playground for Architecture Research.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "R ELATED  W ORK \nThe previous RCA related work can be divided into the following two categories: High Performance RCA Architectures: PRIME [ 4 ] uses 6-bit inputs and 8-bit weights and targets 6-bit output precision. A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight. Area with different duplication granularity \nVII.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "To properly model the energy harvesting, losses during conversion, and leakage, we built a rectiﬁcation circuit with 4  ×  5 . 5 V ,  2 . 2 F super-capacitors connected in parallel to a voltage regulator \ncircuit.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Here, we partition the output FM regions into three categories –  a  inner part,  b  middle part, and \nc  outer part. 5 and carefully consider our design decisions. a  is the region where the convolution kernel only multiplies with the pixels in RoIs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "In particular, we plan to visit along with a couple of our trained undergraduate and graduate stu- dents to local middle and high schools and talk to students about the exciting opportunities in computing discipline. A selected group of undergraduate students and volunteers from CRA-W, ACM, and Girls Who Code programs will be trained to go to these schools and talk to students. We have had continuous partnership with the CSATS faculty for over 5 years and have hosted \nday-long seminars for middle school and high school teachers as part of our prior NSF funded outreach efforts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "[67]  Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. In  Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) , pages 502–518, Vancouver, Canada, August 2017. Association for Computational Linguistics.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "International Society for Optics and Photonics, SPIE, 144 – 152. 2021. [67]  Anlan Zhang, Chendong Wang, Bo Han, and Feng Qian.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "The PIs and their students are passionate about the broader outreach and in kindling interest in the K-12 students to pursue STEM careers. In the context of this project, we plan to participate in Exploration-U Science Day and organize a booth on Generative AI. Preparation for Activities:  The two senior PIs have extensive prior experience in supervising female un- dergraduate and graduate students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "[4] J. Albericio, P. Judd, T. Hetherington, T. Aamodt, N. E. Jerger, and \nA. Moshovos, “Cnvlutin: Ineffectual-neuron-free deep neural network computing,”  ACM SIGARCH Computer Architecture News , vol. 44, no. 3, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Deepspeed-moe: Advancing mixture-of-experts inference and training to power next-generation ai scale. In  International conference on machine learn- ing , pages 18332–18346. PMLR, 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Our experiments reveal that the proposed FL scheme can skip up to  53%  of the frames, with  very less  accuracy loss ( 0 . If that is the case, then full inference needs to be invoked. Otherwise, we further check whether an object is entering to or exiting from the current frame (in Line  30 ) to perform full inference for it.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "It can be observed that, while the “exact pixel match based similarity” is scarce at frame level, an alternate similarity based on the “magnitude of pixel differences” is abundant. The distribution of the absolute differences (deltas) between the pixel values in successive frames plotted in Fig. 2b provide one such opportunity.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "[30]  Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language un- derstanding, 2019. [31]  Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Evomoe: An evolutional mixture-of-experts training framework via dense- to-sparse gate. [117] Xiaonan Nie, Xupeng Miao, Shijie Cao, Lingxiao Ma, Qibin Liu, Jilong Xue, Youshan Miao, Yi Liu, Zhi Yang, and Bin Cui. IEEE, 2006.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "2020. Toward the Next-generation VR/AR Optics: A Review of Holographic Near-eye Displays from a Human-centric Perspective. Optica  (2020), 1563–1578.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "The current scheduler is activity aware, i.e. while performing an inference it always tries to choose the best available sensor to perform the task at hand. Furthermore, the AASR poses negligible overhead both in terms of compute and memory.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "\"https://www. xilinx.com/products/boards-and-kits/ek-u1-zcu102-g.html\". [65]  Tiancheng Xu, Boyuan Tian, and Yuhao Zhu.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "(Accessed on 11/13/2023). Debendra Das Sharma. Compute express link (cxl): Enabling heterogeneous data-centric computing with heterogeneous memory hierarchy.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Accessed: 2024-10- 18. [30] Bill Dally. Directions in deep learning hardware.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "[59]  Stereolabs. 2020. ZED Software Development Kit.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 16,
    "augmented": true
  },
  {
    "text": "292 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Only intermittent learn- ing [ 47 ] focuses on performing on-device training, but with very small workloads and models. Considering the scale, scope and workload of our problem, limits direct comparisons, ex- cept for comparing their exemplar selection method. Similarly, Ekya [ 12 ] only focuses on co-location of computation, and it’s efﬁciency on ﬁnishing compute even on a custom hardware is shown in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Speciﬁcally, in our design, the PC frames are encoded in an “IPP” fashion, where each I-frame is followed by two P-frames. Combining Inter-frame and Intra-frame Compression \nSimply put, our intra-frame compression proposal can sig- niﬁcantly reduce the execution latency, while the inter-frame compression proposal can further improve the compression efﬁciency. We emphasize here that, these two proposals can work in an interleaved fashion (with a frame-level granularity) for a PC video stream.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "E.g., with 32 × 32 tiles, only 3% of the tiles are identical. In the extreme case where the tile size equals frame size, only less than 0.1% of the successive frames are identical. As a result, any approach trying to exploit frame reuse (e.g., skip inferences for similar frames) based on this speciﬁc similarity metric (exact pixel match) will not have much scope for optimization.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "5%  w.r.t. 7. A  Decision Maker  is placed be- fore the original compute engine (CPU in this example) to dynamically decide how to process the incoming frame, and opportunistically bypass the computation, i.e., either  1  Full Inference (FI) or  2  Skip Inference (SI), or reduce the compute by only processing RoIs, when opted for  3  Partial Inference (PI), with a little overhead ( 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Caine. Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, and Benjamin et al. 569–590, 2024.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "More speciﬁcally, the rendering process is a projection from the  360 ° frame pixels’ 3D coordinates to the 2D frame pixels’ 2D coordinates on HMDs. The projection process considers two user-side aspects –  head orientation and pupillary dis- tance 1   – to render stereoscopic views or Field of View (FoV) frames for both eyes, towards the head direction. The head orientation is sensed by an inertial measurement unit (IMU) on the HMD as a triple [ Y aw ,  Pitch ,  Roll ] for projection computation 2 .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Pose Estimate \n33  ms Kimera [53] \nEye Track \n33  ms NVGaze [26] \nScene Reconstruct \n100  ms InfiniTAM [50] \nHologram 33  ms GSW [49, 63] \ntasks and interacts with more hardware resources [ 61 ]. 5 fps, and the battery life can be as short as just 1 hour. Based on our measurements collected from a smartphone [ 60 ] running a sim- ple AR application [ 3 ], the processing performance can be lower than 0 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "lions of additional battery-supported analytics platforms would introduce severe environmental challenges due to resource extraction, production, and replacement of batteries [ 3 ], [ 5 ], [ 10 ], [ 13 ], [ 53 ], [ 66 ], [ 69 ]. By demonstrating the viability of a battery-less edge server for video analytics, Us.´as spearheads the adoption of similarly sustainable systems for other do- mains. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "However, we argue that there is scope to further optimize resource procurement based on the fre- quency of peak load and constant load in a given request \narrival scenario. From our simulation experiments we observe that  mixed  procurement did not reduce cost of Wiki trace. Figure  6  plots the peak-to-median ratio for three different traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "We also spawn con- tainers much more in advance than the predicted arrival time and also keep them alive for at least a minute before evicting them from memory, to account for arrival unpredictability. It is seen that  Kraken  meets the SLOs for all requests from the lightly-loaded trace over 18 hours while averaging 0.85 memory-resident containers at any given second 3 . Other \n3 These results are not shown in any graph.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "We believe that the co- optimization of deep learning and energy harvesting techniques for edge devices will further invigorate research on the next generations of intelligent and sustainable IoT platforms. VI. A CKNOWLEDGMENTS This work was supported in part by Semiconductor Research Corporation (SRC), Center for Brain-inspired Computing (C- BRIC) and NSF Grant #1822923 (SPX: SOPHIA).",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy. An FSM transition can happen between any pair of power levels. Activation solution under power level  l: <m l , n l , aG l > \nActivation solution under power level  h: <m h , n h , aG h > \nSmooth transition l->h without power prediction \nSmooth transition l->h \nwith power prediction \nSmooth transition h->l without power prediction \nSmooth transition h->l \nwith power prediction \n1 \n2 \n3 \n4 \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "Similarly, other approximation-via-data-reduction techniques, such as sub-sampling, did not perform inference with a desirable accuracy. The quantized DNNs benefit from lower compute and memory footprints, but need specialized fine-tuning and often suffer from lower ac- curacy. Collectively, the aforementioned figures demonstrate that the harvested energy budget is insuf- ficient to perform  all  inferences with acceptable accuracy on currently proposed EH-WSN systems.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Therefore, there has been a significant body of work [ 40 ,  42 ,  47 ,  56 ] on developing appropriate next generation hardware (most of \n3 \nthem on simulation). Although, we evaluate and show the communication cost savings of  Seeker  on the battery backed CoTS hardware, we propose possible (simulated) hardware accelerator designs to fully deploying a EH-WSN capable of performing inference, compression and communication in harvested energy budget. Complex Compute on EH-WSNs:  To quantify the scope performing complex compute using EH-WSNs, we took hu- man activity recognition (HAR) as a workload 1 , and per- formed experiments on the MHEALTH data-set [9, 10] (see Section 5 for data-set details) using the DNNs proposed in [ 26 ,  60 ], an energy harvesting friendly DNN hardware accelerator [ 56 ] (to ensure that we are using the state of the art EH-WSN hardware) and recently proposed HAR- specific optimizations for EH systems [ 47 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 232,
    "augmented": false
  },
  {
    "text": "The data volume communicated for different number of clusters is represented in Figure 13. B APPENDIX \n16 \n-0.45 \n-0.24 \n-0.02 \n-0.07 \n-0.14 \n-0.19 \n-0.50 \n-0.40 \n-0.30 \n-0.20 \n-0.10 \n0.00 \n0 \n50 \n100 \nWalking Climbing Cycling Running Jogging Jumping Geo Mean \nError \nAccuracy (%) \nCoreset: Compressed Coreset: Reconstructed Reconstructed with Larger Model Seeker Baseline: EAP Baseline: Origin Baseline: Large DNN Error vs Fully Powered \n(a) Accuracy with MHEALTH dataset \n-0.26 \n-0.19 \n-0.76 \n-0.28 \n-0.04 \n-0.80 \n-0.60 \n-0.40 \n-0.20 \n0.00 \n0 \n20 \n40 \n60 \n80 \n100 \nWalking Climbing Cycling Running Jumping Geo Mean \nError \nAccuracy (%) \nCoreset: Compressed Coreset: Reconstructed Reconstructed with Larger Model Seeker Baseline: EAP Baseline: Origin Baseline: Large DNN Error vs Fully Powered \n(b) Accuracy with PAMAP2 dataset \nFigure 17: Accuracy and communication efficiency of  Seeker  with different data sets and sensitivity study. We also conducted an empirical study on number of clusters required, and found out that the bearing set data needs about 15 to 20 clusters to maintain the inference accuracy.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 321,
    "augmented": true
  },
  {
    "text": "Note that, this operation, which is a matrix multiplication on each FoV pixel coordinate, can be quite compute intensive. In fact, the number of pixels in the FoV is usually around 1 million, and the videos stream at a rate of 30 fps for an immersive experience. This amounts to about  2.3 GFLOPS , which represents a substantial amount of computation, given the limited compute capabilities and power in such edge devices.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "For example, a dynamic RoI encoding is proposed to compress the data volume to be transferred through net- work [17]. An anchor-point selection algorithm (running in cloud) is also proposed to decide whether to reuse the previous results or not in [30]. Both require the assistance of the cloud, and hence, introduce additional costs and privacy issues.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "However, instead of designing a centralized DNN which processes the combined data from all the sensors, we design three different smaller DNNs that work on their individual data. Further, to build an energy efﬁcient version of the DNNs, we applied the energy-aware DNN optimizations proposed in [3], [15]. We use two different datasets, MHEALTH [12], [13], and PAMAP2 [16], [17], for our evaluation which follow the similar sensor setup described in Section IV-A.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Hot experts are those that are more frequently invoked for generating responses because of common or recurring query topics, whereas cold experts are the ones which are less frequently utilized. We will dynamically classify experts as “hot” and “cold” experts based on their frequency of use. Towards this, we plan to experiment with various latency reducing/hiding techniques such as caching and prefetching by intelligently using experts based on their frequency of in- vocation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "[34]  NASA. 2020. NASA at Home – Virtual Tours and Apps.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 20,
    "augmented": false
  },
  {
    "text": "Finally, we assume the exact same setup of the Urban trafﬁc dataset and hence have 5 different MobileNetV2 models trying to classify the trafﬁc they are facing, and learning from the streaming data. We vary the training intervals to see the effect of frequency of retraining. Existing Approaches:  Although there has been signiﬁcant re- search [ 40 ], [ 41 ], [ 47 ], [ 52 ], [ 56 ], [ 61 ], [ 72 ], [ 104 ] on enabling machine learning in intermittently powered devices, a major- ity of it focuses on performing inference.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "[70] A. Prabhu, C. Dognin, and M. Singh, “Sampling bias in deep active \nclassiﬁcation: An empirical study,”  arXiv preprint arXiv:1909.09389 , 2019. 491–506, 2017. 67, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "[8]  Liang Wang, Mengyuan Li, Yinqian Zhang, Thomas Ristenpart, and Michael Swift. 2018. Peeking Behind the Curtains of Serverless Plat- forms.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Although not all sensors participate every time, the equilibrium ensures a stable pattern of participation. Averaged over multiple rounds, the collected gradients form an unbiased estimator   b ∇ L ( θ )  of  ∇ L ( θ ) : \nE [ b ∇ L ( θ )] =  ∇ L ( θ ) . Since the regularizers are deterministic, their gradients ∇ Ω SNR ( θ )  and  ∇ Ω complexity ( θ )  do not introduce bias.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "8525. Springer. [58]  Julian Steil, Inken Hagestedt, Michael Xuelin Huang, and Andreas Bulling.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "We treat the convolution scheduling (using input stationary and at a kernel level) in a morphable systolic hardware to be the main challenge and explain it. V. I MPLEMENTATION AND  E VALUATION \nWe focus our evaluation on urban mobility, i.e. performing single shot  object detection for trafﬁc monitoring using the MobileNetV2  [ 51 ] model on the urban trafﬁc data set [ 97 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "(2)  δ  appropriately penalizes incorrect inferences, discouraging low-quality data contri- butions. Briefly, these parameters should be chosen to ensure that:  (1)  γ  suffi- ciently incentivizes correct participation without leading to excessive energy expenditure. Detailed guidelines for selecting these hy- perparameters are provided in Appendix  A .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Optica  (2020), 1563–1578. [7]  Suyeon Choi, Jonghyun Kim, Yifan Peng, and Gordon Wetzstein. 2021.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "6c. 6b and Fig. On plotting the distance vectors for each row of the FoV frames, we observe a recurring  ellipse  pattern.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "In addition to the  Inter-Holo  de- sign, our proposed  Intra-Holo  technique focuses on computation approximation opportunities, and as such, it is orthogonal to these prior efforts. 7 CONCLUSION The extremely heavy computation in hologram processing hinders the growth of the 3D display applications on AR headsets. Note, however, that none of these existing schemes target at reducing the amount of “unnecessary” computations in the AR holographic applications.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Equilibrium Stability and Impact on Stationarity \nThe key subtlety is that  D  depends on equilibrium strategies. This stability allows us to treat  D  as effectively fixed for the purpose of the asymptotic analy- sis. However, the equilibrium ensures a stable operating regime where sensor behaviors—and thus  D —do not change dras- tically over time.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "While down-scaling, we drop the models with the least prediction accuracy in that interval. If the  Mode  is greater than needed votes  ⌊ N / 2 ⌋ +  1  we prune the models to  ⌊ N / 2 ⌋ + 1 . For consecutive sampling intervals, we calculate the  Mode  (most frequently occurring) of the majority vote received for every input.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "https://archive.org/details/twitterstream. Twitter Stream traces. References \n[1]  [n.d.].",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "ScaleFlux. Csd 2000. https://scaleflux.com/products/csd-2000/ , a. (Accessed on 11/13/2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "0 \n100 \n200 \n300 \n1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 \n# TIles Utilized \nTraning Iteration \n#Tiles-Oracle ηdŝůĞƐͲhƔĄƐ DadianNao ŵĞĂŶͲhƔĄƐ Mean-DaDianNao \n(a) Monotonically increasing \n0 \n50 \n100 \n1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46 49 \n#Tiles Utilized \nTraining Iteration \n#Tiles-Oracle dŝůĞƐͲhƔĄƐ DaDianNao DĞĂŶͲhƔĄƐ Mean-DaDianNao \n(b) Rapidly varying \nFig. 11: Tile utilization against available power:  Us. ´as  with eager scheduling vs an oracle scheduler.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 187,
    "augmented": false
  },
  {
    "text": "Additionally, the experimental analysis indicates that our approach outperforms the state-of-the-art work with respect to accuracy and/or performance/energy savings. A CKNOWLEDGMENT \nWe thank the anonymous reviewers for their helpful feed- back and suggestions towards improving the paper content. This research is supported in part by NSF grants #1931531, #1955815, #2116962, #2122155 and #2028929.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "We propose a comprehensive framework that integrates a game-theoretic partici- pation strategy with a federated learning approach tailored for EH-WSNs. Abstract \nEnergy-harvesting wireless sensor networks (EH- WSNs) offer sustainable solutions for large-scale IoT deployments but face challenges due to the unreliability and intermittent availability of in- dividual sensors. Our game-theoretic model enables sensors to make optimal participation de- cisions based on energy levels, data quality, and collective inference impact, fostering cooperative behavior while managing individual energy con- straints.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "P   pipe   = \nLC X \nLk =1 P Lk (4) \nLat pipe   =  max ( Lat L 1 , Lat L 2 ...Lat LC ) (5) \nC. Dynamic activation strategy \n1) Problem formulation:  In this section, we focus on ﬁguring out the ResiSchedule solution to achieve the maximal throughput. Note that the pipelined computation mode means that all the  LC convolution layers are executed fully parallel. We also model the pipelined computation mode shown in Equations 4 and 5.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Second,  which features of these inputs are salient and need more fine-grained computation, and which of them could be approximated without impacting the QoS? Third,  how do we make dynamic decisions of approximation based on the runtime conditions (e.g., user’s current pose and eye movements)? Towards this, we propose  HoloAR , an opportunistic and edge- friendly framework to speed up the AR holographic computation \n(a) An app.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "We believe it will not be fair to compare the energy efﬁciency and throughput of a system like ours, which in- herently has more memory, I/O and reconﬁguration operation with a pure compute based systems mentioned in the hardware baseline. Further, we are the ﬁrst of a kind system to imagine sustainability ﬁrst and design a morphable hardware which can facilitate multiple functionality. We also compare our work against two reconﬁgurable platforms [ 15 ], [ 63 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "At the beginning of each kernel scheduling iteration, the micro-proﬁler decides the right conﬁguration, and the control distributes equal number of kernels to each active tile (given  A  active kernel, and  K total kernels, each tile gets  ⌊ K / A ⌋ kernels to execute). The conservative scheduler ensures that no tile loses power before ﬁnishing the current scheduled kernel. However, in the middle of the execution if any new tiles becomes alive (because of an increase in harvested power), the scheduler immediately marks it ready to start working and the tile fetches a kernel (currently not scheduled in any of the tiles) and starts working on it.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "However, the computation and power demands of deep neural network (DNN) based inference pose signiﬁcant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN). This paper presents a novel scheduling policy along with an adaptive ensemble learner to efﬁciently perform HAR on a distributed energy-harvesting body area network. Moreover, managing inferences requiring responses from multiple energy- harvesting nodes imposes challenges at the system level in addition to the constraints at each node.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Prior works on intermittent learning have either chosen one teacher model \n900 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Us. ´as does not deliver the highest throughput and also consumes more power compared to the other accelerators. Performance-Power Trade-offs:  As Table  II  suggest,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the Workshop on Hot Topics in Operating Systems , New York, NY, USA, 2019. Association for Computing Machinery. [84]  Tien-Ju Yang, Andrew G. Howard, Bo Chen, Xiao Zhang, Alec Go, Vivienne Sze, and Hartwig Adam.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Aligned with the departmental BPC plan, the students working on this project will participate in various diversity, equity, inclusion and belonging (DEIB) DEIB activities. We also plan develop recruiting relationships with HBCUs. All these efforts should help us in broadening participation in this project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "In  International Conference on Machine Learning , pages 31094– 31116. Flexgen: High-throughput generative inference of large language models with a single gpu. [146] Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Beidi Chen, Percy Liang, Christopher Ré, Ion Stoica, and Ce Zhang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "6 \n4 Experimental Results \nNExUME can be seamlessly integrated as a “plug-in” for  both  training and inference frameworks in deep neural network (DNN) applications, specifically designed for intermittent and (ultra) low-power deployments. In this section, we discuss the effectiveness of NExUME across two distinct types of environments, highlighting its versatility and broad applicability. In case of a power emergency, the task is abandoned and a hardware-assisted backup and restore is performed.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "[11] Beverly Hills has thousands of surveillance cameras, “https://bit.ly/BeverlyHillsCamera.” [12] R. Bhardwaj, Z. Xia, G. Ananthanarayanan, J. Jiang, Y. Shu, N. Kar- \nianakis, K. Hsieh, P. Bahl, and I. Stoica, “Ekya: Continuous learning of video analytics models on edge compute servers,” in  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , 2022, pp. 119–135. [13] R. Bird, Z. J. Baum, X. Yu, and J. Ma, “The regulatory environment \nfor lithium-ion battery recycling,” 2022.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 185,
    "augmented": false
  }
]