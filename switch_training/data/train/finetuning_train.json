[
  {
    "text": "This makes it possible to find a sweet spot, given specific needs, in efficiency and accuracy trade offs. The number of estimators also needs to be customized for different datasets. Figure 4d shows that inference time will increase linearly with the number of estimators whereas it has a very small impact on correlation.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "If that is the case, then full inference needs to be invoked. Otherwise, we further check whether an object is entering to or exiting from the current frame (in Line  30 ) to perform full inference for it. Our experiments reveal that the proposed FL scheme can skip up to  53%  of the frames, with  very less  accuracy loss ( 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "For instance, InFaas [ 83 ] can choose variants among a same model to maintain accu- racy and latency requirements. However, denser models tend to have up to 6 √ó  the size and twice the latency of smaller models to achieve increased accuracy of about 2-3%. Besides using dense models, ensembling [ 15 ] techniques have been used to achieve higher accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "[195] Zeyang Zhong, Urvashi Khandelwal, Omer Levy, and Dan Jurafsky. arXiv preprint arXiv:2405.03133 , 2024. Lory: Fully Differentiable Mixture-of- Experts for Autoregressive Language Model Pre-training.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles  PC2, PC4, PC5  and  PC8  under limited power budget, as depicted in Table II and Figure 1. The annotations indicate the consumed power ( ¬µ W), tile size and duplication count (e.g., 25x2x1) and power efÔ¨Åciency. With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of \n180 ¬µ W to 330 ¬µ W, and the throughput is increased by 85.7%.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "In the process of coreset construction we only preserve the coordinates of the centers and the radii of the clusters, and hence miss the coordinates of the points inside the clus- ters. However, any random distribution of the lost points in the cluster could provide us with a 2 ùëü ‚àí approximate repre- sentation of the original distribution (where  ùëü is the radius of the cluster; refer Figure 7a for a toy example). However, to achieve this, we need some extra information about the clus- ters.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "The response latency metric includes model inference latency, communication/network latency and syn- chronization overheads. Queries that do not meet response latency requirements (>700ms) are considered as SLO vio- lations. The cost metric is the billing cost from AWS, and the accuracy metric is measured as the percentage of requests that meet the target accuracy requirements.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "¬¥as  will be limited either by the live of the harvesting source ( ‚âà 20 ‚Äì 30 years for solar, ‚âà 10 ‚Äì 12 years for portable wind turbines), or the training hardware (typical life cycle of embedded devices are of range of 7 ‚Äì 10 years). We believe that the lifetime of  Us. Any battery backed system will be limited to the charging cycle of the batteries ( ‚âà 500 cycles for Li-ion batteries) which leads to a typical 18 to 24 months of life for such devices (compared to this, a super capacitor have a life of more than 100 years).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "This prediction involves translating the blocks of  F t ‚àí 1  according to  M t  and serves as the predicted frame. Each layer of the neural network encodes progressively finer details of  R t . The residual frame  R t , which contains only the differences not captured by the motion prediction, is then encoded using the layered neural network.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "This maximizes the accuracy of the teacher, and consequently minimizes the chance of the student model learning wrong labels. Note that the limited parameters of the student make it more sensitive to data Ô¨Ådelity and hence ensuring an accurate data labeling is very important for end to end classiÔ¨Åcation accuracy. The impact of wrong labeling is discussed in ¬ß V .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Furthermore, running inference for videos on edge devices is even more expensive than images due to the data volume and the power/energy constraints. There has been recent research in optimizing video analytics on edge devices, targeting smartphones, autonomous driving cars, and VR/AR headsets. These optimizations have been attempted at different levels, including model compression (pruning [2], [3], quantization [4]), compiler support [2], [5]‚Äì [7], runtime systems [7]‚Äì[13], and hardware enhancements [9], [14], [15].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "In  The Twelfth International Conference on Learning Representations , 2024. Minillm: Knowledge distillation of large language models. [56] Yanchu Guan, Dong Wang, Zhixuan Chu, Shiyu Wang, Feiyue Ni, Ruihua Song, Longfei Li, Jinjie Gu, and Chenyi Zhuang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Collaborative edge and cloud neural networks for real-time video processing. Philipp M. Grulich and Faisal Nawab. Proc.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "1 has a preference on FI and is accuracy-friendly, while decreasing  T moving  will skip more frames and improve the performance, the speciÔ¨Åc impact of the selected thresholds on accuracy drop, performance improvement, and energy reduction deserves further study. Also, as discussed in Sec. 2 affect the accuracy and performance, e.g., a larger  T moving  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "E Workings of Re-RAM Crossbar \nE.1 Re-RAM cross-bar for DNN inference: \nReRAM x-bars are an emerging class of computing devices that leverage resistive random-access memory (ReRAM) technology for efficient and low-power computing. Perform the forward pass with the updated dropout mask to obtain the output Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the Taylor expansion approximation of the neurons‚Äô impact on the loss, along with the QuantaTask optimization to handle energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "Water Resources Research , 43(1), 2007. [79]  Cheng Wang, Bhuvan Urgaonkar, Neda Nasiriani, and George Kesidis. Using burstable instances in the public cloud: Why, when and how?",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "However,  Kraken  is able to \nmaintain at least 99.5% SLO guarantee and spawns 50%, 34% and 15% less containers compared to  Arch ,  Fifer  and  Xanadu , respectively. Moreover, the reduced SLO target results in increased SLO violations across all policies. Reducing the SLO, in turn, can potentially reduce the batch sizes of functions as well.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "In A. Oh, T. Nau- mann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,  Advances in Neural Information Processing Systems , volume 36, pages 34661‚Äì34710. Curran Associates, Inc., 2023. [190] Shulin Zhao, Prasanna Venkatesh Rengasamy, Haibo Zhang, Sandeepa Bhuyan, Nachiappan Chi- dambaram Nachiappan, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "Input : Poses : pose sensors Input : Objs : set of virtual objects Output: Holo–¥rams : Generated holograms \n1  procedure  Intra _ Holo ( Poses ,  Objs ) // main \n2 Cam2ObjDists =  PoseEstimation ( Poses ) \n3 for  obj  in  Objs  do // approx. based on dist. 4 Œ≤  =  approxFactors (cam2ObjDists[obj]) \n5 Holograms[obj] = Algorithm1( 16  √ó  Œ≤ , obj) \n6 return  { Holo–¥rams } \nIn the  Inter-Holo  design, the hologram computation can be ap- proximated by identifying the region of focus from eye tracking.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 200,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication . 446‚Äì460. [60]  Fernando Moya Rueda, Ren√© Grzeszick, Gernot A. Fink, Sascha Feld- horst, and Michael ten Hompel.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "The addition of the recovery parameter (number of points per cluster) needs  4 more bits (in our experiments, we never observe any clusters having more than 16 data points) of data per cluster, bringing the total data communication volume to  42 Bytes , which is still a significant 5 . 7 √ó  less in comparison to the original 240 Bytes needed to communicate the raw data in our setup. However, since clustering based coreset construction is more expensive than the importance sampling based coreset construction, it is not always possible to build a recoverable coreset at the edge, unless we figure out a to recover the lost points while we perform importance sampling.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "Discussion:  Although  Origin  is proposed and works for energy harvesting wireless sensor networks, it can also be used with battery-powered or hybrid (a combination to battery powered and EH) systems to minimize the energy footprint while maximizing the accuracy. Furthermore, it uses multiple sensors effectively and hence poses minimum risk if one of the sensors fails. This makes  Origin  versatile and suitable for systems whose intermittence comes from either or both of power or device reliability limitations, both of which will be key factors in real-world IoT deployments.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "In the  Projection Computation  stage (refer to  b  in Fig. 3), we use the transformation matrix ( T  ) to generate the mapping ( P ) between the  360 ¬∞ frame coordinates and the  2 D  FoV frame coordinates. At any instance, a user is only concerned about the FoV pixels in the entire  360 ¬∞ frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Next, the new inputs are fed into Step  4  to perform the PI (details are in Sec. IV-B4), and Ô¨Ånally, we report the output result to the application, as shown in the blue BBoxes in Step  5  . Since Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "However, certain jobs could be too big to execute atomically on harvested en- ergy. For ex- ample, for a DNN execution, the jobs could be CONV2D (  C1  ), batch normalization (  C2  ), etc. These jobs form the functional program execution DAG.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Strict Relaxed 0 \n25 \n50 \n75 \n100 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace. Figure 17:  Cost savings of Cocktail for Sentiment Analysis. of 0.5% than  Clipper  (not plotted).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "2020. In  ACM SIGGRAPH 2020 Emerging Technologies (SIGGRAPH ‚Äô20) . Neural Holography.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "In  Eurosys , 2017. Proteus: Agile ML Elasticity Through Tiered Reliability in Dynamic Resource Markets. [43]  Johann Hauswald, Michael A. Laurenzano, Yunqi Zhang, Cheng Li, Austin Rovinski, Arjun Khurana, Ronald G. Dreslinski, Trevor Mudge, Vinicius Petrucci, Lingjia Tang, and Jason Mars.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Figure 3: Dataset study. 0 \n0.5 \n1 \n0 0.5 1 \nPupi Postion Y \nPupil Position X \n0 \n0.5 \n1 \n0 0.5 1 \nPupil Position Y \nPupil Position X \n0 \n0.5 \n1 \n0 0.5 1 \nPupil Position Y \nPupil Position X \nUser1: \nUser2: \nUser3: \n(b) User eye tracking study. ObjSize \n(a) Object study.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "IEEE Micro , 40(2):17‚Äì24, 2020. [103] Eitan Medina and Eran Dagan. Habana labs purpose-built ai inference and training processor ar- chitectures: Scaling ai training systems using standard ethernet with gaudi processor.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Unlike conventional storage servers,  Salient Store  discerns between the ‚Äúdata path‚Äù and the ‚Äúresource path‚Äù for system I/O calls, translating these requests into CSD-specific functions. Edge Server \nPCIe Root COmplex \nFPGA \nCSD \nCSD \nFPGA \nAccelerator \nFigure 2: High-level design of the  Salient Store  edge server - it consists of the accelerated video analytics compute along with computational storage and classical storage drives. Data-flow Reorganization in  Salient Store  : At the core of  Salient Store  ‚Äôs design is the ‚Äúdata-aware‚Äù reorganization of compute processes.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "Maureen Daum, Brandon Haynes, Dong He, Amrita Mazumdar, and Magdalena Balazinska. Tasm: A tile-based storage manager for video analytics. In  2021 IEEE 37th International Conference on Data Engineering (ICDE) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Github copilot. \" [49] Mohammad Gokaslan, Girish Mishra, and Andrea Madotto. https://github.com/features/copilot \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "He has an extensive research background and publication record in efficient methods for LLMs such as LLM pruning (NAACL 2024), LLM parameter-efficient finetuning (ACL 2022, EMNLP 2023), long-context LLMs (ACL 2022, NeurIPS 2024), data selection for LLM in-context learning (ICLR 2023). Rui Zhang (Co-PI):  Zhang‚Äôs research expertise includes LLMs, trustworthy human-centered AI, and AI for science. He will lead Thrust-2 and collaborate with Das and Zhang in Thrust-4.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "This further motivates us to look for opportunities in the data distribution to improve the compression ratio. As the DNN models were designed to infer on the full data, we retrain the DNN models to recognize the compressed rep- resentation of the data and infer directly from that (both from the importance sampling and clustering). As the coreset for- mation algorithms are fairly simple [ 7 ,  8 ,  36 ,  37 ], it does not take much latency or energy to convert the raw sensor data into the coreset form even while using a commercial-off- the-shelf micro-controller (like TI MSP430FR5969 [ 66 ]).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "30 \n35 \n40 \n45 \n50 \n0 0.2 0.4 0.6 0.8 1 \nPSNR (dB) \nBits per Pixel \nH264 H265 Salient Store \nFigure 8: Compression and Recovery efficiency. Furthermore, as we can see in Fig. 9, HEVC takes significantly more latency compared to  Salient Store  and therefore not entirely suitable for high frame-rate applications with resource constraints.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "[24]  James Cadden, Thomas Unger, Yara Awad, Han Dong, Orran Krieger, and Jonathan Appavoo. SEUSS: skip redundant paths to make serverless fast. 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Recall that, Frame-1, as the base frame, has to do the full inference (Step  1  ), and output the feature maps for each layer (Step  2  ). As for Frame-3, only the RoIs (in purple) are passed to the DNN layers (Step  3  ), and we generate the corresponding PI-outputs (in yellow) in Step  4  . Next, as discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "ITU-T Recommendation H.265. Hello bytes, bye blocks: Pcie storage meets compute express link for memory expansion (cxl-ssd). Myoungsoo Jung.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "[112] Sai Prashanth Muralidhara, Lavanya Subramanian, Onur Mutlu, Mahmut Kandemir, and Thomas Moscibroda. Reducing memory interference in multicore systems via application-aware memory channel partitioning. In  Proceedings of the 44th annual IEEE/ACM international symposium on microar- chitecture , pages 374‚Äì385, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "https://developer.nvidia.com/rtx/dlss , 2024. James Jie Pan, Jianguo Wang, and Guoliang Li. Ac- cessed: 2024-08-02.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "[6] Aaron Harlap, Andrew Chung, Alexey Tumanov, Gregory R. Ganger, and Phillip B. Gibbons. 2018. Tributary: spot-dancing for elastic ser- vices with latency SLOs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "In addition, we also discuss the  our design‚Äôs versatility  on other 360 ¬∞ video representation formats. Energy Savings : Overall, our software implementation EA+AE on GPU can save 54% computation, which translates to 28% total energy savings, compared to the baseline. Com- pared to the state-of-the-art hardware-modiÔ¨Åed PTU, our soft- ware implementation can still provide 16% computation and 8% total energy savings.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "The proposed ar- chitecture is named  D¬¥ej`a View , a play on the word D¬¥ej`a vu, as it uses previous or  already seen  views. To the best of our knowledge, this is the Ô¨Årst work that leverages head orientation and correlation between eyes to do efÔ¨Åcient memoization and in turn result in compute reduction in the VR video streaming domain. The major  contributions of the paper can be summarized as follows: \n‚Ä¢  From an open-source 360¬∞ VR video dataset [3],  we identify both temporal reuse and spatial locality that exists in user behavior .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "¬¥as to effectively perform more computation with an intermittent power source. This allows  Us. 11  shows its ability to maximize the instantaneous power utilization and scale the number of tiles.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "The research team is planning to organize summer activities with high school students and teachers in the context of this project as well. More specifically, to complement the summer camp with a more in-depth exploration for the students, we will work with the local school science teachers and students to develop the inquisitiveness of the potential of LLM concepts and develop simple but interesting LLM-based applications to attract young students. For example, PI Zhang will lead a workshop for high school students featured with an LLM and society seminar and a Computational Linguistics Olympiad competition to inspire students‚Äô interests in CS and AI.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "2 √ó  and  ‚âà 6 . 1 √ó , respectively. This paper pro- vides a comprehensive overview of the potential of CSDs to revolutionize storage, making them not just data repositories but active participants in the computational process.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "The weight matrix is designed by considering the accuracy of each model for each class, giving us a weight matrix of  L √ó N  dimension, where  L is the number of unique labels and  N  is the number of models used in the ensemble. For instance, if there are 3 unique classes predicted by all the ensemble models, we sum the weights for all models of the same class. The majority vote is calculated as a sum of model-weights for each unique class in the individual prediction of the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "Computational Wave Optics Library for C++: CWO++ Library. Computer Physics Communications  (2012), 1124‚Äì1138. [56]  Jeffrey H. Shuhaiber.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "However, storage systems are not typically built to cater towards the ML applications, and now that compression becomes a ML application with the use of stacked neural codecs, building the right storage stack along with computational storage devices becomes an important problem. Evolution of Computational Storage:  The advent of CSDs represents a paradigm shift, bringing computation closer to storage. These devices, by integrating CPUs or FPGAs into the storage \n4 We do  not  consider H265 here as currently in commercial systems H264 is the standard and typically enjoys hardware support.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Below, we provide an overview of the RCA interfaces and our system integration model and then discuss the two main steps to map a CNN to ResiRCA:  ofÔ¨Çine compilation  and  runtime execution . A. ResiRCA overview \nFigure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system. S YSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "of the 11th Int. [84] K. Seyerlehner, G. Widmer, and P. Knees, ‚ÄúFrame level audio \nsimilarity-a codebook approach,‚Äù in  Proc. Conf.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands ¬© 2020 Association for Computing Machinery. ACM ISBN 978-1-4503-8204-5/20/12...$15.00 https://doi.org/10.1145/3429880.3430093 \nACM Reference Format: Jashwant Raj Gunasekaran, Cyan Subhra Mishra, Prashanth Thi- nakaran, Mahmut Taylan Kandemir, and Chita R. Das. 2020.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "The proposed scalable cross-layer framework will enable the exploration of novel architectural and system-level solutions in addressing the LLM design challenges. In particular, we expect each individual thrust of our project to form a ‚Äúbaseline‚Äù upon which further extensions and enhancements can be built. Specifically, our algorithmic layer will ad- vance state-of-the-art in LLM models and algorithms and generate an extensible framework in which more futuristic EoE networks can be explored.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "b  If exploiting the  EA  opportunity is not possible, we take advantage of the  AE  opportunity, by performing computation for only one eye (and construct the result for the other eye). Intuitively, as mentioned earlier in Sec. C. InterFrame-IntraEye (EA) Computation Optimization \nWe plan to leverage the  EA  opportunity when the user‚Äôs head orientation does not change.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Upon closer examination, we see that this is due to functions having different degrees of  Commonality and  Connectivity . This difference is lesser for the other applications. From Table 5, it can be seen that  Comm Only  spawns 8% more containers than  Conn Only  for  Social Network .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Moreover, more than 40% of requests show significant variability in inter- arrival times. We also spawn con- tainers much more in advance than the predicted arrival time and also keep them alive for at least a minute before evicting them from memory, to account for arrival unpredictability. To deal with such traces, we modified  Kraken ‚Äôs load prediction model to predict future request arrival times, owing to the sparse nature of the trace.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "All these applications rely on high quality PC capturing, processing and displaying for a more realistic experience. Additionally, with the new generation mobile phones, capable of capturing PC and then streaming them into an AR/VR enabled head mounted displays (HMDs), capturing 3D PC now is becoming as common as capturing a photograph. With this trend, the PC business is expected to reach a 10 Billion dollar industry by 2024 [ 71 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Implications of Public Cloud Resource Heterogeneity for Inference Serving WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands \n3 How to Design Self-Managed ML Prediction Serving System? The objectives from Section  2  strongly motivate the need for a self-managed ML-prediction system that avoids the over-provisioning problem in VMs by efficiently blending serverless functions  with VMs. At the same time, right-sizing the number of requests in VMs and correctly configuring serverless functions  is quintessential to satisfy the three pri- mary application constraints: cost, latency, and accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "Thus, using  serverless func- tions  for such scenarios will not drastically reduce cost. From our simulation experiments we observe that  mixed  procurement did not reduce cost of Wiki trace. This is because the difference between peak-to-median in the traces are not large and therefore more functions get offloaded to  serverless functions .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "15 \nC.1.3 Loop Tiling \nThe algorithm uses loop tiling to divide the computation into smaller blocks that can be managed between power interruptions. C.1.2 Function Definitions \n‚Ä¢  SAVE_STATE : Saves the current indices and the partial result of the output matrix  C  to non-volatile memory to allow recovery after a power interruption. ‚Ä¢  LOAD_STATE : Retrieves the last saved indices and partial result from non-volatile memory to resume computation.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "This process benefits significantly from residual learning techniques, where each successive layer in the network aims to correct errors from the previous layers, thereby enhancing the reconstructed video quality incrementally with each additional decoding layer. Moreover, neural codecs excel in adaptability, offering robust performance across variable bandwidth and computational conditions, making them particularly suited for real-time streaming environments. These codecs can operate on generic computational hardware, such as GPUs and FPGAs, without the need for specialized video processing units, thus broadening their applicability across different device platforms.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "[82] Youngjae Kim, Brendan Tauras, Aayush Gupta, and Bhuvan Urgaonkar. A low latency router supporting adaptivity for on-chip interconnects. In  Proceedings of the 42nd annual Design Automation Conference , pages 559‚Äì564, 2005.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "We would also like to thank Dr. Jack Sampson, Dr. Aasheesh Kolli and Dr. Timothy Zhu for their feedback on this paper. R EFERENCES \n[1] Arm Holdings, ‚ÄúArm Frame Buffer Compression (AFBC).‚Äù ‚Äùhttps: //developer.arm.com/architectures/media-architectures/afbc‚Äù, 2019. [2] K. Boos, D. Chu, and E. Cuervo, ‚ÄúFlashBack: Immersive Virtual Reality on Mobile Devices via Rendering Memoization,‚Äù in  Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services , ser.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "The rsa algorithm. RSA laboratories , pp. 1‚Äì11, 2009.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 21,
    "augmented": false
  },
  {
    "text": "The occupied DRAM size is mainly determined by  P buff . In fact, with a VR screen size of  1 ,  000 √ó 1 ,  000 , one  P buff  occupies  ‚âà 8 MB  in DRAM. Since this puts a high demand on memory, one edge VR headset cannot afford to memoize for all possible head orientations.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "[67] Shaomang Huang, Jianfeng Pan, and Hanzhong Zheng. arXiv preprint arXiv:2311.05232 , 2023. A survey on hallucination in large lan- guage models: Principles, taxonomy, challenges, and open questions.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "The overall design of our proposed  HoloAR framework is illustrated in Fig. 4.2 HoloAR Overview \nDriven by the above discussion and the potential approximation opportunities presented by the  Inter-Holo  and  Intra-Holo  scenarios, we propose  HoloAR , a novel framework for holographic process- ing in AR applications to improve  both  the performance and en- ergy consumption of the hologram processing, without affecting user experience. HoloAR  aims to reduce the amount of hologram computations as much as possible by carefully approximating the hologram computing for select objects, while maintaining an ac- ceptable video quality.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "Yet, the expansion of these technologies to encompass large-scale storage stacks and the integration of CSDs into conventional storage systems, particularly for ML applications, remains a significant challenge and an open area of research. However, there has been a significant push towards enabling more complex workloads, including query processing on CSDs. Efforts to adapt CSDs for machine learning applications, albeit limited in scope to classical learning and data management, mark a crucial step forward.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Discussion:  For applications that are latency tolerant, we can potentially redirect requests from failed instances to existing instances, which would lead to increased tail latency. The results we how are only for latency intolerant applications. Note that, the ensembles used in our experiments are at-least 4 models or more.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "We show that uniformly scaling resources for all models in the ensemble leads to over-provisioning of resources and towards minimizing it, we build a distributed weighted auto-scaling policy that utilizes the  importance sampling technique to proactively allocate resources to every model. 2 Cocktail is ascribed to having the perfect blend of models in an ensemble. Further,  Cocktail  leverages transient VMs as they are cheaper, to drastically minimize the cost for hosting model- serving infrastructure in a public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "[4]  S. Ayukawa, N. Tokudome, S. Enokida, and T. Nishida, ‚ÄúTime- series lidar data superimposition for autonomous driving,‚Äù  Proc. of ICT-ROBOT, ThBT3 , vol. 3, 2016.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "[43]  Marek Kowalski, Jacek Naruniec, ‚ÄúLiveScan3D-Hololens,‚Äù \n‚Äùhttps://github.com/MarekKowalski/LiveScan3D-Hololens‚Äù , 2020. [45]  S. Martin, M. Stefan, A. Karl  et al. [44]  Marek Simonik, ‚ÄúRecord3D-Record your own 3D Videos!‚Äù \n‚Äùhttps://record3d.app/‚Äù , 2021.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "mean Average Precision (mAP) : The accuracy of the DNN models for object detection can be quantiÔ¨Åed by mAP [40], to evaluate how well the estimated results match the ground-truth. We implemented our FI and PI on top of the ncnn library [5]. To get mAP, the precision for each class is Ô¨Årst calculated across all of the Intersection over Union (IoU [41]) thresholds, and the Ô¨Ånal mAP will be the averaged precision of all classes (the higher, the better).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. baseline InterHolo IntraHolo InterIntraHolo \nExec. Latency (ms) \nHoloCompute Overhead \n876.81 \n430.15 393.07 \n(b) Exec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Although we use specific combinations of applications and traces to highlight the improvements, the results are similar for other workload mixes as well. This results in the majority of requests getting queued at the containers. 6.1.3 Analysis of Key Improvements : This subsection fo- cuses on the key improvements offered by  Kraken  in terms of Container Utilization, Response Latency Distribution and Energy Efficiency.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Since the Relaxed  workload has much lower accuracy constraints, smaller models are able to singularly achieve the accuracy requirements at lower latency. Accuracy violations : The accuracy is mea- sured as a moving window average with size 200 for all the requests in the workload. Accuracy Met (%) Scheme Strict Relaxed InFaas 21 71 Clipper 47 89 Cocktail 56 96 \nTable 6:  Requests meeting target accuracy averaged for both Trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "The Extended- Round-Robin policy (ERR) [ 47 ] takes a store-and- execute approach, and the number associated repre- sents the ratio of store cycles vs execute cycles (e.g. RR3 is 3 store cycles followed by 1 execute cycle). The ‚ÄôBaseline‚Äô model is a fully powered system with no energy restrictions, and the quantized model runs on harvested energy using a RR12 policy.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "[56] Yanchu Guan, Dong Wang, Zhixuan Chu, Shiyu Wang, Feiyue Ni, Ruihua Song, Longfei Li, Jinjie Gu, and Chenyi Zhuang. Intelligent virtual assistants with llm-based process automation, 2023. [57] Nikhil Gupta and Jason Yip.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Even though there have been significant research in accelerating both compression (Collet & Kucherawy, 2018; Chen et al., 2021) and encryption (Milanov, 2009; Rawat et al., 2019; Yang et al., 2015), operating on large-scale video data often demands more resource than what edge servers could afford (Mishra et al., 2024). Now that we know Classical approach of video data storage involves encoding and encrypting the video data before storing them in a redundant storage array (Huang & Xu, 2014; Fan et al., 2022; Korkiakangas, 2014; Yue et al., 2016) which consumes significant resources (refer Table 1). Co-locating this compute along with the inference and training would definitely hinder the critical path.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 197,
    "augmented": true
  },
  {
    "text": "These solutions operate on augmented commercial off the shelf micro-controllers [ 66 ], or specialized products with traditional architecture [ 62 ], and rely on their efficient prediction of power failure. To tackle this, a significant amount of work has been done on check-pointing, and compiler level tweaks, which help maximize the forward progress on such devices [ 39 ,  43 ,  44 ]. While these software optimizations and judicious use of persistent storage works for smaller workloads like keyword spotting (e.g  \"Ok Google\" detection), they are inefficient for complex workloads (e.g.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "These stages include the data loading phase, the modular polynomial multiplication via the SDMM unit, and the final accumulation registers. Data is input into the HSPM in a serial-to-parallel conversion process, while the outputs, after undergoing addition operations, are retrieved serially through an address signal. Central to the Ring-Learning with Errors (R-LWE) based Public Key Encryption (PKE) is the equation d  =  a  ¬∑  b  +  c .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "\"https://medium.com/demagsign/meet-the-humans- of-the-future-holograms-digital-humans-and-deep-fakes-35024b881545\". [15]  Stuart Golodetz, Michael Sapienza, Julien Valentin, Vibhav Vineet, Ming-Ming Cheng, Anurag Arnab, Victor Adrian Prisacariu, Olaf Kaehler, Carl Yuheng Ren, David W. Murray, Shahram Izadi, and Philip H.S. Torr.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "[53]  Romain Lerallut, Diane Gasselin, and Nicolas Le Roux. Large-scale real-time product recommendation at criteo. In  Proceedings of the 9th ACM Conference on Recommender Systems , pages 232‚Äì232, 2015.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "491, p. 229622, 2021. [54] Markets and Markets, ‚ÄúSmart cities market analysis, industry size and \nforecast,‚Äù  https://www.marketsandmarkets.com/Market-Reports/smart- cities-market-542.html#: ‚àº :text=The%20global%20Smart%20Cities% 20Market,drive%20the%20smart%20cities%20market , 2022, (Accessed on 08/04/2023). [55] M. McCloskey and N. J. Cohen, ‚ÄúCatastrophic interference in connec- \ntionist networks: The sequential learning problem,‚Äù in  Psychology of learning and motivation .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "3:  Different Ô¨Çavors of (extended) round-robin scheduling and their execution Ô¨Çow. Each policy is named after the num- ber of nodes the cycle has, i.e. RR3 has 3 nodes with no no-ops and RR6 has 3 nodes with 3 no-ops.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "However, there has been signiÔ¨Åcant recent development in portable wind turbines [ 96 ], which can be deployed on rooftops, can work with  ‚â• 5 mph  wind speed, and can provide power equivalent of 15 solar cells. Therefore, similar technologies can be used to augment the harvesting mechanism. Deployment Training Completed \nMean Power Consumed (W) \nMean Power \nWasted (W) \nCarbon Footprint (lbs/yr) Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Additionally, sometimes sudden changes in subsequent frames (e.g., with a new object in the frame), require adaptive decisions, which cannot be achieved by Euphrates [9] and DeepCache [8]. Also, as opposed to Euphrates, one may prefer to use existing hardware, due to considerable development effort and associated cost with customization. Unlike the work presented in this paper, none of the four prior schemes mentioned in Table I performs well in all features listed in the table.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "However, as we did not want to burden the host device with complex computation, the aggregation task is very na¬®ƒ±ve in that it just performs recall and incorporates no intelligence. AASR intelligently takes advantage of multiple DNNs (by bringing in activity aware scheduling), leverages the workload (by considering the activity continuity via recall and extended round-robin strategies), and also poses minimal overhead on the host device for running aggregation. Hence, there is an opportunity to also improve the ensemble technique.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "While prior efforts have attempted to address this problem through acceleration using a GPU or FPGA, none of them has analyzed the  360 ¬∞  VR pipeline to examine if there is any scope to optimize the computation with known techniques such as memoization. Thus, in this paper, we analyze the VR computation pipeline and observe that there is signiÔ¨Åcant scope to skip computations by leveraging the temporal and spatial locality in head orienta- tion and eye correlations, respectively, resulting in computation reduction and energy efÔ¨Åciency. Thus, improving the computational efÔ¨Åciency of the video processing pipeline in a VR is critical.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "This is done using a rectifier, which transforms alternating current (AC) into a more usable direct current (DC). 3. Power Conditioning : Once energy is harvested, it often needs to be converted and stabilized for use.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "3) What are the Pros and Cons? :  The proposed inter- frame attribute compression further improves the compres- sion efÔ¨Åciency by skipping the redundant storage for the same/similar segments matched across frames, with extra latency overhead (but still much better than the state-of-the- art ‚Äì  139 ms  vs  5 . IV-A 2  for intra-frame compression, to further compress these deltas.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "It can be seen that mixed scheme has similar cost to reactive but it reduces SLO vi- olations by up to 60%. This is because, the mixed scheme offloads request in the peak to serverless functions. However, the  Paragon  scheme is 10% more cost-effective than mixed and at the same time ensures similar SLOs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. and starts Ô¨Çushing the results for backup.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "5 √ó speedup compared to the software based RSA algorithm. While we do agree that the lattice-based encryption has more overheads compared to the RSA algorithm, the benefit of being ‚Äúquantum-safe‚Äù outweighs the minimal cost incurred on encryption. Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Energy Costs and Future Utility: Participation incurs energy costs, reducing the sensor‚Äôs capacity for future tasks. Additionally, sensors must consider the discounted value of future utility. Let  C i ( t )  represent the cost component: \nC i ( t ) =  e i ( t ) +  Œ≤V i ( t  + 1) , \nwhere  e i ( t )  is the total energy expenditure for participa- tion, encompassing data capture, inference computation, and communication: \ne i ( t ) =  e cap ( SNR i ( t )) +  e inf  +  e comm .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "This also determines the ‚Äúorder of computation‚Äù, which is Ô¨Årst  T  , then  P , and Ô¨Ånally  F . ‚Ä¢  Input (in-)Variability:  It should be clear from the discus- sion above that  T 1 ,  T 3  T 4 , and  T 5  can be determined apriori. However,  T 2  can change at runtime, and if any element in  T 2 is changed, the transformation matrix needs re-computation \nFig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "Thus, it is important to keep learning and adapting to the user behavior. Since, we cannot keep re-training the DNNs because of their resource constraints, we choose to periodically update the conÔ¨Ådence matrix. The initial conÔ¨Ådence matrix, derived from the test cases, would be programmed into the host device.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "However, since clustering based coreset construction is more expensive than the importance sampling based coreset construction, it is not always possible to build a recoverable coreset at the edge, unless we figure out a to recover the lost points while we perform importance sampling. Importance Sampling Coreset Recovery:  Unlike cluster- ing, when we construct a coreset with importance sampling, we typically have no information regarding the lost data points. We hypothesize that the dropped sample should con- tain, although not important, sensor specific artifacts.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "However, as we can see from  6  in Fig. 3a, only the bounding boxes (in red) and the MV (in black) are meaningful, and the remaining regions (in white) are similar with those of previous frames, which, intuitively, do not provide as much contribution to detect the ‚Äúposition change‚Äù event denoted by the colored regions. This observation reveals an opportunity to perform partial inference (PI)  by operating only on the bounding boxes and MV regions.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "In  CVPR Workshop on the Future of Datasets in Vision , volume 2. sn, 2015. Intel Corporation. Smart city technologies and intelligent transportation systems are helping cities absorb growing populations, overcome congestion, and create sustainable futures.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Note that the tail latency of  Clipper  is still higher than  Cocktail  because  Clipper ensembles more models than  Cocktail , thereby resulting in straggler tasks in the VMs. In contrast, both Cocktail  and  Clipper  can reach the accuracy at lower latency due to ensembling, thus minimizing SLO violations to 1%. Also, the tail latency is higher for Twitter trace (Figure  7c , 7d ) owing to its bursty nature.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Note that, the  product  of these Ô¨Åve transforms gives us the Ô¨Ånal transformation matrices ( T L  and  T R ), which together convert the  3 D  coordinates of the  360 ¬∞ frame to the  2 D  coordinates suitable for HMD. Mathematically, the transformation matrix for each eye is shown in Equation 1. T L = T 5  √ó  T 4  √ó  T   L 3   √ó  T 2   √ó  T 1 T R = T 5  √ó  T 4  √ó  T   R 3   √ó  T 2   √ó  T 1 (1) \nThese Ô¨Åve transforms are of dimension of  4 √ó 4  ( 3  dimensions for rotation;  1  for translation), thus producing  4  √ó  4  T L  and T R  matrices [27].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "[ 50 ], [ 73 ] at a much lower rate, necessitates informed decisions regarding deployment placement and sampling rates. Secondly, the issue of  functionality  comes to the fore, requiring effective continuous learning from often non- Independently and Identically Distributed (non-IID) data. Such non-IID data distributions, evident in tasks like standard trafÔ¨Åc monitoring with varied class observations (e.g., more cars than buses, all frames having  STOP  signs), may introduce sampling bias  [ 70 ], [ 74 ] in the network.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "Especially, for each P-block, we Ô¨Årst calculate its 2-Norm distance to its  best matched block  in I-frame. We then compare this distance with a preset threshold (e.g., 300 7 ) to determine if this segment can be approximated by  direct reuse ; otherwise, we mark it as an post-intra-encoded block. Also, the total number of blocks is 50000, and the search step is set to be the size of the current P-block (i.e., to Ô¨Ånd the best matched block for current P-block, each time, we traverse the search region in the reference frame by this step size).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "Furthermore, the development of energy-efficient, adaptive systems like NExUME is aligned with the growing need for sustainable computing practices across all disciplines of technology. It challenges the machine learning community to consider not only the accuracy and efficiency of algorithms but also their environmental impact and accessibility, ensuring a broader positive social impact. 10 \nReferences \nSayed Saad Afzal, Waleed Akbar, Osvy Rodriguez, Mario Doumet, Unsoo Ha, Reza Ghaffarivar- davagh, and Fadel Adib.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "The possible alternate solu- tions being battery-backed custom HW [ 16 ], battery-backed commercial GPU and Ô¨Åxed power budget with store and \n902 \nAuthorized licensed use limited to: Penn State University. TABLE  III  depicts some of such possible comparison points. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "298 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "VI-A ) used for our analyses, e.g., experimental platform, dataset, and different designs (Sec. VI-B ). We then compare those design schemes on our platform (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "In addition, we design a scheme named Paragon on top of AWS platform, which incorporates some of the proposed design choices. 3. We propose detailed design choices that can adopted to- wards designing a self-managed inference-serving system.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Further, we also observed in Sec. 3 that, the main reason behind this is that the number of depth planes affects the number of synchronizations between parallel executions, and determines the amount of com- putation required to generate the holograms. Unlike prior works targeting at optimizing the efficiency of the hologram program- ming itself by proposing alternative hardware [ 32 ,  35 ], we primarily focus on exploring the intrinsic approximation opportunities (dis- cussed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Let us now consider the example in Fig. 3  a  that, there also exists spatial locality for attribute compression, which can be identiÔ¨Åed with the help of the Morton code. Recall from Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "example using a state-of-the-art inter-frame compression technique [ 13 ] and our proposal, and study the following important questions: i)  what  is the opportunity?, ii) how do we  capture  and  exploit  such opportunity?, and iii) what are the potential  beneÔ¨Åts ? Figure 7: Inter-Frame attribute compression example. A. Inter-Frame Attribute Compression \n1) What is the Temporal Opportunity?",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Abstract \nThe advent of transformer-based architectures [157] has revolutionized the field of natural language pro- cessing (NLP), exhibiting unprecedented capabilities in understanding the nuances of human language, maintaining rich context, and generating human-like responses. At the forefront of these transformative advancements are Large Language Models (LLMs), which have led to a paradigm shift in NLP and artifi- cial intelligence (AI) at large. Their seamless integration into everyday life across diverse domains‚Äîsuch as virtual assistants [12,16,51], customer service chatbots [6,121], code generation tools like GitHub Copi- lot [48], and knowledge management systems like NotebookLM [52]‚Äîhas profoundly impacted how we interact with technology.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 166,
    "augmented": false
  },
  {
    "text": "Ilker Bozcan and Erdal Kayacan. 119‚Äì135, 2022. Au-air: A multi-modal unmanned aerial vehicle dataset for low altitude traffic surveillance, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "2.2 Motivation \n2.2.1 What is the Major Bottleneck? To identify the major performance bottlenecks in the current AR headsets, we characterized the execution latency of the software pipeline (discussed above in Fig. 1c) on a typical edge prototype [ 36 ] running a set of state-of-the-art AR-related tasks [ 19 ,  26 ,  49 ,  50 , 53 ], and compared the collected results against ideal execution latencies for the same set of tasks (i.e., the maximum latency within which the task needs to finish before its next invocation).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "We then introduce our proposed intra-frame geometry and attribute compression schemes which are discussed in detail in Sec. A. Intra-frame Compression \nIn this subsection, we Ô¨Årst present the state-of-the-art intra- frame geometry and attribute compression techniques and discuss their inefÔ¨Åciencies. IV-B  and Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "2012. [20]  M. A. Awad and I. Khalil. The VLDB Journal  17, 3 (2008), 401‚Äì417.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "For small-scale applications with strong harvested power supply, discarding the incomplete execution may have only modest overheads. However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle. Activation solution transition FSM \nThe convolution computations of one inference may not be completed while transitioning to a new power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "It is also possible to use bigger VMs, which can handle more concurrent requests compared to m4-large, thus mini- mizing the total number of VMs used. However, we observe that the pricing of EC2 VMs is a linear function of the VM size in terms of compute capacity and memory. Hence, nor- malized by number of requests, bigger VMs would still incur similar costs as smaller VMs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "III-B  that Morton codes can reveal opportunities for both geometry similarity (owing to the fact that the Morton code itself is the reÔ¨Çection of the geometrical relationship between points) and attribute similarity (the RGB attributes of two adjacent points are more likely to be similar). Unlike the prior octree-based works [ 56 ], [ 72 ] which mainly focus on the compression efÔ¨Åciency (i.e., attaining higher compression ratio and good quality simultaneously) with sequential updates and longer execution latency, in this work, we focus primarily on speeding up the PCC at the  edge and achieving the real-time target mentioned above without losing much quality or compression ratio. A. Intra-frame Compression \nIn this subsection, we Ô¨Årst present the state-of-the-art intra- frame geometry and attribute compression techniques and discuss their inefÔ¨Åciencies.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 183,
    "augmented": false
  },
  {
    "text": "The mask values are determined using a sigmoid function to ensure they lie between 0 and 1: m i  =  œÉ ( z i ) where  z i  are learnable parameters and  œÉ ( ¬∑ )  is the sigmoid function. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output. Apply the dropout mask during the forward pass.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "[26]  Joohwan Kim, Michael Stengel, Alexander Majercik, Shalini De Mello, David Dunn, Samuli Laine, Morgan McGuire, and David Luebke. (2019). 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "8 , T missed  = 0 . C. Results \nWe present and compare the execution latency and energy consumption (via BatteryManager API in Android Studio) when performing inference for each video under the three conÔ¨Ågurations described in Sec. V-A, as well as the mAP \n3 We experimentally set  T moving  = 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "https://doi.org/10.1145/3429880.3430093 \n1 Introduction \nSustained advances in ML has fueled the proliferation of emerging applications such as product recommendation sys- tems, facial recognition systems, and intelligent personal assistants [ 7 ]. ACM, New York, NY, USA,  6  pages. In  Workshop on Serverless Computing (WoSC‚Äô20), December 7≈õ11, 2020, Delft, Netherlands.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Specifically, the weights are arranged in a way that mimics the convolution operation, such that each weight corresponds to a specific location in the input signal. The input signal is applied to the x-bar in the same way, but the weights are now applied in a more structured way. To perform convolution, ReRAM x-bars use a similar approach, but with a more complex circuit.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "These additional energy savings come from the computational reduction by partial inference, rather than computing for the entire frame. 9c. 1081 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "205‚Äì218. [43]  Paulo Silva, Daniel Fireman, and Thiago Emmanuel Pereira. 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "(2009)) states that for con- vex, Lipschitz-smooth objectives and unbiased gradient oracles, SGD converges to a stationary point if the step sizes  { Œ± k }  decrease at an appropriate rate. A common choice is  Œ± k  = 1 / ‚àö \nk , but any diminishing sequence with P \nk   Œ± k  =  ‚àû and  P \nk   Œ± 2 k   <  ‚àû works. Under these conditions, we have: \nlim k ‚Üí‚àû E [ J ( Œ∏ k )] =  J ( Œ∏ ‚àó ) and lim k ‚Üí‚àû E [ ‚à•‚àá J ( Œ∏ k ) ‚à• ] = 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 169,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 7b, overall, the  Inter-Holo  scheme provides a 1 . 15 √ó  speedup compared to the baseline.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "As previ- ously discussed in Section  3 , spot instances interruptions can lead to intermittent loss in accuracy as certain models will be unavailable in the ensemble. However for large ensembles (5 models are more), the intermittent accuracy loss is very low. Figure  12b  plots the failure analysis results for top three constraints by comparing the ensemble accuracy to the target accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "[10] M. Riera, J.-M. Arnau, and A. Gonz¬¥alez, ‚ÄúComputation Reuse in DNNs by Exploiting Input Similarity,‚Äù in  Proceedings of the International Symposium on Computer Architecture , 2018, p. 57‚Äì68. [11] L. N. Huynh, Y. Lee, and R. K. Balan, ‚ÄúDeepMon: Mobile GPU- Based Deep Learning Framework for Continuous Vision Applications,‚Äù in  Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services , 2017, p. 82‚Äì95. [12] P. Guo and W. Hu, ‚ÄúPotluck: Cross-application approximate deduplica- tion for computation-intensive mobile applications,‚Äù p. 271‚Äì284, 2018.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 181,
    "augmented": true
  },
  {
    "text": "An ideal system would be at the point (1,1). It can be observed from these results that the proposed  ResiSchedule  strategy can make good use of the  Piezo source when it does exceed the minimal activation thresholds, though the very low duty cycle yields very low throughput. 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 \n0 0.10.20.30.40.50.60.70.80.9 1 \nPower Utilization \nPower efficiency \nPiezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 170,
    "augmented": false
  },
  {
    "text": "Each user has unique expressions of behaviour classes reÔ¨Çected in the sensor data. For example, gaits of two different people may signiÔ¨Åcantly vary, and might be entirely different from the training data. Thus, it is important to keep learning and adapting to the user behavior.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "The duplication sensitivity results are presented in Section VI-F. ‚Ä¢  Regarding the throughput absolute values, the results with the power sources of  Thermal  and  TV-RF  are much higher than those with the others, which is constant with the power strength illustrated in Figure 4. B. Energy efÔ¨Åciency \nWe evaluate energy efÔ¨Åciency by measuring MAC operations per Joule, as shown in Figure 9.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Due to the unavailability of the hardware RTL, we estimated its energy consumption based on the published characterization numbers from the Jetson GPU plat- form with the ZCU102 FPGA[ 64 ] (which is similar to the HORN-8 prototype) [ 51 ]. Because of the LUT memoization and power ef- ficiency optimizations [ 35 ], HORN-8 saves around 48% power 5 . However, HORN-8 does not explore the approximation opportuni- ties to speedup the hologram execution.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "(a): Viewing the W-CGH from different eye-center positions. (c) Viewing S-CGH from different focal distances. Focal distance from left to right:  0.3m ,  0.4m ,  0.5m , and  0.6m \nFigure 9: A demo of viewing/rendering the virtual planet whole-hologram (W-CGH, generated from all of the depth planes, i.e., from  1-st  to  16-th ) or sub-hologram (S-CGH, generated from only a subset of the depth planes, from 9-th  to  12-th  in this case) with different configurations.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "[5] Amazon. EC2 pricing. https://docs.aws.amazon.com/ sagemaker/latest/dg/deepar.html,February2020 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "The latent space takes the activity, and the first and second order moments of the data sample to recreate the signal, and the Discriminator tried to distinguish between the generated sig- nal and the actual signal. The generator is tuned repeatedly until the discriminator could not distinguish the original and the generated signal. Motivated by this, we designed a GANs to regenerate the lost data points while performing importance sampling.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "In addition, the availability of clean and high-quality data is reaching physical limits. As models grow larger, they re- quire exponentially more data, but the Chinchilla Law [64] indicates that, beyond a certain point, increasing model size without proportional data scaling yields diminishing returns. This scarcity of high-quality data constrains the effective training of larger models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "5537‚Äì5543, 2023. doi: 10. 1109/ICRA48891.2023.10160700. Roberto Pierdicca, Michele Sasso, Flavio Tonetto, Francesca Bonelli, Andrea Felicetti, and Marina Paolanti.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "IV  to each of the PC frames. SpeciÔ¨Åcally, we choose to segment each PC frame into 30000 blocks 7 , and use a 2-layer encoder (more speciÔ¨Åcally, we Ô¨Årst encode the attributes via the proposed intra-frame encoder \n6 Based on our proÔ¨Åling, the provided attribute compression APIs (e.g., JPEG- Turbo-based) would degrade the quality of PC signiÔ¨Åcantly; thus, we do not use such APIs/Libs in our evaluations. 6 \n‚Ä¢  Intra-Only : We apply our intra-frame compression method discussed in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "This adaptation is guided by the dropout mask vector and the specific type of sparse matrix operation being performed. Moreover, we have implemented a modified version of the matrix multiplication operation that strategically skips the loading of rows and/or columns from the input matrices into the GPU‚Äôs shared memory and register files. While the overhead in streaming multi-processor (SM) utilization was marginal (within 5%), there was a noticeable increase in memory bandwidth usage, ranging from 6% to 17%.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "The reason why YOLOv4-tiny saves more is that the PI beneÔ¨Åts more in a ‚Äúshallow‚Äù model with a relatively larger room to skip. 8c-8d and Fig. 9c-9d show, i.e.,  55%  latency and  56%  energy saving in YOLOv3, and  61%  latency and  64% energy saving in YOLOv4-tiny.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "images), inference on low-dimensional sensor data (such as inertial measure- ment unit or IMU vibration data) is much more sensitive to lossy compression as separating between features might be difficult to do. And we will not achieve a sufficient com- pression ratio from lossless approaches either. Therefore, the standard data compression techniques are not very useful, let alone their energy efficient (such as quantized versions [ 33 ]) counterparts.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "To maximize the compute reuse between the compute pipeline and the archival pipeline,  Salient Store  uses apart of the neural network of the inference engine to extract features, and then further performs the encoding using the FPGA in the CSD. As discussed earlier, Salient Store  edge storage implements a video archival by using neural compression followed by a quantum safe encryption (refer Fig. 1).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Furthermore, given the plug-and-play nature of storage media like HDDs and SSDs, securing this data becomes even more critical. The typical  archival process  involves three key phases: compression, encryption, and redundancy. Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "If the tiling sizes of output solutions are the same, we choose larger  m because larger  m  implies fewer partial sum adds. Figure 7 shows the Ô¨Ånite state machine (FSM) directing transition strategy. D. Activation transition \nThe power instability of energy harvesting implies that the activation solution needs to change dynamically as power level changes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "3886‚Äì 3895, 2017. 8, pp. [16]  C. Dorea and R. L. de Queiroz, ‚ÄúBlock-based motion estima- tion speedup for dynamic voxelized point clouds,‚Äù in  2018 25th IEEE International Conference on Image Processing (ICIP) , 2018, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "(3) Evaluation of these policies on a publicly-available data set and also on data from real industrial grinding machines. We show that our privacy preserving partitioning approach outperforms edge- local prediction accuracy and achieves much of the accuracy in a data-sharing model. Finally, we provide a sensitivity analysis to understand the effect of different hyper-parameters on the accuracy and latency.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "This  maximizes data and resource reuse , and the pipeline for inference and compression do not diverge from the get going. However, even with data reuse, performing compression using neural codecs would require extra compute resources, energy and latency, hindering the critical path, i.e., inference. However,  this issue could be alleviated by not using the compute resource in the critical path and preferably moving the compute to the storage where the data will eventually be stored .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "Another interest- ing observation is that,  Intra-Holo  saves more execution time than Inter-Holo . This is because the latter only approximates the objects outside of the current region of focus (still requiring full compute for the objects inside), whereas the scope of the former is much larger, i.e., including all the objects in the current viewing window and approximating each of them based on its location. In addition, from an individual video‚Äôs perspective, we further observe that the  shoe  video achieves the maximum performance benefits from our schemes (specifically, 23%, 69% and 73% latency reduction with Inter-Holo ,  Intra-Holo  and  Inter-Intra-Holo , respectively, compared to the baseline).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 172,
    "augmented": false
  },
  {
    "text": "Cerebras systems: Journey to the wafer-scale engine. University of Chicago, Tech. Rep , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "For example, the classiÔ¨Åer used in the left ankle sensor tends to be more accurate overall, but for classifying climbing action, it is not better than the chest sensor. Hence, to give the left ankle more weight while doing an ensemble for a climbing task makes \nthe classiÔ¨Åer biased. Furthermore, it the relative weight of each sensor is likely to shift from user to user.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "These QuantaTasks are carefully coded with optimized assembly language to maximize their efficiency. We take advantage of the on-board NV FeRAM to perform backup and restore in case of power emergencies. In case of a power emergency, the task is abandoned and a hardware-assisted backup and restore is performed.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "IEEE, 2014, pp. [17] P. Chi, S. Li, Y. Cheng, Y. Lu, S. H. Kang, and Y. Xie, ‚ÄúArchitecture \ndesign with stt-ram: Opportunities and challenges,‚Äù in  2016 21st Asia and South PaciÔ¨Åc design automation conference (ASP-DAC) . 609‚Äì622.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "[38]  B. Li, ‚Äú3d fully convolutional network for vehicle detection in point cloud,‚Äù in  2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2017, pp. Association for Computing Machinery, 2020. [37]  K. Lee, J. Yi, Y. Lee, S. Choi, and Y. M. Kim,  GROOT: A Real-Time Streaming System of High-Fidelity Volumetric Videos .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "4%  for YOLOv4-tiny. 4) Model-SpeciÔ¨Åc Analysis:  To study how the inference behavior changes across different DNN models, we next compare the performance and the energy consumption of two DNN models used in this work (YOLOv3 and YOLOv4-tiny), and plot the results in Fig. These results clearly show that our proposal is able to maintain high accuracy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "‚Ä¢  The results of  ResiSchedule  are very close or equal to that of  Sequential  under most cases. The results of Naive1  are the worst because it lacks both adequate hardware resources and scheduling Ô¨Çexibility. Although  Naive2  is based on the  ResiRCA  architecture, the throughput is still relatively low because it lacks scheduling adaptation to Ô¨Åt to the changing harvested power.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "[116] Chrysostomos A Nicopoulos, Dongkook Park, Jongman Kim, Mazin S Yousif, and Chita R Das. Association for Computing Machinery. Vichar: A dynamic virtual channel regulator for network-on-chip routers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "When training, a document of NLP is first routed to CS in the first layer, then routed to AI, and NLP. This procedure repeats  ‚åä L/k ‚åã times in a single run where  L  is the number of layers in LLM. Modeling Expert Collaboration with Graph Ensemble-of-Experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "In this paper, we propose and evaluate  Cocktail , a cost-effective model serving system that exploits ensembling techniques to meet high accuracy under low latency goals. In  Cocktail , we adopt a three-fold approach to reduce the resource footprint of model ensembling. More speciÔ¨Åcally, we (i) develop a novel dynamic model selection, (ii) design a prudent resource management scheme that utilizes weighted autoscaling for efÔ¨Åcient resource allocation, and (iii) lever- age transient VM instances to reduce the deployment costs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "To further exploit the energy efÔ¨Åciency, we also implement our hardware  prototype using an FPGA to evaluate the energy beneÔ¨Åts brought by the microarchitectural augmentations. Both the proposed software and hardware solutions are modular , and hence can be integrated to the existing pipeline with little change. ‚Ä¢  We evaluate our integrated design, including both  EA  and AE , using an open-source 360¬∞ VR video dataset [3] with the traces of 20 users watching 5 different VR videos.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "5s, pp. 20, no. [56] H. R. Mendis, C.-K. Kang, and P.-c. Hsiu, ‚ÄúIntermittent-aware neu- \nral architecture search,‚Äù  ACM Transactions on Embedded Computing Systems (TECS) , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Additionally, the PWS uses a DAG descriptor, which is a file that contains a python dictionary that specifies the connectivity among functions. Although constructing this is a one-time effort, automating this process through offline DAG profiling can be explored in future work. Table 4 gives an overview of Kraken ‚Äôs policies and their implementation details.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": ", and  Can we leverage this proximity to safely skip some computations to save energy? 360 ¬∞ V IDEO  P ROJECTION \nTo leverage the opportunities in the  360 ¬∞ video projection, we need to understand the execution of the entire projection processing in a  360 ¬∞ VR system. III.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "To the best of our knowledge, this is the Ô¨Årst work that focuses on low power and reconÔ¨Ågurable RCA design from both the hardware and software angles targeting energy harvesting systems. This paper makes the following key  contributions : ‚Ä¢  Low power, reconÔ¨Ågurable hardware design:  We pro- pose a novel architecture that implements a lightweight and low power RCA to adapt to time-varying power resources. Furthermore, the proposed hardware is reconÔ¨Ågurable at a Ô¨Åne grain, to be able to dynamically activate different scaled computations, which can Ô¨Åt to the changing features of the underlying power resources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Objective functions : In order to reduce cost and latency while maximizing the accuracy, we deÔ¨Åne a latency-accuracy metric ( ¬µ AL ) and cost metric ( ¬µ c ): \n¬µ AL  =   Acc target \nLat target ¬µ C  =  k  √ó N ‚àë m = 1 \ninst _ cost \nP f m \nwhere  N  is the number of models used to ensemble and inst _ cost  is the VM cost. Our Ô¨Årst objective function ( O 1 ) is to the maximize  ¬µ AL  such that target accuracy ( Acc target ) is reached within the target latency ( Lat target ). Each model  m  has a packing factor \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1045 \nP f m  and k is a constant which depends on the VM size in terms of vCPUs (xlarge, 2xlarge, etc).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 216,
    "augmented": true
  },
  {
    "text": "During the multiplication-addition operation, the input signals are applied to the rows of the x-bar, and the weights are applied to the columns. The output of each ReRAM device is the product of the input and weight signals, which are added together using the crossbar wires. The ReRAM devices are programmed to have different resistance values, which are used to store the weights.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "[59]  Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gregory R Ganger, Phillip B Gibbons, and Matei Zaharia. Pipedream: generalized pipeline parallelism for dnn training. In  Proceedings of the 27th ACM Symposium on Operating Systems Principles , pages 1‚Äì15, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Another comparison parameter is the  compression ra- tio . Our proposal provides similar compressed size as TMC13 [ 56 ] ( ‚âà 0 . 1 √ó  larger) when exploiting the entropy en- coding.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Finally, our partnership with ANL (see the attached collaboration letter) allows us to access ANL re- sources, including hardware accelerators for LLM. Office Space:  Each PI has an office that is approximately 75 sq. ft., including desks with workstations and peripherals.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "‚Ä¢  T 2  gives us  eyes‚Äô view ; i.e., this changes the virtual world‚Äôs coordinate frame to match the frame of the eye. This requires knowledge of the head orientation or the direction of gaze, which can be read at runtime from the IMU sensors embedded in the VR headset. ‚Ä¢  T 3  transforms the  360 ¬∞ coordinates from a  monocular view to a  stereoscopic view .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Motivation \nTo understand the energy proÔ¨Åle in the current VR devices, we characterize the energy consumption of  360 ¬∞ video pro- cessing on a prototype [36] (conÔ¨Ågured similar to a com- mercial VR device [39], discussed in Sec. V) in Fig. 2a.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "and starts Ô¨Çushing the results for backup. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "[106] Meta AI. LLaMA-3.1 405B: Pre-trained Language Model. Our next-generation meta training and inference accelerator, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "[32]  Microsoft Research Blog. 2020. Second Version of HoloLens HPU will Incorporate AI Coprocessor for Implementing DNNs.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Springer, 2020. [7] Muhammad Adnan, Akhil Arunkumar, Gaurav Jain, Prashant Nair, Ilya Soloveychik, and Pu- rushotham Kamath. Keyformer: Kv cache reduction through key tokens selection for efficient gener- ative inference.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "266‚Äì268. [66] Y. Zhu, A. Samajdar, M. Mattina, and P. Whatmough, ‚ÄúEuphrates: Algorithm-SoC Co-design for Low-power Mobile Continuous Vision,‚Äù in  Proceedings of the International Symposium on Computer Architec- ture (ISCA) , 2018, pp. [65] D. Zhou, S. Wang, H. Sun, J. Zhou, J. Zhu, Y. Zhao, J. Zhou, S. Zhang, S. Kimura, T. Yoshimura, and S. Goto, ‚Äú14.7 a 4gpixel/s 8/10b h.265/hevc video decoder chip for 8k ultra hd applications,‚Äù in 2016 IEEE International Solid-State Circuits Conference (ISSCC) , 2016, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 200,
    "augmented": true
  },
  {
    "text": "Xanadu: Mitigating cascading cold starts in serverless function chain deploy- ments. In  Proceedings of the 21st International Middleware Conference . 356‚Äì370.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "360 ¬∞ V IDEO  P ROJECTION \nTo leverage the opportunities in the  360 ¬∞ video projection, we need to understand the execution of the entire projection processing in a  360 ¬∞ VR system. We illustrate the details of  360 ¬∞ video projection in Fig. 3 as three stages (detailed background of this projection transformation can be found in [21], [27]).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "In  2008 15th IEEE International Conference on Image Processing , pages 277‚Äì280. IEEE, 2008. Appendix \nA Modeling of Ensembling \nWhile performing an ensemble it is important to be sure that we can reach the desired accuracy by combining more models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Container Utilization:  Figure 11 plots the average num- ber of requests executed per container (Jobs per container) \n2 MLP misprediction rates are not shown in any Figure \n162 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \n0 \n100 \n200 \n300 \nArch Fifer DProb Kraken SProb Xanadu \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(a) Social Network. Although we use specific combinations of applications and traces to highlight the improvements, the results are similar for other workload mixes as well. 0 \n150 \n300 \n450 \n600 \nArch Fifer DProb Kraken SProb Xanadu \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 198,
    "augmented": true
  },
  {
    "text": "For instance, if there are 3 unique classes predicted by all the ensemble models, we sum the weights for all models of the same class. The class with the maximum weight ( P class ) is the output of the majority vote. Hence, classes that did not get the highest votes can still be the Ô¨Ånal output if the models associated with that class has a higher weight, than the combined weights of highest voted class.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "html . https://ai.googleblog.com/2018/05/custom-on-device-ml-models. (Accessed on 11/21/2022).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Therefore, we believe that, achiev- ing beneÔ¨Åts by exploiting the  EA  and  AE  opportunities needs an extensive study and a careful design, especially from an architectural perspective, to maximize the beneÔ¨Åts. As shown in Fig. Driven by the above discussion and the potential optimiza- tion opportunities presented by  EA  and  AE , we propose  D¬¥ej`a View , an energy-efÔ¨Åcient design for  360 ¬∞ video streaming on VRs.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "5c, SLAT reduces the data communication volume up to  ‚âà 5 . 63 √ó  compared to the classical approaches, thereby saving bandwidth (reduces bandwidth by  ‚âà 36% , public cloud has strict regulations on measuring the actual bandwidth, and hence we report the approximate result from the traffic pattern) and energy. 0 \n1 \n2 \n3 \n4 \n5 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nNorm.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "First,  HoloAR  utilizes the exist- ing viewing-window based technique [52] (denoted \na  ) to skip the hologram computations for the objects which are outside of the current viewing window, in a ‚Äújust-in-time‚Äù fashion. Next,  HoloAR employs the  Inter-Holo  scheme (denoted  b  ), to take advantage of the region of focus from analyzing the current eye tracking inputs and sparsely compute the objects outside the RoF. Finally,  HoloAR \n499 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \n(a) Viewing-Window scenario [52].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "The batch size represents the number of requests that can be served by a function without violating the allotted stage-wise SLO. 4.3 Reactive Scaler (RS) Though the introduction of Request Batching  5  allows Kraken  to reduce the containers provisioned, load mispredic- tions and probability miscalculations can still occur, leading to resource mismanagement, which could potentially affect the SLO compliance. To deal with this,  Kraken  also employs the RS  7  to scale containers up or down in response to re- quest overloading at containers (due to under-provisioning) and container over-provisioning, respectively.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "Proper selection and tuning of  Œª 1 , Œª 2  help main- tain stable and robust training dynamics. Thus, the proposed training process achieves a harmonious balance: it respects the strategic, energy-constrained envi- ronment (through equilibrium and game-theoretic consider- ations), while leveraging well-established convex optimiza- tion guarantees to ensure convergence of the global model parameters. 11",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "After sensing, the input samples are then buffered in the video buffer, waiting to be processed timely at the frame-rate. 1b. Specifically, the AR hardware has three major components: Sensor Inputs:  The AR headset receives the real-time information from both the surrounding environment and the user (viewer), with two types of sensing:  ‚ë† ‚Äúworld sensors‚Äù  to sense the physical surrounding the user is currently in, such as cameras for the RGB image and LiDAR/depth sensor for the depth or distance of the objects in front of the user, and  ‚ë° ‚Äúuser sensors‚Äù  to sample the behavior/status of the user, such as inertial measurement unit (IMU) sensors for head rotation, IR sensors for eye tracking, and controller for hand gesture.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 167,
    "augmented": true
  },
  {
    "text": "Therefore, only for this small number of pixel coordinates, the entire coordinate projection computations need to be processed. Algorithm 1  Algorithm to capture and utilize the pattern  Œî \nInput:  [ ‚Éóx 0: n ‚àí 1 l , ‚Éóy 0: n ‚àí 1 l ] : left-eye projection (all rows) Input:  [ ‚Éóx 0 r , ‚Éóy 0 r ] : right-eye Ô¨Årst-row‚Äôs projection Output:  [ ‚Éóx 1: n ‚àí 1 r , ‚Éóy 1: n ‚àí 1 r ] : right-eye projection \n1:  procedure  C APTURE P ATTERN ( ‚Éóx 0 r ,  ‚Éóy 0 r ,  ‚Éóx 0 l   ,  ‚Éóy 0 l   ) \n2: [Œî x ,  Œî y ]  :=  [ ‚Éóx 0 r   ‚àí ‚Éóx 0 l   ,  ‚Éóy 0 r   ‚àí ‚Éóy 0 l   ] 3: return  Œî = [Œî x ,  Œî y ] \n4:  end procedure \n5:  procedure  U TILIZE P ATTERN ( ‚Éóx 1: n ‚àí 1 l ,  ‚Éóy 1: n ‚àí 1 l ,  Œî ) 6: [ ‚Éóx 1: n ‚àí 1 r ,  ‚Éóy 1: n ‚àí 1 r ]  :=  [ ‚Éóx 1: n ‚àí 1 l +  Œî x  ,  ‚Éóy 1: n ‚àí 1 l +  Œî y ] \n7: return  [ ‚Éóx 1: n ‚àí 1 r ,  ‚Éóy 1: n ‚àí 1 r ] 8:  end procedure \nThe Effect of AE:  with this  AE  optimization, for the right eye, the intensive projective transformation computations can now be short-circuited by light-weight  Add  operations. As a result, by exploiting the  AE  scheme on the Ô¨Årst frame in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 494,
    "augmented": false
  },
  {
    "text": "This database will help in various intelligent decisions such as using the most ideal hardware for an expert and dropping an expert if it does not meet the minimum required accuracy/SLO for an application. Task-3.2: Chiplet-Based Modular Hardware Platform After identifying the device affinity and the execution attributes of each expert, towards the goal of design- ing a suitable hardware platform, we envision mapping these experts onto appropriate chiplets which may differ across experts. To explore the search space, we plan to investigate four design choices: what types of chiplets are needed in a chip, how the EoE can be mapped to our chip, how the memory hierarchy can be tailored for a given EoE mapping, and how the chiplets and chips can be interconnected, as illustrated in Figure 6.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 167,
    "augmented": false
  },
  {
    "text": "To search for the best architecture for the given intermittent environ- ment, DynNAS utilizes the approach proposed by iNAS (Mendis et al., 2021). After the network architecture is determined, DynFit is used to train the network considering energy intermittency, and DynInfer is employed to perform inference under intermittent power conditions. In this section, we elaborate on the key components, focusing on DynFit and DynInfer, and explain how they uniquely adapt DNN training and inference to intermittent power conditions.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "The PI technique can further save  6%  more energy on average, as shown in Fig. 8c. On the other hand, the YOLOv4-tiny inference with the FI+SI scheme saves  53%  energy w.r.t.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "There have been prior works like N-body application [ 5 ] which utilize the Morton code for parallel octree construction 4 ; however, we believe ours is the Ô¨Årst work that tries to apply such technique in the PCC pipeline. Morton Code Can Also Assist Attribute Compression: As discussed above, Morton code naturally describes the geometrical relations among points; thus, intuitively, it makes sense to utilize the Morton code to improve the geometry compression. However, our goal is to go beyond just optimizing the geometry compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Thus, we need to perform  full inference  for Frame-3 to maintain high accuracy for detection, as shown in  7  . Putting all these together, in this scenario, both Frame-1 and Frame-3 employ full inference, whereas the inference for Frame-2 can be skipped, with very little overhead (only  0 . However, for Frame-3, the motion vectors generated by codec (  6  ) drift away from the bounding box in Frame- 1 (with an overlap ratio of 0.6 in the right case), indicating that the object has moved/shifted a signiÔ¨Åcant distance.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "5.1. 5.4. We discuss the impact of our proposal on output/result quality, compared to the baseline design, later in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Mathematical Formulation:  Let  W  be the weight matrix of a layer. The L2 norm of the weights is calculated as: \n‚à• W ‚à• 2  = sX \ni,j W   2 ij \nDefine the dropout probability  p i  for neuron  i  based on the L2 norm of its corresponding weights. The idea is to use the inverse of the L2 norm to determine the probability: \np i  = Œ± ‚à• W i ‚à• 2  +  œµ \nwhere  Œ±  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "Trans- mitting coresets rather than raw data greatly improves the \nenergy efficiency of communication to the host, when re- quired, and effectively increases the number of completed inferences, thereby increasing overall accuracy. The host, after obtaining information from multiple sensors, per- forms any further required computation and uses ensemble learning [ 47 ] to give an accurate classification result. Depending on the incoming data and the EH budget, the sensor decides whether to skip compute, perform an inference at the edge, or form a coreset to offload the inference to the host.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "[2]  2019. Accessed: 2020-05-07. https://archive.org/details/twitterstream.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "https : / / www.nytimes.com/2024/10/16/business/energy- environment/amazon- google- microsoft-nuclear-energy.html , 2024. Accessed: 2024-10-20. Amazon, google, microsoft turn to nuclear energy.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efÔ¨Åciency. S YSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives. III.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "However,  Arch  uses 4x the number of containers used by  Kraken  (Figure 10a). Kraken  also performs similar to  Fifer , while using 58% reduced containers for  Social Network . From Figures 9 and 10, it can be seen that  Xanadu  has similar (or worse) end- to-end response times than  Kraken  (up to 50 ms more), but \nspawns more containers as well (up to 70% more) and satisfies fewer SLOs on average (0.2% lesser).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "1‚Äì8. [34]  A. Kuntz, C. Bowen, and R. Alterovitz, ‚ÄúFast anytime motion planning in point clouds by interleaving sampling and interior point optimization,‚Äù in  Robotics Research . Springer, 2020, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Skip Inference:  When the current frame is identiÔ¨Åed as ‚Äúclonable‚Äù by the previous frame, the CPU is released without any inference execution request. Partial Inference:  In this case, rather than processing the whole frame, only the RoI blocks are fed into the CPU and, with the memoized feature maps from previous frame, the CPU is able to generate the desired result for the current frame as accurate as performing inference on a full frame. Instead, the previous results (the bounding boxes [including the classes and scores] in the previous frame), which have been memoized before, are directly loaded as the inference result for the current frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "From Fig. 5c, we can observe that, as the precision decreases from  4  (resolution is  0 . 0001 ) to  1  (resolution is  0 .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "2018. Convolutional Neural Networks for Human Activity Recognition Using Body-Worn Sensors. [60]  Fernando Moya Rueda, Ren√© Grzeszick, Gernot A. Fink, Sascha Feld- horst, and Michael ten Hompel.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "2018. Survey on wireless sensor network applications and energy efficient routing protocols. Wireless Personal Communications 101, 2 (2018), 1019‚Äì1055.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "Experiments on waymo (Sun et al., 2020) dataset shows the PSNR of Salient Store  compared to the classical H264 and HEVC encoding pipeline in Fig. 5.2 Evaluation of Video Data Recovery and Quality: \nTo ensure proper video quality upon recovery, we perform a peak signal-to-noise ratio (PSNR) study of  Salient Store  with the classical encoding mechanisms H264 (ITU-T, 2019a) and H265 (HEVC) (ITU-T, 2019b). 77 √ó  speedup against VSS and a classical storage server, respectively.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "The output signal is obtained by summing the weighted input signals over a sliding window, which moves across the input signal to compute the convolution. At the circuit level, the ReRAM x-bar for multiplication-addition typically includes several com- ponents, such as digital-to-analog converters (DACs), analog-to-digital converters (ADCs), shift registers, and hold capacitors. The DACs and ADCs are used to convert the digital input and weight signals into analog signals that can be applied to the rows and columns of the x-bar.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "1‚Äì11, 2009. The rsa algorithm. RSA laboratories , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 21,
    "augmented": true
  },
  {
    "text": "6) Tradeoffs between Accuracy and Energy Consumption: So far in our evaluation, we wanted to minimize the accuracy impact (see Table III). However, as an alternate design princi- ple, one may want to relax this accuracy constraint and thus save more energy. We used Pytorch [46] to proÔ¨Åle the accuracy behavior of two videos picked from VIRAT [33] dataset, and show that our proposal can adaptively support such alternate design choices.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Industry Collaboration: We have several ongoing collaborations with industries like NVIDIA, AMD, Google and Meta, who are major players in advancing deep learning technology/systems. We plan to collaborate with them on various aspects of this project as well, and explore opportunities for technology transfer. Furthermore, the PIs will leverage additional connections through their former students working in these companies.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "The mask values are determined using a sigmoid function to ensure they lie between 0 and 1: m i  =  œÉ ( z i ) where  z i  are learnable parameters and  œÉ ( ¬∑ )  is the sigmoid function. Apply the dropout mask during the forward pass. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "[60] Suchin Gururangan, Margaret Li, Mike Lewis, Weijia Shi, Tim Althoff, Noah A Smith, and Luke Zettlemoyer. Scaling expert language models with unsupervised domain discovery. arXiv preprint arXiv:2303.14177 , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Mitigating Data Drift:  Dealing with data drift in edge com- pute nodes presents a signiÔ¨Åcant challenge. While larger models with more parameters may exhibit limited data drift due to their increased capacity to generalize, deploying such large models on edge compute nodes can be difÔ¨Åcult due to \ninherent limitations in form factor, energy efÔ¨Åciency, thermal constraints, and compute resources. To accommodate these constraints, it is a common practice to employ compressed Deep Neural Network (DNN) models, that are quantized, distilled, or otherwise reduced in size.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "This is unfortunate as they contribute significantly to the data management and data movement, especially in a emerging complute landscape where date storage and data protection has be- come one of the key concerns. To mitigate this, we propose  Salient Store  that specifically focuses on the integration of Computational Storage Devices (CSDs) into edge servers to enhance data processing and management, particularly in continuous learning scenarios, prevalent in fields such as autonomous driving and urban mobility. Our research, gos beyond the compute domain, and identifies the gaps in current storage system designs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "[2]  Rachel Albert, Anjul Patney, David Luebke, and Joohwan Kim. arXiv preprint arXiv:2012.09988  (2020). 2017.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "Learning Approach: Our approach diverges from classi- cal Learning paradigms. We adopt a hybrid strategy where periodic or event-triggered updates refine the model parame- ters based on equilibrium-driven data collection. This hybrid \n5 \n275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 \napproach mitigates the high communication overhead and energy consumption, making it more suitable for resource- constrained EH-WSNs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 187,
    "augmented": false
  },
  {
    "text": "[17] P. Chi, S. Li, Y. Cheng, Y. Lu, S. H. Kang, and Y. Xie, ‚ÄúArchitecture \ndesign with stt-ram: Opportunities and challenges,‚Äù in  2016 21st Asia and South PaciÔ¨Åc design automation conference (ASP-DAC) . IEEE, 2016, pp. 109‚Äì114.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Sourav Dutta and Chinwe Ekenna. Air-to-ground surveillance using predictive pursuit. In  2019 International Conference on Robotics and Automation (ICRA) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "In this scheme, one can observe from Fig. IV-C). overhead, as discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "‚Ä¢  We implement both our schemes as a  software  enhancement to the existing compute pipeline in NVIDIA GPUs. We propose a memoization scheme, called  EA , to capture recent head orientation data for temporal reuse, and for the spatial reuse, we design the  AE  scheme, which leverages the stationary relationship between two eyes to efÔ¨Åciently reduce the amount of projection computation. To further exploit the energy efÔ¨Åciency, we also implement our hardware  prototype using an FPGA to evaluate the energy beneÔ¨Åts brought by the microarchitectural augmentations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "[47] S. Lee, B. Islam, Y. Luo, and S. Nirjon, ‚ÄúIntermittent learning: On- \ndevice machine learning on intermittently powered system,‚Äù  Proceed- ings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies , vol. 3, no. 4, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Further, to study how the tuned approximation (in Algo. 3) affect the energy savings achieved, we report five design points in Fig. 2 and Algo.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "1 , typically consists of 5 stages: 3D content generation, PC encoding, data transmission, PC decoding, render and display. In the  3D Content Generation  stage, the capturing device (e.g., the iPhone) uses LiDAR scanning or photogrammetry for the PC data acquisition. LiDAR maps spatial relationships and shapes by measuring the time taken by signals to bounce off objects and return to the scanner, while photogrammetry takes many photos from different angles to capture the target‚Äôs geometry [ 9 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "6b and Fig. 6c retain the same ellipse behavior but different shapes. Second, for different head orientations, their distance vectors plotted in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "The noisy data is generated by adding a Gaussian noise (with maximum SNR of 20dB) over the unseen test data. These variations can cause misclassiÔ¨Åcations and the adaptive nature of the conÔ¨Ådence matrix mitigates this. To mimic the noisy and inconsistent behaviour of real- world scenarios, we test the adaptive nature of the ensemble learner for 3 different previously unseen users over a 1000 iterations (10000 successful classiÔ¨Åcations; each iteration has 10 classiÔ¨Åcations).",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Similarly, for the next frame,  Frame-II , now the user lifts her head a bit, hence the corresponding viewing window changes from the previous one. Because of this, now the  football  is partially located in the viewing window, and requires computing (only for the bottom right part that is inside the viewing window). Note also that, since the  soccer ball  hologram has been already generated in Frame-I , we can skip its computation.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "To accommodate these constraints, it is a common practice to employ compressed Deep Neural Network (DNN) models, that are quantized, distilled, or otherwise reduced in size. Traditionally, data drift has been handled by cloud-based periodic re-training using continuous learning algorithms [ 20 ], [ 74 ]. However, while com- pressed models are essential for meeting resource limitations, they are more sensitive to data drift because they may not generalize as effectively.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "[41]  Aaron Harlap, Andrew Chung, Alexey Tumanov, Gregory R. Ganger, and Phillip B. Gibbons. Tributary: spot-dancing for elastic services with latency SLOs. In  ATC , 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "[83]  Neeraja J. Yadwadkar, Francisco Romero, Qian Li, and Christos Kozyrakis. A case for managed and model-less inference serving. In  Proceedings of the Workshop on Hot Topics in Operating Systems , New York, NY, USA, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "However, managing such data requires substantial storage infrastructure. minimizing communication and preserving privacy. Data Archival:  The answer is straightforward, especially for mission-critical public records like urban mobility and surveillance data: these need to be archived in a local storage to avoid under- mining the benefits of edge computation, i.e.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "However, the tail latencies of  DProb  and  SProb  sometimes exceeds the SLO, since they don‚Äôt use  Commonality  and  Connectivity . 6.2.1 Sensitivity Study : This subsection compares  Kraken against  Oracle , which is an ideal policy that is assumed to be able to predict future load and all path probabilities with 100% accuracy and also has request batching. It is observed that Xanadu  also violates the SLO for the Twitter trace, owing to the reactive scale-outs resulting from MLP mispredictions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "8d and Fig. 8c, the latency is further decreased by  13%  (V1P) and  19%  (V2P), whereas the energy saving is increased by  12%  and  22% . The improvement brought by PI for YOLOv4-tiny model is more signiÔ¨Åcant as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "98.50% \n99.00% \n99.50% \n100.00% \n0 \n10000 \n20000 \n30000 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(b) Media Service. 99.00% \n99.25% \n99.50% \n99.75% \n100.00% \n0 \n3000 \n6000 \n9000 \n12000 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(c) Hotel Reservation. Figure 14: Simulator: Comparison of Total Number of Containers spawned VS SLOs satisfied by each policy.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Usas: A sustainable continuous-learning¬¥ framework for edge servers. In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pp. 891‚Äì907.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "We need some feedback from the end-user to make a correct estimate of accuracy. 3.2 Resource selection \n3.2.1 Static Load  From  Observation 2 , it is clear that, be- sides model selection, it is crucial to select and configure the right resource to satisfy the application constraints. Therefore, it would be best to build a learning- based system, which takes into account feedback (user-given data) to build a novel model selection system.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "5s, pp. 1‚Äì27, 2021. [57] Meta, ‚ÄúSharing our progress on combating climate change = https://about.fb.com/news/2022/11/metas-progress-on-combating- climate-change/ ,‚Äù (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Inference with Neuron Shapley Value Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Otherwise, maintain or reduce the dropout rate to improve accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "5 \nmedium, facilitate computation at the storage level. Initial applications of CSDs were confined to tasks like encryption/decryption, RAID, and compression. However, there has been a significant push towards enabling more complex workloads, including query processing on CSDs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "Video Inference on Mobile Platforms \nThe key difference between a video-based DNN application and other popular DNN inferencing applications like natural language processing (NLP) or speech-to-text is that, the former interacts with video frames which are either captured from the camera or downloaded/streamed from internet and hence, has a strict latency requirement for performing inferencing within the frame deadline. As shown in the ‚ÄúHW‚Äù (Hardware) layer in Fig. 1, a typical mobile neural network video inference system has two major hardware components: (i) an SoC with a CPU/GPU/NPU for processing the intensive computations, and an intermediate buffer in DRAM for storing the video frames as well as the intermediate data between layers of DNNs, and (ii) a video decoder communicating with the SoC ,typically via the memory bus.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 199,
    "augmented": false
  },
  {
    "text": "[2]  L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, ‚ÄúSwitched by input: Power efÔ¨Åcient structure for RRAM-based convolutional neural network,‚Äù in  2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC) , pp. 1‚Äì6, 2016. [3]  A. ShaÔ¨Åee, A.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "[63] S.-H. Noh, J. Koo, S. Lee, J. Park, and J. Kung, ‚ÄúFlexblock: A Ô¨Çexible \ndnn training accelerator with multi-mode block Ô¨Çoating point support,‚Äù IEEE Transactions on Computers , 2023. 27, p. 28, 2009.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Note that the pattern behavior also depends on the row numbers. This again validates the quality impact discussed earlier. Putting together, these above observa- tions indicate that, with very little change (to capture the row- dependent information) in our original  AE  design, our idea is able to work with any representation format.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Amazon buys stake in nuclear energy developer in push to power data centres. https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911 , 2024. [44] Financial Times.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Curran Associates, Inc., 2021. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors,  Advances in Neural Informa- tion Processing Systems , volume 34, pages 24545‚Äì24555.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "The presence of the discount factor  Œ≤  further stabilizes the process. With  Œ≤  ‚àà [0 ,  1) , sensors value future utility less than immediate utility. This discounting ensures diminish- ing returns for postponing beneficial participation or indefi- nitely waiting for ideal conditions.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Challenges with Data Compression: Using standard compression algorithms, like discrete cosine transform, dis- crete wavelet transform, and Fourier decomposition etc., to minimize the communication overhead is not a viable solu- tion [ 45 ]. This is partly because we need a very high compres- sion ratio with very low power. Secondly, these compression algorithms are not context-aware, and hence lose relevant \n4 \nfeatures during the process of compression resulting in de- graded inference accuracy (refer Table 1 for details).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "The rest of the containers are a result of  reactive scaling  that follows from MLP mispredictions, which accounts for 34% of the total number of containers spawned. 161 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. 0 500 1000 1500 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers \nNGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "The MR hardware, highlighted in Fig. 3b, consists of a single shift block, a subtractor, and a adder, consuming much less hardware then the state-of-the-art (Fan et al., 2018). This process is constant time, requiring only a single subtraction of  q .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "The weight matrix is designed by considering the accuracy of each model for each class, giving us a weight matrix of  L √ó N  dimension, where  L is the number of unique labels and  N  is the number of models used in the ensemble. The majority vote is calculated as a sum of model-weights for each unique class in the individual prediction of the ensemble. For instance, if there are 3 unique classes predicted by all the ensemble models, we sum the weights for all models of the same class.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Both the baseline setups run on a fully powered system equipped with a steady power source. 2) Baseline-2 uses state of the art pruning techniques described in [3], [15] to prune the DNNs of Baseline-1 to Ô¨Åt the average harvested power budget from our harvesting trace described in Section IV-A. C. Accuracy Results \nBaseline:  We choose two baselines for our evaluation: 1) Baseline-1 consists of the original DNNs built along the lines of [11], [14] (without any pruning).",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "IEEE Transactions on Circuits and Systems for Video Technology , 30(6):1683‚Äì1698, 2019. Vikram Sharma Mailthody, Zaid Qureshi, Weixin Liang, Ziyan Feng, Simon Garcia De Gonzalo, Youjie Li, Hubertus Franke, Jinjun Xiong, Jian Huang, and Wen-mei Hwu. Image and video compression with neural networks: A review.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Distance Vector Study:  Let us further look into the detailed mapping of a  360 ¬∞ frame (in equirectangular format) onto a 2 D  FoV frame in the Projection Mapping stage (refer  c  in Fig. The pixel rendered at  [ x 0 l   , y 0 l   ]  on the left VR screen is mapped from position  [( x 360 ) 0 l   ,  ( y 360 ) 0 l   ] on the equirectangular  360 ¬∞ frame, as shown in Fig. 3), at a pixel granularity.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Do not distribute. Ambi- ent energy availability varies over time and space, leading to fluctuating sensor activity levels and intermittent participa- tion in both training and inference tasks. Despite these advantages, large-scale EH Wireless Sensor Networks (EH-WSNs) remain inherently uncertain.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Beyond 800 s , they quickly recover back to the required accuracy because additional instances are spawned in place of failed instances. It can be seen that queries in all three constraints suffer an intermittent loss in accuracy of 0.6% between the time period 240 s  and 800 s . We induce failures in the in- stances using  chaosmonkey  [ 19 ] tool with a 20% failure proba- bility.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "[44]  Arjun Singhvi, Kevin Houck, Arjun Balasubramanian, Mo- hammed Danish Shaikh, Shivaram Venkataraman, and Aditya Akella. 2019. Archipelago: A scalable low-latency serverless platform.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Swift: Adaptive video streaming with layered neural codecs. In  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , pp. 103‚Äì118, Renton, WA, April 2022b.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Neuron Shapley Value Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ¥ . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass. , m n ]  where  m i  ‚àà{ 0 ,  1 } .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "Such capabilities not only enhance user experience by minimizing buffering and maximizing video quality but also optimize bandwidth usage, presenting a cost-effective solution for content providers. These technical advancements position neural codecs as potential game-changers in the video streaming industry (NVIDIA Corporation, 2024), promising significant improvements in efficiency, scalability, and flexibility in various streaming scenarios. One major issue with neural codecs are their lack of utilization of inter-frame similarity.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "The accuracy improvement in the 4-home setup is significant and the reason for the lower edge accuracy of the 4-home setup is the limitation in number of training samples (2 home setup has twice the amount of data than the 4 home setup to train with). 2) However, the cloud execution latency also increases for the 2-home setup due to the model complexity. The 2-home setup, albeit more accurate, has a more complex model (#splitting points 10501) at the cloud thanks to the large volume of training samples, leading to more execution time compared to the relatively simpler model for the 4-home setup.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "Association for Computational Linguistics, 2020. [196] Yanqi Zhou, Nan Du, Yanping Huang, Daiyi Peng, Chang Lan, Da Huang, Siamak Shakeri, David So, Andrew Dai, Yifeng Lu, Zhifeng Chen, Quoc Le, Claire Cui, James Laudon, and Jeff Dean. In  Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 4599‚Äì4604.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Our discussion in this section is summarized in Tab. This stage mostly comprises of memory operations, and thus is not a compute bottleneck. I.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Similarly Table  9  shows the different models trained for BERT-based sentiment analysis on twitter dataset. Model Params (M) Top1 Accuracy % Latency (ms) Pf Squeezenet 4,253,864 70.10 43.45 10 MobileNEt V2 4,253,864 68.20 41.5 10 Inception V4 23,851,784 76.74 74 6 Resnet50 95,154,159 79.20 98.22 5 ResNet18 44,964,665 76.26 35 6 DenseNet-201 20,242,984 79.80 152.21 2 DenseNet-121 8,062,504 78.72 102.35 3 Xxception 22,910,480 77.80 119.2 4 NasNet 5,326,716 77.90 120 3 InceptionResnetV2 2,510,000 80.30 251.96 1 \nTable 8:  Pretrained models for CIFAR-100 using Imagenet. F Spot Instance Price Variation \nWe proÔ¨Åle the spot price of 4 types of  C5  EC2 VMs over a 2-week period in August 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 264,
    "augmented": false
  },
  {
    "text": "8 , when using various designs explained in Sec. VI-B  to compress the six PC videos from the 8iVFB and MVUB datasets (described in Table  I ). Then, we discuss and present the validity of our results on the smartphones.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Dataset Platform Energy Source Stateful ePerceptive DynBal NExUME \nFMNIST MSP430FR5994 Piezoelectric 20.1 20.8 21.5 23.4 CIFAR10 Arduino Nano Thermal 16.0 16.5 17.0 18.5 MHEALTH ESP32 S3 Eye Piezoelectric 18.5 19.0 19.6 21.0 PAMAP STM32H7 Thermal 16.5 17.0 17.5 19.0 AudioMNIST Raspberry Pi Pico Piezoelectric 20.5 21.0 21.7 23.2 Table 2: Energy efficiency comparison on different hardware platforms. Table 2 presents the energy efficiency in MOps/Joule for each dataset on different hardware platforms using piezoelectric and thermal energy harvesting. NExUME achieves the highest energy efficiency across all platforms and datasets.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "IEEE, 2012. In  2012 45th Annual IEEE/ACM International Symposium on Microarchitecture , pages 294‚Äì304. [144] Akbar Sharifi, Shekhar Srikantaiah, Asit K Mishra, Mahmut Kandemir, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "It is noteworthy that, the process of neural compression as well as inference/representation learning use the feature extraction method. In this work, our goal is to use this to our advantage and maximize the compute and data reuse. The critical insight to be gleaned here is reusing data and compute pipeline prior to its transfer to storage could markedly diminish the costs associated with data movement.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "To ensemble the \nAR pipeline with generic state-of-the-art components shown in Fig. 1c, we implemented an open-source full-system extended real- ity testbed, ILLIXR [ 19 ], on the edge GPU platform [ 36 ], and built our  HoloAR  design on top of it. To collect performance metrics such as the streaming multiprocessor (SM) utilization, memory traffic, and CUDA kernel execution latency, we utilized the open-source Nvidia NVPROF tool [37] on the GPU platform.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "A survey of deep neural network architectures and their applications. [54]  Weibo Liu, Zidong Wang, Xiaohui Liu, Nianyin Zeng, Yurong Liu, and Fuad E Alsaadi. In  Proceedings of the 9th ACM Conference on Recommender Systems , pages 232‚Äì232, 2015.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "This was possible by restricting the training space and by using the superior exemplar set construction by using representation learning. Fig. 8  shows the impact of micro-proÔ¨Åling on the hyper parameter selection.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Moreover, the CoE (College of Engineering) is a partner with the National GEM Consortium that leads the Grad Lab, which facilitates the participation of populations underrepresented in computing for graduate studies in engineering and science. Plan of Activities:  Aligned with the departmental BPC plan, we plan to pursue several activities related to this proposed research as summarized below: ‚Ä¢  Customized Graduate Student Recruiting and Training:  We will recruit graduate women and students from populations underrepresented in computing to work on this project. For this, we will collabo- rate with the Multicultural Engineering Graduate Student Association (MEGA) and Graduate Women in Engineering (GradWIE) programs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "These aforementioned hardware equivocally echo the need of highly parallel computation with bigger and faster memory hierarchy to contain the pool of data for high-scale deployments. Tools, Platforms and Frameworks for LLM Evaluation:  Although they do not capture system insights, a few mathematical models [133] have been proposed to estimate the complexity of LLM training process. Our proposal to this end is to augment the said conventional wisdom with custom ‚Äúchiplet-based‚Äù accelerators  tailored  for the models running on them and using their reconfigurable property to leverage the same hardware for different types of experts that we define or may emerge in the future.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "The ‚Äòdepth‚Äô of a function, in this context, is defined as the distance, in terms of the number of edges in the DAG, from the start state to the current state. For practical purposes, we fix it to be the execution time of the slowest function at the current function depth. The Probability Vector after  ùëë number of time steps can be represented as  ùëÉ ùëë .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Allotting stage-wise SLOs to each function in a chain in proportion to their execution times reveals that there are cases where there is significant difference (slack) between the function‚Äôs expected SLO and its run-time. Functions in a chain can have widely varying execution times. Slack refers to the difference in expected response time and actual execution time of functions within a function chain.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Scenario3: A new object is entering the frame (or an existing object is exiting). Scenario2: An object was not captured by the previous frame, but captured by the current frame. for different cases.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "Vstore: A data store for analytics on large videos. In  Proceedings of the Fourteenth EuroSys Conference 2019 , pp. Tiantu Xu, Luis Materon Botelho, and Felix Xiaozhu Lin.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Sourav Dutta and Chinwe Ekenna. Air-to-ground surveillance using predictive pursuit. In  2019 International Conference on Robotics and Automation (ICRA) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Such differential resolution within an image can reduce computational costs without significantly impacting user experience [ 25 ,  47 ,  62 ]. Further optimizations such as eye- dominance (i.e., HVS prefers scene perception from one eye over the other) and learning-based foveated rendering are orthogonal to this core idea and beyond the scope of this paper [24, 30]. Despite providing significant performance and energy-efficiency benefits, these prior works still miss out on even more selective rendering of viewed hologram images - beyond just the FoV and/or regions of the user‚Äôs focus.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "Habana gaudi ai processor. https://habana.ai/products/gaudi2/ , 2023. Ac- cessed: 2024-04-27.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "They are further encoded by the conventional video encoders, as if they are planar videos, for transmission efÔ¨Åciency. The video frames are transmitted to the users, who wear a portable VR headset (like Facebook Oculus or Google Cardboard), via  Youtube  or  Facebook 360  services [7], [61]. 360 ¬∞ video streaming creates an interactive and immersive environment by connecting the user and the video content; the users are allowed to move their heads‚Äô orientation to enjoy the surroundings in all perspectives along with a 3D view, i.e., a different view for each of the eyes, and hence creating an illusion that the user is present at the scene rather than viewing it on a projected surface.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Continuous Learning: Accuracy \nFig. Labels: MN ‚Äì MobileNet-V2, BL ‚Äì Baseline, Teacher ‚Äì the ensemble of teacher models, MN‚Äì#: targeted MobileNet-V2 model for the particular time of day. A.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "These containers have to be provisioned in advance to service fu- ture load to shield the end user from the effects of cold starts \nand thereby meet the SLO. This load will have to be predicted in order to make timely container provisioning decisions. Algorithm 1  Proactive Scaling with weight estimation \n1:  for  Every Monitor_Interval= PW  do 2: Proactive_Weighted_Scaler ( ‚àÄ ùëìùë¢ùëõùëêùë°ùëñùëúùëõùë† ) 3:  procedure  Proactive_Weighted_Scaler( func ) 4: cl  ‚Üê ùê∂ùë¢ùëüùëüùëíùëõùë° _ ùêøùëúùëéùëë ( ùëìùë¢ùëõùëê ) 5: ùëùùëô ùë° + ùëÉùëä ‚Üê Load_Predictor ( ùëêùëô, ùëùùëô ùë° )  a 6: batches  ‚Üê l p ùëôùë° + ùëÉùëä f ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m \nb 7: total_con  ‚Üê Estimate_Containers ( ùëèùëéùë°ùëê‚Ñéùëíùë†, ùëìùë¢ùëõùëê ) 8: reqd_con  ‚Üê ùëöùëéùë• ( ùëöùëñùëõ _ ùëêùëúùëõ,ùë°ùëúùë°ùëéùëô _ ùëêùëúùëõ ) 9: Scale_Containers ( ùëìùë¢ùëõùëê,ùëüùëíùëûùëë _ ùëêùëúùëõ ) 10:  procedure  estimate_containers( load, func ) ‚ä≤ Output:  ùëüùëíùëûùëë _ ùëêùëúùëõ 11: func.prob  ‚Üê Compute_Prob (func) 12: reqd_con  ‚Üê‚åà ùëôùëúùëéùëë ‚àó ùëìùë¢ùëõùëê.ùëùùëüùëúùëè ‚åâ 13: extra  ‚Üê‚åà( Comm ( ùëìùë¢ùëõùëê ) +  Conn ( ùëìùë¢ùëõùëê )) ‚àó ùëüùëíùëûùëë _ ùëêùëúùëõ ‚åâ 14: reqd_con  ‚Üê reqd_con + extra \nKraken  makes use of a Load Predictor  2b  (Algorithm 1  a ) which uses the EWMA model to predict the incoming load at the end of a fixed time window,  ùëÉùëä .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 427,
    "augmented": false
  },
  {
    "text": "Further evaluations suggest Origin  with RR-12 to be the best Ô¨Åt for HAR. Going beyond RR-12 might lead to missing an activity window for high intensity or rapid activities, and going below RR-12 might lead to energy scarcity at times. In case of abundant energy supply, one can use a round robin policy Ô¨Åt for the given EH source.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "In contrast, Predicting Transform and Lifting Transform are based on the hierarchical nearest-neighbor interpolation [ 80 ]. Apart from these methods that compress a static PC, there also exist several attempts at optimizing the compression for dynamic PCs by exploring the ‚Äútemporal redundancy‚Äù across the PC video frames. The main idea behind RAHT is to use the attribute values in a lower octree level to predict the values in the upper level.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "6 Analysis of Results This section presents experimental results for single ap- plications run in isolation for all schemes on the real system and simulation platform. We have also verified that  Kraken (as well as the other schemes) yield similar results (within 2%) when multiple applications are run concurrently. Additionally, it helps compare the resource footprint of  Kraken  against a clairvoyant policy (Oracle) that has 100% load prediction accuracy.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Data streaming and partial compute storage are facilitated by four double buffered SRAM structures, with the \nweights residing in a double buffered multi-banked SRAM. These super-tiles Each tile, individually switchable ON or OFF based on power availability, houses 64 16-bit Ô¨Çoating point MAC units conÔ¨Ågured in an 8  √ó  8 systolic array for convolution operations. A modular computational approach is adopted where each tile is accountable for one CNN kernel, necessitating  ‚åà [ C  √ó H  √ó W ] / 64 ‚åâ iterations for a kernel of size [ C  √ó H  √ó W ] .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "4. In Step  1  , same as our FL scheme discussed in Sec. IV-A, the bounding boxes (BBoxes, in red) are extracted by the ‚Äúfull-inferenced‚Äù previous frame, and the MVs are obtained from the current frame (Frame-3).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Fig. 7: The proposed frame-level reuse and tile/region-level reuse design blocks implementation; BB/BBox: bounding boxes from the last FI; MV: motion vectors of the current frame; FM: feature maps for each layer from the last FI. Partial Inference:  In this case, rather than processing the whole frame, only the RoI blocks are fed into the CPU and, with the memoized feature maps from previous frame, the CPU is able to generate the desired result for the current frame as accurate as performing inference on a full frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "6b  b  . This approach tries to reduce the amount of hologram computation by approximating each of the holograms based on the distance between the user and the object. ‚Ä¢  Inter-Intra-Holo : The above two designs can be integrated to- gether into the original hologram pipeline, in either Inter-then- Intra or Intra-then-Inter fashion.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "In  2019 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 331‚Äì344. IEEE, 2019. [83]  Neeraja J. Yadwadkar, Francisco Romero, Qian Li, and Christos Kozyrakis.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Probability:  As alluded to in Section 2, one of the factors used in function weight estimation is its invocation probabil- ity. The procedure in Section 3 describes how the transition probabilities of the states associated with functions are com- puted through repeated matrix multiplications of the Transi- tion Matrix, ùëá with the Probability Vector,  ùëÉ . ùê∂ùëúùëöùëùùë¢ùë°ùëí _ ùëÉùëüùëúùëè , \n158 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nin Algorithm 1, first estimates the invocation probabilities of a function‚Äôs immediate predecessors and uses it along with system log information and load measurements of the function to calculate its invocation probability.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 176,
    "augmented": true
  },
  {
    "text": "Many prior works [ 2 , 25 , 35 , 63 , 74 , 75 ] have extensively tried to reduce model latency by reducing overheads due to shared resources and hardware interference. We believe that our proposed policies can be complementary and beneÔ¨Åcial to these prior works to reduce the cost and resource footprint of ensembling. There are mainstream commercial systems which automate single model-serving like TF-Serving [ 60 ], SageMaker [ 6 ], AzureML [ 10 ], Deep-Studio [ 28 ] etc.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "[22] M. Motamedi, D. D. Fong, and S. Ghiasi, ‚ÄúFast and Energy-EfÔ¨Åcient CNN Inference on IoT Devices,‚Äù  CoRR , 2016. [23] C. Wu, D. Brooks, K. Chen, D. Chen, S. Choudhury, M. Dukhan, K. Hazelwood, E. Isaac, Y. Jia, B. Jia, T. Leyvand, H. Lu, Y. Lu, L. Qiao, B. Reagen, J. Spisak, F. Sun, A. Tulloch, P. Vajda, X. Wang, Y. Wang, \nB. Wasti, Y. Wu, R. Xian, S. Yoo, and P. Zhang, ‚ÄúMachine Learning at Facebook: Understanding Inference at the Edge,‚Äù in  Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA) , 2019, pp. 331‚Äì344.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 240,
    "augmented": true
  },
  {
    "text": "How Much to Memoize? Thus, we memoize both head orientation and its corresponding projec- tion matrix (i.e., projection computation results) in a memory buffer, namely,  P buff , and use the head orientation to index the address/pointer of that  P buff  stored in DRAM. The occupied DRAM size is mainly determined by  P buff .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "This is because that all the nodes in the tree are traversed sequentially. ‚Ä¢  Entropy Encoding:  To further compress the generated occupy bits vector, a typical encoding technique ‚Äì Entropy Encoding [ 35 ], [ 60 ] ‚Äì is employed. ‚Ä¢  Compressed Geometry Stream (Output):  The Ô¨Ånal com- pressed geometry output stream is ready to be stored in the memory or streamed over the network.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Building meta‚Äôs genai infrastructure, 2024. [105] Meta. Our next-generation meta training and inference accelerator, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": ". In this signed representation, the Gaussian distribution ranges from  [0 , ks )  to  [ q  ‚àí ks,  0) , where  k  takes integer values  1 ,  2 ,  3 , . .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Accessed: 2023-10-20. [101] Sadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason D Lee, Danqi Chen, and San- jeev Arora. Fine-tuning language models with just forward passes.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "C. Accuracy Results \nBaseline:  We choose two baselines for our evaluation: 1) Baseline-1 consists of the original DNNs built along the lines of [11], [14] (without any pruning). 2) Baseline-2 uses state of the art pruning techniques described in [3], [15] to prune the DNNs of Baseline-1 to Ô¨Åt the average harvested power budget from our harvesting trace described in Section IV-A. Both the baseline setups run on a fully powered system equipped with a steady power source.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "IEEE, 154‚Äì161. In  2020 IEEE International Conference on Cloud Engineering (IC2E) . The ifs and buts of less is more: a serverless computing reality check.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Restrictions apply. Figure 1: Example PC applications and processing pipelines. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Alisa: Accelerating large language model inference via sparsity-aware kv caching. [193] Youpeng Zhao, Di Wu, and Jun Wang. arXiv preprint arXiv:2303.18223 , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Fig. 10a  shows the contribution of the different components of  Us. When power is highly uncertain, the morphable hardware also strongly contributes, however, as the power proÔ¨Åle becomes stable, the algorithmic contributions dominate.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "This means that only a portion of computation results from   ‚àó Tile count 1   to  Tile count 1   will be discarded. The discussion on this transition without power prediction is applied for transitions 1  and 2  in the Figure 7. We call this smooth transition strategy as  Transition Keep .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "A storage platform entirely designed with CSDs is not pragmatic at the current time because of their exorbitant cost and power consumption (AMD, b; Cao et al., 2020) . However, a combination of CSDs with classical storage medium provides the most optimal solution and hence motivates our design. Edge Server \nPCIe Root COmplex \nFPGA \nCSD \nCSD \nFPGA \nAccelerator \nFigure 2: High-level design of the  Salient Store  edge server - it consists of the accelerated video analytics compute along with computational storage and classical storage drives.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing , HPDC ‚Äô24, page 227‚Äì239, New York, NY, USA, 2024. Association for Computing Machinery. [103] Eitan Medina and Eran Dagan.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Note that this additional eye tracking proce- dure needs to be invoked for each frame, in order to capture/reflect the current eye movements without causing nausea for the user. Fortunately, there already exist a large body of techniques which can track the eye movements efficiently (e.g., see [ 26 ] and [ 12 ] and the references therein). As a result, eye tracking needs to incur minimum overhead, while providing a fairly good accuracy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "The feedback from industry will help us fine tune our proposed EoE models. K12 and Outreach : Our outreach plans include involvement of underrepresented groups in computer science and engineering and various K-12 related activities. Furthermore, the PIs will leverage additional connections through their former students working in these companies.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "However, when applied to low-dimensional sensor data, classical lossy compression techniques tend to discard or distort some important fea- tures, which significantly degrades the inference accuracy. To mitigate the shortcomings of classical compression tech- niques, recent works [ 7 ,  36 ,  37 ] propose using  coresets , a data representation technique from computational geometry that preserves important, representative features when building a compressed form of the data, and thereby reducing the pay- load size while preserving data integrity for efficient edge communication. Although, with the help of coresets, one can efficiently offload minimal input representations to a more compute-capable device, performing accurate inference on coresets is non-trivial due to their low-dimensional nature.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 172,
    "augmented": false
  },
  {
    "text": "[28] J. R. Gunasekaran, C. S. Mishra, P. Thinakaran, B. Sharma, M. T. \nKandemir, and C. R. Das, ‚ÄúCocktail: A multidimensional optimization for model serving in cloud,‚Äù in  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , 2022, pp. 1041‚Äì1057. [29] U. Gupta, Y. G. Kim, S. Lee, J. Tse, H.-H. S. Lee, G.-Y.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Even though the accuracy claim of the models was nearly 85%, in the Ô¨Årst iteration, the accuracy drops below 80% because of the added noise. 6), that Origin  keeps up with the claimed accuracy (base accuracy), and at times outperforms it. As the conÔ¨Ådence matrix gets updated with the newer conÔ¨Ådence values sent from the sensor, we can see (from Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "An ideal scheme would focus on packing more number of requests per container to improve utilization without caus- ing SLO violations. Kraken  shows 4x, 2.16x and 2.06x more container utilization compared to  Arch ,  Fifer , and  Xanadu respectively. This is because  Kraken  limits the number of containers spawned through function weight assignment and request batching.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "In Kevin Duh, Helena Gomez, and Steven Bethard, editors,  Findings of the Association for Computational Linguistics: NAACL 2024 , pages 1417‚Äì1428, Mexico City, Mexico, June 2024. Association for Computational Linguistics. [182] Wei Zhang, Chen Liu, Xinyu Wang, and Jian Li.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "However, this poses a chicken and egg problem ‚Äì to know which sensor is the best for classifying an activity we need to know what activity is going to be performed beforehand. However, while perfect future knowledge remains impossible, in the context of HAR, we can anticipate the next activity from the previous activity with high conÔ¨Ådence. Intuitively, human activities do not usually stop abruptly, i.e.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "The current commercial- of-the-shelf (CotS) hardware capable of performing such \nHarvester \nAmbient Energy \nAC-DC Converter Impedance \nMatching \nDC-DC Converter \nController \nPower Management/\n \nConditioning \nEnergy Storage¬†\n \nSensor/ Compute \n(a) High-level overview of an energy harvesting sys- tem. Need for Specialized Hardware:  One of the major chal- lenges in deploying learning tasks using EH-WSNs is to find the proper hardware platform. Communicate elsewhere \n0-50 50-500 500-1k 1k-10k > 10k Harvested/available power in the sensor node (¬µW) \nCompute at the edge \nCOTS high-end wearables  (bat.)",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "[4] The state of ai in early 2024: Gen ai adoption spikes and starts to generate value. Accessed: 2024-10-22. tome01.com/exploring-llms-real-world-case-studies-in-ai-generated-art- literature , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "650‚Äì657, May 2007. [16]  X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, ‚ÄúRF-powered systems using steep-slope devices,‚Äù in  2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS) , pp. 7, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "The cost incorporates energy consumption and future op- portunities. Let  e i ( t )  be the energy expenditure for sensor s i  if it participates at time  t , accounting for capture, infer- ence, and communication costs. Introduce a discount factor Œ≤  ‚àà [0 ,  1) , and let  V i ( t  + 1)  represent the expected future utility of sensor  s i  given its current decisions and predicted energy availability.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "252 \n[22] A. [21] L. F. Hodges, ‚ÄúTutorial: Time-multiplexed Stereoscopic Computer Graphics,‚Äù  IEEE Computer Graphics and Applications , pp. 20‚Äì30, 1992.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Video meta-information:  This contains the additional infor- mation, such as frame rates, video semantics/types, etc., about the video inputs. Video Type (Cam movement/focus of attention direction) \nFrame Rate (fps) \n#Frames Bit Rate (kbps) \nV1 Rhinos [4] Stationary cam, no focus direction 30 3280 13462 \nV2 Timelapse [56] \nStationary cam, fast-moving objects, no focus direction \n30 2730 15581 \nV3 Rollercoaster [35] \nFast-moving cam hooked in front of a rollercoaster, uni-direction focus \n29.97 6194 16075 \nV4 Paris [51] \nStationary cam, smooth scene cuts, no focus direction \n59.94 14629 14268 \nV5 Elephants [5] Stationary cam, uni-direction focus 30 5510 16522 \nthis work, we are focusing on reusing computation results rather than reducing the content maintenance/transfer, and hence do not consider that optimization. This feature can only be used as an add-on, along with other inputs to further improve compute reuse scope.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 259,
    "augmented": true
  },
  {
    "text": "[49] S. Li, Z. Yang, D. Reddy, A. Srivastava, and B. Jacob, ‚ÄúDramsim3: \na cycle-accurate, thermal-capable dram simulator,‚Äù  IEEE Computer Architecture Letters , vol. 6765‚Äì6816, 2017. 1, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:1907.04018  (2019). [53]  Dhiraj Neupane and Jongwon Seok. 2020.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Videos # Frames # Avg. Objects Static/Dynamic Object/Full Frame Description V1  [33] 20655 Medium Medium Small A few people and cars move in the parking lot V2  [33] 9075 Medium Medium Small More activities of people in the parking lot GL1  [43] 6477 More Dynamic Medium More activities of people and cars in the parking lot HC1  [43] 6000 More Dynamic Medium People do exercises in a garden P1  [42] 3915 Less Dynamic Small-Large Several people walk around in a room P2  [42] 2955 Medium Dynamic Small-Large More people than P1 in the room \n0% \n20% \n40% \n60% \n80% \n(a) FI+SI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead \n(b) FI+SI exec. time \n0% \n20% \n40% \n60% \n80% \n(c) FI+SI+PI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead Partial \n(d) FI+SI+PI exec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 244,
    "augmented": false
  },
  {
    "text": "They employ autoscaling mechanisms to cope up with dy- namic load. These autoscaling mechanisms can be of two types: (i) spawn VMs if the resource utilization of existing VMs reaches a certain threshold (80% in most cases) [ 9 ], and (ii) spawn additional VMs than predicted request demand [ 6 ]. Prior works  [ 3 ,  9 ] have tried to solve the resource scal- ing problem with respect to hosting the applications in VMs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Us. ¬¥as  closely tracks oracle, where as DaDianNao [ 16 ] falls short. ¬¥as  with eager scheduling vs an oracle scheduler.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "[72]  Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. Tutorial at Association of Computational Logistics (ACL) , 2012. Deep learning for nlp.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "[70] A. Prabhu, C. Dognin, and M. Singh, ‚ÄúSampling bias in deep active \nclassiÔ¨Åcation: An empirical study,‚Äù  arXiv preprint arXiv:1909.09389 , 2019. [71] I. X. G. Processors, ‚ÄúRankings about energy in the world,‚Äù https://www.intel.com/content/www/us/en/products/details/processors/ xeon/scalable/gold/products.html , (Accessed on 11/21/2022). [72] K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, \nJ. Sampson, M. T. Kandemir, and V. Narayanan, ‚ÄúResirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent em- bedded processors,‚Äù in  2020 IEEE International Symposium on High Performance Computer Architecture (HPCA) .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 238,
    "augmented": false
  },
  {
    "text": "Most of these works rely on software checkpointing (static and dynamic (Maeng & Lucia, 2018), refer ¬ßAppendix C) to save and restore, while some of the prior works developed nonvolatile hardware (Ma et al., 2016, 2017) which inherently takes care of the checkpointing. Considering the scope of these initiatives, it is crucial to acknowledge that, despite the substantial support for energy harvesting and intermittency management, developing intermittency-aware applications and hardware necessitates multi-dimensional efforts that span from theoretical foundations to circuit design. Intermittent DNN Execution/Training:  As the applications deployed on such EH devices demand analytics, executing DNNs on EH devices and EH-WSNs have become prominent (Lv & Xu, 2022; Gobieski et al., 2019; Qiu et al., 2020; Mishra et al., 2021).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 226,
    "augmented": false
  },
  {
    "text": "Recently, state-of-the-art AR headsets such as HoloLens [ 31 ] have even been planning to integrate the holographic processing units (HPUs) for processing the information coming from all of the on-board sensors (currently under development) [32]. 1b, e.g., CPUs for generic processing, GPUs for graphics computing, vision processing units (VPUs) for rendering, and tensor processing units (TPUs) for learning infer- ences. On-board Battery:  It is to be noted that all of the sensors and the processing engines mentioned above are  battery-backed , as shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "A 128kB SRAM serves as a scratchpad for storing activations, transposes, and intermediate differentials during the backward pass. The accelerator also houses 256  √ó  256 compactor-mux combinational logic units (256 units per tile) for ReLU activation (forward pass) and inverse activation (backward pass). For smaller DNNs without 256 kernels in any layer, a batching mode is operational with a batch size of  B  =  ‚åä A / L ‚åã images, where  L  denotes the layer with the fewest channels, and  A  the number of active tiles.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "Syst. , 32(C):82‚Äì98, March 2014. [41]  Aaron Harlap, Andrew Chung, Alexey Tumanov, Gregory R. Ganger, and Phillip B. Gibbons.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "As part of compiling a CNN to ResiRCA, we build a proÔ¨Åling table relating each potential tiling and pipeline conÔ¨Åguration \nthat might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw. This proÔ¨Åling collects data used to determine the best activation solution for each power level. At runtime, each time when entering a new power cycle, we Ô¨Årst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Furthermore, it then applies innovative coreset techniques to efficiently and intelligently offload unfinished compute tasks to a more capable host to further increase the inferences that can be performed. Seeker  fo- cuses on building an efficient EH-WSN which can collabora- tively work to maximize the inferences performed at the EH- edge nodes. Towards this, we propose  Seeker , a novel approach that leverages and extends coresets to efficiently execute DNN inference across a set of EH sensor nodes and a host mobile device.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "[156] Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R. Das. Accessed: 2024-10-20. Kube-knots: Resource harvesting through dynamic container orchestration in gpu- based datacenters.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Classically, video data is streamed simultaneously to compute and storage systems for various processing tasks, such as inference, exemplar selection, and storage, thereby increasing I/O bandwidth and system processing demands. This processing complexity necessitates substantial compute and memory resources, escalating power consumption \n1 Management and retrieval of data typically utilize a vector database like file-system, although this is beyond the scope of this discussion. 2 \nData Task Algorithm % CPU Utilization % DRAM Utilization 16 Core Xeon Peak Average All Encryptions RSA512 2.18 14.56 5.85 All Decryptions RSA512 3.45 17.2 6.12 \n3D PC Compression OctTree 26.78 78.2 32.54 Inflation OctTree 29.24 81.56 36.18 \nVideo \nCompression ZStd 24.7 62.54 24.5 Inflation ZStd 22.6 79.18 29.43 Compression H264 12.85 52.46 21.4 Inflation H264 14.2 69.46 26.18 All (un)RAID Unraid 11.25 29.4 19.24 Table 1: Resource utilization while running different algorithms under classical data archival pipeline for multiple data modalities in an AWS h1.4xlarge storage-optimized instance.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 292,
    "augmented": false
  },
  {
    "text": "B Why DeepARest Model? We quantitatively justify the choice of using DeepARest by conducting a brick-by-brick comparison of the accuracy loss \n1056    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nwhen compared with other state-of-the-art prediction models used in prior work. Table  4  shows the root mean squared error (RMSE) in- curred by all the models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Adaptive Tuning:  If conditions change over time, adjust Œ≥, Œ¥,  and  Œ∑  dynamically based on observed participation rates, accuracy levels, and energy depletion patterns. Exploration Algorithm \nAlgorithm  3  outlines a systematic approach to exploring suit- able hyperparameter values. 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "The for- ward pass computes activations via the formula  A muv  = ‚àë C ‚àí 1 \nc = 0   ‚àë H ‚àí 1 \ni = 0   ‚àë W ‚àí 1 \nj = 0   X ( u + i )( v +  j ) c   ¬∑ K mijc , with results stored in the double-buffered output feature map SRAM. In DNN training, meticulous compute mapping, mem- ory access strategies, and operational formulas are instru- mental for the forward and backward passes. The backward pass emphasizes gradient computation through backpropaga- tion, which is crucial for weight updates.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "Figure 15 shows the breakdown of total number of containers spawned for each application, aver- aged across all realistic large-scale traces using the simulator. Consequently, Oracle  does not suffer from cold starts and minimizes con- tainers spawned. 6.2.1 Sensitivity Study : This subsection compares  Kraken against  Oracle , which is an ideal policy that is assumed to be able to predict future load and all path probabilities with 100% accuracy and also has request batching.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Considering the fact that we do have access to the sensor data to train the learning algorithm, we can use the same data to train the GAN and with sufficient data, the discriminator could generate the lost signal with minimum error. Our experiments show that the deviation from the original signal, in most cases, is limited to  ‚â§ 15%. However, in some pathological cases, the error at times goes close to 60%, and we believe them to be generated artifacts which are common side effects of the GANs[ 11 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "1. Second, by increasing the number of depth planes, it takes around 2 √ó  latency to generate a hologram with 2 √ó  number of depth planes. As also mentioned in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:1701.06538 , 2017. [146] Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Beidi Chen, Percy Liang, Christopher R√©, Ion Stoica, and Ce Zhang. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Task- 1.4: Algorithmic Choices Informed by System and Hardware Constraints. Task-1.1: EoE Design Space Exploration In order to address the limitations of the state-of-the-art monolithic LLMs, in this task, we propose to make a paradigm shift by laying the algorithmic foundations for an EoE system, a novel LLM framework consisting of numerous expert models that can be composed into an ecosystem  dynamically  according to the user query. The main objective of this morphable design is to minimize the resource requirements and training/inference time compared to gigantic monolithic models, while maintaining required accuracy needs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Prior works on intermittent learning have either chosen one teacher model \n900 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "Depending on the application type, the maximum ensemble size can vary from tens to hundreds of models. These re- sources are available in different types including CPU/GPU instances, burstables and transient instances. The entire model framework is typically hosted on re- sources like VMs or containers in public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Central to the Ring-Learning with Errors (R-LWE) based Public Key Encryption (PKE) is the equation d  =  a  ¬∑  b  +  c . During the data loading phase, the 256 coefficients of polynomial  b  are input serially into a 6-bit shift register. In this context, the operand  a  can represent polynomials such as  p ,  a , or  c 1  from Algorithm 1, while  b  corresponds to  e 1 ,  r 2 , and  c  to  e 2 ,  e 3 ,  c 2 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "Similarly, the overhead introduced by Algo. 1 to YOLOv4- tiny is not too much ‚Äì  5%  of the baseline execution latency, as shown in Fig. 9b.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Note that, this step also needs to be performed sequentially across the tree layers. Takeaway:  The prior octree-based works for both geometry and attribute compression suffer from performance inefÔ¨Åcien- cies, mainly because the octree construction, serialization and attribute transformations involve sequential computations. To improve the performance, next we want to explore the hidden spatio-temporal locality opportunities (missed by the prior works), and speed up  both  the geometry and attribute compression from  both  the intra- and inter-frame perspectives.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "0 \n150 \n300 \n450 \n600 \nArch Fifer DProb Kraken SProb Xanadu \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(b) Media Service. 0 \n150 \n300 \n450 \nArch Fifer DProb Kraken SProb Xanadu \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(c) Hotel Reservation. Figure 9: Real System: Breakdown of Average End-to-End Response Times in terms of queueing delay, cold start delay and execution time.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "The cost is calculated as the cost per hour of EC2 c5.xlarge instance use, billed by AWS [ 5 ]. We ensure all instances are fully utilized by packing multiple requests in accordance to the  P f  . As shown in Figure  3b , Ensemble-OD is always ex- pensive than single-OD for the all the models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "2) introduced by our proposal amount to only  0 . 5%  of the end-to-end execution latency (the baseline YOLOv3 inference). 1 and Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "The time taken to spawn new VM takes about 60s to 100s de- pending on the size of the VM instance. The time taken to choose models from the model-cache is less than 1ms. The end-to-end response time to send the image to a worker VM and get the prediction back, was dominated by about 300ms (at maximum) of payload transfer time.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "We illustrate the  360 ¬∞ video projection/projection transfor- mation 3   computation in Fig. 2b. At a high level, we need two major inputs to generate the Ô¨Ånal projected frames on the display.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "We implemented our FI and PI on top of the ncnn library [5]. mean Average Precision (mAP) : The accuracy of the DNN models for object detection can be quantiÔ¨Åed by mAP [40], to evaluate how well the estimated results match the ground-truth. To get mAP, the precision for each class is Ô¨Årst calculated across all of the Intersection over Union (IoU [41]) thresholds, and the Ô¨Ånal mAP will be the averaged precision of all classes (the higher, the better).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Holographic 3-D Displays - Electro-holography Within the Grasp of Commercialization . 2010. [52]  Stephan Reichelt, Ralf Haussler, Norbert Leister, Gerald Futterer, Hagen Stolle, and Armin Schwerdtner.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "2009. [115] Abhinand Nasari, Lujun Zhai, Zhenhua He, Hieu Le, Suxia Cui, Dhruva Chakravorty, Jian Tao, and Honggao Liu. Porting ai/ml models to intelligence processing units (ipus).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "(II) Computational Approximation : To address (I) and maintain continuous operation, EH-WSNs may skip some compute during energy shortfalls by dropping neurons (zero padding) or by approximating computations (quantization). Depending on the EH profile, this might lead to significant delays and SLO violations. When the income falls below the threshold, the system halts the inference and checkpoints the intermediate states (via software or persistent hardware) (Maeng & Lucia, 2018; Qiu et al., 2020), resuming upon energy recovery.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "It can be seen that the maximum latency of  Cocktail  is similar to the 75th PCTL latency of  InFaas . The total response latency includes additional 200-300ms incurred for query serialization and data transfer over network. This is because the single model inference have up to 2x higher latency to achieve higher accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "It is also possible to use bigger VMs, which can handle more concurrent requests compared to m4-large, thus mini- mizing the total number of VMs used. It can be seen that virtual machines are always cheaper compared to using  serverless functions for all constant request rates. A similar trend is observed for the iso-accuracy model types, which is shown in Figure  3b .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "0 \n2 \n4 \n6 \n8 \n0 \n10 \n20 \n30 \n40 \n1 2 3 4 5 6 7 8 9 10 \nConvergence Error(%) \nBatch Size \nTranining Iterations Batch Size-Actual Batch Size-Oracle Convergence Error (%)-Actual Convergence Error (%)-Oracle \n(b) Batch-size and convergence. 0 \n5 \n10 \n15 \n0% \n20% \n40% \n60% \n80% \n100% \n1 2 3 4 5 6 7 8 9 10 \n# Exemplar/100 Frames \nExemplar vs Traning  \nTime \nTranining Iterations Exemplar Selection Tranining #Exemplar/100 frames \n(c) Exemplar selection w.r.t. training.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "in parallel with the help of Morton codes, which speeds up the geometry compression by  37 √ó ; 2). by utilizing the spatial locality with Morton code for attribute compression, instead of performing transforms through octree layers, in our proposal, only simple subtractions are needed for computing deltas. Further, all the points are processed in parallel; 3).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "As discussed in Fig. As one can observe from the  Intra- Holo  scenario shown in Fig. 3a, another enabler for computation reduction is the relative distance between the camera/user and the objects, i.e.,  left-right .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "We observe that the system used in [ 47 ] does not aggressively employ quantization, which is a commonly used technique [ 64 ] to reduce both compute and transmission energy in DNN tasks. Our analysis, as shown in Figure 2c, shows accuracy as a function of quantization (we took the approach of perform- ing post training quantization and fine-tuned the DNN to work with reduced bit precision instead of training the DNN from scratch with a reduced precision). The quantized DNNs benefit from lower compute and memory footprints, but need specialized fine-tuning and often suffer from lower ac- curacy.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "0 \n300 \n600 \n900 \n1200 \n1500 \nArch Fifer DProb Kraken SProb Xanadu \nJobs per Container \nFigure 11: Real System: Comparison of Container Utilization (a.k.a. average #jobs executed per Container). 0 \n300 \n600 \n900 \n1200 \n0.25 0.5 0.75 0.98 0.99 \nResponse Time (ms) \nCDF Archipelago Fifer DProb Kraken SProb SLO Xanadu \nFigure 12: Real System: Response Time Distribution.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Task-2.5: Runtime Support Our runtime support system will serve as the cohesive glue that efficiently manages system resources, models, and data in real-time with minimal overhead. It effectively addresses the operational efficiency and response quality within the constraints of stringent SLOs and a minimum accuracy rate. By integrating expert affinities (Expert‚ÄìExpert, Expert‚ÄìData, Expert‚ÄìRouter, and Expert‚ÄìComposition Function) detailed in Table 2, the system will optimize responsiveness and computational efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "7 , the Ô¨Årst frame, I- Frame, contains three points ‚Äì  P 0  with geometry data  [ 0 , 0 , 0 ] and an attribute value  50 ,  P 1  with  [ 12 , 8 , 13 ]  for geometry and 52  for attribute, and  P 2  with  [ 19 , 26 , 58 ]  for geometry and 20  for attribute. 3  b  , two blocks (a set of points) which are located close to one another are likely to contain similar color pixels. In the example shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Even today, more than 10 million users enjoy  360 ¬∞ videos \nusing Google Cardboard [10], Samsung Gear VR [44], and Oculus VR [8], to experience  360 ¬∞ video [7], art museum [9], live stadium [46], etc. Especially, VR and AR are now gaining traction because of their versatile nature of providing an immersive sensory experience, which is not possible with the conventional systems ‚Äì especially in the domain of video streaming. They are emerging as one of the most important entertainment markets and Goldman Sachs predicts that, by 2025, around 79 million users will use online video streaming from the VR/AR ecosystem, resulting in a multi-billion dollar market [20], penetrating the Ô¨Åelds of media streaming, VR gaming, education, medicine, communication and many more.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "517‚Äì531. [69]  Haibo Zhang, Shulin Zhao, Ashutosh Pattnaik, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "A low latency router supporting adaptivity for on-chip interconnects. ACM SIGARCH Computer Architecture News , 34(2):4‚Äì15, 2006. [81] Jongman Kim, Dongkook Park, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Towards this, in this thrust, we propose to explore a novel ‚Äúchiplet-based‚Äù custom hard- ware platform. In terms of cost, utilization, power, and area require- ments, we expect several inefficiencies with existing off-the-shelf hardware like CPUs and GPUs when executing our models for training, inference, and re-training purposes, thus exacerbating the gap towards democratization. Chiplet-based designs have shown great promise for integrating a variety of modular chips, both homogeneous and heterogeneous, on a silicon interposer [72,152] and is a great fit for our envisioned modular and fault-tolerant design.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "ISSN 0016-0032. doi: https: //doi.org/10.1016/j.jfranklin.2023.11.038. Journal of the Franklin Institute , 2023. URL  https://www.sciencedirect.com/science/ article/pii/S0016003223007536 .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Therefore, the resource manager should be able to leverage this information to make optimal serverless function configuration decisions. 4 Evaluation and Initial Results \nThis section introduces how an ML-serving framework can capitalize on the design choices discussed in Section  3 . Also, these policies can be changed over time by Amazon, and they can also be dif- ferent for other cloud providers [ 8 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "This leaves an optimization space in trading between communication cost vs. accuracy, i.e. whether to construct strict and low-volume coresets and lose accuracy or to preserve maximum data points and pay for the communication cost . We perform an analysis on the MHELATH [ 9 ,  10 ] data set (we take a overlapping moving window of 60 data points sampled at 50Hz from 3 different IMUs, overlap size: 30 data points) to find a trade-off between the coreset size (directly related to the communication cost) and the inference accuracy.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "Due to this inherent nature of compute, the pattern between left eye and right eye can be easily  captured  by proÔ¨Åling the distance vector for only the Ô¨Årst row on the screens:  Œî = \u0002 ‚Éóx 0 r   ‚àí ‚Éóx 0 l   , ‚Éóy 0 r   ‚àí ‚Éóy 0 l \u0003 , as shown in line number  2  in Algorithm 1. How to capture the pattern and utilize the pattern? 7%  of the entire FoV frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "). Cooperative game theory has been used to encourage collab- oration among sensors to enhance network performance ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "2020. Firecracker: Lightweight Virtualization for Serverless Applications. In  NSDI .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "To achieve this, the router needs to be re- trained/fine-tuned according to the state of the expert network by taking advan- tage of expert-router affinity to the greatest extent possible. Since the ex- perts are pivotal in the way the prompt/query is being answered, it is equally imperative for the routers to fully utilize the expert network by directing the rel- evant queries to the right expert(s) dynamically depending on the current ex- perts being involved in the network. Unlike conventional networks, where an entire end-to-end training of the experts and routers needs to be done alike, our scheme makes use of a more targeted approach that can sig- nificantly reduce the training complexity of the routers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "https://docs.aws.amazon.com/ lambda/latest/dg/configuration-concurrency.html. Provisioned Concurrency. [4]  2020.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "time \nFig. 0% \n20% \n40% \n60% \n80% \n(a) FI+SI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead \n(b) FI+SI exec. time \n0% \n20% \n40% \n60% \n80% \n(c) FI+SI+PI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead Partial \n(d) FI+SI+PI exec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "case.edu/bearingdatacenter/download-data-file , 2018. Accessed: 2024-11-27. Graham Gobieski, Nathan Beckmann, and Brandon Lucia.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Cocktail  was also able to deliver modest accuracy gain \n1052    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nConst1 Const2 Const3 Const4 \nBaseline \n0 \n20 \n40 \nLatency-reduction \n0.50 \n0.75 \n1.00 \nAccuracy-Gain \n(a)  Image ClassiÔ¨Åcation:Cifar100. Const1 Const2 Const3 Const4 \nBaseline \n0 \n10 \n20 \n30 \nLatency-reduction \n0.6 \n0.8 \n1.0 \n1.2 \nAccuracy-Gain \n(b)  Sentiment Analysis. Figure 16:  Latency reduction (%) plotted as bar graph(primary y- axis) and accuracy gains (%) plotted as line graph (secondary y-axis) over InFaaS.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 178,
    "augmented": false
  },
  {
    "text": "Us. ¬¥as  excels as a candidate for continuous learning at all scales due to the hardware‚Äôs adaptability to varying data and model sizes. As data and model dimensions decrease, the hardware assistance‚Äôs impact becomes more pronounced, making  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "We hypothesize that the dropped sample should con- tain, although not important, sensor specific artifacts. And these artifact must have some pattern, if modeled correctly, could represent the lost data. Towards this, we designed and trained a generative adversarial network (GAN, see Figure 7b for the structural details) to recover the lost samples of the importance sampling.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Our exper- imental results reveal that,  HoloAR  provides 29% reduction in power consumption and 2 . 7 √ó  speedup, which collectively trans- late to 73% total energy savings compared to the baseline setup (Sec. 5.3).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Typically denser models are designed with more parameters (ex. NASLarge ) to classify complex \n1042    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nModel (Acronym) Params (10k) \nTop-1 Accuracy(%) \nLatency (ms) P f \nMobileNetV1 (MNet) 4,253 70.40 43.45 10 MobileNetV2 (MNetV2) 4,253 71.30 41.5 10 NASNetMobile (NASMob) 5,326 74.40 78.18 3 DenseNet121 (DNet121) 8,062 75.00 102.35 3 DenseNet201 (DNet201) 20,242 77.30 152.21 2 Xception (Xcep) 22,910 79.00 119.2 4 Inception V3 (Incep) 23,851 77.90 89 5 ResNet50-V2 (RNet50) 25,613 76.00 89.5 6 Resnet50 (RNet50) 25,636 74.90 98.22 5 IncepResnetV2 (IRV2) 55,873 80.30 151.96 1 NasNetLarge (NasLarge) 343,000 82.00 311 1 \nTable 1:  Collection of pretrained models used for image classiÔ¨Åcation. classes of images.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 317,
    "augmented": false
  },
  {
    "text": "The conductance values G1 and G2 of the ReRAM devices are set to the corresponding weight values for the multiplication operation. To perform multiplication-addition, we first apply the input voltages V1 and V2 to the rows of the crossbar array. The output currents I1 and I2 are then computed as follows: \nI  =  I 1 +  I 2 =  G 1  √ó  V  1 +  G 2  √ó  V  2 \n23 \n(a) Re-RAM Cell \n(b) A Full Re-RAM tile \nFigure 5: DNN computation using ReRAM xBAR.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Finally, we provide a sensitivity analysis to understand the effect of different hyper-parameters on the accuracy and latency. II. E DGE -C LOUD  P ARTITIONING  P OLICIES \nIn this section, we discuss the various policies to \nCloud  Server \nDeploy 1 \nDeploy 2 \nDeploy 3 \nDeploy n \nData_1 Data_2 Data_3 Data_n \nDevice_1 \nDevice_2 \nDevice_3 \nDevice_n \nData Shared \nRF_1 RF_2 RF_3 RF_n \nPeer connections for Policy 2 \n(a) Data Sharing Policies.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "To prune, or not to prune: exploring the efficacy of pruning for model compression. [199] Yang Zhu, Luke Zettlemoyer, and Jimmy Ba. arXiv preprint arXiv:1710.01878 , 2017.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "3.2.3 Provisioning Time vs Execution Time  We know that new VMs take a few hundred seconds to start-up. Server- less functions  can start-up much faster (1s-10s), but they also incur additional latency to load a pre-trained model from external data-store. Prior literature [ 5 ,  10 ] tries to hide the model load latency by pre-warming serverless function in- stances through periodically issuing dummy requests.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "2.3 Why Not More Compute at Storage Stacks? Integrating additional compute capabilities within storage stacks to offload certain computational tasks may seem an intuitive solution to the problem at hand. This strategic compute-reuse could help in optimizing the efficiency and efficacy of computational operations, especially in large scale data intensive and data driven applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "What (features) to Memoize? As discussed earlier, at any moment during VR video processing, the execution pipeline is not only impacted by the head orientation, but also by other features such as video frame rate, video types/semantics information, pixel values, user interactions. To better under- stand which of these are the best candidates ( features , using machine learning parlance) for memoization and whether they are sufÔ¨Åcient or not, we next discuss input parameters and their impact on the computation: ‚Ä¢  Head orientation:  Any changes in this affect the matrix T 2  as discussed in Tab.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "12, pp. 2935‚Äì 2947, 2017. [51] M Sandler, A Howard, Menglong Zhu, Andrey Zhmoginov, Liang- \nChieh Chen , ‚ÄúMobilenetv2: Inverted residuals and linear bottlenecks,‚Äù in  CVPR , 2018.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "gov/news/0728-storage-device/ . (Accessed on 11/13/2023). Shiju Li, Kevin Tang, Jin Lim, Chul-Ho Lee, and Jongryool Kim.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Observing this, we propose to develop an evaluation framework with three components. The first compo- nent of this framework will employ actual machine experiments on Argonne National Lab (ANL) machines (see the collaboration letter from ANL and our preliminary results [26]). Given extremely long training latencies, we cannot rely on simulation alone as it would take extremely long running times.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "3. Adding regularizer gradients  Œª 1 ‚àá ‚Ñ¶ SNR ( Œ∏ k )  and Œª 2 ‚àá ‚Ñ¶ complexity ( Œ∏ k ) . 5: A subset of sensors, determined by the equilibrium, send their gradient estimates to the aggregator.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Moreover, more than 40% of requests show significant variability in inter- arrival times. To deal with such traces, we modified  Kraken ‚Äôs load prediction model to predict future request arrival times, owing to the sparse nature of the trace. We also spawn con- tainers much more in advance than the predicted arrival time and also keep them alive for at least a minute before evicting them from memory, to account for arrival unpredictability.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "We postpone optimizations for such applications to a future work. The proposed  HoloAR  on the edge GPU cannot achieve such strict la- tency requirement, and can cause lagging, e.g., the eye could move to another area, while the hologram is still being computed for the previous focus region. 5.5 Future Work \nDespite the hardware-agnostic nature of  HoloAR , it is still in- teresting to study how to deploy our idea on an ASIC hardware, and co-design the next-generation accelerator on edge for the AR hologram.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "This includes the intermittent failures ( ‚â§ 20W where no compute could be done); we included check- pointing to ensure that progress is saved in power-failures. Note that, even with DVFS, most scheduled compute could not be Ô¨Ånished. C/S is the ratio of  C ompleted over the  S cheduled training tasks over multiple time windows of 4hours.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "The SDMM also offers a simpler controller design for multiplication and in-place product term reduction after vector-vector multiplications. Notably, the SDMM can be easily reconfigured to support any modulus. 5 Implementation and Evaluation \nTo implement and evaluate  Salient Store  , we chose two different platforms ‚Äì 1) Using a server- grade system with two Xilinx-Samsung computational storage drive (AMD, b), and 2) Using amazon web services (AWS) F1 instances, which have AMD Alveo FPGA which can work as the compute capable of peer-to-peer communication and thereby enabling a computational storage platform.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "We picked the constraints using a similar procedure by ordering constraints across Ô¨Åve different categories for  CIFAR-100 ,  SST-2  and SemEval  (twitter tweets) datasets. The list of models used for them are given in the Appendix. Note that the latency is the raw model execution latency, and does not include the addi- tional network-transfer overheads incurred.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Our evaluations indicate 2.2 √ó speedup and 56 %  energy saving over the baseline setting. SpeciÔ¨Åcally, we propose and evaluate two schemes (for skipping the inference, and bypassing the compute for unimportant regions), to improve performance and save energy. In contrast, this paper revisits the  < accuracy, energy, performance >  design space, and tunes the design knobs adaptively with the changing constraints of applications over time.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "For annotating the incoming video stream we use three teachers models, namely, ResNet101 [ 32 ], YOLOV2 [ 22 ], and VGG16 [ 87 ]. For sustainability, we use solar power to perform our compute. Since our dataset is from Bellevue, WA, we took the SOLRAD solar radiation data [ 25 ] (managed and published by National Oceanic and Atmospheric Administra- tion, NOAA) of Seattle, WA (the SOLRAD center closest to Bellevue and hence we believe is a good approximation).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 136,
    "augmented": false
  },
  {
    "text": "Deepspeed-fastgen: High-throughput text generation for llms via mii and deepspeed-inference. arXiv preprint arXiv:2401.08671 , 2024. [65] Connor Holmes, Masahiro Tanaka, Michael Wyatt, Ammar Ahmad Awan, Jeff Rasley, Samyam Ra- jbhandari, Reza Yazdani Aminabadi, Heyang Qin, Arash Bakhtiari, Lev Kurilenko, and Yuxiong He.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "The prototyping efforts in the proposed research will be carried out primarily in the research labs at Penn State, directed by Das, Kandemir, and Zhang. The PIs‚Äô labs house several medium-sized clusters of rack-mounted servers connected via 10Gbps Eth- ernet switches. A large portion of our test and development will be performed on these machines.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "D. Adaptive Ensemble Learner \nAs discussed earlier in Section III-D, origin uses a lightweight and adaptive ensemble learner that performs weighted majority voting based on a conÔ¨Ådence matrix. The conÔ¨Ådence matrix adapts and learns from the user pattern. It is obvious that it is not feasible to train a DNN for all types and variances of human actions.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": ". . do 3: The aggregator signals that a training update round is imminent.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "Therefore, we also investigate a combined  Inter-Intra-Holo  scheme which com- bines both the schemes to further reduce the amount of hologram computations. Note that, both the  Inter-Holo  and the  Intra-Holo  schemes are complementary to each other, when both the eye tracking and pose estimation inputs are available at the same time. We would like to emphasize that the proposed  HoloAR  framework can, in principle, work with any hardware platform.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Huggingface‚Äôs transformers: State-of- \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1055 \nthe-art natural language processing. arXiv preprint arXiv:1910.03771 , 2019. [82]  Carole-Jean Wu, David Brooks, Kevin Chen, Douglas Chen, Sy Choud- hury, Marat Dukhan, Kim Hazelwood, Eldad Isaac, Yangqing Jia, Bill Jia, et al.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Our research, gos beyond the compute domain, and identifies the gaps in current storage system designs. To mitigate this, we propose  Salient Store  that specifically focuses on the integration of Computational Storage Devices (CSDs) into edge servers to enhance data processing and management, particularly in continuous learning scenarios, prevalent in fields such as autonomous driving and urban mobility. This is unfortunate as they contribute significantly to the data management and data movement, especially in a emerging complute landscape where date storage and data protection has be- come one of the key concerns.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "02%) accuracy loss. ‚Ä¢  Efficient Computation:  We augment a state-of-the-art EH-sensor node with quantized DNNs to increase the num- ber of accurate inferences at the edge (by up to 40%). We leverage data memoization to skip unnecessary compute saving inference execution time and energy.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Classically, once data is collected, it is classiÔ¨Åed, labeled, and bounded by borders (bounding box) mostly using manual labor (at times with software assistance) or crowd sourcing [ 33 ], [ 82 ], [ 88 ]. This requires the data to be present at a central location for manual inspection, both of which are not possible because of communication and privacy constraints. Therefore, we adapt a ‚Äústudent-teacher paradigm‚Äù [ 46 ], where a more \nClassify \nLow Conf \nFrame?",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Our Intra-Inter-V2 (Compression efÔ¨Åciency-oriented):  Sim- ilarly, our Intra-Inter-V2 scheme (oriented towards high \n293 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "[38] Oculus, ‚ÄúAsynchronous TimeWarp (ATW).‚Äù ‚Äùhttps://developer. [36] Nvidia, ‚ÄúJETSON AGX XAVIER AND THE NEW ERA OF AU- TONOMOUS MACHINES.‚Äù ‚Äùhttp://info.nvidia.com/rs/156-OFN-742/ images/Jetson AGX Xavier New Era Autonomous Machines.pdf‚Äù, 2019. [37] Oculus, ‚ÄúRendering to the Oculus Rift,‚Äù ‚Äùhttps://developer.oculus.com/ documentation/pcsdk/latest/concepts/dg-render/‚Äù.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments. When we change to a smaller ReRAM duplication granularity  G , we Ô¨Ånd that the throughput of  Pipelining  is better than that of  Sequential for many power levels. The duplication sensitivity results are presented in Section VI-F. ‚Ä¢  Regarding the throughput absolute values, the results with the power sources of  Thermal  and  TV-RF  are much higher than those with the others, which is constant with the power strength illustrated in Figure 4.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "For example, with octree-based PCC, considering a PC is con- tained in a  D √ó D √ó D  cube, the cube is recursively divided into 8  D / 2 √ó D / 2 √ó D / 2  sub-cubes until  D = 1 . The occupied/non- empty voxels in level n  can be indicated by the  occupy  bits of its ‚Äúparent voxel‚Äù (voxel in level n ‚àí 1 ). Each branch node in the octree stores 8 occupy bits, indicating the occupancy of its children/sub-cubes.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "Head Orientation Prediction for  360 ¬∞  Video Streaming: To optimize both performance and energy, researchers have leveraged the powerful remote rendering engines on cloud to predict the next head orientation for the VR clients [2], [6], [18], [23], [30]‚Äì[32]. FlashBack maintains a storage cache of multiple versions of pre-rendered frames, which can be quickly indexed by head orientations [2]. In comparison, Semantic- Aware-Streaming (SAS) exploits the semantic information inherent in a VR video content to precisely predict users‚Äô next head orientations [28].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": ". 8 \nAlgorithm 1  Neural Encoding and Compression using the video data inference pipeline. 1:  Input:  Video frames sequence  F  =  { f 1 , f 2 , .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "Kite: A family of hetero- geneous interposer topologies enabled via accurate interconnect modeling. In  2020 57th ACM/IEEE Design Automation Conference (DAC) , pages 1‚Äì6. IEEE, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Llm-mq: Mixed-precision quantization for efficient llm deployment. In  The Efficient Natural Language and Speech Processing Workshop with NeurIPS , volume 9, 2023. [96] Sean Lie.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "No. 501 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \nTable 2: Salient features of the six videos used in this study. We conclude this section by outlining some research directions for implementing approximation-based accelerators for AR holograms.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "[40]  Haoran Qiu, Subho S Banerjee, Saurabh Jha, Zbigniew T Kalbarczyk, and Ravishankar K Iyer. 2020. In USENIX ATC .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "[19]  Y. Feng, S. Liu, and Y. Zhu, ‚ÄúReal-time spatio-temporal lidar point cloud compression,‚Äù in  2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2020, pp. [18]  Eugene d‚ÄôEon, Bob Harrison, Taos Myers and Philip A. Chou, ‚ÄúJPEG Pleno Database: 8i Voxelized Full Bodies (8iVFB v2) - A Dynamic Voxelized Point Cloud Dataset,‚Äù  ‚Äùhttps://bit.ly/ 3cJQ61a‚Äù , 2017. 10 766‚Äì10 773.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "[7]  Akshitha Sriraman, Abhishek Dhanotia, and Thomas Wenisch. 2019. Softsku: Optimizing server architectures for microservice diversity@ scale.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "A large portion of our test and development will be performed on these machines. A variety of other grid computing resources are also freely available to their re- search groups. The PIs and their students also have access to grid and supercomputing resources through the College of Engi- neering at University Park.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "[38] MYO NeuralNet , ‚ÄúCalculating the Output Size of Convolutions and Transpose Convolutions,‚Äù ‚Äùshorturl.at/ioLRV‚Äù, 2020. [39] Qualcomm Technologies Inc., ‚ÄúSnapdragon 845 Mobile Platform,‚Äù ‚Äùshorturl.at/fouyP‚Äù, 2018. [40] L. Liu and M. T. Zsu,  Encyclopedia of Database Systems , 1st ed.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Mid + Residual:  Within each segment, since the points are located in small regions, their attribute values tend to have similar numbers. Therefore, instead of recording the exact attribute values for all the points within a segment, we only need to Ô¨Ånd the ‚Äú median value ‚Äù of these attributes (as base) and then compute and compress the  residual values (as deltas) for these points. SpeciÔ¨Åcally, with the Morton codes for all the points (i.e., the intermediate results from geometry compression without any additional overhead), we Ô¨Årst sort these points in the Morton code order, and then segment these sorted points into several blocks which can help to gather the points with similar positions/coordinates into one segment.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "1 , to obtain the occupy bits for one branch node, we Ô¨Årst calculate which branches its children should be on (e.g.,  C [  j ] %8  in Line #5), and then merge all of its occupied branches via the ‚Äú | ‚Äù operation. This inexpensive post-processing step can be applied to all branch nodes in parallel, thus does not bring much overhead. 3) What are the BeneÔ¨Åts and Drawbacks?",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "USENIX Association, 2018. [9] K. Ma, X. Li, S. Li, Y. Liu, J. J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúNonvolatile processor architecture exploration for energy-harvesting applications,‚Äù  IEEE Micro , vol. 35, no.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "First, due to the stateless nature of FaaS, individual mi- croservices have to be designed as functions and explicitly chained together using tools to compose the entire appli- cation, thus forming a Directed Acyclic Graph (DAG) [ 33 ]. Serverless com- puting (FaaS) has recently emerged as a first-class platform to deploy latency-critical user facing applications as it miti- gates resource management overheads for developers while simultaneously offering instantaneous scalability. However, deploying complex microservice-based applications on FaaS has unique challenges owing to its design limitations.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "[16] A. Reiss and D. Stricker, ‚ÄúIntroducing a new benchmarked dataset for activity monitoring,‚Äù in  ISWC . IEEE, 2012. [17] A. Reiss and D. Stricker, ‚ÄúCreating and benchmarking a new dataset for physical activity monitoring,‚Äù in  PETRA , F. Makedon, Ed.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Other recent works [9], [5], [7], [8] have proposed using energy harvesting (EH) solutions to provide additional energy and increase the battery life in IoT devices. Moreover, in addition to prolonging device lifetime, energy harvesting can help us reduce the environmen- tal impact of batteries [10]. These works provide software, hardware and compiler-level solutions, which can be applied to build a battery-less system working entirely on harvested energy.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Neural-Holography proposes an algorithmic hologram generation framework that uses camera-in-the-loop train- ing to achieve unprecedented image fidelity and real-time frame rates [ 48 ]. OLAS proposes an overlap-add stereogram algorithm, which uses overlapping hogels to encode the view-dependent light- ing effects of a light field into a hologram, achieving better quality than other holographic stereograms [ 46 ]. These display quality optimizations are orthogonal to our approximation-based proposal, and our approach can be used along with such optimizations.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 136,
    "augmented": false
  },
  {
    "text": "2) Energy Savings:  As shown in Fig. 8a, the YOLOv3 inference with the proposed FI+SI scheme only consumes  50% energy on average, with respect to the baseline, due to the fact that  53%  of the inferences can be skipped. The PI technique can further save  6%  more energy on average, as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "On the other hand, the  shoe  video frames typically contain more objects (2 . 3 on average, as shown in Tab. 2), thereby gaining more opportunities to reduce the amount of computations for all the objects in the current frame.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "This paper presents the  ResiRCA  architecture that integrates a new, lightweight, and conÔ¨Ågurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node. To maximize ResiRCA throughput under different power levels, we develop the  ResiSchedule  approach for dynamic RCA reconÔ¨Åguration. The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "Model-serving in Cloud : The most relevant prior works to Cocktail  are InFaas [ 83 ] and Clipper [ 27 ], which have been extensively discussed and compared to in Section  6 . Unlike them,  Cocktail‚Äôs  model selection pol- icy tries to right-size the ensemble for a given latency, while maximizing accuracy. Users also have the option to manually mention the ensemble size.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "2.2 Related Work \nEnsembling in practice : Ensembling is supported by com- mercial cloud providers like Azure ML-studio [ 11 ] and AWS Autogluon [ 31 ] to boost the accuracy compared to single models. Azure initially starts with 5 models and scales up to \nFeatures \nClipper [ 27 ] \nRaÔ¨Åki [ 80 ] \nInfaas [ 83 ] \nMArk [ 86 ] \nSagemaker \nSwayam [ 34 ] \nCocktail \nPredictive Scaling \u0017 \u0017 \u0017 \u0013 \u0017 \u0013 \u0013 SLO Guarantees \u0013 \u0017 \u0013 \u0013 \u0017 \u0013 \u0013 Cost Effective \u0017 \u0017 \u0013 \u0013 \u0017 \u0017 \u0013 Ensembling \u0013 \u0013 \u0017 \u0017 \u0013 \u0017 \u0013 Heterogeneous Instances \u0017 \u0013 \u0013 \u0013 \u0013 \u0017 \u0013 Dynamic ensemble selection \u0017 \u0017 \u0017 \u0017 \u0017 \u0017 \u0013 Model abstraction \u0013 \u0013 \u0013 \u0017 \u0017 \u0017 \u0013 \nTable 2:  Comparing  Cocktail  with other related frameworks. 200 using a hill-climb policy [ 17 ] to meet the target accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 170,
    "augmented": false
  },
  {
    "text": "In  Proceedings of 10th International Workshop on Accelerating Analytics and Data Management Systems (ADMS‚Äô19) , 2019. Fpga acceleration of zstd compression algorithm. Jianyu Chen, Maurice Daverveldt, and Zaid Al-Ars.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Battery (B) \nB \nEH \nƒÇ Sigmoid \n... \nReRAM Memory \nBasic MCU System \nB \nEH EH \nEH \nEH \nB \nFig. Pool Unit FC Unit \nAdder Tree \nResiRCA \nReRAM crossbar \n... \nADC&S+A \nDAC \nReRAM crossbar \nƒÇ \nTx/RX \nEnergy Harvestor Sensors \nEnergy harvesting (EH) \n... Output Reg.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "But, our dynamic policy with the class-based weighted voting, adapts to input images in a given interval by accurately selecting the best performing model for each class. To further demonstrate the effectiveness of our dynamic model selection, Figure  10b , 10c  plots the number models in every sampling interval along with cumulative accuracy and window accuracy within each sampling interval for three schemes. We observe that  Cocktail  can effectively scale up and scale down the mod- els while maintaining the cumulative accuracy well within the threshold.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Detailed Evaluation:  We provide a detailed evaluation of our system and the proposed hardware design. Our evalu- ations show that, even when powered by an unreliable EH source,  Seeker ‚Äôs coreset-based optimizations result in bet- ter accuracy than that of a fully-powered system running a state-of-the-art classifier optimized for energy efficiency. Specifically,  Seeker  reaches 86.8% top-1 accuracy in com- parison to the 81.2% accuracy of the baseline system.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Relating this to our problem, each coin represents a model, and an occurrence of head represents the model giving the correct classiÔ¨Åcation. This is a standard binomial distribution problem and can be solved by using the following formula: \nP head  = N ‚àë i = ‚åä N \n2   ‚åã + 1 \n\u0012 N i \n\u0013 a i   ( 1 ‚àí a ) ( N ‚àí i ) . Hence, the problem boils down to Ô¨Ånd the probability of at least  ‚åä N / 2 ‚åã + 1  heads when all N coins are tossed together.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Fast Calculation Method with Foveated Rendering for Computer-generated Holograms Using an Angle-changeable Ray- tracing Method. Appl. Opt.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands J.R. Gunasekaran, et al. 0 \n5 \n10 \n0 \n1 \n2 \nBerkley WITS Twitter Wiki \nSLO Violations \nNormalized Cost \nreactive util_aware exascale mixed \nFigure 5. Cost of using  mixed  compared to  util_aware  and  exascale , normalized to a baseline  reactive  scheme for four traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "2019. Distilling the Essence of Raw Video to Reduce Memory Usage and Energy at Edge Devices. In  Proceedings of the International Symposium on Microarchitecture (MICRO) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "The capability to adjust the quality dynamically, by decoding additional layers as resources permit, ensures efficient bandwidth usage and enhances the overall Quality of Experience (QoE), making layered neural codecs a compelling choice for modern video streaming solutions. In an effort to optimize video compression beyond traditional and current neural codec capabilities, we introduce an enhanced layered neural codec that utilizes both intra-frame and inter-frame redundancies. This allows for dynamic adaptation to network fluctuations and client-side computational capabilities, thereby optimizing the streaming experience.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "We intend to model this structure by building a  C hain Ensemble- o f- E xperts (CEoE), where layers are assigned for different classification criteria  a , and each expert in each layer is assigned for a type  t  under its classification  a , such as math in skills, medical in domains. Experts can be classified via a set of diverse criteria  a , such as domain, skills, and languages. During training, a document is routed to its type in criteria  a 1  and then routed to its type in another  a 2  until all criteria in  a  are covered.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "Task-1.3: Continual Adaptation of EoE through Morphable LLM Experts LLMs require continual learning to keep pace with rapidly evolving knowledge and user demands. For example, each expert in chains and trees can produce intermediate results, and they can be aggregated into the final manager expert to produce the ultimate result. How- ever, traditional monolithic LLMs are not well-suited for frequent updates, because training monolithic LLMs often involves wholesale replacement which is prohibitively expensive and challenging.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "In  2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA) , pp. 241‚Äì253, 2020. doi: 10.1109/ISCA45697.2020.00030. 23 \nShulin Zhao, Haibo Zhang, Cyan Subhra Mishra, Sandeepa Bhuyan, Ziyu Ying, Mahmut Taylan Kandemir, Anand Sivasubramaniam, and Chita Das.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "[186] Yusen Zhang, Ansong Ni, Ziming Mao, Chen Henry Wu, Chenguang Zhu, Budhaditya Deb, Ahmed Awadallah, Dragomir Radev, and Rui Zhang. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1592‚Äì1604, Dublin, Ireland, May 2022. Summ n : A multi-stage summarization framework for long input dialogues and documents.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "Still, we argue that, even with the Intra-Inter-V2 option (see one demo in Fig. 10a  iv  ) which has the worst quality, the absolute PSNR is close to  40 dB, which is sufÔ¨Åcient for many of the video applications that do not require very high resolution [ 6 ]. For other high-demanding applications like AR-based surgery [ 11 ], our proposals may jeopardize the video quality, and consequently, we may need further software and/or hardware optimizations for improved user experience.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "It dynamically adjusts training strategies, such as the intensity and timing of dropout and quantization, based on predictions of energy availability. We propose a dynamic adjustment of training parameters‚Äîdropout rates and quantization levels‚Äîthat adapt in real-time to the available energy, which varies in energy harvesting scenarios. This approach utilizes a model that integrates the characteristics of the network architecture and the specific energy harvesting profile.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Given a memory budget that limits the number of experts the system can host, the EoE network must  adapt  its structure to meet user needs. To this end, we can  prune  the network to a smaller number of experts by using three operations: (1) Remove, eliminating an expert from the graph. This can be achieved by deleting its vector in the gating function  g ; (2) Combine, combining several experts in one EoE layer.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Given all the other models have higher accuracy, the least accuracy we can expect with such an ensemble is 83%. This analysis forms the base of our ensemble technique, and hence proving the combination of multiple available models can be more accurate than the most accurate individual model. B Why DeepARest Model?",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "2020. Hyperion: A 3D Visualization Platform for Optical Design of Folded Systems. Frameless  2, 1 (2020), 21.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing , HPDC ‚Äô24, page 227‚Äì239, New York, NY, USA, 2024. [102] Avinash Maurya, Robert Underwood, M. Mustafa Rafique, Franck Cappello, and Bogdan Nicolae. Datastates-llm: Lazy asynchronous checkpointing for large language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Inference with Learning Sparse Masks Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. Otherwise, maintain or reduce the dropout rate to improve accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "[36]  K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúSpendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,‚Äù in  2017 22nd Asia and South PaciÔ¨Åc Design Automation Conference (ASP-DAC) , pp. 678‚Äì683, 2017. [37]  N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 199,
    "augmented": false
  },
  {
    "text": "Bounding and Selecting Hyperparameters  Œª 1 , Œª 2 \nThe choice of  Œª 1  and  Œª 2  affects the curvature of  J ( Œ∏ )  and can influence convergence speed and the location of  Œ∏ ‚àó . Some guidelines include: \n1. Start with small values of  Œª 1  and  Œª 2  to avoid over- whelming the primary loss  L ( Œ∏ ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Wu, ‚ÄúChasing carbon: The elusive environmental footprint of computing,‚Äù  IEEE Micro , vol. 42, no. 4, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Public cloud providers leave these major decisions to be ≈Çmanually handled\" by users, which is very time consuming and strenuous. As a result, the major- ity of application providers use  static resource provisioning , which results in poor resource utilization and higher costs. Prior works  [ 3 ,  9 ] have tried to solve the resource scal- ing problem with respect to hosting the applications in VMs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": ". The core of our architectural investigation is ‚Äúexpert‚Äìaccelerator affinity‚Äù (Table 2), which involves dy- namically mapping ‚Äúexperts‚Äù to the most suitable accelerators with configurations such as  one-to-one ,  one- to-many ,  many-to-one  and  many-to-many , each providing unique benefits for scalability and efficiency. Task-3.1: Expert/Hardware Co-Characterization To efficiently serve various application needs, the question we ask is  what are the intelligent ways to execute EoEs?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "Note that the pattern behavior also depends on the row numbers. 10  b  . Clearly, a pattern (different from the  ellipse  observed with the Equirectangular format) exists in  Œî x  and  Œî y .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "To improve the conÔ¨Ådence of the teacher models, we employ an ensemble learning based weighted majority voting policy [ 28 ]. Each of the teacher models infers on the exemplar frame. Furthermore, each teacher model has its private conÔ¨Ådence matrix on different object classes.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Due to the unavailability of the hardware RTL, we estimated its energy consumption based on the published characterization numbers from the Jetson GPU plat- form with the ZCU102 FPGA[ 64 ] (which is similar to the HORN-8 prototype) [ 51 ]. To put the energy-efficiency of our designs into perspective, we compared their energy consumption against the state-of-the-art HORN-8 hardware accelerator [ 35 ]. Finally, the energy saving achieved by the  Inter-Intra-Holo  scheme is about 73%, meaning that it only consumes 27% of the baseline energy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "2% accuracy of the state-of-the-art. 1 INTRODUCTION \nInnovations in low-power computing, artificial intelligence, and communication technologies have given rise to the gen- eration of intelligently connected devices that constitute the Internet of Things (IoT). Wireless sensor networks (WSNs), one of the prominent classes of IoT deployments, is currently dominating and expected to be pervasive impacting many application spaces [ 13 ] including, but not limited to, body area network [ 22 ,  47 ], industrial monitoring [ 34 ], predic- tive maintenance [ 70 ], commercial satellites[ 15 ] and smart farming [ 61 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "In fact, for training GPT-3, on an average, 5.4 million liters of water is consumed! Clearly, such extensive requirements create barriers for academic institutions and smaller enterprises for advancing the state-of-the-art in LLM cost-effective training, inference, and adaptability. In addition, the availability of clean and high-quality data is reaching physical limits.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": ", n , we merge them into one model  Œ∏ m  by computing a weighted average of parameters where the weight is each parameter‚Äôs Fisher information:  Œ∏ m  =   P n i =1   F i Œ∏ i /  P n i =1   F i , where  F i  is the Fisher Information for  Œ∏ i . Knowledge Adaptation via Expert Growing and Shrinking. To incorporate new knowledge, we will explore novel algorithms for expert-growing via life-long learning [147].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Restrictions apply. 30 35 40 45 50 55 60 65 70 75 80 \nBaseline \nWin-1 \nWin-2 \nWin-3 \nWin-4 \nWin-5 \nBaseline \nWin-1 \nWin-2 \nWin-3 \nWin-4 \nWin-5 \nBaseline \nWin-1 \nWin-2 \nWin-3 \nWin-4 \nWin-5 \nVideo Audio 3DPC \nAccuracy (%) \nSM SMR LM \nFig. 1: Data drift on different data modalities.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "On plotting the distance vectors for each row of the FoV frames, we observe a recurring  ellipse  pattern. The intuitive reason behind this  ellipse  pattern is related to the built-in features of the equirectangular format. Second, for different head orientations, their distance vectors plotted in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "8b. In these two slices, the objects keep moving. Thus, most of the frames will perform FI under FI+SI, as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Additionally, we introduce a novel dataset aimed at furthering the application of energy harvesting in computational settings. Such platforms represent the future of the Internet of Things (IoT) and energy harvesting wireless sensor networks (EH-WSNs). 1 Introduction \nThe increasing demand for ubiquitous, sustainable, and energy-efficient computing, combined with advancements in energy harvesting systems, has spurred significant research into battery-less devices (Gobieski et al., 2019; Resch et al., 2020; Mishra et al., 2021; Saffari et al., 2021; Afzal et al., 2022).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "Modest adaboost- teaching adaboost to generalize better. In  Graphicon , pages 987‚Äì997, 2005. [78]  Jasper A Vrugt and Bruce A Robinson.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "However, as mentioned in ¬ß I , the commercial GPUs used for DNN training are typically power hungry ( typically in 100s of Watts TDP; We exprimented with multiple GPUs, server class A6000: 300W TDP, server class A100: 250W ‚Äì 400W TDP, client class TRX3090: 350W TDP, and client class T4: 70W TDP), and are  not  equipped to handle intermittent power emergencies. However, these GPUs are often equipped with dynamic voltage and frequency scaling (DVFS). 2   To un- derstand the impact of DVFS on energy savings and dynamic compute scaling, we implemented a simple multi-arm bandit algorithm to select the right bucket of compute frequencies (SM frequency for NVIDIA GPUs), and memory frequencies to match the power-demands of the intermittent solar source.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 185,
    "augmented": false
  },
  {
    "text": "However, the granularity of similarity explored in these prior works is  static , and either too coarse (e.g., skips the entire frame [9]) or too strict (e.g., still needs to compute despite very few changes). Hence, properly exploiting these concepts together in an ‚Äúintegrated‚Äù fashion for better optimizing neural inferencing is very much in its infancy that this paper proposes to address. SpeciÔ¨Åcally, we present a systematic study of integrating the  temporal correlations  and  region-based inference  in a  uniÔ¨Åed  approach and try answering the following critical questions:  (i) what \nis the scope to explore both the pixel- and computational- similarities, i.e., frame-level, region-level or pixel-level?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "Our solu- tion decentralizes this massive compute using a sustainable approach and hence has its own merits. Further, this can help build future solutions using these decentralised nodes for other applications. Moreover, communicating and storing such high volume data will also require energy.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "28% of the time the sensors could Ô¨Ånish the inference, while 72% of the time the inference failed as the sensor could not harvest enough energy while not performing any inference. Fig. 1:  Fraction of inference completed on harvested energy using na¬®ƒ±ve scheduling.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Our results from exhaustive experimental analysis demon- strate that  Cocktail  can minimize deployment cost by 1.4 √ó while meeting the accuracy for up-to 96% of the requests and providing 2 √ó  reduction in latency, when compared to state-of-the-art model serving systems. 5. We show that ensemble models are inherently fault- tolerant over single models, since in the former, failure of a model would incur some accuracy loss without complete failure of the requests.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "For instance, from \n154 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nFeatures \nArchipelago [44] \nPower-chief [51] \nFifer [32] \nXanadu [27] \nGrandSLAm [34] \nSequoia [46] \nHybrid Histogram [42] \nCirrus [25] \nKraken \nSLO Guarantees ‚úì ‚úó ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì Dynamic DAG Applications ‚úó ‚úó ‚úó ‚úì ‚úó ‚úó ‚úó ‚úó ‚úì Slack-aware batching ‚úó ‚úó ‚úì ‚úó ‚úì ‚úó ‚úó ‚úó ‚úì Cold Start Spillover Prevention ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úì Function Weight Apportioning ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úì Energy Efficieny ‚úó ‚úì ‚úì ‚úì ‚úó ‚úó ‚úì ‚úì ‚úì Request Arrival Prediction ‚úì ‚úó ‚úì ‚úì ‚úì ‚úó ‚úì ‚úó ‚úì Satisfactory Tail Latency ‚úì ‚úó ‚úì ‚úó ‚úì ‚úì ‚úì ‚úì ‚úì \nTable 1: Comparing the features of  Kraken  with other state-of-the- art resource management frameworks. App DBP Total Fanout Possible Paths Max Depth Social Network 2 8 7 5 Media Service 3 7 5 6 Hotel Reservation 1 2 2 4 Table 2: Analyzing Variability in Application Workflows. the start function  NGINX , any one of  Search ,  Make_Post , Read_Timeline  and  Follow  can be taken.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 393,
    "augmented": false
  },
  {
    "text": "By tackling the dual challenges of sensor unreliability and energy scarcity through a rigorous game-theoretic and fed- erated learning lens, our work addresses a critical gap in the design of sustainable, intelligent EH-WSNs. This inte- grated framework is theoretically grounded, yet practical for a wide range of IoT applications, from remote wildlife mon- itoring to large-scale industrial status tracking and precision agriculture. The remainder of this paper is organized as follows.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "[72] K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, \nJ. Sampson, M. T. Kandemir, and V. Narayanan, ‚ÄúResirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent em- bedded processors,‚Äù in  2020 IEEE International Symposium on High Performance Computer Architecture (HPCA) . [71] I. X. G. Processors, ‚ÄúRankings about energy in the world,‚Äù https://www.intel.com/content/www/us/en/products/details/processors/ xeon/scalable/gold/products.html , (Accessed on 11/21/2022). [70] A. Prabhu, C. Dognin, and M. Singh, ‚ÄúSampling bias in deep active \nclassiÔ¨Åcation: An empirical study,‚Äù  arXiv preprint arXiv:1909.09389 , 2019.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 238,
    "augmented": true
  },
  {
    "text": "¬¥as  introduces a design philosophy for building a morphable hardware, and it can easily be adapted by any of the systolic array based commercial off the shelf (or research prototype) DNN training accelerators. DNN Compute Mapping:  Typically there are three ways of mapping DNN compute into a systolic array, namely, 1. output \nDRAM \nRepresntation Learning \nMicro-profiler \nActivation \nNormalize & Pooling \nHost \nPower Predictor  Examplar \nGlobal Scratch-pad \nDouble Buffered IF Map \nDouble Buffered Filter \nSTT-RAM S \nSTT-RAM N \nNVSB-SE \nNVSB-NW \nDouble Buffered \nOF Map \nP-SUM \nW \nArbiter \n2xNVSB \nP- MUX \nTile-Q \nPE-Block \nSouth Control \nMaster \nNorth \nControl \n(a) High-level arch \no-Path De-Mux \n4x4 STiles w/ 8x8 SA each 128 cycles \n(64 x16)x 16bits Results \nPower off Warning from \nPredictor \nNext \nTile \nTo arbiter \n& Fabric \nclk \nw-pdown \nstate on pwr warning (>256 cycles) off \nbackup \ndat Compute \npath tile arbiter & fabric \nfab-state \n!pdown \n4kB NVSB \nNext STile \n128 Cycles \nFilter \ni-Path mux \nFrom IF or NVSB of failed PE  \ni-Path mux \nPrev STile Next STile \nWork-Q \nLogic \nOutput \nFilter \n8x8 Priority \nMux \n512B NVSB if FULL \nWr-Q \n(b) Power-down/ Failure handling \nFig. 5: Overall architecture with the components and the power failure handle sequence of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 403,
    "augmented": false
  },
  {
    "text": "The remainder of this paper is organized as follows. In Sec- tion  3 , we present the system model, detailing the EH-WSN \nsetup and data capture process. In Section  4 , we introduce the game-theoretic model of sensor participation, motivat- ing our approach against simpler heuristics and discussing why equilibrium solutions are desirable.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "We call this  Eager Scheduling . To enable eager scheduling, we decentralized the global kernel dispatch queue and equipped each tile with a local kernel dispatch queue (1Byte wide 16 deep). At the beginning of each kernel scheduling iteration, the micro-proÔ¨Åler decides the right conÔ¨Åguration, and the control distributes equal number of kernels to each active tile (given  A  active kernel, and  K total kernels, each tile gets  ‚åä K / A ‚åã kernels to execute).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "This hardware-driven adaptive scheduling signiÔ¨Åcantly impacts different data modal- ities, from large-scale to small-scale, and various magnitudes of energy income, as depicted in Fig. 10c . For scenarios with larger and predictable energy income, software-based backup and restore mechanisms can offer signiÔ¨Åcant beneÔ¨Åts, as the energy consumed for such operations is typically a small fraction of the overall energy income.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 6b  b  , similar to the  Inter- Holo  pipeline, the additional pose estimation step also sits between the inputs and the original hologram processing, and thus has to be efficient without introducing much overhead. Our profiling on the edge GPU prototype [ 36 ] shows that Kimera-VIO takes, on av- erage, 13 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "have a huge impact on the convergence and accuracy of the models. To achieve this, we design a ‚Äúmicro-proÔ¨Åler‚Äù that can look into the drift of the models as well as the power availability and decide the right hyperparameters to train the models. For each edge servers to handle multiple steams with multiple drifts, we need to jointly optimize the hyper-parameters for maximizing accuracy with minimum power and resource budget.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Optimizing data layouts for parallel computation on multicores. In  2011 International Conference on Parallel Architectures and Compilation Techniques , pages 143‚Äì154. IEEE, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": ", July 2022, (Accessed on 08/04/2023). [76] G. V. Research, ‚ÄúConsumer iot market size, share and trends \nanalysis report by component (hardware, services), by connectivity technology (wired, wireless), by application (healthcare, wearable devices), and segment forecasts, 2023 - 2030,‚Äù https://www.grandviewresearch.com/industry-analysis/consumer- iot-market-report#: ‚àº :text=The%20global%20consumer%20IoT% 20market,advanced%20devices%20and%20home%20appliances. [77] M. S. rutgers.edu, ‚ÄúSupport for trafÔ¨Åc cameras increases if used as a tool to limit interactions with police,‚Äù https://www.rutgers.edu/news/support-trafÔ¨Åc-cameras-increases-if- used-tool-limit-interactions-police , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 245,
    "augmented": true
  },
  {
    "text": "This allows the DNN to maintain high accuracy even under severe energy constraints. 2. Energy Variability Awareness:  By integrating energy profiles directly into the training process, NExUME ensures that the model learns to handle fluctuations in energy supply, leading to more robust performance compared to methods that do not consider energy variability during training.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "The PIs also have access to NSF CloudBank, ACCESS and various NERSC resources. Also, Kandemir was a co-PI on a recent MRI award. This grant enables the PIs as well as the project team to access, among other resources, hundreds of Intel Xeon nodes, various types of NVIDIA GPUs (A100 and V100), and two large storage arrays consisting of various types of HDDs, SSDs, FPGAs, as well as 4 computational storage devices (Samsung SmartSSD).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "Chitaranjan Das; Pennsylvania State University; PI 2. Mahmut Taylan Kandemir; Pennsylvania State University; co-PI 3. Rui Zhang; Pennsylvania State University; Co-PI 4.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "10: Sensitivity study. (b): The pattern between left-eye and right-eye in the  front  face in Cube Mapping [41]. (a): Video quality metric (PSNR [25], [40]) across video inputs.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms. Such platforms often already operate at their limits just in order to transmit sensed data at acceptable quality of \nservice (QoS) rates for deployment-viable battery lifetimes, and may not have additional resources available for further computation. For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "We took the learning from multiple domain specific litera- tures [ 19 ,  29 ,  53 ] to isolate the frequency regions specific to the fault pattern to minimize the computations. But, because of the larger data volume, the number of computations per- formed at the edge diminished significantly (refer Figure 15). We also conducted an empirical study on number of clusters required, and found out that the bearing set data needs about 15 to 20 clusters to maintain the inference accuracy.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "A CKNOWLEDGEMENTS \nThis work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants #1822923 \n(SPX: SOPHIA), #1763681, #1629915, #1629129, #1317560, #1526750, National Natural Science Foundation of China [NSFC Project No. IX. ResiRCA for the Ô¨Årst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "Both these schemes suffer from over- provisioning VMs because (i) we cannot always accurately predict the future load, and (ii) resource utilization is not always the right indicator for increased load. We conduct simulation experiments to compare the schemes, using the profiled values (explained in Section  2.2 ) for four different well-known request arrival traces. Each request in the trace is associated with an ML inference query, which is randomly picked from our model pool.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2310.16795 , 2023. [46] Elias Frantar and Dan Alistarh. Qmoe: Practical sub-1-bit compression of trillion-parameter models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "12. Throughput normalized to G4 with  Naive2  vs. ReRAM duplication granularity \nThe RCA area is impacted from the parallelism granularity G , as shown in Figure 13. It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed ‚Äúsmart dust‚Äù solutions [ 8 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Accessed: 2023-10-20. https://cset.georgetown.edu/wp-content/uploads/ AI- and- Compute- How- Much- Longer- Can- Computing- Power- Drive- Artificial- Intelligence-Progress.pdf , January 2022. Ai and compute: How much longer can computing power drive artificial intelligence progress ?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "3. This balances task importance against energy consumption, leading to efficient utilization of available energy. Complexity Analysis : The heuristic has a time complexity of O ( N  log  N )  due to sorting tasks based on  P   eff i   , which is acceptable for real-time applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Hwajung Kim, Heon Y Yeom, and Hanul Sung. 45‚Äì51, 2022. Understanding the performance characteristics of computational storage drives: A case study with smartssd.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "USENIX Association. [28]  Deepstudio. Deep Learning Dtudio, February 2020. https://docs.deepcognition.ai/ .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "We denote by  E i ( t )  the energy harvested by sensor  s i  during slot  t . The sensor maintains an energy buffer whose state evolves as \nB i ( t  + 1) =  B i ( t ) +  E i ( t )  ‚àí e i ( t ) , \nwhere  B i ( t )  is the energy available at the beginning of slot  t , and  e i ( t )  is the energy expended during that slot. Predicting future energy intake is challenging, so each sensor employs an estimator   ÀÜ E i ( t  + 1)  to anticipate its upcoming energy resources.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "The associated conÔ¨Ådence matrix boosts the classiÔ¨Åcation accuracy and also resolves ties while voting. Moreover, the host device, which performs the ensemble, is equipped with a conÔ¨Ådence matrix, which adapts to the user and performs weighted majority voting instead of a na¬®ƒ±ve majority voting. The added recall functionality enables ensemble learning.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "C System Overheads \nWe characterize the system-level overheads incurred due to the design choices in  Cocktail . The  mongodb  database is a centralized server, which resides on the head-node. Since the primary contribution in  Cocktail  is to provide high accuracy and low latency predictions at cheaper cost, appli- cation developers can adapt the prediction algorithm to their needs or even plug-in their own prediction models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "0 \n0.4 \n0.8 \n1.2 \n1.6 \nBerkley WITS Twitter Wiki \nNormalized VMs \nreactive util_aware exascale \nFigure 4. Also, the number of concurrent requests which can be executed in VMs should be accurately determined to meet response latency. Over-provisioning of  util_aware  and  exascale , nor- malized to a baseline  reactive  scheme for four traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "2018. Tributary: spot-dancing for elastic ser- vices with latency SLOs. [6] Aaron Harlap, Andrew Chung, Alexey Tumanov, Gregory R. Ganger, and Phillip B. Gibbons.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "[67]  C. R. Qi, L. Yi, H. Su, and L. J. Guibas, ‚ÄúPointnet++: Deep hierarchical feature learning on point sets in a metric space,‚Äù in  Proceedings of the 31st International Conference on Neural Information Processing Systems , 2017, p. 5105‚Äì5114. [68]  F. Qian, B. Han, J. [66]  C. R. Qi, H. Su, K. Mo, and L. J. Guibas, ‚ÄúPointnet: Deep learning on point sets for 3d classiÔ¨Åcation and segmentation,‚Äù in  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "). ). Cooperative game theory has been used to encourage collab- oration among sensors to enhance network performance ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "Preliminary work. Under review by the International Conference on Machine Learning (ICML). Do not distribute.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 24,
    "augmented": false
  },
  {
    "text": "It is imperative for these applications to deliver accurate predic- tions at sub-millisecond latencies [ 27 , 34 , 35 , 39 , 44 , 83 ] as they critically impact the user experience. This trend is expected to perpetuate as a number of applications adopt a variety of ML models to augment their services. These ML models are typically trained and hosted on cloud platforms as service end- points, also known as  model-serving  framework [ 6 ,  28 ,  60 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "In  2014 IEEE International Conference on Robotics and Automation (ICRA) . 1304‚Äì1311. Visual precis generation using coresets.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "If the model overfits high-SNR data, increase  Œª 1 . If it be- comes too large and slow to run, increase  Œª 2 . By keeping  Œª 1 , Œª 2  within reasonable bounds, we ensure that the modified gradient   b ‚àá J ( Œ∏ )  remains well-behaved, preserving the conditions for SGD convergence.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "We will also carve up short lecture materials based on the project and preserve them on departmental machines. Finally, the curriculum materials will be stored as long as they are used to enhance the courses that PIs teach at Penn State. The lecture slides/videos are expected to be stored until their useful lifetime, and they will also be made available via YouTube.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Calculate the gradients of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the reconstruction error of the feature maps: \np i  = Œ≥  RE i max( RE ) +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Inference with Feature Map Reconstruction Error Dropout and QuantaTask Optimization: Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 338,
    "augmented": false
  },
  {
    "text": "This is due to the Ô¨Çoating- point hardware rounding (to Ô¨Ånd the nearest-neighbor integer coordinates) and the transformation matrix‚Äôs various weights are dependent on the row numbers. 6b and 6c, the  i th-row‚Äôs pattern may not be exactly the same as the  j th-row. To simplify our  AE  design, we simply reuse the pattern captured in the  1 st row, and do not consider the deeper information related to the row numbers.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "From our evaluation, we found an 8:1 ratio of SSD to CSD (capacity ratio) provides the best possible cost-to-acceleration benefit. 6 Conclusions \nIn this paper, we have explored the critical role of storage systems in the context of continuous learning video analytics edge server, emphasizing in particular the transformative potential of Computational Storage Devices (CSDs) in this domain. Our proposal,  Salient Store  , highlights the need for a paradigm shift in storage architecture to accommodate the dynamic and computationally intensive nature of modern ML applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Through this integrated approach, we aim to lower the barriers to entry for AI development. Thrust-1 is aimed at in- vestigating the algorithmic foundations of our EoE paradigm that consists of an ensemble of experts, which will facilitate application-specific morphable LLMs. In this context, we propose a research plan consisting of 4 intertwined thrusts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "While down-scaling, we drop the models with the least prediction accuracy in that interval. If there is a tie, we drop the model with least packing factor ( P f  ). It can so happen that dropping models can lead to drop in accuracy for certain intervals, because the class of images being predicted are different.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Mathematical Formulation:  Let  W  be the weight matrix of a layer. D.2 Optimal Brain Damage Dropout with QuantaTask Optimization \nOptimal Brain Damage Dropout leverages a simplified version of the Optimal Brain Damage pruning method to adjust dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. The sensitivity of each weight W ij  is calculated using the second-order Taylor expansion of the loss function  L : \n‚àÜ L ‚âà 1 \n2 \nX \ni,j \n‚àÇ 2 L ‚àÇW   2 ij ( W ij ) 2 \nwhere ‚àÇ 2 L ‚àÇW   2 ij   is the second-order derivative (Hessian) of the loss with respect to the weights.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "Journal of Ma- chine Learning Research , 22(241):1‚Äì124, 2021. [64] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Ruther- ford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. Training compute- optimal large language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "Clipper , on the other hand, is static and always uses all the models. The percentage of model-reduction is lower for  Const2 , 3 and 4 because, the total models used in the ensemble is less than  Const1  (8, 7 and 6 models, respectively). Still, the savings in terms of cost will be signiÔ¨Åcant because even removing one model from the ensemble amounts to  ‚àº 20% cost savings in the long run ( Clipper  vs  Clipper-X  ensemble in Figure  8 ).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Sambanova sn40l: Scaling the ai memory wall with dataflow and composition of experts. Brown, and Kunle Olukotun. [131] Raghu Prabhakar, Ram Sivaramakrishnan, Darshan Gandhi, Yun Du, Mingran Wang, Xiangyu Song, Kejie Zhang, Tianren Gao, Angela Wang, Karen Li, Yongning Sheng, Joshua Brot, Denis Sokolov, Apurv Vivek, Calvin Leung, Arjun Sabnis, Jiayu Bai, Tuowen Zhao, Mark Gottscho, David Jackson, Mark Luttrell, Manish K. Shah, Edison Chen, Kaizhao Liang, Swayambhoo Jain, Urmish Thakker, Dawei Huang, Sumti Jairath, Kevin J.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 206,
    "augmented": true
  },
  {
    "text": "In  2024 USENIX Annual Technical Conference (USENIX ATC 24) , pages 1203‚Äì 1221, Santa Clara, CA, July 2024. Centimani: Enabling fast AI accelerator selection for DNN training with a novel performance predictor. USENIX Association.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "However, the intermittent and unpredictable nature of harvested energy introduces significant challenges in maintaining reliable and consistent network performance ( ? ). The unreliability of individual EH sensors, due to fluctua- tions in energy availability, necessitates the deployment of a large number of inexpensive and potentially unreliable de- vices to ensure network robustness.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "291‚Äì304. [3] X. Corbillon, F. De Simone, and G. Simon, ‚Äú360-Degreee Video Head Movement Dataset,‚Äù in  Proceedings of the 8th ACM on Multimedia Systems Conference , 2017, pp. 199‚Äì204.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "D ISCUSSION \nKey insights:  Compared to other systems, the ratio of energy requirement of task vs the harvested energy is much higher here. While many of the prior works have designed their systems around inference using intermittent systems, we are one of the few works which focuses on learning, and the only work which does it on a large scale of data. Added with time constraints, designing such a system becomes tricky.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "This inequality implies that even in a worst-case scenario for accuracy gain, the net expected benefit of correct par- ticipation surpasses the sum of potential incorrect penalties and energy costs. Without this condition, sensors might find participation systematically unprofitable. Non-Participation and Equilibrium: Since  Œ∑ > Œ¥ , we ensure that sensors prefer risking occasional incorrect infer- ences over consistently abstaining.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "This is because the twitter workload is bursty, thereby leading to intermittent over-provisioned VMs. Note that, all the schemes incur higher cost for twitter trace (Figure  8b ) compared to wiki trace (Figure  8a ). On the other hand,  Clipper  uses all models in ensemble and the  Clipper-X  policy does not right size the models as aggressively as  Clipper , hence they are more expensive.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "[77]  Alexander Vezhnevets and Vladimir Vezhnevets. Computer Networks , 2009. Modest adaboost- teaching adaboost to generalize better.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "The fundamental issue with the previous approach is the inability to select correct numbers of IID data for training. In addition to that, just DNN training cannot learn \new classes if there is no way to annotate and label new classes. Representation learning solves both these issues.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Note that each func- tion triggers only one other function in the application at a time. The decision to trigger the next function typically depends on the input to the current function, although there are cases like  Media Service  where this decision may de- pend on previous function inputs as well. Therefore, there is considerable variation in the functions that can be invoked in DDAs, thus, negating the inherent assumption in many frameworks [ 32 ,  42 ,  44 ,  50 ] that all functions will be invoked with the same frequency as the application.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "TOTAL INFERENCES \nPiezo WiFi-h WiFi-o Thermal TV-RF \nLeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 \nE. Power predictor \nWith an accurate power predictor [ 45 ], [ 36 ], we can make more smooth transitions among different power levels. The beneÔ¨Åt is that we can keep more MAC results of the last \nincomplete inference when switching from a higher power level to a lower power level, even if  Condition trans   is not satisÔ¨Åed. However, to be valuable the power predictor must have high accuracy.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 193,
    "augmented": false
  },
  {
    "text": "In this paper, we propose to build a self-managed ML prediction system, which can optimize the diverse application requirements based on characteristics of heterogeneous public cloud resource offerings. Towards this, we discuss the trade-offs of intermixing resources like serverless functions along with VMs and identify the key challenges associated with configuring these resources. The critical challenge of deploying ML prediction serving applications in public cloud is to combine both model and resource heterogeneity towards optimizing for application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "The unit compute (only a 3  √ó  3 convolution per tile) that  Us. ¬¥as  can perform is much smaller than the other accelerators, limiting its throughput but increasing its modularity of handling intermittent power failures (or power changes). Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "We design and implement  Kraken  on  OpenFaaS  and evaluate it on a multi-node  Kubernetes -managed cluster. Our extensive ex- perimental evaluation using  DeathStarbench  workload suite and real-world traces demonstrates that  Kraken  spawns up to 76% fewer containers, thereby improving container uti- lization and saving cluster-wide energy by up to 4 √ó  and 48%, respectively, when compared to state-of-the art schedulers employed in serverless platforms. CCS Concepts ‚Ä¢  Computer systems organization  ‚Üí Cloud Comput- ing ;  Resource-Management ; Scheduling.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "Once the user specifies target domains, the algorithm locates the most irrelevant domains in the graph (either branch or leaf) until the number of experts fits within the memory constraints or the relevance reaches a threshold. Then, remove operations are repeatedly used to prune the system. If the number of experts is still larger than needed, a clustering algorithm (e.g., AGNES [139], and topic clus- tering [160]) can be employed to combine experts with the highest cluster scores, thus reducing the total number of experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Meta strikes geothermal energy deal with sage geosystems to power data centers. https:// www.reuters.com/business/energy/meta-strikes-geothermal-energy-deal-with- sage-geosystems-power-data-centers-2024-08-26/ , 2024. Accessed: 2024-10-20.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "[59] Microsoft, ‚ÄúBuilding world-class sustainable datacenters and investing \nin solar power in arizona,‚Äù https://blogs.microsoft.com/on-the- issues/2019/07/30/building-world-class-sustainable-datacenters-and- investing-in-solar-power-in-arizona/ , (Accessed on 04/28/2023). [60] Microsoft-Rocket-Video-Analytics-Platform, \n‚Äúhttps://github.com/microsoft/Microsoft-Rocket-Video-Analytics- Platform.‚Äù [61] C. S. Mishra, J. Sampson, M. T. Kandemir, and V. Narayanan, ‚ÄúOrigin: \nEnabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks,‚Äù in  DATE , 2021. 905 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 217,
    "augmented": false
  },
  {
    "text": "In Proceedings of the 22nd ACM International Symposium on High-Performance Parallel and Distributed Com- puting , pages 151‚Äì160. ACM, 2014. [37] Shihan Dou, Enyu Zhou, Yan Liu, Songyang Gao, Jun Zhao, Wei Shen, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, and Xuanjing Huang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "From Figure  3a , it can be seen that the static policy has an accuracy loss of up to 1.45% when compared to full-ensemble, but is still better than single models. The Ô¨Årst step towards making model ensembling cost effective is to minimize the \n1044    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \number of models by pruning the ensemble, which reduces the overall resource footprint. In order to estimate the right number of models to participate in a given ensemble, we conduct an experiment where we chose top   N \n2   accurate models (static) from the full-ensemble of size  N .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "To further mimic realwold scenarios of multiple cameras sending multiple streams with various stream rate, we  distributed  video data into across two CSDs in different ratio, as shown in TABLE 2. Trivially, a load-balanced scenario outperforms any of the biased data distribution scenario. However, it is evident that any compute offloaded to any of the CSDs in these scenarios offers benefits in terms of data processing latency.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Although efÔ¨Åcient hardware accelerators [ 16 ], [ 27 ], [ 80 ] have been developed to do the same, these ac- celerators are typically designed with a ‚Äúthroughput-Ô¨Årst‚Äù \n895 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "IEEE, 2020. [138] Ananda Samajdar, Yuhao Zhu, Paul Whatmough, Matthew Mattina, and Tushar Krishna. Scale-sim: Systolic cnn accelerator simulator.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "This has proved to be more accurate than traditional single large models because it inherently re- duces incorrect predictions due to variance and bias. An Ensemble is deÔ¨Åned as a set of clas- siÔ¨Åers whose individual decisions combined in some way to classify new examples. The commonly used ensemble method in classiÔ¨Åcation problems is bagging [ 33 ] that considers homogeneous weak learners, learns them independently from each other in parallel, and combines them following some kind of deterministic aver- aging process [ 18 ] or majority voting [ 49 ] process.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "‚Ä¢  DynInfer : An intermittency- and platform-aware task scheduler that optimizes computational tasks for intermittent power supply, ensuring consistent and reliable DNN operation. DynInfer leverages software-compiler-hardware co-design to manage and deploy tasks. This optimizer allows for dynamic adjustments of dropout rates and quantization levels based on real-time energy availability, thus maintaining learning stability and improving model accuracy under power constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "In order to accommodate the RCA to the changing harvested power supply, we need a ‚Äúlightweight‚Äù and ‚ÄúÔ¨Åne-grain controllable‚Äù design from both the hardware and software angles. VIII. C ONCLUSION \nMAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "A standard offering with 2 √ó g4dn.12xlarge instances need 4kW power [ 7 ] (the compute units have a TDP of  ‚âà 1 kW  [ 65 ], [ 71 ]) for \nperforming analytics. With state-of-the-art learning APIs [ 60 ] and intelligent co-location and scheduling of inference and continuous learning [ 12 ], these edge servers can support about 8 videos streams [ 12 ], resulting in  ‚âà 120 W  (just for compute) per video stream. Scaling this to crowded cities with 30- 50+kilo-cameras like Beverly Hills ( >  35 k  [ 11 ]), Los Angeles ( ‚âà 35 k  [ 92 ]), New York ( ‚âà 56k [ 92 ]), or Chicago ( ‚âà 30k) will need a lot of power.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 190,
    "augmented": false
  },
  {
    "text": "7: The proposed frame-level reuse and tile/region-level reuse design blocks implementation; BB/BBox: bounding boxes from the last FI; MV: motion vectors of the current frame; FM: feature maps for each layer from the last FI. V. E VALUATION \nTargeting the object detection task on edge devices, we compare our proposed frame-level scheme ( Full-Inference  and Skip-Inference , i.e., FI+SI) and region-level scheme ( Full- Inference ,  Skip-Inference  and  Partial-Inference , i.e., FI+SI+PI) against the  baseline inference , which performs full infer- ence on every frame, as well as four state-of-the-art runtime techniques (DeepCache [8], Euphrates [9], Potluck [12], and MCDNN [7]), by quantifying the normalized execution time, energy consumption, and accuracy (mean Average Precision, \nmAP). We Ô¨Årst describe the design conÔ¨Ågurations, experi- mental platform, datasets, and measurement tools used in this work, and then analyze the collected results.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 263,
    "augmented": false
  },
  {
    "text": "Fast  Cache \nMobileNet NasNet \nResNet50 DenseNet121 \nDynamic Model  Selection \n. . Key takeaway :  The cost-effectiveness of transient instances, is naturally suitable for hosting ensemble models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "7. ‚Ä¢  EA+AE  (SW) : The above two designs can be seamlessly integrated into the original SoC, with the  EA  block placed before the GPU and the  AE  block after the GPU. We denote this design combination as  EA+AE .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "In  Advances in Neural Information Processing Systems , pages 5998‚Äì6008, 2017. [158] Shyam Venkataramani, Suresh Cherian, Sergio DeRose, Karthik Sankaralingam, and Sek Ching Wong. Garnet: A detailed network-on-chip simulator.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "It runs on a  C5.16x  [ 8 ] large instance to handle these large volume of diverse tasks. reside in the mas- ter node. Each worker VMs runs a client process to serve its corresponding model.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "2 ). III-B  that Morton codes can reveal opportunities for both geometry similarity (owing to the fact that the Morton code itself is the reÔ¨Çection of the geometrical relationship between points) and attribute similarity (the RGB attributes of two adjacent points are more likely to be similar). Furthermore, we also observed in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "B. Activity Aware Scheduling \nTo enable the activity awareness we keep a small lookup table of accuracy of all the sensors over all the classes. However, accuracy being a Ô¨Çoating point number, is expensive in terms of energy to store and lookup.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "0 \n2000 \n4000 \n6000 \n2 4 6 8 10 12 14 16 \nPower (mW) \n# Depth-planes \nCPU SoC GPU Mem \n(a) Power breakdown. 23.6 \n19.8 \n7.1 6.7 \n0 10 20 30 40 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "(a): Viewing the W-CGH from different eye-center positions. (b) Viewing the W-CGH from different focal distances. (c): View- ing the S-CGH from different focal distances.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "¬¥as  hardware‚Äôs most important feature is its ability to  morph  according to power availability. Fig. 11  shows its ability to maximize the instantaneous power utilization and scale the number of tiles.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Note however that, this meta- information is not on the data-dependence chain, and we do not consider it for memoization. To summarize, among the above discussed features, we identify  head orientation  as the only suitable memoization candidate for boosting the compute reuse scope. Thus, we memoize both head orientation and its corresponding projec- tion matrix (i.e., projection computation results) in a memory buffer, namely,  P buff , and use the head orientation to index the address/pointer of that  P buff  stored in DRAM.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Our research, gos beyond the compute domain, and identifies the gaps in current storage system designs. We proposes a framework that aligns more closely with the growing data demands. We present a detailed analysis of data movement challenges within the archival workflows and demonstrate how the strategic integration of CSDs can significantly optimize data compression, encryption, as well as other data management tasks, to improve overall system performance.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "IEEE, 2015, pp. [23] P. Foster, S. Sigtia, S. Krstulovic, J. Barker, and M. D. Plumbley, \n‚ÄúChime-home: A dataset for sound source recognition in a domestic environment,‚Äù in  2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) . 1184‚Äì1188.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Understanding the performance characteristics of computational storage drives: A case study with smartssd. Electronics , 10(21):2617, 2021. Yoonsung Kim, Changhun Oh, Jinwoo Hwang, Wonung Kim, Seongryong Oh, Yubin Lee, Hardik Sharma, Amir Yazdanbakhsh, and Jongse Park.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "To give an example, we selected a segment of frames (i.e.,  Frame#6750  to  Frame#6850 ) from V1 [33], in which the objects move more aggressively than other segments. We want to emphasize however that, such static (pre-deÔ¨Åned) window-size works well only when there are few movements in the videos. On the other hand, when the video has more dynamic behavior, this static skipping jeopardizes the quality of applications which demand high accuracy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "One of the most emerging line of work aims to solve the energy provisioning problem at the edge by integrating en- ergy harvesting (EH) to the sensor nodes while making them more capable performing complex compute intermittently, which has given rise to energy harvesting wireless sensor networks (EH-WSNs). Specifically, recent works [ 24 ,  43 ] pro- posed EH, along with compiler/runtime optimizations and leveraging non-volatile processors (NVP) [ 40 ,  56 ], to increase local compute at the edge. Prior works, trying to tackle this conflict between computa- tion, communication, power-requirement and quality of ser- vice (QoS), have pursued three major approaches: inference effort partitioning optimizations [ 22 ,  30 ,  31 ,  50 ], mitigation of energy provisioning limitations [ 24 ,  40 ,  43 ,  47 ,  56 ], and minimizing communication overheads [32, 33, 36, 37, 45].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 230,
    "augmented": true
  },
  {
    "text": "Visual precis generation using coresets. In  2014 IEEE International Conference on Robotics and Automation (ICRA) . 1304‚Äì1311.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Accessed: 2024-04-27. Pytorch: An imperative style, high-performance deep learning library. https://pytorch.org/ , 2019.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "In certain energy-critical scenarios, even EH-WSNs applying state-of-the-art techniques fail to consistently meet SLOs, sometimes skipping entire inferences to deliver results on time. Adding further approximation to save energy atop an already heavily reduced network can propagate errors through the layers, leading to significant accuracy drops (Islam & Nirjon, 2019; Kang et al., 2022; Lv & Xu, 2022; Kang et al., 2020), further violating SLOs. (II) Computational Approximation : To address (I) and maintain continuous operation, EH-WSNs may skip some compute during energy shortfalls by dropping neurons (zero padding) or by approximating computations (quantization).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 183,
    "augmented": true
  },
  {
    "text": "[26]  S. Han, H. Mao, and W. J. Dally, ‚ÄúDeep compression: Compressing deep neural network with pruning, trained quantization and huffman coding,‚Äù CoRR , vol. abs/1510.00149, 2015. abs/1803.00227, Apr 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "1‚Äì6, 2015. Mingsong Lv and Enyu Xu. In  Proceedings of the 52nd Annual Design Automation Conference , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Potentially, content-based optimizations (e.g., content cache [63]) can beneÔ¨Åt the data transfer; however, they are not attractive candidates to leverage compute reuse, which is the major power-hungry stage (as shown in Fig. 2a). In \n246 \nTABLE II: Video workloads.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Unlike prior works targeting at optimizing the efÔ¨Åciency of  each computation  [28], [57], we primarily focus on reducing  the amount of computation to be performed, by exploring the intrinsic ‚Äúcompute reuse opportunities‚Äù in  360 ¬∞ VR video processing. Opportunities \nExploring and exploiting computation output reuse oppor- tunities is non-trivial in this context. A.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "A distributed online optimization strategy for cooperative robotic surveillance. In  2023 IEEE International Conference on Robotics and Automation (ICRA) , pp. 5537‚Äì5543, 2023. doi: 10.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "This strategy is particularly useful when we need a single model to handle diverse knowledge sources or when we aim to reduce training costs by first training smaller models and then combining them. To create a smaller model for a domain- specific dataset  D , we will identify parameters that have the least influence on loss  L ( D )  and remove them from the large expert. The importance of each weight at index  i , denoted as  I W i , can be approximated by: I W i  =  |L ( D )  ‚àíL W i =0 ( D ) | , where  L W i =0 ( D )  is the loss, by setting parameter  W i  to zero.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "Further, the simulator was integrated with CACTI [ 62 ] and DRAMSIM3 [ 49 ] to estimate access latency, power, and simulate the memory access pattern. C. Hardware Implementation and Evaluation \nThe proposed morphable hardware was simulated using an in-house simulator based on ScaleSim [ 79 ]. We included a wrapper around ScaleSim to  dynamically  change the con- Ô¨Åguration of the systolic array.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "C.1.1 Algorithm Overview \nThe GeMM operation, typically expressed as  C  =  A  √ó  B , where  A ,  B , and  C  are matrices, is imple- mented with considerations for energy limitations. The algorithm breaks the matrix multiplication into smaller chunks (tiles), periodically saves the state before potential power losses, and resumes computation from the last saved state upon power restoration. C.1.2 Function Definitions \n‚Ä¢  SAVE_STATE : Saves the current indices and the partial result of the output matrix  C  to non-volatile memory to allow recovery after a power interruption.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "06 ¬∞  of accuracy [ 26 ]. Thus, both of these two tasks are able to meet the performance re- quirements shown in Table 1. 4 ms  and achieves 2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "IEEE Micro , 43(2):99‚Äì109, 2022a. Compute express link (cxl): Enabling heterogeneous data-centric computing with heterogeneous memory hierarchy. Debendra Das Sharma.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "In each case, the points/values in  red  are communicated to the host. Coreset Construction Using Clustering:  Although im- portance sapling based coreset construction is computation- ally inexpensive, it suffers from accuracy loss because it doesn‚Äôt explicitly preserve the intricate structure of the data points. To address this, we also utilize coreset construction using k-means clustering [ 8 ,  36 ,  37 ], which separates the data points into a set of k (or fewer) N-spherical clusters and represents the geometric shape of the data by using the cluster centers and cluster radii (Fig.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "We refer to such functions as Dynamic Branch Points (DBPs), and the chains they are a part of as Dynamic Function Chains. Clearly, having prior knowledge of what functions will be invoked for an application makes container provisioning easier for SDAs. 2.1.2 Dynamic DAGs : Although the application DAG con- sists of multiple functions that may be invoked, there are cases where the functions can themselves invoke other func- tions depending on the inputs they receive.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Even a 10ms reduction in latency is of signiÔ¨Åcant importance to the providers [ 35 ]. Besides accuracy again, ensembling can also achieve lower latency. The latency of the ensemble is calculated as the time between start and end of the longest running model.As shown in Table  3 , in the case of  NASLarge , the ensemble latency is 2 √ó  lower (151ms) than the baseline latency (311ms).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "This study involved adjusting the acceptable latency and the capacitance of the energy harvesting setup to assess their impacts on accuracy. By effectively managing energy constraints and adapting to intermittent power conditions, NExUME enables more reliable and accurate monitoring in industrial environments where energy harvesting is a viable power solution. 4.4 Sensitivity and Ablation Studies of NExUME \nTo elucidate the influence of variable SLOs and hardware-specific settings on system performance, we conducted a comprehensive sensitivity study.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "6.1.4 Ablation Study : This subsection conducts a brick-by- brick evaluation of  Kraken  using  Conn Only  and  Comm Only , \n163 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. Only  DProb  and SProb  consume lesser energy than  Kraken  (4% lesser), due to their more aggressive container reduction approach. Application Kraken Comm Only Conn Only Social Network (99.94%, 284) (99.91%, 276) (99.89%, 256) Media Service (99.73%, 572) (99.66%, 561) (99.64%, 552) Hotel Reservation (99.87%, 316) (99.77%, 290) (99.74%, 282) Table 5: Real System: Comparing (SLO Guarantees,#Containers Spawned) against  Comm Only  and  Conn Only .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 226,
    "augmented": true
  },
  {
    "text": "2), ER-r might lead to lower accuracy in many cases. A better approach is to prioritize performing inferences on the sensor that has the highest local accuracy for the current activity. However, this poses a chicken and egg problem ‚Äì to know which sensor is the best for classifying an activity we need to know what activity is going to be performed beforehand.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "2020. \"https://github.com/ google-research-datasets/Objectron/blob/master/index/laptop_annotations\". Objectron Dataset Annotation: laptop.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "In Proceedings of the European conference on computer vision (ECCV) , pp. 285‚Äì300, 2018. Chih-Hsuan Yen, Hashan Roshantha Mendis, Tei-Wei Kuo, and Pi-Cheng Hsiu.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "V. \nB. Region-Level Pruning As discussed in Sec. This leads us to our next question ‚Äì  Can we do better? IV-A, while our proposed frame level scheme (coarse granularity) enjoys FI skipping opportunities in some cases, we need to perform FI for the remaining cases, to maintain the accuracy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 27th ACM Symposium on Operating Systems Principles , pages 1‚Äì15, 2019. Pipedream: generalized pipeline parallelism for dnn training. [59]  Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gregory R Ganger, Phillip B Gibbons, and Matei Zaharia.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping. In  IEEE Intl. Conf.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "[189] Zhenyu Zhang, Ying Sheng, Tianyi Zhou, Tianlong Chen, Lianmin Zheng, Ruisi Cai, Zhao Song, Yuandong Tian, Christopher R√©, Clark Barrett, Zhangyang \"Atlas\" Wang, and Beidi Chen. H2o: Heavy-hitter oracle for efficient generative inference of large language models. In A. Oh, T. Nau- mann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,  Advances in Neural Information Processing Systems , volume 36, pages 34661‚Äì34710.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Furthermore, incorporating more advanced compute hardware, such as FPGAs, GPGPUs and other accelerators, would lead to underutilized I/O slots and memory, consequently escalating the cost of storage systems. Additionally, storage solutions that are optimized for I/O throughput tend to lose their specialized efficiency when repurposed for general compute tasks (Haynes et al., 2021). While the previous research has suggested the idea of integrating analytics into storage systems, these discussions usually revolve around system architecture, scheduling, and data management, without delving into the requisite compute capabilities (Haynes et al., 2021; Daum et al., 2021; Tsai et al., 2020; Xu et al., 2019).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 179,
    "augmented": false
  },
  {
    "text": "A CKNOWLEDGMENT \nThis research is supported in part by NSF grants #1763681, #1629915, #1629129, #1317560, #1526750, #1714389, #1912495, and a DARPA/SRC JUMP grant. We believe, given that the current VR devices are battery-backed, these kinds of energy savings and performance improvements will not only enable the users to experience longer videos, but also encourage both industry \nand academia to work further on improving the pipeline to make VR more pervasive and versatile. We would also like to thank Dr. Jack Sampson, Dr. Aasheesh Kolli and Dr. Timothy Zhu for their feedback on this paper.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "Moreover, streaming requires two projections for both the eyes. As the 360 ¬∞ video is not in a planar format, the VR ecosystem converts it to a conformal 2D format by passing it through multiple stages of transformations. Thus, unlike planar videos, in  360 ¬∞ videos, speciÔ¨Åcally the projection computations for capturing the head movements and eye correlations, are sig- niÔ¨Åcantly computation-heavy, amounting to  59%  of the overall VR (headset) power budget.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "[31]  Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola. Autogluon-tabular: Robust and accurate automl for structured data, 2020. [32]  Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "177‚Äì186. [34] H. Miao and F. X. Lin, ‚ÄúTell Your Graphics Stack That the Display Is Circular,‚Äù in  Proceedings of the 17th International Workshop on Mobile Computing Systems and Applications , ser. HotMobile ‚Äô16, 2016, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Military Technical College, 2018, pp. 1‚Äì13. [51]  C. Moreno, Y. Chen, and M. Li, ‚ÄúA dynamic compression technique for streaming kinect-based point cloud data,‚Äù in 2017 International Conference on Computing, Networking and Communications (ICNC) .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Also, the total number of blocks is 50000, and the search step is set to be the size of the current P-block (i.e., to Ô¨Ånd the best matched block for current P-block, each time, we traverse the search region in the reference frame by this step size). ‚Ä¢  Intra-Inter-V2 : For this conÔ¨Åguration, we choose a larger threshold (1200) for the ‚Äúdirect-reuse decision making‚Äù such that the ratio of the  direct reuse  will increase with slight drops in quality. Other settings are not changed (they remain the same as in the Intra-Inter-V1 version).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 136,
    "augmented": false
  },
  {
    "text": "103‚Äì118, 2022a. Mallesham Dasari, Kumara Kahatapitiya, Samir R. Das, Aruna Balasubramanian, and Dimitris Samaras. Swift: Adaptive video streaming with layered neural codecs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Thelatency modelfordataloadforoneconvolution operationis Lat load = Bits input /BW ld .Theterm Lat load \nrepresentsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.Theterm BW ld denotesthebandwidthof eachloadoperation.Themodelsof P store and Lat store can bederivedinasimilarfashion. 2) ComputationonReRAMs: P comp isthedominantand mostcomplicatedpartwheretheanaloganddigitalsignals aremixed.Theenergyofone-cycle MACoperationsforan activationsizeof m√ón andactualduplicationaG, P comp‚àítile \ndividesintothefollowingparts:1) E DAC   denotestheenergy consumedforconvertingthedigitalinputsignaltotheanalog signalinabit-serialfashion;2) E MAC   denotestheenergy forperforming MACoperationsonReRAMs;and3) E ADC \nconsistsofthreepartsasshowninFigure5:3i) E BL   denoting theenergyforactivatingbitlines;3ii) E SA‚àíRef   denotingthe energyforsensingandamplifyingthe MACresultsignaland thenreferencinganalogsignalstodigitalsignals;and,3iii) E S+A   denotingtheenergyofShift&Addparttocomposethe Ô¨Ånaloutput. IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisÔ¨Åxedas Lat comp = T comp ,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 425,
    "augmented": true
  },
  {
    "text": "[178] Ted Zadouri, Ahmet √úst√ºn, Arash Ahmadian, Beyza Ermi¬∏s, Acyr Locatelli, and Sara Hooker. Push- ing mixture of experts to the limit: Extremely parameter efficient moe for instruction tuning. arXiv preprint arXiv:2309.05444 , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "News , 39(2):1‚Äì7, August 2011. [21] Jingwei Cai, Zuotong Wu, Sen Peng, Yuchen Wei, Zhanhong Tan, Guiming Shi, Mingyu Gao, and Kaisheng Ma. Gemini: Mapping and architecture co-exploration for large-scale dnn chiplet accelera- tors.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "The GKDQ always points to the next available kernel location. The control fetches the right number of kernels and all of them are synchronously executed in the active tiles. Eager Scheduling:  A weight stationary implementation with a conservative scheduling will always run synchronously.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Neurons with lower Shapley values are more likely to be dropped: \np i  = Œ¥ œï i  +  œµ where  Œ¥  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. Define a binary dropout mask  m  = [ m 1 , m 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "[2] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub KoneÀácn`y, Stefano Mazzocchi, Brendan McMahan, et al. Proceedings of Machine Learning and Systems , 1:374‚Äì 388, 2019. Towards federated learning at scale: System design.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "\"http://openholo.org/database/depth\". [46]  Nitish Padmanaban, Yifan Peng, and Gordon Wetzstein. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Yoonsung Kim, Changhun Oh, Jinwoo Hwang, Wonung Kim, Seongryong Oh, Yubin Lee, Hardik Sharma, Amir Yazdanbakhsh, and Jongse Park. Dacapo: Accelerating continuous learning in autonomous systems for video analytics. arXiv preprint arXiv:2403.14353 , 2024.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "The accuracy gain seen in  CIFAR-100  is lesser than ImageNet dataset because the class-based weighted voting works effectively when handling large number of classes (100 in  CIFAR  vs 1000 in ImageNet). Nevertheless,  Cocktail  is able to deliver the accuracy at 2x lower latency than  InFaaS  and 1.35x lower cost than Clipper. of 0.5% than  Clipper  (not plotted).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "[55] M. McCloskey and N. J. Cohen, ‚ÄúCatastrophic interference in connec- \ntionist networks: The sequential learning problem,‚Äù in  Psychology of learning and motivation . 24, pp. Elsevier, 1989, vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Roberta: A robustly optimized bert pretraining approach. [55]  Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoy- anov. arXiv preprint arXiv:1907.11692 , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "In fact, only one input argument, i.e., the number of depth planes, requires to be changed based on the approximation factor  Œ± , when the object is outside of RoF. Here, we set  Œ±  to 0 . 5, as our detailed profiling (discussed later in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Simi- larly, the pixel value rendered at  [ x 0 r , y 0 r ]  on the right VR screen \n247 \n0 \n2 \n4 \n6 \n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \nAvg. Reuse distance (# frame) \nUsers \nRhinos Timelapse Rollercoaster Paris Elephants \n(a) Reuse distance is just  2  for most of cases \n28% \n0% \n20% \n40% \n60% \nReuse Ratio \nVideo (b) Reuse ratio \n0% 20% 40% 60% 80% 100% \nG 4 3 2 1 \nNorm. to Ground Truth(G) \nPrecision \nReuseRatio PSNR \n(c) Precision vs. reuse ratio tradeoffs \nFig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 165,
    "augmented": false
  },
  {
    "text": "0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \nKitti Vision nuScenes Chime Cityscapes Waymo \nNormalized Latency \nCompute Server CSD Alveo FPGA \nFigure 4: Latency analysis of  Salient Store  on the commercial Xilinx CSD on a workstation class machine (lower is better). Data Location kernel Execution SpeedUp CSD1 CPU 1 CSD1 CSD1 3.9 CSD1 (0.1X), CSD2(0.9X) CSD1 (0.1X), CSD2(0.9X) 4.46 CSD1 (0.3X), CSD2(0.7X) CSD1 (0.3X), CSD2(0.7X) 5.608 CSD1 (0.4X), CSD2(0.6X) CSD1 (0.4X), CSD2(0.6X) 6.67 CSD1 (0.5X), CSD2(0.5X) CSD1 (0.5X), CSD2(0.5X) 7.7 Table 2: Effect of Data distribution on compute speed-up. Compute server indicates a software only classical storage solution without CSDs.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 244,
    "augmented": true
  },
  {
    "text": "We call this smooth transition strategy as  Transition Keep . With a power predictor [ 36 ], we can estimate the power level of the next power cycle in advance. In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Underthesequentialcomputation mode, theconvolutionlayersareexecutedonebyoneinasequential \nfashion, and as a result, the power model and latency model in Equations 2 and 3 can be directly used. We also model the pipelined computation mode shown in Equations 4 and 5. P LK  =(P ld √ó Lat ld Lk   +P comp √ó Lat comp Lk \n+P st √ó Lat st Lk   +P merge  √ó Lat merge Lk )/Lat Lk (2) \nLat LK  = Lat ld Lk   + Lat comp Lk + Lat st Lk   + Lat merge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC ‚â• 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 262,
    "augmented": true
  },
  {
    "text": "If those get full because of continuous power failures, the control directs the data to the global NVSBS (NVSB-NW and NVSB-SE in Fig. 5a ). The NVSB stores the global/asynchronous work queue and the shufÔ¨Çing conÔ¨Åguration (mini-batch arrangement).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "There is not much perfor- mance difference between V2 and V1, because we have to run the block matching algorithm on all the blocks before making the ‚Äúdirect-reuse‚Äù decision, which dominates the entire pipeline in both the design variants. CWIPC. Energy Consumption:  Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "[40]  X. Dong, C. Xu, Y. Xie, and N. P. Jouppi, ‚ÄúNVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory,‚Äù IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) , vol. 31, pp. 2.4.1‚Äì2.4.4, 2017.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "0 \n300 \n600 \n900 \n1200 \n0.25 0.5 0.75 0.98 0.99 \nResponse Time (ms) \nCDF Archipelago Fifer DProb Kraken SProb SLO Xanadu \nFigure 12: Real System: Response Time Distribution. across all functions in  Social Network  for the Poisson trace. An ideal scheme would focus on packing more number of requests per container to improve utilization without caus- ing SLO violations.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "‚Ä¢  We design a  morphable hardware accelerator  that efÔ¨Å- \nciently maps training tasks, is suitable for intermittent computing, and can adapt its capabilities to reduce power emergencies without devolving to grid operation. We dis- cuss how the proposed hardware techniques can be adapted by many of the current DNN training accelerators to add similar dynamism in sustainability-sensitive environments. ‚Ä¢  Finally, we evaluate Us.¬¥as in depth on a  real-world trafÔ¨Åc \ndata set  [ 97 ] and perform sensitivity studies on other classes (audio, IMU) of data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "We also conducted experiments with a strategy mimicking Potluck [12] on V1 [33] by employing the down-sampled image as the feature vector. as  key , and then caches the corre- sponding inference results (as  value ) for further reuse. Rather than capturing the reuse opportunities in raw input data, Potluck [12] Ô¨Årst extracts the feature vector (i.e., a vector generated from input image, such as SURF [47], HoG [48], Down-sampling [16], etc.)",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "In  SysML Conference , pp. 1‚Äì3, 2018. Graham Gobieski, Brandon Lucia, and Nathan Beckmann.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "Keep the cost down: A review on methods to optimize llm‚Äô s kv-cache consumption, 2024. [149] Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catan- zaro. Megatron-lm: Training multi-billion parameter language models using model parallelism, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "edu/~kriz/cifar.html . Albert: A lite bert for self-supervised learning of language representations. [51]  Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gim- pel, Piyush Sharma, and Radu Soricut.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "These aforementioned hardware equivocally echo the need of highly parallel computation with bigger and faster memory hierarchy to contain the pool of data for high-scale deployments. Our proposal to this end is to augment the said conventional wisdom with custom ‚Äúchiplet-based‚Äù accelerators  tailored  for the models running on them and using their reconfigurable property to leverage the same hardware for different types of experts that we define or may emerge in the future. Tools, Platforms and Frameworks for LLM Evaluation:  Although they do not capture system insights, a few mathematical models [133] have been proposed to estimate the complexity of LLM training process.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "Implications of Public Cloud Resource Heterogeneity for Inference Serving WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands \n3 How to Design Self-Managed ML Prediction Serving System? The objectives from Section  2  strongly motivate the need for a self-managed ML-prediction system that avoids the over-provisioning problem in VMs by efficiently blending serverless functions  with VMs. At the same time, right-sizing the number of requests in VMs and correctly configuring serverless functions  is quintessential to satisfy the three pri- mary application constraints: cost, latency, and accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "5 EVALUATION We evaluate our proposed  HoloAR  design by comparing the execu- tion latency and total energy consumption with four different AR hologram setups. In this section, we first describe our evaluation methodology, experimental platform, datasets, and measurement tools. Next, we analyze the results measured using these platforms.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Typically, the input feature maps are larger than the (individual) weights, and more importantly large weights can easily be represented \n897 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "; and vii)  What are the various combinations of algorithmic constructs, runtime software configurations, and architectural features, and how can their ‚Äúaffinity‚Äù be synergistically leveraged to enhance the efficiency of training and inference processes? . ; vi) What are the additional complexities and opportunities KV-caches bring in an EoE environment?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "482‚Äì494. [19] HEADJACK, ‚ÄúThe Best Encoding Settings For Your 4k 360 3D VR Videos + FREE Encoding Tool,‚Äù ‚Äùhttps://headjack.io/blog/best- encoding-settings-resolution-for-4k-360-3d-vr-videos/‚Äù. He, M. A. Qureshi, L. Qiu, J. Li, F. Li, and L. Han, ‚ÄúRubiks: Practical 360-Degree Streaming for Smartphones,‚Äù in  Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services , 2018, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "Therefore, different DNNs are needed to process data from these different locations. Consequently, the power requirement and the latency of these DNNs may vary and synchronizing them for collective execution would require scheduling that addresses these differences in resource requirements. Even if we were able to design a proper scheduling policy, for a conventional ensemble, all the sensors involved need to Ô¨Ånish their computation.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "The details of these formats are in the purview of cartography and computer graphics domain, and hence we do not evaluate all of the aforementioned formats. In our evaluations and experiments, we used the equirectangular format [52], which is one of the most popular projection formats. The  Projection Mapping  stage (  c  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "[22]  S. Giancola, J. Zarzar, and B. Ghanem, ‚ÄúLeveraging shape completion for 3d siamese tracking,‚Äù in  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. 1037‚Äì1050. [21]  Geo Week News Staff, ‚ÄúCloud Chamber: Low-cost smartphone app captures point clouds for AEC,‚Äù  ‚Äùhttps://bit.ly/3DP1Qvc‚Äù , 2018.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "And, Ô¨Ånally, we update RoI for the next layer (the region with the purple border in Step  7  ). The execution time of the PI for Frame-3 is only 54% of the FI, due to a large amount of computation reduction (achieved by omitting the unimportant regions). C. Design and Implementation \nWe designed our both schemes (frame-level reuse in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "This means that the object in question has been moving towards a direction, which triggers a ‚Äúposition change‚Äù event. Consequently, to reÔ¨Çect this event, Frame-3 needs to perform a full inference. However, as we can see from  6  in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Restrictions apply. [18] A. F. CNBC, ‚ÄúHow trafÔ¨Åc sensors and cameras are trans- forming city streets,‚Äù  https://www.cnbc.com/2021/02/22/how-trafÔ¨Åc- sensors-and-cameras-are-transforming-city-streets.html , (Accessed on 04/28/2023). Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "This approach defines a large set of different expert types, routers and composition functions that can be used to build an ‚Äúensemble‚Äù (model) that is customized for the application at hand, and allows for independent training and updating of experts, fa- cilitating continual learning and adaptability. Our proposal introduces an  Ensemble of Experts (EoE)  framework that embodies this co-design philosophy. We envision a network of expert language models, each trained on domain- \nspecific datasets, forming a modular and scalable system.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "Task fusion to minimize checkpointing overhead, which is critical in intermittent environments. 3. Dynamic adjustment of computational tasks based on both energy and task criticality.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "[29]  Magic Leap. 2020. Magic Leap 1 is a Wearable Computer for Enterprise Produc- tivity.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "For data compression in EH-WSNs, we need the compression algorithm to be  1  light weight  (for energy efficiency),  2  feature preserving  (for higher accuracy),  3 having a high compression ratio  (for communication effi- ciency), and  4  context agnostic  (for better generalization); i.e., our deployment scenario demands a  smaller representa- tive form  of the data that still  preserves enough application- specific features to perform meaningful classifications in a given DNN . Therefore, the standard data compression techniques are not very useful, let alone their energy efficient (such as quantized versions [ 33 ]) counterparts. Why Coresets?",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "For practical purposes, we fix it to be the execution time of the slowest function at the current function depth. The ‚Äòdepth‚Äô of a function, in this context, is defined as the distance, in terms of the number of edges in the DAG, from the start state to the current state. The Probability Vector after  ùëë number of time steps can be represented as  ùëÉ ùëë .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "981. [68]  Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, and Hartwig Adam. IOP Publishing, 032009.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Recall that the details of the pre- diction were described in Section  4.2.2 . The DeepAREst [ 4 ] model was trained using  Keras  [ 22 ] and  Tensorflow , over 100 epochs with 2 layers, 32 neurons and a batch-size of 1. The load prediction model resides in the master VM which constantly records the arrival rate in adjacent windows.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "To capture the current RoF, an additional eye track- ing step is introduced before the hologram computations, as shown in Fig. 6b \na  . This eye tracking step takes the current IR sensor im- ages as its input, and analyzes the user‚Äôs current gaze area as well as \nAlgorithm 2:  Inter-Holo algorithm.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "[43] Y. Xu, X. Liu, L. Qin, and S.-C. Zhu, ‚ÄúCross-View People Tracking by Scene-Centered Spatio-Temporal Parsing,‚Äù in  Proceedings of the Thirty- First AAAI Conference on ArtiÔ¨Åcial Intelligence , 2017, p. 4299‚Äì4305. [41] A. Rosebrock, ‚ÄúIntersection over Union (IoU) for Object Detection,‚Äù ‚Äùshorturl.at/gszOR‚Äù, 2016. [42] CVLAB in EPFL, ‚ÄúMulti-camera Pedestrians Video,‚Äù ‚Äùshorturl.at/ zDY25‚Äù.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks. The layers are scheduled in a sequential fashion. This execution style is called  Sequential .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Origin  uses the DNNs of Baseline-2 for the classiÔ¨Åcation tasks. A majority voting en- semble method is used in both of these baselines to mimic ensemble learning. Both the baseline setups run on a fully powered system equipped with a steady power source.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Containers \nRequest  \nQueue \nFunction 1 \nFunction 2 \nFunction n \n. . .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 20,
    "augmented": true
  },
  {
    "text": "When introduced to a new set of constraints (change of power availability, accuracy etc. IV. ), the micro-proÔ¨Åler Ô¨Årst looks in the history table to Ô¨Ånd a conÔ¨Åguration and runs proÔ¨Åling if and only if it could not Ô¨Ånd one.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "6.3.3 Sensitivity to Constraints \nFigure  14  plots the sensitivity of model selection policy un- der a wide-range of latency and accuracy constraints. Note that, the ensembles used in our experiments are at-least 4 models or more. For smaller ensembles, instance failures might lead to higher accuracy loss, but in our experiments, single models typically satisfy their constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "5, as our detailed profiling (discussed later in Sec. 5) indicates that setting  Œ±  to this specific value brings significant energy savings while maintaining good hologram quality. We also present a sensitivity study on how en- ergy savings and performance vary with different approximation factors in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "VI-C . We also investigate how different thresholds/preferences shape the behavior of our approach in a sensitivity study in Sec. VI-E .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Moreover, this additional request load trickles down to all the descendants, adversely affecting their response times as well. We refer to this effect as  Cold Start Spillover . Inadequately provisioning containers for such functions causes requests to queue up as containers are spawned in the background.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "In  Workshop on Serverless Computing (WoSC‚Äô20), December 7≈õ11, 2020, Delft, Netherlands. ACM, New York, NY, USA,  6  pages. https://doi.org/10.1145/3429880.3430093 \n1 Introduction \nSustained advances in ML has fueled the proliferation of emerging applications such as product recommendation sys- tems, facial recognition systems, and intelligent personal assistants [ 7 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "This is achieved through the use of a single Digital Signal Processing (DSP) block that operates on signed data representation. Consequently, these units are referred to as Signed Double Modular Multiplication (SDMM) units. The HSPM accelerator‚Äôs architecture, as illustrated in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "In  EuroSys . [35]  Kate Keahey, Jason Anderson, Zhuo Zhen, Pierre Riteau, Paul Ruth, Dan Stanzione, Mert Cevik, Jacob Colleran, Haryadi S. Gunawi, Cody Hammock, Joe Mambretti, Alexander Barnes, Fran√ßois Halbach, Alex Rocha, and Joe Stubbs. GrandSLAm: Guaranteeing SLAs for Jobs in Microservices Execution Frameworks.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "[90] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. Gshard: Scaling giant models with conditional computation and automatic sharding. arXiv preprint arXiv:2006.16668 , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, compared to the black line (only 10 blocks), the attribute in yellow line ( 10 4 \nblocks, each of them is  1000 √ó  smaller) exhibits a better similarity (i.e., left-shift towards the y-axis). This again indicates that, within a smaller macro block, the voxels have richer similarity with their neighbors. ‚Ä¢  When partitioning the macro blocks in an even more Ô¨Åne grain fashion, as shown in the green line with  10 5   segments, now the CDF curve is pushed towards left even further.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "This scarcity of high-quality data constrains the effective training of larger models. Furthermore, as depicted in Figure 1, Bill Dally, the Chief Scientist at NVIDIA, summarizes [30] how the compute needs for training have increased with model com- plexity, placing immense strain on existing computing systems. The resulting power needs have recently triggered data center providers to install their own power plants [44,53,136,155].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Chih-Kai Kang, Hashan Roshantha Mendis, Chun-Han Lin, Ming-Syan Chen, and Pi-Cheng Hsiu. Everything leaves footprints: Hardware accelerated intermittent deep inference. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , 39(11):3479‚Äì3491, 2020.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pp. 2001‚Äì2010, 2017. Sahand Salamat, Armin Haj Aboutalebi, Behnam Khaleghi, Joo Hwan Lee, Yang Seok Ki, and Tajana Rosing.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "More recently, another foveated rendering based CGH reconstruction technique has been proposed to accelerate calculations with negligible effect for the viewer [ 22 ]. We implemented such foveated rendering idea (de- noted as  Inter-Holo  design in Sec. 4.3) and found to reduce around 23% execution latency (in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "In this work we quantitatively characterize the cost, accuracy and latency implications of hosting ML inferences on different public cloud resource of- ferings. Our evaluation shows that, prior work does not solve the problem from both dimensions of model and resource heterogeneity. Hence, to holistically address this problem, we need to solve the issues that arise from combining both model and resource heterogeneity towards optimizing for application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Figure 6: Intra-Frame attribute compression example. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Accessed: 2024-04-27. [129] Ashutosh Pattnaik, Xulong Tang, Onur Kayiran, Adwait Jog, Asit Mishra, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. Opportunistic computing in gpu architectures.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "[83]  Neeraja J. Yadwadkar, Francisco Romero, Qian Li, and Christos Kozyrakis. A case for managed and model-less inference serving. In  Proceedings of the Workshop on Hot Topics in Operating Systems , New York, NY, USA, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Tianyi Shen, Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. IEEE Embedded Systems Letters , 2022. An efficient edge-cloud partitioning of random forests for distributed sensor networks.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Policies and Provisions for Reuse and Redistribution \nNo permission restrictions will be placed on the data. All data mentioned above will be accessible via our website dedicated to the project. 4.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "policy in use. Further, the scheduling strategy was modiÔ¨Åed using activity aware scheduling with extended round-robin such that all the sensors get enough time to harvest and also the best possible sensor works on the classiÔ¨Åcation task at hand instead of any arbitrary sensor. The added recall functionality enables ensemble learning.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "HotMobile ‚Äô16, 2016, pp. 57‚Äì 62. [35] mooovr, ‚ÄúRollerCoaster at Seoul Grand Park.‚Äù ‚Äùhttps://www.youtube.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Therefore, we need to Ô¨Ånd the classiÔ¨Åcation result for all the sensors without activating them. Even though AAS provides signiÔ¨Åcantly better results com- pared to standard round-robin, it is still unable to incorporate ensemble learning. The major challenge is the inability to run inferences in all the sensors simultaneously because of the harvested energy budget.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Exploiting frame similarity for efficient inference on edge devices. In  2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) , pages 1073‚Äì1084, 2022. [176] Huizi Yu, Lizhou Fan, Lingyao Li, Jiayan Zhou, Zihui Ma, Lu Xian, Wenyue Hua, Sijia He, Mingyu Jin, Yongfeng Zhang, Ashvin Gandhi, and Xin Ma.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "921‚Äì926. IEEE, 2022. Chih-Kai Kang, Hashan Roshantha Mendis, Chun-Han Lin, Ming-Syan Chen, and Pi-Cheng Hsiu.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "9, which is further translated to the total end-to-end energy savings shown in the right y-axis in Fig. 9. From this Ô¨Ågure, we observe that: ‚Ä¢  Baseline:  In  Baseline , since there are no optimizations, the projection operations for both eyes consume equal energy (on GPU), i.e., each eye‚Äôs compute consumes  50%  energy.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "[3]  2019. Provisioned Concurrency. https://aws.amazon.com/solutions/ case-studies/airbnb/.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "[126] Bowen Pan, Yikang Shen, Haokun Liu, Mayank Mishra, Gaoyuan Zhang, Aude Oliva, Colin Raffel, and Rameswar Panda. Dense training, sparse inference: Rethinking training of mixture-of-experts language models. arXiv preprint arXiv:2404.05567 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "As shown in Figure  5 ,  mixed procurement reduces the over-provisioning cost of VMs. However, these schemes do not address the holis- tic problem by taking into account model selection, resource selection, and resource scaling to cope up with user-specified constraints. We conduct similar experiments to mimic the mixed  procurement scheme.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Load Generator:  We use different traces which are given as input to the load generator. Firstly, we use real-world re- quest arrival traces from Wikipedia [ 76 ], which exhibit typical characteristics of ML inference workloads as it has recurring diurnal patterns. The second trace is production twitter [ 48 ] trace which is bursty with unexpected load spikes.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efÔ¨Åciently performing inference on an IoT device if it does not have either a high power or high stability power source. Given form factor constraints on energy storage, the former may be challenging, and energy-harvesting from sources such as solar, thermal, kinetic and radio frequency [ 11 ], [ 12 ], [ 13 ], [ 14 ], [ 15 ], [ 16 ] is notoriously unstable. While unstable power sources have been successfully utilized for applications in the IoT space [ 17 ], [ 18 ], [ 19 ], their use has not been heavily explored for RCA design.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 170,
    "augmented": true
  },
  {
    "text": "1586‚Äì1597, 2017. [43] Keras, ‚ÄúKeras applications,‚Äù  https://keras.io/api/applications/ , (Ac- \ncessed on 11/21/2022). [44] Konstantin Shmelkov, Cordelia Schmid, Karteek Alahari , ‚ÄúIncremental \nlearning of object detectors without catastrophic forgetting,‚Äù in  ICCV , 2017.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "For example, the total 168  Tiles  and one  IMA  element of the ISAAC architecture [ 3 ] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets. It can be seen that those designs are  not  suitable for an RCA supplied with harvested unstable power. ‚Ä¢  Although the spike-based scheme [ 5 ] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input/output data.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "The idea of making the ensemble task activity aware has similarities to weighted majority voting, where we assign weights to the individual learners participating in the ensemble, such that a higher accuracy classiÔ¨Åer contributes more weight towards the Ô¨Ånal result. However, from Fig. 2 it is clear that not all the sensors are equally good at classifying various ac- tivities; in fact, this builds the foundation of AASR.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Figure 4d shows that inference time will increase linearly with the number of estimators whereas it has a very small impact on correlation. Therefore, reducing the number of estimators while keeping the prediction quality over a certain boundary will optimize fine tuning the model. IV.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "edu/kriz/learning-features-2009-TR. pdf , 2009. Arduino.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "188‚Äì191. IEEE, 2021. Tong Chen, Haojie Liu, Qiu Shen, Tao Yue, Xun Cao, and Zhan Ma.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint of P merg   <P budget shouldbealways met.Therefore,the power P merge   andlatency Lat merge   ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofÔ¨Çine. 4)Activationtransitioncost:Theexecutiontransitionfrom onetiletoanotherinsideonepowercycleorfromoneactivation solutiontoanotherindifferentpowerlevelsalsocostspower P trans andlatency Lat trans .Activationtransitionimpliesthat weneedtoenablethecorrespondingcircuitsoftheto-be- activatedrowsandcolumnswhileshuttingdowntheothers. Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 211,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. [2] W. Niu, X. Ma, S. Lin, S. Wang, X. Qian, X. Lin, Y. Wang, and B. Ren, ‚ÄúPatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-Based Weight Pruning,‚Äù in  Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , 2020, p. 907‚Äì922.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "Considering that a lot of motivated undergrad- uate students at Penn State are interested in ML and AI, we plan to assign well-defined projects from this research as ‚Äúhonors theses‚Äù. We will team an undergraduate with one graduate student for regular men- toring. We have advised several Penn State honors students (including women and minorities) through our prior NSF projects.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping. Conf. In  IEEE Intl.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "The distance of this feature vector from the other cluster center is called ‚ÄúclassiÔ¨Åcation loss‚Äù [ 74 ], and this re-triggers clustering with an updated number of clusters. An encounter of a new example of the existing class is followed by an update to the clustering by minimizing the classiÔ¨Åcation loss of the newly-seen data. Case-3:  Finally, if the classiÔ¨Åer sees an example of a new class then the feature vector of the data sits far from all the cluster centers indicating an unknown class.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Clipper: A low-latency online pre- diction serving system. CoRR , abs/1812.01776, 2018. [27]  Daniel Crankshaw, Xin Wang, Guilio Zhou, Michael J. Franklin, Joseph E. Gonzalez, and Ion Stoica.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Users submit requests in the form of invocation triggers to applications  1  hosted on a Serverless platform. In  Kraken , containers are provisioned in advance by the Proactive Weighted Scaler (PWS)  2  to serve these incoming requests by avoiding cold starts. To achieve this, the PWS  2  first fetches relevant system metrics (using a monitoring tool  3  and orchestrator logs).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Achieving Compliant Data Res- idency and Security with Azure. https://azure.microsoft.com/mediahandler/files/ resourcefiles/achieving-compliant-data-residency-and-security-with-azure/ Achieving_Compliant_Data_Residency_and_Security_with_Azure.pdf . Mikl√≥s Ajtai.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "diurnal, flash-crowds etc.) 2.3 Over-provisioning VMs \nReal-world request arrivals rates are usually not constant as they significantly vary over time (e.g. Over-provisioning of  util_aware  and  exascale , nor- malized to a baseline  reactive  scheme for four traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "We use the published short object-centric Objectron [ 1 ] video dataset, which is accompanied by AR session metadata such as camera poses, as well as the object annotations such as position, orientation and dimension for nine categories of object videos 4 . The salient characteristics these videos are given in Tab. To collect performance metrics such as the streaming multiprocessor (SM) utilization, memory traffic, and CUDA kernel execution latency, we utilized the open-source Nvidia NVPROF tool [37] on the GPU platform.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "\"https://www.ni.com/en-us/innovations/white-papers/11/peak- signal-to-noise-ratio-as-an-image-quality-metric.html\". 2019. Peak Signal-to-Noise Ratio as an Image Quality Metric.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "The scheduler will pick the right model combinations from the cache based on the application requirements. We implement a load generator, which uses a \nWoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands J.R. Gunasekaran, et al. 0 \n1 \n2 \n3 \n4 \n0 \n0.5 \n1 \n1.5 \nutil_aware exascale mixed paragon \nSLO Violations \nNormalized Cost \nCost SLO violations \n(a)  Workload-1: Berkeley Trace.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "This software-based viewing window optimization is considered to be the state-of-the-art at an algorithm level, and we refer to it as Baseline  in this study. Video #Frames #Obj/Frame Distance ObjSize 1 bike[38] 150k 1.1 2.08m 1.54m 2 book[39] 576k 1.5 0.64m 0.28m 3 bottle[40] 476k 1.1 0.47m 0.22m 4 cup[41] 546k 1.6 0.47m 0.16m 5 laptop[42] 485k 1.3 0.58m 0.38m 6 shoe[43] 557k 2.3 0.65m 0.21m \n5.1 AR Hologram Configurations \nWe evaluate the following five configurations of AR holo- gram processing to demonstrate the effectiveness of our proposed HoloAR : ‚Ä¢  Baseline (Viewing-Window):  Similar to the recent viewing- window based sub-hologram optimization [ 52 ], we first obtain the field of view or the current viewing window from the user‚Äôs head orientation, and then skip the computations of the objects, which are outside the viewing window (i.e., only compute for the objects located inside) to save computations and energy. No.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 273,
    "augmented": true
  },
  {
    "text": "Sambanova sn40l: Scaling the ai memory wall with dataflow and composition of experts. arXiv preprint arXiv:2405.07518 , 2024. [132] Joan Puigcerver, Carlos Riquelme Ruiz, Basil Mustafa, and Neil Houlsby.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Using ER-r, we can complete more total inferences, \n1 This can also be extended to larger numbers of sensors and modalities \nbut this design is limited by the accuracy of individual sensors. Moreover, since all sensors are not equally capable of classifying each activity with same accuracy (Fig. 2), ER-r might lead to lower accuracy in many cases.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "In this section, we elaborate on the key components, focusing on DynFit and DynInfer, and explain how they uniquely adapt DNN training and inference to intermittent power conditions. 3.1 DynFit: Intermittency-Aware Learning \nDynFit  is designed to optimize deep neural networks (DNNs) for execution in environments char- acterized by intermittent power supply due to energy harvesting. The primary goal of DynFit is to \n3 \nadapt the DNN‚Äôs training process to operate efficiently under unpredictable energy budgets while maintaining acceptable accuracy and adhering to predefined service level objectives (SLOs).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "As we can see, the input voltages V1 and V2 are applied to the rows of the crossbar array, while the conductance values G1 and G2 are applied to the columns. The output currents I1 and I2 are the result of the multiplication-addition operation, and are obtained by summing the currents flowing through the ReRAM devices. Please refer to Figure 5a for more details.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "[7]  Akshitha Sriraman, Abhishek Dhanotia, and Thomas Wenisch. In  ATC . Tributary: spot-dancing for elastic ser- vices with latency SLOs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "[24]  Paul Covington, Jay Adams, and Emre Sargin. Deep neural networks for youtube recommendations. In  Proceedings of the 10th ACM con- ference on recommender systems , pages 191‚Äì198, 2016.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "¬¥as offers a 4.96% greater mean accuracy than prior approaches while our morphable accelerator that adapts to solar variance can save up to  { 234.95kWH, 2.63MWH } /year/edge-server compared to a  { DNN accelerator, data center scale GPU } , respectively. I. I NTRODUCTION \nThe rampant growth, and anticipated sustained expansion of data collection and consumption are currently driving data-driven analytics using trained inference models, with signiÔ¨Åcant economic impact. Amidst the myriad of data-driven domains, urban mobility, smart cities, autonomous driving, and the Internet of Things (IoT) emerge as some of the most rapidly expanding Ô¨Åelds contributing to the global economy, amounting to more than 4 trillion US dollars [ 1 ], [ 54 ], [ 76 ], [ 98 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 188,
    "augmented": true
  },
  {
    "text": "Co-locating this compute along with the inference and training would definitely hinder the critical path. 3 We assume the data to be eventually available in the data repository, where they can be properly stored for efficient lookup. This can be done by periodically transporting the data by swapping out storage bays.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Prior works relied on supervised learning or K-means clustering, un- suitable for  Us. ¬¥as  due to its need for unsupervised data annota- tion and the inability to handle large-scale datasets with numer- ous classes. To overcome these limitations,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Moreover, in many cases, computations are also sensor input-dependent such as the IMU data for determining the head orientation, which is updated across frames , at runtime. As discussed in Sec. III, the projection computation varies across  eyes  even for the same head orientation.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "We conducted character- ization experiments on AWS Lambda, currently the most predominant serverless function provider, to study the mem- ory allocated vs computation time trade-off. In our exper- iments we configure the memory allocation to the lambda function such that individual query latency is within the user-specified latency constraint. Figure  7  shows the computation time and cost for executing 1 million infer- ence queries for three different model types with different memory allocations.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "To identify them, we studied two published AR datasets (Objectron [ 1 ] for objects shown in Fig. 3a, and MPIIDEye [ 58 ] for users shown in Fig. 3b), and observed the following two properties in the AR holographic applications: Spatio Diversity for Objects:  Intuitively, objects which are far from the user and with small-sized shapes require less informa- tion to generate the virtual hologram than others (more details are provided in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "5) for AR holograms. 4.3) and found to reduce around 23% execution latency (in Sec. However, such performance gain from foveated rendering is still insufficient to close the 10 √ó  gap discussed above.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. nuscenes: A multimodal dataset for autonomous driving. 11621‚Äì11631, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. Figure 6: Intra-Frame attribute compression example.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "2019. Fast Calculation Method with Foveated Rendering for Computer-generated Holograms Using an Angle-changeable Ray- tracing Method. [62]  Lingjie Wei and Yuji Sakamoto.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Further, \n1 To give a quantitative estimation of the popularity of the game, a Pok√©mon GO event at Safari Zone New Taipei City, Taiwan in October 2019 had a total of 327,000 attendees and they walked around 4.5 million kilometers to catch 50 Million Pok√©mons [5]. 494 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. the limited battery capacity prevents users from enjoying their AR devices for extended periods of time.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "[4]  S. Ayukawa, N. Tokudome, S. Enokida, and T. Nishida, ‚ÄúTime- series lidar data superimposition for autonomous driving,‚Äù  Proc. ly/3OF66Tw‚Äù , 2021. [3] Apple Inc.,  ‚Äùhttps://www.apple.com/iphone-13-pro/‚Äù , 2021.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "1) Prior Intra-Frame Compression InefÔ¨Åciencies:  State- of-the-Art Intra-Geometry Compression 5 :  As discussed in Fig. 2  and Sec. Figure 4: Intra-frame PCC pipelines.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Wireless sensor networks (WSNs), one of the prominent classes of IoT deployments, is currently dominating and expected to be pervasive impacting many application spaces [ 13 ] including, but not limited to, body area network [ 22 ,  47 ], industrial monitoring [ 34 ], predic- tive maintenance [ 70 ], commercial satellites[ 15 ] and smart farming [ 61 ]. Moreover, these WSNs are and further will be participating in producing rapid inferences to support the increasingly complex tasks enabled by machine learning \n(ML) algorithms [ 47 ,  68 ], often tweaked towards edge de- ployments, and applications of such edge-analytics is also ex- ploding with the user and market demands. This represents a particularly challenging tension between energy availability and desired functionality, because the form factor constraints of the WSNs fundamentally limit active power, energy re- serves, compute and communication capabilities.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 209,
    "augmented": false
  },
  {
    "text": "DRQ: dynamic region-based quantization for deep neural network acceleration. In  ISCA . IEEE.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 24,
    "augmented": true
  },
  {
    "text": "The model‚Äôs performance is measured by a loss function  ‚Ñì :  Y √ó Y ‚Üí R ‚â• 0  that is convex in  Œ∏  for any fixed input-label pair  ( x, y ) . Problem Setting and Notation \nWe consider a global inference model  f Œ∏  :  X ‚ÜíY  parame- terized by  Œ∏  ‚àà R d . Addi- tionally, we discuss bounds on the newly introduced hyper- parameters and provide guidelines for selecting them.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Although dynamic model selection poli- cies can signiÔ¨Åcantly reduce the resource footprint as shown in Figure  3b , the cost is still 20-30% higher when compared to a single model inference. How to save cost? This calls for a dynamic model selection policy which can accurately de- termine the number of models required, contingent upon the accuracy and scalability of the model selection policy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "7 ) ( 10 ‚àí i )   =  0 . 83 \nThis corresponds to an accuracy of 83%, which is greater than our required accuracy of 82%). Given all the other models have higher accuracy, the least accuracy we can expect with such an ensemble is 83%.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Therefore, in Sec. V, we perform a detailed comparison of our work against these prior works. 3) System Support for Exploiting Pixel and Computa- tion Similarities: State-of-the-art proposals such as Deep- Cache [8], and Euphrates [9] have explored the temporal similarity at runtime for DNN inference on video streams.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Almost all of these applications can be categorized as interactive volumetric video streaming. where both geometry and attributes are essential as the contents are consumed by people for infotainment purpose. Related Work \n1) Point Cloud Use-cases:  Recently, PC is being widely used in various Ô¨Åelds, such as AR/VR [ 46 ], [ 81 ], telepres- ence [ 43 ], [ 57 ], [ 86 ], virtual tourism [ 12 ], [ 50 ], teleopera- tion [ 83 ], telemedicine [ 51 ], video streaming [ 24 ], [ 37 ] and gaming [ 81 ], [ 87 ], etc.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "109‚Äì114. 904 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "7. In the  Baseline , the OCE takes the head orientation as its input, processes the entire projection transformation for each pixel coordinate in the FoV region, and then stores the compute results for both eyes in DRAM for the subsequent mapping stage from the  360 ¬∞ frame to framebuffer. In our  EA  design, the last two head orientations are  cached  in local SRAM ( Comp 1  and  Comp 2  in the  EA block) and their corresponding projection computation results are stored in DRAM ( P i ‚àí 2 buff   and  P i ‚àí 1 buff ).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "5: Back-tracing from  out  to  in  for CONV. Fig. Thus, the inner part of the output is only related to the RoIs of input; the middle part is related to both the RoIs and the BG; and the outer part is only related to the BG.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Our earlier camps have already introduced participants to basic concepts in programming, building vision systems that assist visually impaired and learning skills towards building a basic embedded vision system, program- ming for robotics and exposure to various emerging tools in computing. We will continue to develop new week-long courses introducing students to LLMs/Generative AI and inspiring them through hands-on application and system building activities. PI Zhang has participated in the 2024 summer camp, and he will lead this effort for the future years.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "[2] ‚ÄúAchieving Compliant Data Residency and Security with Azure,‚Äù \nhttps://azure.microsoft.com/mediahandler/Ô¨Åles/resourceÔ¨Åles/achieving- compliant-data-residency-and-security-with-azure/Achieving Compliant Data Residency and Security with Azure.pdf . 13, no. [3] D. B. Agusdinata, W. Liu, H. Eakin, and H. Romero, ‚ÄúSocio- \nenvironmental impacts of lithium mineral extraction: towards a research agenda,‚Äù  Environmental Research Letters , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "[40]  Y. Lin, Z. Zhang, H. Tang, H. Wang, and S. Han, ‚ÄúPointacc: EfÔ¨Åcient point cloud accelerator,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2021, pp. [39]  L. Li, Z. Li, V. Zakharchenko, J. Chen, and H. Li, ‚ÄúAdvanced 3d motion prediction for video-based dynamic point cloud compression,‚Äù  IEEE Transactions on Image Processing , pp. 289‚Äì302, 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "AMD and Xilinx have intro- duced specialized tools and libraries designed to harness CSDs (AMD, a; AMD & Xilinx), enabling peer-to-peer PCIe transactions that bypass the CPU (AMD & Xilinx). The emergence of Compute Express Link (CXL) technology (Sharma, 2022a,b; Jung, 2022) further amplifies the potential of disaggregated storage and memory systems. Decoupling compute tasks needed for storing the data from the host CPU and embedding them directly within storage devices, particularly through CSDs, has demonstrated significant performance and energy benefits.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "This threshold is exceeded in  Media Service  for the majority of functions. Due to the difference in container provisioning, the difference in response times between the three schemes is evident at the tail of the response time distribution (Figure 13b). Comm Only  and  Conn Only  are seen to exceed the target SLO at the 99th percentile.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "With the help of the pose estimation, now the AR hologram pipeline has the knowledge about the range/size of each object as well as its relative distance from the user. Next, as shown in Algo. 3, for each of the objects, a corresponding approximation factor ( Œ≤ ) can be determined based on these insights.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "The unit compute (only a 3  √ó  3 convolution per tile) that  Us. Us. ¬¥as  was designed on a intermittency friendly approach, and was never designed to hit the best throughput.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "CoRR (2017). [51]  Murad Qasaimeh, Kristof Denolf, Jack Lo, Kees A. Vissers, Joseph Zambreno, and Phillip H. Jones. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "2 is invoked to decide among the execution choices for the incoming frames ‚Äì including Skipping, Full-Inference, and Partial-Inference. B. Experimental Platform and Datasets \nPlatforms : We used the Google Pixel 3 Android Phone [20] as our experimental platform.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Using the global arrival rate from all windows, the model predicts ( L p ) for  T p  time units from  T . T p  is set to 10 minutes because it is sufÔ¨Åcient time to capture the variations in long-term future. All these parameters are tunable based on the system needs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "More interestingly, software-level optimizations for this step have been fully exploited (e.g., the kernel functions are invoked in a fully-parallelized manner), yet it still dominates the latency and energy. This motivates us to further look into architecture-level optimizations in future work, including 1) replacing GPU with ASIC to improve the power efÔ¨Åciency for  Diff Squared  computation kernel; 2) customizing the accelerator (e.g., number of layers of the tree-structured adder) for the  Squared Sum  kernel; and 3) minimizing data movements such as inter-SoC (e.g., between GPU and CPU) or intra-SoC (e.g., across L2/L3 caches in a GPU) memory copies. E. Sensitivity Study \nOur proposed intra-frame PCC utilizes the Morton code to capture the spatial locality, and signiÔ¨Åcantly speeds up the compression ( 44 √ó ), with high compressed quality (48.5 dB PSNR).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 221,
    "augmented": false
  },
  {
    "text": "This allows the EH-sensor to opt for coreset formation followed by data communication to the host device as an energy-viable alternative to local DNN inference on the original data. In our example case, transmitting the raw data (60 data points, 32bit floating point data type) needs  240 Byte s of data trans- fer, and with coreset construction and quantization we can limit it to  36 Bytes  (for 12 clusters, each cluster center is represented by 2 Bytes of data, and radius represented by 1 Byte data), thereby  reducing the data communication volume by 85% . As the coreset for- mation algorithms are fairly simple [ 7 ,  8 ,  36 ,  37 ], it does not take much latency or energy to convert the raw sensor data into the coreset form even while using a commercial-off- the-shelf micro-controller (like TI MSP430FR5969 [ 66 ]).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 214,
    "augmented": true
  },
  {
    "text": "following two properties from a published  360 ¬∞ VR dataset [3], as shown in Fig. 2c: Head Orientation Proximity:  In a short period of time, the user‚Äôs head orientation is usually stable in a small space range (3D) or even still. In fact, from this dataset we have found that, the head orientation for users does not often change within around  150 ms  period of time.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "USENIX Association. [53]  Romain Lerallut, Diane Gasselin, and Nicolas Le Roux. In  13th USENIX Symposium on Operating Systems Design and Imple- mentation (OSDI 18) , pages 611‚Äì626, Carlsbad, CA, October 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Furthermore, estimating the user‚Äôs eye gaze,  Eye Track , requires the execution of a light-weight neural network that takes 4 . 8 ms . 4 ms  and achieves 2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "consuming one among the proposed geometry, intra- and inter- frame attribute compression techniques). We then analyze the bottleneck of our proposal and provide insights for potential architectural support to make PCC even more energy efÔ¨Åcient. As shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Inter-Intra-Holo:  It is to be noted that, when the user eye track- ing and pose estimation are available simultaneously for hologram processing, the  Inter-Holo  and  Intra-Holo  schemes can be both ap- plied to achieve maximum amount of energy savings and perfor- mance benefits. In this paper, we refer to this combined scheme as  Inter-Intra-Holo . 3.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Peacock Panda Quill Slug Cup Class \n0 \n50 \n100 \nAccuracy \nMNetV2 IRV2 NASLarge \nFigure 4:  Class-wise Accuracy. Therefore, a full-ensemble model participation is not required for all the inputs because, every model is in- dividually suited to classify certain classes of images when compared to other classes. Figure  4  shows the class-wise accuracy for three models on 5 distinct classes.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Second Version of HoloLens HPU will Incorporate AI Coprocessor for Implementing DNNs. \"https://www.microsoft.com/en- us/research/blog/second-version-hololens-hpu-will-incorporate-ai- coprocessor-implementing-dnns/\". [33]  Naoya Muramatsu, Chun Wei Ooi, Yuta Itoh, and Yoichi Ochiai.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "[45]  Davide Taibi, Nabil El Ioini, Claus Pahl, and Jan Raphael Schmid Niederkofler. 2020. Patterns for Serverless Functions (Function-as- a-Service): A Multivocal Literature Review..",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Accessed: 2024-08-01. National Institute of Standards and Technology (NIST). Post-quantum cryptography.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "Implementation and Evaluation \n6.1. Discussions and Limitations \n7. Conclusion \nThis should finish at 8 pages.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "[37] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, \nS. Bates, S. Bhatia, N. Boden, A. Borchers  et al. Infobase publishing, 2006. [36] C. Jones and J. D. Ryan,  Encyclopedia of hinduism .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "‚Ä¢  We can search for an intermediate power level, where we Ô¨Årst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level ‚Äì this strategy is called  Multi-step Transition . ‚Ä¢  If the power predictor reports a power transition from a high level to a low level, we can move to the new activation solution before performing the last incomplete inference ‚Äì this strategy is referred to as  Eager Transition . The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "The research team is planning to organize summer activities with high school students and teachers in the context of this project as well. More specifically, to complement the summer camp with a more in-depth exploration for the students, we will work with the local school science teachers and students to develop the inquisitiveness of the potential of LLM concepts and develop simple but interesting LLM-based applications to attract young students. For example, PI Zhang will lead a workshop for high school students featured with an LLM and society seminar and a Computational Linguistics Olympiad competition to inspire students‚Äô interests in CS and AI.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "Furthermore, the implications of training these MoEs in terms of required architectural and system support, overall training time, accuracy, and dynamic adaption in different application domains have not been systematically investigated. Additionally, there exists significant load imbalance among experts, increased communication overhead, and complexity in routing mechanisms [42,74,131,151]. Thus, while the MoE/CoE design paradigm is promising, the overall solution space is little explored, especially for complex compositions of smaller experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "JETSON AGX XAVIER AND THE NEW ERA OF AUTONOMOUS MACHINES. \"http://info.nvidia.com/rs/156-OFN-742/images/Jetson_AGX_ Xavier_New_Era_Autonomous_Machines.pdf\". 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "However, we observe that the pricing of EC2 VMs is a linear function of the VM size in terms of compute capacity and memory. Hence, nor- malized by number of requests, bigger VMs would still incur similar costs as smaller VMs. It is also possible to use bigger VMs, which can handle more concurrent requests compared to m4-large, thus mini- mizing the total number of VMs used.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Figure 1: DAGs of Dynamic Function Chains. NGINX ID \nMOVIE_ID \nTEXT_SERVICE \nUSER_SERVICE \nRATING \nCOMPOSE_REVIEW \nMOVIE_REVIEW \nUSER_REVIEW \nREVIEW_STORAGE \n(b) Media Service. NGINX \nCHECK_RESERVATION GET_PROFILES SEARCH \nMAKE_RESERVATION \n(c) Hotel Reservation.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "These datasets represent typical use cases in embedded systems where energy efficiency and minimal computational overhead are crucial. We use both commercial-off-the-shelf (COTS) hardware and state-of-the-art ReRAM Xbar- based hardware for this evaluation. Secondly, we introduce a novel dataset aimed at advancing research in predictive maintenance and Industry 4.0 (Lasi et al., 2014), and test NExUME on a real manufacturing testbed (¬ß4.3) with COTS hardware.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "On the other hand, the YOLOv4-tiny inference with the FI+SI scheme saves  53%  energy w.r.t. 8c. The PI technique can further save  6%  more energy on average, as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "The rest of this paper presents and experimentally evaluates two novel optimization strategies that exploit this similarity. IV. P ROPOSED  S TRATEGIES \nAs discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "These guidelines help in balancing immediate utility gains with long-term energy sustainability, ensuring that the game- theoretic model drives desirable participation behaviors. 5. Training and Aggregation Framework \nHaving established the equilibrium participation strategies and the underlying reward-based utility functions, we now consider the training process that fine-tunes the global in- ference model  Œ∏  ‚àà R d   within this EH, multi-sensor envi- ronment.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Ekya: Continuous learning of video analytics models on edge compute servers. Romil Bhardwaj, Zhengxu Xia, Ganesh Ananthanarayanan, Junchen Jiang, Yuanchao Shu, Nikolaos Karianakis, Kevin Hsieh, Paramvir Bahl, and Ion Stoica. In  CIDR , 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "These works are broadly categorized into: (i) multiplexing the different instance types (e.g., Spot, On- Demand) [ 12 ,  23 ,  34 ,  41 ,  42 ,  68 ,  79 ], (ii) proactive resource provisioning based on prediction policies [ 34 , 36 , 40 , 41 , 69 , 86 ]. Cocktail  uses similar load prediction models and auto-scales VMs in a distributed fashion with respect to model ensem- bling. Swayam [ 34 ] is relatively similar to our work as it han- \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1043 \nBaseline(BL) NASLarge IRV2 Xception DNet121 NASMob #Models 10 8 7 5 2 BL_Latency 311(ms) 152(ms) 120(ms) 100(ms) 98(ms) E_Latency 152(ms) 120(ms) 103(ms) 89(ms) 44(ms) \nTable 3:  Comparing latency of Ensembling (E_Latency) with single (baseline) models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 286,
    "augmented": true
  },
  {
    "text": "However, to achieve this, we need some extra information about the clus- ters. The standard method of clustering-based coreset con- struction keeps the cluster center and cluster radius, which gives the geometrical shape of the entire data. Extending this with  the point count for each cluster  allows for recon- struction of data in the original form that can be processed by DNNs trained on full-size data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "In general, this transition probability,  ùë° ùëóùëñ , is calculated as the number of requests from ùëì ùëó to  ùëì ùëñ divided by the number of incoming requests to  ùëì ùëñ in the context of the application being considered. In Figure 5, as- suming both column and row indices of ùëá start at 0, an entry ùë° 0 4  represents the transition probability from  NGINX ‚Äôs state to  Follow ‚Äôs state and is equal to 0.2. The Probability Vector is an  ùëõ √ó 1 column vector that cap- tures the probabilities of the model being in different states after a number of time steps have elapsed, given that the model was initialized at a known state.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "In case of a power emergency, the task is abandoned and a hardware-assisted backup and restore is performed. These QuantaTasks are carefully coded with optimized assembly language to maximize their efficiency. We take advantage of the on-board NV FeRAM to perform backup and restore in case of power emergencies.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Therefore, there is an urgent need to  minimize compute and power requirements  in archival processes. 2 \nData Task Algorithm % CPU Utilization % DRAM Utilization 16 Core Xeon Peak Average All Encryptions RSA512 2.18 14.56 5.85 All Decryptions RSA512 3.45 17.2 6.12 \n3D PC Compression OctTree 26.78 78.2 32.54 Inflation OctTree 29.24 81.56 36.18 \nVideo \nCompression ZStd 24.7 62.54 24.5 Inflation ZStd 22.6 79.18 29.43 Compression H264 12.85 52.46 21.4 Inflation H264 14.2 69.46 26.18 All (un)RAID Unraid 11.25 29.4 19.24 Table 1: Resource utilization while running different algorithms under classical data archival pipeline for multiple data modalities in an AWS h1.4xlarge storage-optimized instance. (e.g., systems with CPUs having a thermal design power of 145W and 64GB of DRAM as noted in Table 1) and requiring larger form factors, which exceed the capabilities of intermittent systems and challenge sustainability goals.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 268,
    "augmented": true
  },
  {
    "text": "The terms  R i ( t )  depend on the chosen actions and correct- ness of inferences. Since  U i ( t ) =  R i ( t )  ‚àí C i ( t ) , we have: \nŒ¶( a ( t )) = \nN X \ni =1 [ R i ( t )  ‚àí C i ( t )] . Due to bounded  Œ≥, Œ¥,  and  Œ∑ , and the fact that  ‚àÜ A i ( t )  and energy costs are bounded, each  U i ( t ) is finite.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "To achieve this, we design a ‚Äúmicro-proÔ¨Åler‚Äù that can look into the drift of the models as well as the power availability and decide the right hyperparameters to train the models. Prior works [ 12 ], [ 38 ], [ 68 ] have designed hyperparameter micro-proÔ¨Ålers. However, they never considered an intermit- tent power source, nor explored jointly optimizing multiple models with power, accuracy and latency constraints.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "921‚Äì926. Enabling fast deep learning on tiny energy-harvesting iot devices. In  2022 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "We include details on the energy efÔ¨Åciency of  Us. ¬¥as  under different of operation conÔ¨Ågurations in Table  II . Note that the energy inefÔ¨Åciency arises primarily from i) multiple saves and restores, ii) use of NV memories \nand iii) reconÔ¨Åguring the DRAM (along with a commercial ARM based host CPU).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "We next illustrate 3 common scenarios of leveraging the MVs to capture the reuse opportunities in a DNN-based object detection application. 3) Three Scenarios of Frame-Level Reuse: i Moving Object(s) : As shown in Fig. 3a, one of the most common cases in videos is that the object(s) (which have been identiÔ¨Åed in previous frames, i.e., Frame-1) move around in the current frame (i.e., Frame-2 , Frame-3).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Funda- mentally, while current DNNs can be trained or fine-tuned to fit within a given resource budget‚Äîbe it compute, memory, or energy‚Äîthey are  not  trained to expect a variable or intermittent resource income. Although intermittency-aware NAS (Mendis et al., 2021), could alleviate certain problems, they often assume fixed resource constraints and do not account for real-time energy fluctuations. In certain energy-critical scenarios, even EH-WSNs applying state-of-the-art techniques fail to consistently meet SLOs, sometimes skipping entire inferences to deliver results on time.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "The ‚Äùappeared‚Äú line represents the percentage of the frames in which the corresponding class is present, e.g. 3: Distribution of different classes on a typical trafÔ¨Åc pattern and the impact of training on the sampling bias. 0 20 40 60 80 100 \n0 20 40 60 80 100 \nClass Distribution \nAccuracy (%) \nBaseline Train-Win-1 Train-Win-2 Train-Win-4 Appeared \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "The cost incorporates energy consumption and future op- portunities. Let  e i ( t )  be the energy expenditure for sensor s i  if it participates at time  t , accounting for capture, infer- ence, and communication costs. Introduce a discount factor Œ≤  ‚àà [0 ,  1) , and let  V i ( t  + 1)  represent the expected future utility of sensor  s i  given its current decisions and predicted energy availability.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Summer Research Opportunities for High School Students and Science Teachers:  The PIs has been participating in the organization of various summer activities with high school students and teachers. PI Zhang has participated in the 2024 summer camp, and he will lead this effort for the future years. This summer camp has been very successful, and we plan to extend it to additional school districts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "11b ,  Us. Considering the power proÔ¨Åle of Fig. ¬¥as  can Ô¨Ånish about 50 cycles of retraining (50 complete training cycles) and DaDianNao can only Ô¨Ånish 22 training cycles, even assuming a zero overhead, seamless save-restore of the partial computes of DaDianNao during a power failure/emergency.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "The MoEs themselves are still monolithic models albeit having intra-model sparsity, and parameter-bloating [134] in MoE leads to large training resources. However, existing MoE and CoE models have significant limita- tions. Furthermore, the implications of training these MoEs in terms of required architectural and system support, overall training time, accuracy, and dynamic adaption in different application domains have not been systematically investigated.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "\"https://github.com/ google-research-datasets/Objectron/blob/master/index/bottle_annotations\". [41]  Objectron. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "arXiv , 2023. [169] Zhen Xie, Murali Emani, Xiaodong Yu, Dingwen Tao, Xin He, Pengfei Su, Keren Zhou, and Venka- tram Vishwanath. Centimani: Enabling fast AI accelerator selection for DNN training with a novel performance predictor.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "However, the deployment cost of prediction serving primarily depends on the type of resources being procured, which by them- selves are heterogeneous in terms of provisioning latencies and billing complexity. Thus, it is strenuous for an infer- ence serving system to choose from this confounding array of resource types and model types to provide low-latency and cost-effective inferences. In this work we quantitatively characterize the cost, accuracy and latency implications of hosting ML inferences on different public cloud resource of- ferings.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "IV. C ONCLUSIONS \nAn efficient compute and data partitioning between edge and cloud, while preserving data privacy, is an important problems to address for both existing and future deployments. This work provides a practical solution to achieve latency- accuracy balanced partitions for random forest based infer- ence tasks.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "The major  contributions  of this work are the following: ‚Ä¢  We identify the spatio-temporal redundancies for optimiz- \n1 In this paper, we use ‚Äúlocality‚Äù and ‚Äúframe similarity‚Äù alternatively. To the best of our knowledge, this is the Ô¨Årst work that targets to push the PCC to the edge by taking edge device- speciÔ¨Åc constraints into account and targeting four critical metrics ‚Äì latency, energy, quality, and compression ratio. 75 √ó  by reusing the matched blocks in reference frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "2) High-level Idea:  To answer the above questions, we propose region-level partial inference (PI) to Ô¨Årst determine \nAlgorithm 2:  Region Level Reuse Algo. 4: Main idea in our partial inference scheme. Input :  RD : Reuse Distance Input :  BBs : Bounding Boxes in Previous Frames Input :  MV s : Motion Vectors for Current Frame Output:  Flag : Decisions (Full, Partial, or Skip) Output:  RoIs : Regions of Interest \n1  procedure  Region _ Decision ( RD ,  BBs ,  MV s ) // main \n2 if  Frame Decision ( RD ,  BBs ,  MV s )  is  False  then \n3 return  { Skip , null } \n4 if  IsScenario 2  or  IsScenario 3  then \n5 return  { Full , null } \n6 for  mv  in  MV s  do // only consider Scenario1 \n7 if  max { overlapped.area } ‚â§ T moving 2  √ó  mv.area  then \n8 return  { Full , null } \n9 return  { Partial ,   \u0002   [ BBs, MV s ]  } \nFig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 297,
    "augmented": true
  },
  {
    "text": "raspberryPi) to sample, collect, and process the data and is also equipped with wireless communication to local/cloud server). Each (edge)  device  (which is a part of the  Deployment scenario like machine state monitoring) contains an embedded computer (e.g. The deployed edge devices perform the same analytics task (for example, monitoring the health of same type of machine at different sites) using a  random forest algorithm  (refer Algorithm-1).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Computer Networks , 2009. [77]  Alexander Vezhnevets and Vladimir Vezhnevets. Modest adaboost- teaching adaboost to generalize better.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "0 25 50 75 100 \nMN-BL \nTeacher \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-BL \nTeacher \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nNa√Øve w/Exemplar \nAccuracy in % \nHour-0 Hour-2 Hour-4 Hour-6 Hour-8 \nFig. Similarly, Ekya [ 12 ] only focuses on co-location of computation, and it‚Äôs efÔ¨Åciency on Ô¨Ånishing compute even on custom hardware is shown in Fig. 4 .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "In Figure  14a , we vary the latency under six different constant accuracy categories. 6.3.3 Sensitivity to Constraints \nFigure  14  plots the sensitivity of model selection policy un- der a wide-range of latency and accuracy constraints. It can be seen that for Ô¨Åxed accuracy of 72%, 78% and 80%, the average number of models increase with increase in latency, but drops to 1 for the highest latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "To tackle this, recent works [9], [6] use a non-volatile processor (NVP) to ensure sufÔ¨Åcient forward progress in the face of frequent power emergencies. Moreover, in addition to prolonging device lifetime, energy harvesting can help us reduce the environmen- tal impact of batteries [10]. However, energy harvesting is no panacea due to the Ô¨Åckle nature of harvested energy.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "ISBN 9781450349529. doi: 10.1145/3123939.3123948. URL  https://doi.org/10.1145/ 3123939.3123948 . Shulin Zhao, Haibo Zhang, Sandeepa Bhuyan, Cyan Subhra Mishra, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Scaling this to crowded cities with 30- 50+kilo-cameras like Beverly Hills ( >  35 k  [ 11 ]), Los Angeles ( ‚âà 35 k  [ 92 ]), New York ( ‚âà 56k [ 92 ]), or Chicago ( ‚âà 30k) will need a lot of power. In fact, it will take  ‚â• 3Million cameras (assuming  ‚âà 9 cameras/1000 people, similar to LA, and scaled to US population) to just enable autonomous urban mobility in the USA, which may consume 360 MW  power (1296 GWh  energy, 0.03% of US power) for video analytics alone. Clearly, the current solution is  not  sustainable, neither in terms of the load on the power grid, nor in terms of the  CO 2  footprint (1.1 √ó 10 9 lbs); reducing the power budget for continuous learning is essential, as the carbon footprint of DNN training has emerged as a prominent concern [ 21 ], [ 57 ], [ 67 ], [ 89 ], demanding careful consideration as a primary design metric.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 238,
    "augmented": false
  },
  {
    "text": "Kraken  shows 4x, 2.16x and 2.06x more container utilization compared to  Arch ,  Fifer , and  Xanadu respectively. An ideal scheme would focus on packing more number of requests per container to improve utilization without caus- ing SLO violations. This is because  Kraken  limits the number of containers spawned through function weight assignment and request batching.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Platform Freq. (MHz) \nArea (mm 2 ) \nPower \n(W) \nPeak Thpt. (GOps) \nEnergy Eff.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Instead of throwing more compute power, we want to emphasize that, the discussion in this section only focuses on the attribute locality within one frame, which has ignored the potential localities among consecutive frames. In fact, if frame-2 does not vary much with respect to frame-1, intuitively, there would be temporal locality between the two frames. Thus, to further improve the attribute compression efÔ¨Åciency, in the next section, we investigate the inter-frame similarity opportunity.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Considering the dotted lines with 1000 segments parti- tioned from I- and P- Frames, the green line represents the smallest delta between two segments, which indicates the upper-bound/the scope of the attribute similarity, whereas the red line represents the largest delta/the least similarity among the segments. Further, the gap between the dotted red and green (1000 blocks) is smaller compared to that between the solid yellow and black lines (corresponding to a 20 block partitioning), thus indicating that a Ô¨Åner partition granularity can observe less variance in the temporal \n286 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 166,
    "augmented": false
  },
  {
    "text": "Computer Networks  (2009). [50]  Liang Wang, Mengyuan Li, Yinqian Zhang, Thomas Ristenpart, and Michael Swift. 2018.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Our next-generation meta training and inference accelerator, 2024. [106] Meta AI. LLaMA-3.1 405B: Pre-trained Language Model.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "2  shows the different components of the student-teacher data annotation model adapted in  Us. ¬¥as , where the edge model is the ‚Äústudent‚Äù (continuously retrained), and larger models are the ‚Äúteachers‚Äù (the ones teaching the student about what-is-what). The students models are typically optimized for edge, i.e.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "3274‚Äì3280. [82]  C. Tu, E. Takeuchi, A. Carballo, and K. Takeda, ‚ÄúPoint cloud compression for 3d lidar sensor using recurrent neural network with residual blocks,‚Äù in  2019 International Conference on Robotics and Automation (ICRA) , 2019, pp. [81]  TopoDOT Blogger, ‚ÄúUsing Point Clouds for Augmented and Virtual Reality,‚Äù  ‚Äùhttps://bit.ly/3OFdA97‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Slack refers to the difference in expected response time and actual execution time of functions within a function chain. Functions in a chain can have widely varying execution times. Allotting stage-wise SLOs to each function in a chain in proportion to their execution times reveals that there are cases where there is significant difference (slack) between the function‚Äôs expected SLO and its run-time.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "36, pp. 1804‚Äì1816, Nov 2017. [22]  A. Colin, E. Ruppel, and B. Lucia, ‚ÄúA reconÔ¨Ågurable energy storage architecture for energy-harvesting devices,‚Äù in  Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018 , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "‚Ä¢  CWIPC:  Overall, when employing the CWIPC, the output frame size reduces to around  14%  of the original input frame (including 63 %  of geometry and 37 %  of attribute data). The reason for such low compression ratio is because ‚Äì  1  for intra-attribute compression, only entropy encoder is applied; and  2  even with the inter-frame compression, only few macro blocks are matched and inter-encoded, which limits the beneÔ¨Åts from inter-frame compression. As for \n8 The geometry PSNR are excellent for all designs (e.g.,  >  70dB), so we only compare the PSNR for attributes in the evaluations.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "The similar trends across these results highlight the impact of varying time windows and encounter- ing diverse scene changes, leading to degradation in network accuracy by up to 30%. These Ô¨Åndings underscore the critical challenge posed by data drift and the need for continuous learning on edge servers. Continuous Learning at the Edge: Continuous learning, wherein the model continually learns from new samples over time, adapting to seen and previously unseen classes, has \n892 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Convolutional Neural Networks for Human Activity Recognition Using Body-Worn Sensors. Informat- ics  (2018). [61]  Rachid Saadane, Abdellah Chehri, Seunggil Jeon, et al .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "9. That is, the selection ratio of  Sequential  is much higher than the ratio of  Pipelining  in ResiSchedule  solutions in the whole power trace. Energy efÔ¨Åciency of CNNs across the power sources normalized to ResiSchedule \nis higher than that of  Pipelining  solution for a signiÔ¨Åcant fraction of the active power cycles.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "2.2.2 What are the Prior Optimization Efforts? Targeting the compute-intensive holographic processing dis- cussed above,  foveated rendering  techniques have been previously proposed to approximate selective regions (i.e.,  peripheral vision ). In fact, prior research on HVS has shown that human eyes are able to observe beyond 135 ¬∞  vertically and 160 ¬∞  horizontally, but see fine details within an only around 5 ¬∞  central circle (i.e.,  foveal vision ).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "This research is supported in part by NSF grants #1931531, #1955815, #2116962, #2122155 and #2028929. R EFERENCES \n[1] T.-J. Yang, A. Howard, B. Chen, X. Zhang, A.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "(3) \nFormulation of the Composite Optimization Problem:  The problem is non-convex due to the discrete nature of quantization levels and dropout rates. We employ an alternating optimization strategy, iteratively optimizing subsets of variables while keeping others fixed. Our method differs from standard approaches by integrating energy constraints directly into the optimization, ensuring that the network learns to adapt its parameters based on energy availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "). Non-cooperative game models allow sensors to make au- tonomous decisions while considering the potential ac- tions of others, leading to equilibria that balance individ- ual utility with collective goals ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "5, in this paper, we evaluate the performance and energy benefits of  HoloAR  by using an embedded GPU prototype for the edge AR headsets [ 36 ], and leave the hardware-software co- design based on FPGA-based acceleration for future work. We would like to emphasize that the proposed  HoloAR  framework can, in principle, work with any hardware platform. As discussed later in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Our experiments show that the deviation from the original signal, in most cases, is limited to  ‚â§ 15%. Considering the fact that we do have access to the sensor data to train the learning algorithm, we can use the same data to train the GAN and with sufficient data, the discriminator could generate the lost signal with minimum error. However, in some pathological cases, the error at times goes close to 60%, and we believe them to be generated artifacts which are common side effects of the GANs[ 11 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Kaisheng Ma, Xueqing Li, Jinyang Li, Yongpan Liu, Yuan Xie, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Incidental computing on iot nonvolatile processors. In Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "\"https: //www.businessofapps.com/data/pokemon-go-statistics/\". [6]  Chenliang Chang, Kiseung Bang, Gordon Wetzstein, Byoungho Lee, and Liang Gao. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "This signiÔ¨Åcantly boosts accuracy compared to single-models, and for this obvious advantage, frameworks like Clipper [ 27 ] leverage ensembling techniques. Since cost plays a crucial role in application-provider consideration, it is quintessential to minimize the deployment costs, while maximizing accuracy with low latency. Nevertheless, with ensem- bling, the very high resource footprint due to sheer number of models that need to be run for each request [ 27 , 56 ], ex- acerbates the public cloud deployment costs, as well as leads to high variation in latencies.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "While probability-based container provisioning can significantly reduce the number of containers, the presence of container cold-starts leads to SLO violations (requests not meeting their expected response latency). This is because cold starts can take up a significant proportion of a function‚Äôs response time (up to 10s of seconds [ 13 ,  14 ]). A significant amount of research [ 18 ,  22 ,  24 ,  38 ,  39 ,  43 ,  52 ] has been focused to- wards reducing cold-start overheads (in particular, proactive container provisioning [ 3 ,  32 ,  44 ,  46 ]).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "To efficiently steam volumetric video to mobile devices, GROOT proposes a novel PD- Tree data structure and streams the volumetric videos at a 30fps frame rate with minimal memory usage and computation for de- coding [ 27 ]. Tigris proposes an algorithm-architecture co-design system specialized for point cloud registration, to improve real-time performance and energy effi- ciency for 3D perception applications [ 65 ]. Note, however, that none of these existing schemes target at reducing the amount of ‚Äúunnecessary‚Äù computations in the AR holographic applications.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Computational storage: an efficient and scalable platform for big data and hpc applications. Journal of Big Data , 6:1‚Äì29, 2019b. Min-Han Tsai, Nalini Venkatasubramanian, and Cheng-Hsin Hsu.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "The average number of models is in primary axis and cumulative accuracy in secondary axis. 6.3.2 Cocktail Failure Resilience \nWe use spot instances to host models in  Cocktail . As previ- ously discussed in Section  3 , spot instances interruptions can lead to intermittent loss in accuracy as certain models will be unavailable in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "As the energy income becomes more sporadic, hardware- assisted scheduling seamlessly transfers work to active pro- cessing elements (PEs), maximizing the completion of tasks that could have otherwise been lost. This hardware-driven adaptive scheduling signiÔ¨Åcantly impacts different data modal- ities, from large-scale to small-scale, and various magnitudes of energy income, as depicted in Fig. ¬¥as  plays a crucial role in efÔ¨Åciently handling varying energy income and workloads.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Since capturing PC no longer requires sophisticated, commercial and expensive devices and people are equipped with mobile PC capturing devices (like iPhone 13 Pro [ 3 ]), the application providers are also pushing many of the PC processing tasks like compression or rendering to the edge, to avoid the use of expensive cloud resources, minimize the data transfer latency, and/or protect user‚Äôs privacy. With this trend, the PC business is expected to reach a 10 Billion dollar industry by 2024 [ 71 ]. Considering the dense features, 3D geometry and the visual attributes captured in PC, especially for the media applications like telepresence and virtual visits, pre-processing [ 21 ], [ 44 ], [ 61 ], [ 84 ], compressing and storing [ 14 ], [ 16 ], [ 19 ], [ 47 ], [ 48 ], [ 74 ], post-processing and streaming [ 25 ], [ 40 ], [ 66 ], [ 76 ], [ 90 ] PC using a mobile device, while maintaining a reasonable quality of service (QoS), are fast becoming challenging tasks.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 242,
    "augmented": true
  },
  {
    "text": "Under review. arXiv:2410.05435v1  [cs.AR]  7 Oct 2024 \nClassification \nResults and \nActions \nUpdate \nModel Finetuning Exemplar Selection \nInference \nModel \nStacked Encoder \nStacked \nDecoder \nCompressed \nData \nQuantum-safe \nEncryption \nArchival¬† Storage (HDD) \nComputational \nStorage FPGA \nComptinuous Learning Compute \nVideo Source \nNeural Encoder \nFrame Loss \nFigure 1: Data flow pipeline of continuous learning edge servers with storage and data archival pipeline. The Shown storage pipeline is the preliminary focus of  Salient Store  .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "MACH [63] integrates a display cache to reduce the amount of memory bandwidth. Although, these techniques can potentially save memory usage/energy for  360 ¬∞ VR videos, as discussed in earlier sections, due to inherent nature of  360 ¬∞ video processing, which introduces additional overheads for projection computation, we identify compute  to be the major energy bottleneck. For example, AFBC [1] is proposed to efÔ¨Åciently compress video streams between the processing pipeline blocks.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "[54]  Kyle Olszewski, Zimo Li, Chao Yang, Yi Zhou, Ronald Yu, Zeng Huang, Sitao Xiang, Shunsuke Saito, Pushmeet Kohli, and Hao Li. IEEE Access  8 (2020), 93155‚Äì93178. 2017.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "https://aws.amazon.com/solutions/ case-studies/airbnb/. [3]  2019. Provisioned Concurrency.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "The weight for each function corresponds to the state transition probability from the start state to the current one (note that this may require possibly transitioning through a number of intermediate states). Thus, for a DAG with  ùëõ functions, the transition probabil- ity matrix,  ùëá , is an  ùëõ √ó  ùëõ matrix, where  ùëõ is the total number of states and each entry,  ùë° ùëóùëñ , is the transition probability from the state corresponding to the function along the col- umn j, ( ùëì ùëó ), to that of the function along the row i, ( ùëì ùëñ ). An example of a Transition Matrix for the  Social Network , with 11 functions, is depicted in Figure 5.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "2% accuracy of the state-of-the-art. Wireless sensor networks (WSNs), one of the prominent classes of IoT deployments, is currently dominating and expected to be pervasive impacting many application spaces [ 13 ] including, but not limited to, body area network [ 22 ,  47 ], industrial monitoring [ 34 ], predic- tive maintenance [ 70 ], commercial satellites[ 15 ] and smart farming [ 61 ]. 1 INTRODUCTION \nInnovations in low-power computing, artificial intelligence, and communication technologies have given rise to the gen- eration of intelligently connected devices that constitute the Internet of Things (IoT).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "In  2009 First International Conference on Advances in System Simu- lation , pages 125‚Äì131, 2009. [83] Yeskendir Koishekenov, Alexandre Berard, and Vassilina Nikoulina. Memory-efficient nllb-200: Language-specific expert pruning of a massively multilingual machine translation model.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "This GPU is commonly used in contemporary VR devices (Oculus [39], Magic Leap [16], and GameFace [47], etc.). Note that, with this setup, the projection computation is triggered for each frame, and also per projection computation invocation includes computation of two projection matrices for the two eyes. ‚Ä¢  PTU  (HW):  A recent optimized solution [28] utilizes a more energy-efÔ¨Åcient hardware accelerator, i.e., Projec- tive Transformation Unit ( PTU ), to process the compute- intensive projection operations.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "[17]  K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúArchitecture exploration for ambient energy harvesting nonvolatile processors,‚Äù in  2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , pp. 526‚Äì537, 2015. [18]  K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, ‚ÄúNEOFog: Nonvolatility-exploiting optimizations for fog computing,‚Äù in  Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 215,
    "augmented": false
  },
  {
    "text": "To explain the high-level idea behind PI, we reconsider Frame-3 in Scenario-1 discussed in Sec. 4. IV-A, and present our Ô¨Åve-step solution in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "5. ‚Ä¢  In the  Viewing-Window  scenario shown in Fig. 5a, only the soccer ball  object is located inside the viewing window in the current frame,  Frame-I , while  football  and  box  are not.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "1b). Therefore, we induce a delay (no-op cycles in Fig. 3) between one sensor Ô¨Ånishing an inference and the next sensor starting the next one, so that each of the sensors get more time to accumulate more energy prior to attempting an inference.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Instruction in Responsible Professional Practices \nThe PhD students will receive instruction in responsible and ethical professional practices regularly within the context of their work. Training will cover the fundamentals of the scientific method, data protection and ethical sharing, lab safety, and other standards of professional practice. They will also be encouraged to affiliate with one or more professional societies in their chosen field.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "We propose novel inference \nstrategies to maximize the number of predictions performed at the edge, while consulting the cloud only when the local results are not satisfactory. We also provide novel learning strategies, especially when the distributed sensors do not want to share the local data with the cloud, saving crucial communication latency and energy. We propose a novel framework to perform intelligent edge- cloud partitioning for a distributed sensor network running random forest-based analytics.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "In the following two subsections, targeting inference-based video applications, we present two novel schemes that take advantage of this similarity:  frame-level pruning  and  region-level pruning . A. Frame-Level Pruning \n1) Shortcomings of Pixel-by-Pixel Comparison:  We believe a solution based on exact pixel-by-pixel matching would be too strict and would not be suitable for DNN-based applications. This can be illustrated with a simple use-case scenario.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "To calculate the required number of containers for a single function that has multiple context-independent states associated with it, we take the sum of the calculated values for all of those states. 4 Overall Design of Kraken \nKraken 1   leverages the function weight estimation model from the above section along with several other design choices as outlined in this section (Figure 6). Users submit requests in the form of invocation triggers to applications  1  hosted on a Serverless platform.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "On the other hand, for attribute compression, we propose to sort the points in the Morton code order with the goal of capturing the attribute similarities. We believe this is the Ô¨Årst work that applies the Morton code-based parallel octree construction algorithm [ 31 ] to speed up PC geometry com- pression. Also, to utilize temporal locality, we propose an inter-frame compression scheme which further increases the compression efÔ¨Åciency.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 9th ACM Conference on Recommender Systems , pages 232‚Äì232, 2015. [54]  Weibo Liu, Zidong Wang, Xiaohui Liu, Nianyin Zeng, Yurong Liu, and Fuad E Alsaadi. A survey of deep neural network architectures and their applications.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Exploring Extended Reality with ILLIXR: A new Playground for Architecture Research. arXiv:cs.DC/2004.04643 \n505 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \n[20]  IFIXIT. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Background \nPoint Cloud in Real Life:  Point Cloud (PC) is a set of points which represent objects or shapes in a 3D space where each point/voxel (3D equivalent of a 2D pixel) contains its 3D location (x, y, z coordinates), as well as some attributes (e.g., colors, normal, etc. ). B ACKGROUND AND  R ELATED  W ORK \nA. II.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "While PCs containing only the 3D geometry data are commonly used in LiDAR-based 3D imaging for autonomous vehicles or robotics path planning, the lack of attributes nullify their usage for visual media consumption. Therefore, any PC application meant for visual media like \n283 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Recognizing facial expression: machine learning and application to spontaneous behavior. In  2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR‚Äô05) , volume 2, pages 568‚Äì573. IEEE, 2005.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efÔ¨Åciency. III. S YSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "On the other hand, our FI+SI+PI scheme can save  55% / 61%  of the execution time for YOLOv3/YOLOv4-tiny. More speciÔ¨Åcally, \nas shown in Fig. 8b and Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "27 √ó  the power compared to its planar counter- parts (1.5  Watts ). We also observe that, unlike conventional planar video processing where  memory  is the main bottleneck ( 43% ), in  360 ¬∞ VR video processing,  compute  dominates the \n1 Pupillary distance is the distance, typically measured in millimeters, between the centers of the pupils of the eyes. 2 Yaw: vertical; Pitch: side-to-side; Roll: front-to-back.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "I, thus changing the transformation matrix  T  and eventually leading to  re-computation  of the most compute-intensive projection matrix  P . To better under- stand which of these are the best candidates ( features , using machine learning parlance) for memoization and whether they are sufÔ¨Åcient or not, we next discuss input parameters and their impact on the computation: ‚Ä¢  Head orientation:  Any changes in this affect the matrix T 2  as discussed in Tab. Thus, it is a critical feature in projection computation executions.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "In Proceedings of the 18th Conference on Embedded Networked Sensor Systems , pp. 382‚Äì394, 2020. eperceptive: energy reactive embedded intelligence for batteryless sensors.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Inter-Intra-Holo : The above two designs can be integrated to- gether into the original hologram pipeline, in either Inter-then- Intra or Intra-then-Inter fashion. In this paper, we chose the first one and denote this design as  Inter-Intra-Holo . ‚Ä¢  HORN-8:  While hardware acceleration of hologram is not a goal of this work, to qualitatively compare our GPU-based design with hardware specific accelerators, we also discuss one of the most recent ASIC implementations, HORN-8 [ 35 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "And, over 40 hours of continuous learning, we get  ‚âà 5.02 frames/100-frames as exemplar data (resulting in  ‚âà 17.4% of total accelerator time). Performance-Power Trade-offs:  As Table  II  suggest,  Us. the learner classiÔ¨Åed  ‚âà 4.5 frames/100-frames (on an average) as exemplar data.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Therefore, there is an opportunity to skip some intermediate inferences over the period of an activity in order to increase harvesting duration and the prob- ability that an initiated inference will complete. So long as the number of skipped inferences is modest, there will still likely be samples processed before an activity Ô¨Ånishes. This can be extended further adopting a round-robin activation schedule to both increase harvesting periods per initiated in- ference on each node while increasing the odds that at least some node is attempting an inference at any given time.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "9 in most cases and 0 . 6 in some of the worst cases (refer Figure 14 for an example). In rare cases (once in over 2000 cases), the generator induced arti- facts which could result in wrong classifications.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "926‚Äì932. R EFERENCES \n[1]  E. E. Aksoy, S. Baci, and S. Cavdar, ‚ÄúSalsanet: Fast road and vehicle segmentation in lidar point clouds for autonomous driving,‚Äù in  2020 IEEE intelligent vehicles symposium (IV) . IEEE, 2020, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "977‚Äì987. In  2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS) . Phoenix: A \nConstraint-Aware Scheduler for Heterogeneous Datacenters.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "In  2018 USENIX Annual Technical Conference . 2018. KylinX: a dynamic library operating system for simplified and efficient cloud virtualization.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "IEEE. [65]  Ben Taylor, Vicent Sanz Marco, Willy Wolff, Yehia Elkhatib, and Zheng Wang. 2018.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "This inequality implies that even in a worst-case scenario for accuracy gain, the net expected benefit of correct par- ticipation surpasses the sum of potential incorrect penalties and energy costs. Without this condition, sensors might find participation systematically unprofitable. Non-Participation and Equilibrium: Since  Œ∑ > Œ¥ , we ensure that sensors prefer risking occasional incorrect infer- ences over consistently abstaining.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Under each type, there can be subtypes of ex- perts. For example, there can be different subtypes of sci- ence experts for different sci- entific disciplines. We will maintain a repository of LLM experts that are independently trained, from which we can select and modify to form an ecosystem of LLM experts for complex tasks in continually evolving usage scenarios.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2403.16303 , 2024. [177] Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito. Wordcraft: story writing with large language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "299 \nAuthorized licensed use limited to: Penn State University. [90]  T. Xu, B. Tian, and Y. Zhu, ‚ÄúTigris: Architecture and algorithms for 3d perception in point clouds,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2019, p. 629‚Äì642. [91]  X. Yan, C. Zheng, Z. Li, S. Wang, and S. Cui, ‚ÄúPointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling,‚Äù in  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "Intel Power Gadget. https://github.com/sosy-lab/cpu- energy-meter. [17]  February 2018.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Prior work [ 9 ] solves an optimization problem such that the input parameters are model_type, hardware_type (CPU or GPU), and the output parameter is response latency. 3.1 Model Selection \nIn accordance with  Observation 1 , model selection should be a function of any two parameters which optimize the remain- ing (third) parameter. At the same time, right-sizing the number of requests in VMs and correctly configuring serverless functions  is quintessential to satisfy the three pri- mary application constraints: cost, latency, and accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "To incorporate new knowledge, we will explore novel algorithms for expert-growing via life-long learning [147]. , n , we merge them into one model  Œ∏ m  by computing a weighted average of parameters where the weight is each parameter‚Äôs Fisher information:  Œ∏ m  =   P n i =1   F i Œ∏ i /  P n i =1   F i , where  F i  is the Fisher Information for  Œ∏ i . Knowledge Adaptation via Expert Growing and Shrinking.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "This improvement is significant in the context of energy-harvesting intermittent systems, where achieving high accuracy under strict energy constraints is challenging. For instance, on CIFAR10, NExUME achieves an accuracy of 76.29%, which is approximately 4.54% higher than DynBal, the next best method. The superior performance of NExUME can be attributed to its unique integration of energy variability awareness directly into both the training (DynFit) and inference (DynInfer) processes.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "As shown in Fig. 7c, on average, the  Inter- Holo  scheme saves 18% energy compared to the baseline, and the Intra-Holo  scheme saves 70% energy. Finally, the energy saving achieved by the  Inter-Intra-Holo  scheme is about 73%, meaning that it only consumes 27% of the baseline energy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "279‚Äì292. [28] J. R. Gunasekaran, C. S. Mishra, P. Thinakaran, B. Sharma, M. T. \nKandemir, and C. R. Das, ‚ÄúCocktail: A multidimensional optimization for model serving in cloud,‚Äù in  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , 2022, pp. [27] Z. Gong, H. Ji, C. W. Fletcher, C. J. Hughes, and J. Torrellas, \n‚ÄúSparsetrain: Leveraging dynamic sparsity in software for training dnns on general-purpose simd processors,‚Äù in  Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques , 2020, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 192,
    "augmented": true
  },
  {
    "text": "Task-2.6: Fault-Tolerant Expert Training Fault-tolerance of monolithic LLM models has been a major concern due to the long-running training jobs on a large number of GPUs [27, 149, 165]. The proposed EoE model can provide inherent fault-tolerance since each expert can be trained independently, and is thus exposed to hardware failures in a reduced time- frame. To further minimize the impact of failures, we will investigate known fault-tolerance techniques from the distributed computing domain to support graceful degradation of training.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "[168] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis. Efficient streaming lan- guage models with attention sinks. arXiv , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Impact on Exemplar Selection \nUs. ¬¥as  beneÔ¨Åts from the use of  multiple  teacher models for data annotation and exemplar selection. Prior works on intermittent learning have either chosen one teacher model \n900 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "We then analyze the results measured using these platforms. A. VR Design ConÔ¨Ågurations \nWe evaluate the following six conÔ¨Ågurations of VR stream- ing to demonstrate the effectiveness of D¬¥ej`a View: ‚Ä¢  Baseline  (SW):  We use a mobile GPU [36] to evaluate the baseline VR video streaming.",
    "source": "DejaView.pdf",
    "type": "sliding_window_partial",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "4  c  , the modiÔ¨Åed components in our pipeline compared to the previously-proposed geometry compression approach (depicted in Fig. 4  a  ) include the following: ‚Ä¢  Morton Code Generation:  Given the raw PC, instead of constructing the octree point-by-point, now the Ô¨Årst step is to generate the Morton codes in one shot (note that this can be performed in parallel and only takes 0.5 ms ). This additional pre-processing step can draw an overall layout for all the points, which will further help to parallelize the octree construction.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "[86]  Chengliang Zhang, Minchen Yu, Wei Wang, and Feng Yan. Xlnet: Generalized autoregressive pre- training for language understanding. arXiv preprint arXiv:1906.08237 , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "As the number of storage servers increases, the network contention and data orchestration challenges exponentially increase. Furthermore, each server performs more remote accesses, increasing the contention even more. This leads to an exponential growth in latency with the increase in the number of storage servers used per application.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "Our key contributions can be summarized as follows: \n‚Ä¢  DynFit : A novel training optimizer that embeds energy variability awareness directly into the DNN training process. The method includes targeted fine-tuning that not only regularizes the model but also pre- vents overfitting, enhancing robustness to fluctuations in resource availability. This optimizer allows for dynamic adjustments of dropout rates and quantization levels based on real-time energy availability, thus maintaining learning stability and improving model accuracy under power constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Our Intra-Inter-V1 (Quality-oriented):  This design favors the quality over compression efÔ¨Åciency, and it only takes  124 ms  ( 41 ms  for geometry compression, and  83 ms for attribute compression), contributing to around  34 √ó speedup w.r.t. CWIPC. This speedup comes from: 1).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "However, managing such data requires substantial storage infrastructure. For instance, storing a full day‚Äôs worth of 1080p video at 60fps requires ( 1920  √ó  1080  √ó  3  pixels  √ó  4  bytes per pixel  √ó 60  frames per second  √ó 3600 √ó 24)117 . 32  TiB of raw video data, which compresses to approximately 60  GiB to  400  GiB of encoded data per day.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "In  2019 IEEE International Conference on Cluster Computing (CLUSTER) . 2019. Kube-Knots: Re- source Harvesting through Dynamic Container Orchestration in GPU- based Datacenters.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "For example, the classiÔ¨Åer used in the left ankle sensor tends to be more accurate overall, but for classifying climbing action, it is not better than the chest sensor. Furthermore, it the relative weight of each sensor is likely to shift from user to user. Hence, to give the left ankle more weight while doing an ensemble for a climbing task makes \nthe classiÔ¨Åer biased.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Table  1  shows the different models available for image predic- tion, that are pretrained on Keras using  ImageNet  [ 29 ] dataset. Each model has unique accuracy and latencies depending on the model architecture. Typically denser models are designed with more parameters (ex.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "0 100 200 300 Time \n0.1 \n0.2 \n0.3 \nPrice ($) \nxlarge 2xlarge 4xlarge 8xlarge \nFigure 18:  Spot instance price variation (time is in hours). F Spot Instance Price Variation \nWe proÔ¨Åle the spot price of 4 types of  C5  EC2 VMs over a 2-week period in August 2020. The price variation is shown in Fig 18 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "To incorporate new knowledge, we will explore novel algorithms for expert-growing via life-long learning [147]. We will freeze some neurons of the expert while expanding the network with new parameters and retraining it on new datasets. On the other hand, for knowledge integrity and resource efficiency, we will also explore innovative directions for expert shrinking by unlearning outdated knowledge that is no longer required.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2404.05567 , 2024. Exploring fault-tolerant network-on-chip architectures. [127] Dongkook Park, Chrysostomos Nicopoulos, Jongman Kim, Narayanan Vijaykrishnan, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "https://gemini.google.com/app \", 2024. Google gemini. \" [52] Google.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "Porting ai/ml models to intelligence processing units (ipus). [115] Abhinand Nasari, Lujun Zhai, Zhenhua He, Hieu Le, Suxia Cui, Dhruva Chakravorty, Jian Tao, and Honggao Liu. 2009.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "System Model \nWe consider a network of  N EH sensors  S = { s 1 , s 2 , . . .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Award # 2338418 (CAREER: Trustworthy Human-Centered Summarization); PI: Zhang; duration=09/15/24-08/31/29; amount=$546,000. Broader Impacts: This project initiates several aspiring education and outreach activities supported by project research outcomes to involve, mentor, and empower female, underrepresented, disabled, and interdisciplinary students. Intellectual Merit: This research advances trustwor- thy summarization by centering design, development, and deployment on humans in terms of user preferences for controllability, social perspectives for fairness, and human knowledge for factuality.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "The micro-proÔ¨Åler, having run multiple sweeps, returns a set of hyper-parameters ( Œ® i ) for each model which is then stored in a history table. This helps us avoid unnecessary proÔ¨Åling (up to 41%). When introduced to a new set of constraints (change of power availability, accuracy etc.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Phoenix: A constraint-aware scheduler for heteroge- neous datacenters. [74]  P. Thinakaran, J. R. Gunasekaran, B. Sharma, M. T. Kandemir, and C. R. Das. In  2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS) , June 2017.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "2017. Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency. [30]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Algorithm Compression Ratio Accuracy Loss (%) Fourier Decomposition 3 - 5 9.1 - 18.3 DCT 3 - 5 5.8 - 16.2 DWT 3 - 6 5.3 - 12.7 Coreset 3 - 10 0.02 - 0.76 Table 1: Accuracy trade-off of different compression techniques: Low-dimensional data loses important fea- tures under lossy compression, dropping inference ac- curacy significantly compared to the original data. (Notations used: DCT: Discrete Cosine Transform, DWT: Discrete Wavelet Transform. De- tails on Coreset are available on Section 4.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "Figure 15 shows the breakdown of total number of containers spawned for each application, aver- aged across all realistic large-scale traces using the simulator. This is due to  Kraken ‚Äôs load/path probability miscalculations and the usage of  Commonality and  Connectivity  to cope with this. It is observed that  Kraken  spawns more containers ( 7%) than  Oracle , on average.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "[49] C.-H. Tsai, H.-T. Wang, C.-L. Liu, Y. Li, and C.-Y. Lee, ‚ÄúA 446.6 K-gates 0.55‚Äì1.2 V H. 265/HEVC decoder for next generation video applications,‚Äù in  2013 IEEE Asian Solid-State Circuits Conference (A- SSCC) , 2013, pp. 305‚Äì308.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2015 Conference on Em- pirical Methods in Natural Language Processing (EMNLP) , pages 58‚Äì68. Association for Computational Linguistics, 2015. [200] Yazhou Zu, Alireza Ghaffarkhah, Hoang-Vu Dang, Brian Towles, Steven Hand, Safeen Huda, Adekunle Bello, Alexander Kolbasov, Arash Rezaei, Dayou Du, Steve Lacy, Hang Wang, Aaron Wis- ner, Chris Lewis, and Henri Bahini.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "However, not all the deployments may want to participate in data sharing because of privacy reasons. B. The Case of Privacy Awareness \nHaving a centralized data repository of various systems improves model robustness.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "11  shows its ability to maximize the instantaneous power utilization and scale the number of tiles. This allows  Us. ¬¥as to effectively perform more computation with an intermittent power source.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Llmcompass: En- abling efficient hardware design for large language model inference. In  2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA) , pages 1080‚Äì1096, 2024. [181] Nan Zhang, Yanchi Liu, Xujiang Zhao, Wei Cheng, Runxue Bao, Rui Zhang, Prasenjit Mitra, and Haifeng Chen.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "In  2018 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 620‚Äì629, Feb 2018. [45]  Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vi- jay Vasudevan, et al. Searching for mobilenetv3.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "In  Practical Hologra- phy XXX: Materials and Applications , Hans I. Bjelkhagen and V. Michael Bove Jr. (Eds.). International Society for Optics and Photonics, SPIE, 144 ‚Äì 152.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "As a result, they can also be deployed on top of the PTU-based SoC. This can be further asserted from Fig. 9, that only 28%  of the compute energy is consumed w.r.t.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Secondly, the issue of  functionality  comes to the fore, requiring effective continuous learning from often non- Independently and Identically Distributed (non-IID) data. [ 50 ], [ 73 ] at a much lower rate, necessitates informed decisions regarding deployment placement and sampling rates. Such non-IID data distributions, evident in tasks like standard trafÔ¨Åc monitoring with varied class observations (e.g., more cars than buses, all frames having  STOP  signs), may introduce sampling bias  [ 70 ], [ 74 ] in the network.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Figure 3:  Cost and accuracy of ensembling vs single models. accuracies (< 75%) because single models can reach those accuracies. NASLarge IRV2 XceptionDNet121 NASMob 0 \n2 \n4 \n6 \nCost($) \nSingle-OD Ensemble-OD Ensemble-spot \n(b)  Cost of full-ensembling hosted on OD and Spot instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "The noisy data is generated by adding a Gaussian noise (with maximum SNR of 20dB) over the unseen test data. The Ô¨Årst iteration shows the accuracy with the unchanged conÔ¨Ådence matrix. Even though the accuracy claim of the models was nearly 85%, in the Ô¨Årst iteration, the accuracy drops below 80% because of the added noise.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "#depthPlanes \n(b) Avg. number of depth planes. Figure 8: (a): Profiling the power breakdown on the edge GPU prototype [36]; and (b): Average number of depth planes required for four design configurations.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Clearly, such temporal similarity for a particular user‚Äôs interests exposes another opportunity for leveraging prior \n497 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \nfoveated rendering in AR holograms, by reducing the amount of computation needed for the objects which are outside the RoF, thus only emphasizing on the processing of the objects which the user is currently focusing on. Driven by these observations, we next want to study the details of hologram with the goal of addressing two critical questions:  What are the problems in the current state-of-the-art hologram software and hardware? For example,  User1 has similar interest as  User3 , whereas  User2  focuses more on the bottom left corner.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 190,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:1811.02883 , 2018. Scale-sim: Systolic cnn accelerator simulator. [139] Warren S Sarle.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Albert: A lite bert for self-supervised learning of language representations. arXiv preprint arXiv:1909.11942 , 2019. [52]  Yunseong Lee, Alberto Scolari, Byung-Gon Chun, Marco Domenico Santambrogio, Markus Weimer, and Matteo Interlandi.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Therefore, managing and storing the hefty volume of video data brings more challenge due to the energy, compute and form-factor limitations. Modern and upcoming applications like urban mobility and autonomous driving are predicted to be generating hundreds of exabytes of data (Urban Traffic Dataset; Corporation; Wright\"; \"premioinc\") per year while increasingly being deployed at the edge calling for a robust, secure, and efficient infrastructure for storing data at the edge while needing occasional human intervention for maintenance. Using State-of-the-Art Video Data Storage?",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "A typical EH setup consists of 5 components, namely, energy capture (solar panel, thermocouple, etc), power conditioning, voltage regulation (buck or boost converter), energy storage (super capacitor) and compute unit (refer ¬ßAppendix B for details about each of them). To cater towards the sporadic \n2 \npower income and failures, an existing body of works explores algorithms, orchestration, compiler support, and hardware development (Yang et al., 2017, 2018; Mendis et al., 2021; Maeng & Lucia, 2018; Gobieski et al., 2018; Qiu et al., 2020; Islam et al., 2022; Mishra et al., 2024, 2021; Ma et al., 2016, 2017; Liu et al., 2015). Most of these works rely on software checkpointing (static and dynamic (Maeng & Lucia, 2018), refer ¬ßAppendix C) to save and restore, while some of the prior works developed nonvolatile hardware (Ma et al., 2016, 2017) which inherently takes care of the checkpointing.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 270,
    "augmented": false
  },
  {
    "text": "Clipper: A low-latency online pre- diction serving system. In  14th USENIX Symposium on Networked Sys- tems Design and Implementation (NSDI 17) , pages 613‚Äì627, Boston, MA, March 2017. USENIX Association.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "V. E VALUATION \nWe compare our proposed  EA  and  AE  designs with six different VR streaming setups, by evaluating the computation and the total energy consumption. In this section, we Ô¨Årst describe the experimental platforms, datasets and measurement tools used in this study. We then analyze the results measured using these platforms.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "¬¥as  can Ô¨Ånish about 50 cycles of retraining (50 complete training cycles) and DaDianNao can only Ô¨Ånish 22 training cycles, even assuming a zero overhead, seamless save-restore of the partial computes of DaDianNao during a power failure/emergency. Setup Effective Training Accuracy Degradation Replacement Cycle* Battery Backed Custom HW[5000mAH] 93.17 2.48 2 - 3 years Battery Backed Mobile GPU 78.55 7.43 18 - 24 months Fixed Power [15W] 67.54 12.6 NA Fixed Power [35W] 100 1.87 Us. ¬¥as 95.3 1.92 7 - 10 years \nTABLE III: Comparing  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 166,
    "augmented": false
  },
  {
    "text": "In  2023 IEEE International Conference on Robotics and Automation (ICRA) , pp. 5537‚Äì5543, 2023. doi: 10. A distributed online optimization strategy for cooperative robotic surveillance.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Restrictions apply. 296 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "We acknowledge that all product names used are for identiÔ¨Åcation purposes only and may be trademarks of their respective companies. R EFERENCES \n[1] S. M. Abhay S, ‚ÄúAutonomous vehicle market by level of au- \ntomation,‚Äù  https://www.alliedmarketresearch.com/autonomous-vehicle- market , Feb 2022, (Accessed on 08/04/2023). [2] ‚ÄúAchieving Compliant Data Residency and Security with Azure,‚Äù \nhttps://azure.microsoft.com/mediahandler/Ô¨Åles/resourceÔ¨Åles/achieving- compliant-data-residency-and-security-with-azure/Achieving Compliant Data Residency and Security with Azure.pdf .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 168,
    "augmented": true
  },
  {
    "text": "Since our dataset is from Bellevue, WA, we took the SOLRAD solar radiation data [ 25 ] (managed and published by National Oceanic and Atmospheric Administra- tion, NOAA) of Seattle, WA (the SOLRAD center closest to Bellevue and hence we believe is a good approximation). In our experiments we assume the hardware to be powered by a solar panel of one square-meter, and the powers are scaled accordingly (data is available as  W / m 2 ). Finally, we assume the exact same setup of the Urban trafÔ¨Åc dataset and hence have 5 different MobileNetV2 models trying to classify the trafÔ¨Åc they are facing, and learning from the streaming data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "Fig. 8c  shows the time distribution of the accel- erator between performing exemplar selection and training. It also shows the number of exemplar frames per 100 frame, i.e., of any 100 frame encountered, how many of those will contain a relatively new data.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "The results, plotted in Figure 3c, indicate that the greatest improvements are derived from the ‚Äúsynergistic operation‚Äù of all components, particularly DynFit and DynInfer. An ablation study evaluates the contributions of individual components within NExUME. Although iNAS enhances network selection, its lack of intermittency awareness significantly impacts accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Studying the state-of-the-art ensemble model-serving frameworks, we observe the following critical shortcomings: ‚Ä¢  Ensemble model selection policies used in frameworks like Clipper [ 27 ] are static, as they  ensemble all available models  and focus solely on minimizing loss in accuracy. This leads to higher latencies and further inÔ¨Çates the resource foot- print, thereby accentuating the deployment costs. ‚Ä¢  Existing ensemble weight estimation [ 87 ] has  high com- putational complexity  and in practice is limited to a small set of off-the-shelf models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "E Workings of Re-RAM Crossbar \nE.1 Re-RAM cross-bar for DNN inference: \nReRAM x-bars are an emerging class of computing devices that leverage resistive random-access memory (ReRAM) technology for efficient and low-power computing. These devices can perform multiplication and addition operations in a single operation, making them ideal for many signal pro- cessing and machine learning applications. Moreover, these devices can also be used for performing convolution operations, which are widely used in image and signal processing applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Prior works  [ 3 ,  9 ] have tried to solve the resource scal- ing problem with respect to hosting the applications in VMs. They employ autoscaling mechanisms to cope up with dy- namic load. These autoscaling mechanisms can be of two types: (i) spawn VMs if the resource utilization of existing VMs reaches a certain threshold (80% in most cases) [ 9 ], and (ii) spawn additional VMs than predicted request demand [ 6 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "In practice, we can extend Origin  further to other multi-sensor data-sets for HAR. Note that both the baselines are running on a fully powered system whereas  Origin runs entirely on harvested energy. Discussion:  Although  Origin  is proposed and works for energy harvesting wireless sensor networks, it can also be used with battery-powered or hybrid (a combination to battery powered and EH) systems to minimize the energy footprint while maximizing the accuracy.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "The PIs plan to recruit new women and minorities for this project as well. 5 Results from Prior NSF Support Award # 1763681  (SHF: Medium: Embracing Architectural Heterogeneity through Hardware-Software Co- design); PI: Das; Co-PIs: Sivasubramaniam and Kandemir; duration= 06/01/2018‚Äì05/31/2023; amount= $1,000,000. Intellectual Merit: This project explores hw-sw support to transform applications into suitable device-agnostic codelets, that serve as the granularity for seamless scheduling and execution across GPUs and FPGAs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "An example of a Transition Matrix for the  Social Network , with 11 functions, is depicted in Figure 5. An additional state,  end , is added to represent the state the model transitions to after a path in the DAG is completely executed. In Figure 5, as- suming both column and row indices of ùëá start at 0, an entry ùë° 0 4  represents the transition probability from  NGINX ‚Äôs state to  Follow ‚Äôs state and is equal to 0.2.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "In  Databricks Data Intelligence Platform: Unlocking the GenAI Revolution , pages 311‚Äì330. Springer, 2024. [58] Rakesh Gupta, Anil Singh, and Deepak Kumar.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "VII. C ONCLUDING  R EMARKS \nThe growth of smart cities and urban mobility applications, along with reformations in privacy laws, have produced a need for pervasive, DNN based continuous learning at the edge. Although current commercial devices are capable of handling inference at the edge, the power and resource requirements of training make it impractical and unsustainable for all edge nodes to also perform continuous training off of grid power.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "[94] Pengfei Li, Jianyi Yang, Mohammad A. Islam, and Shaolei Ren. Making ai less ‚Äúthirsty‚Äù: Uncovering and addressing the secret water footprint of ai models. arXiv preprint arXiv:2109.11295 , 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "12, no. 12th International Conference on Civil and Architecture Engineering. Military Technical College, 2018, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, we analyze four scenarios, \n241 \n2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA) \n978-1-7281-4661-4/20/$31.00 ¬©2020 IEEE DOI 10.1109/ISCA45697.2020.00030 \namely,  InterFrame-IntraEye (EA) ,  IntraFrame-InterEye (AE) , IntraFrame-IntraEye (AA) , and  InterFrame-InterEye (EE) , that are critical in capturing the head movement and eye correlation for projection computation. Out of these four scenarios, we observe that  EA  computation for head orientation can be exploited for  temporal reuse/memoization  since there is little difference between two previous head orientations, and  AE computation for exploiting the correlation between both the eyes by  spatial reuse ‚Äì correlating the coordinate relationship between both eyes . Since  head movement  and  cor- relations between the left and right eye projections  are the two critical components of the projection computation, we analyze and study them to explore possible opportunities to exploit these relations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 250,
    "augmented": true
  },
  {
    "text": "[189] Zhenyu Zhang, Ying Sheng, Tianyi Zhou, Tianlong Chen, Lianmin Zheng, Ruisi Cai, Zhao Song, Yuandong Tian, Christopher R√©, Clark Barrett, Zhangyang \"Atlas\" Wang, and Beidi Chen. Q-hitter: A better token oracle for efficient llm inference via sparse-quantized kv cache. In P. Gibbons, G. Pekhi- menko, and C. De Sa, editors,  Proceedings of Machine Learning and Systems , volume 6, pages 381‚Äì394, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "4 Optimizing Lattice-Based Cryptography \nFollowed by the video compression, in this section, we discuss the quantum safe encryption technique. Among quantum safe encryption algorithms, Lattice-based cryptography (LBC) (Micciancio & Regev, 2009; Ajtai, 1996), grounded in hard lattice problems, offers robust resistance against quantum attacks. This quantum resilience is vital for protecting large data-sets on machine learning storage servers, particularly from ‚Äôstore now, decrypt later‚Äô threats.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "However, the model selection policy effectively switches between differ- ent models based on the structure of input text (equivalent to classes in images). For instance, complex sentences are more accurately classiÔ¨Åed by denser models compared to smaller. Despite the lower accuracy gains,  Cocktail  is able to reduce the cost (Figure  17 ) of model-serving by 1.45 √ó  and 1.37 √ó for Wiki trace compared to  InFaaS  and  Clipper , respectively.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Additionally, we implement a partial inference scheme to enable region/tile-level reuse. Our experiments on a representative mobile device (Pixel 3 Phone) show that the proposed partial inference scheme achieves  2 √ó speedup over the baseline approach that performs full inference on every frame. We integrate these two data reuse algorithms to accelerate the neural network inference and improve its energy efÔ¨Åciency.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "These will be stored in XML and web formats. The lineage data will use the formats required by the underlying data lineage tools. 3.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Reasons for InefÔ¨Åciency \nTo better understand the performance of the PCC pipeline, we characterize the ‚Äúlatency breakdown‚Äù of two state-of- the-art G-PCC techniques, i.e., PCL [ 72 ] and TMC13 [ 56 ], on a typical edge SoC platform (NVIDIA AGX Xavier) in Figs. 2  b  and  c  . Overall, the entire PCC pipeline takes around 3.5 seconds 3 , which prevents one from employing such techniques in an edge device.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "B ACKGROUND AND  R ELATED  W ORK \nIn this section, we start our discussion by explaining a typical DNN execution on mobile devices for video analytics. We then go over potential optimization opportunities that prior works have explored to make DNN inference mobile-friendly. 1074 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "We extended this design idea by constructing a random forest model as a combination of multiple decision trees from different learners (different deployments). To preserve the data privacy of the participat- ing deployments, the cloud learns by ensembling randomly sampled decision trees from each of the deployments, instead of learning a random forest from the data shared by each of them. Random sampling of the decision trees also augments the model by minimizing the data induced bias of each of the models.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "Thus, our proposal does not rely on any assistance from hardware accelerators, cloud platforms, or neural networks. Instead, we focus exclusively on a typical edge GPU to execute the hologram, and present our three techniques, namely,  Inter-Holo  (as  Reference ),  Intra-Holo  and  Inter- Intra-Holo , which capture various approximation opportunities in the AR hologram applications to improve both performance and energy efficiency. Framework Prototype:  To prototype a real-life AR headset, a proper codebase and a hardware platform are essential.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Another comparison parameter is the  compression ra- tio . Our proposal provides similar compressed size as TMC13 [ 56 ] ( ‚âà 0 . 1 √ó  larger) when exploiting the entropy en- coding.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "We ensure its performance by: 1. (5) \nScheduling Performance Assurance:  Our scheduling heuristic,  Energy-Aware Priority Scheduling , while sub-optimal in the theoretical sense, is designed to perform near-optimally in practice for real- time systems. The energy availability constraint over time is expressed as (subject to energy and task constraints): P \ni : s i ‚â§ t<f i   E i  ‚â§ E b ( t )  The objective is to maximize the total weighted priority of scheduled tasks: \nmax { x i ,s i } \nN X \ni =1 \n\u0000 p i  ‚àí Œ±E i  ‚àí Œ≤ ( f i  ‚àí D i ) + \u0001 x i .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 184,
    "augmented": true
  },
  {
    "text": "ArXiv  (2021). [9]  Y. Feng, Shaoshan Liu, and Yuhao Zhu. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "[26] B. C. Kim and C. E. Rhee, ‚ÄúCompression EfÔ¨Åciency Evaluation for Virtual Reality Videos by Projection Scheme,‚Äù  IEIE Transactions on Smart Processing & Computing , pp. 102‚Äì108, 2017. [27] S. M. LaValle, ‚ÄúThe Geometry of Virtual Worlds.‚Äù ‚Äùhttp://msl.cs.uiuc.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. 0 \n100 \n200 \n300 \n1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 \n# TIles Utilized \nTraning Iteration \n#Tiles-Oracle Œ∑d≈ù≈Øƒû∆êÕ≤h∆îƒÑ∆ê DadianNao ≈µƒûƒÇ≈∂Õ≤h∆îƒÑ∆ê Mean-DaDianNao \n(a) Monotonically increasing \n0 \n50 \n100 \n1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46 49 \n#Tiles Utilized \nTraining Iteration \n#Tiles-Oracle d≈ù≈Øƒû∆êÕ≤h∆îƒÑ∆ê DaDianNao DƒûƒÇ≈∂Õ≤h∆îƒÑ∆ê Mean-DaDianNao \n(b) Rapidly varying \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 189,
    "augmented": false
  },
  {
    "text": "These stages include the data loading phase, the modular polynomial multiplication via the SDMM unit, and the final accumulation registers. The HSPM accelerator‚Äôs architecture, as illustrated in Fig. 3a, comprises three pipelined stages.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "The host device is used for data logging‚Äîcollecting SLOs, violations, power failures, etc., along with running the ‚Äúbaseline‚Äù inferences without intermittency. Baselines:  We take the combination of best available approaches for DNN inference on intermittent environment as baselines. All these DNNs are executed with the state-of-the-art checkpointing and scheduling approach (Maeng & Lucia, 2018).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "199‚Äì208. Spock: Exploiting Serverless Functions for SLO and Cost Aware Resource Procurement in Public Cloud. In  2019 IEEE 12th Interna- tional Conference on Cloud Computing (CLOUD) .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "overhead, as discussed in Sec. IV-C). In this scheme, one can observe from Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "Typically, these online service ap- plications are user-facing and hence, are administered under strict Service Level Objectives (SLOs) [ 47 ,  48 ] and response latency requirements. Therefore, choosing the underlying resources (virtual machines or containers) from a plethora of public cloud resource offerings [ 31 ,  33 ,  37 ,  41 ,  45 ,  50 ] becomes crucial due to their characteristics (such as provisioning la- tency) that determine the response latency. Serverless com- puting (FaaS) has recently emerged as a first-class platform to deploy latency-critical user facing applications as it miti- gates resource management overheads for developers while simultaneously offering instantaneous scalability.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 173,
    "augmented": true
  },
  {
    "text": "2dB when compared to TMC13, due to the macro block-based approximation for the inter-frame compression. the quality, it drops the PSNR by 7 . As for \n8 The geometry PSNR are excellent for all designs (e.g.,  >  70dB), so we only compare the PSNR for attributes in the evaluations.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2109.11295 , 2021. [94] Pengfei Li, Jianyi Yang, Mohammad A. Islam, and Shaolei Ren. Making ai less ‚Äúthirsty‚Äù: Uncovering and addressing the secret water footprint of ai models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very Ô¨Åne-grain fashion. 3) Execution strategies:  Figure 6 shows Ô¨Åve different execution strategies for a two-layer convolution execution experiencing two power cycles with different levels. In Fig- ure 6(a), a naive scheduling strategy is employed on a  Simple architecture .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Video Redandblack Longdress Loot Soldier Andrew10 Phil10 #Frames 300 300 300 300 318 245 #Points/Frame 727070 834315 793821 1075299 1298699 1486648 \nB. PCC Design ConÔ¨Ågurations \nTo demonstrate the effectiveness of our proposal, we evaluate the following Ô¨Åve PCC designs: ‚Ä¢  TMC13  [ 56 ]: We use TMC13 (G-PCC codec from MPEG), as the  state-of-the-art  approach for  intra-frame compression . Especially, by tuning the parameters (e.g., octree depth, compression algorithm, etc. ), we utilize the octree-based method to compress the geometry data losslessly, while the attributes are compressed by the predictive RAHT lossily.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 183,
    "augmented": false
  },
  {
    "text": "[8] Niket Agarwal, Tushar Krishna, Li-Shiuan Peh, and Niraj K Jha. Keyformer: Kv cache reduction through key tokens selection for efficient gener- ative inference. In P. Gibbons, G. Pekhimenko, and C. De Sa, editors,  Proceedings of Machine Learning and Systems , volume 6, pages 114‚Äì127, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Under the assumptions that ‚àÜ A i ( t )  is non-decreasing and that sensors have consistent energy and accuracy estimates, no cyclical behavior can persist. A cycle would imply an infinite sequence of im- provements or a return to a previously visited state without improvement, which cannot occur since profitable devia- tions strictly increase  Œ¶( a ( t )) . The presence of the discount factor  Œ≤  further stabilizes the process.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "The function is designed to handle energy constraints by decomposing the convolution loops into smaller quanta tasks. Foloowing are the outline of the requirements: \n1. Define ‚ÄòQuantaTask‚Äò as the minimum iterations that can run.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "The batch size denotes the number of requests per function each container can simultaneously serve without exceed- ing the SLO. However, only a fraction of these containers are actually spawned, as determined by the function‚Äôs batch size. In order to effectively handle mis-predictions in load,  Kraken  also employs a Reactive Scaler (RS)  7  that consists of two major components.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "If we can deploy the decision making logic on a  custom hardware  with negligible overhead, our proposed techniques would be more effective when targeting light DNN models. Also, as discussed in Sec. V-C, the overheads brought by our decision making amount to  5%  of the DNN inference time for YOLOv4-tiny when running on CPU, which reduces the performance and energy savings for our proposed schemes.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "In Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture , pp. 204‚Äì218, 2017. Kiwan Maeng and Brandon Lucia.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "However, with a proper retraining, the smaller model could keep up with the original accuracy. We also observe a similar trend over other modalities, making the importance of continuous learning clear for multiple domains. However, in a continuous learning paradigm, training be- comes an essential, repeatedly scheduled task whose computa- tional and time costs cannot be considered a one-time overhead freely delegated to the cloud.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "[86]  Chengliang Zhang, Minchen Yu, Wei Wang, and Feng Yan. Mark: Exploiting cloud services for cost-effective, slo-aware machine learning inference serving. In  ATC , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "In fact, from this dataset we have found that, the head orientation for users does not often change within around  150 ms  period of time. Furthermore, even in cases where head orientation changes, the change is usually within a small range ‚Äì in a few consecutive frames. Since two identical head orientations lead to the same projection matrices, one opportunity to reduce computation is to  memoize  a set of head orientations as well as their corresponding compute results.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "( T s ) is set to 1 minute as it is the typical instance provisioning time for EC2 VMs. To calculate ( L p ), we sample the arrival rate in adjacent windows of size  W over the past S seconds. Using the global arrival rate from all windows, the model predicts ( L p ) for  T p  time units from  T .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Workload:  As shown in Table  5  we use image-classiÔ¨Åcation and Sentiment Analysis (text) applications with two datasets each for our evaluation. Sentiment analysis outputs the sen- timent of a given sentence as positive negative and (or) neu- tral. We use 9 different prominently used text-classiÔ¨Åcation models from transformers library [ 81 ] (details available in appendix) designed using Google BERT [ 30 ] architecture trained on  SST  [ 72 ] and  SemEval  [ 66 ] dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "2019. Kube-Knots: Re- source Harvesting through Dynamic Container Orchestration in GPU- based Datacenters. In  2019 IEEE International Conference on Cluster Computing (CLUSTER) .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Our  Paragon  scheme optimizes the model selection for workload-2 such that, it chooses the least cost-effective model for the given accuracy and latency constraint. The naive model selection policy would not choose the models as its oblivious to user requirements and model characteristics. Figure  1  shows the candidate models which can be used for a given latency and accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "2017. Latency Requirements for Foveated Rendering in Virtual Reality. ACM Trans.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1053 \n[12]  Ataollah Fatahi Baarzi, Timothy Zhu, and Bhuvan Urgaonkar. Ensembling in Azure ML Studio., February 2020. https://docs.microsoft.com/en-us/azure/machine-learning/studio- module-reference/multiclass-decision-forest . Burscale: Using burstable instances for cost-effective autoscaling in the public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "Towards this, Han et al. proposed the viewpoint-dependent PCC scheme (termed as ‚ÄúViVo‚Äù) which only sends the 3D tiles within user‚Äôs Ô¨Åeld of view [ 24 ], thereby reducing the data volume. Such optimizations [ 37 ], [ 59 ], [ 68 ] are extremely important for applications like virtual tourism, video streaming etc.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "This ensures that no computation is lost when the power goes out. C.1.5 Resumption Mechanism \nUpon resuming, the algorithm loads the saved state using the  LOAD_STATE  function. This state is used to continue the computation exactly where it left off, minimizing redundant operations and ensuring efficiency.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Therefore,  Us. ¬¥as employs a weight stationary compute mapping for executing the training tasks on the morphable hardware. A.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Otherwise, continue refine- ment. 15: end if 16: Check feasibility conditions again to ensure no viola- tion of baseline inequalities. 17: If performance metrics (accuracy, sustainability) are satisfactory, terminate.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Q-hitter: A better token oracle for efficient llm inference via sparse-quantized kv cache. In P. Gibbons, G. Pekhi- menko, and C. De Sa, editors,  Proceedings of Machine Learning and Systems , volume 6, pages 381‚Äì394, 2024. [189] Zhenyu Zhang, Ying Sheng, Tianyi Zhou, Tianlong Chen, Lianmin Zheng, Ruisi Cai, Zhao Song, Yuandong Tian, Christopher R√©, Clark Barrett, Zhangyang \"Atlas\" Wang, and Beidi Chen.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "By characterizing accuracy  vs.  latency of ensemble models, we identify that prudently selecting a subset of available models under a given latency can achieve the target ac- curacy. Cocktail , by coalescing these beneÔ¨Åts, is capable of operating in a region of optimal cost, accuracy and latency (shown in Figure  1 ) that prior works cannot achieve. Towards this, the key contributions  of the paper are summarized below: \n1.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "1) with more holographic data accesses (fetched from the host-side memory). We next quantify how many depth planes can be reduced by our approximation scheme. Towards this, we plot, in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "5:  Simulation-Refinement Loop: 6:  for  k  = 1 ,  2 , . . .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "In our EoE , two unique KV cache challenges arise: i) Loading experts and their KV caches onto GPUs for a user can cause high latency and memory consumption due to the initial ‚Äúprefill‚Äù stage, leading to a  cold start  problem. We plan to address this in two ways. To address this, we plan to prefetch experts  and their KV caches (leveraging hot and cold experts) or GPU load balancing to select devices with sufficient memory; and ii) Each expert has specific memory requirements for model weights and past KV caches, and must reserve space for future KV caches to prevent out-of-memory errors, which depends on the expert‚Äôs response length‚Äîfrom single words to thousands of tokens.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "1%  for YOLOv4-tiny ‚Äì both w.r.t. One can observe that the mAP in our FI+SI scheme only drops by  0 . 075%  on average for YOLOv3, and  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "From Table 5, it can be seen that  Comm Only  spawns 8% more containers than  Conn Only  for  Social Network . This difference is lesser for the other applications. Upon closer examination, we see that this is due to functions having different degrees of  Commonality and  Connectivity .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "2.2 Motivation Two specific challenges in the context of DDAs along with potential opportunities to resolve them are described below: Challenge 1: Path Prediction in DDAs. DDAs will only have a subset of their functions invoked for an incoming request to the application due to the presence of conditional paths within their DAGs. Figure 1 depicts the DAGs of three such applications from the  ùê∑ùëíùëéùë°‚ÑéùëÜùë°ùëéùëü benchmark suite [ 29 ], and Table 2 summarizes the various workflows that can be triggered by an incoming request to them.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "In our work, local computation across the CNN applications is  ‚àº 50x more efÔ¨Åcient than transmission over Bluetooth with 3Mbps and 2.5mW. C. Power utilization In order to further understand the power utilization, we use a two-dimensional plot that illustrates the features of power consumption with the ResiSchedule  strategy, as shown in Figure 10. The x-axis (power efÔ¨Åciency) denotes the percentage of power cycles where the RCA can activate.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Hence- forth, we refer to static function chains as Static DAG Ap- plications (SDAs). Clearly, having prior knowledge of what functions will be invoked for an application makes container provisioning easier for SDAs. For example, in  Hotel Reservation (Figure 1c), if only one path (say,  NGINX - Make_Reservation ) is always chosen, it represents a static function chain.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "In Houda Bouamor, Juan Pino, and Kalika Bali, editors,  Proceedings of the 2023 Conference on Empirical Methods in Natu- ral Language Processing , pages 6998‚Äì7010, Singapore, December 2023. Unified low-resource sequence labeling by sample-aware dynamic sparse finetuning. Association for Computational Linguistics.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "If the number of experts is still larger than needed, a clustering algorithm (e.g., AGNES [139], and topic clus- tering [160]) can be employed to combine experts with the highest cluster scores, thus reducing the total number of experts. Automatic EoE Graph Construction for Workload Balance. The EoE graph pruning process, involving removing and merging experts, can sometimes result in imbalanced branches, where one branch contains significantly more experts than another.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "550‚Äì555. [52]  MPEG, ‚ÄúG-PCC codec description v2,‚Äù ‚Äùhttps://bit.ly/ 3nN43C8‚Äù , 2019. [53]  MPEG, ‚ÄúMPEG Point Cloud Compression,‚Äù  ‚Äùhttps://mpeg- pcc.org‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "The PIs‚Äô labs house several medium-sized clusters of rack-mounted servers connected via 10Gbps Eth- ernet switches. A large portion of our test and development will be performed on these machines. The prototyping efforts in the proposed research will be carried out primarily in the research labs at Penn State, directed by Das, Kandemir, and Zhang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "In an edge server where we are only worried about storage and not retrieval 3 , the vector database approach is  not  effective. Rather, storing the data in a compressed and encrypted format (with redundancies) is more efficient and therefore is the focus of our work. However, it is obvious that this approach, albeit good for streaming and retrieval, are not entirely space-efficient, and at times can increase the data volume by many folds (Douze et al., 2024).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "0 100 200 300 \nStatic Provisioning \nProbability-based \nXanadu \n# Containers NGINX ID Movie_ID Text User_Service Rating Compose_Review Movie_Review User_Review Review_Storage \n(b) Media Service. 0 50 100 150 \nStatic Provisioning \nProbability-based \nXanadu \n# Containers \nNGINX Check_Reservation Get_Profiles Search Make_Reservation \n(c) Hotel Reservation. Figure 2: Function-wise Breakdown of Container Provisioning across Applications.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Silicon inter- poser with tsvs (through silicon vias) and fine multilayer wiring. In  2008 58th Electronic Components and Technology Conference , pages 847‚Äì852. IEEE, 2008.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Towards this, we discuss the trade-offs of intermixing resources like serverless functions along with VMs and identify the key challenges associated with configuring these resources. We propose multiple key-policies to make resource manage- ment; (i) latency aware, (ii) multi-dimensional SLO aware, and (iii) request load variation aware. These policies can be collectively used for cost-effective prediction serving with- out compromising on latency and accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "24 \nF Pseudo Codes \nF.1 Depth-wise Separable Convolution 2D Using TI LEA \nDepth-wise separable convolution is an efficient form of convolution that reduces the computational cost compared to standard convolution. Here we describe the implementation of depth-wise sep- arable convolution 2D using the Low Energy Accelerator (LEA) in Texas Instruments‚Äô MSP430 microcontrollers. F.1.1 depth-wise Separable Convolution 2D Using Conv1D \nThe pseudo code described in Algorithm 1 implements a depth-wise separable convolution 2D (DWSConv2D) using a 1D convolution primitive function (conv1D).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 168,
    "augmented": false
  },
  {
    "text": "NetAdapt: Platform- Aware Neural Network Adaptation for Mobile Applications. In  ECCV . [69]  Zhuoran Zhao, Kamyar Mirzazad Barijough, and Andreas Gerstlauer.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "However, since most of these applications are now running on low-power mobile devices, and frequent communi- cation of data to and from cloud via wireless medium is inefficient, optimization of an AR pipeline to maximize the compute and en- ergy efficiency, while providing adequate QoS, at an edge device is an architectural challenge. Furthermore, existing AR headsets are typically equipped with multiple sensors for head orientation, eye tracking, motion detection, etc., to provide an interactive and life- like experience. These sensor inputs play a major role in deciding which portions of the 3D voxels need to be rendered for the user to view.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "Background \nPoint Cloud in Real Life:  Point Cloud (PC) is a set of points which represent objects or shapes in a 3D space where each point/voxel (3D equivalent of a 2D pixel) contains its 3D location (x, y, z coordinates), as well as some attributes (e.g., colors, normal, etc.). Capturing PC representation of the real world typically requires millions of voxels, far more than the amount of pixels required for 2D images. While PCs containing only the 3D geometry data are commonly used in LiDAR-based 3D imaging for autonomous vehicles or robotics path planning, the lack of attributes nullify their usage for visual media consumption.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "Predicting future energy intake is challenging, so each sensor employs an estimator   ÀÜ E i ( t  + 1)  to anticipate its upcoming energy resources. Incorporating uncertainty-aware models or robust estimation techniques is beyond the scope of this paper. Prior to deployment, a global inference model  f Œ∏  is trained offline on representative data and distributed to each sensor.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Compression Pipeline:  \nTMC13 \n0 \n200 \n400 \n600 \n800 \nConst. Ser. Entropy Other Geo.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 26,
    "augmented": false
  },
  {
    "text": "Yoonsung Kim, Changhun Oh, Jinwoo Hwang, Wonung Kim, Seongryong Oh, Yubin Lee, Hardik Sharma, Amir Yazdanbakhsh, and Jongse Park. Understanding the performance characteristics of computational storage drives: A case study with smartssd. Electronics , 10(21):2617, 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "IEEE Computer Society. [194] Zexuan Zhong, Mengzhou Xia, Danqi Chen, and Mike Lewis. Lory: Fully Differentiable Mixture-of- Experts for Autoregressive Language Model Pre-training.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Note that changing the models or/and framework would lead to minor deviations. While providing latency and top-1% ac- curacy of the pretrained models is an ofÔ¨Çine step in  Cocktail , we can calculate these values through one-time proÔ¨Åling and use them in the framework. All decisions related to VM au- toscaling, bin-packing and load-prediction are reliant on the centralized mongodb database, which can become a potential bottleneck in terms of scalability and consistency.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Moreover, the L1 hit rate for both these steps is as high as 99%. Thus, GPU seems to be one of the reasonable hardware candidates for mapping the hologram application. Second, the four major reasons for instruction stalls in the  Forward-Propagation  step are: Data Request (21%), Execu- tion Dependency (19%), Instruction Fetch (15%), and Sync (10%), whereas in the  Backward-Propagation  step they are Read-only Loads (42%), Sync (24%), Data Request (16%), and Execution Dependency (6%).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "Moreover, we believe that advancing the capabilities of smaller models in intermittent environments is crucial for widespread adoption of sustainable, battery-free devices in various domains, including environmental monitoring, industrial IoT, and healthcare. By addressing the challenges of intermittent computing, our work contributes to the broader goal of enabling pervasive, sustainable intelligence at the edge. NExUME is especially advantageous in intermittent environments, and its utility extends to ultra- low-power or energy scavenging systems.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Therefore, as shown in Fig. 7 that, the results of the left-eye are generated by the Original Compute Engine (GPU in this case) and fed into the  AE  block with the Ô¨Årst row for the right-eye, to store the pattern into the Delta Buffer. After that, the computation for the right-eye can be easily reconstructed by the left- eye‚Äôs compute results and the pattern, which only consumes 13%  energy compared to the  Baseline .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Impact on Quality : The proposed  AE  scheme captures the pattern between both the eyes with only the  1 st  row of the frame, and then uses the same pattern to  bypass  the projection computation for the remaining rows of the right eye. Note that, as shown in Fig. 6b and 6c, the  i th-row‚Äôs pattern may not be exactly the same as the  j th-row.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "In addition, we sample SLO violations for every 10s interval and reactively spawn additional instances to every pool based on aggregate resource utilization of all instances. This captures SLO violations due to mis-predictions. Prediction Policy : To effectively capture the \nModel RMSE MWA 77.5 EWMA 88.25 Linear R. 87.5 Logsitic R. 78.34 Simple FF.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "2020. [22]  Marc Brooker, Andreea Florescu, Diana-Maria Popa, Rolf Neugebauer, Alexandru Agache, Alexandra Iordache, Anthony Liguori, and Phil Piwonka. Journal of Artificial Intelligence Research  22 (2004), 385‚Äì421.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Year 3 \nTHRUST-I:Algorithmic  \nSupport for Ensemble  \nof Experts \n2.1 Data Locality and Parallelism-Aware LLM Training \nTHRUST 2: System  \nSupport for Expert  \nScheduling and Data  \nMovements \n3.1 Expert/Hardware Co-Characterization \nTHRUST 3:  Chiplet- \nbased Adaptive and  \nReconfigurable  \nHardware Platform \nCurriculum Development, Undergraduate Research Involvement, Training in Galaxy Community, Industry Outreach, Result  \nDissemination  \nBPC, K-12, Undergraduate Honors, Science-U \n1.1 EoE Design Space Exploration \n1.2 Constructing Morphology of EoE \n2.2 Router Retraining \n2.3 Using Hot and Cold Experts: Caching and Prefetching \n3.2 Chiplet-Based Modular Hardware Platform \n1.3 Continual Adaptation of LLM Experts \n3.3 Handling Unforeseen Cases using Reconfiguration \nTHRUST 4:  \nEvaluation  \nand Fine  \nTuning \n4.1 Evaluation Infrastructure: Experiments + Simulation + Analytical Modeling \n1.4 Algorithmic Choices Informed by System & Hardware Constraints \nYear 2 \nYear 1 \n2.4 KV Cache Management \n2.5 Runtime Support \n2.6 Fault Tolerance \n4.2 Methodology \n3.4 Going beyond with Hardware Software Co-optimization \nFigure 8 :  Project timeline that shows both research and educational/outreach efforts. Collaboration Logistic \nThe PIs will meet regularly to assess the overall progress of the project. They will not only evaluate whether the individual and intermediate research goals have been achieved or not, but  will also discuss the progress towards achieving the educational and outreach/BPC goals of the project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 365,
    "augmented": false
  },
  {
    "text": "To solve this issue, we propose to re-construct the expert graph automatically to balance the workload. We cluster the experts according to their domain similarity so that each parent node is assigned two most similar leaves. We first form a binary tree over all selected domains where the experts are the leaf nodes at the finest granularity.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "https://www.nvidia.com/en-us/data-center/nvlink/ \", 2024. [120] Octopai. Octopai: Automated data lineage, data catalog and discovery.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "[53]  Dhiraj Neupane and Jongwon Seok. 2020. arXiv preprint arXiv:1907.04018  (2019).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "643‚Äì656. In  Proceedings of the International Symposium on Microarchitecture (MICRO) . ASV: Accelerated Stereo Vision System.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Heiner Lasi, Peter Fettke, Hans-Georg Kemper, Thomas Feld, and Michael Hoffmann. ACM Transactions on Embedded Computing Systems (TECS) , 21(5):1‚Äì26, 2022. More is less: Model augmentation for intermittent deep inference.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Therefore, the better option, from a communication cost perspective, is to execute the inferences on the individual sensors and use an ensemble learning method (like majority voting) to aggregate these results for the Ô¨Ånal classiÔ¨Åcation. The conventional \nmethod, where the sensors collect the data and send it to the cloud or any other host device (such as connected mobile phones) is not an effective option as communicating large data demands more power, which is both highly variable and scarce in EH systems. 1% \n0 20 40 60 80 100 All Succeed Atleast one succeed Failed \n9% 90% \n(a)  Inference completion breakdown when three EH sensors are working together to Ô¨Ånish the incoming inferences.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "Also, these policies can be changed over time by Amazon, and they can also be dif- ferent for other cloud providers [ 8 ]. Therefore, the resource manager should be able to leverage this information to make optimal serverless function configuration decisions. 4 Evaluation and Initial Results \nThis section introduces how an ML-serving framework can capitalize on the design choices discussed in Section  3 .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "2:  Accuracy of the individual DNNs and with a majority voting ensemble for different activities. To design these DNNs, we leverage the work in [11], [14] and further apply state of the art optimizations given in [3], [15] to make the DNN more suitable for energy-scarce applications. Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "This encourages us to further study whether this distance vector changes with head orientation or not, and also whether it is invariant for any particular frame ‚Äì if yes, then how? To investigate these questions, we examine how the distance vector varies within a same frame, with two different head orientations, shown in Fig. 6b and Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "494‚Äì506. 241‚Äì253. [108] S. Zhao, H. Zhang, C. S. Mishra, S. Bhuyan, Z. Ying, M. T. Kandemir, \nA. Sivasubramaniam, and C. Das, ‚ÄúHoloar: On-the-Ô¨Çy optimization of \n3d holographic processing for augmented reality,‚Äù in  MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture , 2021, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "[23]  Daniel K Nikolov, Sifan Ye, Sydney Dlhopolsky, Zhen Bai, Yuhao Zhu, and Jannick P Rolland. Imaging and Applied Optics 2018 (3D, AO, AIO, COSI, DH, IS, LACSEA, LS&C, MATH, pcAOP) , DTu5F.6. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Otherwise, if the expression  Condition trans \nis not satisÔ¨Åed, with power prediction, we can still speculatively attempt to perform a smooth transition. There are two strategies to achieve this. ‚Ä¢  We can search for an intermediate power level, where we Ô¨Årst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level ‚Äì this strategy is called  Multi-step Transition .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Each QuantaTask ensures that execution proceeds without partial computation, which would otherwise lead to overhead from checkpointing and potential data corruption. The main properties of QuantaTasks are atomicity and respect for energy constraints. Figure 1 illustrates QuantaTask execution with a simple example.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "The reason behind this is that, as shown earlier in Tab. 2, the  bike  video usually has only one object per frame (1 . 1 on average), and also the ranges/sizes of the bikes are larger, compared to others.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "References \n[1]  Omid Alipourfard, Hongqiang Harry Liu, Jianshu Chen, Shivaram Venkataraman, Minlan Yu, and Ming Zhang. 2017. CherryPick: Adap- tively Unearthing the Best Cloud Configurations for Big Data Analytics.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "[197] Yanqi Zhou, Tao Lei, Hanxiao Liu, Nan Du, Yanping Huang, Vincent Zhao, Andrew Dai, Zhifeng Chen, Quoc Le, and James Laudon. pages 42531‚Äì42542. PMLR, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "These trade-offs are not very straightforward due to the following  challenges : First,  among all of the inputs to the AR headset (shown later in Fig. 1b), which one(s) are critical for holographic processing? Second,  which features of these inputs are salient and need more fine-grained computation, and which of them could be approximated without impacting the QoS?",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "The hybrid storage system is capable of taking the computed \n2 Given a powerful enough computer like quantum computers, RSA encrypted data can be decrypted, and therefore National Institute of Standards and Technology (NIST) called for proposals to develop post quantum cryptography algorithms (National Institute of Standards and Technology (NIST), 2024), and defined a standard for the same. One of the successful submissions ‚Äì which was later defined as a standard ‚Äì uses lattice-based encryption algorithm (Micciancio & Regev, 2009) and will be the focus of our work. 3 \nframe features and the motion vectors from the compute hardware to perform a novel layered neural compression.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "V). For example, PTU [28] uses a hardware-accelerated rendering unit (HAR) to mitigate energy- overheads due to on-device rendering. In this work, we pro- pose two optimizations, i.e.,  EA  and  AE , which can be coupled with the existing  360 ¬∞ video compute engine (without any hardware modiÔ¨Åcations), and are even more energy efÔ¨Åcient than the existing state-of-the-art  PTU  (discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "1‚Äì26, 2022. VLDB Endow. [42] D. Kang, J. Emmons, F. Abuzaid, P. Bailis, and M. Zaharia, ‚ÄúNoscope: \nOptimizing deep cnn-based queries over video streams at scale.‚Äù  Proc.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "[33]  Eric Jonas, Johann Schleier-Smith, Vikram Sreekanti, Chia-Che Tsai, Anurag Khandelwal, Qifan Pu, Vaishaal Shankar, Joao Carreira, Karl Krauth, Neeraja Yadwadkar, et al . 2019. Cloud programming sim- plified: A berkeley view on serverless computing.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Different from these two prior works, Potluck [12] caches the feature vectors (FVs) and correspond- ing inference results for key frames, and reuse the results for other frames with similar FVs, with the costs of FV extraction (e.g., down-sampling [16]) penalty and potential accuracy and/or performance drop due to sampling failures. However, with limited energy budget on typical edge devices, the accuracy is far from sufÔ¨Åcient for vision applications (quantitative results in Sec. On the other hand, MCDNN [7] proposes a scheduler to dynamically choose the best suitable model from several candidate models (e.g., standard model, medium-pruned variant, and heavily- pruned variant), and pushes the accuracy as high as possible within the energy budget.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 182,
    "augmented": true
  },
  {
    "text": "We intend to co-locate the expert and routers physically in the system during both training and inference time to leverage this affinity and reduce expensive data movement cost. Task-2.3: Using Hot and Cold Experts: Caching and Prefetching Clearly, the optimized management of the system memory/storage hierarchy in LLM inference is of crit- ical importance [131, 146]. Towards this, we plan to experiment with various latency reducing/hiding techniques such as caching and prefetching by intelligently using experts based on their frequency of in- vocation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "498 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. Motivated by this, we next explore the entire design space for the AR holographic applications running on edge GPUs, and try to ex- ploit potential opportunities for reducing computations to improve both performance and energy efficiency in hologram processing. 4 PROPOSED STRATEGIES \nAs discussed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "In A. Oh, T. Nau- mann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,  Advances in Neural Information Processing Systems , volume 36, pages 34661‚Äì34710. [190] Shulin Zhao, Prasanna Venkatesh Rengasamy, Haibo Zhang, Sandeepa Bhuyan, Nachiappan Chi- dambaram Nachiappan, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita Das. Curran Associates, Inc., 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "Accessed: 2024-10-20. [156] Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R. Das. Kube-knots: Resource harvesting through dynamic container orchestration in gpu- based datacenters.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "IV-B) as plugable modules to the existing compute engines (e.g., CPU, GPU, etc. C. Design and Implementation \nWe designed our both schemes (frame-level reuse in Sec. IV-A and region-level reuse in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "As shown in Fig. 9 , a single teacher, even with the augmented heuristics, typically fails to select the right exemplar set. The exemplar set signiÔ¨Åcantly impacts the accuracy in two ways: 1. missing valid exemplars will result in the student model missing out in learning vital information, increasing its drift, and 2. a wrong annotation by the teacher can also result in the student learning wrong labels, resulting in increased mis-predictions.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "4, pp. 37‚Äì47, 2022. [30] S. Han, H. Mao, and W. J. Dally, ‚ÄúDeep compression: Compressing \ndeep neural networks with pruning, trained quantization and huffman coding,‚Äù  arXiv preprint arXiv:1510.00149 , 2015.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "This process involves ‚Äúrepresentation learning‚Äù (Rebuffi et al., 2017), where data is transformed into ‚Äúfeature vectors‚Äù using deep neural networks, followed by unsupervised learning techniques like k-means clustering. In urban mobility, high-volume data streams from multiple sources, such as high-resolution traffic cameras, are first compressed then analyzed for exemplar selection. This task dynamically adapts to changing traffic patterns and environmental conditions.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Peeking Behind the Curtains of Serverless Plat- forms. In  ATC . [9]  Neeraja J. Yadwadkar, Francisco Romero, Qian Li, and Christos Kozyrakis.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "9: Impact of multiple teachers on exemplar selection. X- axis shows #exemplars/100 inferred frames over a 2hr window. Having an ensemble provides robust exemplar selection and improves accuracy over a single teacher.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Hottiles: Ac- celerating spmm with heterogeneous accelerator architectures. In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pages 1012‚Äì1028. IEEE, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Weiqiang Liu, Sailong Fan, Ayesha Khalid, Ciara Rafferty, and M√°ire O‚ÄôNeill. Springer, 2023. Optimized schoolbook polynomial multiplication for compact lattice-based cryptography on fpga.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "[35]  Takashi Nishitsuji, Yota Yamamoto, Takashige Sugie, Takanori Akamatsu, Ryuji Hirayama, Hirotaka Nakayama, Takashi Kakue, Tomoyoshi Shimobaba, and Tomoyoshi Ito. \"https://www.nasa.gov/ nasa-at-home-virtual-tours-and-augmented-reality\". NASA at Home ‚Äì Virtual Tours and Apps.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "IEEE, 2008. [153] Xulong Tang, Ashutosh Pattnaik, Onur Kayiran, Adwait Jog, Mahmut Taylan Kandemir, and Chita Das. Quantifying data locality in dynamic parallelism in gpus.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "6b and Fig. To investigate these questions, we examine how the distance vector varies within a same frame, with two different head orientations, shown in Fig. This encourages us to further study whether this distance vector changes with head orientation or not, and also whether it is invariant for any particular frame ‚Äì if yes, then how?",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "1‚Äì13. [51]  C. Moreno, Y. Chen, and M. Li, ‚ÄúA dynamic compression technique for streaming kinect-based point cloud data,‚Äù in 2017 International Conference on Computing, Networking and Communications (ICNC) . Military Technical College, 2018, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Need for Specialized Hardware:  One of the major chal- lenges in deploying learning tasks using EH-WSNs is to find the proper hardware platform. Current devices adapt in one of three ways:  1) Send all the sensor data to a connected host device, or cloud, to offload the compute and act only as a sens- ing and display device; 2) Process data on the device itself, potentially dropping or delaying tasks due to energy short- falls; 3) A mix of the two models, where some computations do happen on the device while others are offloaded to balance compute, energy, and communication resources ; and typically, the latter is preferred, but it is non-trivial to find the optimal balance between what is to be done on the edge, what to be offloaded [20, 31, 65, 69], and  how to efficiently offload . As a result, it is difficult to reliably run these complex tasks standalone on the edge device.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 210,
    "augmented": true
  },
  {
    "text": "CCS Concepts ‚Ä¢  Computer systems organization  ‚Üí Cloud Comput- ing ;  Resource-Management ; Scheduling. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Autoscaling the instances equally for every model based on predicted load, would inherently lead to over-provisioned instances for under-used models. Importance Sampling:  An important concern in autoscaling is that the model selection policy dynamically determines the models in the ensemble for a given request constraints. All these parameters are tunable based on the system needs.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Hierarchy \nL1 $ \n2.4 KV Cache  Management \nCompression \nHardware-aware policies \nTailored Token  Eviction \nEnsuring Coherence \nThrust 4:  \nEvaluation &  \nFine Tuning \n2.5 Runtime  \nSupport \nSLO  Guarantee \nAccuracy \n2.6 Fault Tolerant  \nExpert Training \nIsolated  Training Redundancy \nCheckpoint /Recovery \nAlgorithmic Characteristics \nDynamic Re-routing \nCross-Layer Evaluation \n3.1 Expert/Hardware  \nCo-Characterization \nExperts Hardware \nProfile  Expert Execution Attribute Database \n3.2 Chiplet-based Modular  \nHardware Platform \n3.3 Reconfiguration 3.4 Hardware-Software  \nCo-Optimization \n4.1 Evaluation Infrastructure 4.2 Methodology \nExpert,  EoE Chiplet,  Chip Chiplet, Chip Reconfigure Chiplet,  Network \nMonitor & Control \nExposed Hardware Knobs \nPath Frequency \nAccelerator Availabililty \nExperiments on  Testbeds \nAnalytical Model \nSimulation \nTraining  Dataset \nMetrics of  Interest \n‚Ä¢ Latency ‚Ä¢ Power ‚Ä¢ Accuracy ‚Ä¢ Cost \nMemory  Constraints \nGPU \nCPU \nAccel \nAccel \nReconfig \nPlug-n-Play  \nChiplets \nExpert-to-Chiplet  \nMapping Homogeneous and  Heterogeneous Chips \nCustom  Interconnection  \nNetwork \nFigure 2 :  Overview of the proposed project. The included numbers indicate task IDs. See our timeline (Figure 8) for time-span of the individual tasks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 308,
    "augmented": false
  },
  {
    "text": "https://www.nvidia.com/en-us/data-center/nvlink/ \", 2024. [119] Nvidia. Nvidia nvlink. \"",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "It is clear that we  can neither  use the commercial GPUs  nor rely on the standard software and algorithmic approach for intermittent training purpose as they  cannot  Ô¨Ånish the compute given the intermittent power budget. of the scheduled training without any intermittency support. 0 0.2 0.4 0.6 0.8 \n1 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nA6000 w/DVFS RTX3090 w/DVFS Non-intermittent Custom HW w/Ekya \nOur Custom HW \nCompleted/Scheduled \nC/S Win-1 C/S Win-2 C/S Win-3 C/S Win-4 C/S Win-5 C/S mean \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 197,
    "augmented": true
  },
  {
    "text": "DynFit introduces key mechanisms to dynamically adjust computational complexity based on energy availability, thereby enabling energy-efficient execution of DNN models in constrained environments. The primary goal of DynFit is to \n3 \nadapt the DNN‚Äôs training process to operate efficiently under unpredictable energy budgets while maintaining acceptable accuracy and adhering to predefined service level objectives (SLOs). These mechanisms include: (i)  Dynamic Dropout , which adjusts the dropout rates based on available energy to reduce computational load; (ii)  Dynamic Quantization , which modifies quantization levels in response to energy constraints to save energy; and (iii)  QuantaTask  design, which defines atomic computational units that can be executed without interruption given the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 170,
    "augmented": true
  },
  {
    "text": "In  Combinatorial Optimization . Springer, 489‚Äì507. [37]  J√∂rn Kuhlenkamp, Sebastian Werner, and Stefan Tai.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "To cater towards the sporadic \n2 \npower income and failures, an existing body of works explores algorithms, orchestration, compiler support, and hardware development (Yang et al., 2017, 2018; Mendis et al., 2021; Maeng & Lucia, 2018; Gobieski et al., 2018; Qiu et al., 2020; Islam et al., 2022; Mishra et al., 2024, 2021; Ma et al., 2016, 2017; Liu et al., 2015). Most of these works rely on software checkpointing (static and dynamic (Maeng & Lucia, 2018), refer ¬ßAppendix C) to save and restore, while some of the prior works developed nonvolatile hardware (Ma et al., 2016, 2017) which inherently takes care of the checkpointing. A typical EH setup consists of 5 components, namely, energy capture (solar panel, thermocouple, etc), power conditioning, voltage regulation (buck or boost converter), energy storage (super capacitor) and compute unit (refer ¬ßAppendix B for details about each of them).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 270,
    "augmented": true
  },
  {
    "text": "Considering the global control always enqueues any idle tile with work, whenever the tile has no work left, it steals a kernel from the most \n899 \nAuthorized licensed use limited to: Penn State University. When any of the active tiles are marked ready by the scheduler, the tile employees a state machine to decide where to get work from. Each time the tile Ô¨Ånishes some work, if its remaining work queue (the local work queue size) is less than the average of all other active tiles, it seeks a new kernel to work on.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Furthermore, the proposed hardware is reconÔ¨Ågurable at a Ô¨Åne grain, to be able to dynamically activate different scaled computations, which can Ô¨Åt to the changing features of the underlying power resources. To the best of our knowledge, this is the Ô¨Årst work that focuses on low power and reconÔ¨Ågurable RCA design from both the hardware and software angles targeting energy harvesting systems. This paper makes the following key  contributions : ‚Ä¢  Low power, reconÔ¨Ågurable hardware design:  We pro- pose a novel architecture that implements a lightweight and low power RCA to adapt to time-varying power resources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "Our proposed frame-level reuse shows  ‚âà 53%  of the frames to be redundant and hence skips the inference, leading to only less than  1%  accuracy loss. Combining the frame-level reuse with the partial inference gives  2 . 2 √ó  performance improvement on average, and up to  80%  energy savings, while losing less than  2%  accuracy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "The project will be managed by the three PIs from Penn State. The specific responsibilities of the PIs and their complementary expertise are explained below: Chitaranjan Das (PI):  Das is the PI of the project and will be responsible for the overall coordination and progress as planned in the project schedule. Collaboration Plan \nProject Team \nThe proposed project spans design and analysis of LLM and expert models, characterization and evaluation of such models, development of compiler and runtime system support for efficient LLM/expert training and inference as well as chiplet selection for LLM/expert execution.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "com / research / introducing-apple-foundation-models \", 2024. [17] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the dan- gers of stochastic parrots: Can language models be too big?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "We identify  online-pruning opportunities for inferences, which can also be exploited at  frame-level ,  region-level , and  pixel-level. SpeciÔ¨Åcally, our approach combines inter-frame similarities, motion vectors (MVs), and the concept of regions of interest, to make online video analytics/inferences inherently faster, along with the runtime support for improving the video streaming pipeline. Our main  contributions  in this work include the following: ‚Ä¢  First, we study the similarities between successive frames in videos at various levels.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "1941‚Äì1953, 2017. [14] L. Gong, C. Wang, X. Li, H. Chen, and X. Zhou, ‚ÄúA Power-EfÔ¨Åcient and High Performance FPGA Accelerator for Convolutional Neural Net- works: Work-in-Progress,‚Äù in  Proceedings of the Twelfth IEEE/ACM/I- FIP International Conference on Hardware/Software Codesign and System Synthesis Companion , 2017. [15] J. Wang, J. Lin, and Z. Wang, ‚ÄúEfÔ¨Åcient Hardware Architectures for Deep Convolutional Neural Network,‚Äù  IEEE Transactions on Circuits and Systems I: Regular Papers , pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "Wood. IEEE, 2020. [20] Nathan Binkert, Bradford Beckmann, Gabriel Black, Steven K. Reinhardt, Ali Saidi, Arkaprava Basu, Joel Hestness, Derek R. Hower, Tushar Krishna, Somayeh Sardashti, Rathijit Sen, Korey Sewell, Muhammad Shoaib, Nilay Vaish, Mark D. Hill, and David A.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Background and Related Work \nVery basic, just the outline, compact and make robust \n2.1. concludes with a discussion of limitations and future work. 2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Qlora: Efficient finetuning of quantized llms. Advances in Neural Information Processing Systems , 36, 2024. [35] Shichen Dong, Wen Cheng, Jiayu Qin, and Wei Wang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Random sampling of the decision trees also augments the model by minimizing the data induced bias of each of the models. We extended this design idea by constructing a random forest model as a combination of multiple decision trees from different learners (different deployments). To preserve the data privacy of the participat- ing deployments, the cloud learns by ensembling randomly sampled decision trees from each of the deployments, instead of learning a random forest from the data shared by each of them.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "299 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "FI+SI:  We evaluate our FI+SI scheme that skips the inference by utilizing MVs, as discussed in Sec. IV-A. Design conÔ¨Ågurations \nBaseline:  We evaluate the baseline video object detection on an edge CPU 1 , where every frame is fully inferenced.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Spatial Locality in Attributes:  Towards exploring the attribute similarity within one frame, we partition a frame (whose points are Ô¨Årst sorted in Morton-code order) from the 8iVFB dataset [ 18 ] into  10 ,  10 2 ,  10 4   and  10 5   macro blocks , plot the CDF of the range for attribute delta ( Max red  ‚àí Min red ) within one segment/macro block in Fig. 3  a  , and observe that: ‚Ä¢  Overall, with more segments/macro blocks whose size is smaller (compared to a frame), more similarity exists in a block (delta is small). SpeciÔ¨Åcally, compared to the black line (only 10 blocks), the attribute in yellow line ( 10 4 \nblocks, each of them is  1000 √ó  smaller) exhibits a better similarity (i.e., left-shift towards the y-axis).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 203,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Our Intra-Inter-V1 (Quality-oriented):  This design favors the quality over compression efÔ¨Åciency, and it only takes  124 ms  ( 41 ms  for geometry compression, and  83 ms for attribute compression), contributing to around  34 √ó speedup w.r.t. Further, all the points are processed in parallel; 3). we discard the entropy encoding for further speedup.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "However, the tail latencies of  DProb  and  SProb  sometimes exceeds the SLO, since they don‚Äôt use  Commonality  and  Connectivity . It is observed that Xanadu  also violates the SLO for the Twitter trace, owing to the reactive scale-outs resulting from MLP mispredictions. 6.2.1 Sensitivity Study : This subsection compares  Kraken against  Oracle , which is an ideal policy that is assumed to be able to predict future load and all path probabilities with 100% accuracy and also has request batching.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "Here, we vary the tile size (an N √ó N tile is a N √ó N pixel block) from 4 √ó 4 to the entire frame (1080 √ó 1920) on the x-axis, and the y-axis gives the fraction of ‚Äúidentical tiles‚Äù (when compared pixel-by- pixel) in  two successive frames . To explore these opportunities, Fig. 2a plots the ‚Äúpixel-level similarity‚Äù between two successive frames in a video.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "7 √ó  speedup, which collectively trans- late to 73% total energy savings compared to the baseline setup (Sec. Our exper- imental results reveal that,  HoloAR  provides 29% reduction in power consumption and 2 . 5.3).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "USENIX Association. [28]  Deepstudio. Deep Learning Dtudio, February 2020. https://docs.deepcognition.ai/ .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "We demonstrate the real-world applicability of our approach for two smart manufacturing deployments, and analyzed the accuracy-latency trade offs and their sensitivity to user-supplied thresholds. We believe that our solution can be easily deployed and be beneficial for random forest based distributed sensing-computing platforms. This work provides a practical solution to achieve latency- accuracy balanced partitions for random forest based infer- ence tasks.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Driven by these observations, we next want to study the details of hologram with the goal of addressing two critical questions:  What are the problems in the current state-of-the-art hologram software and hardware? , and  How can we leverage ‚Äúapproximation opportunities‚Äù (based on the two observations above) to speed up hologram processing and save energy, while still maintaining a high QoS? 3 HOLOGRAPHIC PROCESSING STUDY \nTo leverage the opportunities in the holographic processing from a RGB-D (i.e., RGB and depth) image, we need to first understand the detailed execution of the entire hologram processing from both the algorithm and hardware perspectives.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": ":  The proposed inter- frame attribute compression further improves the compres- sion efÔ¨Åciency by skipping the redundant storage for the same/similar segments matched across frames, with extra latency overhead (but still much better than the state-of-the- art ‚Äì  139 ms  vs  5 . In this example, for compressing the P-Frame, one pointer (for  S 1  which contains  P 0  and  P 1 ) and only one post-intra-encoded compressed delta (for  P 2 ) are required for storage, instead of storing all three. 9 s ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "Moreover, we also implement the memoization option so that it does not have to repeat infer- ences if it encounters similar data, thereby saving substantial energy as well as delivering results with extremely low la- tency. However, even with all these optimizations, due to the fickle nature of EH,  Seeker  cannot finish all the inferences at the edge and must communicate with a host device. To minimize the data communication overhead between the sensor-node and the host device,  Seeker  utilizes coresets to build representative, yet compressed, forms of the data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "[78]  Jasper A Vrugt and Bruce A Robinson. In  Graphicon , pages 987‚Äì997, 2005. Modest adaboost- teaching adaboost to generalize better.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "For active RCAs, one option is to use loop tiling to decompose computations, and the other is to parallelize computations. A. Computation decomposition and parallelism \nIf the harvested power  P   budget   is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress. The parallelism in this context is of two types:  intra layer parallelism via layer duplication  and  inter layer parallelism via layer pipelining .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "diurnal, flash-crowds etc.) Therefore, resource procurement and management deci- sions need to be adjusted depending on the resource utiliza- tion/load and arrival rates. Public cloud providers leave these major decisions to be ≈Çmanually handled\" by users, which is very time consuming and strenuous.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "experts are equally relevant, we will prioritize those with available accelerators to improve performance. ;  Expert‚ÄìComposition Function:  the tendency of some experts to use the same composition function frequently across different requests; Expert‚ÄìAccelerator:  the tendency of some experts to utilize the same chiplet or different chiplets in the same chip. Definitions of different affinities:  Expert‚ÄìExpert:  the tendency of certain experts to be used more frequently together to serve a request;  Expert‚ÄìData:  the tendency of similar experts to use a common subset of training data;  Expert‚ÄìRouter:  the tendency of given experts and routers to be used together frequently to serve different requests and to share a subset of training data.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "We use such a viewing-window based ‚Äúsub-hologram‚Äù technique which has already been proposed in prior works (such as Sub-Hologram [ 52 ]) as the  Baseline  design. ‚Ä¢  Apart from the viewing window, the dense or sparse hologram computing is also RoF-dependent, which is the main idea be- hind foveated rendering [ 25 ,  47 ,  62 ], as discussed in Sec. 1 and Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Distance \nCount P-Block \nOther \nFigure 9: Energy consumption breakdown for inter-frame attribute compression for Loot video [ 54 ]. consuming one among the proposed geometry, intra- and inter- frame attribute compression techniques). 51% \n32% \n17% \n2-Norm Attri.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "2018. Fast Generation of Mesh Based CGH in Head-Mounted Displays using Foveated Rendering Technique, In Imaging and Applied Optics 2018 (3D, AO, AIO, COSI, DH, IS, LACSEA, LS&C, MATH, pcAOP). Imaging and Applied Optics 2018 (3D, AO, AIO, COSI, DH, IS, LACSEA, LS&C, MATH, pcAOP) , DTu5F.6.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "[50] Z. Li and D. Hoiem, ‚ÄúLearning without forgetting,‚Äù  IEEE transactions \non pattern analysis and machine intelligence , vol. 40, no. 12, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "500 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 4.4 Intra-Holo Computation Optimization \nAlgorithm 3:  Intra-Holo proposal algorithm. Input : Poses : pose sensors Input : Objs : set of virtual objects Output: Holo–¥rams : Generated holograms \n1  procedure  Intra _ Holo ( Poses ,  Objs ) // main \n2 Cam2ObjDists =  PoseEstimation ( Poses ) \n3 for  obj  in  Objs  do // approx.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "Several works have explored adaptive participation strate- gies that consider energy harvesting rates, energy consump- tion patterns, and application-specific requirements ( ? Some methods pro- pose selecting a subset of sensors based on energy levels or predefined schedules ( ? ), but these can lead to suboptimal performance by not considering the sensors‚Äô data quality or potential future contributions.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "This experiment to mimics a consolidated edge server catering to many video streams. Compute server indicates a software only classical storage solution without CSDs. Figure 5: Performance of  Salient Store  on larger compute and storage nodes.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Vision Proximity:  It is to be emphasized that, even when the head orientation input for two computations are the same, the two eye coordinates can be different. Because of this, in current designs, the projection transformation is invoked  twice as it needs to generate two different transformation matrices for the left eye and the right eye. Since two identical head orientations lead to the same projection matrices, one opportunity to reduce computation is to  memoize  a set of head orientations as well as their corresponding compute results.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "(Accessed on 11/20/2023). https://www.xilinx.com/products/ design-tools/vitis/xrt.html . Guilherme H. Apostolo, Pablo Bauszat, Vinod Nigade, Henri E. Bal, and Lin Wang.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a \n3-bit resolution, which is a high performance but also a high power consuming design. ‚Ä¢  The architecture-centric works [ 3 ], [ 4 ], [ 5 ] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption. Although the above designs provide different approaches to achieve high throughput, high energy efÔ¨Åciency and low power, they cannot be directly applied or combined to be applied in the energy harvested edge devices due to the following reasons.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "in a point-by-point fashion. ‚Ä¢  Octree Construction:  With the input geometry data, the octree construction algorithm is invoked to add the points and update the tree (e.g., the maximum depth required for inclusion of a point, occupancy information for nodes, etc.) This point-by-point ‚Äúupdate‚Äù makes this stage difÔ¨Åcult to parallelize.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "[23] J. Huang, Z. Chen, D. Ceylan, and H. Jin, ‚Äú6-DOF VR Videos with a Single 360-camera,‚Äù  2017 IEEE Virtual Reality (VR) , pp. 37‚Äì44, 2017. [24] A. Inc., ‚ÄúRendering Omni-directional Stereo Content.‚Äù ‚Äùhttps:// developers.google.com/vr/jump/rendering-ods-content.pdf‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "In certain energy-critical scenarios, even EH-WSNs applying state-of-the-art techniques fail to consistently meet SLOs, sometimes skipping entire inferences to deliver results on time. Funda- mentally, while current DNNs can be trained or fine-tuned to fit within a given resource budget‚Äîbe it compute, memory, or energy‚Äîthey are  not  trained to expect a variable or intermittent resource income. Although intermittency-aware NAS (Mendis et al., 2021), could alleviate certain problems, they often assume fixed resource constraints and do not account for real-time energy fluctuations.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "VI. E XPERIMENTAL  R ESULTS \nIn this section, we compare our proposed intra-frame and inter-frame designs against two different PCC techniques, by evaluating four metrics critical for the PC-based applications ‚Äì execution latency, energy consumption, video quality, and compression ratio. VI-E .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Training and Aggregation Framework \nHaving established the equilibrium participation strategies and the underlying reward-based utility functions, we now consider the training process that fine-tunes the global in- ference model  Œ∏  ‚àà R d   within this EH, multi-sensor envi- ronment. These guidelines help in balancing immediate utility gains with long-term energy sustainability, ensuring that the game- theoretic model drives desirable participation behaviors. 5.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Furthermore, these accelerators have been designed to operate under constantly available power. This has lead to a global concern of the energy and consequently carbon-footprint of the DNN training [ 21 ], [ 57 ], [ 67 ], [ 89 ]. However, these devices take a ‚Äúthroughput-Ô¨Årst‚Äù approach, to minimize the time consumption and seldom optimize power consumption Ô¨Årst.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "We also assume that energy resources, accuracy gains, and reward/penalty parameters are finite and bounded, and that sensors have consistent estimation mechanisms for  ‚àÜ A i ( t ) and   ÀÜ E i ( t  + 1) . Potential Function Construction \nTo prove convergence, we define a potential function that reflects the collective utility of the sensor network: \nŒ¶( a ( t )) = \nN X \ni =1 U i ( a i ( t ) ,  a ‚àí i ( t )) . Since  U i ( t ) =  R i ( t )  ‚àí C i ( t ) , we have: \nŒ¶( a ( t )) = \nN X \ni =1 [ R i ( t )  ‚àí C i ( t )] .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 203,
    "augmented": false
  },
  {
    "text": "Assuming each request to a function within the appli- cation spawns one container for that function, the number of containers to be provisioned in advance for functions at depth  ùëë is given by: \nùëÅùê∂ ùëë ùë° =  ‚åà PL  ùë° ¬∑ ( ùëá ùëë ¬∑  ùëÉ 0 )‚åâ \nHere,  ùëÅùê∂ ùëë ùë° is a column vector of ùëõ elements, each correspond- ing to the number of elements required to be provisioned for functions at a depth,  ùëë , from the start function. For example, if  ùëÉùêø ùë° is estimated to be 25 requests, then from Figure 5, we obtain the number of containers needed for functions at depth,  ùëë =  1, by multiplying 25 with  ùëÉ 1  (which is  ùëá 1 ¬∑ P 0 ). Provisioning these containers at a fixed time window in advance from  ùë° prevents cold starts from affecting the end-user experience.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 206,
    "augmented": true
  },
  {
    "text": "We do not observe much change in the data volume. However, due to complex interaction between multiple storage nodes, especially where some of the data needed to arrive at different nodes via network, in Fig. 6, we observe a significant change in the latency compared to a single storage node.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "In such a case, as the pixel values of the identiÔ¨Åed object have changed, Frame i + 1  cannot reuse the result (LED bulb) from Frame i  even though it should ideally be able to do so in an object detection application. Con- sider an object detection scenario where a multi-color LED bulb on a Christmas tree identiÔ¨Åed as an object of interest, glowing red in Frame i , changes to blue in Frame i + 1 . This can be illustrated with a simple use-case scenario.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Several recent efforts have been put into optimizing the 3D CNN to increase the compression ratio and/or decrease the number of parameters in the neural network model [ 27 ], [ 69 ]. However, based on the results reported in [ 40 ], even with a custom 3D-CNN accelerator, only 2.5 √ó  speedup could be achieved for 3D-CNN compared to edge GPU. Considering that NN-PCC can take thousands of seconds to compress one PC frame [ 88 ], such a huge gap between the long execution latency of NN-PCC and the \n2 Although V-PCC and NN-PCC have high compression efÔ¨Åciencies, they are compute-intensive [ 41 ], [ 88 ], and consequently, are not the best option for mobile devices and are not considered in this work.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 182,
    "augmented": true
  },
  {
    "text": "1‚Äì15. In  Proceedings of the Fifteenth European Conference on Computer Systems . SEUSS: skip redundant paths to make serverless fast.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "While previous works have de- signed energy-efÔ¨Åcient training hardware with support for variable precision training, none have adapted to variable energy income. Us. ¬¥as  optimizes the entire solution space, maximizing hardware reuse for exemplar selection and micro- proÔ¨Åling while addressing the training task.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Fig. 4 shows the latency while using the storage server and CSD for performing data writes,  normalized  to the latency of doing the same using the state of the art Alveo FPGAs. Salient Store  on CSDs perform  ‚âà 1 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "In many real-world applications, especially in IoT and edge computing, there is a critical need for smaller, energy-efficient models that can operate autonomously without reliance on batteries. These tiny, reusable devices contribute to reducing embodied carbon and represent a significant step toward sustainability. Moreover, we believe that advancing the capabilities of smaller models in intermittent environments is crucial for widespread adoption of sustainable, battery-free devices in various domains, including environmental monitoring, industrial IoT, and healthcare.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA ¬© 2021 Association for Computing Machinery.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "This indicates two memoization buffers are sufÔ¨Åcient. (b) plots among all the head orientations, how many can be memoized by these two buffers. (c) illustrates the trade-off between the precision level and reuse ratio.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "The different methods for each component are summarized in Table 1. Note that  existing works have only studied a few specific points in this vast design space , lack- ing a comprehensive exploration of this search space of expert model design and implementation. Each expert can vary in model size and architecture depending on the complexity of its domain.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "[88]  C.-H. Wu, C.-F. Hsu, T.-K. Hung, C. Griwodz, W. T. Ooi, and C.-H. Hsu, ‚ÄúQuantitative comparison of point cloud compression algorithms with pcc arena,‚Äù  IEEE Transactions on Multimedia , pp. 6, p. 855‚Äì866, 2020. [87]  We are Luminous, ‚ÄúInteritum - Sureal VR Point Cloud Game,‚Äù \n‚Äùhttps://www.youtube.com/watch?v=P5BgrdXis68‚Äù , 2016.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "Five layer scheduling schemes: (a) Naive execution @Simple architecture; (b) Naive execution @ResiRCA architecture; (c) Se- quential resilient execution @ResiRCA architecture; (d) Pipelining resilient execution @ResiRCA architecture; and (e) Hybrid resilient execution @ResiRCA architecture \nResiRCA architecture; we call this execution style  Pipelining . For ease of explanation and simulation, we only allow full pipelining in this execution, which means MAC operations of all the layers are included in each pipeline stage. Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "keeps up with the accuracy of the traditional compression system thanks to the robust layered coding algorithm. 5b,  Salient Store  has  4 . Additionally, as shown in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "Zero: Memory optimizations toward training trillion parameter models. [135] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. PMLR, 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Los alamos national laboratory and sk hynix to demonstrate first-of-a-kind ordered key-value store computational storage device. https://discover.lanl. gov/news/0728-storage-device/ .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with L2 Dynamic Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ± . Define the energy budget  E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "C \nC \nC controlling circuit \nFig. 4-bit \nOutput  Reg. Variance feature of different power sources \nIII-ADC \nBL \nWL \nSL \nÕô \nÕô \nÕô \nColumn 1 \nÕô \nCSA + \n- \nSAR \nÕô Ref \nShift&Add \nÕô \nDriver \nÕô \nRow 1 \nRow 2 \nRow m \nDriver \nDriver \nI-DAC Õô \nÕô \nÕô Õô \nII-Comp \n4-bit inputs 1-bit resolution \n1-bit weights \n4-bit outputs \nbit- serial \nInput  Reg.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "However, the computation and power de- mands of Deep Neural Network (DNN)-based inference pose significant challenges in an energy-harvesting wireless sen- sor network (EH-WSN). Moreover, these tasks often require responses from multiple physically distributed EH sensor nodes, which impose crucial system optimization challenges in addition to per-node constraints. To address these chal- lenges, we propose  Seeker , a hardware-software co-design approach for increasing on-sensor computation, reducing communication volume, and maximizing inference comple- tion, without violating the quality of service, in EH-WSNs co- ordinated by a mobile device.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "541‚Äì552, 2017. [6]  C. Xue, W. Chen, J. Liu, J. Li, W. Lin, W. Lin, J. Wang, W. Wei, T. Chang, T. Chang, T. Huang, H. Kao, S. Wei, Y. Chiu, C. Lee, C. Lo, Y. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, ‚Äú24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors,‚Äù in  2019 IEEE International Solid- State Circuits Conference - (ISSCC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "C. Results \nWe present and compare the execution latency and energy consumption (via BatteryManager API in Android Studio) when performing inference for each video under the three conÔ¨Ågurations described in Sec. YOLOv3 achieves 55.3 %  mAP on average, whereas YOLOv4-tiny achieves 40.2 %  [45] mAP. The former one is a quite heavy model, with 106 layers and 65.86 Bn FLOPS, whereas the latter one is a lighter model, with 38 layers and 6.94 Bn FLOPS.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "Maximization of wireless sensor network lifetime using solar energy harvesting for smart agriculture monitoring. Ad Hoc Networks  94 (2019), 101966. [64]  Zhuoran Song, Bangqi Fu, Feiyang Wu, Zhaoming Jiang, Li Jiang, Naifeng Jing, and Xiaoyao Liang.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Association for Computing Machinery, 2020. [24]  B. Han, Y. Liu, and F. Qian,  ViVo: Visibility-Aware Mobile Volumetric Video Streaming . [25]  X.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Mete: meet- ing end-to-end qos in multicores through system-wide resource management. [144] Akbar Sharifi, Shekhar Srikantaiah, Asit K Mishra, Mahmut Kandemir, and Chita R Das. In  Proceedings of the ACM SIGMETRICS joint international conference on Measurement and modeling of computer systems , pages 13‚Äì24, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "The host, after obtaining information from multiple sensors, per- forms any further required computation and uses ensemble learning [ 47 ] to give an accurate classification result. Note that, unlike prior EH-WSN systems [ 47 ], the role of the host device here is not limited to just result aggregation; rather, the host participates and performs inference when the sen- sors do not have enough energy and choose to communicate the data (in the form of coresets) to the host. In this section, we will explain, in detail, the overall execution workflow of the  Seeker  system, followed by the the detailed design of the hardware support to maximize its energy efficiency.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "6b and Fig. For example, similar to the distance vector study in Fig. We want to emphasize that our underlying ideas behind the proposed  EA  and  AE  (designed for the Equirectangular format) can work irrespective of the representation formats used [48].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Common crawl corpus. Accessed: 2024-10- 18. https://commoncrawl.org , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "This is expected to be much faster than RAHT, and in fact, our experimental results show  ‚âà 49 √ó  speedup (53 ms  vs 2 . 6 s ). 6 , compared to RAHT, our proposal reuses the intermediate Morton codes, which have been computed during the geome- try compression, to precisely identify the points with similar attributes from a set of irregular points.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "To further demon- strate the sensitivity of Cocktail to dataset and applicability to other classiÔ¨Åcation applications, we also evaluate it us- ing  CIFAR-100  and Sentiment-Analysis application. We use three important metrics: response latency, cost and accuracy for evaluating and comparing our design to other state-of- the-art systems. The response latency metric includes model inference latency, communication/network latency and syn- chronization overheads.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "TheenergyforoneReRAMrow(e DAC ),oneReRAMcell (e MAC  )andoneReRAMcolumn(e BL ,e SA‚àíRef ,e S+A )are theworst-casevaluesfromthesimulation.Table V-B 2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies. TABLEII R ELATIONSHIPOFENERGYANDTHE R E RAM TILINGSIZEAND R E RAM COPIES . Component Energyequation DAC E DAC =e DAC √óm√óaG Computation E M AC =e MAC   √óm√ón√óaG \nADC BL E BL =e BL √ón√óaG SA-Ref E SA‚àíRef =e SA‚àíRef √ón√óaG S+A E S+A =e S+A √ón√óaG \n3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 272,
    "augmented": true
  },
  {
    "text": "PMLR, 2021, pp. 6109‚Äì6119. [47] S. Lee, B. Islam, Y. Luo, and S. Nirjon, ‚ÄúIntermittent learning: On- \ndevice machine learning on intermittently powered system,‚Äù  Proceed- ings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Simi- larly, the pixel value rendered at  [ x 0 r , y 0 r ]  on the right VR screen \n247 \n0 \n2 \n4 \n6 \n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \nAvg. Reuse distance (# frame) \nUsers \nRhinos Timelapse Rollercoaster Paris Elephants \n(a) Reuse distance is just  2  for most of cases \n28% \n0% \n20% \n40% \n60% \nReuse Ratio \nVideo (b) Reuse ratio \n0% 20% 40% 60% 80% 100% \nG 4 3 2 1 \nNorm. to Ground Truth(G) \nPrecision \nReuseRatio PSNR \n(c) Precision vs. reuse ratio tradeoffs \nFig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 165,
    "augmented": true
  },
  {
    "text": "This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA. B. Mapping inference tasks to ResiRCA To achieve both generally low power and intermittency- compatible execution, the proposed ResiRCA architecture has the following two features that impact the software management of the RCA: Lightweight:  From the perspective of the ReRAM circuit at the core of the RCA, the precision and resolution of inputs, weights and outputs are kept low to yield low power. The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiÔ¨Åcations.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 169,
    "augmented": true
  },
  {
    "text": "This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the sensitivity of the weights, along with the QuantaTask optimization to handle energy constraints. D.3 Feature Map Reconstruction Error Dropout with QuantaTask Optimization \nFeature Map Reconstruction Error Dropout leverages the reconstruction error of feature maps to adjust dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Perform the forward pass with the updated dropout mask to obtain the output Y .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "B ACKGROUND AND  M OTIVATION \nBefore getting into the details of the existing issues and possible solutions, we Ô¨Årst outline the computation pipeline of the state-of-the-art  360 ¬∞ VR streaming (Fig. 1). Further, we describe the existing energy inefÔ¨Åciencies in processing  360 ¬∞ VR systems, to motivate our design for mitigating the com- putational inefÔ¨Åciencies by avoiding redundant computations.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "4, pp. 1‚Äì30, 2019. [48] L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, \n‚ÄúHyperband: A novel bandit-based approach to hyperparameter opti- mization,‚Äù  The Journal of Machine Learning Research , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "In contrast, the  bike  video achieves the minimum speedup (4%, 34% and 36% in the same order). The reason behind this is that, as shown earlier in Tab. In addition, from an individual video‚Äôs perspective, we further observe that the  shoe  video achieves the maximum performance benefits from our schemes (specifically, 23%, 69% and 73% latency reduction with Inter-Holo ,  Intra-Holo  and  Inter-Intra-Holo , respectively, compared to the baseline).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Since the data size is limited, with increasing numbers of machines, the training data-per-machine decreases, and hence gives us the opportunity to also study the impact of data availability. We implemented a random forest based regression model to predict the surface roughness value and tested our partitioning policies. The edge node is implemented on Raspberry Pi development boards and the cloud is emulated via a desktop class Intel corei9 10900k CPU (with 64GB DDR4 RAM).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Energy Consumption:  Fig. 8b  plots the energy consumptions (in  J ) for the SOTA works on the primary y-axis (left), and our proposals on the secondary y-axis (right). Clearly, TMC13 and CWIPC are two of the most energy-consuming schemes, which consume  11 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Springer, 2017, pp. 525‚Äì561. [79]  M. A. S. Teixeira, H. B. Santos, A. S. d. Oliveira, L. V. Arruda, and F. Neves, ‚ÄúRobots perception through 3d point cloud sensors,‚Äù in  Robot Operating System (ROS) .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Our architectural support will result in a search space exploration methodology that can be used to map experts to chiplets for improving execu- tion efficiency. Curriculum Development Activities : As we have done in our prior NSF projects, we will integrate our research results from this project with educational activities and graduate and undergraduate student train- ing for nurturing the future workforce in science and engineering. Finally, our evaluation infrastructure can be used for fostering new research directions not only in LLMs, but also broadly in any ‚Äútransformer-based‚Äù applications like recommendation systems and multi-modal Generative AI applications, for efficient training and inferences.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "¬¥as  delivers 4.96% more accurate classiÔ¨Åcation compared to a na¬®ƒ±ve learner, and the morphable hardware design uses intermittent computing to maintain forward progress even while running on lower power budget. Together,  Us. ¬¥as  can save up to 200lbs of  CO 2  per year compared to a state of the art accelerator running on the grid.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "In  SoCC , 2018. [24]  Paul Covington, Jay Adams, and Emre Sargin. Stratus: Cost-aware container scheduling in the public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Jaeyoung Do, Yang-Suk Kee, Jignesh M Patel, Chanik Park, Kwanghyun Park, and David J DeWitt. IEEE, 2021. Query processing on smart ssds: Opportunities and challenges.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "[57] Nikhil Gupta and Jason Yip. Dbrx: Creating an llm from scratch using databricks. In  Databricks Data Intelligence Platform: Unlocking the GenAI Revolution , pages 311‚Äì330.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "The depth-wise separable convolution is performed in two main steps: depth-wise convolution and point-wise convolution. F.1.1 depth-wise Separable Convolution 2D Using Conv1D \nThe pseudo code described in Algorithm 1 implements a depth-wise separable convolution 2D (DWSConv2D) using a 1D convolution primitive function (conv1D). The DWSConv2D function takes four inputs: an input matrix, depth-wise kernels (DWsKernels), point-wise kernels (PtWsKernel), and an output matrix.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "In this design space, we plan to expose various ‚Äúknobs‚Äù from hardware via which software can better monitor and control the execution. Recent works have started exploiting HW-SW co-optimizations, for example, application-specific software prefetching can be used to tolerate the memory access latencies [70, 71], and L2-cache can be precisely populated with most frequency accessed embeddings [70]. Further, in some specific cases of unknown constraints, the software can indicate an expert to  migrate  to another chiplet.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "[4]  Amazon. In  Proceedings of the 28th Inter- national Symposium on High-Performance Parallel and Distributed Computing , pages 1‚Äì12, 2019. Spotweb: Running latency-sensitive distributed web services on transient cloud servers.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "It can be seen that  Cock- tail  shows similar reduction (as Imagenet) while using only 4.4 models on average. Fig- ure  15a  plots the average number of models used by the three policies for the top four constraints. It comprises of 100 distinct image classes and we trained 11 different models including the nine that are common from Table  1 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "[66]  C. R. Qi, H. Su, K. Mo, and L. J. Guibas, ‚ÄúPointnet: Deep learning on point sets for 3d classiÔ¨Åcation and segmentation,‚Äù in  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. [67]  C. R. Qi, L. Yi, H. Su, and L. J. Guibas, ‚ÄúPointnet++: Deep hierarchical feature learning on point sets in a metric space,‚Äù in  Proceedings of the 31st International Conference on Neural Information Processing Systems , 2017, p. 5105‚Äì5114. [68]  F. Qian, B. Han, J.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "While with our inter-frame compression design, the compression ratio can be further improved (increasing from 5.95 in intra-frame design to 10.43) with 35 √ó  speedup and 97.4 %  energy savings with respect to a state-of-the-art inter-frame PCC scheme [ 13 ]. Moreover, our proposal not only accelerates the PC encoding stage, but also can improve the performance of the decoding stage which involves inverse encoding operations (e.g., reduces decoding latency to  ‚âà 70 ms ), thus enabling the end-to-end PC processing in near real-time (i.e., 10FPS). II.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "[42]  Aaron Harlap, Alexey Tumanov, Andrew Chung, Gregory R. Ganger, and Phillip B. Gibbons. In  ATC , 2018. Proteus: Agile ML Elasticity Through Tiered Reliability in Dynamic Resource Markets.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "13 \nA More Results on Other Platforms and EH Sources \nFigure 4: Hardware setup of NExUME using MSP-EXP430FR5994 as the edge compute, Adafruit ItsyBitsy nRF52840 Express for communicating, Energy Harvester Breakout - LTC3588 with super- capacitors as energy rectification and storage and a Pixel-5 phone as the host. Datasets Full Power MSP on Piezo AP PT iNAS+PT NExUME Better FMNIST 98.70 71.90 79.72 83.68 88.90 6.24% CIFAR10 89.81 55.05 62.00 66.98 76.29 13.90% MHEALTH 89.62 59.76 65.40 71.56 80.75 12.84% PAMAP 87.30 57.38 65.77 65.38 75.16 14.97% AudioMNIST 88.20 67.29 73.16 75.41 80.01 6.10% Table 4: Accuracy of NExUME on MSP board using vibration from a Piezoelectric harvestor. Better refers to the improvement over iNAS+PT baseline.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 280,
    "augmented": false
  },
  {
    "text": "In our evaluation, we will employ both architecture-level and LLM/application-level met- rics. The former includes execution cycles, energy consumption and carbon footprint (by extending GA4HPC [11]). In addition to these, we will also use LLM/application-level metrics such as LLMOps (an extension of MLOps [84] tailored for LLMs).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Assuming each request to a function within the appli- cation spawns one container for that function, the number of containers to be provisioned in advance for functions at depth  ùëë is given by: \nùëÅùê∂ ùëë ùë° =  ‚åà PL  ùë° ¬∑ ( ùëá ùëë ¬∑  ùëÉ 0 )‚åâ \nHere,  ùëÅùê∂ ùëë ùë° is a column vector of ùëõ elements, each correspond- ing to the number of elements required to be provisioned for functions at a depth,  ùëë , from the start function. In order to apply this to proactive container allocation decisions, we can adopt the following procedure. The incoming load to the application at time stamp,  ùë° , is denoted as  ùëÉùêø ùë° and can be predicted using a load estimation model.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 176,
    "augmented": true
  },
  {
    "text": "For example, recent research on mixture-of-experts (MoE) mostly focused on implementing experts as sparse feed-forward neural network (FFNN) layers in an end-to-end transformer [74], and thus they still need to be trained as a single model, and not flexible to be trained or fine-tuned separately. The other line of re- search [131,151] implemented experts as individual language models, yet the experts are selected to work individually and they cannot be composed dynamically to complete complex tasks. Note that  existing works have only studied a few specific points in this vast design space , lack- ing a comprehensive exploration of this search space of expert model design and implementation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "2 ) to measure their difference: \nDi f f ( I block , P block ) =  ‚àë K i = 1 ( r iP  ‚àí r iI ) 2  +( g iP  ‚àí g iI ) 2  +( b iP  ‚àí b iI ) 2  (2) \nwhere  P block  =  { ( x iP , y iP , z iP , r iP , g iP , b iP ) } ,  I block  =  { ( x iI , y iI , z iI , r iI , g iI , b iI ) } , for  i  =  { 1 ,..., K } . Note that, the BM can be performed in parallel as there is no dependence across blocks. Reuse:  for blocks for which the reference blocks are similar enough (e.g., the 2-norm differences are less than the pre- deÔ¨Åned thresholds), only the pointers to their reference blocks will be recorded (in our proposal, for each P-block, we set the number of candidate blocks as 100, thus, 6 bits are sufÔ¨Åcient for encoding one P-block).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 304,
    "augmented": false
  },
  {
    "text": "In comparison, given a GPU-based system with  k parallel cores, our design requires only  O ( ‚àë D i = 1   N i / k )  time ( N i is #nodes in layer ‚àí i ). And, as we show later in Sec. VI , our results indicate  37 √ó  speedup for the geometry compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "8: Measure key indicators: participation rate, average energy depletion rate, frequency of incorrect infer- ences, and overall inference accuracy. , K  (number of refinement iterations) do 7: Run a simulation or small-scale test deployment us- ing the current  Œ≥ k , Œ¥ k , Œ∑ k . .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "[13] R. Bird, Z. J. Baum, X. Yu, and J. Ma, ‚ÄúThe regulatory environment \nfor lithium-ion battery recycling,‚Äù 2022. [14] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, \nA. Krishnan, Y. Pan, G. Baldan, and O. Beijbom, ‚Äúnuscenes: A multimodal dataset for autonomous driving,‚Äù in  Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2020, pp. 11 621‚Äì11 631.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Historically, researchers have investigated these components individually, often focusing on high- performance computing, scientific computing, and database applications. However, the specific demands of ML applications on storage systems have largely been overlooked. storage stack archi- tects often abstract the computational processes, neglecting considerations such as data movement cost, compute cost, and power requirements.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "The codec‚Äôs autoencoder component, which is trainable, is then tasked with compressing these enriched features. This setup not only streamlines the encoding process by utilizing high-quality \n10 \nfeatures but also significantly enhances compression efficiency by exploiting both intra-frame richness and inter-frame continuity. The training process is designed to optimize the autoencoder‚Äôs ability to compress and decompress video sequences efficiently, without altering the pretrained feature extractor, thereby providing a stable, high-performance baseline for feature representation.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "[68] Y. Peng, Y. Bao, Y. Chen, C. Wu, and C. Guo, ‚ÄúOptimus: an efÔ¨Åcient \ndynamic resource scheduler for deep learning clusters,‚Äù in  Proceedings of the Thirteenth EuroSys Conference , 2018, pp. Dean, ‚ÄúCarbon emissions and large neural network training,‚Äù  arXiv preprint arXiv:2104.10350 , 2021. 1‚Äì14.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "This process repeats for all coefficients  a i . The resultant outputs from each SDMM calculation are accumulated every cycle. The final polynomial product  p  is sequentially read out by the address signal  addr ab , combined with the coefficient of  c , thereby producing the final output  d  as d  =  a  ¬∑  b  +  c .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Ada-kv: Optimizing kv cache eviction by adaptive budget allocation for efficient llm inference, 2024. [44] Financial Times. [43] Yuan Feng, Junlin Lv, Yukun Cao, Xike Xie, and S. Kevin Zhou.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "These mechanisms include: (i)  Dynamic Dropout , which adjusts the dropout rates based on available energy to reduce computational load; (ii)  Dynamic Quantization , which modifies quantization levels in response to energy constraints to save energy; and (iii)  QuantaTask  design, which defines atomic computational units that can be executed without interruption given the energy budget. Unlike standard implementations where dropout rates and quantization levels are fixed or adjusted solely based on training dynamics, DynFit adjusts these parameters in real-time based on the energy profile of the device. Specifically, during training, we simulate energy variability by incorporating energy traces into the training loop.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "Restrictions apply. However, the huge data volume of the PC still remains \n284 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "This problem has been addressed in federated learning by combining the models using weight averaging [2]. Using the example of modern industrial machine state monitoring, the sensor attached to the machines for monitoring their health can also give away critical information like run time, operating conditions, materials etc., which might cause major privacy concerns. However, not all the deployments may want to participate in data sharing because of privacy reasons.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "3, 2016. [5]  J. B ¬¥ edorf, E. Gaburov, and S. P. Zwart, ‚ÄúA sparse octree gravitational n-body code that runs entirely on the GPU processor,‚Äù  Journal of Computational Physics , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Springer, 2014. [14] F. M. Rueda, R. Grzeszick, G. A. Fink, S. Feldhorst, and M. ten Hompel, ‚ÄúConvolutional neural networks for human activity recognition using body-worn sensors,‚Äù  Informatics , 2018. [15] T. Yang, Y. Chen, and V. Sze, ‚ÄúDesigning energy-efÔ¨Åcient convolutional neural networks using energy-aware pruning,‚Äù in  CVPR .",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "[143] Akbar Sharifi, Emre Kultursay, Mahmut Kandemir, and Chita R Das. Addressing end-to-end memory access latency in noc-based multicores. In  2012 45th Annual IEEE/ACM International Symposium on Microarchitecture , pages 294‚Äì304.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "The challenge here is to  send \n1 Throughout the paper we evaluate many of our motivation results using HAR as a workload as it is one such application, where the (EH-)WSN, used as body area network, fits perfectly with RF or body movement as the har- vesting source. Said coordinating device completes the rest of the computations and finally, aggregates them with the ones completed in the sensor nodes. a mobile phone), where sufficient resources are available to complete any remaining inference,  if the data can be sent from the sensor .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1047 \nThe weights are multiplied with the predicted load to scale instances  (launch_workers)  for every model pool. We name this as an importance sampling  6b  technique, because the model pools are scaled proportional to their popularity. As shown in Algorithm  2 , weights are determined by frequency in which a particular model is chosen for requests ( get_popularity ) with respect to other models in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Prior work [ 9 ] solves an optimization problem such that the input parameters are model_type, hardware_type (CPU or GPU), and the output parameter is response latency. To do so, they suggest using offline profil- ing or results from previous executions. Unlike prior works, we suggest that the input and output parameters can be any linear combination of the three primary parameters men- tioned above, depending on the application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 29th Symposium on Operating Systems Principles , SOSP ‚Äô23, page 364‚Äì381, New York, NY, USA, 2023. Association for Computing Machinery. [163] Zihao Wang, Bin Cui, and Shaoduo Gan.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Figure 4: Function Hit Rate for an Evenly Distributed Load across all Paths in each Application. NGINX \nSearch \nMake_Post \nRead_Timeline \nFollow \nText \nMedia \nUser_tag \nURL_Shortener \nCompose_Post \nPost_Storage User_Tag URL Compose_Post \nFollow Text \nend \nSearch Make_Post Read_Timeline \nNGINX \nPost_Storage \n0.08 \n0.4 \n0.32 \n0.2 \n0.5 \n0.3 \n0.1 \n0.1 \n1 \n1 \n1 \n1 1 \n1 \nFigure 5: Transforming the Social Network DAG into a Transition Matrix. behavior [ 19 ,  20 ].",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "P LK  =(P ld √ó Lat ld Lk   +P comp √ó Lat comp Lk \n+P st √ó Lat st Lk   +P merge  √ó Lat merge Lk )/Lat Lk (2) \nLat LK  = Lat ld Lk   + Lat comp Lk + Lat st Lk   + Lat merge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC ‚â• 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication. Underthesequentialcomputation mode, theconvolutionlayersareexecutedonebyoneinasequential \nfashion, and as a result, the power model and latency model in Equations 2 and 3 can be directly used. We also model the pipelined computation mode shown in Equations 4 and 5.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 262,
    "augmented": false
  },
  {
    "text": "Journal of Machine Learning Research , 23(120):1‚Äì39, 2022. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. [43] Yuan Feng, Junlin Lv, Yukun Cao, Xike Xie, and S. Kevin Zhou.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "It can be seen that  Cock- tail  shows similar reduction (as Imagenet) while using only 4.4 models on average. Figure  16a  plots the latency reduction and accuracy boost when compared to  InFaaS  (baseline). As expected,  Clipper  and  Clipper-X use more models than  Cocktail  (11 and 5.4, respectively) due to non-aggressive scaling down of the models used.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "[55]  Tomoyoshi Shimobaba, Jiantong Weng, Takahiro Sakurai, Naohisa Okada, Takashi Nishitsuji, Naoki Takada, Atsushi Shiraki, Nobuyuki Masuda, and To- moyoshi Ito. 2012. Computational Wave Optics Library for C++: CWO++ Library.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "[36]  K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúSpendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,‚Äù in  2017 22nd Asia and South PaciÔ¨Åc Design Automation Conference (ASP-DAC) , pp. 678‚Äì683, 2017. [37]  N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 199,
    "augmented": true
  },
  {
    "text": "It is to be noted that the savings are lower for  Relaxed  workload because, the number of models in the ensemble are inherently low, thus leading to reduced beneÔ¨Åts from scaling down the models. Cocktail  spawns 29% lesser VMs on top of Clipper-X , because it is not aggressive enough like  Cocktail to downscale more models at every interval. Intuitively,  InFaas  has the least number of VMs spawned because it does not ensemble models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output. DynFit integrates closely with DynAgent, which serves as a repository of EH profiles and hardware characteristics. Let  Q  represent the set of execution quanta, where each quanta  q  ‚ààQ  is defined by a tuple  ( l, e ) : q  = ( l, e ) Here,  l  is the number of loop iterations and  e  is the estimated energy required for these iterations.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 172,
    "augmented": false
  },
  {
    "text": "This stability is critical for maintaining consistent network performance and energy sustainability over time. 4 \n220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 \nAchieving an NE ensures that sensor participation patterns are stable; once equilibrium is reached, no single sensor ben- efits from changing its participation decision independently. Nash Equilibrium and Stability: A Nash equilibrium (NE) represents a stable action profile  a ‚àó ( t )  where no sensor can unilaterally improve its utility by deviating from its current strategy: \nU i ( a ‚àó i   ( t ) ,  a ‚àó ‚àí i ( t ))  ‚â• U i ( a i ( t ) ,  a ‚àó ‚àí i ( t )) ‚àÄ a i ( t ) ,  ‚àÄ i.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 292,
    "augmented": true
  },
  {
    "text": "Sun, and N. Vasconcelos, ‚ÄúDeep learning with low precision by half-wave gaussian quantization,‚Äù  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. [31]  G. Venkatesh, E. Nurvitadhi, and D. Marr, ‚ÄúAccelerating deep con- volutional networks using low-precision and sparsity,‚Äù in  2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp. 5406‚Äì5414, 2017.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "Msp dsp library: Low energy accelerator (lea) user‚Äôs guide. Texas Instruments. https://software-dl.ti.com/msp430/msp430_public_sw/mcu/msp430/DSPLib/ 1_30_00_02/exports/html/usersguide_lea.html , 2024b.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "To incorporate the ER-r, we induce delays between sending the external signal and starting the inference on the same sensor. This delay depends of the extended round- robin policy. Combination of ER-r and AAS, results in more than 70% accuracy for most of the activities (Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Then the optimal solution can be selected from among them. The solution space is actually very small because of the constraints that tile size candidates and aG  are all bounded in the integer domain. It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "As a result, the attribute and geometry are compressed separately. There are 3 methods for attribute compression in the G-PCC ‚Äì  RAHT  [ 14 ],  Predicting Transform  [ 52 ], and  Lifting Transform  [ 52 ]. The main idea behind RAHT is to use the attribute values in a lower octree level to predict the values in the upper level.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "‚Ä¢  We propose two complementary designs to capture and utilize such spatio-temporal localities. First, we propose a Morton code-assisted intra-frame compression scheme, where  both  the geometry and attribute can be compressed in a  highly parallel fashion. We believe this is the Ô¨Årst work that applies the Morton code-based parallel octree construction algorithm [ 31 ] to speed up PC geometry com- pression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Motivated by the observation that the ATW transform matrix generated by rotation on a 2D image is shared by both eyes, PIMVR [57] calculated the transform matrix only once, and scheduled two tiles (one for left-eye one for right-eye) with the same coordinate to the same vault in HMC. However, in contrast to the  360 ¬∞ VR video streaming, ATW is in 2D planar format, and share the same compute results across eyes. These two characterizations indicate that such optimizations in the planar world are infeasible to be applied in 3D PT-rendering.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "VI , our results indicate  37 √ó  speedup for the geometry compression. Apart from compression, the de-compression stage can also be run in parallel after applying our proposal, and can be even faster than the compression stage due to its reduced complexity (note that, this also applies for the attribute compression proposals as discussed later in Sec. IV-C 1 and Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "In case of a power emergency, the task is abandoned and a hardware-assisted backup and restore is performed. 6 \n4 Experimental Results \nNExUME can be seamlessly integrated as a ‚Äúplug-in‚Äù for  both  training and inference frameworks in deep neural network (DNN) applications, specifically designed for intermittent and (ultra) low-power deployments. In this section, we discuss the effectiveness of NExUME across two distinct types of environments, highlighting its versatility and broad applicability.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "VI-B  to compress the six PC videos from the 8iVFB and MVUB datasets (described in Table  I ). Then, we discuss and present the validity of our results on the smartphones. 8 , when using various designs explained in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "[65]  C. R. Qi, W. Liu, C. Wu, H. Su, and L. J. Guibas, ‚ÄúFrustum pointnets for 3d object detection from rgb-d data,‚Äù in  Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018. [66]  C. R. Qi, H. Su, K. Mo, and L. J. Guibas, ‚ÄúPointnet: Deep learning on point sets for 3d classiÔ¨Åcation and segmentation,‚Äù in  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. [64]  Point Cloud Library Contributors, ‚ÄúPcl gpu octree,‚Äù  ‚Äùhttps: //github.com/PointCloudLibrary/pcl/tree/master/gpu/octree‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 201,
    "augmented": true
  },
  {
    "text": "We implement each ap- plication as a workflow of chained functions in  OpenFaaS . Applications:  Each request is modeled after a query to one of the three applications (DDAs) we consider from the ùê∑ùëíùëéùë°‚ÑéùëÜùë°ùëéùëü benchmark suite [ 29 ]. The Twitter trace has a large variation in peaks (average = 3332 rps, peak= 6978 rps) when compared to the Wiki trace (average = 284 rps, peak = 331 rps).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "With this trend, the PC business is expected to reach a 10 Billion dollar industry by 2024 [ 71 ]. Since capturing PC no longer requires sophisticated, commercial and expensive devices and people are equipped with mobile PC capturing devices (like iPhone 13 Pro [ 3 ]), the application providers are also pushing many of the PC processing tasks like compression or rendering to the edge, to avoid the use of expensive cloud resources, minimize the data transfer latency, and/or protect user‚Äôs privacy. Considering the dense features, 3D geometry and the visual attributes captured in PC, especially for the media applications like telepresence and virtual visits, pre-processing [ 21 ], [ 44 ], [ 61 ], [ 84 ], compressing and storing [ 14 ], [ 16 ], [ 19 ], [ 47 ], [ 48 ], [ 74 ], post-processing and streaming [ 25 ], [ 40 ], [ 66 ], [ 76 ], [ 90 ] PC using a mobile device, while maintaining a reasonable quality of service (QoS), are fast becoming challenging tasks.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 242,
    "augmented": false
  },
  {
    "text": "Lightweight ReRAM circuit design \npower ReRAM cells. 5. C \nC \nC controlling circuit \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 21,
    "augmented": true
  },
  {
    "text": "This ef- fect is highlighted in applications such as  Social Network  and Media Service  which have relatively high MLP misprediction rates (80% and 50%, respectively 2 )) due to the presence of multiple possible paths (Table 2). This can be attributed to  Xanadu ‚Äôs container pre-deployment policy which causes reactive scale outs as a result of MLP mispredictions. From Figures 9 and 10, it can be seen that  Xanadu  has similar (or worse) end- to-end response times than  Kraken  (up to 50 ms more), but \nspawns more containers as well (up to 70% more) and satisfies fewer SLOs on average (0.2% lesser).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "2020. Fifer: Tackling Resource Underutilization in the Serverless Era. In  Proceedings of the 21st International Middleware Conference .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "In  2017 IEEE Visual Communications and Image Processing (VCIP) , pp. 1‚Äì4. IEEE, 2017.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 24,
    "augmented": false
  },
  {
    "text": "This hybrid \n5 \n275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 \napproach mitigates the high communication overhead and energy consumption, making it more suitable for resource- constrained EH-WSNs. By aligning update events with periods when sensors are most likely to participate meaningfully, we ensure that the global model is refined efficiently without imposing excessive en- ergy demands on the sensors. While traditional methods require persistent communication between sensors and the aggre- gator, our framework leverages the established equilibrium strategies to determine optimal times for model updates.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 214,
    "augmented": true
  },
  {
    "text": "We also elaborate on how the new loss function, the introduced regularizers, and their gradients integrate into the backprop- agation and stochastic gradient descent (SGD) steps. ‚ñ° \nC. Proof of Convergence for the Equilibrium-Aware Training Process \nIn this appendix, we provide a comprehensive and detailed proof of the convergence theorem stated in the main text. Addi- tionally, we discuss bounds on the newly introduced hyper- parameters and provide guidelines for selecting them.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "It challenges the machine learning community to consider not only the accuracy and efficiency of algorithms but also their environmental impact and accessibility, ensuring a broader positive social impact. 10 \nReferences \nSayed Saad Afzal, Waleed Akbar, Osvy Rodriguez, Mario Doumet, Unsoo Ha, Reza Ghaffarivar- davagh, and Fadel Adib. Furthermore, the development of energy-efficient, adaptive systems like NExUME is aligned with the growing need for sustainable computing practices across all disciplines of technology.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Load balancing techniques for efficient training of large-scale neural networks. IEEE Transactions on Neural Networks and Learning Systems , 32(6):2345‚Äì 2356, 2021. [89] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "It is evident that the LSTM and DeepAREst have lowest RMSE value. DeepARest is 10% better than LSTM model. Since the primary contribution in  Cocktail  is to provide high accuracy and low latency predictions at cheaper cost, appli- cation developers can adapt the prediction algorithm to their needs or even plug-in their own prediction models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "[4]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg. 2017. Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "By integrating these components, an EH system can sustainably power devices without relying on traditional power grids, making it ideal for remote or mobile applications. C Intermittent Computing and Check-pointing \nC.1 Intermittency-Aware General Matrix Multiplication (GeMM) \nHere we explain the operation of an energy-aware algorithm for performing General Matrix Multipli- cation (GeMM). The algorithm is designed to operate in environments where energy availability is intermittent, such as in devices powered by energy harvesting.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "Thus, both of these two tasks are able to meet the performance re- quirements shown in Table 1. On the other hand,  Scene Reconstruct captures comprehensive consistent maps of environments from an RGB-D image, and consumes 120 ms  in the practical setting. Note that such maps are not necessarily required to be generated for each frame (typically computed once per two or three frames [ 28 ,  50 ], thus 67 ‚àí 100 ms  in Table 1); hence, we argue that the state-of-the-art InfiniTAM technique, which implements a framework for real-time depth fusion and learning of 3D scenes [ 50 ], is already close to the ideal case.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "[61]  Oren M Tepper, Hayeem L Rudy, Aaron Lefkowitz, Katie A Weimer, Shelby M Marks, Carrie S Stern, and Evan S Garfein. 2017. Mixed Reality with HoloLens: Where Virtual Reality Meets Augmented Reality in the Operating Room.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 1, a typical VR HMD [39] has two major components: (i) an SoC with a video decoder, a GPU for processing projection computation, and a display controller, and (ii) a video buffer in DRAM for storing the decoded  360 ¬∞ frames and projected frames for both the left and right eyes. More speciÔ¨Åcally, the  360 ¬∞ video processing pipeline can be summarized as follows: Video Decoder:  The HMD receives encoded  360 ¬∞ video bitstream from the network (YouTube [61], Facebook-360 [7], etc).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Moreover, the divergence of analytics and archival pipelines from the outset suggests that optimizing both hardware, software and data-flow used in inference, learning and archival could significantly enhance throughput and energy efficiency. This can be achieved by using modern  neural compression algorithms  instead of the classical encoding algorithm. Therefore, there is an urgent need to  minimize compute and power requirements  in archival processes.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "In this section, we will explain, in detail, the overall execution workflow of the  Seeker  system, followed by the the detailed design of the hardware support to maximize its energy efficiency. 4.1 Decision Flow: From Sensors to the Host Figure 8 depicts a flow chat showing the decision process taken in the sensor nodes to navigate between each compo- nents. Each sensor has a data buffer that collects the data points for classification (implemented using a 60  √ó 3 FIFO structure of 4Byte cells to store the floating point data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Toward the Next-generation VR/AR Optics: A Review of Holographic Near-eye Displays from a Human-centric Perspective. 2020. Optica  (2020), 1563‚Äì1578.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "[37]  K. Lee, J. Yi, Y. Lee, S. Choi, and Y. M. Kim,  GROOT: A Real-Time Streaming System of High-Fidelity Volumetric Videos . Association for Computing Machinery, 2020. [38]  B. Li, ‚Äú3d fully convolutional network for vehicle detection in point cloud,‚Äù in  2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2017, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "‚Ä¢  We go beyond the compute and look into future-proofing the storage server by equipping it with quantum safe lattice-based encryption technique. Furthermore, we add failure management support for the intermittent edge servers. This includes a hardware software co-design for compute-intensive applications along with map- ping different functions to different hardware in the data pipeline.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Baseline  iNAS+PT designs the network from the ground up while combining the work of iNAS (Mendis et al., 2021) and EAP (Yang et al., 2018, 2017). Baseline  AP  is a DNN compressed to fit the average power of the energy harvesting (EH) environment using iNAS (Mendis et al., 2021) and energy-aware pruning (EAP) (Yang et al., 2017, 2018). Baseline  PT  takes the  Full Power  DNN and uses techniques proposed by (Yang et al., 2018) and (Yang et al., 2017) to prune, quantize, and compress the model.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 165,
    "augmented": true
  },
  {
    "text": "Furthermore, in the retail and business sectors, LLM-powered AI chatbots have been shown to reduce the time taken to process an order by 50% to 70%, demonstrating significant efficiency gains even in industries traditionally reliant on human interaction. LLMs have also made significant inroads into fields traditionally dominated by human creativity, such as creative writing and AI-generated artworks [3, 45, 85, 125, 177]. In healthcare for instance, more than 40% of institutions are leveraging LLMs to enhance patient care through improvements in diagnos- tics, patient support, and documentation efficiency [122, 130, 142, 176].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "This has a significant economic (users, products and data generating dollar value) as well as environmental (battery and e-waste) impact (Mishra et al., 2024). In fact, advances in EH has lead to a staggering development in intermittently powered battery-free devices (Maeng & Lucia, 2018; Gobieski et al., 2019; Qiu et al., 2020; Saffari et al., 2021; Afzal et al., 2022). A typical EH setup consists of 5 components, namely, energy capture (solar panel, thermocouple, etc), power conditioning, voltage regulation (buck or boost converter), energy storage (super capacitor) and compute unit (refer ¬ßAppendix B for details about each of them).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 192,
    "augmented": false
  },
  {
    "text": "EC2 pricing. https://aws.amazon.com/ec2/pricing/. [6]  Amazon.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "[62] Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Wenfei Zhou, James Coady, David Peng, Yujie Qiao, Luke Benson, Lucy Sun, Alex Wardle-Solano, Hannah Szabo, Eka- terina Zubova, Matthew Burtell, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Alexander R. Fabbri, Wojciech Kryscinski, Semih Yavuz, Ye Liu, Xi Victoria Lin, Shafiq Joty, Yingbo Zhou, Caiming Xiong, Rex Ying, Arman Cohan, and Dragomir Radev. Rep., jan , 2020. Folio: Natural language reasoning with first-order logic.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 233,
    "augmented": true
  },
  {
    "text": "5.3). Finally, based on our findings, we discuss future direc- tions that may help one design custom hardware accelerators for AR holograms (Sec. 5.5).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "As shown in Figure  3b , Ensemble-OD is always ex- pensive than single-OD for the all the models. Therefore, it is important to ensemble an ‚Äúoptimal‚Äù number of less compute intensive models to reduce the cost. 3 Prelude to Cocktail \nTo speciÔ¨Åcally address the cost of hosting an ensembling- based model-serving framework in public clouds without sacriÔ¨Åcing the accuracy, this section introduces an overview of the two primary design choices employed in  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "As a result, it is difficult to reliably run these complex tasks standalone on the edge device. While an NVP ensures safe check- pointing for a given computation, current edge scenarios may require a device to be simultaneously performing multi- ple functionalities [ 3 ‚Äì 5 ,  25 ] and might be at energy scarcity. [ 56 ] demon- strates the possibility of performing complex DNN inference at the EH-Sensor itself.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "2) Point Cloud Analysis:  To analyze objects/scenes in PCs, 3D convolutional neural networks (CNNs) have been widely used in techniques like 3D shape classiÔ¨Åcation [ 66 ], [ 67 ], [ 89 ], [ 91 ], object detection [ 38 ], [ 45 ], [ 65 ], tracking [ 22 ], [ 78 ], or segmentation [ 10 ], [ 66 ], [ 67 ], [ 89 ]. While most prior works target accuracy, Mesorasi [ 20 ] improves the compute and memory efÔ¨Åciency of 3D CNNs using delayed-aggregation and software-hardware co-design, and PointAcc [ 40 ] proposes special mapping unit and memory management for optimiza- tions. However, the huge data volume of the PC still remains \n284 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 192,
    "augmented": false
  },
  {
    "text": "All the three PIs will work in close coordination on the individual research topics as well as the overall integration of the project. The expertise of the management team members are complementary, and col- lectively cover all major aspects of the proposed research, namely, algorithm design, system-level support and architectural support. Das and Kandemir have worked together in prior and on-going NSF projects and have a history of successful collaboration, including co-advising underrepresented students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "The proposed EoE model can provide inherent fault-tolerance since each expert can be trained independently, and is thus exposed to hardware failures in a reduced time- frame. Task-2.6: Fault-Tolerant Expert Training Fault-tolerance of monolithic LLM models has been a major concern due to the long-running training jobs on a large number of GPUs [27, 149, 165]. To further minimize the impact of failures, we will investigate known fault-tolerance techniques from the distributed computing domain to support graceful degradation of training.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Hence, the over- all cost incurred by  mixed  procurement can be higher or lower than VM-only autoscaling policies. Prior work  like Cherrypick [ 1 ] solves the resource se- lection and configuration problems from VM perspective but does not consider Serverless Functions. We argue that compared to VMs there is more variability in configurations for  serverless functions  because the resources are billed at a more fine-grained 2   allocation of CPU and memory.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "It combines theoretical bounds with empirical evaluation, guiding the search toward stable and efficient equilibria. The above guidelines and the explo- ration algorithm provide a structured approach to selecting and refining  Œ≥, Œ¥,  and  Œ∑ . Exploration Algorithm \nAlgorithm  3  outlines a systematic approach to exploring suit- able hyperparameter values.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Horovod: fast and easy distributed deep learning in tensor- flow, 2018. Curran Associates, Inc., 2021. [141] Alexander Sergeev and Mike Del Balso.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "This allows for dynamic adaptation to network fluctuations and client-side computational capabilities, thereby optimizing the streaming experience. The capability to adjust the quality dynamically, by decoding additional layers as resources permit, ensures efficient bandwidth usage and enhances the overall Quality of Experience (QoE), making layered neural codecs a compelling choice for modern video streaming solutions. In an effort to optimize video compression beyond traditional and current neural codec capabilities, we introduce an enhanced layered neural codec that utilizes both intra-frame and inter-frame redundancies.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Detailed guidelines for selecting these hy- perparameters are provided in Appendix  A . Guidelines for Hyperparameter Selection: The param- eters  Œ≥ ,  Œ¥ , and  Œ∑  critically influence sensor behavior by dictating the trade-offs between participation rewards, penal- ties for incorrect submissions, and deterrents against non- participation. A complete formal proof, including all technical conditions, is provided in Appendix  B .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Combining the  Recall  with AAS (which we term as AASR - Activity Aware Scheduling with Recall) opens possibilities for getting a more accurate classiÔ¨Åcation. To minimize the communication overhead, and to ensure participation of all sensors, we build the  recall  strategy into the host device. The host device remembers the most recent classiÔ¨Åcations by all of the sensors.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Texas Instruments. Msp430fr5994 mixed-signal microcontrollers. https://www.ti.com/ product/MSP430FR5994 , 2024a.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "HAR has been pervasive enough given the rise of smart wearables and has been studied well enough to have ample access to resources to make a judicious evaluation. Further, we also evaluate one more emerging application from predictive maintenance domain. Algorithm Compression Ratio Accuracy Loss (%) Fourier Decomposition 3 - 5 9.1 - 18.3 DCT 3 - 5 5.8 - 16.2 DWT 3 - 6 5.3 - 12.7 Coreset 3 - 10 0.02 - 0.76 Table 1: Accuracy trade-off of different compression techniques: Low-dimensional data loses important fea- tures under lossy compression, dropping inference ac- curacy significantly compared to the original data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "Mingsong Lv and Enyu Xu. Efficient dnn execution on intermittently-powered iot devices with depth-first inference. IEEE Access , 10:101999‚Äì102008, 2022.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Similarly, for performing convolution, the ReRAM x-bar typically includes additional components, such as delay lines and adders. 24 \nF Pseudo Codes \nF.1 Depth-wise Separable Convolution 2D Using TI LEA \nDepth-wise separable convolution is an efficient form of convolution that reduces the computational cost compared to standard convolution. The delay lines are used to implement the sliding window for the convolution operation, while the adders are used to sum the weighted input signals over the sliding window.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "E XPERIMENTAL  R ESULTS \nIn this section, we compare our proposed intra-frame and inter-frame designs against two different PCC techniques, by evaluating four metrics critical for the PC-based applications ‚Äì execution latency, energy consumption, video quality, and compression ratio. VI-A ) used for our analyses, e.g., experimental platform, dataset, and different designs (Sec. Towards this, we Ô¨Årst describe the conÔ¨Åg- urations (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 657‚Äì669. [70]  Shulin Zhao, Haibo Zhang, Sandeepa Bhuyan, Cyan Subhra Mishra, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "3 Data Compression using Neural Codec \nIn this section we go over the overall design and design choices for the neural codec design of Salient Store  . We discuss the edge storage architecture followed by the choice of neural codec and their design. 3.1 Salient Store  Storage Architecture: \nSalient Store  edge storage architecture is crafted to optimize data-flow and computational effi- ciency in continuous learning edge servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "This calls for revisiting the entire training process; we need to train the DNN in such a way that it is aware of the intermittency and adapts  to it. Although intermittency-aware NAS (Mendis et al., 2021), could alleviate certain problems, they often assume fixed resource constraints and do not account for real-time energy fluctuations. Moreover, existing works like Keep in Balance (Yen et al., 2023), Stateful Neural Networks (Yen et al., 2022), ePerceptive (Montanari et al., 2020), and Zygarde (Islam & Nirjon, 2019) address aspects of intermittent computing but do not integrate energy variability awareness directly into the training and inference processes to enable dynamic adaptation.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 182,
    "augmented": true
  },
  {
    "text": "2.2.2. In this paper, the foveated rendering idea (denoted as  Inter-Holo  design) has been implemented (in Sec. Apart from neural network techniques, foveated rendering is another promising performance optimization for reducing computational costs [ 2 ,  22 ,  24 ,  25 ,  30 ,  47 ,  62 ], as summarized in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "3. Over multiple iterations of such asynchronous scheduling, the kernel queue for each tile will be of different size creating a load imbalance; how to tackle this? How do we know when to stop executing?",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "We will conduct the following research to incorporate the availability of expert accelerators, memory constraints, and workload balance to inform our algorithmic choices: Selecting Experts based on Available Expert Accelerators. Our LLM expert repository offers a rich set of diverse skills and domains to serve a user query. As a user query can be possibly answered by different sets of experts, we will choose experts based on the combination of two factors: (1) The relevance of expert to the user query, and (2) the availability of accelerator (developed in Thrust 3) for the expert.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "We adjust dropout rates and apply L2 regularization accordingly to balance the training process. We monitor the update frequency  F p  of each weight  w p  over a window of  T  iterations: \nF p  =  1 \nT \nT X \nt =1 U p ( t ) , U p ( t ) = \u001a 1 , if  w p  is updated at iteration  t 0 , otherwise (4) \nWeights with  F p  < Œ∏ low  are considered under-trained, and those with  F p  > Œ∏ high  are considered overfitting. This adaptive strategy ensures that all weights are adequately trained despite the dynamic adjustments.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": ";  iv)  How can inter-chiplet and inter-chip data movements be choreographed to maximize performance and minimize energy consumption for training, inference, and re-training? ; and v)  What are the hardware-software co-design opportunities towards an efficient cross-stack system? .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "V). Pixel Content Reuse on VRs:  Pixel value reuse has been well-studied in VRs [17], [22], [23], [29], [33], [50], [60], [66] to improve throughput and performance. Moreover,  EA  and  AE  can further be integrated into  PTU  to save even more energy.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "In the earlier case of na¬®ƒ±ve scheduling we tried to build an efÔ¨Åcient DNN by applying energy aware pruning [15]. However, since Origin  follows an activity aware scheduling with extended round-robin, it can relax the power constraint pruning if needed. Instead of restricting the power constraint to the average power of the entire power trace, the constraint can be relaxed to the average power requirement of the extended round-robin \n0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 AAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baseline-2 Baseline 1 \n(a)  Accuracy with MHEALTH dataset.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 190,
    "augmented": false
  },
  {
    "text": "On the other hand, the two  P 2  points are relatively far away from each other and their attribute inputs are quite different, offering little reuse opportunity. To summarize, in this example, the Ô¨Årst two points in I-Frame,  P 0  and  P 1 , could be reused for compressing the P-Frame, thus reducing the compressed output size. 2) How to Capture the Temporal Opportunity?",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Such signiÔ¨Åcant speedup comes with a reduction in quality. In the example shown in Fig. 5 , the octree constructed based on the Morton codes is slightly different from the one generated by the sequential algorithm (which is lossless).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "In 2012 16th international symposium on wearable computers , pp. 108‚Äì109. IEEE, 2012.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 24,
    "augmented": false
  },
  {
    "text": "2:  Compute  e max total   =  e max cap   +  e inf   +  e comm . 3:  Ensure baseline feasibility: If  Œ≥ 0  ¬∑  ‚àÜ A min  ‚â§ Œ¥ 0  +  e max total   , increase  Œ≥ 0  until this condition is met. 4:  Set  Œ∑ 0  > Œ¥ 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Gshard: Scaling giant models with conditional computation and automatic sharding. arXiv preprint arXiv:2006.16668 , 2020. [91] Feihui Li, Chrysostomos Nicopoulos, Thomas Richardson, Yuan Xie, Vijaykrishnan Narayanan, and Mahmut Kandemir.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Our experiments suggests variance to be the most suitable metric to decide the threshold. Why Variance:  Random-forest typically randomly samples the data and generates different estimators from the given data. The bootstrapping strategy makes each estimator learn different features of the data set and therefore increases the generality of the whole model.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Data Annotation \nPicking the Important Ones:  Typically, edge models are ca- pable of inferring at the frame rate of the camera (at times, 30fps to 60fps) [ 19 ]. However, the teacher model used to label the incoming data cannot match this in a resource- constrained environment where performing training is going to be even more resource consuming. Therefore, we employ an intelligent ‚Äúdata sampling mechanism‚Äù to select the frames that might contain new information and a potential candidate for learning.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "2 F super-capacitors connected in parallel to a voltage regulator \ncircuit. The harvested power is given as an input to a mov- ing average power predictor [ 61 ], [ 72 ] to predict the future available power. Note that the power predictors used in prior works are meant for Ô¨Åckle energy harvesting scenarios like piezoelectric (movement), or RF (WiFi).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "This work aims to address this limitation by pursuing answers to the following questions -  1) how do we leverage mul- tiple available energy harvesting wireless sensors collectively, and 2) where should each individual sensor perform its own inference, considering that they collectively perform a single task? Our approach to address these questions relies on decen- tralizing the DNN execution and letting each sensor perform its own inference. In networks of energy harvested sensors, the power-hungry nature of commu- nication results in intermittent coordination failures due to one or more of the sensors, or even the fusing node itself, lacking sufÔ¨Åcient energy at the time that inter-node communication is required.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "2: Auto-labeling in  Us. ¬¥as : Select frames only with low conÔ¨Ådence as they might contain potentially new information, and use ensemble learning to improve the labeling. general, robust and larger model (typically with hundreds of millions of parameters [ 43 ], [ 99 ]) helps in annotating the data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Unlike the work presented in this paper, none of the four prior schemes mentioned in Table I performs well in all features listed in the table. Edge devices are often equipped with mature and robust video and vision pipelines, including sophisticated hardware like the codecs, which the current video analytics pipeline is yet to fully exploit. While one may hypothesize that a new software-hardware co-design may be a panacea for numerous applications, video analytics at the edge is not necessarily in this category.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "TABLE I: Qualitative summary of DNN vision optimiza- tion work in terms of accuracy, saving, adaptivity, hardware support, and decision making mechanism (DM). Restrictions apply. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "We also demonstrate that, such spatio-temporal localities can be precisely captured by Morton codes [ 30 ]. SpeciÔ¨Åcally, we Ô¨Ånd that 1  the points with similar Morton codes within one frame tend to have little variances in both geometry and attribute values ( spatial locality ), and 2 the points with adjacent Morton codes (for instance, a cluster of geometrically close points) are likely to move in a certain direction, as a whole block, across frames ( temporal locality ). ‚Ä¢  We propose two complementary designs to capture and utilize such spatio-temporal localities.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "As opposed to the software-based ‚Äúoptical Ô¨Çow‚Äù solution widely used in the computer vision domain [36], collecting the MV from the  codec hardware  is quite light-weight. In fact, our proÔ¨Åling indicates that only tens of  Œºs  are needed to generate the MVs for one frame (negligible compared to milliseconds or even seconds that DNN inference takes). We next illustrate 3 common scenarios of leveraging the MVs to capture the reuse opportunities in a DNN-based object detection application.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "However, managing such data requires substantial storage infrastructure. For instance, storing a full day‚Äôs worth of 1080p video at 60fps requires ( 1920  √ó  1080  √ó  3  pixels  √ó  4  bytes per pixel  √ó 60  frames per second  √ó 3600 √ó 24)117 . 32  TiB of raw video data, which compresses to approximately 60  GiB to  400  GiB of encoded data per day.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "However, to be valuable the power predictor must have high accuracy. For both  Piezo  and  Thermal  power sources the prediction accuracy when using a multi-power-level-optimized extension of the power predictor in [ 36 ] are above 80%. Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with  Transition keep   for all the workloads with these power sources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "The network only gets activated when it gets a  w-pdown warning signal from the predictor. This signal starts a graceful power-down sequence for the required number of tiles. The w-pdown  triggers the  backup  signal and the system goes into pwr-warning  state (other states being on, off, invalid and X).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "[ 50 ], [ 73 ] at a much lower rate, necessitates informed decisions regarding deployment placement and sampling rates. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "This indicates that the optimization scope of the distance- based  Intra-Holo  is larger than that of the RoF-based  Inter-Holo , which provides more sparsity in the hologram computing. Finally, combination of the two schemes ( Inter-Intra-Holo ), results in 28 . 95% power reduction compared to the baseline.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Note that this step is also time-consuming, as shown in Fig. 2 . This is because that all the nodes in the tree are traversed sequentially.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "To support faster inter-chip communication, which is essential for training, the chips can be interconnected using a fast fabric like NVLink [119], Infinity Fabric [13], or any newer technologies, and to cater inter-chiplet communication, which is essential for both training and inference, the chips can benefit from high-performance on-chip interconnect designs [10, 18, 31, 41, 108, 110, 116, 143]. Task-3.3: Handling Unforeseen Cases using Reconfiguration Besides having dedicated hardware for experts, there are three possible challenges which require adaption in hardware: the chiplets may incur failures, the work contained in inference is input dependent, and re- \ntraining is needed as part of continuous learning. The PI has extensive experience in designing on-chip interconnects for multicore architectures and will use the in-house simulation tools and other open-source network design tools [8, 19, 21, 116] to investigate the on-chip and inter-chip communication fabrics.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 222,
    "augmented": true
  },
  {
    "text": "5b, the user is currently focusing on the  soccer ball ; mean- while the  football  is located outside of the RoF, hence, becomes a candidate for approximation. On the other hand, in  Frame-II , the user moves her eyes and changes the region of focus. Now, the  football  needs the full depth planes‚Äô information, while the soccer ball  can be approximated.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Multi-View Learning and Collaborative Inference \nMulti-view learning leverages multiple sources or perspec- tives to improve learning performance ( ? ). In EH-WSNs, sensors providing different views of the same scene can en- hance inference accuracy through collaborative processing.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "We will then perform ‚Äúunlearning‚Äù by parameter-efficient fine-tuning to update the most relevant parameters. Task-1.4: Algorithmic Choices Informed by System and Hardware Constraints Our EoE system optimization is fundamentally a co-design problem across the algorithm, system, and architecture layers. As the above tasks develop optimal algorithms for dynamic morphable LLMs, they introduce many types of ‚Äúaffinities‚Äù (listed in Table 2) to facilitate our system and architectural level opti- mizations, which are investigated in Thrusts 2 and 3, respectively.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "4, pp. 42, no. Wu, ‚ÄúChasing carbon: The elusive environmental footprint of computing,‚Äù  IEEE Micro , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "5c, to provide an intuitive comparison in different scenarios. Here, we quantify the video quality with the popular Peak Signal-to-Noise Ratio (PSNR, normalized to the ground-truth; the higher, the better) [25], [40]. From Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "abs/1510.00149, 2015. 1737‚Äì1746, 2015. [27]  S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan, ‚ÄúDeep learning with limited numerical precision,‚Äù in  Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37 , ICML‚Äô15, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "IEEE, 2020. Urban Traffic Dataset. https://github.com/edge-video-services/ekya#urban-traffic-dataset.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "Evomoe: An evolutional mixture-of-experts training framework via dense- to-sparse gate. [118] NVIDIA. arXiv preprint arXiv:2112.14397 , 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Sailong Fan, Weiqiang Liu, James Howe, Ayesha Khalid, and Maire O‚ÄôNeill. Using machine learning to enhance archival processing of social media archives. Journal on Computing and Cultural Heritage (JOCCH) , 15(3):1‚Äì23, 2022.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "6.1 Latency, Accuracy and Cost Reduction \nLatency Distribution : Figure  7  shows the distribution of to- tal response latency in a standard box-and-whisker plot. The boundaries of the box-plots depict the 1st quartile (25th per- centile (PCTL)) and 3rd quartile (75th PCTL), the whiskers plot the minimum and maximum (tail) latency and the middle line inside the box depict the median (50 PCTL). The total response latency includes additional 200-300ms incurred for query serialization and data transfer over network.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "In contrast, this paper attempts to exploit available approximation opportunities unique in AR holo- graphic applications, and proposes a two-stage  HoloAR  scheme to speed up the execution and save energy. We also propose  Intra-Holo  to further approximate each of the object holograms, by analyzing its cur- rent distance from the user. Specifically, we leverage the existing foveated rendering in  Inter-Holo  to track the user‚Äôs eye movements and approximate the holograms of the objects that are outside the user interest.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Moreover, in addition to prolonging device lifetime, energy harvesting can help us reduce the environmen- tal impact of batteries [10]. However, energy harvesting is no panacea due to the Ô¨Åckle nature of harvested energy. To tackle this, recent works [9], [6] use a non-volatile processor (NVP) to ensure sufÔ¨Åcient forward progress in the face of frequent power emergencies.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Although, with the help of coresets, one can efficiently offload minimal input representations to a more compute-capable device, performing accurate inference on coresets is non-trivial due to their low-dimensional nature. From the aforementioned challenges, it is evident that we need a concoction of both hardware-driven and software optimized solutions to build next-generation EH-WSNs with the ability to perform fine-grained intermittent computing, while ensuring efficient network communication. Towards this, we propose  Seeker , a novel approach that leverages and extends coresets to efficiently execute DNN inference across a set of EH sensor nodes and a host mobile device.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "We achieve this by clustering the feature vector of the Large DNN model. Fundamentally, we use the larger DNN models as feature extractors which turn the data into a feature vector. In the original training phase, these feature vectors are separated using K-means [ 74 ] or other clustering.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Recall that, in the AR holographic application discussed above in Fig. 1a and Section 2.1, there are two types of inputs to the holographic pipeline ‚Äì  world sensors  for the physical objects (real cars in this case) in the world, and  user sensors  for the user behavior/state such as pose and eye movements (discussed in details in Sec. 3).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "PMLR, 2021, pp. 6109‚Äì6119. [47] S. Lee, B. Islam, Y. Luo, and S. Nirjon, ‚ÄúIntermittent learning: On- \ndevice machine learning on intermittently powered system,‚Äù  Proceed- ings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "From this Ô¨Ågure, we observe that: ‚Ä¢  Baseline:  In  Baseline , since there are no optimizations, the projection operations for both eyes consume equal energy (on GPU), i.e., each eye‚Äôs compute consumes  50%  energy. ‚Ä¢  EA:  With our proposed  EA  scheme, we fully exploit the temporal compute reuse  across frames with head orien- tations unchanged, with a negligible overhead ( 1%  extra \n6 Due to space limitation, here we only present 5 videos and 20 users. overhead, as discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "As a result, it is difficult to reliably run these complex tasks standalone on the edge device. Current devices adapt in one of three ways:  1) Send all the sensor data to a connected host device, or cloud, to offload the compute and act only as a sens- ing and display device; 2) Process data on the device itself, potentially dropping or delaying tasks due to energy short- falls; 3) A mix of the two models, where some computations do happen on the device while others are offloaded to balance compute, energy, and communication resources ; and typically, the latter is preferred, but it is non-trivial to find the optimal balance between what is to be done on the edge, what to be offloaded [20, 31, 65, 69], and  how to efficiently offload . Need for Specialized Hardware:  One of the major chal- lenges in deploying learning tasks using EH-WSNs is to find the proper hardware platform.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 210,
    "augmented": false
  },
  {
    "text": "How- ever, such hacks can fail if the cloud service provider decides to change the idle timeout of function instances or change the overall mechanism to recycle idle function instances. Prior literature [ 5 ,  10 ] tries to hide the model load latency by pre-warming serverless function in- stances through periodically issuing dummy requests. Rather than capitalizing on such design hacks, we need to develop prediction policies to estimate load correctly.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "IV  that, the Morton codes can precisely describe the geometry relations among points (thus, ensuring a good geometry compression), but sometimes they may not work well for the attributes, especially when the spatial locality is not rich for some blocks/frames. Clearly, the geometry data has been compressed very well, as opposed to the attribute data. Recall from our intra-frame design discussion in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": ",  (ii) can we exploit the temporal continuity of the video steam and safely skip the inference computation for similar frames? SpeciÔ¨Åcally, we present a systematic study of integrating the  temporal correlations  and  region-based inference  in a  uniÔ¨Åed  approach and try answering the following critical questions:  (i) what \nis the scope to explore both the pixel- and computational- similarities, i.e., frame-level, region-level or pixel-level? , and if not,  (iii) can we just focus on the RoIs in the current frame and signiÔ¨Åcantly reduce the computational requirements for its inferencing?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Energy (J) [Our scheme] \nEnergy (J) [SOTA] \nVideo \nSOTA Energy \nOur Energy \nSOTAs \n(b) Energy consumption \n0 \n15 \n30 \n45 \n60 \n0.00 5.00 10.00 15.00 20.00 \nRaw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 \nRedandblack Longdress Loot Soldier Andrew10 Phil10 Avg. PSNR (dB) \nSize(MB) \nVideo \nSize(Geometry) Size(Attribute) PSNR (dB) \n40dB \n(c) Compressed size & PSNR \nFigure 8: Results: (a) Latency breakdown. (b) Energy consumption.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 309,
    "augmented": false
  },
  {
    "text": "2 s  to  121 ms ) and  96%  improvement in energy efÔ¨Åciency, with only  13%  compression ratio drop and a minimal degradation in video quality with respect to the state-of-the-art schemes. And, more importantly, these proposals are compliant with the emerging MPEG PCC standards [ 53 ]. The experimental results with six PC videos show that our proposals provide  34 √ó  speedup (latency reduces from  4 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "IV. C ONCLUSIONS \nAn efficient compute and data partitioning between edge and cloud, while preserving data privacy, is an important problems to address for both existing and future deployments. This work provides a practical solution to achieve latency- accuracy balanced partitions for random forest based infer- ence tasks.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Cocktail  was also able to deliver modest accuracy gain \n1052    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nConst1 Const2 Const3 Const4 \nBaseline \n0 \n20 \n40 \nLatency-reduction \n0.50 \n0.75 \n1.00 \nAccuracy-Gain \n(a)  Image ClassiÔ¨Åcation:Cifar100. While able to reduce 60% of the models used in the ensemble,  Cocktail  also re- duces latency by up to 50% and boosts accuracy by up to 1.2%. Figure  16a  plots the latency reduction and accuracy boost when compared to  InFaaS  (baseline).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "V. I MPLEMENTATION AND  E VALUATION \nWe focus our evaluation on urban mobility, i.e. We treat the convolution scheduling (using input stationary and at a kernel level) in a morphable systolic hardware to be the main challenge and explain it. performing single shot  object detection for trafÔ¨Åc monitoring using the MobileNetV2  [ 51 ] model on the urban trafÔ¨Åc data set [ 97 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "intel.com/content/www/us/en/transportation/urban-mobility.html . Custom On-Device ML Models with Learn2Compress. (Accessed on 11/21/2022).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Background and Related Work \nVery basic, just the outline, compact and make robust \n2.1. Energy Harvesting Wireless Sensor Networks \nEnergy harvesting wireless sensor networks (EH-WSNs) have emerged as a sustainable solution for long-term envi- ronmental monitoring, infrastructure surveillance, and IoT applications ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, in the traditional 2D video compression domain, the video frames are usually rich in spatial locality (similar neighboring \n4 We do not claim the parallel octree construction as our contribution. b \n0% 25% 50% 75% 100% \n0 50 100 150 200 Delta(red) \n#blocks=20,best #blocks=20,worst #blocks=1000,best #blocks=1000,worst \n0% 25% 50% 75% 100% \n0 100 200 Range(Delta) \n#blocks=10 #blocks=100 #blocks=10000 #blocks=100000 \na \nc \nFigure 3: a) Spatial locality within one frame. However, our goal is to go beyond just optimizing the geometry compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 170,
    "augmented": true
  },
  {
    "text": "We propose both software modiÔ¨Åcations for existing compute pipeline and microarchitectural additions for further enhancement. We evaluate our design by implementing the software enhancements on an NVIDIA Jetson TX2 GPU board and our microarchitectural additions on a Xilinx Zynq-7000 FPGA model using Ô¨Åve video workloads. Experimental results show that  D¬¥ej`a View  can provide  34%  computation reduction and  17%  energy saving, compared to the state-of-the-art design.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Consequently, there is no data in the range  [0 , q  ‚àí 1) , allowing the maximum value of the 13-bit samples to be represented efficiently by a 6-bit signed number. The modular multiplication utilizing these signed numbers is formulated as follows: b  ‚äó a mod  q  =  q  ‚àí [( b  ‚àí a ) mod  q ] (1) \nHere, the most significant bit (MSB) signed-bit dictates the subtraction of the result from the modulus q , as illustrated in Fig. 3b.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "To enable sustainable machine status monitoring with energy harvesting (from machine vibrations or Wifi signals) we evaluate our setup using Bridgeport machines for monitoring their status. Prior works (Center, 2018) majorly focused on fault analysis but there are little to no datasets on predictive maintenance. Setup and Sensor Arrangement:  Two different types of 3-axis accelerometers (with 100Hz and 200Hz sampling rate) were placed in three different locations of a Bridgeport machine to collect and analyze data under different operating status.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "We denote this design combination as  EA+AE . ‚Ä¢  PTU+EA+AE  (HW) : In addition to the GPU-based design, our proposed designs can also be integrated into any other hardware platforms, including the FPGA-based PTU [28]. The  PTU+EA+AE  implementation combines the  PTU  and our  EA+AE  optimizations together.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "[30] H. Yeo, C. J. Chong, Y. Jung, J. Ye, and D. Han, ‚ÄúNEMO: Enabling Neural-Enhanced Video Streaming on Commodity Mobile Devices,‚Äù in  Proceedings of the Annual International Conference on Mobile Computing and Networking (MobiCom) , 2020. [29] C. Louizos, K. Ullrich, and M. Welling, ‚ÄúBayesian Compression for Deep Learning,‚Äù in  Proceedings of the 31st International Conference on Neural Information Processing Systems , 2017, p. 3290‚Äì3300. [31] K. Simonyan and A. Zisserman, ‚ÄúVery Deep Convolutional Networks for Large-scale Image Recognition,‚Äù  arXiv preprint arXiv:1409.1556 , 2014.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 184,
    "augmented": true
  },
  {
    "text": "Common func- tions refer to those which are a part of two or more paths within an application DAG. In addition to critical functions, it is also crucial to assign higher weights to common functions as well. This effect can worsen if the same were to happen with multiple critical functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Note that  existing works have only studied a few specific points in this vast design space , lack- ing a comprehensive exploration of this search space of expert model design and implementation. For example, recent research on mixture-of-experts (MoE) mostly focused on implementing experts as sparse feed-forward neural network (FFNN) layers in an end-to-end transformer [74], and thus they still need to be trained as a single model, and not flexible to be trained or fine-tuned separately. The other line of re- search [131,151] implemented experts as individual language models, yet the experts are selected to work individually and they cannot be composed dynamically to complete complex tasks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "Section  V-C will further present quantitative analysis and solution on how \ntoÔ¨Ågureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA. B.Powermodelandlatencymodel PowersupplyisasigniÔ¨ÅcantconstraintforResiSchedule. Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solution m,n,aG  wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,P load ,P comp andP store ,andtheyareperformed insequence.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 196,
    "augmented": false
  },
  {
    "text": "For 3D point cloud data, we selected the  KITTI Vision Benchmark Suite  (Geiger et al., 2012), a fundamental data-set in autonomous driving research. It includes a variety of data types and tasks, providing a real-world urban driving context that is essential for testing  Salient Store  ‚Äôs performance in processing and managing 3D spatial data. Additionally, the  nuScenes  data-set (Caesar et al., 2020) by Aptiv, with its comprehensive sensor data and annotations covering diverse driving scenes, is instrumental in evaluating  Salient Store  ‚Äôs efficiency in multi-modal data processing typical in urban mobility scenarios.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "2.3 Pros and Cons of Model Ensembling \nIn this section, we quantitatively evaluate (i) how effective ensembles are in terms of accuracy and latency compared to single models, and (ii) the challenges in deploying en- semble frameworks in a cost-effective fashion on a public cloud. Cocktail‚Äôs  autoscaling policy strikes parallels with Swayam‚Äôs distributed autoscaling; however, we further incorporate novel importance sampling techniques to reduce over-provisioning for under-used models. Table  2  provides a comprehensive comparison of  Cocktail with the most relevant works across key dimensions.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 44th annual IEEE/ACM international symposium on microar- chitecture , pages 374‚Äì385, 2011. Compact language models via pruning and knowledge distillation. [113] Saurav Muralidharan, Sharath Turuvekere Sreenivas, Raviraj Joshi, Marcin Chochowski, Mostofa Pat- wary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, and Pavlo Molchanov.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "This adaptive strategy ensures that all weights are adequately trained despite the dynamic adjustments. Dropout scheduling techniques are incorporated, where dropout rates are increased or decreased over time based on the training progress and energy availability, mitigating potential overfitting introduced by static dropout variations. Complexity Analysis of DynFit:  The time complexity of DynFit during training is  O ( N  ¬∑  T ) , where N  is the number of weights and  T  is the number of training iterations.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "they are application/data agnostic and can represent any form of data (IMU [ 36 ], Image [ 55 ], DNN feature map [ 17 ,  38 ,  46 ,  52 ]). This fulfils requirement  4  . Furthermore, constructing core- sets do not need any application information, i.e.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "The Extended- Round-Robin policy (ERR) [ 47 ] takes a store-and- execute approach, and the number associated repre- sents the ratio of store cycles vs execute cycles (e.g. RR3 is 3 store cycles followed by 1 execute cycle). The ‚ÄôBaseline‚Äô model is a fully powered system with no energy restrictions, and the quantized model runs on harvested energy using a RR12 policy.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Accessed: 05/19/2024. https://software-dl.ti.com/msp430/msp430_public_sw/mcu/msp430/DSPLib/ 1_30_00_02/exports/html/usersguide_lea.html , 2024b. Bashima Islam and Shahriar Nirjon.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "IV-A 2  for intra-frame compression, to further compress these deltas. On the other hand, if the ‚Äúbest matched I-block‚Äù is not as similar as the P-block (e.g., the 2-norm differences are larger than the threshold), simply approximating the P-block with its reference block will signiÔ¨Åcantly degrade the quality; instead, we compute and store the deltas for such block pairs, and then invoke the  Base+Deltas  technique, as mentioned in Sec. Reuse:  for blocks for which the reference blocks are similar enough (e.g., the 2-norm differences are less than the pre- deÔ¨Åned thresholds), only the pointers to their reference blocks will be recorded (in our proposal, for each P-block, we set the number of candidate blocks as 100, thus, 6 bits are sufÔ¨Åcient for encoding one P-block).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 195,
    "augmented": true
  },
  {
    "text": "Custom On-Device ML Models with Learn2Compress. Custom on-device ml models with learn2compress. https://ai.googleblog.com/2018/05/custom-on-device-ml-models.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "We integrate these two data reuse algorithms to accelerate the neural network inference and improve its energy efÔ¨Åciency. More speciÔ¨Åcally, for each frame in the video, we can dynamically select between (i) performing a full inference, (ii) performing a partial inference, or (iii) skipping the inference al- together. Our experimental evaluations using six different videos reveal that the proposed schemes are up to  80%  ( 56%  on average) energy efÔ¨Åcient and  2 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "3.2 DynInfer: Intermittency-Aware Inference Scheduling \nDynInfer  optimizes the inference phase of DNNs operating under intermittent power conditions. Unlike traditional systems with stable power, intermittent environments pose unique challenges for executing inference tasks efficiently and reliably. The inference process is represented as a set of tasks  T  =  { T 1 , T 2 , .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "We include details on the energy efÔ¨Åciency of  Us. Note that the energy inefÔ¨Åciency arises primarily from i) multiple saves and restores, ii) use of NV memories \nand iii) reconÔ¨Åguring the DRAM (along with a commercial ARM based host CPU). ¬¥as  under different of operation conÔ¨Ågurations in Table  II .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Component Spec Power Area(mm 2 ) SRAM Buffers 1kB*256+8kB*256+64kB+16*256kB 10.372W 117.164 MAC Unit (8*8)*256 8.46W 32.72 Adder Tree and Comparator 16*16bit + 256 2.4W 21.556 Control ‚Äì 0.96W 12.2 Host ‚àº Cortex A78 series 11W ‚Äì Design at 592MHz with Synopsys AED 32nm library Total 256 tiles 33.192W 183.64 \nTABLE I: Area and power estimation of our design. (e.g. Ekya [ 12 ] using ResNeXt101) to annotate the data or used a heuristic on top of the teacher model (e.g.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 186,
    "augmented": true
  },
  {
    "text": "24, pp. 109‚Äì165. [56] H. R. Mendis, C.-K. Kang, and P.-c. Hsiu, ‚ÄúIntermittent-aware neu- \nral architecture search,‚Äù  ACM Transactions on Embedded Computing Systems (TECS) , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "[46]  Mayank Raj, ‚ÄúPoint Clouds and its signiÔ¨Åcance in AR,‚Äù  ‚Äùhttps: //bit.ly/3uknBjT‚Äù , 2020. [45]  S. Martin, M. Stefan, A. Karl  et al. , ‚ÄúComplex-yolo: real-time 3d objectdetection on point clouds,‚Äù in  Computer vision and pattern recognition , 2018.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "To get mAP, the precision for each class is Ô¨Årst calculated across all of the Intersection over Union (IoU [41]) thresholds, and the Ô¨Ånal mAP will be the averaged precision of all classes (the higher, the better). The IoU threshold is set as 0.5 (a widely used value in mAP calculation) in our evaluations. Datasets : We use three published video datasets (VIRAT [33], EPFL [42] and CAMPUS [43]), to study the performance and energy behavior across different videos.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "For the purposes of this experiment, we base our function weights only on invocation frequencies that are periodically calculated at the beginning of each scaling window. Figure 2 depicts the number of containers provisioned per function for three container provisioning policies subject to a Poisson arrival trace ( ùúá = 25 requests per second (rps)) for three applications. To analyze the benefits of using invocation frequency, we designed a probability-based policy that employs weighted container scaling.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Bringing  Connectivity  into the weight estimation process helps  Kraken  assign a higher weight to critical func- tions, in turn, ensuring that more containers are assigned to them, resulting in improved response times for the functions themselves, as well as their descendants. Commonality:  As described in Section 2, in addition to cold start spillovers, incorrect probability estimations may arise due to variability in workflow activation patterns. This may be due to change in user behavior manifesting itself as variable function input patterns.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Algorithm 1:  Adaptive Frame Level Reuse Algo. Input :  RD : Reuse Distance Input :  BBs : Bounding Boxes in Previous Frames Input :  MV s : Motion Vectors for Current Frame Output:  Do Full Inference : Decisions \n1  procedure  Moving ( BBs ,  mv ) // Scenario1 \n2 if  0  < max { overlapped.area } ‚â§ T moving  √ó  mv.area  then \n3 return  True \n4 else \n5 return  False \n6  procedure  Missed ( BBs ,  mv ) // Scenario2 \n7 if  mv.area  ‚â• T missed  √ó  min { BBs.area }  then \n8 return  True \n9 else \n10 return  False \n11  procedure  Entering/Exiting ( mv ) // Scenario3 \n12 if  mv  is at edge  then \n13 return  True \n14 else \n15 return  False \n16  procedure  Frame _ Decision ( RD ,  BBs ,  MV s ) // main \n17 if  RD  ‚â• RD upper bound  then \n18 return  True \n19 if  MV s  ==  ‚àÖ then \n20 return  False \n21 Fuse and Filter the  MV s \n22 if  BBs  ==  ‚àÖ then \n23 if  MV s is large  then \n24 return  True \n25 else \n26 return  False \n27 for  mv  in  MV s  do \n28 if  mv.area  > T area √ó minBBs.area  then \n29 if  Moving ( BBs , mv )  or  Missed ( BBs , mv )  then \n30 return  True \n31 if  Entering/Exiting ( mv )  then \n32 return  True \n33 return  False \n4) Algorithm:  To handle the three common scenarios dis- cussed above, we propose our  adaptive  frame level (FL) reuse algorithm to determine whether to invoke full inference (FI) or skip inference (SI) for the current frame ‚Äì as shown in Line  16 in Algo. 1.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 478,
    "augmented": false
  },
  {
    "text": "https://software-dl.ti.com/msp430/msp430_public_sw/mcu/msp430/DSPLib/ 1_30_00_02/exports/html/usersguide_lea.html , 2024b. Accessed: 05/19/2024. Bashima Islam and Shahriar Nirjon.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "However, they never considered an intermit- tent power source, nor explored jointly optimizing multiple models with power, accuracy and latency constraints. Further- more, each model might contribute differently to the overall accuracy. Observing this, we propose a ‚Äúweighted accuracy metric‚Äù, where the weight of each of the model is a function of the accuracy, time needed and power availability.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "‚àó Work was done as a student at Penn State. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "A hierarchical K-means+ (or DBSCAN) clustering approach learns representations for exemplar se- lection. Additionally, a novel power-aware micro-proÔ¨Åling policy is adapted to determine optimal hyper-parameters for a variable-power environment. The robust exemplar selection and micro-proÔ¨Åling mechanisms are discussed and evaluated in ¬ß III-B  and ¬ß III-C , respectively.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "11 Proper selection and tuning of  Œª 1 , Œª 2  help main- tain stable and robust training dynamics. Thus, the proposed training process achieves a harmonious balance: it respects the strategic, energy-constrained envi- ronment (through equilibrium and game-theoretic consider- ations), while leveraging well-established convex optimiza- tion guarantees to ensure convergence of the global model parameters.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Bearing fault data. URL  https://www.sciencedirect.com/science/ article/pii/S0016003223007536 . Case Western Reserve University Bearing Data Center.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": ":  Towards further improving the compression efÔ¨Åciency, one could consider different options. Instead of throwing more compute power, we want to emphasize that, the discussion in this section only focuses on the attribute locality within one frame, which has ignored the potential localities among consecutive frames. 3) How to Further Improve the Compression EfÔ¨Åciency for Attributes?",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "(Accessed on 09/12/2023). [79] Jihye Kim, Sungho Lee, and Minseok Park. Optimizing resource allocation in gpu clusters for deep learning training.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Rather than capturing the reuse opportunities in raw input data, Potluck [12] Ô¨Årst extracts the feature vector (i.e., a vector generated from input image, such as SURF [47], HoG [48], Down-sampling [16], etc.) as  key , and then caches the corre- sponding inference results (as  value ) for further reuse. We also conducted experiments with a strategy mimicking Potluck [12] on V1 [33] by employing the down-sampled image as the feature vector.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "If the student (or the edge model) is conÔ¨Ådent about the classiÔ¨Åcation (e.g. However, if the student is not conÔ¨Ådent on the classiÔ¨Åcation, the frame is then saved as a potential exemplar (we will further reÔ¨Åne this in ¬ß III-B ). a clear frame with no new objects, or a frame similar to one of the training samples), then that frame is discarded as it potentially contains little to no new information.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Algorithm 1  Model Selection and Weighted Majority Voting \n1:  procedure  F ULL _E NSEMBLE (M ODEL L IST , SLO) 2: for  model  ‚àà ModelList  do 3: if  model.latency  ‚â§ SLO.latency  then 4: Model.add(model) 5: end if 6: end for O 1 7:  end procedure 8:  procedure  D YNAMIC _M ODEL _S CALING ( Models ) 9: if  curr_accuracy  ‚â• accuracy_threshold  then \n10: if  max vote  >   N \n2   + 1  then  O 2 \n11: to _ be _ dropped  ‚Üê max vote  ‚àí N \n2   + 1 12: Models . drop ( to _ be _ dropped ) 13: end if 14: else 15: addModel  ‚Üê find _ models ( remaining _ models ) 16: Models . append ( addModel ) 17: end if 18:  end procedure 19:  procedure  W EIGHTED _V OTING ( Models ) 20: for  model in  ‚àÄ Models  do 21: class  ‚Üê model .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 266,
    "augmented": false
  },
  {
    "text": "If not, we have to execute the entire computation as in the baseline case. As a result, by exploiting the  EA  scheme on the second frame, its compute energy consumption can be reduced to only  1%  of that consumed by  Baseline . D. IntraFrame-InterEye (AE) Computation Optimization \nIn  EA , the compute can be bypassed by reusing the pre- computed results, if the head orientation matches with any of the two previously memoized head orientations (stored in reg- isters).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Xanadu  [ 27 ] represents the policy that scales containers only along the Most Likely Path (MLP), which is the request‚Äôs expected path. If the request takes a different path,  Xanadu provisions containers along the path actually taken, in a reactive  fashion, and scales down the containers it provi- sioned along the MLP. Consequently,  Xanadu , when subject to moderate/heavy load, over-provisions containers by 32% compared to the Probability-based policy (from Figure 2) as a result of being locked into provisioning containers for the MLP until it is able to recalculate it.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "315‚Äì327. [57]  Attila Reiss and Didier Stricker. 2012.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA ¬© 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8638-8/21/11...$15.00 https://doi.org/10.1145/3472883.3486992 \nKeywords serverless, resource-management, scheduling, queuing \nACM Reference Format: Vivek M. Bhasi, Jashwant Raj Gunasekaran, Prashanth Thinakaran, Cyan Subhra Mishra, Mahmut Taylan Kandemir, and Chita Das. 2021.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "Further, we describe the existing energy inefÔ¨Åciencies in processing  360 ¬∞ VR systems, to motivate our design for mitigating the com- putational inefÔ¨Åciencies by avoiding redundant computations. A. 360 ¬∞  Video Streaming Pipeline \nThe key  difference  between a  360 ¬∞ VR video compared to a conventional 2D video is that the former provides content-rich immersive user experience.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "[82] Youngjae Kim, Brendan Tauras, Aayush Gupta, and Bhuvan Urgaonkar. Flashsim: A simulator for nand flash-based solid-state drives. In  2009 First International Conference on Advances in System Simu- lation , pages 125‚Äì131, 2009.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "In  Information Security Practice and Experience: 11th International Conference, ISPEC 2015, Beijing, China, May 5-8, 2015, Proceedings , pp. 454‚Äì468. Springer, 2015.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "This is because  Kraken  limits the number of containers spawned through function weight assignment and request batching. Consequently, they exhibit up to 0.24% more SLO Violations compared to  Kraken , for this workload mix. DProb  and  SProb  both exhibit higher utilization compared to  Kraken  (15%) as a result of spawning fewer containers overall, owing to not accounting for  crit- ical  and  common  functions while provisioning containers.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "At the same time, the quality further drops by  2 . Still, we argue that, even with the Intra-Inter-V2 option (see one demo in Fig. 9 dB.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "After a sensor detects an activity, it anticipates the next activity to be the current classiÔ¨Åed activity, looks up for the best sensor, and signals to activate it for the upcoming inference. However, this leads to another potential issue - what if the current inference is running on the best sensor, and the sensor does not have enough energy to run the next inference? In this case, the current sensor chooses the next best sensor for the job and signals it.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "URL  https://doi.org/10.1145/ 3123939.3123948 . ISBN 9781450349529. doi: 10.1145/3123939.3123948. Shulin Zhao, Haibo Zhang, Sandeepa Bhuyan, Cyan Subhra Mishra, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "As can be observed from Table IV, Potluck [12] provides very good accuracy ‚Äì  51 . We also conducted experiments with a strategy mimicking Potluck [12] on V1 [33] by employing the down-sampled image as the feature vector. 6% , which is slightly better than  50 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "A. We discuss about the hardware and software framework, and the accuracy of  Origin  compared to two different baselines. E VALUATION \nIn this section we explain the strategy for evaluating  Origin .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "https://bit.ly/3PXwecP . (Accessed on 11/13/2023). NVIDIA Corporation.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "39, pp. 1‚Äì7, Aug. 2011. [38]  Synopsis, ‚ÄúHSPICE.‚Äù https://www.synopsys.com/veriÔ¨Åcation/ams- veriÔ¨Åcation/hspice.html/.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "2  and Sec. III , most of the existing G-PCC tech- niques [ 56 ], [ 72 ] are based on octree data structure. We illustrate the generic pipelines (for  1  geometry compression, and for 2  attribute compression) employed by the state-of- the-art intra-frame compression techniques in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "IEEE, 2020. Los Alamos National Laboratory. Los alamos national laboratory and sk hynix to demonstrate first-of-a-kind ordered key-value store computational storage device.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "24 Watts , on average, when running on the edge GPU, which translates to 3 . 86% power reduction, compared to the baseline. In addition, our  Intra-Holo  scheme is more power efficient than  Inter- Holo , translating to 27 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "(Notations used: DCT: Discrete Cosine Transform, DWT: Discrete Wavelet Transform. 29.14 44.76 52.29 58.67 \n70.86 55.24 47.71 41.33 \n0 \n20 \n40 \n60 \n80 \n100 \nRR3 RR6 RR9 RR12 \n% Scheduled Computation \nCompleted Failed \n(a) Completion with ERR \n0 \n20 \n40 \n60 \n80 \n100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy (%) \nRR3 RR6 RR9 RR12 Baseline \n(b) Accuracy of ERR \n0 10 20 30 40 50 60 70 80 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy (%) \nQuantization Level 16b Quantization Level 12b Quantization Level 8b \n(c) Accuracy vs quantiza- tions \n0 \n20 \n40 \n60 \n80 \n100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy (%) \nSampling with Probability Weighted Sampling Baseline \n(d) Accuracy vs sub- sampling \nFigure 2: Accuracy comparison of various classical node-level optimization techniques. The Extended- Round-Robin policy (ERR) [ 47 ] takes a store-and- execute approach, and the number associated repre- sents the ratio of store cycles vs execute cycles (e.g.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 310,
    "augmented": true
  },
  {
    "text": "To address this, we design a Weight Estimator  2a  to assign weights to all functions so as to allocate resources in propor- tion to them. Explained below is the working of the proce- dure  ùê∏ùë†ùë°ùëñùëöùëéùë°ùëí _ ùê∂ùëúùëõùë°ùëéùëñùëõùëíùëüùë† in Algorithm 1 which is used to estimate function weights. Probability:  As alluded to in Section 2, one of the factors used in function weight estimation is its invocation probabil- ity.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "The (Critical, Non-Critical) function pairs chosen for this experiment were ( Make_Post ,  Text ), ( ID ,  Rating ) and ( NGINX , Search ) for  Social Network ,  Media Service  and  Hotel Reserva- tion , respectively. It can be observed that underprovisioning containers for just one Critical function has a greater im- pact on application performance than doing so for a single Non-Critical function, with the end-to-end response time and SLO guarantees becoming 24ms and 0.25% worse on average. This effect can worsen if the same were to happen with multiple critical functions.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "More speciÔ¨Åcally, we (i) develop a novel dynamic model selection, (ii) design a prudent resource management scheme that utilizes weighted autoscaling for efÔ¨Åcient resource allocation, and (iii) lever- age transient VM instances to reduce the deployment costs. In  Cocktail , we adopt a three-fold approach to reduce the resource footprint of model ensembling. In this paper, we propose and evaluate  Cocktail , a cost-effective model serving system that exploits ensembling techniques to meet high accuracy under low latency goals.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "In our experiments, we use Ô¨Åve different types of these constraints. The queries consist of images or sentences, which are randomly picked from the test dataset. As an example for the  Imagenet  dataset shown in Figure  6 , each constraint is a representative of <latency, accuracy> com- bination offered by single models (shown in Table  1 ).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "7, by the  Intra-Holo and  Inter-Intra-Holo  schemes, respectively. 1 and 6 . The above observations from these two figures explain the power benefits of our proposed designs.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "[88]  Sheikh Ziauddin and Matthew N Dailey. Iris recognition performance enhancement using weighted majority voting. In  2008 15th IEEE International Conference on Image Processing , pages 277‚Äì280.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Conceptual Role of Parameters \nThe scalar  Œ≥ >  0  represents the reward scaling for correct participation. If  Œ≥  is too low, sensors will not have suffi- cient incentive to expend energy on high-SNR captures. If Œ≥  is too high, sensors may waste energy attempting difficult inferences.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Thus,  Kraken  makes use of PWS and RS to scale containers to meet the target SLOs while simul- taneously minimizing the number of containers by making use of function invocation probabilities, function batching, and container eviction, where appropriate. 4.1 Proactive Weighted Scaler We describe in detail the components of PWS below. 4.1.1 Estimating function weights : Since workflows in SDAs are pre-determined, pre-deploying resources for them is straightforward in comparison to DDAs, whose workflow activation patterns are not known a priori.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "[43] O. Rift, ‚ÄúOculus Rift - How Does Time Warping Work?‚Äù ‚Äùhttps://www. youtube.com/watch?v=WvtEXMlQQtI‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "1, the neural network video inference software pipeline can be summarized as follows: Input:  The raw video data is Ô¨Årst stored in memory (usually in the H.264/MPEG format). A hardware-based H.264/MPEG decoder decodes the compressed video bitstreams to obtain the original video frames. These frames are then buffered in a memory buffer, waiting for the next stage ‚Äì NN Inference.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Special-purpose Computer HORN-8 for Phase-type Electro- holography. [35]  Takashi Nishitsuji, Yota Yamamoto, Takashige Sugie, Takanori Akamatsu, Ryuji Hirayama, Hirotaka Nakayama, Takashi Kakue, Tomoyoshi Shimobaba, and Tomoyoshi Ito. 2018.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Second, the four major reasons for instruction stalls in the  Forward-Propagation  step are: Data Request (21%), Execu- tion Dependency (19%), Instruction Fetch (15%), and Sync (10%), whereas in the  Backward-Propagation  step they are Read-only Loads (42%), Sync (24%), Data Request (16%), and Execution Dependency (6%). These stalls originate mainly from the inter-block and intra- block synchronizations required by the application, as discussed above when explaining Algo. 1.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "11 \nYongpan Liu, Zewei Li, Hehe Li, Yiqun Wang, Xueqing Li, Kaisheng Ma, Shuangchen Li, Meng-Fan Chang, Sampson John, Yuan Xie, et al. Ambient energy harvesting nonvolatile processors: From circuit to system. In  Proceedings of the 52nd Annual Design Automation Conference , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Inputs are broadcast into each tile so that each tile can work on a kernel. Computation is  redistributed  when there is a change in the power availability, and multiple tiles are shutdown (redacted) without impacting the data Ô¨Çow. or decomposed as multiple units called ‚Äúkernels‚Äù (or ‚ÄúÔ¨Ålters‚Äù).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 2446‚Äì2454, 2020. Yao Tian, Xi Zhao, and Xiaofang Zhou.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Apache¬Æ Subversion¬Æ. https://subversion.apache.org/ , 2024. [16] Apple.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "This inte- grated framework is theoretically grounded, yet practical for a wide range of IoT applications, from remote wildlife mon- itoring to large-scale industrial status tracking and precision agriculture. The remainder of this paper is organized as follows. By tackling the dual challenges of sensor unreliability and energy scarcity through a rigorous game-theoretic and fed- erated learning lens, our work addresses a critical gap in the design of sustainable, intelligent EH-WSNs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "6b and Fig. 6c. On plotting the distance vectors for each row of the FoV frames, we observe a recurring  ellipse  pattern.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Algorithm Compression Ratio Accuracy Loss (%) Fourier Decomposition 3 - 5 9.1 - 18.3 DCT 3 - 5 5.8 - 16.2 DWT 3 - 6 5.3 - 12.7 Coreset 3 - 10 0.02 - 0.76 Table 1: Accuracy trade-off of different compression techniques: Low-dimensional data loses important fea- tures under lossy compression, dropping inference ac- curacy significantly compared to the original data. De- tails on Coreset are available on Section 4. (Notations used: DCT: Discrete Cosine Transform, DWT: Discrete Wavelet Transform.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "Fortunately, there already exist a large body of techniques which can track the eye movements efficiently (e.g., see [ 26 ] and [ 12 ] and the references therein). In this work, we chose to use the NVGaze technique [ 26 ] to perform eye tracking for the  Inter-Holo  design due to two main reasons. First, it provides sufficient accuracy for the AR applications ‚Äì as high as 2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level. Throughput model  Achieving the maximal computation progress under the harvested energy has two implications. The Ô¨Årst one is that we expect more energy can be used for program progress.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Fig. 1 illustrates the data flow in an edge server, where video data are first encoded (using H264 or similar codecs), then encrypted (with RSA or similar standards), and finally stored across a distributed set of disks to ensure redundancy (e.g., RAID 5). These processes create a complex data-flow pipeline, differentiating two streams of video data: one for real-time inference and training, and another for archival.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "5117‚Äì5124, 2019. [4] J. Wu, C. Leng, Y. Wang, Q. Hu, and J. Cheng, ‚ÄúQuantized Convo- lutional Neural Networks for Mobile Devices,‚Äù in  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2016, pp. 4820‚Äì4828.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "The tail latency (measured at P99) for  DProb almost exceeds the SLO, whereas it does so for  SProb . Kraken manages to avoid high tail latency by assigning augmented weights to key functions, thus, helping it tolerate incorrect load/probability estimations. SProb  does worse than  DProb  at the tail because of its lack of adaptive probability estimation.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "[82]  Carole-Jean Wu, David Brooks, Kevin Chen, Douglas Chen, Sy Choud- hury, Marat Dukhan, Kim Hazelwood, Eldad Isaac, Yangqing Jia, Bill Jia, et al. Machine learning at facebook: Understanding inference at the edge. In  2019 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 331‚Äì344.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "It is observed from our failure- resilience results that  Cocktail  can adapt to instance fail- ures by limiting the accuracy loss within 0.6%. 2 Background and Motivation \nWe start by providing a brief overview of model-serving in public cloud and ensembling, followed by a detailed analysis of their performance to motivate the need for  Cocktail . We show that ensemble models are inherently fault- tolerant over single models, since in the former, failure of a model would incur some accuracy loss without complete failure of the requests.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "In  2020 IEEE International Conference on Smart Computing (SMARTCOMP) , pp. Analytics-aware storage of surveillance videos: Implementation and optimization. Min-Han Tsai, Nalini Venkatasubramanian, and Cheng-Hsin Hsu.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Set a diminishing step-size schedule  { Œ± k } k ‚â• 0 . 2:  for  each training round  k  = 0 ,  1 ,  2 , . .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "4:  Set  Œ∑ 0  > Œ¥ 0 . 2:  Compute  e max total   =  e max cap   +  e inf   +  e comm . 3:  Ensure baseline feasibility: If  Œ≥ 0  ¬∑  ‚àÜ A min  ‚â§ Œ¥ 0  +  e max total   , increase  Œ≥ 0  until this condition is met.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Note that the tail latency of  Clipper  is still higher than  Cocktail  because  Clipper ensembles more models than  Cocktail , thereby resulting in straggler tasks in the VMs. The difference in latency between Cocktail  and  InFaas  is lower for  Relaxed  workload when compared to  Strict  workload (20% lower in tail). Since the Relaxed  workload has much lower accuracy constraints, smaller models are able to singularly achieve the accuracy requirements at lower latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "V. E VALUATION \nTargeting the object detection task on edge devices, we compare our proposed frame-level scheme ( Full-Inference  and Skip-Inference , i.e., FI+SI) and region-level scheme ( Full- Inference ,  Skip-Inference  and  Partial-Inference , i.e., FI+SI+PI) against the  baseline inference , which performs full infer- ence on every frame, as well as four state-of-the-art runtime techniques (DeepCache [8], Euphrates [9], Potluck [12], and MCDNN [7]), by quantifying the normalized execution time, energy consumption, and accuracy (mean Average Precision, \nmAP). 7: The proposed frame-level reuse and tile/region-level reuse design blocks implementation; BB/BBox: bounding boxes from the last FI; MV: motion vectors of the current frame; FM: feature maps for each layer from the last FI. We Ô¨Årst describe the design conÔ¨Ågurations, experi- mental platform, datasets, and measurement tools used in this work, and then analyze the collected results.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 263,
    "augmented": true
  },
  {
    "text": "In each inference event, sensors decide whether to partic- ipate. If sensor  s i  participates at time  t , it must capture data at a chosen Signal-to-Noise Ratio (SNR), process the data using  f Œ∏ , and transmit the result to a designated  lead sensor . High-SNR data capture improves the sensor‚Äôs con- tribution to global accuracy but consumes more energy.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "[68]  Haibo Zhang, Prasanna Venkatesh Rengasamy, Shulin Zhao, Nachiappan Chi- dambaram Nachiappan, Anand Sivasubramaniam, Mahmut T. Kandemir, Ravi Iyer, and Chita R. Das. In  Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications . 106‚Äì111.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "the baseline, as shown in Fig. On the other hand, the YOLOv4-tiny inference with the FI+SI scheme saves  53%  energy w.r.t. 9a.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "2 ) to measure their difference: \nDi f f ( I block , P block ) =  ‚àë K i = 1 ( r iP  ‚àí r iI ) 2  +( g iP  ‚àí g iI ) 2  +( b iP  ‚àí b iI ) 2  (2) \nwhere  P block  =  { ( x iP , y iP , z iP , r iP , g iP , b iP ) } ,  I block  =  { ( x iI , y iI , z iI , r iI , g iI , b iI ) } , for  i  =  { 1 ,..., K } . Note that, the BM can be performed in parallel as there is no dependence across blocks. Reuse:  for blocks for which the reference blocks are similar enough (e.g., the 2-norm differences are less than the pre- deÔ¨Åned thresholds), only the pointers to their reference blocks will be recorded (in our proposal, for each P-block, we set the number of candidate blocks as 100, thus, 6 bits are sufÔ¨Åcient for encoding one P-block).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 304,
    "augmented": true
  },
  {
    "text": "We observe that, with representation learning, Us. ¬¥as  is  ‚âà 4 . ¬¥as uses a 2 level exemplar selection algorithm (one using the conÔ¨Ådence matrix, and then further reÔ¨Åned by the representa- tion learning).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "No. Video #Frames #Obj/Frame Distance ObjSize 1 bike[38] 150k 1.1 2.08m 1.54m 2 book[39] 576k 1.5 0.64m 0.28m 3 bottle[40] 476k 1.1 0.47m 0.22m 4 cup[41] 546k 1.6 0.47m 0.16m 5 laptop[42] 485k 1.3 0.58m 0.38m 6 shoe[43] 557k 2.3 0.65m 0.21m \n5.1 AR Hologram Configurations \nWe evaluate the following five configurations of AR holo- gram processing to demonstrate the effectiveness of our proposed HoloAR : ‚Ä¢  Baseline (Viewing-Window):  Similar to the recent viewing- window based sub-hologram optimization [ 52 ], we first obtain the field of view or the current viewing window from the user‚Äôs head orientation, and then skip the computations of the objects, which are outside the viewing window (i.e., only compute for the objects located inside) to save computations and energy. This software-based viewing window optimization is considered to be the state-of-the-art at an algorithm level, and we refer to it as Baseline  in this study.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 273,
    "augmented": false
  },
  {
    "text": "It can be seen that although both  util_aware  and  exascale  can reduce SLO vi- olations (shown in Figure  5 ), they still suffer from 20% to 30% over-provisioned VMs across all four traces. This, in turn, increases the cost of deployment (shown in Figure  5 ), compared to baseline  reactive  scheme. WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands J.R. Gunasekaran, et al.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "iii  Entering/Exiting Object(s) : Another scenario is where one or more objects are moving into or out from a frame (refer Frame-2 in Fig. Frame-2 needs to be carefully processed and full inference needs to be employed, as indicated by  4  in Fig. 3b.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "[10]  C. Choy, J. Gwak, and S. Savarese, ‚Äú4d spatio-temporal convnets: Minkowski convolutional neural networks,‚Äù in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. [11]  A. Corning, ‚ÄúAR/VR in the OR ‚Äì Surgical Applications of Augmented and Virtual Reality,‚Äù  ‚Äùshorturl.at/fqwAJ‚Äù , 2021. [9]  Charles Thomson, ‚ÄúReality capture 101: point clouds, pho- togrammetry and LiDAR,‚Äù  ‚Äùhttps://bit.ly/3xfqvqy‚Äù , 2019.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "Looking ahead, the role of storage systems is poised to become even more pivotal as ML applications continue to evolve and generate larger, more complex datasets. In summary, our research presents a comprehensive vision for the future of storage systems in ML, where computational storage \n17 \ndevices play a key role in advancing the, performance, efficiency, and capabilities of storage servers, thereby contributing significantly to the broader field of ML. The ongoing innovation in the design and optimization of CSDs will be crucial in meeting these challenges.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "These technologies have become an important part of our daily life, in the form of creative photography, content creation, gaming, online shopping, virtual touring, and educational and non-educational training, etc. For ex- ample, one of the earliest AR games, Pok√©mon GO (launched in July 2016), had a cumulative download of over 1 Billion, and gener- ated about $900 Million in revenue by late 2019 1 . Moreover, these AR infotainment applications have helped many of us through the recent global pandemic by bringing us the liveliness of the virtual outdoors, while we were confined to our homes, and more AR capa- ble mobile devices penetrating the market with cheaper price tags have made AR applications pervasive and made the virtual world easily accessible for users on the tip of their fingers.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 182,
    "augmented": false
  },
  {
    "text": "Acknowledgments \nWe are indebted to our shepherd Manya Ghobadi, the anony- mous reviewers and Anup Sarma for their insightful com- ments to improve the clarity of the presentation. Special mention to Nachiappan Chidambaram N. for his intellec- tual contributions. This research was partially supported by NSF grants #1931531, #1955815, #1763681, #1908793, #1526750, #2116962, #2122155, #2028929 ,and we thank NSF Chameleon Cloud project CH-819640 for their generous compute grant.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "1  a  ). The received frame is decoded in the  PC Decoding  stage and the decoded PC frame is forwarded to the  Render and Display  stage where it is Ô¨Ånally rendered and displayed on the screen. Note that although the same method is followed and has been well established for streaming  2 D  or  360 ¬∞ videos, given that the PC data is much denser, compression becomes essential as well as the primary bottleneck, often taking several seconds to compress one PC frame [ 26 ](see Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "It is imperative for these applications to deliver accurate predic- tions at sub-millisecond latencies [ 27 , 34 , 35 , 39 , 44 , 83 ] as they critically impact the user experience. This trend is expected to perpetuate as a number of applications adopt a variety of ML models to augment their services. These ML models are typically trained and hosted on cloud platforms as service end- points, also known as  model-serving  framework [ 6 ,  28 ,  60 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Towards this, in the future, we plan to explore GPU-speciÔ¨Åc \n295 \nAuthorized licensed use limited to: Penn State University. 2 s  to  121 ms ) and  96%  improvement in energy efÔ¨Åciency, with only  13%  compression ratio drop and a minimal degradation in video quality with respect to the state-of-the-art schemes. Note however that, even with our proposals, the execution latency per PC frame is still slightly beyond the real-time requirement (i.e.,  ‚â• 100 ms ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle. Fortunately, there exist opportunities to keep and transfer the intermediate computation results of the last incomplete inference to the next power cycle. Considering a transition \nfor one layer from an activation solution  ‚ü® m 1 , n 1 , aG 1 ‚ü© to ‚ü® m 2 , n 2 , aG 2 ‚ü© , we Ô¨Ånd that, if the expression  Condition trans : ( m 1 =  m 2)&( n 2  |  ( Tile count 1   √ó  n 1))&( aG 1 =  aG 2) is true for each convolution layer, the activation solution ‚ü® m 1 , n 1 , aG 1 ‚ü© with power level PL1 can be transferred to be equivalent to an execution of activation solution  ‚ü® m 2 , n 2 , aG 2 ‚ü© with PL2.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 233,
    "augmented": false
  },
  {
    "text": "Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency. In  USENIX Middleware Conference . [5]  J. R. Gunasekaran, P. Thinakaran, et al .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "We present a detailed analysis of data movement challenges within the archival workflows and demonstrate how the strategic integration of CSDs can significantly optimize data compression, encryption, as well as other data management tasks, to improve overall system performance. By leveraging the parallel processing capabilities of FPGAs and the high internal bandwidth of SSDs,  Salient Store  reduces the communication latency and data volume by  ‚âà 6 . 2 √ó  and  ‚âà 6 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Kite: A family of hetero- geneous interposer topologies enabled via accurate interconnect modeling. [19] Srikant Bharadwaj, Jieming Yin, Bradford Beckmann, and Tushar Krishna. ACM SIGPLAN Notices , 53(2):43‚Äì55, 2018.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Similarly, for the next frame,  Frame-II , now the user lifts her head a bit, hence the corresponding viewing window changes from the previous one. Because of this, now the  football  is partially located in the viewing window, and requires computing (only for the bottom right part that is inside the viewing window). Note also that, since the  soccer ball  hologram has been already generated in Frame-I , we can skip its computation.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "existing policies such as  Arch  and  Fifer  exhibit similar perfor- mance and resource usage when their prediction models and keep-alive times are similarly adjusted. Xanadu , on the other hand, while having 0.74 memory-resident containers per sec- ond, suffers from 55% SLO Violations on average across all applications as a result of MLP mispredictions whose effects are exacerbated in this scenario, due to low request volume. Varying SLO:  Table 7 shows the SLO guarantees and num- ber of containers spawned for existing policies as well as Comm Only  and  Conn Only , when the SLO is reduced from 1000ms to a value 30% higher than the response time of the slowest workflow in each application.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 172,
    "augmented": false
  },
  {
    "text": "2020. [2]  Marc Brooker, Andreea Florescu, Diana-Maria Popa, Rolf Neugebauer, Alexandru Agache, Alexandra Iordache, Anthony Liguori, and Phil Piwonka. Firecracker: Lightweight Virtualization for Serverless Applications.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Image and video compression with neural networks: A review. IEEE Transactions on Circuits and Systems for Video Technology , 30(6):1683‚Äì1698, 2019. Vikram Sharma Mailthody, Zaid Qureshi, Weixin Liang, Ziyan Feng, Simon Garcia De Gonzalo, Youjie Li, Hubertus Franke, Jinjun Xiong, Jian Huang, and Wen-mei Hwu.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "CoRR , abs/2104.08378, 2021. Accelerating sparse deep neural networks. [110] Asit K Mishra, Narayanan Vijaykrishnan, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "The size of the circle representing the solutions de- picts the compute capabilities of the sensor nodes, the shade shows the available power, and their position on the axes approximates the amount of compute done on the node and the amount of reliability on external communication. The power source is denoted in  (Red) (notations used in Figure 1b: COTS: Commercial-off- the-shelf, Bat. : Battery, Bonito [ 22 ], Chinchilla [ 43 ], ResiRCA [56], Origin [47]) \ncompute are not energy efficient to run with all modali- ties of harvested energy since all of them do not have the same energy income (see Figure 1b).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "5b), limiting the memoization opportunities to those instances. Such low reuse ratio is expected because of the high sensitivity of the IMU sensors. However, a higher reuse ratio can be achieved by relaxing the precision of the IMU output.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "(Eds.). International Society for Optics and Photonics, SPIE, 144 ‚Äì 152. In  Practical Hologra- phy XXX: Materials and Applications , Hans I. Bjelkhagen and V. Michael Bove Jr.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "The improvements in energy efficiency are due to NExUME‚Äôs ability to adjust computational workload dynamically, minimizing energy wastage and ensuring that computa- tions are matched to the available energy budget. NExUME, thanks to its inherent learnt adaptability, significantly reduces saves, restores, reconfigurations and READ/WRITE from/to nonvolatile memory or to the flash memory in the cases and devices where NVMs are not present which gives it edge over the baselines across multiple devices. Discussion of Results:  1.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "uses the  Intra-Holo  scheme (denoted  c  ), to identify the number of depth planes required for a particular object by analyzing the rela- tive camera-to-object distance as well as the shape/size of the target object. Figure 6: The proposed  HoloAR  which includes  Inter-Holo leveraging foveated rendering, and  Intr-Holo  further ap- proximating holograms for far objects. Note that, both the  Inter-Holo  and the  Intra-Holo  schemes are complementary to each other, when both the eye tracking and pose estimation inputs are available at the same time.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "The parameter  Œ∑ >  0  penalizes non-participation, ensuring that sensors do not remain idle indefinitely. If Œ≥  is too high, sensors may waste energy attempting difficult inferences. The parameter  Œ¥ >  0  penalizes incorrect in- ferences, discouraging reckless submissions of low-quality data.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "In  2012 IEEE conference on computer vision and pattern recognition , pp. 3354‚Äì3361. IEEE, 2012.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "Spock: Exploiting Serverless Functions for SLO and Cost Aware Resource Procurement in Public Cloud. In  2019 IEEE 12th Interna- tional Conference on Cloud Computing (CLOUD) . 199‚Äì208.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "First, feasible implementations of Ô¨Çexible activation options require a low power and reconÔ¨Ågurable RCA. Second, a dynamic loop tiling strategy alongside a coordinated parallelism scheme should be devised to match execution power consumption as closely as possible to power income to maximize efÔ¨Åciency. This section addresses the Ô¨Årst of these challenges, and Section V discusses our approach to the second.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Fuse multiple ‚ÄòQuantaTask‚Äòs to minimize load/store operations. 4. Check for sufficient energy before launching a ‚ÄòQuantaTask‚Äò.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "0 500 1000 1500 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers \nNGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network. 0 500 1000 1500 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers NGINX ID Movie_ID Text User_Service Rating Compose_Review Movie_Review User_Review Review_Storage \n(b) Media Service. 0 200 400 600 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers \nNGINX Check_Reservation \nGet_Profiles Search \nMake_Reservation \n(c) Hotel Reservation.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "¬¥as  delivers 4.96% more accurate classiÔ¨Åcation compared to a na¬®ƒ±ve learner, and the morphable hardware design uses intermittent computing to maintain forward progress even while running on lower power budget. Together,  Us. ¬¥as  can save up to 200lbs of  CO 2  per year compared to a state of the art accelerator running on the grid.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "[57]  Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Association for Computing Machinery. Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "[86]  Z.-R. Wang, C.-G. Yang, and S.-L. Dai, ‚ÄúA fast compression framework based on 3d point cloud data for telepresence,‚Äù  Int. J. Autom. [85]  Vision Lab, Nanjing University, ‚ÄúMultiscale Point Cloud Geometry Compression,‚Äù  ‚Äùhttps://bit.ly/3xiAxah‚Äù , 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "ACKNOWLEDGMENTS \nThis research is supported in part by NSF grants #1763681, #1629915, #1629129, #1317560, #1526750, #1714389, #1912495, and #1909004. This work was also supported in part by CRISP, one of six centers in JUMP, a Semiconductor Research Corporation (SRC) program sponsored by DARPA. We would also like to thank Dr. Jack Sampson and Dr. Dinghao Wu for their feedback on this paper.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "Towards information-theoretic k-means clustering for image indexing. Signal Processing , 93(7):2026‚Äì2037, 2013. 18 \nWei Cao, Yang Liu, Zhushi Cheng, Ning Zheng, Wei Li, Wenjie Wu, Linqiang Ouyang, Peng Wang, Yijing Wang, Ray Kuan, et al.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Such invariances are leveraged as reuse opportunities to reduce the compute-heavy projection computation. ‚Ä¢  We design two complementary schemes to capture both temporal and spatial reuse opportunities. We propose a memoization scheme, called  EA , to capture recent head orientation data for temporal reuse, and for the spatial reuse, we design the  AE  scheme, which leverages the stationary relationship between two eyes to efÔ¨Åciently reduce the amount of projection computation.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "3. Energy Variability Awareness:  By integrating energy profiles directly into the training process, NExUME ensures that the model learns to handle fluctuations in energy supply, leading to more robust performance compared to methods that do not consider energy variability during training. Efficient Scheduling:  DynInfer‚Äôs energy-aware task scheduling and task fusion mechanisms reduce overhead from checkpointing and optimize the execution of tasks within \n8 \nthe available energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "The clusters offer researchers HPC and GPU con- figuration 9both A 100 and H 100)agility to target highly specialized use-cases. Researchers currently share approximately 105TB of NAS storage. The department operates its own firewall infrastructure using Palo Alto, Cisco, and Sonicwall products.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "CONTaiNER: Few- shot named entity recognition via contrastive learning. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 6338‚Äì6353, Dublin, Ireland, May 2022. Association for Com- putational Linguistics.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "[181] Nan Zhang, Yanchi Liu, Xujiang Zhao, Wei Cheng, Runxue Bao, Rui Zhang, Prasenjit Mitra, and Haifeng Chen. In Kevin Duh, Helena Gomez, and Steven Bethard, editors,  Findings of the Association for Computational Linguistics: NAACL 2024 , pages 1417‚Äì1428, Mexico City, Mexico, June 2024. Pruning as a domain-specific LLM extractor.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "In the direction of fault tolerance, there are works on various checkpointing [102, 162] strategies so that system gracefully comes out of failure with minimum loss of progress. Our approach con- siders the mentioned state-of-the-art optimizations and on top of that exploits the natural affinities among experts, routers, composition functions, data, and hardware to synergistically boost training/inference. LLM Hardware and Accelerators:  These sophisticated system level strategies require the use of equally high-performing hardware to complement for faster, efficient and economic implementation for both train- ing and inferring from these models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "[10]  Azure. Google Preemptible VMs., February 2018. https://cloud.google.com/preemptible-vms . Machine Learning as a Service., February 2018. https://azure.microsoft.com/en-us/pricing/details/machine-learning- service/ .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "3%  accuracy drop, then  21% more energy can be saved (amounting to  77%  energy reduction compared to the baseline). A similar trend can also be observed in V2, as shown in Fig. 10(b).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "[65] D. Zhou, S. Wang, H. Sun, J. Zhou, J. Zhu, Y. Zhao, J. Zhou, S. Zhang, S. Kimura, T. Yoshimura, and S. Goto, ‚Äú14.7 a 4gpixel/s 8/10b h.265/hevc video decoder chip for 8k ultra hd applications,‚Äù in 2016 IEEE International Solid-State Circuits Conference (ISSCC) , 2016, pp. 266‚Äì268. [66] Y. Zhu, A. Samajdar, M. Mattina, and P. Whatmough, ‚ÄúEuphrates: Algorithm-SoC Co-design for Low-power Mobile Continuous Vision,‚Äù in  Proceedings of the International Symposium on Computer Architec- ture (ISCA) , 2018, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 200,
    "augmented": false
  },
  {
    "text": "immersive telepresence, telemedicine, video streaming etc., needs the attributes to be stored along with the 3D coordinates. Figure 1: Example PC applications and processing pipelines. Since PC generation requires sophisticated instruments like LiDAR or 3D cameras, it was typically done on server- class computers with high compute and storage capabilities.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "[15] T. Yang, Y. Chen, and V. Sze, ‚ÄúDesigning energy-efÔ¨Åcient convolutional neural networks using energy-aware pruning,‚Äù in  CVPR . IEEE, 2017. [16] A. Reiss and D. Stricker, ‚ÄúIntroducing a new benchmarked dataset for activity monitoring,‚Äù in  ISWC .",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "We have 10 (therefore N = 10) such models and among them the least accurate model is MobileNetV1 (accuracy 70%, therefore a = 0.70). We need to Ô¨Ånd the probability of at least 6 of them being correct. Using the equation above we Ô¨Ånd the probability to be \nP head  = 10 ‚àë i = ‚åä 10 \n2   ‚åã + 1 = 6 \n\u0012 10 i \n\u0013 0 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Developers also need to indicate the primary ob- jective between these two constraints. Cocktail  automatically \nDataset Application Classes Train-set Test-set ImageNet [ 29 ] Image 1000 1.2M 50K CIFAR-100 [ 50 ] Image 100 50K 10K SST-2 [ 72 ] Text 2 9.6K 1.8K SemEval [ 66 ] Text 3 50.3K 12.2K \nTable 5:  Benchmark Applications and datasets. chooses a set of single or ensemble models required to meet the developer speciÔ¨Åed constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "1  a  ). Related Work \n1) Point Cloud Use-cases:  Recently, PC is being widely used in various Ô¨Åelds, such as AR/VR [ 46 ], [ 81 ], telepres- ence [ 43 ], [ 57 ], [ 86 ], virtual tourism [ 12 ], [ 50 ], teleopera- tion [ 83 ], telemedicine [ 51 ], video streaming [ 24 ], [ 37 ] and gaming [ 81 ], [ 87 ], etc. B.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "As data and model dimensions decrease, the hardware assistance‚Äôs impact becomes more pronounced, making  Us. Us. ¬¥as  excels as a candidate for continuous learning at all scales due to the hardware‚Äôs adaptability to varying data and model sizes.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "To search for the best architecture for the given intermittent environ- ment, DynNAS utilizes the approach proposed by iNAS (Mendis et al., 2021). Our innovation lies in the integration of energy variability awareness directly into both the training and inference processes, enabling dynamic adaptation to real-time energy conditions, which is not addressed by existing methods (Mendis et al., 2021; Yen et al., 2023, 2022; Montanari et al., 2020; Islam & Nirjon, 2019). While each component can individually optimize DNNs for intermittent environments, their combination yields the best results.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "These data are can then be moved to a central facility where they can be further treated for efficient retrieval ans on demand streaming. Urban Mobility ‚Äì A Case Study in Continuous Learning:  To thoroughly understand this data flow, let us examine ‚Äúurban mobility‚Äù, a prevalent continuous learning task (Bhardwaj et al., 2022). This task dynamically adapts to changing traffic patterns and environmental conditions.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "o information. When inserting the Ô¨Årst  P 0  point into the bounding box and the octree, two actions are taken: (1) expanding the bounding box with a step-size of  2 n , where n  =  1 , 2 , 3 , ¬∑¬∑¬∑ , until  P 0  is wrapped inside the bounding box. In this case, the side length of the bounding box cube becomes 2 , and now  P 0  is located inside the bounding box.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Furthermore, the AASR poses negligible overhead both in terms of compute and memory. The idea of making the ensemble task activity aware has similarities to weighted majority voting, where we assign weights to the individual learners participating in the ensemble, such that a higher accuracy classiÔ¨Åer contributes more weight towards the Ô¨Ånal result. Our goal is to develop an activity aware ensemble technique which can further improve accuracy, when compared to AASR.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Dur E Shahwar Kundi, Song Bian, Ayesha Khalid, Chenghua Wang, M√°ire O‚ÄôNeill, and Weiqiang Liu. Axmm: Area and power efficient approximate modular multiplier for r-lwe cryptosystem. In 2020 IEEE International Symposium on Circuits and Systems (ISCAS) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "In  2020 IEEE International Conference on Smart Computing (SMARTCOMP) , pp. 25‚Äì32. IEEE, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "Since processing these critical regions is in general much lighter-weight than processing a whole frame due to smaller size and less computation, the proposed partial inference is able to minimize the unnecessary computation (on the background/unimportant regions), thereby further speeding up the inference and reducing the energy consumption. ‚Ä¢  Next, we propose a tile-level inference scheme to enable the region/tile reuse by identifying the critical regions. In order to maintain high accuracy, we also propose an adaptive technique to dynamically adjust the reuse window size based on the runtime statistics by comparing the MVs in consequent frames.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "The time taken to spawn new VM takes about 60s to 100s de- pending on the size of the VM instance. The time taken to choose models from the model-cache is less than 1ms. The end-to-end response time to send the image to a worker VM and get the prediction back, was dominated by about 300ms (at maximum) of payload transfer time.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Accelerating hpc applications using computational storage devices. In  2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS) , pp. 1878‚Äì1885, 2019a.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "The data lineage information will also help the project to reduce its ‚Äústorage footprint‚Äù. More specifically, instead of storing all versions of each and every dataset and model we generate, we can only store the most important ones and, for the remaining ones, the data lineage information (a kind ‚Äúmetadata‚Äù) can be used to re-generate them, if/when needed. Collaboration Plan \nProject Team \nThe proposed project spans design and analysis of LLM and expert models, characterization and evaluation of such models, development of compiler and runtime system support for efficient LLM/expert training and inference as well as chiplet selection for LLM/expert execution.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Figure 1a shows the basic building blocks of an energy har- vesting sensing/computing unit. The harvested energy is \n2 \ntypically stored in either an intermediate storage like a (su- per) capacitor [ 22 ], or used for charging. For building scalable and sustainable infrastructure of battery-free EH-WSNs, the former is more feasible and will be our focus for this work.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "John Wiley & Sons. Holographic Imaging . [4]  Stephen A Benton and V Michael Bove Jr. 2008.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "It offers high-resolution sensor data, including LIDAR and camera recordings, across a variety of urban and suburban landscapes. This data-set‚Äôs volume and diversity make it an excellent benchmark for assessing  Salient Store  ‚Äôs capabilities in handling large-scale, real-world data. For 3D point cloud data, we selected the  KITTI Vision Benchmark Suite  (Geiger et al., 2012), a fundamental data-set in autonomous driving research.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "[3] Exploring llms - real-world case studies in ai-generated art & literature. [2] NVIDIA H100 Tensor Core GPU, 2023. https://www.nvidia.com/en-us/data-center/ technologies/hopper-architecture/ . References \n[1] NVIDIA A100 Tensor Core GPU., 2023.  https://www.nvidia.com/en-us/data-center/ a100/ .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "For exam- ple, to store/transmit these two arrays,  4 bytes √ó 16 = 64 bytes are needed. However, even without any compression, we only need  4 bytes √ó 3 √ó 3 = 36 bytes  to represent these 3 points. Therefore, an extra post-processing step is needed to merge these two arrays in the ‚Äúoccupy bits‚Äù style.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "This paper pro- vides a comprehensive overview of the potential of CSDs to revolutionize storage, making them not just data repositories but active participants in the computational process. 1 Introduction \nVideo analytics, powered by deep neural networks (DNNs) has become the key component of multiple applications including but not limited to autonomous driving (Brown et al., 2023; Fang et al., 2023; Huang et al., 2023), urban mobility (Corporation; Custom On-Device ML Models with Learn2Compress), surveillance and monitoring (Bozcan & Kayacan, 2020; Dutta & Ekenna, 2019; Pichierri et al., 2023), video streaming and conferencing (Dasari et al., 2022b; Cheng et al., 2024; Sivaraman et al., 2024), telemedicine (Wan et al., 2020), and tourism (Zhu et al., 2024; Pierdicca et al., 2021; Godovykh et al., 2022). While some of these applications rely on collecting the video data and processing them offline, many need real-time analytics for the seamless integration, operation and effectiveness of the task at hand (Bramberger et al., 2004; Apostolo et al., 2022; Grulich & Nawab, 2018).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 334,
    "augmented": false
  },
  {
    "text": "5 J energy, respectively, which translate to  ‚âà 97%  energy savings w.r.t. TMC13, while our Intra- Inter-V1 and Intra-Inter-V2 only consume  0 . 52 J  and  0 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Finally,  HoloAR \n499 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \n(a) Viewing-Window scenario [52]. (b) Inter-Holo scenario. (c) Intra-Holo scenario.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Energy and Buildings , 140:81‚Äì97, 2017. Data driven prediction models of energy use of appliances in a low-energy house. [4] Heiner Lasi, Peter Fettke, Hans-Georg Kemper, Thomas Feld, and Michael Hoffmann.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "[43]  Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, ‚ÄúGradient-based learning applied to document recognition,‚Äù  Proceedings of the IEEE , vol. 86, pp. 2278‚Äì2324, Nov 1998.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Our Ô¨Årst objective function ( O 1 ) is to the maximize  ¬µ AL  such that target accuracy ( Acc target ) is reached within the target latency ( Lat target ). max ¬µ AL  : \u001a Acc target  ‚â• Acc target  ¬± Acc margin Lat target  ‚â§ Lat target  ¬± Lat margin \nTo solve  O 1 , we determine an initial model list by choosing the individual models satisfying  Lat target  and then create a probabilistic ensemble that satisÔ¨Åes the  Acc target . Cocktail takes the accuracy of each model as a probability of cor- rectness and then iteratively constructs a model list, where the joint probability of them performing the classiÔ¨Åcation is within the accuracy target.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "0 \n20 \n40 \n60 \n80 \nPercentage \nModel Type \n(a)  Different accuracy for ISO- latency. 0 \n200 \n400 \n600 \n800 \n1000 \nTime(ms) \nModel Type \n(b)  Different response latencies for ISO-accuracy. Figure 2.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "E. Sensitivity Study \nOur proposed intra-frame PCC utilizes the Morton code to capture the spatial locality, and signiÔ¨Åcantly speeds up the compression ( 44 √ó ), with high compressed quality (48.5 dB PSNR). To study how the inter-compressed frames/blocks would affect the compression efÔ¨Åciency (the compressed size w.r.t. Additionally, by exploiting the temporal locality across frames, our inter-frame compression further increases compression efÔ¨Åciency with the cost of longer processing latency and lower quality.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "VII. Although, these techniques can potentially save memory usage/energy for  360 ¬∞ VR videos, as discussed in earlier sections, due to inherent nature of  360 ¬∞ video processing, which introduces additional overheads for projection computation, we identify compute  to be the major energy bottleneck. Hence, these memory optimizations are not applicable to reduce compute energy on  360 ¬∞ VR videos.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "3) matter only during data transfer (from the input 360 ¬∞ frame to the framebuffer) in the projection mapping stage, after the coordinate mappings ( P  in Fig. 3) are gener- ated. Potentially, content-based optimizations (e.g., content cache [63]) can beneÔ¨Åt the data transfer; however, they are not attractive candidates to leverage compute reuse, which is the major power-hungry stage (as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Under review. arXiv:2408.13696v2  [cs.LG]  26 Jan 2025 \n(NAS) (Yang et al., 2018, 2017; Mendis et al., 2021), there is no guarantee that the energy income con- sistently meets or exceeds this average. When the income falls below the threshold, the system halts the inference and checkpoints the intermediate states (via software or persistent hardware) (Maeng & Lucia, 2018; Qiu et al., 2020), resuming upon energy recovery.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "1073‚Äì1084, 2022b. doi: 10.1109/ICDCS54860.2022.00107. Hang Yue, Laurence R Rilett, and Peter Z Revesz.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Swift: Adaptive video streaming with layered neural codecs. Mallesham Dasari, Kumara Kahatapitiya, Samir R Das, Aruna Balasubramanian, and Dimitris Samaras. (Accessed on 11/21/2022).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solution m,n,aG  wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,P load ,P comp andP store ,andtheyareperformed insequence. 1)Loadandstore: P load and P store   denotethepower consumedbyloadingthedatafromthepureReRAMmem- oryintotheinputregistersandstoringthedatafromthe outputregistersintotheReRAM memory . P load = aG√ó (Bits input /BN in )√óP ld‚àíbit   modelsloadpoweroperation.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 208,
    "augmented": false
  },
  {
    "text": "‚Ä¢  AE:  For those head orientations not memoized, we further exploited the  spatial compute reuse  across eyes within a frame. 9. In the proposed  AE  scheme, one can observe that for the left-eye computation, the energy consumption is the same as in the  Baseline .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "(2019), A74‚ÄìA81. [18]  Jisoo Hong, Youngmin Kim, Hyunjoo Bae, and Sunghee Hong. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Gshard: Scaling giant models with conditional computation and automatic sharding. arXiv preprint arXiv:2006.16668 , 2020. [89] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "We also compare our work against two reconÔ¨Ågurable platforms [ 15 ], [ 63 ]. Power Aware Scaling: The  Us. ¬¥as  hardware‚Äôs most important feature is its ability to  morph  according to power availability.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "‚Ä¢  In  AA , the input and output mapping are unique, that is, no two input coordinates in  360 ¬∞ frame map to the same coordinates in the 2D FoV frame, thereby eliminating any compute reuse scope. Although, in principle, for computing the transformation for consecutive pixels, one can leverage data value similarity to reduce the computation, in this work we are not focusing on leveraging any such opportunity. ‚Ä¢  EE  offers little chance of reuse, and can only be leveraged in rare occasions, where we have oracular knowledge of head movements.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "[33]  Eric Jonas, Johann Schleier-Smith, Vikram Sreekanti, Chia-Che Tsai, Anurag Khandelwal, Qifan Pu, Vaishaal Shankar, Joao Carreira, Karl Krauth, Neeraja Yadwadkar, et al . In  Proceedings of the 21st International Middleware Conference . 280‚Äì295.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "com/learning-center/solar-insolation-maps.html/#Map1 , (Accessed on 11/21/2022). [91] N. A. W. . Sun, ‚ÄúUs solar insolation maps,‚Äù  https://www.solar-electric.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "[60]  Christopher Olston, Noah Fiedel, Kiril Gorovoy, Jeremiah Harmsen, Li Lao, Fangwei Li, Vinu Rajashekhar, Sukriti Ramesh, and Jordan Soyke. TensorÔ¨Çow-serving: Flexible, high-performance ml serving. In  Proceedings of the 27th ACM Symposium on Operating Systems Principles , pages 1‚Äì15, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Real-Time Spatio-Temporal LiDAR Point Cloud Compression. 2020. 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)  (2020), 10766‚Äì10773.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "class ] 23: end for 24: P class  ‚Üê max ( weighted _ vote , key  =  class ) 25: returnP class 26:  end procedure \n4.1.1 Class-based Weighted Majority Voting \nThe model selection policy described above ensures that we only use the necessary models in the majority voting. In or- der to increase the accuracy of majority voting, we design a weighted majority voting policy  3  . The weight matrix is designed by considering the accuracy of each model for each class, giving us a weight matrix of  L √ó N  dimension, where  L is the number of unique labels and  N  is the number of models used in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "A. First sensor at the chest, second on the right wrist and last sensor on the left ankle. Energy Harvester and Sensor Setup \nOur evaluation setup consists of three sensors at three dif- ferent locations.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "2.1 Serverless Function Chains (DAGs) Many applications are modeled as function chains and typically administered under strict SLOs (hundreds of mil- liseconds) [ 30 ]. Serverless function chains are formed by stitching together various individual serverless functions using some form of synchronization to provide the func- tionality of a full-fledged application. Function chains are supported in commercial serverless platforms such as AWS Step Functions [4, 23], IBM Cloud Functions [8], and Azure Durable functions [ 6 ].",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "[51] F. G. VR360, ‚ÄúVirtual guided tour of Paris.‚Äù ‚Äùhttps://www.youtube.com/ watch?v=sJxiPiAaB4k‚Äù, 2019. [52] Wikepedia, ‚ÄúEquirectangular Projection.‚Äù ‚Äùhttps://en.wikipedia.org/wiki/ Equirectangular projection‚Äù, 2019. [53] Wikipedia, ‚ÄúPixel 2,‚Äù ‚Äùhttps://en.wikipedia.org/wiki/Pixel 2‚Äù.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "based coresets can achieve an accuracy of  ‚âà 85%. The recon- struction feature at the host comes with little to no overhead for the host (given the host devices have considerably more compute than the sensor nodes). The addition of the recovery parameter (number of points per cluster) needs  4 more bits (in our experiments, we never observe any clusters having more than 16 data points) of data per cluster, bringing the total data communication volume to  42 Bytes , which is still a significant 5 .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "The distribution of the absolute differences (deltas) between the pixel values in successive frames plotted in Fig. 2b provide one such opportunity. It can be observed that, while the ‚Äúexact pixel match based similarity‚Äù is scarce at frame level, an alternate similarity based on the ‚Äúmagnitude of pixel differences‚Äù is abundant.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "to Ground Truth(G) \nPrecision \nReuseRatio PSNR \n(c) Precision vs. reuse ratio tradeoffs \nFig. 5: In  EA , (a) shows that, on average, how many frame(s) from the current frame to a previous one with the same head orientation, as denoted as reuse distance. This indicates two memoization buffers are sufÔ¨Åcient.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "the learner classiÔ¨Åed  ‚âà 4.5 frames/100-frames (on an average) as exemplar data. ¬¥as  on other applications, data modalities, and power environments. 10: Contribution of different components of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "ft., including desks with workstations and peripherals. List of Project Personnel and Partner Institutions \n1. Chitaranjan Das; Pennsylvania State University; PI 2.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "8 J , respectively, for one PC frame. This is mainly due to their long execution latencies. Further, as mentioned in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "of the scheduled training without any intermittency support. Restrictions apply. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "We propose a novel and efficient approach for continual learning of EoE. This strategy is particularly useful when we need a single model to handle diverse knowledge sources or when we aim to reduce training costs by first training smaller models and then combining them. We split a large expert into smaller, domain-specific experts, train them on focused domain- specific datasets, and then merge them back into a reinforced model.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "10th IEEE Real-Time and Embedded Technology and Applications Symposium, 2004. , pp. 174‚Äì181, 2004. doi: 10.1109/ RTTAS.2004.1317262. Barry Brown, Mathias Broth, and Erik Vinkhuyzen.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "2018. Bin-Packing. In  Combinatorial Optimization .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 14,
    "augmented": false
  },
  {
    "text": "Why Not the Usual Process? Now that we know Classical approach of video data storage involves encoding and encrypting the video data before storing them in a redundant storage array (Huang & Xu, 2014; Fan et al., 2022; Korkiakangas, 2014; Yue et al., 2016) which consumes significant resources (refer Table 1). Rather, storing the data in a compressed and encrypted format (with redundancies) is more efficient and therefore is the focus of our work.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "A. Computation decomposition and parallelism \nIf the harvested power  P   budget   is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress. With this design idea, the system can keep making forward progress over a large range of power incomes. Sections  V-A - V-C  develop a dynamic activation strategy for different power levels and Section  V-D discusses the transition strategy between dynamic activation solutions.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Furthermore, the design  needs to be programmable  to ensure encryption keys to be changed regularly for additional security. Solution Space and Our Work:  This paper proposes  Salient Store  , a novel storage solution designed for continuous learning edge servers by incorporating a hardware-software co-design framework that allows for efficient data archival and storage. Salient Store  utilizes the state-of- the-art neural compression which partially uses the inference/ exemplar selection pipeline along with layered neural codecs to compress the video data.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "It can be clearly seen that the computation time reduces with increased memory alloca- tion but also results in higher cost of deployment for every model type. Therefore, depending on the latency re- quirements of the user applications,  serverless functions  need to be allocated the appropriate memory. This is because, inherently, serverless providers allocate a powerful compute core for functions with higher memory allocation.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "[25] N. Global Monitoring Laboratory, ‚ÄúSolrad network,‚Äù  https://gml.noaa. IEEE, 2012, pp. 3354‚Äì 3361.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Apart from the above mentioned optimizations at the layer- level (DeepCache) and the frame-level (Euphrates), recall that, in Table I, we indicated (in the last column) the Decision Making Logic (DM) the previously proposed optimization strategies employ. Now, in Table IV, we present the mAP, latency and energy efÔ¨Åciency results with those prior schemes. Rather than capturing the reuse opportunities in raw input data, Potluck [12] Ô¨Årst extracts the feature vector (i.e., a vector generated from input image, such as SURF [47], HoG [48], Down-sampling [16], etc.)",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "Thus, compared to V1 and V2 whose latencies can be decreased by  62%  and  55%  respectively with FI+SI as shown in Fig. 8b, the latencies for GL1 and HC1 only decrease by around  38% , while the energy saving is about  37% , which is lower than the corresponding savings for V1 ( 59% ) and V2 ( 53% ). Additionally, even with our proposed PI technique, the improvements for GL1 and HC1 with YOLOv3 model are not very signiÔ¨Åcant (e.g., the latency reduction is improved by  4% for GL1 as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "Note that, we set the bidding price conser- vatively to 40% of OD. Although,  Cocktail  spawns about 50% more VMs than  InFaas , the high  P f  of small models and spot-instance price reductions combined with autoscaling policies lead to the overall 30-40% cost savings. 6.3 Sensitivity Analysis \nIn this section, we analyze the sensitivity of  Cocktail  with respect to various design choices which include (i) sampling interval of the accuracy measurements, (ii) spot-instance fail- ure rate and (iii) type of datasets and applications.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "6c retain the same ellipse behavior but different shapes. Furthermore, by exacting the x (or y) coordinate in the distance vector, the above  ellipse  pattern can be represented as  Œî x  =  a  ¬∑  cos ( Œ∏ )  and  Œî y  =  b  ¬∑  sin ( Œ∏ ) +  c , where  Œ∏  ‚àà [0 , œÄ ] , and  a, b, c  vary with head orientation change but remain same \nfor each row in the same frame. Additionally, there are few pixel positions at the frame edges which can only be viewed by one eye (denoted as  exclusive ), which cannot be captured by the above pattern.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Such similar performance demonstrates that our proposal is expected to work well for low-power edge devices like smartphones as well. D. Architectural Insights: \nIn this section, we further investigate the energy efÔ¨Åciency characteristics of the proposed optimizations by dissecting the total energy consumption for the inter-frame attribute compression proposal (which is the most time- and energy- \n294 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "VSS‚Äôs emphasis on video data optimization makes it a pertinent benchmark for assessing the  Salient Store  storage system‚Äôs capabilities in managing large-scale machine learning data-sets. This system has demonstrated significant improvements in VDBMS read performance, up to 54%, and a reduction in storage costs by up to 45% (Haynes et al., 2021). VSS excels in decoupling high-level video operations from storage and retrieval processes, efficiently organizing data on disk, enhancing caching mechanisms, and reducing redundancies in multi-camera setups (Haynes et al., 2021).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Although the spike-based scheme [ 5 ] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input/output data. For example, the total 168  Tiles  and one  IMA  element of the ISAAC architecture [ 3 ] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets. It can be seen that those designs are  not  suitable for an RCA supplied with harvested unstable power.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "In  Ambient Assisted Living and Daily Activities: 6th International Work-Conference, IWAAL 2014, Belfast, UK, December 2-5, 2014. Proceedings 6 , pp. 91‚Äì98.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Hence, to enhance the Ô¨Çexibility of our proposed design for trading off the compression efÔ¨Åciency with the quality, we can use the  percentage of ‚Äúdirect-reuse‚Äù blocks  as a  tunable design knob , for which, users can choose the appropriate value based on their preferences (i.e., fewer ‚Äúdirect-reuse‚Äù blocks with higher PSNR vs. more ‚Äúdirect-reuse‚Äù blocks with higher compression efÔ¨Åciency). VII. C ONCLUDING  R EMARKS \nPC processing has become the trend for many video applications spanning scientiÔ¨Åc computing, education, health- care and entertainment, and is recently being ofÔ¨Çoaded to the edge.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "To the best of our knowledge, this is the Ô¨Årst work that tries to enable DNN inference for human activity recognition in a distributed energy harvesting wireless sensor network by leveraging ensemble learning. SpeciÔ¨Åcally, Origin targets inherent features of sensor data from distributed body area networks in human activity recognition (HAR) tasks and leverages non- volatile processing, intelligent scheduling for energy-harvesting sensor nodes, and ensemble leaning to classify human activity with minimum accuracy loss compared to a state-of-the-art battery powered system. The paper makes the following key contributions: 1) We design a scheduling policy that chooses the salient sensor for performing the inference depending on the an- ticipated activity, i.e.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "Different from the three prior works discussed above, which mainly focus on one model, MCDNN targets a multi-model system and proposes a runtime scheduler to improve the accuracy as much as possible within a limited energy budget. We also tested this idea in our framework (with YOLOv3 [44] and YOLOv4-tiny [37] as the available models) and set \nthe energy budget for the scheduler to be the total energy consumption resulting from our approach. As can be seen from Table IV, MCDNN yields similar latency/energy savings with our approach, but with signiÔ¨Åcantly lower accuracy ( 36 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "AWS Lambda. Serverless Functions. https://aws.amazon.com/ lambda/.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "On the dan- gers of stochastic parrots: Can language models be too big? In  Proceedings of the 2021 ACM conference on fairness, accountability, and transparency , pages 610‚Äì623, 2021. [18] Maciej Besta, Syed Minhaj Hassan, Sudhakar Yalamanchili, Rachata Ausavarungnirun, Onur Mutlu, and Torsten Hoefler.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "The key components of the design are explained in detail below. 4.1 Dynamic Model Selection Policy \nWe use a window-based dynamic model selection policy using two objective functions as described below. Objective functions : In order to reduce cost and latency while maximizing the accuracy, we deÔ¨Åne a latency-accuracy metric ( ¬µ AL ) and cost metric ( ¬µ c ): \n¬µ AL  =   Acc target \nLat target ¬µ C  =  k  √ó N ‚àë m = 1 \ninst _ cost \nP f m \nwhere  N  is the number of models used to ensemble and inst _ cost  is the VM cost.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Metadata will most likely be needed as a part of curriculum development process and training. When needed, this material will be ported to other formats as well. These will be stored in XML and web formats.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "Input : C : Code Array;  P : Parent Array;  N : Number of Points \n1  Occupy Bits Array:  O  =  {} \n2  L  =  len ( C ) ‚àí N \n3  for  i in L  do \n4 p  =  P [ i ] \n5 O [ p ]  |  = ( C [ j ] %8 ) ,  P [ j ] =  p \nOutput :  O : Occupy Bits Array \nand energy savings, due to embracing more parallelism. 3) What are the BeneÔ¨Åts and Drawbacks? :  To summa- rize, compared to the prior schemes like PCL [ 72 ] and TMC13 [ 56 ], the most obvious beneÔ¨Åt from our proposal is the potential performance improvement in terms of latency \nAlgorithm 1:  Octree Occupy Bits Generation Algo.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 209,
    "augmented": true
  },
  {
    "text": "IV. DNN training is mas- sively parallel, fairly compute intensive, time consuming, and needs a lot of (albeit structured) data movements [ 16 ], [ 37 ]. T HE  MORPHABLE H ARDWARE \nWhy Not Commercial GP-GPUs?",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "10(b). These results indicate that our proposal is Ô¨Çexible/adaptive with different design preferences. D. Comparison against Prior Work \nAs discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "[24]  X. Sun, S. Yin, X. Peng, R. Liu, J. Seo, and S. Yu, ‚ÄúXNOR-RRAM: A scalable and parallel resistive synaptic architecture for binary neural networks,‚Äù in  2018 Design, Automation Test in Europe Conference Exhibition (DATE) , pp. 1423‚Äì1428, 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "iii  Entering/Exiting Object(s) : Another scenario is where one or more objects are moving into or out from a frame (refer Frame-2 in Fig. 3c). In this case, although the MV is smaller than the bounding boxes, its position is on the edge, indicating that a new object is entering the frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the IEEE International Conference on Big Data , pages 1234‚Äì1243. IEEE, 2019. [183] Yuanrui Zhang, Wei Ding, Mahmut Kandemir, Jun Liu, and Ohyoung Jang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. (c): View- ing the S-CGH from different focal distances. 41.48 31.79 30.74 \n0 10 20 30 40 50 60 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "3  b  , and a visual view of how these segments look like in Fig. 3  c  , and we observe that: ‚Ä¢  Compared to the two solid lines (the frame is partitioned into 20 blocks), the two dotted lines (when partitioned into 1000 blocks) are closer to the y-axis, indicating that a Ô¨Åner segment can better capture the temporal-locality. ‚Ä¢  Considering the dotted lines with 1000 segments parti- tioned from I- and P- Frames, the green line represents the smallest delta between two segments, which indicates the upper-bound/the scope of the attribute similarity, whereas the red line represents the largest delta/the least similarity among the segments.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "First, we use a synthetic Poisson-based request arrival rate with an average rate  ùúá =  100. The Twitter trace has a large variation in peaks (average = 3332 rps, peak= 6978 rps) when compared to the Wiki trace (average = 284 rps, peak = 331 rps). Second, we use real-world request arrival traces from Wiki [ 49 ] and Twitter [ 1 ] by running each experiment for about an hour.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Storing only  two \nhead orientations (in registers) and their associated  P buff  in the DRAM occupies only  ‚âà 16 MB  memory space. Further, we also observe that, the duration for which the head orientation does not change for three consecutive frames sums up to only  ‚âà 28%  of the video runtime on average (refer to Fig. 5b), limiting the memoization opportunities to those instances.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "This includes a hardware software co-design for compute-intensive applications along with map- ping different functions to different hardware in the data pipeline. Furthermore, we add failure management support for the intermittent edge servers. ‚Ä¢  We go beyond the compute and look into future-proofing the storage server by equipping it with quantum safe lattice-based encryption technique.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Rethinking the value of network pruning. arXiv preprint arXiv:1810.05270 , 2018. [99] Zichang Liu, Aditya Desai, Fangshuo Liao, Weitao Wang, Victor Xie, Zhaozhuo Xu, Anastasios Kyril- lidis, and Anshumali Shrivastava.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Routerless network-on-chip. IEEE, 2018. In 2018 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 492‚Äì503.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "From Figure  3a , it can be seen that the static policy has an accuracy loss of up to 1.45% when compared to full-ensemble, but is still better than single models. This implies that the models other than top   N \n2   yields a signiÔ¨Åcant 1.45% accuracy improvement in the full-ensemble but they cannot be statically determined. Peacock Panda Quill Slug Cup Class \n0 \n50 \n100 \nAccuracy \nMNetV2 IRV2 NASLarge \nFigure 4:  Class-wise Accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "[20] Google, ‚ÄúPixel Phone Hardware Tech Specs,‚Äù ‚Äùhttps://bit.ly/397dCUB‚Äù. [21] Y. Liu, Y. Wang, R. Yu, M. Li, V. Sharma, and Y. Wang, ‚ÄúOpti- mizing CNN Model Inference on CPUs,‚Äù in  Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference , 2019, p. 1025‚Äì1040. [22] M. Motamedi, D. D. Fong, and S. Ghiasi, ‚ÄúFast and Energy-EfÔ¨Åcient CNN Inference on IoT Devices,‚Äù  CoRR , 2016.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "0 \nTime (ms) \nExec Time (ms) Stage-wise SLO (ms) \n600 \n450 \n300 \n150 \n(b) Media Service. 0 \nTime (ms) \nExec Time (ms) Stage-wise SLO (ms) \n400 \n300 \n200 \n100 \n(c) Hotel Reservation. Figure 7: Slack for various Functions in each Application.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Several works have explored adaptive participation strate- gies that consider energy harvesting rates, energy consump- tion patterns, and application-specific requirements ( ? ). These strategies aim to balance energy expenditure with the need for timely and accurate data, often using heuristic or optimization-based approaches.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Please refer to Figure 5a for more details. As we can see, the input voltages V1 and V2 are applied to the rows of the crossbar array, while the conductance values G1 and G2 are applied to the columns. The output currents I1 and I2 are the result of the multiplication-addition operation, and are obtained by summing the currents flowing through the ReRAM devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Hence, rather than relying on low-level raw pixel values, most DNN applications leverage high-level features, where ‚Äúnew events‚Äù or ‚Äúmotions‚Äù make more sense to employ in determining whether we can reuse the results from previous \n1076 \nAuthorized licensed use limited to: Penn State University. In such a case, as the pixel values of the identiÔ¨Åed object have changed, Frame i + 1  cannot reuse the result (LED bulb) from Frame i  even though it should ideally be able to do so in an object detection application.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "The caveat is to have a model trained on the sub-sampled data, which can be done as an one-time step. The entire process of importance sampling uses simple arithmetic operations and is therefore viable in energy-scarce situations. The host can take the sub-sampled data and perform inference.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Our results show a 6% to 22% improvement in accuracy over current methods, with an increase of less than 5% in computational overhead. This paper details the development of the adaptive training framework, describes the integration of energy profiles with dropout and quantization adjustments, and presents a comprehensive evaluation using real- world data. Additionally, we introduce a novel dataset aimed at furthering the application of energy harvesting in computational settings.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "However,  this issue could be alleviated by not using the compute resource in the critical path and preferably moving the compute to the storage where the data will eventually be stored . This is where the modern and upcoming computational storage devices (CSDs) come to rescue: bringing computation closer to data while providing with maximum energy efficiency and programmability (Newsroom; AMD, b) . However, storage systems are not typically built to cater towards the ML applications, and now that compression becomes a ML application with the use of stacked neural codecs, building the right storage stack along with computational storage devices becomes an important problem.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Specifically, recent works [ 24 ,  43 ] pro- posed EH, along with compiler/runtime optimizations and leveraging non-volatile processors (NVP) [ 40 ,  56 ], to increase local compute at the edge. EH as a solution has been partic- ularly interesting as a means to address the sustainability issue of battery backing trillions of future devices. More importantly, EH can help us build sustainable distributed sensing/monitoring infrastructure at virtually inaccessible places like oil-wells, mines, and even satellite orbits [ 14 ,  49 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "In addition to capture costs, partici- pation incurs inference computation cost  e inf  and communi- cation cost  e comm . Thus, if sensor  s i  participates with SNR SNR i ( t ) , its total energy expenditure is \ne i ( t ) =  e cap ( SNR i ( t )) +  e inf  +  e comm \n3 \n165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 \nThe improvement in global inference accuracy due to sen- sor  s i  is denoted by  ‚àÜ A i ( t ) . This quantity depends on SNR i ( t )  and on the data contributed by other participating sensors, as their combined perspectives shape the overall result.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 279,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Our Intra-only:  The performance of above two tech- niques has two orders of gap with the  ‚âà 100 ms  real- time requirement [ 19 ]. On the other hand, our intra- only scheme takes only  95 ms  ( 42 ms  for geometry and 53 ms  for attribute compression), which is  43 √ó  faster w.r.t. TMC13.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "1b. To implement such ap- plications, today‚Äôs AR headsets are usually equipped with various hardware components for sensing and processing, as depicted in Fig. 1a, where a physical car being driven on a highway is replaced by the corresponding virtual/augmented holographic car in a real-time fashion such that, instead of viewing the real cars, the AR user views the virtual ones.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Our evaluations indicate 2.2 √ó speedup and 56 %  energy saving over the baseline setting. Further, relaxing the accuracy loss tolerance to 2 % , we can save up to  80%  energy. Additionally, the experimental analysis indicates that our approach outperforms the state-of-the-art work with respect to accuracy and/or performance/energy savings.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "35, no. [9] K. Ma, X. Li, S. Li, Y. Liu, J. J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúNonvolatile processor architecture exploration for energy-harvesting applications,‚Äù  IEEE Micro , vol. USENIX Association, 2018.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Processing Engines:  To efficiently handle the above two types of inputs, various computational resources have been integrated into AR SoCs, as shown in Fig. After sensing, the input samples are then buffered in the video buffer, waiting to be processed timely at the frame-rate. 1b, e.g., CPUs for generic processing, GPUs for graphics computing, vision processing units (VPUs) for rendering, and tensor processing units (TPUs) for learning infer- ences.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "The major  contributions of the paper can be summarized as follows: \n‚Ä¢  From an open-source 360¬∞ VR video dataset [3],  we identify both temporal reuse and spatial locality that exists in user behavior . To the best of our knowledge, this is the Ô¨Årst work that leverages head orientation and correlation between eyes to do efÔ¨Åcient memoization and in turn result in compute reduction in the VR video streaming domain. The proposed ar- chitecture is named  D¬¥ej`a View , a play on the word D¬¥ej`a vu, as it uses previous or  already seen  views.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "Different from these two prior works, Potluck [12] caches the feature vectors (FVs) and correspond- ing inference results for key frames, and reuse the results for other frames with similar FVs, with the costs of FV extraction (e.g., down-sampling [16]) penalty and potential accuracy and/or performance drop due to sampling failures. On the other hand, MCDNN [7] proposes a scheduler to dynamically choose the best suitable model from several candidate models (e.g., standard model, medium-pruned variant, and heavily- pruned variant), and pushes the accuracy as high as possible within the energy budget. However, with limited energy budget on typical edge devices, the accuracy is far from sufÔ¨Åcient for vision applications (quantitative results in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 182,
    "augmented": false
  },
  {
    "text": "[39] Junjue Wang, Ziqiang Feng, Shilpa George, Roger Iyengar, Pillai Pad- \nmanabhan, Mahadev Satyanarayanan, ‚ÄúTowards scalable edge-native applications,‚Äù in  ACM/IEEE Symposium on Edge Computing , 2019. [40] C.-K. Kang, H. R. Mendis, C.-H. Lin, M.-S. Chen, and P.-C. Hsiu, \n‚ÄúEverything leaves footprints: Hardware accelerated intermittent deep inference,‚Äù  IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , vol. 39, no.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "Hence, it is evident that there is a large optimization space where different models can be selected based upon the needs of the applications. same application requires accuracy to be at-least 80% (ISO- accuracy), as shown in Figure  2b , four different models with different response latencies can satisfy the accuracy. There- fore, depending on the cost budget of the application, one can choose among the different model types by  trading-off accuracy or response latency .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "However, for Frame-3, the motion vectors generated by codec (  6  ) drift away from the bounding box in Frame- 1 (with an overlap ratio of 0.6 in the right case), indicating that the object has moved/shifted a signiÔ¨Åcant distance. Thus, we need to perform  full inference  for Frame-3 to maintain high accuracy for detection, as shown in  7  . Putting all these together, in this scenario, both Frame-1 and Frame-3 employ full inference, whereas the inference for Frame-2 can be skipped, with very little overhead (only  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "In  USENIX Middleware Conference , 2017. Serving dnns like clockwork: Perfor- mance predictability from the bottom up. [35]  Arpan Gujarati, Reza Karimi, Safya Alzayat, Antoine Kaufmann, Ymir Vigfusson, and Jonathan Mace.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Robust bayesian linear classiÔ¨Åer ensembles. In  European Conference on Machine Learning , pages 72‚Äì83. Springer, 2005.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "The requests are sent to GPU instances only if the load matches the  P f  of the instance. Cost-aware Procurement : The cost of executing in a fully packed instance determines how expensive is each instance. Prior to scaling-up instances, we need to estimate the cost  4b of running them along with existing instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "performing single shot  object detection for trafÔ¨Åc monitoring using the MobileNetV2  [ 51 ] model on the urban trafÔ¨Åc data set [ 97 ]. This is a trafÔ¨Åc video dataset containing 62GB of videos recorded from Ô¨Åve pole-mounted Ô¨Åsh-eye cameras in the city of Bellevue, WA, USA. Each video stream is recorded with a resolution of 1280  √ó  720 at 30fps.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "8 , T missed  = 0 . 8 , T area  = 0 . 25 and  RD upper bound  = 10  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "When any of the active tiles are marked ready by the scheduler, the tile employees a state machine to decide where to get work from. Each time the tile Ô¨Ånishes some work, if its remaining work queue (the local work queue size) is less than the average of all other active tiles, it seeks a new kernel to work on. Considering the global control always enqueues any idle tile with work, whenever the tile has no work left, it steals a kernel from the most \n899 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Evomoe: An evolutional mixture-of-experts training framework via dense- to-sparse gate. arXiv preprint arXiv:2112.14397 , 2021. [118] NVIDIA.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "The second trace is production twitter [ 48 ] trace which is bursty with unexpected load spikes. Firstly, we use real-world re- quest arrival traces from Wikipedia [ 76 ], which exhibit typical characteristics of ML inference workloads as it has recurring diurnal patterns. Load Generator:  We use different traces which are given as input to the load generator.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers. Previous work [ 3 ] has noted vulnerabilities to pipeline bubbles and execution stalls in CNNs because of the large variance in weight and feature map scales across different layers. In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very Ô¨Åne-grain fashion.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Thus, it is important to keep learning and adapting to the user behavior. Since, we cannot keep re-training the DNNs because of their resource constraints, we choose to periodically update the conÔ¨Ådence matrix. The initial conÔ¨Ådence matrix, derived from the test cases, would be programmed into the host device.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "If individually  E C 1 , E C 2  > E b  but  E C 1  +  E C 2  ‚â§ E b , we fuse  C 1  and  C 2  into a single task. For example, Consider two convolution operations  C 1  and  C 2  with energy requirements  E C 1  and  E C 2 , respectively. The fused task executes both convolutions atomically within the energy budget, avoiding the overhead of checkpointing between them.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "In  USENIX Middleware Conference , 2017. [34]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg. Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource EfÔ¨Åciency.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Consequently, the stochastic gradient descent (SGD) updates retain their convergence properties, ensuring that the training process reliably optimizes  J ( Œ∏ ) . 9:  end for \nRegularizers and SGD Convergence: The chosen reg- ularizers  ‚Ñ¶ SNR ( Œ∏ )  and  ‚Ñ¶ complexity ( Œ∏ )  are both convex and smooth, with known closed-form gradients. This property guarantees that the inclusion of regularizers does not com- promise the convexity or smoothness of the overall objective J ( Œ∏ ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "In exemplar selection, the entire dataset is analyzed to detect classes with unique features, i.e., the images that are much different from the training data distribution or new classes that were not included in the training data. It is noteworthy that, the process of neural compression as well as inference/representation learning use the feature extraction method. This is typically achieved through representation learning (Rebuffi et al., 2017) where the data is first converted into a feature vectors using the convolution layers of a large DNN model (or multiples of them), and then performing an unsupervised learning based classification, e.g., k-means++ (Arthur & Vassilvitskii, 2007; Bahmani et al., 2012), to cluster the data.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 179,
    "augmented": true
  },
  {
    "text": "CSE Department Resources: The Department of Computer Science and Engineering (CSE) at Penn State uses a network of Linux, OS X, and Windows workstations and servers to support academic com- puting needs. A variety of other grid computing resources are also freely available to their re- search groups. For example, Kandemir‚Äôs lab has CAPI-capable FPGA resources integrated into IBM Power servers for modeling of emerging accelerator and chiplet resources and software licenses for the HLS and EDA flows needed to generate new accelerator and chiplet models and deploy them on this platform.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Only intermittent learning [ 47 ] focuses on performing on-device training, but with very small workloads and models. Existing Approaches:  Although there has been signiÔ¨Åcant re- search [ 40 ], [ 41 ], [ 47 ], [ 52 ], [ 56 ], [ 61 ], [ 72 ], [ 104 ] on enabling machine learning in intermittently powered devices, a major- ity of it focuses on performing inference. Considering the scale, scope and workload of our problem, limits direct comparisons, except for comparing their exemplar selection method (refer Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "Not adopting an importance sampling based weighted policy would result in equivalent number of VMs as the Bline for all models. How- ever, since  Cocktail  exploits importance sampling by keeping track of the frequency in which models are selected, the num- \nber of VMs spawned for model1, model2 and model-3 is upto 3 √ó  times lesser than uniform scaling. Figure  9b  shows the most used models in decreasing order of importance.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "We also design an autoscaler  6  , which utilizes a prediction pol- icy  6a  to forecast the request load and scale instances for every model pool, thereby minimizing over-provisioning of resources. The autoscaler further employs an importance sam- pling  6b  algorithm to estimate the importance of each model pool by calculating percentage of request served by it in a given time interval. The key components of the design are explained in detail below.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Such optimizations [ 37 ], [ 59 ], [ 68 ] are extremely important for applications like virtual tourism, video streaming etc. 2) Point Cloud Analysis:  To analyze objects/scenes in PCs, 3D convolutional neural networks (CNNs) have been widely used in techniques like 3D shape classiÔ¨Åcation [ 66 ], [ 67 ], [ 89 ], [ 91 ], object detection [ 38 ], [ 45 ], [ 65 ], tracking [ 22 ], [ 78 ], or segmentation [ 10 ], [ 66 ], [ 67 ], [ 89 ]. More complex optimizations are needed when  human-object  interactions and  human-object-sensors interactions are involved (for applications like telepresence, telemedicine, virtual shopping and gaming) and need the help of PC data analytics to recognize/classify the interactable objects/scenes.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 195,
    "augmented": true
  },
  {
    "text": "8  shows the impact of micro-proÔ¨Åling on the hyper parameter selection. Due to the drift- and weighted accuracy- aware micro-proÔ¨Åler, the suggested conÔ¨Åguration is almost every time the same as an oracular selection. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP , pages 353‚Äì355, 2018. Glue: A multi-task benchmark and analysis platform for natural language understanding. [160] Bo Wang, Maria Liakata, Arkaitz Zubiaga, and Rob Procter.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "[200] Yazhou Zu, Alireza Ghaffarkhah, Hoang-Vu Dang, Brian Towles, Steven Hand, Safeen Huda, Adekunle Bello, Alexander Kolbasov, Arash Rezaei, Dayou Du, Steve Lacy, Hang Wang, Aaron Wis- ner, Chris Lewis, and Henri Bahini. Resiliency at scale: Managing  { Google‚Äôs }{ TPUv4 }  machine learning supercomputer. In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pages 761‚Äì774, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "Hence, to holistically address this problem, we need to solve the issues that arise from combining both model and resource heterogeneity towards optimizing for application constraints. Towards this, we discuss the design implications of a self-managed inference serving system, which can optimize for application requirements based on public cloud resource characteristics. CCS Concepts:  ¬∑  Computer systems organization  ‚Üí Real-time system architecture .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "[49] S. Li, Z. Yang, D. Reddy, A. Srivastava, and B. Jacob, ‚ÄúDramsim3: \na cycle-accurate, thermal-capable dram simulator,‚Äù  IEEE Computer Architecture Letters , vol. 19, no. 2, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Associa- tion for Computing Machinery. ISBN 9781450385572. doi: 10.1145/3466752.3480056. URL https://doi.org/10.1145/3466752.3480056 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Such optimizations [ 37 ], [ 59 ], [ 68 ] are extremely important for applications like virtual tourism, video streaming etc. More complex optimizations are needed when  human-object  interactions and  human-object-sensors interactions are involved (for applications like telepresence, telemedicine, virtual shopping and gaming) and need the help of PC data analytics to recognize/classify the interactable objects/scenes. 2) Point Cloud Analysis:  To analyze objects/scenes in PCs, 3D convolutional neural networks (CNNs) have been widely used in techniques like 3D shape classiÔ¨Åcation [ 66 ], [ 67 ], [ 89 ], [ 91 ], object detection [ 38 ], [ 45 ], [ 65 ], tracking [ 22 ], [ 78 ], or segmentation [ 10 ], [ 66 ], [ 67 ], [ 89 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 195,
    "augmented": false
  },
  {
    "text": "Association for Computing Machinery. ISBN 9781450392549. doi: 10.1145/3517207.3526973. URL  https://doi.org/ 10.1145/3517207.3526973 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Yann Collet and Murray Kucherawy. 509‚Äì531, 2024. Zstandard compression and the application/zstd media type.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "P   pipe   = \nLC X \nLk =1 P Lk (4) \nLat pipe   =  max ( Lat L 1 , Lat L 2 ...Lat LC ) (5) \nC. Dynamic activation strategy \n1) Problem formulation:  In this section, we focus on Ô¨Åguring out the ResiSchedule solution to achieve the maximal throughput. Although we can arrange more hardware resources with the pipelined computation mode, it does not mean this mode will always yield greater computation progress than the sequential mode due to the constraints of tile size and parallelism granularity. Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "Figure 17:  Cost savings of Cocktail for Sentiment Analysis. Strict Relaxed 0 \n25 \n50 \n75 \n100 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace. of 0.5% than  Clipper  (not plotted).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "The key components of the scheduler are the ‚Äúmoving average power predictor‚Äù and the ‚Äúmicro-proÔ¨Åler‚Äù. 6 : Accelerator level  provides a high-level overview of the compute scheduling (where the redacted part of the hard- ware is turned off because of the lack of power). In the  i th   kernel scheduling iteration, given the power budget and power prediction, the \nmicro-proÔ¨Åler decides the required training conÔ¨Åguration, and the control logic (conservatively) enables suitable number of tiles (say  t i  tiles of the 256 tiles).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 12 \nTien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. Designing energy-efficient convolutional neural networks using energy-aware pruning.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Users also have the option to manually mention the ensemble size. Unlike them,  Cocktail‚Äôs  model selection pol- icy tries to right-size the ensemble for a given latency, while maximizing accuracy. Model-serving in Cloud : The most relevant prior works to Cocktail  are InFaas [ 83 ] and Clipper [ 27 ], which have been extensively discussed and compared to in Section  6 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "IEEE, 2024. [22] Jerry Chee, Yaohui Cai, Volodymyr Kuleshov, and Christopher M De Sa. Quip: 2-bit quantization of large language models with guarantees.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "To study how this decision affects the video quality, we report \n250 \n0% 20% 40% 60% 80% 100% \n0% 20% 40% 60% 80% 100% \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nRhinos Timelapse Rollercoaster Paris Elephants Avg. % Total Energy Saving \nCompute Energy  Consumption \nL \nR %TotalEnergySaving \nFig. To simplify our  AE  design, we simply reuse the pattern captured in the  1 st row, and do not consider the deeper information related to the row numbers.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 221,
    "augmented": true
  },
  {
    "text": "IV  that, the Morton codes can precisely describe the geometry relations among points (thus, ensuring a good geometry compression), but sometimes they may not work well for the attributes, especially when the spatial locality is not rich for some blocks/frames. ‚Ä¢  Our Intra-Inter-V1 (Quality-oriented):  To further reduce the frame size, this design exploits the temporal locality across PC frames. As a result, the data size becomes 5%  less than our intra-only design (e.g., only 12 %  of the original size), while dropping the quality by  6 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "While \n15 \nSalient Store  is consistently performing better than H264, HEVC thanks to it‚Äôs novel approach of fine grained computation at times outperforms our approach. 8. Experiments on waymo (Sun et al., 2020) dataset shows the PSNR of Salient Store  compared to the classical H264 and HEVC encoding pipeline in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Entropy Other Geo. Compression Pipeline:  PCL \nb c a \nFigure 2: Prior PC compression technique categories and latency breakdown for prior techniques on compressing one PC frame from [ 55 ]. real-time refresh requirement of vision applications is yet to close and prevents the deployment of NN-PCC on edge devices.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Employing predictive energy harvesting models to anticipate energy availability and adjust computations proactively. These strategies ensure that the system remains operational and provides degraded but acceptable performance under severe energy constraints. In extreme cases, the system can enter into a low-power standby mode and resume operation when sufficient energy is available.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "[43] O. [41] OpenGL, ‚ÄúCubemaps - Learn OpenGL.‚Äù ‚Äùhttps://learnopengl.com/ Advanced-OpenGL/Cubemaps‚Äù, 2019. [42] OpenGL, ‚ÄúThe Industry‚Äôs Foundation for High Performance Graphics.‚Äù ‚Äùhttps://www.opengl.org/‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "We ensure all instances are fully utilized by packing multiple requests in accordance to the  P f  . As shown in Figure  3b , Ensemble-OD is always ex- pensive than single-OD for the all the models. The cost is calculated as the cost per hour of EC2 c5.xlarge instance use, billed by AWS [ 5 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "First sensor at the chest, second on the right wrist and last sensor on the left ankle. Each sensor consists of four major components, namely, the sensing component, an IMU, which collects acceleration and attitude data, an energy harvester which harvest the surrounding RF (WiFi) energy, a compute component same as [6] and a wireless communication module (BLE or WiFi) to connect to a host device (battery backed mobile phone). We assume the communication cost to be negligible since it infrequently sends a few bytes of data to the host.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "USENIX Association. 2018. [36]  Bernhard Korte and Jens Vygen.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "Tianyi Shen, Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. An efficient edge-cloud partitioning of random forests for distributed sensor networks. IEEE Embedded Systems Letters , 2022.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "This quantum resilience is vital for protecting large data-sets on machine learning storage servers, particularly from ‚Äôstore now, decrypt later‚Äô threats. Algorithm 3  Lattice-Based Encryption Process \n1:  procedure  L ATTICE _B ASED _E NCRYPT (message, public_key) 2: PM  ‚Üê ConvertToPolynomial(message) 3: (PA, PE)  ‚Üê GenerateRandomPolynomials() 4: C1  ‚Üê PolynomialMultiply(PA, public_key) ‚ñ∑ Utilizing HSPM 5: C2  ‚Üê PolynomialMultiply(PA, PM) ‚ñ∑ Employing SDMM 6: return  (C1, C2) 7:  end procedure \nAt the heart of LBC lies the Ring-Learning with Errors (R-LWE) algorithm, which translates plaintext messages into polynomial representations and intertwines them with random polynomials using complex multiplications and additions, as delineated in Algorithm 3. Note that, within the LBC algorithm, certain components, specifically polynomial multiplications, exhibit similarities to operations performed in CNNs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 274,
    "augmented": false
  },
  {
    "text": "These shortcomings collectively motivate the central premise of this work:  how to solve the complex optimiza- tion problem of cost, accuracy and latency for an ensem- bling framework? In this paper, we present and evaluate Cocktail 2 , which to our knowledge is the Ô¨Årst work that pro- poses a cost-effective model-serving system by exploiting ensembling techniques for classiÔ¨Åcation-based inference, to deliver high accuracy and low latency predictions. Cocktail adopts a three-pronged approach to solve the optimization problem.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "Existence of a Nash Equilibrium \nSince no infinite sequence of profitable unilateral deviations can occur, the best-response dynamics must terminate in a state where no sensor can unilaterally improve its utility. This contradiction shows that no infinite improvement sequence can occur. Because  Œ¶  is bounded above by  Œ¶ max , only a finite number of increments can occur before no further improvements are possible.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "2 ). Furthermore, we also observed in Sec. III-B  that Morton codes can reveal opportunities for both geometry similarity (owing to the fact that the Morton code itself is the reÔ¨Çection of the geometrical relationship between points) and attribute similarity (the RGB attributes of two adjacent points are more likely to be similar).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "[89]  W. Wu, Z. Qi, and L. Fuxin, ‚ÄúPointconv: Deep convolutional networks on 3d point clouds,‚Äù in  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. [90]  T. Xu, B. Tian, and Y. Zhu, ‚ÄúTigris: Architecture and algorithms for 3d perception in point clouds,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2019, p. 629‚Äì642. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "To we model this problem as a coin-toss problem involving N  biased coins with having probability of occurrence of head to be  a . Relating this to our problem, each coin represents a model, and an occurrence of head represents the model giving the correct classiÔ¨Åcation. Then, the Ô¨Ånal ac- curacy of this ensemble would be the probability of at least ‚åä N / 2 ‚åã + 1 of them giving a correct result.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "CCS Concepts:  ¬∑  Computer systems organization  ‚Üí Real-time system architecture . Copyrights for components of this work owned by others than ACM must be honored. Keywords:  serverless, resource-management, inference \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Multiple sensors observing the same phenomenon from different angles can collectively provide more comprehensive and reliable insights than any single sensor could. However, requiring all sensors to partic- ipate at all times is impractical, as it drains energy reserves too quickly. Conversely, simplistic policies‚Äîsuch as se- lecting only the highest-energy sensors‚Äîignore factors like data relevance, sensor quality, and the strategic implications of current participation on future network states.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "We introduce weights to estimate the appropriate number of containers to be spawned for each function. To design such a policy, the RM framework needs to know each function‚Äôs invocation frequency, which is a good estimator of its relative popularity. Opportunity 1:  In order to reduce overprovisioning of contain- ers, it is vital to design a workflow-aware resource management (RM) framework that can dynamically scale containers for each function, as opposed to uniformly scaling for all functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "In  2014 47th Annual IEEE/ACM International Symposium on Microarchitecture , pages 458‚Äì470. [72] Natalie Enright Jerger, Ajaykumar Kannan, Zimo Li, and Gabriel H Loh. Noc architectures for silicon interposer systems: Why pay for more wires when you can get them (from your interposer) for free?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 21st International Middleware Conference . Fifer: Tackling Resource Underutilization in the Serverless Era. 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "5b shows the results for the PAMAP2 dataset. Fig. 5a shows the accuracy results on the MHEALTH dataset, and Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Thus, to systematically explore the potential opportunities of approximation in the AR hologram applications, we start by distinguishing between three fundamental scenarios, where the  objects ,  head pose , and  eye tracking  provide different opportunities, as depicted in Fig. Further, in many cases, these inputs are dynamically changing at the same frequency (e.g., the image sensors) as the frame-rate, which needs to be captured and updated at runtime, or even at a faster rate (e.g., the IMU and IR sensors). 5.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "2018. Stratus: Cost-aware Container Scheduling in the Public Cloud. [3]  Andrew Chung, Jun Woo Park, and Gregory R. Ganger.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "275 \n290 \n305 \n320 \n600 \n700 \n800 \n1 10 19 28 37 46 55 \nRequests/second \n# Containers \nSampling interval (minutes) \nOracle Kraken Trace \n(b) Containers spawned over time. Figure 16: Simulator: Comparison of End-to-End (E2E) Response Times and Containers Spawned Over Time (60 minutes) of  Kraken and  Oracle . 0 \n150 \n300 \n450 \n600 \nOracle Kraken Oracle Kraken Oracle Kraken \nSocial Network Media Service Hotel Reservation \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(a) E2E Response Time Break- down.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "However, our goal is to go beyond just optimizing the geometry compression. SpeciÔ¨Åcally, in the traditional 2D video compression domain, the video frames are usually rich in spatial locality (similar neighboring \n4 We do not claim the parallel octree construction as our contribution. b \n0% 25% 50% 75% 100% \n0 50 100 150 200 Delta(red) \n#blocks=20,best #blocks=20,worst #blocks=1000,best #blocks=1000,worst \n0% 25% 50% 75% 100% \n0 100 200 Range(Delta) \n#blocks=10 #blocks=100 #blocks=10000 #blocks=100000 \na \nc \nFigure 3: a) Spatial locality within one frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 170,
    "augmented": false
  },
  {
    "text": "Tasm: A tile-based storage manager for video analytics. In  2021 IEEE 37th International Conference on Data Engineering (ICDE) , pp. Maureen Daum, Brandon Haynes, Dong He, Amrita Mazumdar, and Magdalena Balazinska.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Proper selection and tuning of  Œª 1 , Œª 2  help main- tain stable and robust training dynamics. The regularizers, being convex and with bounded gradients, integrate seam- lessly into the backpropagation and SGD updates, shaping the optimization landscape but not invalidating convergence properties. The equilibrium ensures  D  remains stable, allowing classi- cal stochastic optimization theory to hold.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Furthermore, the feature extraction for each of the potential \nexemplars for the teacher model is hardware-assisted (¬ß V-C ), and hence poses no overhead to the inference task. 0 \n9 \n18 \n27 \nR Y V R+Y R+V Y+V R+Y+V IL-RR IL-K-Last List \n# Exemplars \n#Exemplars Selected (Best Case) #Exemplars Selected (Worst Case) Average Exemplars \nFig. 9: Impact of multiple teachers on exemplar selection.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "3a, the bike  object is closer to the user, and also has a larger range/size ( size=farmost-nearest ); thus, more information is required to create the hologram for the  bike  for maintaining fairly good QoS than the  chair . For example, compared to the  chair  object in Fig. 3a) affect the amount of computations actually required to provide just enough yet necessary virtual holo- grams.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "same application requires accuracy to be at-least 80% (ISO- accuracy), as shown in Figure  2b , four different models with different response latencies can satisfy the accuracy. There- fore, depending on the cost budget of the application, one can choose among the different model types by  trading-off accuracy or response latency . Hence, it is evident that there is a large optimization space where different models can be selected based upon the needs of the applications.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Ai and compute: How much longer can computing power drive artificial intelligence progress ? In  Proceedings of the 37th International Conference on Neural Information Processing Systems , NIPS ‚Äô23, Red Hook, NY, USA, 2024. Curran Associates Inc. \n[100] Andrew J. Lohn and Micah Musser.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Services like Ads and News Feed [ 39 , 44 ] would require SLOs within 100ms, while facial tag recommendation [ 83 ] can tolerate up to 1000ms. We deÔ¨Åne SLO as the end-to-end response latency required by an application. Since these inference requests are often user-facing, it is imperative to administer them under a strict service level ob- jective (SLO).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "2021. HoloAR: On-the-fly Optimization of 3D Holographic Processing for Aug- mented Reality. In  MICRO-54: 54th Annual IEEE/ACM International Sympo- sium on Microarchitecture (MICRO ‚Äô21), October 18‚Äì22, 2021, Virtual Event, Greece.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Restrictions apply. lions of additional battery-supported analytics platforms would introduce severe environmental challenges due to resource extraction, production, and replacement of batteries [ 3 ], [ 5 ], [ 10 ], [ 13 ], [ 53 ], [ 66 ], [ 69 ]. By demonstrating the viability of a battery-less edge server for video analytics, Us.¬¥as spearheads the adoption of similarly sustainable systems for other do- mains.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Also, we estimate the right configuration of lambda functions by conduction offline experiments. For the model selection problem, we maintain an offline model cache which consists of the de- tails of individual model latency and accuracy profiled by executing on c4 Àô large VM. The scheduler will pick the right model combinations from the cache based on the application requirements.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems , CHI ‚Äô23, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9781450394215. doi: 10.1145/3544548.3581045.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "83 538‚Äì83 547, 2020. [33]  N. Koh, P. K. Jayaraman, and J. Zheng, ‚ÄúParallel point cloud compression using truncated octree,‚Äù in  2020 International Conference on Cyberworlds (CW) , 2020, pp. 1‚Äì8.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "IEEE. In  ISWC . Introducing a New Benchmarked Dataset for Activity Monitoring.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 21,
    "augmented": true
  },
  {
    "text": "These observations motivate us to investigate the reasons behind such low performance on GPU: is it because of the intrinsic software/algorithm characteristics, or is it primarily a hardware mapping issue? Thus, it can be concluded that, without any optimization, a state- of-the-art edge GPU is only able to compute for  <  4 depth planes in real-time [ 36 ]. Towards this, we profiled the hologram processing on the edge GPU [ 36 ] using the NVPROF tool [ 37 ], and observed the follow- ing: First, the SM utilization for both the steps is very high, i.e., 74% for  Forward-Propagation  and 90% for  Backward-Propagation .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "This figure shows a clear pattern of trade-offs between more-energy-savings vs. more-quality-drop. Generality of  HoloAR :  Although the core idea of approximation seems to be general across many video domains, our proposal is not expected to work very well for all AR applications. Specifi- cally, there are two classes of applications that would probably achieve only limited benefits from our approach.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "The bootstrapping strategy makes each estimator learn different features of the data set and therefore increases the generality of the whole model. Why Variance:  Random-forest typically randomly samples the data and generates different estimators from the given data. Our experiments suggests variance to be the most suitable metric to decide the threshold.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "2019.00259. Mahdi Torabzadehkashi, Siavash Rezaei, Ali HeydariGorji, Hosein Bobarshad, Vladimir Alves, and Nader Bagherzadeh. Computational storage: an efficient and scalable platform for big data and hpc applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "1084 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Eager Scheduling:  A weight stationary implementation with a conservative scheduling will always run synchronously. However, in the middle of an kernel execution iteration, if the hardware gains access to more power which in turn can enable more tiles, it cannot do so without breaking synchrony (i.e. when some of the tiles are half way through the compute, some other tiles can just start execution).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "35%  of that consumed by baseline. 248 \nFig. 7: The proposed  EA  and  AE  design blocks implementation.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "In addition to that, just DNN training cannot learn \new classes if there is no way to annotate and label new classes. The fundamental issue with the previous approach is the inability to select correct numbers of IID data for training. Representation learning solves both these issues.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "[67] D. Patterson, J. Gonzalez, Q. Le, C. Liang, L.-M. Munguia, \nD. Rothchild, D. So, M. Texier, and J. Dean, ‚ÄúCarbon emissions and large neural network training,‚Äù  arXiv preprint arXiv:2104.10350 , 2021.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "2, pp. 106‚Äì109, 2020. [50] Z. Li and D. Hoiem, ‚ÄúLearning without forgetting,‚Äù  IEEE transactions \non pattern analysis and machine intelligence , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Sahand Salamat, Hui Zhang, Yang Seok Ki, and Tajana Rosing. Nascent2: Generic near-storage sort accelerator for data analytics on smartssd. ACM Transactions on Reconfigurable Technology and Systems (TRETS) , 15(2):1‚Äì29, 2022.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. baseline InterHolo IntraHolo InterIntraHolo \nAvg. #depthPlanes \n(b) Avg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "the start function  NGINX , any one of  Search ,  Make_Post , Read_Timeline  and  Follow  can be taken. Henceforth, we refer to such Dynamic DAG Applications as DDAs. 2.2 Motivation Two specific challenges in the context of DDAs along with potential opportunities to resolve them are described below: Challenge 1: Path Prediction in DDAs.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Towards Real-time Photorealistic 3D Holography with Deep Neural Networks. Nature  592 (2021). [55]  Tomoyoshi Shimobaba, Jiantong Weng, Takahiro Sakurai, Naohisa Okada, Takashi Nishitsuji, Naoki Takada, Atsushi Shiraki, Nobuyuki Masuda, and To- moyoshi Ito.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "2008. Pre- dicting WWW surfing using multiple evidence combination. The VLDB Journal  17, 3 (2008), 401‚Äì417.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "IV. T HE  MORPHABLE H ARDWARE \nWhy Not Commercial GP-GPUs? DNN training is mas- sively parallel, fairly compute intensive, time consuming, and needs a lot of (albeit structured) data movements [ 16 ], [ 37 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Why Not? Exploring the realm of computational storage drives presents a tantalizing avenue for on-disk com- puting capabilities. Storage controllers, typically constrained by I/O bandwidth, are now being complemented by the vast internal bandwidth of solid-state drives (SSDs), making them prime candi- dates for near-data processing.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiÔ¨Åcations. Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input/output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources. Similar hybrid arrangements have been explored in the NVP literature [ 23 ] and impose minimal design overheads.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "2 Yaw: vertical; Pitch: side-to-side; Roll: front-to-back. power consumption, constituting  59% . Previous studies have observed that the computation in  360 ¬∞ video processing is, mainly, the  projection transformation  [28].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Proceedings of Machine Learning and Systems , 1:374‚Äì 388, 2019. Data driven prediction models of energy use of appliances in a low-energy house. [3] Luis M. Candanedo, V¬¥eronique Feldheim, and Dominique Deramaix.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Load Balancer : The master VMs runs a separate thread to monitor the importance sampling of all individual model pools. It keeps track of the number of requests served per model in the past 5 minutes. This information is used for cal- culating the weights per model for autoscaling decisions.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "[174] Ziyu Ying, Sandeepa Bhuyan, Yan Kang, Yingtian Zhang, Mahmut T. Kandemir, and Chita R. Das. IEEE, 2024. Edgepc: Efficient deep learning analytics for point clouds on edge devices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "2. Baseline Ratios:  Start with ratios that link  Œ≥  to typical accuracy gains and set  Œ¥, Œ∑  based on fractions or multiples of  Œ≥  ¬∑  ‚àÜ A min  or  Œ≥  ¬∑  ‚àÜ A max . Practical Hyperparameter Tuning Strategies \n1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "By exploring these key aspects, we envision developing a self-managed inference-serving system, which can provide for different diverse needs of applications by leveraging the \n0 50 100 150 200 250 300 350 \n20.00% \n40.00% \n60.00% \n80.00% \n100.00% \nMobileNet V1 \nMobileNEt V2 \nInception V3 \nResnet50 \nResNet50-V2 \nDenseNet-201 \nDenseNet-121 \nXxception \nNasNetMobile \nInceptionResnetV2 \nvgg16 NasNetLarge \nLatency (ms) \nAccuracy % \nTop1-Accuracy Latency \nFigure 1. Accuracy and Latency of Different Pretrained Models. 0 \n20 \n40 \n60 \n80 \nPercentage \nModel Type \n(a)  Different accuracy for ISO- latency.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "Therefore,  Us. A. ¬¥as employs a weight stationary compute mapping for executing the training tasks on the morphable hardware.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Firecracker: Lightweight Virtualization for Serverless Applications. In  NSDI . [3]  Andrew Chung, Jun Woo Park, and Gregory R. Ganger.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Studying the state-of-the-art ensemble model-serving frameworks, we observe the following critical shortcomings: ‚Ä¢  Ensemble model selection policies used in frameworks like Clipper [ 27 ] are static, as they  ensemble all available models  and focus solely on minimizing loss in accuracy. Since cost plays a crucial role in application-provider consideration, it is quintessential to minimize the deployment costs, while maximizing accuracy with low latency. Hence, the non-trivial challenge here lies in making the cost of ensembling predictions analogous to single model predictions, while satisfying these requirements.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "This prediction involves translating the blocks of  F t ‚àí 1  according to  M t  and serves as the predicted frame. The residual frame  R t , which contains only the differences not captured by the motion prediction, is then encoded using the layered neural network. Each layer of the neural network encodes progressively finer details of  R t .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "TMC13. This is due to: 1). the octree can be constructed \n1x 1x \n43.5x \n34.2x \n35.2x \n0 40 80 120 160 200 \n0 \n2000 \n4000 \n6000 \n8000 \nTMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 \nRedandblack Longdress Loot Soldier Andrew10 Phil10 Avg.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 242,
    "augmented": false
  },
  {
    "text": "I. We have two important takeaways: ‚Ä¢  Computation Dependence Chain: We note that there exists a data dependence from the  360 ¬∞ frame to generate the Ô¨Ånal FoV frame, where  F  depends on  P , which in turn depends on  T  . This also determines the ‚Äúorder of computation‚Äù, which is Ô¨Årst  T  , then  P , and Ô¨Ånally  F .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "We do encourage the use of green data centers for other centralized compute applications. Further, this can help build future solutions using these decentralised nodes for other applications. VII.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "We argue that compared to VMs there is more variability in configurations for  serverless functions  because the resources are billed at a more fine-grained 2   allocation of CPU and memory. Observation 5:  Serverless functions can be used with VMs to avoid over-provisioning resources, but the right configuration needs to be accurately determined for the functions such that it satisfies the application cost and latency constraints. 1 For squeezenet model, allocating beyond 2GB did not reduce computation time, but resulted in increased cost 2 The smallest standard performance VM (C4 family) comes with 2 vcpus and 3.75GB memory.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "ACM Transactions on Reconfigurable Technology and Systems (TRETS) , 15(2):1‚Äì29, 2022. ScaleFlux. Csd 2000. https://scaleflux.com/products/csd-2000/ , a.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "First, it uses a dynamic model selection policy to signiÔ¨Åcantly reduce the number of models used in an ensem- ble, while meeting the latency and accuracy requirements. Cocktail adopts a three-pronged approach to solve the optimization problem. Figure 1:  BeneÔ¨Åts of  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "6351‚Äì6360. [45] G. Kordopatis-Zilos, S. Papadopoulos, I. Patras, and I. Kompatsiaris, \n‚ÄúVisil: Fine-grained spatio-temporal video similarity learning,‚Äù in  Pro- ceedings of the IEEE/CVF international conference on computer vision , 2019, pp. [44] Konstantin Shmelkov, Cordelia Schmid, Karteek Alahari , ‚ÄúIncremental \nlearning of object detectors without catastrophic forgetting,‚Äù in  ICCV , 2017.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "(c) Head movement and pupillary distance as inputs. Therefore, unlike the 2D video processing where the display can directly read \n242 \n59% \n29% \n6%  6% \nCompute \nMemory Decode Display \n(a) Power breakdown. (b) Overview of  360 ¬∞  video projection.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Finally, if the frame falls under the category in which objects have not been signiÔ¨Åcantly displaced, then it is labeled as ‚ÄúPI‚Äù (as shown in Line  9  in Algo. 2), and the union of the BBoxes and the MVs is reported as the  new  regions of interest (RoIs) (see  2  in Fig. 4).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "This speedup comes from: 1). instead of searching the matched macro block from the entire space (the I-MB-Tree traversal as described in Sec. V ), given the points sorted in the Morton code order, the search space for block matching in our proposal is minimized (in the I-frame, now, we only need to search the neighboring regions for the current P-block); 2).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Case-2:  If the data belongs to a known class, but is signif- icantly different from the training samples, it falls not too far from one of the clusters. This distance of the new data from the cluster center is called the ‚Äúdistillation loss‚Äù [ 74 ]. An encounter of a new example of the existing class is followed by an update to the clustering by minimizing the classiÔ¨Åcation loss of the newly-seen data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "The use of FPGA not only accelerates the processing speed but also provides flexibility to adapt to various codec configurations. Training the Neural Codecs to Utilize Inference Pipeline:  The enhancement of our layered neural codec involves a joint training regimen that integrates the model used in inferecne pipeline, specifically MobileNet, as a static feature extractor within the compression framework. This strategy capitalizes on the robust, pre-trained features of MobileNet, which are frozen during training to ensure their integrity and to leverage their proven capability in capturing essential visual features.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms. Such integration grants IoT devices an important degree of independence from remote servers, which can be critical in deployments with challenging communication environments. Keywords -Energy harvesting, ReRAM crossbar, CNN, Recon- Ô¨Ågurable hardware, Loop tiling, Computation scheduling \nI. I NTRODUCTION \nIn recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [ 1 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "Setup Effective Training Accuracy Degradation Replacement Cycle* Battery Backed Custom HW[5000mAH] 93.17 2.48 2 - 3 years Battery Backed Mobile GPU 78.55 7.43 18 - 24 months Fixed Power [15W] 67.54 12.6 NA Fixed Power [35W] 100 1.87 Us. ¬¥as 95.3 1.92 7 - 10 years \nTABLE III: Comparing  Us. ¬¥as  can Ô¨Ånish about 50 cycles of retraining (50 complete training cycles) and DaDianNao can only Ô¨Ånish 22 training cycles, even assuming a zero overhead, seamless save-restore of the partial computes of DaDianNao during a power failure/emergency.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 166,
    "augmented": true
  },
  {
    "text": "A suitable gap might be chosen so that: Œ¥ < Œ∑  ‚â§ Œ¥  +  c, \nfor some small  c >  0 . Choosing  c  relative to typical gains, say  c  ‚âà 0 . Non-Participation and Equilibrium: Since  Œ∑ > Œ¥ , we ensure that sensors prefer risking occasional incorrect infer- ences over consistently abstaining.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "¬¥as  is  ‚âà 4 . 94% (maximum  ‚âà 8 . 03%, and minimum  ‚âà 2 .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "(Notations used: DCT: Discrete Cosine Transform, DWT: Discrete Wavelet Transform. 29.14 44.76 52.29 58.67 \n70.86 55.24 47.71 41.33 \n0 \n20 \n40 \n60 \n80 \n100 \nRR3 RR6 RR9 RR12 \n% Scheduled Computation \nCompleted Failed \n(a) Completion with ERR \n0 \n20 \n40 \n60 \n80 \n100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy (%) \nRR3 RR6 RR9 RR12 Baseline \n(b) Accuracy of ERR \n0 10 20 30 40 50 60 70 80 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy (%) \nQuantization Level 16b Quantization Level 12b Quantization Level 8b \n(c) Accuracy vs quantiza- tions \n0 \n20 \n40 \n60 \n80 \n100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy (%) \nSampling with Probability Weighted Sampling Baseline \n(d) Accuracy vs sub- sampling \nFigure 2: Accuracy comparison of various classical node-level optimization techniques. The Extended- Round-Robin policy (ERR) [ 47 ] takes a store-and- execute approach, and the number associated repre- sents the ratio of store cycles vs execute cycles (e.g.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 310,
    "augmented": false
  },
  {
    "text": "We will also outreach to researchers in other disciplines by giving project-related talks at different departments at Penn State (e.g., math and statistics). One example is the Science-U camp at Penn State, which is designed to take K-12 students through a one-week journey that investigates an area of STEM in an exciting way. The PIs are involved in several K-12 activities such as the summer CS program for girls (funded by CSE and led by Das).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Setup and Sensor Arrangement:  Two different types of 3-axis accelerometers (with 100Hz and 200Hz sampling rate) were placed in three different locations of a Bridgeport machine to collect and analyze data under different operating status. There were 5 operating statuses: three different speeds of rotation of the spindle ( R1: 100RPM ,  R2: 200RPM ,  R3: 300RMP  with no job; RPM ‚Äì rotations per minute), spindle under job ( SJ ), and spindle idle ( SI ). We collected over 700,000 samples over a period of 2 hours for each of the sensors.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "In our setup, one I-frame(intra-compressed frame) is followed by two P-frames(predicted frames), and the number of threads for MB matching is set to 4. Similarly, we have opted to use octree-based algorithm for geometry compression, and directly applied entropy encoding to the raw attributes. 6 \n‚Ä¢  Intra-Only : We apply our intra-frame compression method discussed in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "2020. OpenHolo: Open Source Library for Hologram Generation, Reconstruction and Signal Pro- cessing. In  Imaging and Applied Optics Congress .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "On-board Battery:  It is to be noted that all of the sensors and the processing engines mentioned above are  battery-backed , as shown in Fig. 1b. This is for enabling users to freely move around in a large area without the need of connecting with a power cable constantly.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "It can be observed that, while the ‚Äúexact pixel match based similarity‚Äù is scarce at frame level, an alternate similarity based on the ‚Äúmagnitude of pixel differences‚Äù is abundant. SpeciÔ¨Åcally, about 95% of the deltas (pixel differences in successive frames) are less than 3. The rest of this paper presents and experimentally evaluates two novel optimization strategies that exploit this similarity.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "However, prior works do not consider other avenues for optimizing the computation. In this context, this paper dives deep to understand the projection computation pipeline for ex- ploring available opportunities and optimizations for speedup as well as power savings. Since  head movement  and  cor- relations between the left and right eye projections  are the two critical components of the projection computation, we analyze and study them to explore possible opportunities to exploit these relations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Deep neural networks for youtube recommendations. [24]  Paul Covington, Jay Adams, and Emre Sargin. In  Proceedings of the 10th ACM con- ference on recommender systems , pages 191‚Äì198, 2016.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "5.2 Evaluation Methodology We evaluate the  Kraken  prototype on a 5 node  Kuber- netes  cluster with a dedicated manager node. Each node is equipped with, 32 cores (Intel CascadeLake), 256GB of RAM, 1 TB of storage and a 10 Gigabit Ethernet interconnect [ 35 ]. For energy measurements, we use an open-source version of Intel Power Gadget [ 16 ] that measures the energy consumed by all sockets in a node.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "2020. Objectron Dataset Annotation: bike. \"https://github.com/google- research-datasets/Objectron/blob/master/index/bike_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "This leads to higher latencies and further inÔ¨Çates the resource foot- print, thereby accentuating the deployment costs. ‚Ä¢  Existing ensemble weight estimation [ 87 ] has  high com- putational complexity  and in practice is limited to a small set of off-the-shelf models. Studying the state-of-the-art ensemble model-serving frameworks, we observe the following critical shortcomings: ‚Ä¢  Ensemble model selection policies used in frameworks like Clipper [ 27 ] are static, as they  ensemble all available models  and focus solely on minimizing loss in accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "[36] C. Jones and J. D. Ryan,  Encyclopedia of hinduism . [35] Z. Jackson, ‚ÄúFree spoken digit dataset (fsdd),‚Äù https://github. com/Jakobovski/free-spoken-digit-dataset , July 2022, (Accessed on 07/08/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "98.50% \n99.00% \n99.50% \n100.00% \n0 \n200 \n400 \n600 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(c) Hotel Reservation. 99.00% \n99.25% \n99.50% \n99.75% \n100.00% \n0 \n300 \n600 \n900 \n1200 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(b) Media Service. Figure 10: Real System: Comparison of Total Number of Containers spawned VS SLOs satisfied by each policy.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "As a result, any approach trying to exploit frame reuse (e.g., skip inferences for similar frames) based on this speciÔ¨Åc similarity metric (exact pixel match) will not have much scope for optimization. Instead, one may want to consider alternate similarity metrics that can lead to richer reuse opportunities. The distribution of the absolute differences (deltas) between the pixel values in successive frames plotted in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Note also that, since the  soccer ball  hologram has been already generated in Frame-I , we can skip its computation. Again, the  box  object is still outside of the viewing window and thus, we do not need to compute its hologram. We use such a viewing-window based ‚Äúsub-hologram‚Äù technique which has already been proposed in prior works (such as Sub-Hologram [ 52 ]) as the  Baseline  design.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "11b ,  Us. ¬¥as  maintains a high duty cycle across power variance, whereas DaDianNao [ 16 ] could not be active for all the power cycles. Considering the power proÔ¨Åle of Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Further, as mentioned in Sec. VI-B , 4 CPU threads are invoked to perform the macro-block matching in CWIPC, this results in even higher CPU power. For example, the average CPU power for TMC13 is  1687 mW whereas  3622 mW  for CWIPC.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Cocktail  was able to deliver correct predic- tions for 35% of the tied votes, whereas breaking the ties in Clipper  led only to 20% correct predictions. USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1049 \nInFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp. Since majority voting can include ties in votes, we analyzed the number of ties, which were correctly predicted for all the queries.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "All these parameters are tunable based on the system needs. Importance Sampling:  An important concern in autoscaling is that the model selection policy dynamically determines the models in the ensemble for a given request constraints. Autoscaling the instances equally for every model based on predicted load, would inherently lead to over-provisioned instances for under-used models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "A data-driven framework for archiving and exploring social media data. Annals of GIS , 20(4):265‚Äì277, 2014. Zhiyu Huang, Haochen Liu, and Chen Lv.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Abstract \nAs continuous learning based video analytics continue to evolve, the role of effi- cient edge servers in efficiently managing vast and dynamic datasets is becoming increasingly crucial. Unlike their compute architecture, storage and archival system for these edge servers has often been under-emphasized. This is unfortunate as they contribute significantly to the data management and data movement, especially in a emerging complute landscape where date storage and data protection has be- come one of the key concerns.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2012 International Sym- posium on High Performance Computer Architecture (HPCA) , pages 507‚Äì518. IEEE, 2012. Garnet: A detailed network-on-chip simulator.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "The Ô¨Årst one is that we expect more energy can be used for program progress. The other is more subtle in that we expect the power can be consumed quickly in order to receive more energy from outside. In this regard, the metric  throughput  measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "129‚Äì147, 1982. [48]  R. Mekuria, K. Blom, and P. Cesar, ‚ÄúDesign, implementation, and evaluation of a point cloud codec for tele-immersive video,‚Äù  IEEE Transactions on Circuits and Systems for Video Technology , pp. 828‚Äì842, 2017.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Computation is  redistributed  when there is a change in the power availability, and multiple tiles are shutdown (redacted) without impacting the data Ô¨Çow. Inputs are broadcast into each tile so that each tile can work on a kernel. or decomposed as multiple units called ‚Äúkernels‚Äù (or ‚ÄúÔ¨Ålters‚Äù).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Our experimental evaluation on a 160-core cluster using  Deathstarbench  workload suite and real-world traces demonstrate that  Kraken  spawns up to 76% fewer containers, thereby improving container utilization and cluster-wide energy savings by up to 4 √ó  and 48%, respec- tively, compared to state-of-the art schedulers employed in serverless platforms. 8 Acknowledgement We are indebted to the anonymous reviewers for their in- sightful comments. This research was partially supported by NSF grants #1931531, #1955815, #1763681, #2116962, #2122155 and #2028929.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "eperceptive: energy reactive embedded intelligence for batteryless sensors. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems , pp. 382‚Äì394, 2020.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output Y . If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Mahmut Taylan Kandemir; Pennsylvania State University; co-PI 3. Chitaranjan Das; Pennsylvania State University; PI 2. Rui Zhang; Pennsylvania State University; Co-PI 4.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, as shown in Fig. The points within one segment are geometrically close to each other, and hence their attributes are also likely to be similar. 6 , in order to capture the spatial locality in attributes (e.g., points with similar Morton codes tend to have similar colors), our proposed pipeline Ô¨Årst sorts the points using the Morton codes and then partition/group them into multiple segments.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "1) Overall Execution Latency: On average, our FI+SI scheme can reduce  52%  of the execution time for YOLOv3, and  53%  for YOLOv4-tiny, compared to the baseline. On the other hand, our FI+SI+PI scheme can save  55% / 61%  of the execution time for YOLOv3/YOLOv4-tiny. From these results, we can make the following observations.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "The reason why YOLOv4-tiny saves more is that the PI beneÔ¨Åts more in a ‚Äúshallow‚Äù model with a relatively larger room to skip. 75 √ó  of the baseline latency to perform the PI on a frame in video HC1 [43], whereas YOLOv4-tiny takes only  ‚àº 0 . For example, YOLOv3 takes, on average,  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Abstract ‚ÄîAs Point Clouds (PCs) gain popularity in processing millions of data points for 3D rendering in many applications, efÔ¨Åcient data compression becomes a critical issue. This is because compression is the primary bottleneck in minimizing the latency and energy consumption of existing PC pipelines. Data compression becomes even more critical as PC processing is pushed to edge devices with limited compute and power budgets.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "5 √ó speedup compared to the software based RSA algorithm. While we do agree that the lattice-based encryption has more overheads compared to the RSA algorithm, the benefit of being ‚Äúquantum-safe‚Äù outweighs the minimal cost incurred on encryption. Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "For each sensor to perform inference using the limited and unstable harvested energy poses a scheduling problem, as non-deterministic time is required for the EH sensors to accumulate enough energy to perform the inference. This scheduling is made even more difÔ¨Åcult as each sensor can harvest and consume different amounts of energy depending upon their location, have different sensor sampling rate, and require different DNNs to be executed. Further, all sensors might not be able to participate in the ensemble due to the Ô¨Åckle nature of harvested energy.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "Data Lineage and Reproducibility \nAll three PIs are fully committed to ‚Äúreproducibility‚Äù and open access policy. In addition to the data de- scribed above, they will also generate and maintain ‚Äúannotations‚Äù attached to i) the libraries used in com- piler and runtime system source codes, and ii) the characterization and experimental data generated by the project. 6.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "All data mentioned above will be accessible via our website dedicated to the project. 4. Policies and Provisions for Reuse and Redistribution \nNo permission restrictions will be placed on the data.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "The throughput can be expressed as follows: \nThr pipe ave   = P Lk = LC Lk =1 ( m  √ó  n ) Lk  √ó  aG Lk \nLat pipe (8) \n2) Activation strategy formulation :  The activation strategy for the sequential mode can be described as shown below. In order to formulate the problem in a concise way, the tiling factors,  m  and  n , are constrained to be divisors of the ReRAM weight matrix M √ó  N using the annotations of  m  |  M ;  n  |  N . Objective:  Maximize  Thr sequ ave Subjected to:  for each layer Lk, P   load Lk   , P  store Lk , P   comp Lk , P   trans Lk , P   merge Lk < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ‚ü® m Lk , n Lk , aG Lk ‚ü© for each layer Lk \nSimilarly, the activation strategy under the pipeline execution mode can be described as below.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 270,
    "augmented": true
  },
  {
    "text": "Modern smart machines come with inte- grated sensors with built-in communication protocols to send data to either an attached computer, a base station or cloud. These features increase the cost of the machines significantly, making it extremely hard for small and medium scale entities to procure them. Moreover, a majority of the machines in operation, comprising much of the modern supply chain, are classical machines without any sensing or intelligence built into them.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "We use 9 different prominently used text-classiÔ¨Åcation models from transformers library [ 81 ] (details available in appendix) designed using Google BERT [ 30 ] architecture trained on  SST  [ 72 ] and  SemEval  [ 66 ] dataset. Each request from the load-generator is modelled after a query with spe- ciÔ¨Åc  <latency,accuracy>  constraints. The queries consist of images or sentences, which are randomly picked from the test dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Custom composition functions are anticipated to further speed up the integration of diverse expert outputs, thereby improving overall response times. Data locality should benefit from prefetching and caching critical data, which would lower transfer delays and potentially speed up training and inference. Intelligent routing algorithms are proposed to efficiently distribute queries based on real-time performance data and expert availability.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "1109/ICRA.2014.6907021 [56]  K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, J. Samp- son, M. T. Kandemir, and V. Narayanan. ResiRCA: A Resilient Energy Harvesting ReRAM Crossbar-Based Accelerator for Intelligent Embedded Processors. 2020.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "Alisa: Accelerating large language model inference via sparsity-aware kv caching. In  2024 ACM/IEEE 51st Annual International Symposium on Computer Ar- chitecture (ISCA) , pages 1005‚Äì1017, Los Alamitos, CA, USA, Jul 2024. IEEE Computer Society.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece ¬© 2021 Association for Computing Machinery. Request permissions from permissions@acm.org. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Extending our assumption from AAS, we hypothesize that the most recent classiÔ¨Åcation result of a sensor must be a good \nrepresentation of what its inference would be for the current activity. Therefore, we need to Ô¨Ånd the classiÔ¨Åcation result for all the sensors without activating them. Hence, by memorizing or  recalling  the most recent classiÔ¨Åcation result, we can get the inference result of a sensor even without activating it.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "These factors collectively restrict innovation, limit accessibility, and contribute to significant environmental impact due to high power consumption and carbon emissions, conflicting with global commitments to achieve carbon neutrality [14,17]. These hardware inefficiencies lead to suboptimal performance and increased energy consumption. Finally, the inherent limitations of monolithic models used in most of the current \nLLM applications [12, 16, 27, 51, 106, 123, 124, 149]‚Äî such as lack of domain specificity and inflexibility in continual learning‚Äîslow down the scientific discovery cycle.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "2019. An open-source benchmark suite for microservices and their hardware-software implications for cloud & edge systems. In  Proceedings of the Twenty-Fourth International Conference on Archi- tectural Support for Programming Languages and Operating Systems .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "It is clear that even with intermittent power availability  Us. ¬¥as  is objectively Ô¨Ånishing more tasks (except compared to a system with a consistently high power availability). Furthermore, we also present a qualitative com- parison on the maintenance cycle needed for these solutions.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "II). Typically, the resolution of the IMU traces can be as high as 20 bits per Ô¨Åeld [3], [28]. From the dataset, we report the average reuse distance, i.e., the average number of preceding frames with same head orientation to be memoized, and show it in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Equilibrium Stability and Impact on Stationarity \nThe key subtlety is that  D  depends on equilibrium strategies. However, the equilibrium ensures a stable operating regime where sensor behaviors‚Äîand thus  D ‚Äîdo not change dras- tically over time. This stability allows us to treat  D  as effectively fixed for the purpose of the asymptotic analy- sis.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "10. From Fig. 10(a), one can observe that, for V1, the energy saving is about  56% with only  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Similarly, Figure 3b demonstrates that, while increasing capacitance should theoretically stabilize the system, its charging characteristics can lead to extended charging times, thus exceeding the latency SLO. Notably, some anomalies in the data were attributed to abrupt power failures, a common challenge in intermittent energy harvesting systems. An ablation study evaluates the contributions of individual components within NExUME.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Depending on the application type, the maximum ensemble size can vary from tens to hundreds of models. classes of images. These 11 models are a representative set to classify all images belonging to 1000 classes in  Imagenet.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "Tigris proposes an algorithm-architecture co-design system specialized for point cloud registration, to improve real-time performance and energy effi- ciency for 3D perception applications [ 65 ]. To efficiently steam volumetric video to mobile devices, GROOT proposes a novel PD- Tree data structure and streams the volumetric videos at a 30fps frame rate with minimal memory usage and computation for de- coding [ 27 ]. Note, however, that none of these existing schemes target at reducing the amount of ‚Äúunnecessary‚Äù computations in the AR holographic applications.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "We then analyze the results measured using these platforms. A. VR Design ConÔ¨Ågurations \nWe evaluate the following six conÔ¨Ågurations of VR stream- ing to demonstrate the effectiveness of D¬¥ej`a View: ‚Ä¢  Baseline  (SW):  We use a mobile GPU [36] to evaluate the baseline VR video streaming. This GPU is commonly used in contemporary VR devices (Oculus [39], Magic Leap [16], and GameFace [47], etc.).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "These simplistic approaches ignore the interdependencies among sensor decisions and fail to account for future resource allo- cation, potentially leading to suboptimal performance over time. Game-Theoretic Modeling \n4.1. Motivation for Game Theory over Simpler Methods \nWhile heuristic methods‚Äîsuch as always selecting the top- k  sensors based on current energy levels‚Äîor greedy algo- rithms that maximize immediate utility might offer straight- forward solutions, they fall short in addressing the strate- gic and long-term dynamics inherent in EH-WSNs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "As shown in Fig. 6b  b  , similar to the  Inter- Holo  pipeline, the additional pose estimation step also sits between the inputs and the original hologram processing, and thus has to be efficient without introducing much overhead. Our profiling on the edge GPU prototype [ 36 ] shows that Kimera-VIO takes, on av- erage, 13 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "In addition, such works have not presented any software level solution to maximize the utilization of the hardware platform. ‚Ä¢  For the ReRAM circuit concerned works [ 6 ], [ 8 ], although they are lightweight, they  cannot  be dynamically reconÔ¨Ågured to adapt changing power levels. In order to accommodate the RCA to the changing harvested power supply, we need a ‚Äúlightweight‚Äù and ‚ÄúÔ¨Åne-grain controllable‚Äù design from both the hardware and software angles.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "[80]  Wei Wang, Jinyang Gao, Meihui Zhang, Sheng Wang, Gang Chen, Teck Khim Ng, Beng Chin Ooi, Jie Shao, and Moaz Reyad. RaÔ¨Åki: machine learning as an analytics service system. Proceedings of the VLDB Endowment , 12(2):128‚Äì140, 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Even though AAS provides signiÔ¨Åcantly better results com- pared to standard round-robin, it is still unable to incorporate ensemble learning. 4:  Accuracy results for AAS combined with ER-r. 0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 RR3 with AAS RR6 RR6 with AAS RR9 RR9 with AAS RR12 RR12 with AAS Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "The ‚Äùappeared‚Äú line represents the percentage of the frames in which the corresponding class is present, e.g. Incorrect exemplar selection might lead to non-IID training data distri- bution, leading to catastrophic forgetting or over-Ô¨Åtting. Fire hydrant, in the taken scene, is present in 100% of the frames.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "The underlying idea is to use spike counts to represent the data value. They propose intra-layer and inter-layer parallelism to support the training phase by reducing potential stalls. ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [ 8 ] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "However, these node-level optimizations are not entirely sufÔ¨Åcient for sensor networks with multiple sensors collectively working together to achieve a goal, which are very common. Although fusing sensor data is not uncommon, it requires one central location where the inference can take place, requiring the communication of sensed data. In networks of energy harvested sensors, the power-hungry nature of commu- nication results in intermittent coordination failures due to one or more of the sensors, or even the fusing node itself, lacking sufÔ¨Åcient energy at the time that inter-node communication is required.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "[14]  Eric Bauer and Ron Kohavi. An empirical comparison of voting classiÔ¨Åcation algorithms: Bagging, boosting, and variants. IEEE, 2005.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Restrictions apply. TABLE II: Salient features of the six videos used in this study. Videos # Frames # Avg.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Los alamos national laboratory and sk hynix to demonstrate first-of-a-kind ordered key-value store computational storage device. IEEE, 2020. Los Alamos National Laboratory.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "However, as mentioned in ¬ß I , the commercial GPUs used for DNN training are typically power hungry ( typically in 100s of Watts TDP; We exprimented with multiple GPUs, server class A6000: 300W TDP, server class A100: 250W ‚Äì 400W TDP, client class TRX3090: 350W TDP, and client class T4: 70W TDP), and are  not  equipped to handle intermittent power emergencies. Therefore, GP-GPUs have classically been used to train DNN models. DNN training is mas- sively parallel, fairly compute intensive, time consuming, and needs a lot of (albeit structured) data movements [ 16 ], [ 37 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "Neural Network Models:  We examine two DNN models in our experiments: YOLOv3 [44] and YOLOv4-tiny [37]. The former one is a quite heavy model, with 106 layers and 65.86 Bn FLOPS, whereas the latter one is a lighter model, with 38 layers and 6.94 Bn FLOPS. The input shape for both of them is  1 √ó 416 √ó 416 √ó 3 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "In The Definitive Guide to AWS Application Integration . Springer. [24]  James Cadden, Thomas Unger, Yara Awad, Han Dong, Orran Krieger, and Jonathan Appavoo.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "USENIX Association. Lessons Learned from the Chameleon Testbed. In  Proceedings of the 2020 USENIX Annual Technical Conference (USENIX ATC ‚Äô20) .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "[60] xinreality, ‚ÄúAsynchronous Spacewarp.‚Äù ‚Äùhttps://xinreality.com/wiki/ Asynchronous Spacewarp‚Äù, 2019. [61] YouTube, ‚ÄúGet Started with YouTube VR.‚Äù ‚Äùhttps://support.google.com/ youtube/answer/7205134?hl=en‚Äù, 2019. [62] V. Zakharchenko, K. P. Choi, and J. H. Park, ‚ÄúQuality metric for spherical panoramic video,‚Äù in  Optics and Photonics for Information Processing X , K. M. Iftekharuddin, A.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "It is known that RCAs achieve their highest efÔ¨Åciency when every cell participates in the MAC computations simul- taneously [ 20 ]. However, naively integrating such an RCA renders its activation power requirement so high that the system will likely have very low duty-cycle on an intermittent supply and may never activate at all for weaker power sources unless a substantial energy store were added, which could be burdensome for form factor constraints in a system that already employs a battery for sensing and other non-inference tasks. TABLE I A N EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT - CYCLE POWER TRACE .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "Therefore, retrofitting such classical machines with smart sensors will help in preventing such failures and will allow taking predictive measures to increase production efficiency. To understand the implications and benefits of retrofitting sensing into these classical machines, we conducted a case study on the data collected from a grinding machine which had three types of sensors ‚Äì one power sensor and two accelerom- eters. It also incorporated the tool parameters like speed, feed \n4 \n0 0.5 1 1.5 2 2.5 3 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nInference Time (ms) \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(a) Inference time vs threshold \n0 1 2 3 4 5 6 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nAverage # Devices Encountered \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(b) Communication through (aver- age) number of devices vs Threshold \n0.78 0.8 0.82 0.84 0.86 0.88 0.9 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nCorrelation \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(c) Correlation vs threshold \n0 0.2 0.4 0.6 0.8 1 1.2 1.4 \n0.86 \n0.861 \n0.862 \n0.863 \n0.864 \n0.865 \n100 200 300 400 500 600 700 800 \nInference Time (ms) \nCorrelation \n# Cloud Estimators Correlation Inference Time \n(d) Accuracy (correlation) and infer- ence time vs # cloud estimators \nFig.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 430,
    "augmented": true
  },
  {
    "text": "However, the intermittent and limited energy income of these deployments demands optimizations for ML applications at the algorithm (Yang et al., 2017; Shen et al., 2022; Mendis et al., 2021), orchestration (Maeng & Lucia, 2018; Mishra et al., 2021), compilation (Gobieski et al., 2018), and hardware development (Qiu et al., 2020; Islam et al., 2022; Mishra et al., 2024) layers. Such platforms represent the future of the Internet of Things (IoT) and energy harvesting wireless sensor networks (EH-WSNs). Equipped with modern machine learning (ML) techniques, these devices can revolutionize computing, monitoring, and analytics in remote, risky, and critical environments such as oil wells, mines, deep forests, oceans, remote industries, and smart cities.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 219,
    "augmented": true
  },
  {
    "text": "II, with the six design conÔ¨Ågurations discussed in Sec. C. Experimental Results \nWe present and compare the energy consumption of the pro- jection computation and the cor- responding video quality impact, when running the Ô¨Åve VR videos described in Tab. V-A.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "¬¥as implements the major portions using ‚Äúcustom hardware‚Äù (dis- cussed in ¬ß IV-A ). To efÔ¨Åciently implement the exemplar selection algorithm,  Us. Since we have multiple teacher models, each of them contributes to the exemplar set, making it robust and removing bias.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Load Balancer : Apart from procuring instances, it is quintessential to design a load balancing and bin-packing  5 strategy to fully utilize all the provisioned instances. We maintain a request queue at every model pool. In order to increase the utilization of all instances in a pool at any given time, the load balancer submits every request from the queue to the lease remaining free slots (viz.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Suppose that each utility function  U i ( t )  is non-decreasing in  ‚àÜ A i ( t ) , that energy constraints and dis- counting ensure diminishing marginal returns for repeated deviations, and that sensors have consistent estimation of ‚àÜ A i ( t )  and   ÀÜ E i ( t  + 1) . Then, the iterative best-response updates described in Algorithm  1  converge to a Nash equi- librium action profile  a ‚àó ( t ) . Existence and Convergence of Equilibrium: \nTheorem 4.1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "4th EURASIP Conference focused on Video/Image Processing and Multimedia Communications (IEEE Cat. No.03EX667) , 2003, pp. 1‚Äì51 vol.1.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "[7]  Suyeon Choi, Jonghyun Kim, Yifan Peng, and Gordon Wetzstein. Optica  (2020), 1563‚Äì1578. 2021.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "The underlying reason is that the smooth  Transition keep   strategy can already handle the smooth transitions with no need of power prediction support for this workload. However, for both  Piezo  and  Thermal , the portions for  PV  are very small. This can also explain why the portions with the power source of  Thermal  are very small.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Scenario2: An object was not captured by the previous frame, but captured by the current frame. Scenario3: A new object is entering the frame (or an existing object is exiting). for different cases.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Although parameters  Œ∏  can theoretically be updated through on-edge training, we assume that frequent retraining in situ is prohibitively expensive given energy constraints. Thus, Œ∏  remains largely static post-deployment. Sensors focus on inference using their local copies of  f Œ∏ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "As the target  2 D  FoV coordinates are already known (VR screen dimensions), these mappings can be performed by multiplying the inverse of the transformation matrix ( T   ‚àí 1 ) with the  2 D  FoV coordinates ( V 2 D ), thus generating the corresponding  360 ¬∞ pixel coordinates ( P ), as shown in Equation 2. P i L   =  T  ‚àí 1 L √ó V i 2 D ; ‚àÄ i  ‚â§ num pixels \nP i R   =  T  ‚àí 1 R √ó V i 2 D ; ‚àÄ i  ‚â§ num pixels (2) \nHere,  V 2 D  = [ q 0 , q 1 , q 2 , q 3 ] ‚ä§ represents the quaternion equiva- lent of the  2 D  FoV coordinates used for matrix multiplication with the inverse transformation matrix ( T   ‚àí 1 ). Note that, this operation, which is a matrix multiplication on each FoV pixel coordinate, can be quite compute intensive.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 232,
    "augmented": false
  },
  {
    "text": "Prior to scaling-up instances, we need to estimate the cost  4b of running them along with existing instances. Cost-aware Procurement : The cost of executing in a fully packed instance determines how expensive is each instance. The requests are sent to GPU instances only if the load matches the  P f  of the instance.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Journal of Artificial Intelligence Research  22 (2004), 385‚Äì421. [22]  Marc Brooker, Andreea Florescu, Diana-Maria Popa, Rolf Neugebauer, Alexandru Agache, Alexandra Iordache, Anthony Liguori, and Phil Piwonka. 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Optica  (2021), 143‚Äì146. [8]  Yu Feng, Patrick Hansen, P. Whatmough, Guoyu Lu, and Yuhao Zhu. 2021.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "The  t i + 1  tiles fetch the next  t i + 1  kernels from the GKDQ and the process continues. This conservative compute and power estimation ensures that none of the kernel computes (the lowest decomposed level of compute unit for the hardware) ever fails and hence there is no need for any partial data movement. The GKDQ always points to the next available kernel location.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Discussion of Results:  1. Dynamic Adaptation:  NExUME‚Äôs DynFit and DynInfer components enable real-time adjustments of dropout rates and quantization levels during training and inference based on instantaneous energy availability. This allows the DNN to maintain high accuracy even under severe energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Gemini: Mapping and architecture co-exploration for large-scale dnn chiplet accelera- tors. In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pages 156‚Äì171. IEEE, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "instead of searching the matched macro block from the entire space (the I-MB-Tree traversal as described in Sec. This speedup comes from: 1). V ), given the points sorted in the Morton code order, the search space for block matching in our proposal is minimized (in the I-frame, now, we only need to search the neighboring regions for the current P-block); 2).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "The commonly used ensemble method in classiÔ¨Åcation problems is bagging [ 33 ] that considers homogeneous weak learners, learns them independently from each other in parallel, and combines them following some kind of deterministic aver- aging process [ 18 ] or majority voting [ 49 ] process. For fur- ther details on ensemble models, we refer the reader to prior works [ 14 , 57 , 58 , 61 , 64 , 77 , 78 , 88 ]. 2.2 Related Work \nEnsembling in practice : Ensembling is supported by com- mercial cloud providers like Azure ML-studio [ 11 ] and AWS Autogluon [ 31 ] to boost the accuracy compared to single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "Function chains are supported in commercial serverless platforms such as AWS Step Functions [4, 23], IBM Cloud Functions [8], and Azure Durable functions [ 6 ]. By characterizing production appli- cation traces from Azure, Shahrad et.al [ 42 ] have elucidated that 46% of applications have 2-10 functions. Excluding the most general (and rare) cases where applications can have loops/cycles within a function chain [ 27 ], applications can be modeled as a  Directed Acyclic Graph  (DAG) where each ver- tex/stage is a function [ 26 ] Henceforth, we will use the terms ‚Äòfunction‚Äô and ‚Äòstage‚Äô interchangeably.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "Since PC generation requires sophisticated instruments like LiDAR or 3D cameras, it was typically done on server- class computers with high compute and storage capabilities. However, with the advent of the modern mobile devices, capturing 3D image and PC on these tiny and battery-backed devices is becoming increasingly common. For example, the recent iPhone 12/13 Pro features LiDAR camera for PC recording, and similarly, Samsung Galaxy S20+/S20 Ultra contains ToF (Time of Flight) camera for the same.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "At any given time  t , the available energy is denoted as  E b ( t ) . Task Fusion and Scheduling:  DynInfer introduces a novel task scheduling algorithm that dynam- ically adjusts to real-time energy availability. When the energy required for executing multiple QuantaTasks exceeds the available energy budget, DynInfer employs  task fusion  to combine smaller tasks into larger atomic units that can be executed within the energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "C ONTINUOUS  L EARNING \nThe Ô¨Årst step to any data-driven learning algorithm is data collection and annotation. III. Overall, Us.¬¥as demonstrates the viability of sustainable con- tinuous learning at edge servers, encompassing advancements in energy harvesting, algorithmic techniques, and hardware adaptation.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "; and vii)  What are the performance, power and accuracy tradeoffs in training or inference, given hyper-parameters like the size of training dataset and the length of prompt? Task-4.1: Evaluation Infrastructure: Experiments + Simulation + Analytical Modeling To compare and contrast the training complexity, training duration, accuracy, and suitability to the cus- tom hardware (utilization) of our proposed EoE-based LLM approach, we need an integrated framework that takes into account the size of the training dataset, hyper-parameters of the smaller expert model and the given hardware resource configuration to estimate the aforementioned parameters. Given extremely long training latencies, we cannot rely on simulation alone as it would take extremely long running times.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "Since knowledge domains often exhibit a hierarchical structure, it is natural to model an EoE using a hierarchical approach to save training and inference costs further. Motivated by this, we propose a novel framework  T ree  E nsemble- o f- E xperts (TEoE). Specifically, given a knowledge domain of  k  layers, we assign the structure to  k  adjacent FFNN expert layers in an EoE model, where the  i th layer indicates the  i th level of the knowledge.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "Since this puts a high demand on memory, one edge VR headset cannot afford to memoize for all possible head orientations. Thus, we want to limit the number of  P buff  that we need to store. To address this, we need to carefully decide how much his- tory is to be memoized for leveraging computation reuse.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Query processing on smart ssds: Opportunities and challenges. In  Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data , pp. 1221‚Äì1230, 2013.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "It can be ob- served that, existing policies, namely,  Arch ,  Fifer  and  Xanadu spawn, respectively, 2.41x, 76% and 30% more containers than  Kraken , on average, across all applications. Overallo- cation of containers in case of  Arch  is due to two reasons: (i) it assumes that all functions in the application will be invoked at runtime; and (ii) it spawns one container per in- vocation request. This repre- sents  ùëÅùê∂ ùëë ùë° (Section 3) for all possible depths,  ùëë .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "These knobs can be integrated to form sequential or pipelined computation modes. For each computation mode, we can derive the optimal activation solutions under each power level directed by the  power model  and  throughput model  ofÔ¨Çine. We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "And, more importantly, these proposals are compliant with the emerging MPEG PCC standards [ 53 ]. The experimental results with six PC videos show that our proposals provide  34 √ó  speedup (latency reduces from  4 . 2 s  to  121 ms ) and  96%  improvement in energy efÔ¨Åciency, with only  13%  compression ratio drop and a minimal degradation in video quality with respect to the state-of-the-art schemes.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Battery (B) \nB \nEH \nƒÇ Sigmoid \n... \nReRAM Memory \nBasic MCU System \nB \nEH EH \nEH \nEH \nB \nFig. 3. ResiRCA architecture overview \nto the network.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Gameformer: Game-theoretic modeling and learning of transformer-based interactive prediction and planning for autonomous driving, 2023. Zhiyu Huang, Haochen Liu, and Chen Lv. URL https://arxiv.org/abs/2303.05760 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "As a result, ‚Äúon-premise‚Äù edge servers  [ 7 ], [ 8 ] have become prime choices for local inference and prediction [ 6 ], [ 39 ], [ 85 ], [ 86 ], necessitating the handling of both learning and inference tasks to meet application needs, including privacy preservation, reduced data communication, and disaggregated computing. As these applications become more ubiquitous, partic- ularly in urban deployments for tasks like trafÔ¨Åc surveillance, autonomous driving, and health analytics [ 18 ], [ 77 ], [ 90 ], demands on communication bandwidth and network reliability limit the direct streaming of diverse data (e.g., video, 3D point cloud, sensor, voice) from numerous sensor-compute nodes to the cloud. Moreover, recent changes in privacy regulations across multiple countries [ 2 ], [ 100 ] call for preserving the privacy of citizens [ 12 ] and may preclude streaming personal data to third-party cloud services.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 213,
    "augmented": true
  },
  {
    "text": "Accessed: 05/19/2021. Texas Instruments. https://transformainsights.com/research/ tam/market , 2023.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Moreover, we believe that advancing the capabilities of smaller models in intermittent environments is crucial for widespread adoption of sustainable, battery-free devices in various domains, including environmental monitoring, industrial IoT, and healthcare. These tiny, reusable devices contribute to reducing embodied carbon and represent a significant step toward sustainability. In many real-world applications, especially in IoT and edge computing, there is a critical need for smaller, energy-efficient models that can operate autonomously without reliance on batteries.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "This approach would notably minimize the consumption of bandwidth and latency and curtail the compute requirements, thereby ensuring that the compute server‚Äôs resources are judiciously employed only for indispensable computations. The critical insight to be gleaned here is reusing data and compute pipeline prior to its transfer to storage could markedly diminish the costs associated with data movement. This strategic compute-reuse could help in optimizing the efficiency and efficacy of computational operations, especially in large scale data intensive and data driven applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Different from these two prior works where approximation decisions are dictated by reuse distance (e.g., the distance between two fully-inferenced frames), Potluck [12] utilized the feature vector extracted from input frames to adaptively trade off computation with reuse of the cached results. In addition to those described above, several ofÔ¨Çoading- based techniques have been proposed to speed up the inference on edge. For example, a dynamic RoI encoding is proposed to compress the data volume to be transferred through net- work [17].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "[66] Y. Zhu, A. Samajdar, M. Mattina, and P. Whatmough, ‚ÄúEuphrates: Algorithm-SoC Co-design for Low-power Mobile Continuous Vision,‚Äù in  Proceedings of the International Symposium on Computer Architec- ture (ISCA) , 2018, pp. 547‚Äì560. 253",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "We would also like to thank Dr. Jack Sampson and Dr. Dinghao Wu for their feedback on this paper. REFERENCES \n[1]  Adel Ahmadyan, Liangkai Zhang, Jianing Wei, Artsiom Ablavatski, and Matthias Grundmann. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "5, in this paper, we evaluate the performance and energy benefits of  HoloAR  by using an embedded GPU prototype for the edge AR headsets [ 36 ], and leave the hardware-software co- design based on FPGA-based acceleration for future work. However, the architectural insights on how to co-design a next-generation accelerator that can accommodate our proposed  HoloAR  framework are discussed later in Sec. 5.5.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Note that  Œ±  can be adjusted based on the application preference, e.g., shifting the  x  =  Œ±  line to the right results in more macro blocks in the I-frame being directly reused for compressing the P-frame, i.e., higher compression ratio, with a cost of quality drop (more details in Sec. ‚Ä¢  Moreover, a vertical line can be drawn in this gap range, i.e.,  x  =  Œ± , and the macro blocks on the left side have ‚Äúenough‚Äù temporal similarities and thus can be compressed with the I-frame (e.g., simply discard the deltas and represent/compress these blocks by the pointers to the matched I-blocks), whereas those on the right have to employ an extra intra-compression step to further compress the deltas. locality opportunities (i.e., the smaller area, the better).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 202,
    "augmented": true
  },
  {
    "text": "95, we choose to ignore further infer- ence computation and only communicate the classification result to the host for further processing. Note that choosing the correlation threshold entirely depends on the application and user preference. 3.2.2 Recoverable Coreset Construction:  The primary reason the accuracy of inferring on coreset data is lower than that of the original model is the loss of features.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "The beneÔ¨Åts of  P f  is contingent upon the models chosen by the model selection policy. Existing ensemble model se- lection policies used in systems like Clipper use all off-the- shelf models and assign weights to them to calculate accu- racy. However, they do not right-size the model selection to include models which primarily contribute to the major- ity voting.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "However, deploying such architectures on ultra-low-power, energy-harvesting devices presents significant challenges due to their substantial \n9 \n200 250 300 350 400 450 500 550 600 \nLatency (ms) \n78 80 82 84 86 88 90 92 94 \nAccuracy (%) \nAccuracy vs. Latency for Different Classes \nR1 R2 R3 SJ SI \n(a) Accuracy vs Latency \n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 Capacitance (F) \n78 \n80 \n82 \n84 \n86 \n88 \n90 \n92 \nAccuracy (%) \nAccuracy vs. Capacitance for Different Classes \nR1 R2 R3 SJ SI \n(b) Accuracy vs Capacitance \nFMNIST CIFAR10 MHEALTH PAMAP AudioMNISTMachine Dataset \n0 \n20 \n40 \n60 \n80 \n100 \nAccuracy (%) \nAbalation Study \nDN DN+DF DN+DF+DI \n(c) Ablation Study Figure 3: Sensitivity and ablation study. DN is DynNAS, DF is DynFit, and DI is DynInfer. computational and memory requirements.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 273,
    "augmented": false
  },
  {
    "text": "1 For squeezenet model, allocating beyond 2GB did not reduce computation time, but resulted in increased cost 2 The smallest standard performance VM (C4 family) comes with 2 vcpus and 3.75GB memory. Implications of Public Cloud Resource Heterogeneity for Inference Serving WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands \n3 How to Design Self-Managed ML Prediction Serving System? But serverless functions can be configured starting from 1 vcpu and 0.128GB memory.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Better refers to the improvement over iNAS+PT baseline. Datasets Full Power MSP on Thermal AP PT iNAS+PT NExUME Better FMNIST 98.70 80.92 86.32 88.93 95.62 7.53% CIFAR10 89.81 64.78 69.29 71.53 83.78 17.13% MHEALTH 89.62 69.77 73.99 77.70 89.62 15.34% PAMAP 87.30 66.33 71.84 74.47 85.24 14.46% AudioMNIST 88.20 73.84 78.03 81.60 87.64 7.40% Table 5: Accuracy of NExUME on MSP board using thermocouple based thermal harvester. Better refers to the improvement over iNAS+PT baseline.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 204,
    "augmented": true
  },
  {
    "text": "3.2.3 Provisioning Time vs Execution Time  We know that new VMs take a few hundred seconds to start-up. Prior literature [ 5 ,  10 ] tries to hide the model load latency by pre-warming serverless function in- stances through periodically issuing dummy requests. Server- less functions  can start-up much faster (1s-10s), but they also incur additional latency to load a pre-trained model from external data-store.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "5 EVALUATION We evaluate our proposed  HoloAR  design by comparing the execu- tion latency and total energy consumption with four different AR hologram setups. In this section, we first describe our evaluation methodology, experimental platform, datasets, and measurement tools. Next, we analyze the results measured using these platforms.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Abstract With a growing demand for adopting ML models for a variety of application services, it is vital that the frameworks serving these models are capable of delivering highly accurate predic- tions with minimal latency along with reduced deployment costs in a public cloud environment. Despite high latency, prior works in this domain are crucially limited by the accu- racy offered by individual models. Intuitively, model ensem- bling can address the accuracy gap by intelligently combining different models in parallel.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "MongoDB: the deÔ¨Ånitive guide: powerful and scalable data storage . \" O‚ÄôReilly Media, Inc.\", 2013. [22]  Francois Chollet.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "1). 2 BACKGROUND AND MOTIVATION \nBefore diving deep into the problems and possible solutions asso- ciated with holographic processing, we first present the hardware \n495 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \nand software pipelines of a typical holographic AR application (in Fig. 5.5).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "The results reported are averaged across both the datasets. Figure  15b  plots the average number of models used by the three policies for the top four constraints. As shown for  Const1 ,  Cocktail  shows similar reduction (as image-classiÔ¨Åcation) with only using 4.8 models on average, which is 40% and 26% lower than Clipper  and  Clipper-X , respectively.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Further, as mentioned in Sec. 8 J , respectively, for one PC frame. This is mainly due to their long execution latencies.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "2 √ó  performance improvement on average, and up to  80%  energy savings, while losing less than  2%  accuracy. We outperform the MCDNN [7] and Euphrates [9] in terms of accuracy, and Potluck [12] and DeepCache [8] in terms of performance improvement. ‚Ä¢  Finally, We compare our approach against four state-of- the-art works (DeepCache [8], Euphrates [9], Potluck [12], and MCDNN [7]).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "We compare the cost of deploying the inference service on a group of virtual machines and  serverless functions . The  serverless functions  are configured according to the memory requirements of each model. We use m4- large instances for VMs and we fix the number of inference queries each VM can handle in parallel, without violating response latencies based on our characterization on AWS EC2.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "However,  Kraken  is able to \nmaintain at least 99.5% SLO guarantee and spawns 50%, 34% and 15% less containers compared to  Arch ,  Fifer  and  Xanadu , respectively. It can be seen that the difference in SLO compli- ance between  Kraken ,  Comm Only , and  Conn Only  increases due to the reduced target SLO. This difference, in terms of percent of SLO violations, changes from being at most 0.1% to being between 0.1 to 0.35%.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Measuring massive multitask language understanding. In  2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS) , pages 742‚Äì755, 2019. [191] Tianyu Zhao, Sharan Narang, Kelvin Guu, Angela Fan, Oriol Vinyals, William W Cohen, and Wei Lu.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Since model execution typically demands either a large memory footprint or high bandwidth or both, using both large capacity DDR and fast memory HBM memory blocks in our chip can be explored to effectively meet these memory requirements. Further, neighboring experts can be mapped to adjacent chiplets for improving physical proximity and reducing data movement costs. Leveraging our prior work on multicores [23,24,77,91,112,144,183‚Äì185], we will explore compiler support in identifying suitable expert-to-chiplet mappings.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Compact language models via pruning and knowledge distillation. arXiv preprint arXiv:2407.14679 , 2024. [114] Naveen Muralimanohar, Rajeev Balasubramonian, and Norman P. Jouppi.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Note that the energy inefÔ¨Åciency arises primarily from i) multiple saves and restores, ii) use of NV memories \nand iii) reconÔ¨Åguring the DRAM (along with a commercial ARM based host CPU). Note that most prior works ignore memory and host overheads while reporting the throughput, efÔ¨Åciency and power numbers. Moreover,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Mentoring Plan \nThis project will accommodate a total of 4 PhD students, as discussed in our Management and Coordi- nation Plan. PI Kandemir is an adviser/co-adviser of 5 female students, and PI Zhang has been advising 1 female PhD student, 4 female undergraduate stu- dents for their honors thesis projects, and serving on PhD dissertation committee for 9 female PhD students including 1 African American student. We plan to share our BPC effort outcomes in our NSF project reports and at different forums such as the annual Big Ten Department Heads meeting as well as in Tapia and CRA-W conferences.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "III. Our main goal in this work is to look deeper into the existing pipeline to dynamically identify better opportunities for optimizations, with minimum changes to the existing software-hardware stack. time support and hardware-based enhancements, performance- and energy-efÔ¨Åcient execution of DNN pipelines for videos on mobile devices are still open problems.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "5b, the user is currently focusing on the  soccer ball ; mean- while the  football  is located outside of the RoF, hence, becomes a candidate for approximation. Now, the  football  needs the full depth planes‚Äô information, while the soccer ball  can be approximated. On the other hand, in  Frame-II , the user moves her eyes and changes the region of focus.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "This feature can only be used as an add-on, along with other inputs to further improve compute reuse scope. For example, if the  360 ¬∞ video frame rate increases from the typical 30 fps to 60 fps, then one can potentially leverage this enhanced compute frequency in conjunction with the head orientation, to further expand the compute reuse window. Note however that, this meta- information is not on the data-dependence chain, and we do not consider it for memoization.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Association for Computing Machinery. ISBN 9781450349529. doi: 10.1145/3123939.3123948. 517‚Äì531, New York, NY, USA, 2017.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "The efficiency of data movement significantly influences the performance and energy consumption of large-scale systems (Park et al.). As earlier discussions highlighted, applications on edge servers need to store generated data on storage stacks. These data are can then be moved to a central facility where they can be further treated for efficient retrieval ans on demand streaming.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "The fol- lowing are the  primary contributions  of our work: ‚Ä¢  Efficient Communication:  We enable low data volume communication by developing extensions to traditional coresets that enhances their applicability to EH-WSN in- ference scenarios. Seeker  provides hardware acceleration support for coreset formation to make them computationally efficient, adaptive, and accuracy-preserving specifically for EH-WSNs. Specifically, we introduce an  activity- aware coreset construction  technique to dynamically adapt to both activity and the available harvested energy, while conserving maximum features of the data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "And Ô¨Ånally, we quantize these deltas for achieving higher compression ratio. In this example, two vectors (as there are two segments) store the Ô¨Ånal data, including  Mid  =  51 , Delta  = [ 0 , 0 ]  for the Ô¨Årst one segment, and  Mid  =  54 , Delta  = [ 0 ]  for the second. 2) What are the Pros and Cons?",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Line-rate compression on lustre/zfs-based par- allel filesystems using noload computational storage processor. 19 \nEideticom and Los Alamos National Laboratory. https://www.eideticom.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "[9] Amey Agrawal, Nitin Kedia, Jayashree Mohan, Ashish Panwar, Nipun Kwatra, Bhargav Gulavani, Ramachandran Ramjee, and Alexey Tumanov. IEEE, 2009. In  2009 IEEE international symposium on performance analysis of systems and software , pages 33‚Äì42.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "[39] Oculus, ‚ÄúOculus Rift and Rift S Minimum Requirements and Sys- tem SpeciÔ¨Åcations.‚Äù ‚Äùhttps://www.tomshardware.com/news/magic-leap- tegra-specs-release,37443.html‚Äù, 2019. [40] OpenCV, ‚ÄúSimilarity check (PNSR and SSIM) on the GPU.‚Äù ‚Äùhttps://docs.opencv.org/2.4/doc/tutorials/gpu/gpu-basics- similarity/gpu-basics-similarity.html‚Äù, 2019. [41] OpenGL, ‚ÄúCubemaps - Learn OpenGL.‚Äù ‚Äùhttps://learnopengl.com/ Advanced-OpenGL/Cubemaps‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 191,
    "augmented": false
  },
  {
    "text": "This can be achieved by using modern  neural compression algorithms  instead of the classical encoding algorithm. However, the neural compression algorithm needs to be  compute efficient  (reusing maximum analytics pipeline), have  high compression ratio  (need to compete with H264) and  feature rich  (could be decompressed and retrieved with a reasonable loss). Furthermore, it needs to take advantage of the  data similarity between frames  to further minimize the storage footprint, and thereby reducing the form factor and need of frequent disk swapping/ maintenance.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Intra-Inter-V2 : For this conÔ¨Åguration, we choose a larger threshold (1200) for the ‚Äúdirect-reuse decision making‚Äù such that the ratio of the  direct reuse  will increase with slight drops in quality. Also, the total number of blocks is 50000, and the search step is set to be the size of the current P-block (i.e., to Ô¨Ånd the best matched block for current P-block, each time, we traverse the search region in the reference frame by this step size). Other settings are not changed (they remain the same as in the Intra-Inter-V1 version).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "How much data do autonomous vehicles generate? https://premioinc.com . (Accessed on 11/13/2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Task-2.5: Runtime Support Our runtime support system will serve as the cohesive glue that efficiently manages system resources, models, and data in real-time with minimal overhead. An example would be: first, dividing the available KV cache space among experts and then, across the attention heads in each expert, with the goal of allocating more cache space to experts and attention heads that can benefit most from that space (compared to other experts/attention heads). And second, we will explore EoE-specific KV cache compression strategies to optimize memory usage including quantization and sparsity optimization tech- niques.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "10  a  . These results indicate that, although we ignore the row-number related information, the resulting PSNR is still sufÔ¨Åcient ( 47 . 71  on average) for VR video applications [26], [62].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "[38] Oculus, ‚ÄúAsynchronous TimeWarp (ATW).‚Äù ‚Äùhttps://developer. oculus.com/documentation/mobilesdk/latest/concepts/mobile-timewarp- overview/?locale=en US‚Äù, 2019. [39] Oculus, ‚ÄúOculus Rift and Rift S Minimum Requirements and Sys- tem SpeciÔ¨Åcations.‚Äù ‚Äùhttps://www.tomshardware.com/news/magic-leap- tegra-specs-release,37443.html‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "[74]  P. Thinakaran, J. R. Gunasekaran, B. Sharma, M. T. Kandemir, and C. R. Das. Phoenix: A constraint-aware scheduler for heteroge- neous datacenters. In  2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS) , June 2017.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "B. Kotra, M. Arunachalam, C. R. Das, and M. T. Kandemir, ‚ÄúA learning-guided hierarchical approach for biomedical image segmentation,‚Äù in  2018 31st IEEE International System-on-Chip Conference (SOCC) , 2018, pp. 227‚Äì232. [19] H. Jiang, A. Sarma, M. Fan, J. Ryoo, M. Arunachalam, S. Naveen, and M. T. Kandemir, ‚ÄúMorphable convolutional neural network for biomedical image segmentation,‚Äù in  2021 Design, Automation Test in Europe Conference Exhibition (DATE) , 2021, pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "Fusing kernels for higher performance deep learning. In Proceedings of the 2017 ACM SIGPLAN International Conference on Compiler Construction , pages 1‚Äì12. ACM, 2017.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "297 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "15 \nC.1.3 Loop Tiling \nThe algorithm uses loop tiling to divide the computation into smaller blocks that can be managed between power interruptions. This tiling not only makes the computation manageable but also optimizes memory usage and cache performance, which is critical in constrained environments. C.1.4 Check-pointing Mechanism \nBefore each power interruption, detected through an energy monitoring system, the algorithm saves the current state using the  SAVE_STATE  function.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "; iv)  How can we identify hot experts and cold experts in LLM inference and how can such information be utilized? ; v)  How should available memory space be managed during training and inference? ; vi) What are the additional complexities and opportunities KV-caches bring in an EoE environment?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "To address these challenges, we propose  Kraken , a DAG workflow-aware resource management framework specifi- cally catered to dynamic DAGs, that minimizes resource con- sumption, while remaining SLO compliant. The key compo- nents of  Kraken  are (i)  Kraken  employs a Proactive Weighted Scaler (PWS) which deploys containers for functions in ad- vance by utilizing a request arrival estimation model. The number of containers to be deployed is jointly determined by the estimation model and function weights.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "This shows how the proposed ‚Äúadaptive‚Äù solution can potentially save more energy with different thresholds in Algo. 10: Tradeoff between accuracy drop and energy saving for (a) V1 and (b) V2 picked from the VIRAT [33] dataset. 2. \nto evaluate the accuracy, and plot the experimental results in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, it is equipped with a 512-core Volta GPU, a 8-core ARMv8 64-bit CPU, and 32GB 256- Bit LPDDR4x Memory. In our implementation, we start the application from CPU (reading the PC data), and then ofÔ¨Çoad the computations to GPU (octree construction, block matching, etc. ), and the compute mode of Jetson AGX Xavier board is set to be 15W.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "We compare against a baseline using na¬®ƒ±ve continuous learning algorithm with no representation learning. In contrast,  Us. ¬¥as uses a 2 level exemplar selection algorithm (one using the conÔ¨Ådence matrix, and then further reÔ¨Åned by the representa- tion learning).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the twenty-eighth annual ACM symposium on Theory of computing , pp. 99‚Äì108, 1996. AMD.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "E.g., with 32 √ó 32 tiles, only 3% of the tiles are identical. In the extreme case where the tile size equals frame size, only less than 0.1% of the successive frames are identical. As a result, any approach trying to exploit frame reuse (e.g., skip inferences for similar frames) based on this speciÔ¨Åc similarity metric (exact pixel match) will not have much scope for optimization.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "5) Video-SpeciÔ¨Åc Analysis:  To investigate how the perfor- mance and energy behavior varies with video salient features such as the object count, objects‚Äô motions, the fraction of area occupied by objects in an entire frame, etc., we have studied the six videos summarized in Table II. V1 and V2 are parking lot videos. V1 has fewer objects and less movements, and thus, compared to V2, the savings on execution time and energy consumption for V1 are slightly higher, as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Ensembling in Azure ML Studio., February 2020. https://docs.microsoft.com/en-us/azure/machine-learning/studio- module-reference/multiclass-decision-forest . USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1053 \n[12]  Ataollah Fatahi Baarzi, Timothy Zhu, and Bhuvan Urgaonkar. Burscale: Using burstable instances for cost-effective autoscaling in the public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "This calls for a dynamic model selection policy which can accurately de- termine the number of models required, contingent upon the accuracy and scalability of the model selection policy. How to save cost? Although dynamic model selection poli- cies can signiÔ¨Åcantly reduce the resource footprint as shown in Figure  3b , the cost is still 20-30% higher when compared to a single model inference.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "1. We comprehensively characterize the cost, accuracy and latency implications of hosting ML inferences on different public cloud resource offerings and unravel the suitable model/resource configurations to meet the cost, latency and accuracy demands. 2.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "the baseline; Region Level Reuse Scheme (e.g., FI+SI+PI) has better performance, because this ‚Äúshallow‚Äù model beneÔ¨Åts more from partial inference. 50% 60% 70% 80% 90% 100% \n0.07% 0.28% 0.40% 1.10% 1.30% \nAccuracy Drop \n(a) V1 \n50% \n60% \n70% \n80% \n90% \n100% \n0.70%0.80%1.10%1.30% 2% \nAccuracy Drop \n(b) V2 \nFig. 10: Tradeoff between accuracy drop and energy saving for (a) V1 and (b) V2 picked from the VIRAT [33] dataset.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "More speciÔ¨Åcally, we (i) develop a novel dynamic model selection, (ii) design a prudent resource management scheme that utilizes weighted autoscaling for efÔ¨Åcient resource allocation, and (iii) lever- age transient VM instances to reduce the deployment costs. Our results from extensive evaluations using both CPU and GPU instances on AWS EC2 cloud platform demonstrate that Cocktail  can reduce deployment cost by 1.4 √ó , while reducing latency by 2 √ó  and satisfying accuracy for 96% of requests, compared to the state-of-the-art model-serving systems. Acknowledgments \nWe are indebted to our shepherd Manya Ghobadi, the anony- mous reviewers and Anup Sarma for their insightful com- ments to improve the clarity of the presentation.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 183,
    "augmented": false
  },
  {
    "text": "Abstract There is an increasing demand for intelligent processing on ultra-low-power internet of things (IoT) device. Recent works have shown substantial efficiency boosts by execut- ing inferences directly on the IoT device (node) rather than transmitting data. However, the computation and power de- mands of Deep Neural Network (DNN)-based inference pose significant challenges in an energy-harvesting wireless sen- sor network (EH-WSN).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "VSS excels in decoupling high-level video operations from storage and retrieval processes, efficiently organizing data on disk, enhancing caching mechanisms, and reducing redundancies in multi-camera setups (Haynes et al., 2021). This system has demonstrated significant improvements in VDBMS read performance, up to 54%, and a reduction in storage costs by up to 45% (Haynes et al., 2021). VSS‚Äôs emphasis on video data optimization makes it a pertinent benchmark for assessing the  Salient Store  storage system‚Äôs capabilities in managing large-scale machine learning data-sets.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "921‚Äì926. IEEE, 2022. Chih-Kai Kang, Hashan Roshantha Mendis, Chun-Han Lin, Ming-Syan Chen, and Pi-Cheng Hsiu.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "In Proceedings of the ACM/IEEE International Conference on Mobile Computing and Networking (MobiCom) . 1‚Äì14. GROOT: A Real-time Streaming System of High-fidelity Volumetric Videos.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "In Proceedings of the 22nd ACM International Symposium on High-Performance Parallel and Distributed Com- puting , pages 151‚Äì160. [36] Xiaobin Dong, Kurt Keutzer, and Cong Zhang. Ramulator: A cycle accurate dram simulator.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "2b. We would also like to point that capturing these opportunities is not trivial and cannot be efÔ¨Åciently done by just optimizing the existing application layer and software stack. In fact, the existing state-of-the-art software stack, such as GoogleVR-SDK [11], simply uses the IMU sensor inputs to calculate the updated transformation matrices, then passes them to the OpenGL [42] engine to process the projection computation, as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "As can be seen from Table IV, MCDNN yields similar latency/energy savings with our approach, but with signiÔ¨Åcantly lower accuracy ( 36 . 9% ). This is mainly because, in MCDNN, the scheduler tends to choose YOLOv4-tiny due to the low energy budget.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "We propose a memoization scheme, called  EA , to capture recent head orientation data for temporal reuse, and for the spatial reuse, we design the  AE  scheme, which leverages the stationary relationship between two eyes to efÔ¨Åciently reduce the amount of projection computation. ‚Ä¢  We implement both our schemes as a  software  enhancement to the existing compute pipeline in NVIDIA GPUs. To further exploit the energy efÔ¨Åciency, we also implement our hardware  prototype using an FPGA to evaluate the energy beneÔ¨Åts brought by the microarchitectural augmentations.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "8, pp. 3886‚Äì 3895, 2017. [16]  C. Dorea and R. L. de Queiroz, ‚ÄúBlock-based motion estima- tion speedup for dynamic voxelized point clouds,‚Äù in  2018 25th IEEE International Conference on Image Processing (ICIP) , 2018, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Time is slotted and indexed by  t  ‚àà N . In each time slot, the network may perform an inference event, dur- ing which sensors have the opportunity to contribute data that enhances the accuracy of a global inference task, such as object detection or environmental classification. Each sensor observes the environment from a distinct van- tage point.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "They propose optimizations to efÔ¨Åciently execute the DNNs on low power IoT devices [7], [8]. Recent works [5], [6] suggest that processing data at the source is more efÔ¨Åcient that sending them to the cloud and getting the results back, owing to the power and latency overhead of data communication. Other recent works [9], [5], [7], [8] have proposed using energy harvesting (EH) solutions to provide additional energy and increase the battery life in IoT devices.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "In  PETRA , Fillia Makedon (Ed.). ACM. [58]  Attila Reiss and Didier Stricker.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "All these videos used are captured at 30fps, and voxelized into  1024 √ó 1024 √ó 1024  voxels (3D points), with each point containing three  Ô¨Çoat-pointing  coordinates and three  unsigned char  RGBs. SpeciÔ¨Åcally, we pick four videos from 8iVFB, and two videos from MVUB. The 8iVFB dataset contains the PC data of four persons, captured by 42 RGB cameras placed at different angles, while the MVUB dataset consists of Ô¨Åve subjects captured by four frontal RGBD cameras.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "For example, an EoE consisting of GPU-affined experts can be mapped to a GPU-only chip, whereas an EoE consisting of varying chiplet affinities can be mapped to a suitable heterogeneous chip. For example, smaller experts may be mapped to individual chiplets (or can be colocated in the same chiplet), while a large expert may be mapped to multiple chiplets. For executing an EoE, we can explore various expert-to-chiplet mapping strategies such as one-to-one, one-to-many, many-to-one, and many-to-many, including EoE mapping to multiple chips.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "B. 06% of the time. Impact on Exemplar Selection \nUs.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 15,
    "augmented": true
  },
  {
    "text": "9b); and a partial \n5 The data is from our estimation based on [ 51 ], rather than real-hardware measurements. 503 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \n(a) Viewing W-CGH from different eye-center positions. 9a; viewing an entire hologram (in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. Figure 7: Inter-Frame attribute compression example.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "[57]  Randall Shumaker and Lackey Stephanie. Virtual, Augmented and Mixed Reality: Designing and Developing Augmented and Virtual Environments: 6th International Conference, VAMR 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014, Proceedings, Part I . 2014.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "It can be seen that smaller models  (MNet, NASMob ) can be packed 2-5 √ó  more when compared to larger models  (IRV2, NASLarge) . There is a linear relationship between  P f  and the instance size. Table  1  provides the  P f  for 11 different models when executed on a  C5.xlarge  instance.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2403.16303 , 2024. [176] Huizi Yu, Lizhou Fan, Lingyao Li, Jiayan Zhou, Zihui Ma, Lu Xian, Wenyue Hua, Sijia He, Mingyu Jin, Yongfeng Zhang, Ashvin Gandhi, and Xin Ma. Large language models in biomedical and health informatics: A review with bibliometric analysis.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Segmentation:  The next step is to partition the sorted PCs (i.e., I-frame and P-frame) into several blocks/segments (similar to the term ‚Äúmacro-blocks‚Äù in 2D image encoding). Block/segment match (BM):  for each block in the P-frame, we iterate through all the candidate blocks in the I-frame and calculate the difference between these  <  I , P  >  block pairs. Finally, the candidate I-block which differs minimally with the P-block is picked as its ‚Äúbest-matched/reference‚Äù block.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "49 √ó  less latency than VSS where as it shows about a  6 . 5b,  Salient Store  has  4 . 18 √ó  speedup compared to the classical storage server.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Folio: Natural language reasoning with first-order logic. [63] Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, and Alexandra Peste. In  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "2 s  to  121 ms ) and  96%  improvement in energy efÔ¨Åciency, with only  13%  compression ratio drop and a minimal degradation in video quality with respect to the state-of-the-art schemes. Note however that, even with our proposals, the execution latency per PC frame is still slightly beyond the real-time requirement (i.e.,  ‚â• 100 ms ). Towards this, in the future, we plan to explore GPU-speciÔ¨Åc \n295 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "The unreliability of individual EH sensors, due to fluctua- tions in energy availability, necessitates the deployment of a large number of inexpensive and potentially unreliable de- vices to ensure network robustness. This redundancy allows for continuous operation despite individual sensor failures or downtime. However, it also introduces complexities in coordinating sensor activities, managing energy resources, and ensuring efficient data collection and processing ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "https://mikhail.io/serverless/ coldstarts/aws/. [14]  2021. Azure Functions Cold Starts.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "0 100 200 300 \nStatic Provisioning \nProbability-based \nXanadu \n# Containers NGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network. 0 100 200 300 \nStatic Provisioning \nProbability-based \nXanadu \n# Containers NGINX ID Movie_ID Text User_Service Rating Compose_Review Movie_Review User_Review Review_Storage \n(b) Media Service. Figure 1: DAGs of Dynamic Function Chains.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "With the help of an activity-aware and recoverable coreset construction and low-power hardware design, we can effi- ciently communicate inferences or compressed data to the host device with minimum power and latency overheads. Seeker , accounting for the available energy budget, con- siders the following decisions:  D0:  Test for data similarity using correlation, and if similarity is found then communi- cate the results to the host;  D1:  DNN at sensor with raw data + Communicate the results to the host;  D2:  Try Quantized \n8 \nStart Current Data \nLast Data \nCorrelation \nPower Predictor\nAbstract to predictive maintenance . Else- vier.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "‚Ä¢  PTU  (HW):  A recent optimized solution [28] utilizes a more energy-efÔ¨Åcient hardware accelerator, i.e., Projec- tive Transformation Unit ( PTU ), to process the compute- intensive projection operations. This is the most recent VR design that uses an FPGA for accelerating the computation. We consider this design as the  state-of-the-art .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "[43]  Johann Hauswald, Michael A. Laurenzano, Yunqi Zhang, Cheng Li, Austin Rovinski, Arjun Khurana, Ronald G. Dreslinski, Trevor Mudge, Vinicius Petrucci, Lingjia Tang, and Jason Mars. Sirius: An open end-to-end voice and vision personal assistant and its implications for future warehouse scale computers. In  ASPLOS , 2015.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Head Orientation Prediction for  360 ¬∞  Video Streaming: To optimize both performance and energy, researchers have leveraged the powerful remote rendering engines on cloud to predict the next head orientation for the VR clients [2], [6], [18], [23], [30]‚Äì[32]. FlashBack maintains a storage cache of multiple versions of pre-rendered frames, which can be quickly indexed by head orientations [2]. In comparison, Semantic- Aware-Streaming (SAS) exploits the semantic information inherent in a VR video content to precisely predict users‚Äô next head orientations [28].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "5b,  Salient Store  has  4 . 49 √ó  less latency than VSS where as it shows about a  6 . 18 √ó  speedup compared to the classical storage server.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "However, to be valuable the power predictor must have high accuracy. Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with  Transition keep   for all the workloads with these power sources. For both  Piezo  and  Thermal  power sources the prediction accuracy when using a multi-power-level-optimized extension of the power predictor in [ 36 ] are above 80%.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "The PIs plan to recruit new women and minorities for this project as well. Intellectual Merit: This project explores hw-sw support to transform applications into suitable device-agnostic codelets, that serve as the granularity for seamless scheduling and execution across GPUs and FPGAs. 5 Results from Prior NSF Support Award # 1763681  (SHF: Medium: Embracing Architectural Heterogeneity through Hardware-Software Co- design); PI: Das; Co-PIs: Sivasubramaniam and Kandemir; duration= 06/01/2018‚Äì05/31/2023; amount= $1,000,000.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Figure 9: Real System: Breakdown of Average End-to-End Response Times in terms of queueing delay, cold start delay and execution time. 99.40% \n99.55% \n99.70% \n99.85% \n100.00% \n0 \n300 \n600 \n900 \n1200 \nArch Fifer Dprob Kraken Sprob Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(a) Social Network. 99.00% \n99.25% \n99.50% \n99.75% \n100.00% \n0 \n300 \n600 \n900 \n1200 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "For example, in Figure 5, if the transition from  Com- pose_Post  to  Post_Storage  depended on the immediate prede- cessors of  Compose_Post , the  Compose_Post  state would be context-dependent and would therefore, be split into context- independent states, namely,  ùê∂ùëúùëöùëùùëúùë†ùëí _ ùëÉùëúùë†ùë° | ùëáùëíùë•ùë° ( Compose Post  given ùëáùëíùë•ùë° was already invoked), ùê∂ùëúùëöùëùùëúùë†ùëí _ ùëÉùëúùë†ùë° | ùëÄùëíùëëùëñùëé etc. We can now transform our previously-assumed Markov Model into a VOMM by splitting up context-dependent states into multiple context-independent states (the number of which is dependent on the DAG structure and the order of the VOMM). for the previous equations to hold.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 165,
    "augmented": true
  },
  {
    "text": "Overall Utility Function: Combining immediate rewards and costs, the overall utility function for sensor  s i  at time  t is: U i ( t ) =  R i ( t )  ‚àí C i ( t ) . This utility function effectively balances the benefits of participation against the associated costs and future oppor- tunities, guiding sensors to make strategic decisions that optimize their long-term contributions to the network. Nash Equilibrium and Stability: A Nash equilibrium (NE) represents a stable action profile  a ‚àó ( t )  where no sensor can unilaterally improve its utility by deviating from its current strategy: \nU i ( a ‚àó i   ( t ) ,  a ‚àó ‚àí i ( t ))  ‚â• U i ( a i ( t ) ,  a ‚àó ‚àí i ( t )) ‚àÄ a i ( t ) ,  ‚àÄ i.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 227,
    "augmented": false
  },
  {
    "text": "291‚Äì304. [3] X. Corbillon, F. De Simone, and G. Simon, ‚Äú360-Degreee Video Head Movement Dataset,‚Äù in  Proceedings of the 8th ACM on Multimedia Systems Conference , 2017, pp. 199‚Äì204.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "IEEE Transactions on Neural Networks and Learning Systems , 32(6):2345‚Äì 2356, 2021. Load balancing techniques for efficient training of large-scale neural networks. [89] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "As a result, the major- ity of application providers use  static resource provisioning , which results in poor resource utilization and higher costs. Public cloud providers leave these major decisions to be ≈Çmanually handled\" by users, which is very time consuming and strenuous. Prior works  [ 3 ,  9 ] have tried to solve the resource scal- ing problem with respect to hosting the applications in VMs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "On the other hand, for applications that demand very small compressed data sizes to transfer through the network, the threshold condition can be relaxed to favor the  direct reuse  more. For example, in this paper, we pick two different thresholds to strike a balance between latency, quality and compression efÔ¨Åciency, as will be discussed in detail later in Sec. VI-C .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Communicate elsewhere \n0-50 50-500 500-1k 1k-10k > 10k Harvested/available power in the sensor node (¬µW) \nCompute at the edge \nCOTS high-end wearables  (bat.) Bonito  (multiple) \nOrigin  (RF) ResiRCA  (RF/Piezo/Solar) Chinchilla  (RF) Ideal Solution  (Any) \nCOTS cheap wearables  (bat.) Seeker  (RF) \nAll compute at edge Partial compute at edge \nDesign space of  ‚ÄúSeeker‚Äù \n(b) Current state-of-the-art of EH-WSN.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "the  Baseline , which contributes to  20%  total energy saving. 9 that, to execute the same amount of the projection computation, the  PTU  scheme consumes only  62%  of energy w.r.t. Due to this, one can observe from Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Our proposal,  Salient Store  , highlights the need for a paradigm shift in storage architecture to accommodate the dynamic and computationally intensive nature of modern ML applications. By reducing unnecessary data movement and enabling near-data processing, CSDs enhance the efficiency, performance, and sustainability of storage servers. Salient Store  , with its intelligent data orchestration and acceleration, can provide up to  6 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "From the software/algorithm perspective, a sub-hologram technique is pro- posed with a tracked viewing-window technology to tailor the holographic computation only for the necessary information in- side of the window [ 52 ]. Optimizations in Holographic Processing:  Holographic pro- cessing has been optimized in various domains [ 33 ,  35 ,  52 ,  54 ], to improve power efficiency or execution performance. For exam- ple, HORN-8 [ 35 ] has proposed a special-purpose computer for electro-holography to reduce the power consumption and still de- liver a high frame rate (similar to that of a cloud GPU).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "Thus, in this paper, we analyze the VR computation pipeline and observe that there is signiÔ¨Åcant scope to skip computations by leveraging the temporal and spatial locality in head orienta- tion and eye correlations, respectively, resulting in computation reduction and energy efÔ¨Åciency. We propose both software modiÔ¨Åcations for existing compute pipeline and microarchitectural additions for further enhancement. The proposed  D¬¥ej`a View  design takes advantage of temporal reuse by memoizing head orientation and spatial reuse by establishing a relationship between left and right eye projection, and can be implemented either on a GPU or an FPGA.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "Vr in tourism: A new call for virtual tourism experience amid and after the covid-19 pandemic. Tourism and Hospitality , 3(1):265‚Äì275, 2022. Philipp M. Grulich and Faisal Nawab.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "De- spite this variation, there may still be matches/recomputations within a frame between two eyes, i.e., IntraFrame-InterEye as shown in  b  in Fig. To leverage this opportunity, we next study the coordinate projection results relationship between left-eye and right-eye. 4.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "If sensors rarely par- ticipate, increase  Œ≥  or decrease  Œ∑ . If sensors over-exert themselves, reduce  Œ≥  or increase  Œ¥, Œ∑ . 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "3480056 \n1 INTRODUCTION Augmented reality (AR) has gained recent traction in both the con- sumer and research communities, thanks to the advances in efficient and low power computing technologies, high-speed communica- tion, and specialized hardware platforms. These technologies have become an important part of our daily life, in the form of creative photography, content creation, gaming, online shopping, virtual touring, and educational and non-educational training, etc. https://doi.org/10.1145/3466752.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "8234‚Äì8240. In  2019 International Conference on Robotics and Automation (ICRA) , pp. IEEE Press, 2019. doi: 10.1109/ICRA.2019.8794073.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "95, we choose to ignore further infer- ence computation and only communicate the classification result to the host for further processing. Note that choosing the correlation threshold entirely depends on the application and user preference. 3.2.2 Recoverable Coreset Construction:  The primary reason the accuracy of inferring on coreset data is lower than that of the original model is the loss of features.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "E CIFAR-100 and BERT Models \nTable  8  shows the different models available for image predic- tion, that are pretrained on Keras using  CIFAR-100  dataset. Model Params (M) \nTop-1 Accuracy(%) \nLatency (ms) P f \nAlbert-base [ 51 ] 11 91.4 55 7 CodeBert [ 32 ] 125 89 79 6 DistilBert [ 67 ] 66 90.6 92 5 Albert-large 17 92.5 120 4 XLNet [ 85 ] 110 94.6 165 3 Bert [ 30 ] 110 92 185 3 Roberta [ 55 ] 355 94.3 200 2 Albert-xlarge 58 93.8 220 1 Albert-xxlarge 223 95.9 350 1 \nTable 9:  Pretrained models for Sentiment Analysis using BERT. Similarly Table  9  shows the different models trained for BERT-based sentiment analysis on twitter dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 213,
    "augmented": false
  },
  {
    "text": "2021. Kraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms. In  ACM Symposium on Cloud Computing (SoCC ‚Äô21), November 1‚Äì4, 2021, Seattle, WA, USA.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "In  USENIX annual technical conference , 2010. [47]  Minoru Kawashima, Charles E Dorgan, and John W Mitchell. Hourly thermal load prediction for the next 24 hours by arima, ewma, lr and \n1054    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nan artiÔ¨Åcial neural network.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "4), with only  1%  overhead w.r.t. baseline. If not, we have to execute the entire computation as in the baseline case.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "These software-based solutions exhibit inefficiencies with respect to energy and time due to performing multiple save- and-restore cycles [ 23 ,  56 ]: while some of these operations are necessary, unnecessary checkpoints will also be conser- vatively performed to ensure forward-progress. Therefore, recent works [ 39 ‚Äì 42 ,  56 ] propose the use of a NVP, where the non-volatility of the hardware itself takes care of saving and resuming the program execution. This reduces software overheads and latencies for handling power emergencies and hence can guarantee better QoS for complex and longer tasks even when power is deeply unreliable.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Thus, using  serverless func- tions  for such scenarios will not drastically reduce cost. For the other traces like Berkeley, WITS and Twitter, the peak- to-median difference is more than 50% and therefore they can benefit from offloading requests to  serverless functions . Observation 4:  It is important to note that, the request arrival pattern plays a key role in determining if mixed procurement can be cost effective.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "The results, summarized in Table  IV , demonstrate the effectiveness of  Us. ¬¥as  in achieving continuous forward progress compared to other approaches. It completed more training tasks while consuming less power and minimizing wastage.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "We would also like to thank Dr. Jack Sampson and Dr. Dinghao Wu for their feedback on this paper. This work was also supported in part by CRISP, one of six centers in JUMP, a Semiconductor Research Corporation (SRC) program sponsored by DARPA. ACKNOWLEDGMENTS \nThis research is supported in part by NSF grants #1763681, #1629915, #1629129, #1317560, #1526750, #1714389, #1912495, and #1909004.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "550‚Äì555. [53]  MPEG, ‚ÄúMPEG Point Cloud Compression,‚Äù  ‚Äùhttps://mpeg- pcc.org‚Äù , 2022. [52]  MPEG, ‚ÄúG-PCC codec description v2,‚Äù ‚Äùhttps://bit.ly/ 3nN43C8‚Äù , 2019.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "This quantity depends on SNR i ( t )  and on the data contributed by other participating sensors, as their combined perspectives shape the overall result. While  ‚àÜ A i ( t )  may not be known precisely, we as- sume that each sensor can estimate its expected contribution based on historical observations and current conditions. Ev- ery inference event presents a binary decision for sensor  s i : a i ( t )  ‚àà{ Participate (P) ,  Not Participate (NP) } .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "As a result, by exploiting the  AE  scheme on the Ô¨Årst frame in Fig. 4  b  , its compute energy can be reduced to only  62 . 35%  of that consumed by baseline.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "2  Further, this locality also exists in attributes (RGB pixels), i.e., spatial locality leads to attribute similarities, and hence opening opportunities for fast attribute compression. 3  And, Ô¨Ånally, the locality extends beyond a single frame, i.e., the temporal locality, which can be leveraged by sorting the points in the Morton code order, creating further opportunities to improve the compression efÔ¨Åciency. Motivated by these opportunities, we propose and evaluate a two-pronged compression approach, where the  intra-frame approach leverages the opportunities described in 1  and 2  , and the  inter-frame  approach takes advantage of 3  .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, there are three points in the this frame:  P 0 ‚Äôs coordinates are  [ 0 , 0 , 0 ] , P 1 ‚Äôs are  [ ‚àí 1 , 0 , 0 ] , and  P 2 ‚Äôs are  [ 3 , 3 , 3 ] . Consider the geometry compression pipeline in PCL [ 72 ], where the points are added one-by-one when constructing the octree. 5  shows an example of geometry compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "For annotating the incoming video stream we use three teachers models, namely, ResNet101 [ 32 ], YOLOV2 [ 22 ], and VGG16 [ 87 ]. This contains a total of 101 hour of video across all cameras of which 30 hours of video is used to Ô¨Åne-tune the teacher models and the rest 71 hours of data is used to evaluate our continuous learning so- lution. Each video stream is recorded with a resolution of 1280  √ó  720 at 30fps.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "Tong Chen, Haojie Liu, Qiu Shen, Tao Yue, Xun Cao, and Zhan Ma. In  2017 IEEE Visual Communications and Image Processing (VCIP) , pp. Deepcoder: A deep neural network based video compression.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "We would also like to point that capturing these opportunities is not trivial and cannot be efÔ¨Åciently done by just optimizing the existing application layer and software stack. We describe the underlying issues to address and emphasize the non-trivialities: ‚Ä¢  To ease development efforts, state-of-the-art VR applica- tions reuse APIs provided by OpenGL [24], [42], and whenever a new frame is decoded, they always invoke the glDrawFrame  twice for both eyes (see line number  257  in googlevr-video360 application [12]). They do not seem to leverage the fact that the transformation matrices are unique for each head orientation and memoizing them will save re-calculating the transformation matrix ( T  ) as well as the projection matrix ( P ).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 177,
    "augmented": true
  },
  {
    "text": "Trans- mitting coresets rather than raw data greatly improves the \nenergy efficiency of communication to the host, when re- quired, and effectively increases the number of completed inferences, thereby increasing overall accuracy. Depending on the incoming data and the EH budget, the sensor decides whether to skip compute, perform an inference at the edge, or form a coreset to offload the inference to the host. The host, after obtaining information from multiple sensors, per- forms any further required computation and uses ensemble learning [ 47 ] to give an accurate classification result.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "3%  accuracy drop, then  21% more energy can be saved (amounting to  77%  energy reduction compared to the baseline). 10(a), one can observe that, for V1, the energy saving is about  56% with only  0 . 07%  accuracy drop; however, if the application is willing/tolerant to live with  1 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Therefore, any PC application meant for visual media like \n283 \nAuthorized licensed use limited to: Penn State University. While PCs containing only the 3D geometry data are commonly used in LiDAR-based 3D imaging for autonomous vehicles or robotics path planning, the lack of attributes nullify their usage for visual media consumption. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "4 \n3.1.1 Adaptive Regularization Strategy \nDynFit introduces an adaptive regularization strategy to address potential overfitting and under- training due to uneven weight updates caused by dynamic dropout and quantization. We monitor the update frequency  F p  of each weight  w p  over a window of  T  iterations: \nF p  =  1 \nT \nT X \nt =1 U p ( t ) , U p ( t ) = \u001a 1 , if  w p  is updated at iteration  t 0 , otherwise (4) \nWeights with  F p  < Œ∏ low  are considered under-trained, and those with  F p  > Œ∏ high  are considered overfitting. Our method differs from standard approaches by integrating energy constraints directly into the optimization, ensuring that the network learns to adapt its parameters based on energy availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 194,
    "augmented": true
  },
  {
    "text": "1080 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Cache topology aware computation mapping for multicores. [77] Mahmut Kandemir, Taylan Yemliha, SaiPrashanth Muralidhara, Shekhar Srikantaiah, Mary Jane Ir- win, and Yuanrui Zhnag. In  Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation , pages 74‚Äì85, 2010.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "[61]  Rachid Saadane, Abdellah Chehri, Seunggil Jeon, et al . 2022. AI-based modeling and data-driven evaluation for smart farming-oriented big data architecture using IoT with energy harvesting capabilities.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Considering the dense features, 3D geometry and the visual attributes captured in PC, especially for the media applications like telepresence and virtual visits, pre-processing [ 21 ], [ 44 ], [ 61 ], [ 84 ], compressing and storing [ 14 ], [ 16 ], [ 19 ], [ 47 ], [ 48 ], [ 74 ], post-processing and streaming [ 25 ], [ 40 ], [ 66 ], [ 76 ], [ 90 ] PC using a mobile device, while maintaining a reasonable quality of service (QoS), are fast becoming challenging tasks. SpeciÔ¨Åcally,  PC compression  ( PCC , or PC encoding ) consists of both geometry (e.g., x, y, z coordinates in the 3D space) and attribute (e.g., RGB colors) compression. Our experiments show that PCC is the most expensive computation in a PC processing pipeline that takes  ‚âà 4 seconds , especially when deployed in mobile/edge devices, and hence, is a major contributor to the performance, video quality, and transmission energy, for the entire PC pipeline.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 254,
    "augmented": false
  },
  {
    "text": "The 8 √ó 8 systolic array in each tile executes multiply-accumulate operations in a pipelined and parallel fashion, abiding by the Weight Stationary approach, thereby optimizing the throughput and efÔ¨Åciency of the train- ing operations within this hardware architecture. Memory accesses are optimally managed via the double-buffered SRAM structures, providing timely data availability for the MAC units. This gra- dient computation, fundamental for learning, is meticulously mapped across the systolic array, ensuring precise and efÔ¨Åcient backpropagation.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Consequently, higher weights have to be assigned to such functions to ensure resilience in the presence of varying application usage patterns. Opportunity 2:  Although proactive provisioning combined with probability-based scaling is useful, it is essential to iden- tify critical and common functions in each DDA and assign them higher weights in comparison to standard functions. Hence, rather than simply measuring the weights only in terms of function invocation frequency, we also need to account for DAG specific factors like  Commonality  and  Con- nectivity .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "The training process is designed to optimize the autoencoder‚Äôs ability to compress and decompress video sequences efficiently, without altering the pretrained feature extractor, thereby providing a stable, high-performance baseline for feature representation. The mathematical formulation for this training process is centered around minimizing the reconstruction loss,  L  =   P N t =1   ‚à• F t  ‚àí ÀÜ F t ‚à• 2 2 ; where  F t   is the original frame at time  t , and  ÀÜ F t   is the reconstructed frame, obtained by decoding the compressed representation that was encoded using features extracted via MobileNet and refined by the motion vector-informed autoencoder. The backpropagation is applied only to the layers of the autoencoder, ensuring that the feature extractor‚Äôs parameters remain intact.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 184,
    "augmented": false
  },
  {
    "text": "(2) \nThis ensures that when energy is low, higher dropout rates and lower quantization bit-widths are used to reduce computational load, and vice versa. Modeling Energy Consumption:  The energy consumption of DNN operations is modeled based on empirical profiling data from the hardware platform. Let  e op  denote the energy consumed per computational operation, which varies with operation type and data precision.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "However, they do not right-size the model selection to include models which primarily contribute to the major- ity voting. We compare the cost of hosting ensembles using both spot (ensemble-spot) and OD (ensemble-OD) instances with the single models hosted on OD (single-OD) instances. Ensemble-spot is explained further in the next section.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Both the proposed software and hardware solutions are modular , and hence can be integrated to the existing pipeline with little change. ‚Ä¢  We evaluate our integrated design, including both  EA  and AE , using an open-source 360¬∞ VR video dataset [3] with the traces of 20 users watching 5 different VR videos. To further exploit the energy efÔ¨Åciency, we also implement our hardware  prototype using an FPGA to evaluate the energy beneÔ¨Åts brought by the microarchitectural augmentations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Springer, 2021. \"premioinc\". How much data do autonomous vehicles generate?",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "National Cybersecurity Center of Excellence (NCCoE). Post-quantum cryptography migration: Nist sp 1800-38b preliminary draft. Technical report, National Institute of Standards and Technol- ogy (NIST), 2023.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "It dynamically adjusts training strategies, such as the intensity and timing of dropout and quantization, based on predictions of energy availability. This method not only conserves energy but also enhances the network‚Äôs adaptability, ensuring robust learning and inference capabilities even under stringent power constraints. Our results show a 6% to 22% improvement in accuracy over current methods, with an increase of less than 5% in computational overhead.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "These strategies ensure that the system remains operational and provides degraded but acceptable performance under severe energy constraints. Novelty in Energy-Aware Scheduling:  While energy-aware scheduling is not novel in itself, our contribution lies in adapting scheduling algorithms specifically for intermittent power environments. Existing scheduling algorithms typically assume stable energy availability and do not account for the atomicity constraints imposed by intermittent power supply.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "An ideal system would be at the point (1,1). The x-axis (power efÔ¨Åciency) denotes the percentage of power cycles where the RCA can activate. The y-axis (power utilization), on the other hand, denotes the percentage of valid power during activations which is actually utilized for computation and data transfer.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "For example, PI Zhang will lead a workshop for high school students featured with an LLM and society seminar and a Computational Linguistics Olympiad competition to inspire students‚Äô interests in CS and AI. Additionally, PI Kandemir will organize an LLM workshop targeting high school teachers, discussing topics such as capabilities of LLMs, how their power and limits can be explained to students, and ethical considerations in using the LLM-based tools. The PIs will seek funding for these activities from Penn State, and in particular from the ICDS (Institute for Computational and Data Sciences).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "[26]  Daniel Crankshaw, Gur-Eyal Sela, Corey Zumar, Xiangxi Mo, Joseph E. Gonzalez, Ion Stoica, and Alexey Tumanov. Inferline: ML inference pipeline composition framework. CoRR , abs/1812.01776, 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Such behavior is seen in some of our workloads such as  ùëÄùëíùëëùëñùëéùëÜùëíùëüùë£ùëñùëêùëí . The order of the VOMM denotes the number of predecessors that influence the tran- sition decision. An application DAG can map neatly onto a Markov model wherein the functions within the application DAG are mod- eled as states of the VOMM.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "To underscore the impact of  Salient Store  at a much larger scale, where one can assume a consolidated edge server catering towards multiple streams as depicted in Ekya (Bhardwaj et al., 2022), we utilized an AWS EC2 F1 instance with Alveo FPGAs, along with EC2 P4 instance with A100 GPUs to implement the continuous learning end-to-end. As shown in Fig. However, it is evident that any compute offloaded to any of the CSDs in these scenarios offers benefits in terms of data processing latency.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "2020. In  2020  { USENIX }  Annual Technical Conference ( { USENIX }{ ATC }  20) . 205‚Äì218.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Since utilities are bounded (due to finite en- ergy and limited accuracy gains) and returns diminish over time, no infinite sequence of profitable deviations is possi- ble. Hence, the best-response dynamics must terminate at a profile where no sensor can improve its utility alone, i.e., a Nash equilibrium. A complete formal proof, including all technical conditions, is provided in Appendix  B .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "This appendix provides a systematic approach to selecting these parameters, including formal bounds, practical heuristics, and an algorithmic procedure to explore suitable values. Guidelines for Hyperparameter Selection and Bounds on Reward Parameters \nThe parameters  Œ≥ ,  Œ¥,  and  Œ∑  govern the reward structure of the proposed framework, influencing whether sensors participate consistently, over-participate and waste energy, or abstain altogether. Conceptual Role of Parameters \nThe scalar  Œ≥ >  0  represents the reward scaling for correct participation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "2020. In  Proceedings of the International Symposium on Microarchitecture (MICRO) . Mesorasi: Architecture Support for Point Cloud Analytics via Delayed- aggregation.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "[84]  Tien-Ju Yang, Andrew G. Howard, Bo Chen, Xiao Zhang, Alec Go, Vivienne Sze, and Hartwig Adam. Netadapt: Platform-aware neural network adaptation for mobile applications. CoRR , abs/1804.03230, 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "The annotations on the new exemplar set created by the representation learner is compared against the conÔ¨Ådence matrix of the edge model to calculate the ‚Äúdrift‚Äù. ¬¥as implements the major portions using ‚Äúcustom hardware‚Äù (dis- cussed in ¬ß IV-A ). Consequently, this exemplar set becomes the training data for the continuous learning, which consequently minimizes the drift.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "In addition to the data de- scribed above, they will also generate and maintain ‚Äúannotations‚Äù attached to i) the libraries used in com- piler and runtime system source codes, and ii) the characterization and experimental data generated by the project. These annotations will provide a kind of ‚Äúdata lineage‚Äù, i.e., they will document a trail that accounts for the origin of a piece of data as well as the stages it went through to reach its final form. In a sense, our annotations will make the data originating from this project more actionable and easily repro- ducible.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "2018. SOCK: Rapid Task Provisioning with Serverless-Optimized Containers. In USENIX ATC .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "Task-1.2: Constructing Morphology of Ensemble of Experts. Task-1.1: EoE Design Space Exploration. Tree Structure \nGraph¬† Structure \nChain Structure \nExpert¬† Function \nForward¬† \nPass \nType/ Subtype \nRouter 1 Router 2 \nRouter 1 \nRouter 2 \nCompo- \nsition \nTask-1.1 to Task-1.2 \nTask-1.2 to Task-1.4 \nTask-1.2 to Task-1.3 \nExpert Splitting \nData \nData \nData \nExpert Merging \nAn Expert from¬† Trained¬† EoE  Model¬†¬† \nTrain ¬†on Domain Datasets \nReinforced  EoE  Expert \nwith New Knowledge \nRemove ¬†Components of Expert¬† Add  Components of Expert \nContinual Learning \nAvaliable¬† Accelerators \nRemove Uncommon¬† \nPathes \nUser¬† Preferences Remove Unwanted \nExperts & Reform \nUser Logs \nRemove Unavaliable \nExperts & Reform \n¬† Experts \nUser Selected/ Unavaliable¬†Experts \nCommonly Routed¬† \nPath \nEoE  Network \nMemory Constraint \nAccelerator \nConstraint \nDomain Experts Skill Experts \nLanguage Experts Data Experts \nMedical Science Law Finance Math Code Retrieval \nDocument Table Image \nGraph \nEN CN TR HI \nSumma- \nrization \nFigure 3 :  An overview of four tasks in Thrust-1.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 256,
    "augmented": true
  },
  {
    "text": "Experimental Platform and Datasets \nPlatforms : We used the Google Pixel 3 Android Phone [20] as our experimental platform. We implemented our FI and PI on top of the ncnn library [5]. This device consists of a 64-Bit Octa-Core, a Qualcomm Snapdragon 845 SoC, [39], a 4GB LPDDR4X memory, and a 64GB storage.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "B. The duplication sensitivity results are presented in Section VI-F. ‚Ä¢  Regarding the throughput absolute values, the results with the power sources of  Thermal  and  TV-RF  are much higher than those with the others, which is constant with the power strength illustrated in Figure 4. Energy efÔ¨Åciency \nWe evaluate energy efÔ¨Åciency by measuring MAC operations per Joule, as shown in Figure 9.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout with learnable mask parameters, along with the QuantaTask optimization to handle energy constraints. D.5 Neuron Shapley Value Dropout with QuantaTask Optimization \nNeuron Shapley Value Dropout applies the concept of Shapley values from game theory (Aas et al., 2021) to assess neuron importance for dropout, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Mathematical Formulation:  The Shapley value  œï i  of neuron  i  is a measure of its contribution to the overall network performance.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "[45] Samsung, ‚ÄúExplore New Dimensions.‚Äù ‚Äùhttps://www.samsung.com/ global/galaxy/gear-vr/#display‚Äù, 2019. [47] Tom‚Äôs HARDWARE, ‚ÄúNvidia‚Äôs Jetson TX2 Powers GameFace Labs‚Äô Standalone VR Headset.‚Äù ‚Äùhttps://www.tomshardware.com/news/ gameface-labs-standalone-steamvr-headset,37112.html‚Äù, 2019. [46] SkySports, ‚ÄúSky VR Virtual Reality,‚Äù ‚Äùhttps://www.skysports.com/ mobile/apps/10606146/sky-vr-virtual-reality‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 173,
    "augmented": true
  },
  {
    "text": "Figure  12b  plots the failure analysis results for top three constraints by comparing the ensemble accuracy to the target accuracy. The desired accuracy for all three constraints are plotted as BL1, BL2 and BL3. We induce failures in the in- stances using  chaosmonkey  [ 19 ] tool with a 20% failure proba- bility.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Our proposal, Origin , holistically looks into multiple aspects of deploying a DNN on an EH-WSN for the purpose of HAR. Origin  combines an intelligent activity aware scheduler with an adaptive and light weight ensemble learning method. Our experiments shows that DNN inference using  Origin , running on a harvested energy only system, is more accurate than energy-constraint- optimized DNNs, running on a fully-powered system.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Complementing the modular models and systems, we advocate for the use of ‚Äúchiplet-based‚Äù hardware accelerators. This dynamic routing reduces computational overhead and energy consumption, helping in addressing the power efficiency concerns. These hardware components are designed to be flex- ible and scalable, allowing customization to specific computational needs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "1b. Specifically, the AR hardware has three major components: Sensor Inputs:  The AR headset receives the real-time information from both the surrounding environment and the user (viewer), with two types of sensing:  ‚ë† ‚Äúworld sensors‚Äù  to sense the physical surrounding the user is currently in, such as cameras for the RGB image and LiDAR/depth sensor for the depth or distance of the objects in front of the user, and  ‚ë° ‚Äúuser sensors‚Äù  to sample the behavior/status of the user, such as inertial measurement unit (IMU) sensors for head rotation, IR sensors for eye tracking, and controller for hand gesture. After sensing, the input samples are then buffered in the video buffer, waiting to be processed timely at the frame-rate.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 167,
    "augmented": false
  },
  {
    "text": "Latency (ms) \n(b)  Wiki-trace:  Relaxed  workload. InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nLatency \n(c)  Twitter-trace:  Strict  workload. InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "678‚Äì683. [6] K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, J. Samp- son, M. T. Kandemir, and V. Narayanan, ‚ÄúResirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent embedded processors,‚Äù in  2020 HPCA , 2020, pp. 315‚Äì327.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Major Results: The main research results so far from this project appear in [70,71,129,140,150,153,156,174,175,179,190]. Award # 2338418 (CAREER: Trustworthy Human-Centered Summarization); PI: Zhang; duration=09/15/24-08/31/29; amount=$546,000. Five PhD students, supported through this project, have graduated and one has joined as a faculty.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "[88] Minho Lee, Sooyeon Park, and Hyunsoo Choi. Ac- cessed: 2024-04-27. Load balancing techniques for efficient training of large-scale neural networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Journal of Parallel and Distributed Computing , 145:45‚Äì58, 2020. [59] Suchin Gururangan, Mike Lewis, Ari Holtzman, Noah A Smith, and Luke Zettlemoyer. Demix layers: Disentangling domains for modular language modeling.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "To further demon- strate the sensitivity of Cocktail to dataset and applicability to other classiÔ¨Åcation applications, we also evaluate it us- ing  CIFAR-100  and Sentiment-Analysis application. The response latency metric includes model inference latency, communication/network latency and syn- chronization overheads. We use three important metrics: response latency, cost and accuracy for evaluating and comparing our design to other state-of- the-art systems.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Association for Computing Machinery. [180] Hengrui Zhang, August Ning, Rohan Baskar Prabhakar, and David Wentzlaff. Llmcompass: En- abling efficient hardware design for large language model inference.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "This state is used to continue the computation exactly where it left off, minimizing redundant operations and ensuring efficiency. D Formulation of Dynamic Dropouts: \nD.1 L2 Dynamic Dropout with QuantaTask Optimization \nL2 Dynamic Dropout leverages the L2 norm of the weights to influence dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Mathematical Formulation:  Let  W  be the weight matrix of a layer.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Race-to-sleep + content caching + display caching: a recipe for energy-efficient video streaming on handhelds. In  Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture , MICRO-50 ‚Äô17, pp. 517‚Äì531, New York, NY, USA, 2017.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Storing only  two \nhead orientations (in registers) and their associated  P buff  in the DRAM occupies only  ‚âà 16 MB  memory space. 5b), limiting the memoization opportunities to those instances. Further, we also observe that, the duration for which the head orientation does not change for three consecutive frames sums up to only  ‚âà 28%  of the video runtime on average (refer to Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "4). Next, the new inputs are fed into Step  4  to perform the PI (details are in Sec. With these new RoIs, in Step  3  , we now only need to focus on the inputs that map to the RoIs, and omit the other ‚Äúunimportant‚Äù regions.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "We empirically measure this by testing for correlation between the sensor signatures of different classes. For two instances of the same class, there should be a very high correlation in the sensor data. Conservatively, we choose a correlation coefficient  ‚â• 0 .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "It has been shown that the power requirement to fully activate a 128 √ó 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [ 3 ]. In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power. With this design, the presented power sources can hardly activate even a small ReRAM.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "However, with limited energy budget on typical edge devices, the accuracy is far from sufÔ¨Åcient for vision applications (quantitative results in Sec. Although the prior works do add value to video analytics, each comes with its own problems and costs. V).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "[18]  K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, ‚ÄúNEOFog: Nonvolatility-exploiting optimizations for fog computing,‚Äù in  Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS , pp. 782‚Äì796, 2018. [19]  M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, ‚ÄúRedesigning software and systems for non-volatile processors on self-powered devices,‚Äù in  2016 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 203,
    "augmented": false
  },
  {
    "text": "If the user task can tolerate lower accuracy prediction, or the user is more conservative about the cost associated with sending a request to the cloud, they could decide to change the threshold according to their requirements. Consequently, the programmable threshold makes the whole design more flexible: the collaboration ratio can be adjusted based on the needs of different types of machines, and more ro- bust compared with the result dependent model simplification strategy which may perform differently on different datasets. Our experiments suggests variance to be the most suitable metric to decide the threshold.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "[102] Avinash Maurya, Robert Underwood, M. Mustafa Rafique, Franck Cappello, and Bogdan Nicolae. Datastates-llm: Lazy asynchronous checkpointing for large language models. In  Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing , HPDC ‚Äô24, page 227‚Äì239, New York, NY, USA, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "119‚Äì135, 2022. Ilker Bozcan and Erdal Kayacan. Au-air: A multi-modal unmanned aerial vehicle dataset for low altitude traffic surveillance, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "[7] AWS Outposts, ‚Äúhttps://aws.amazon.com/outposts/rack/hardware- specs/?nc=sn&loc=4.‚Äù [8] Azure Stack Edge, ‚Äúhttps://azure.microsoft.com/en- us/services/databox/edge/.‚Äù [9] O. Banos, C. Villalonga, R. Garc¬¥ƒ±a, A. Saez, M. Damas, J. Holgado- \nTerriza, S. Lee, H. Pomares, and I. Rojas, ‚ÄúDesign, implementation and validation of a novel open framework for agile development of mobile health applications,‚Äù  BioMedical Engineering OnLine , 2015. [10] S. Bauer, ‚ÄúExplainer: The opportunities and challenges of the lithium \nindustry,‚Äù  Di¬¥alogo Chino , 2020. [11] Beverly Hills has thousands of surveillance cameras, ‚Äúhttps://bit.ly/BeverlyHillsCamera.‚Äù [12] R. Bhardwaj, Z. Xia, G. Ananthanarayanan, J. Jiang, Y. Shu, N. Kar- \nianakis, K. Hsieh, P. Bahl, and I. Stoica, ‚ÄúEkya: Continuous learning of video analytics models on edge compute servers,‚Äù in  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , 2022, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 346,
    "augmented": false
  },
  {
    "text": "The total response latency includes additional 200-300ms incurred for query serialization and data transfer over network. It can be seen that the maximum latency of  Cocktail  is similar to the 75th PCTL latency of  InFaas . This is because the single model inference have up to 2x higher latency to achieve higher accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "9 √ó . We also propose a  recoverable coreset construction  technique, which helps reconstruct the original data from the compressed form with minimum (as low as 0 . 02%) accuracy loss.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Advances in Neural Information Processing Systems , 35:7103‚Äì7114, 2022. [198] Michael Zhu and Suyog Gupta. To prune, or not to prune: exploring the efficacy of pruning for model compression.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": ". . Aggregator \nMaster VM \nUser Requests \n‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ \nQueries Cost aware Procurement \nImportance Sampling \nModel-1  Model-2  Model-3  Model-4  Model-n  \noutput \nHeterogeneity \nPrediction Policy \nAutoscaler \nResource Controller \nLoad Balancer \nÔÅ± argmax O 1  (latency) ÔÅ± argmin O 2  (accuracy) \nCPU GPU CPU GPU \nObjectives \n1a \n3 \n4b \n1b \n2 4 \n4a \n4b \n1 \n6 \n6b \n6a \nw1 w2 w3 wk w4 \n3 \n5  Bin-Packing \nWeight Matrix \nL \nN \nFigure 5:  High-level overview of  Cocktail  design.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "However, if   P \ni   E q i   > E b , we aim to fuse tasks to minimize checkpointing overhead. Task fusion is formalized as finding a partition of  Q  into subsets Q 1 ,  Q 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "¬¥as  will be limited either by the live of the harvesting source ( ‚âà 20 ‚Äì 30 years for solar, ‚âà 10 ‚Äì 12 years for portable wind turbines), or the training hardware (typical life cycle of embedded devices are of range of 7 ‚Äì 10 years). We agree that a limitation of our work comes from the choice of solar energy: unavailability during night and bad weather makes the deployment harder. However, there has been signiÔ¨Åcant recent development in portable wind turbines [ 96 ], which can be deployed on rooftops, can work with  ‚â• 5 mph  wind speed, and can provide power equivalent of 15 solar cells.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock. The energy harvesting mechanism is supported by the power management unit, which can record power production and consumption at an execution cycle level. The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "D.2 Optimal Brain Damage Dropout with QuantaTask Optimization \nOptimal Brain Damage Dropout leverages a simplified version of the Optimal Brain Damage pruning method to adjust dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Perform the forward pass with the updated dropout mask to obtain the output  Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the L2 norm of the weights, along with the QuantaTask optimization to handle energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "5 \nmedium, facilitate computation at the storage level. However, there has been a significant push towards enabling more complex workloads, including query processing on CSDs. Initial applications of CSDs were confined to tasks like encryption/decryption, RAID, and compression.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Instead of updating and storing the occupy bits for each node during the process of adding points, now the outputs of this step are several arrays (Morton codes array, parent array, etc. 4  a  . Note that this step is slightly different from the one in the prior pipeline shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "In the following two subsections, targeting inference-based video applications, we present two novel schemes that take advantage of this similarity:  frame-level pruning  and  region-level pruning . P ROPOSED  S TRATEGIES \nAs discussed in Sec. III, there exist signiÔ¨Åcant similarities between two successive frames (e.g., for more than 95% of the pixels between two adjacent frames) when considering ‚Äúpixel difference‚Äù as the similarity metric.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Optimized schoolbook polynomial multiplication for compact lattice-based cryptography on fpga. IEEE Transactions on Very Large Scale Integration (VLSI) Systems , 27(10):2459‚Äì2463, 2019. Corne Lukken and Animesh Trivedi.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Input : Poses : pose sensors Input : Objs : set of virtual objects Output: Holo–¥rams : Generated holograms \n1  procedure  Intra _ Holo ( Poses ,  Objs ) // main \n2 Cam2ObjDists =  PoseEstimation ( Poses ) \n3 for  obj  in  Objs  do // approx. 500 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 4.4 Intra-Holo Computation Optimization \nAlgorithm 3:  Intra-Holo proposal algorithm.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "The vector index are used to point to the meta-data of the video file and then the actual video data is retrieved from the storage (Shen et al., 2005). This approach helps context-based search like looking for particular objects, events, or attributes (Douze et al., 2024). However, it is obvious that this approach, albeit good for streaming and retrieval, are not entirely space-efficient, and at times can increase the data volume by many folds (Douze et al., 2024).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Imaging and Applied Optics 2018 (3D, AO, AIO, COSI, DH, IS, LACSEA, LS&C, MATH, pcAOP) , DTu5F.6. [23]  Daniel K Nikolov, Sifan Ye, Sydney Dlhopolsky, Zhen Bai, Yuhao Zhu, and Jannick P Rolland. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "This can be achieved by adding several expert functions (e.g., FFNN) and their corresponding gating functions; (3) Quantize, reducing the memory requirement of experts through quantization [34]. Once the user specifies target domains, the algorithm locates the most irrelevant domains in the graph (either branch or leaf) until the number of experts fits within the memory constraints or the relevance reaches a threshold. This can be achieved by deleting its vector in the gating function  g ; (2) Combine, combining several experts in one EoE layer.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "B ACKGROUND AND  R ELATED  W ORK \nIn this section, we start our discussion by explaining a typical DNN execution on mobile devices for video analytics. 1074 \nAuthorized licensed use limited to: Penn State University. We then go over potential optimization opportunities that prior works have explored to make DNN inference mobile-friendly.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "\"https://github.com/google- research-datasets/Objectron/blob/master/index/shoe_annotations\". [44]  OpenCV. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "[7]  W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y. 388‚Äì390, 2019. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, ‚Äú24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors,‚Äù in  2019 IEEE International Solid- State Circuits Conference - (ISSCC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "[63] H. Zhang, P. V. Rengasamy, S. Zhao, N. C. Nachiappan, A. Sivasub- ramaniam, M. T. Kandemir, R. Iyer, and C. R. Das, ‚ÄúRace-to-sleep + Content Caching + Display Caching: A Recipe for Energy-efÔ¨Åcient Video Streaming on Handhelds,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2017, pp. 517‚Äì531. [64] H. Zhang, S. Zhao, A. Pattnaik, M. T. Kandemir, A. Sivasubramaniam, and C. R. Das, ‚ÄúDistilling the Essence of Raw Video to Reduce Memory Usage and Energy at Edge Devices,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2019, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 205,
    "augmented": false
  },
  {
    "text": "[45] Samsung, ‚ÄúExplore New Dimensions.‚Äù ‚Äùhttps://www.samsung.com/ global/galaxy/gear-vr/#display‚Äù, 2019. [46] SkySports, ‚ÄúSky VR Virtual Reality,‚Äù ‚Äùhttps://www.skysports.com/ mobile/apps/10606146/sky-vr-virtual-reality‚Äù, 2019. [47] Tom‚Äôs HARDWARE, ‚ÄúNvidia‚Äôs Jetson TX2 Powers GameFace Labs‚Äô Standalone VR Headset.‚Äù ‚Äùhttps://www.tomshardware.com/news/ gameface-labs-standalone-steamvr-headset,37112.html‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 173,
    "augmented": false
  },
  {
    "text": "Our experiments show that PCC is the most expensive computation in a PC processing pipeline that takes  ‚âà 4 seconds , especially when deployed in mobile/edge devices, and hence, is a major contributor to the performance, video quality, and transmission energy, for the entire PC pipeline. However, it is challenging to design an optimal point cloud \n282 \n2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO) \n978-1-6654-6272-3/22/$31.00 ¬©2022 IEEE DOI 10.1109/MICRO56248.2022.00031 \n2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO) | 978-1-6654-6272-3/22/$31.00 ¬©2022 IEEE | DOI: 10.1109/MICRO56248.2022.00031 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 212,
    "augmented": false
  },
  {
    "text": "(b) Viewing W-CGH from different focal distances. Eye-center coordi- nates from left to right:  (0, 11mm) ,  (0, 12mm) ,  (0, 13mm) , and  (0, 14mm) . 503 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \n(a) Viewing W-CGH from different eye-center positions.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "Specifically, given a knowledge domain of  k  layers, we assign the structure to  k  adjacent FFNN expert layers in an EoE model, where the  i th layer indicates the  i th level of the knowledge. When training, a document of NLP is first routed to CS in the first layer, then routed to AI, and NLP. For in- \nstance, in a three-layer knowledge domain, NLP is under Artificial Intelligence (AI), which is under Com- puter Science (CS).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Initially, the bounding box is inÔ¨Ånitely small (side length is  0 , corresponding to no data); and the octree only has one root  node, which is just a ‚Äúvirtual placeholder‚Äù containing \n288 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Consider the geometry compression pipeline in PCL [ 72 ], where the points are added one-by-one when constructing the octree.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "However, selecting the appro- priate models dynamically at runtime to meet the desired accuracy with low latency at minimal deployment cost is a nontrivial problem. Intuitively, model ensem- bling can address the accuracy gap by intelligently combining different models in parallel. Towards this, we propose  Cocktail , a cost effective ensembling-based model serving framework.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "[38]  Synopsis, ‚ÄúHSPICE.‚Äù https://www.synopsys.com/veriÔ¨Åcation/ams- veriÔ¨Åcation/hspice.html/. [39]  H. Lv, X. Xu, P. Yuan, D. Dong, T. Gong, J. Liu, Z. Yu, P. Huang, K. Zhang, C. Huo, C. Chen, Y. Xie, Q. Luo, S. Long, Q. Liu, J. Kang, D. Yang, S. Yin, S. Chiu, and M. Liu, ‚ÄúBEOL based RRAM with one extra-mask for low cost, highly reliable embedded application in 28 nm node and beyond,‚Äù in  2017 IEEE International Electron Devices Meeting (IEDM) , pp. 2.4.1‚Äì2.4.4, 2017.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 202,
    "augmented": false
  },
  {
    "text": "2. Fig. As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efÔ¨Åciency under stable, high-power scenarios.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "SEUSS: skip redundant paths to make serverless fast. In  Proceedings of the Fifteenth European Conference on Computer Systems . 1‚Äì15.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "We ensure its performance by: 1. Empirical Validation : We compare the heuristic‚Äôs \n5 \nperformance with the optimal solution on smaller problem instances using exhaustive search and find that the heuristic achieves within 95% of the optimal task completion rate. 2.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Directions in deep learning hardware. Available at:  https://youtu. YouTube, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "C ONCLUDING  R EMARKS \nThe growth of smart cities and urban mobility applications, along with reformations in privacy laws, have produced a need for pervasive, DNN based continuous learning at the edge. VII. Although current commercial devices are capable of handling inference at the edge, the power and resource requirements of training make it impractical and unsustainable for all edge nodes to also perform continuous training off of grid power.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Therefore, we employ an intelligent ‚Äúdata sampling mechanism‚Äù to select the frames that might contain new information and a potential candidate for learning. Fig. 2  shows the different components of the student-teacher data annotation model adapted in  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Therefore, by running a few iterations of the SGD algorithms with various other hyperparameters, we can easily  predict  the con- vergence of the models. Note that this needs to be done every time one of the constraints (accuracy, power etc.) changes.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Spotcheck: Designing a derivative iaas cloud on the spot market. In  Proceedings of the Tenth European Conference on Computer Systems , pages 1‚Äì15, 2015. [70]  Steven A Shaya, Neal Matheson, John Anthony Singarayar, Nikiforos Kollias, and Jeffrey Adam Bloom.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "[51]  Mu Editor 2022. https://codewith.mu/en/. Code with Mu a simple Python editor for beginner programmers.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Compute the activations  a  and apply the dropout mask: \nm i  =  œÉ ( z i ) \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y ) . Calculate the gradients of the loss with respect to the weights and dropout mask parameters: ‚àÇ L ‚àÇW ij , ‚àÇ L ‚àÇz i For each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) If  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask parameters  z  based on the gradients: \nz i  ‚Üê z i  ‚àí Œ∑  ‚àÇ L \n‚àÇz i \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \n20 \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Inference with Learning Sparse Masks Dropout and QuantaTask Optimization:  Check the available energy using DynAgent.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 363,
    "augmented": false
  },
  {
    "text": "Deeprecsys: A system for optimiz- ing end-to-end at-scale neural recommendation inference. In  2020 ACM/IEEE 47th Annual International Symposium on Computer Archi- tecture (ISCA) , pages 982‚Äì995, 2020. [40]  Rui Han, Moustafa M. Ghanem, Li Guo, Yike Guo, and Michelle Osmond.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "1 , our experiments, on different modalities, shows the accuracy degradation due to data drift. As depicted in Fig. Although, multiple task-dedicated models are typically deployed to enhance accuracy and reduce sampling bias [ 70 ], particularly in scenarios like trafÔ¨Åc monitoring, where different time periods exhibit distinct trafÔ¨Åc patterns, they are not immune to data drift.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the IEEE International Conference on Big Data , pages 1234‚Äì1243. IEEE, 2019. [183] Yuanrui Zhang, Wei Ding, Mahmut Kandemir, Jun Liu, and Ohyoung Jang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "In Proceedings of the 2013 conference on empirical methods in natural language processing , pages 1631‚Äì1642, 2013. [72]  Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Fi- nally, Section  ? ? presents simulation results and Section  ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 19,
    "augmented": true
  },
  {
    "text": "Ô¨Ånish training on the exemplars (described in ¬ß III-B ) as soon as possible and also reach the desired accuracy ‚Äì but to do this within the harvested budget. A more preferable solution is to get rid of drift as quickly as possible, i.e. Given enough time even na¬®ƒ±ve low power hardware can Ô¨Ånish training, but will have longer periods where the drift is exposed.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "[27] Z. Gong, H. Ji, C. W. Fletcher, C. J. Hughes, and J. Torrellas, \n‚ÄúSparsetrain: Leveraging dynamic sparsity in software for training dnns on general-purpose simd processors,‚Äù in  Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques , 2020, pp. 279‚Äì292. [28] J. R. Gunasekaran, C. S. Mishra, P. Thinakaran, B. Sharma, M. T. \nKandemir, and C. R. Das, ‚ÄúCocktail: A multidimensional optimization for model serving in cloud,‚Äù in  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , 2022, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 192,
    "augmented": false
  },
  {
    "text": "Under these conditions, we have: \nlim k ‚Üí‚àû E [ J ( Œ∏ k )] =  J ( Œ∏ ‚àó ) and lim k ‚Üí‚àû E [ ‚à•‚àá J ( Œ∏ k ) ‚à• ] = 0 . This implies  Œ∏ k  converges in expectation to a stationary point  Œ∏ ‚àó of  J ( Œ∏ ) . Equilibrium Stability and Impact on Stationarity \nThe key subtlety is that  D  depends on equilibrium strategies.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Video Type (Cam movement/focus of attention direction) \nFrame Rate (fps) \n#Frames Bit Rate (kbps) \nV1 Rhinos [4] Stationary cam, no focus direction 30 3280 13462 \nV2 Timelapse [56] \nStationary cam, fast-moving objects, no focus direction \n30 2730 15581 \nV3 Rollercoaster [35] \nFast-moving cam hooked in front of a rollercoaster, uni-direction focus \n29.97 6194 16075 \nV4 Paris [51] \nStationary cam, smooth scene cuts, no focus direction \n59.94 14629 14268 \nV5 Elephants [5] Stationary cam, uni-direction focus 30 5510 16522 \nthis work, we are focusing on reusing computation results rather than reducing the content maintenance/transfer, and hence do not consider that optimization. In \n246 \nTABLE II: Video workloads. No.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 210,
    "augmented": true
  },
  {
    "text": "[164] Wikimedia Foundation. Wikipedia database dumps. https://dumps.wikimedia.org/ , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "Aggregation:  The aggregator averages the received gradients: b ‚àá J ( Œ∏ k ) =  b ‚àá L ( Œ∏ k )+ Œª 1 ‚àá ‚Ñ¶ SNR ( Œ∏ k )+ Œª 2 ‚àá ‚Ñ¶ complexity ( Œ∏ k ) . These gradients are computed analytically since the regularizers are explicit, differentiable functions of  Œ∏ . 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "This 10 √ó  performance gap between the practical scenario and the ideal case (and the large amount of power/energy consumption this task makes) motivates us to focus on holographic processing in this paper, and explore the opportunities for improv- ing the hologram computational efficiency to speed up the overall AR application execution and reduce its energy consumption. 2 In this paper, we mainly use the popular depthmap input method. 7 ms on an edge GPU 3 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Cocktail  spawns 29% lesser VMs on top of Clipper-X , because it is not aggressive enough like  Cocktail to downscale more models at every interval. It is to be noted that the savings are lower for  Relaxed  workload because, the number of models in the ensemble are inherently low, thus leading to reduced beneÔ¨Åts from scaling down the models. Intuitively,  InFaas  has the least number of VMs spawned because it does not ensemble models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "(2009)) states that for con- vex, Lipschitz-smooth objectives and unbiased gradient oracles, SGD converges to a stationary point if the step sizes  { Œ± k }  decrease at an appropriate rate. Diminishing Step-Size and Convergence Results \nClassical convex optimization theory (see Bottou et al. (2018) or Nemirovski et al.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "the  Baseline  method. Later, we show quality results compared to the baseline design. In addition, we also discuss the  our design‚Äôs versatility  on other 360 ¬∞ video representation formats.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "III-B , which indicates that the locality revealed by \nthe Morton codes does not only exists among the geometry data, but it can also help with the attribute compression. Note that, the Morton codes have already been generated as intermediate results during the geometry compression, thus, can be (re)used to identify the spatio-locality for the attribute compression without any extra cost. SpeciÔ¨Åcally, as shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Kraken , while spawning more containers, also is seen to lag behind the trend of the trace due to load prediction errors. Performance under Sparse Load:  Analysis of logs col- lected from the Azure cloud platform [ 42 ] shows request volumes that are much lighter (average of 2 requests/hour) than those of the traces we have considered. Moreover, more than 40% of requests show significant variability in inter- arrival times.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "While unstable power sources have been successfully utilized for applications in the IoT space [ 17 ], [ 18 ], [ 19 ], their use has not been heavily explored for RCA design. Current RCA approaches can be divided into two categories. The approaches in the Ô¨Årst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [ 3 ], [ 4 ], [ 5 ], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [ 6 ], [ 8 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "According to the 2023 McKinsey Global Survey on AI [4], 65% of respondents indicated that their organizations are now utilizing generative AI technologies powered by LLMs, a fig- ure that has nearly doubled from a survey conducted ten months earlier. Their seamless integration into everyday life across diverse domains‚Äîsuch as virtual assistants [12,16,51], customer service chatbots [6,121], code generation tools like GitHub Copi- lot [48], and knowledge management systems like NotebookLM [52]‚Äîhas profoundly impacted how we interact with technology. In healthcare for instance, more than 40% of institutions are leveraging LLMs to enhance patient care through improvements in diagnos- tics, patient support, and documentation efficiency [122, 130, 142, 176].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "The model cache is implemented as a hash-map using  Redis  [ 16 ] in-memory key-value store for fast access. Constraint speciÔ¨Åcation : We expose a simple API to de- velopers, where they can specify the type of inference task (e.g., classiÔ¨Åcation) along with the  <latency,accuracy> constraints. Developers also need to indicate the primary ob- jective between these two constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "ISSN 0140- 3664. doi: https://doi.org/10.1016/j.comcom.2019.10.012. URL  https://www.sciencedirect. com/science/article/pii/S0140366419307960 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "First, we decompose EoE networks into three parts, including routing, expert and aggregation functions, constructing a repository of function choices for each type. We unify these three types of functions in two steps. Next, we evaluate the new combinations by extracting one function from each type.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "VIII. In order to accommodate the RCA to the changing harvested power supply, we need a ‚Äúlightweight‚Äù and ‚ÄúÔ¨Åne-grain controllable‚Äù design from both the hardware and software angles. C ONCLUSION \nMAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "The modular nature of the weight stationary mapping makes it a strong candidate for use in a re-conÔ¨Ågurable or morphable systolic structure as turning off some compute is the same as not computing a kernel and scheduling it for later. Therefore,  Us. This property is true both for the forward pass and the backward pass of the standard CNN training.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Thus, using  serverless func- tions  for such scenarios will not drastically reduce cost. Observation 4:  It is important to note that, the request arrival pattern plays a key role in determining if mixed procurement can be cost effective. For the other traces like Berkeley, WITS and Twitter, the peak- to-median difference is more than 50% and therefore they can benefit from offloading requests to  serverless functions .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Projection:  Note that, the output frames from the decoder are still in the  spherical coordinate system . This is because, for encoding purpose, the original  360 ¬∞ videos are projected into the 2D plane (usually represented in 2D format such as Equirectangular [52], Cubemap [41], etc.). Therefore, unlike the 2D video processing where the display can directly read \n242 \n59% \n29% \n6%  6% \nCompute \nMemory Decode Display \n(a) Power breakdown.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "2 Characterization and Motivation \n2.1 Variability across model types \nDepending on the accuracy and latency requirements of an end-user application, multiple models (shown in Figure  1 ) might satisfy a given constraint. For example, consider a face- recognition application that demands a response latency of under 500ms (ISO-latency). As shown in Figure  2a , four differ- ent models can satisfy the response latency, but each model comes with a different prediction accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 5th International Workshop on Embedded and Mobile Deep Learning , pp. 13‚Äì18, 2021. Tianyi Shen, Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Some methods pro- pose selecting a subset of sensors based on energy levels or predefined schedules ( ? Traditional approaches often assume con- tinuous participation of all sensors, which is impractical in energy-constrained environments ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "dimensions , 30:33. 21 \nInhyuk Park, Qing Zheng, Dominic Manno, Soonyeal Yang, Jason Lee, David Bonnie, Bradley Settlemyer, Youngjae Kim, Woosuk Chung, and Gary Grider. Kv-csd: A hardware-accelerated key-value store for data-intensive applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "[157] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. In  Advances in Neural Information Processing Systems , pages 5998‚Äì6008, 2017. Attention is all you need.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "By the end of the project, the entire framework along with sample expert models, algorithms, system support and documentation will be in the public domain. Our simulation testbed will be tested, refined if necessary, and will be updated in the public domain (Github). The results will be disseminated through timely scientific publications in respected conferences and journals throughout the project period.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": ". . The inference process is represented as a set of tasks  T  =  { T 1 , T 2 , .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "We implemented a counter (local kernel counter) to keep track of the size of the remaining local work queue of each of the tile. We also implemented a counter (layer kernel counter) which keeps track of the total kernels to be scheduled for each layer. Whenever all the local work queue counter hits zero along with the layer kernel counter, the control moves to schedule the next layer (or previous layer in backward propagation) for computation.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Each video stream is recorded with a resolution of 1280  √ó  720 at 30fps. This contains a total of 101 hour of video across all cameras of which 30 hours of video is used to Ô¨Åne-tune the teacher models and the rest 71 hours of data is used to evaluate our continuous learning so- lution. For annotating the incoming video stream we use three teachers models, namely, ResNet101 [ 32 ], YOLOV2 [ 22 ], and VGG16 [ 87 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Although modern encryption algorithms like RSA are secure, there is still a threat of  store now decrypt later 2   kind of attack (National Cybersecurity Center of Excellence (NCCoE), 2023). To mitigate this,  quantum safe encryption algorithms needs to be used without hindering the throughput . Furthermore, the design  needs to be programmable  to ensure encryption keys to be changed regularly for additional security.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "4). With these new RoIs, in Step  3  , we now only need to focus on the inputs that map to the RoIs, and omit the other ‚Äúunimportant‚Äù regions. Next, the new inputs are fed into Step  4  to perform the PI (details are in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "M. Bramberger, J. Brunner, B. Rinner, and H. Schwabach. Real-time video analysis on an embedded smart camera for traffic surveillance. In  Proceedings.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "This conÔ¨Ådence score would further update the weight matrix of the host device using a moving average method and keep updating it as the user keeps using the device. The initial conÔ¨Ådence matrix, derived from the test cases, would be programmed into the host device. Further, after each successful classiÔ¨Åcation, the sensors would send the conÔ¨Ådence score for that classiÔ¨Åer along with the output class.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "First, for the quality-critical applications such as AR surgery [ 56 ], ultra-high resolution/quality of holograms are typically required. In this case, offloading computations to a resource-rich cluster/cloud system would be a more reasonable design choice (instead of approximating on the edge). Specifi- cally, there are two classes of applications that would probably achieve only limited benefits from our approach.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "We cluster the experts according to their domain similarity so that each parent node is assigned two most similar leaves. Next, the routers are trained on the new topology, and the leaf nodes are used when the query routes to them. 2.2 Thrust-2: System Support for Expert Scheduling and Data Movements The primary goal of this thrust is to explore novel system support ‚Äì targeting  both  training and inference ‚Äì that complements our algorithmic support for EoE in Thrust 1 and architectural support for EoE in Thrust 3.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Alternatively, reinforcement learning or Markov Decision Process-based approaches could adaptively learn partici- pation policies that consider both immediate rewards and future states. However, these methods often require exten- sive training data, significant computational resources, and complex communication protocols, which may be impracti- cal for resource-constrained sensor nodes. In contrast, a game-theoretic framework provides equilib- rium guarantees, ensuring stable and cooperative partici- pation strategies.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Key contributions  of the work include: ‚Ä¢  We propose algorithmic enhancements of  continuous learn- \ning  for mitigating data drift and design a  student-teacher based automated data labelling algorithm , to prepare train- ing exemplars from input data. We use a two-level data annotation mechanism: exemplar identiÔ¨Åcation based on the \n1 Vedic goddess of dawn in Hinduism [ 36 ]; emphasizing the dawn of sustainable continuous learning and signiÔ¨Åcance of solar power in our design. Us.¬¥as also employs a dynamically morphable systolic array for enabling energy- efÔ¨Åcient computing within the harvested power envelope.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Dodge, T. Prewitt, R. Tachet des Combes, E. Odmark, R. Schwartz, \nE. Strubell, A. S. Luccioni, N. A. Smith, N. DeCario, and W. Buchanan, ‚ÄúMeasuring the carbon intensity of ai in cloud instances,‚Äù in  2022 ACM Conference on Fairness, Accountability, and Transparency , 2022, pp. 1877‚Äì1894. [22] E. Dong, Y. Zhu, Y. Ji, and S. Du, ‚ÄúAn improved convolution neural \network for object detection using yolov2,‚Äù in  2018 IEEE International Conference on Mechatronics and Automation (ICMA) .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 176,
    "augmented": false
  },
  {
    "text": "In this work, the parallelism granularity  G  of a layer is determined by the ratio between 50% of the peak harvested power during proÔ¨Åling and the power consumption of the full- size ReRAM corresponding to this layer. That is, if the 50% peak harvested power by proÔ¨Åling is twice ( G =2) of the power consumption with a ReRAM size of Layer 1 of 25x6, the RCA will be designed to offer two sets of ReRAMs sized 25x6 for Layer 1. The actual parallelism granularity  aG ‚â§ G  for a layer is decided by the harvested power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "Traditionally, data drift has been handled by cloud-based periodic re-training using continuous learning algorithms [ 20 ], [ 74 ]. As these applications become more ubiquitous, partic- ularly in urban deployments for tasks like trafÔ¨Åc surveillance, autonomous driving, and health analytics [ 18 ], [ 77 ], [ 90 ], demands on communication bandwidth and network reliability limit the direct streaming of diverse data (e.g., video, 3D point cloud, sensor, voice) from numerous sensor-compute nodes to the cloud. However, there are challenges in resources, privacy, and sustainability to utilize existing techniques at envisioned scales.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 2021 International Conference on Management of Data , pp. 685‚Äì696, 2021. Vss: A storage system for video analytics.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Introduction \nThe rapid proliferation of the Internet of Things (IoT) has sparked a tremendous growth in the scale and diversity of sensor deployments, from smart homes to expansive in- dustrial and environmental monitoring systems. 1. Simulation results demonstrate that our integrated approach signif- icantly enhances inference accuracy and energy efficiency compared to traditional participation strategies.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "In this case, the side length of the bounding box cube becomes 2 , and now  P 0  is located inside the bounding box. And (2), inserting the new point into the current octree. In this case,  P 0 is located in the  7 th  child of the  root  node, and the  root  node now stores the occupy information, which is  00000001  (the right-most  1  indicates a ‚Äúchild‚Äù in  7 th  leaf node).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "F Spot Instance Price Variation \nWe proÔ¨Åle the spot price of 4 types of  C5  EC2 VMs over a 2-week period in August 2020. The price variation is shown in Fig 18 . 0 100 200 300 Time \n0.1 \n0.2 \n0.3 \nPrice ($) \nxlarge 2xlarge 4xlarge 8xlarge \nFigure 18:  Spot instance price variation (time is in hours).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "[80] A. Sarma, S. Singh, H. Jiang, A. Pattnaik, A. K. Mishra, V. Narayanan, \nM. T. Kandemir, and C. R. Das, ‚ÄúExploiting activation based gradient output sparsity to accelerate backpropagation in cnns,‚Äù  arXiv preprint arXiv:2109.07710 , 2021. [81] A. Sarma, S. Singh, H. Jiang, A. Pattnaik, A. K. Mishra, V. Narayanan, \nM. T. Kandemir, and C. R. Das, ‚ÄúExploiting activation based gradient output sparsity to accelerate backpropagation in cnns,‚Äù  arXiv preprint arXiv:2109.07710 , 2021. [82] scale.com, ‚ÄúData labeling: The authoritative guide,‚Äù https://scale.com/guides/data-labeling-annotation-guide#data-labeling- for-computer-vision , (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 269,
    "augmented": false
  },
  {
    "text": "Portfolio-driven resource management for transient cloud servers. arXiv preprint arXiv:1910.01108 , 2019. [68]  Prateek Sharma, David Irwin, and Prashant Shenoy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "The moving window is designed using a counter to shift the streaming data.) The sensor also stores one ground truth trace for each activity. The sensor computes the correlation (  1a  ) between the stored ground truth and the current data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "[5]  J. 3, 2016. B ¬¥ edorf, E. Gaburov, and S. P. Zwart, ‚ÄúA sparse octree gravitational n-body code that runs entirely on the GPU processor,‚Äù  Journal of Computational Physics , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Further, neighboring experts can be mapped to adjacent chiplets for improving physical proximity and reducing data movement costs. Leveraging our prior work on multicores [23,24,77,91,112,144,183‚Äì185], we will explore compiler support in identifying suitable expert-to-chiplet mappings. Since model execution typically demands either a large memory footprint or high bandwidth or both, using both large capacity DDR and fast memory HBM memory blocks in our chip can be explored to effectively meet these memory requirements.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "[19]  Mamoun Awad, Latifur Khan, and Bhavani Thuraisingham. 2008. In  ATC .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "B. Why have  EA / AE  Opportunities been previously Ignored? Based on the above discussion, in this work, we focus on EA  and  AE  opportunities.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "2 and Sec. 4.3). We leverage such foveated rendering idea in  Inter-Holo as our  Reference  design in this paper.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "The overall design of our proposed  HoloAR framework is illustrated in Fig. 6a. First,  HoloAR  utilizes the exist- ing viewing-window based technique [52] (denoted \na  ) to skip the hologram computations for the objects which are outside of the current viewing window, in a ‚Äújust-in-time‚Äù fashion.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Compression Pipeline:  \nTMC13 \n0 \n200 \n400 \n600 \n800 \nConst. Ser. Entropy Other Geo.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 26,
    "augmented": true
  },
  {
    "text": "¬¥as  accelerator design is to ensure proper ‚Äúcompute place- ment‚Äù even under a power emergency or power scaling. Conservative Scheduling:  The most important part of the Us. ¬¥as  uses two kinds of scheduling policies to handle the graceful  powerdown  and work queue rearrangement.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "4th EURASIP Conference focused on Video/Image Processing and Multimedia Communications (IEEE Cat. [34] A. Tamhankar and K. R. Rao, ‚ÄúAn overview of H.264/MPEG-4 Part 10,‚Äù in  Proceedings EC-VIP-MC 2003. [33] Kitware, Inc., ‚ÄúThe VIRAT Video Dataset,‚Äù ‚Äùhttps://viratdata.org‚Äù, 2011.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "The elaborate resources and the extensive times that these training tasks entail are indicative of severe financial im- plications of running these models. Similarly, it took 384 A100 GPUs to train BLOOM over 3.5 months [165] and 6144 TPU v4 chips were used to train PaLM-540B model over 50 days [27]. In fact, a recent study from CSET [100] estimates that the cost of building LLMs will move to trillions in roughly 36 months!",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "6 Conclusions \nIn this paper, we have explored the critical role of storage systems in the context of continuous learning video analytics edge server, emphasizing in particular the transformative potential of Computational Storage Devices (CSDs) in this domain. From our evaluation, we found an 8:1 ratio of SSD to CSD (capacity ratio) provides the best possible cost-to-acceleration benefit. Our proposal,  Salient Store  , highlights the need for a paradigm shift in storage architecture to accommodate the dynamic and computationally intensive nature of modern ML applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Specifically, our algorithmic layer will ad- vance state-of-the-art in LLM models and algorithms and generate an extensible framework in which more futuristic EoE networks can be explored. Our system support will provide a framework using which re- searchers can conduct scalable training and inference experiments. Our architectural support will result in a search space exploration methodology that can be used to map experts to chiplets for improving execu- tion efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "This property is true both for the forward pass and the backward pass of the standard CNN training. The modular nature of the weight stationary mapping makes it a strong candidate for use in a re-conÔ¨Ågurable or morphable systolic structure as turning off some compute is the same as not computing a kernel and scheduling it for later. Therefore,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "[45] Giorgio Franceschelli and Mirco Musolesi. AI Models FYI , 2024. On the creativity of large language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "For instance, on CIFAR10, NExUME achieves an accuracy of 76.29%, which is approximately 4.54% higher than DynBal, the next best method. This improvement is significant in the context of energy-harvesting intermittent systems, where achieving high accuracy under strict energy constraints is challenging. The superior performance of NExUME can be attributed to its unique integration of energy variability awareness directly into both the training (DynFit) and inference (DynInfer) processes.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Prediction Policy : To effectively capture the \nModel RMSE MWA 77.5 EWMA 88.25 Linear R. 87.5 Logsitic R. 78.34 Simple FF. 45.45 LSTM 28.56 DeepArEst 26.67 \nTable 4:  Prediction models. different load arrival patterns, we design a DeepAR- estimator (DeepARest) based prediction model.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "This study involved adjusting the acceptable latency and the capacitance of the energy harvesting setup to assess their impacts on accuracy. As shown in Figure 3a, the accuracy improves with increased latency, but with diminishing returns. Similarly, Figure 3b demonstrates that, while increasing capacitance should theoretically stabilize the system, its charging characteristics can lead to extended charging times, thus exceeding the latency SLO.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "In  ASPLOS , 2015. [44]  K. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, D. Dzhulgakov, M. Fawzy, B. Jia, Y. Jia, A. Kalro, J. Law, K. Lee, J. Lu, P. Noordhuis, M. Smelyanskiy, L. Xiong, and X. Wang.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Dynamic DAGs, where only a subset of functions within each DAG are invoked per request type, necessitate the ap- portioning of containers to each function. This assumption leads to the spawning of equal number of containers for all functions in proportion to the application load, resulting in container over-provisioning. Two such inefficien- cies are described below: ‚Ä¢  The majority of serverless platforms [ 32 ,  44 ,  46 ,  50 ] assume that DAGs in applications are static, implying that all com- posite functions will be invoked by a single request to the application.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "22 \nCalculate the gradients of the loss with respect to the activations: \n‚àÇ L ‚àÇ a i \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the Taylor expansion approximation: \np i  = Œª \f\f\f  ‚àÇ L \n‚àÇ a i   a i \f\f\f  +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Inference with Taylor Expansion Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 340,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) , pages 502‚Äì518, Vancouver, Canada, August 2017. Association for Computational Linguistics. [67]  Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "‚Ä¢  T 1  serves as a  rigid body transformation  matrix which ap- plies 3D rotation ( Y aw, Pitch, Roll ) and translation so that, the objects do not get distorted. Since this transformation does not depend on any of the sensor inputs, it can be pre- calculated at compile-time. ‚Ä¢  T 2  gives us  eyes‚Äô view ; i.e., this changes the virtual world‚Äôs coordinate frame to match the frame of the eye.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "Power estimations of our hardware design, modeled by Design Compiler [ 93 ], indicate that the proposed morphable accelerator approach can save up to 234.95kWH/year/edge-server, compared to running continuous learning on a state of the art DNN accelerator and 2.63MWH/year/edge-server, compared to utilizing a datacenter-scale GPU for learning on the edge. II. B ACKGROUND AND  M OTIVATION \nEdge servers often leverage the convenience and Ô¨Çexibil- ity of cloud interfaces, granting access to the same APIs, tools, and functionalities [ 60 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "The architectural backbone of neural codecs typically comprises an autoencoder, where the encoder compresses the video into a compact, lower-dimensional representation, and the decoder reconstructs it back into video format. Unlike traditional codecs that rely on predefined algorithms to compress video data, neural codecs utilize an end-to-end trainable system based on neural networks. These networks are trained on extensive video datasets, allowing them to dynamically adapt compression strategies based on the content‚Äôs complexity and prevailing network conditions.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "3, for each of the objects, a corresponding approximation factor ( Œ≤ ) can be determined based on these insights. Similarly, the original hologram engine can still be reused without any reprogramming, except for the first argument, i.e., the number of depth planes for this particular object, as shown in  Line#5  of Algo. 3.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "ResiRCA: A Resilient Energy Harvesting ReRAM Crossbar-Based Accelerator for Intelligent Embedded Processors. In  2020 HPCA . 315‚Äì327.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "As the target  2 D  FoV coordinates are already known (VR screen dimensions), these mappings can be performed by multiplying the inverse of the transformation matrix ( T   ‚àí 1 ) with the  2 D  FoV coordinates ( V 2 D ), thus generating the corresponding  360 ¬∞ pixel coordinates ( P ), as shown in Equation 2. P i L   =  T  ‚àí 1 L √ó V i 2 D ; ‚àÄ i  ‚â§ num pixels \nP i R   =  T  ‚àí 1 R √ó V i 2 D ; ‚àÄ i  ‚â§ num pixels (2) \nHere,  V 2 D  = [ q 0 , q 1 , q 2 , q 3 ] ‚ä§ represents the quaternion equiva- lent of the  2 D  FoV coordinates used for matrix multiplication with the inverse transformation matrix ( T   ‚àí 1 ). Note that, this operation, which is a matrix multiplication on each FoV pixel coordinate, can be quite compute intensive.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 232,
    "augmented": true
  },
  {
    "text": "The Ô¨Çexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization. Therefore, this weight duplication- based execution style built upon Ô¨Åne-granularity activation can effectively combat  Nonideal scenario 2 . Figure 1 also shows the throughput under the full-size activation mode and the tile-size activation mode.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "[18]  Jisoo Hong, Youngmin Kim, Hyunjoo Bae, and Sunghee Hong. 2020. (2019), A74‚ÄìA81.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "[36] C. Jones and J. D. Ryan,  Encyclopedia of hinduism . Infobase publishing, 2006. [37] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, \nS. Bates, S. Bhatia, N. Boden, A. Borchers  et al.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "To better under- stand which of these are the best candidates ( features , using machine learning parlance) for memoization and whether they are sufÔ¨Åcient or not, we next discuss input parameters and their impact on the computation: ‚Ä¢  Head orientation:  Any changes in this affect the matrix T 2  as discussed in Tab. I, thus changing the transformation matrix  T  and eventually leading to  re-computation  of the most compute-intensive projection matrix  P . Thus, it is a critical feature in projection computation executions.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": ",  Q m  such that, for each subset  Q j ,   P q i ‚ààQ j   E q i   ‚â§ E b , and  m  is minimized. . .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "[32] Sarkar Snigdha Sarathi Das, Arzoo Katiyar, Rebecca Passonneau, and Rui Zhang. ACM SIGARCH computer architecture news , 38(3):106‚Äì116, 2010. CONTaiNER: Few- shot named entity recognition via contrastive learning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Zstandard compression and the application/zstd media type. Technical report, 2018. Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Scharw√§chter, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Figure 1: Main hardware components and software pipeline on a typical AR device. and improve its energy efficiency, with ‚Äúapproximation‚Äù as the core idea. (c) SW pipeline [19, 50].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "[8] Facebook Inc., ‚ÄúFacebook Oculus,‚Äù ‚Äùhttps://www.oculus.com/‚Äù. [9] Google, ‚Äú360¬∞ videos - Google Arts & Culture,‚Äù ‚Äùhttps://artsandculture. google.com/project/360-videos‚Äù.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Figure 1a shows the basic building blocks of an energy har- vesting sensing/computing unit. We also describe the challenges in enabling complex compute on such devices and the need for hardware-software co-design to enable specialized intermittent computing in EH-WSNs. Finally, we define the scope of our work and focus on the problem specifics while alluding to probable solutions.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Specifically, leveraging the observed pat- terns of expert reuse (‚Äúhotness‚Äù patterns) at different locations in the EoE , our system can intelligently predict and load the experts likely needed in subsequent layers to the main memory. While response is being generated for some prior expert, this predictive loading can take place concurrently for the experts ahead in the path to minimize resource idleness and ensure seamless transition for subsequent pro- cessing. Task-2.4: KV Cache Management Key-Value (KV) caches in LLMs store past activations to  accelerate  inference by avoiding redundant com- putations [7, 35, 43, 73, 99, 146, 148, 163, 167, 168, 171, 172, 188, 189, 193].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "[35]  Takashi Nishitsuji, Yota Yamamoto, Takashige Sugie, Takanori Akamatsu, Ryuji Hirayama, Hirotaka Nakayama, Takashi Kakue, Tomoyoshi Shimobaba, and Tomoyoshi Ito. 2018. Special-purpose Computer HORN-8 for Phase-type Electro- holography.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "policy in use. RR indicates the extended round-robin policy in use, e.g. RR6 AAS represents AAS with RR6.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "Robust bayesian linear classiÔ¨Åer ensembles. [18]  Jes√∫s Cerquides and Ramon L√≥pez De M√°ntaras. In  Proceedings of the twenty-Ô¨Årst international conference on Machine learning , page 18, 2004.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Using State-of-the-Art Video Data Storage? Maybe Not:  While storing video data as files works for small systems, in very large-scale systems they are typically stored using vector databases (Shen et al., 2005; Pan et al., 2024). Vector databases typically extract features from the video data to form index and those indices are then sorted using various metrics like neighborhood, maximum similarity, etc.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Thanks to a simpler model (which is a random sample of the edge models), the latency does not increase significantly. 3) The privacy preserving cloud model, although less accurate than the data shared cloud model, performs significantly better than the edge models, with 5.1% more correlation in case of the 2-home setup and 10.37% more correlation for the 4-home setup. B.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "903 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "It is known that RCAs achieve their highest efÔ¨Åciency when every cell participates in the MAC computations simul- taneously [ 20 ]. First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power. Second, the \nvariance of the input power window, i.e., how long the power input stays at a given level, can be large as well.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, we Ô¨Ånd that 1  the points with similar Morton codes within one frame tend to have little variances in both geometry and attribute values ( spatial locality ), and 2 the points with adjacent Morton codes (for instance, a cluster of geometrically close points) are likely to move in a certain direction, as a whole block, across frames ( temporal locality ). ‚Ä¢  We propose two complementary designs to capture and utilize such spatio-temporal localities. We also demonstrate that, such spatio-temporal localities can be precisely captured by Morton codes [ 30 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "We assume the communication cost to be negligible since it infrequently sends a few bytes of data to the host. The speciÔ¨Åcs of the energy-harvesting mechanism producing the power trace are beyond the scope of this work. To replicate the energy harvesting, we use a real power trace harvested from a WiFi source while doing various day to day tasks in an ofÔ¨Åce environment [6].",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Repeatedly carrying out this transition process, starting from the initial Probability Vector, enables the estimation of probabilities of each function along all possible workflows. This equation infers that the Proba- bility Vector at the next time step is obtained by performing a transition operation across all possible current states. Iterating this process for  ùëë time steps would yield the proba- bilities of functions at a depth of  ùëë from the start function, given by  ùëÉ ùëë =  ùëá ùëë ¬∑  ùëÉ 0 .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "To accommodate these constraints, it is a common practice to employ compressed Deep Neural Network (DNN) models, that are quantized, distilled, or otherwise reduced in size. However, while com- pressed models are essential for meeting resource limitations, they are more sensitive to data drift because they may not generalize as effectively. Traditionally, data drift has been handled by cloud-based periodic re-training using continuous learning algorithms [ 20 ], [ 74 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Identifying outlier arms in multi-armed bandit. [87]  Honglei Zhuang, Chi Wang, and Yifan Wang. In  ATC , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "[58]  Soo-Jin Moon, Jeffrey Helt, Yifei Yuan, Yves Bieri, Sujata Banerjee, Vyas Sekar, Wenfei Wu, Mihalis Yannakakis, and Ying Zhang. Alem- bic: Automated model inference for stateful network functions. In  16th USENIX Symposium on Networked Systems Design and Implementa- tion (NSDI 19) , pages 699‚Äì718, Boston, MA, February 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "[36] Xiaobin Dong, Kurt Keutzer, and Cong Zhang. Qaq: Quality adaptive quantization for llm kv cache, 2024. [35] Shichen Dong, Wen Cheng, Jiayu Qin, and Wei Wang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "1586‚Äì1597, 2017. [43] Keras, ‚ÄúKeras applications,‚Äù  https://keras.io/api/applications/ , (Ac- \ncessed on 11/21/2022). [44] Konstantin Shmelkov, Cordelia Schmid, Karteek Alahari , ‚ÄúIncremental \nlearning of object detectors without catastrophic forgetting,‚Äù in  ICCV , 2017.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Conservatively, we choose a correlation coefficient  ‚â• 0 . We store ground truth sensor data pattern for all possible labels, and when new data arrives, we find the correlation of the sampled data against the ground truth data, and if any of the correlation coefficient \n6 \nPower-Pred \n+ Decision Logic (MCU) \nCorrelation \nSensor Data \n16bit DNN (x-bar) \n12bit DNN (x-bar \nCoreset: Imp \nSmp/Clust. 95 to predict that the two activities are the same, and hence skip the inference altogether and just com- municate only the results to the host.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "This gra- dient computation, fundamental for learning, is meticulously mapped across the systolic array, ensuring precise and efÔ¨Åcient backpropagation. Memory accesses are optimally managed via the double-buffered SRAM structures, providing timely data availability for the MAC units. The 8 √ó 8 systolic array in each tile executes multiply-accumulate operations in a pipelined and parallel fashion, abiding by the Weight Stationary approach, thereby optimizing the throughput and efÔ¨Åciency of the train- ing operations within this hardware architecture.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Pok√©mon GO Revenue and Usage Statistics. 2020. \"https: //www.businessofapps.com/data/pokemon-go-statistics/\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "\"https://www. xilinx.com/products/boards-and-kits/ek-u1-zcu102-g.html\". [65]  Tiancheng Xu, Boyuan Tian, and Yuhao Zhu.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "The load to each function within each applica- tion is calculated separately using the collected information. This prevents other applications from interfering with the probability calculation of shared functions. Additionally, the PWS uses a DAG descriptor, which is a file that contains a python dictionary that specifies the connectivity among functions.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "It also leverages the continu- ous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve Ô¨Ånal classiÔ¨Åcation accuracy. Experimental results using two different HAR data-sets show Origin , while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classiÔ¨Åer continuously operating at the same average power. Further,  Origin  proposes an adaptive ensemble learner to personalize the optimizations based on each individual user.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "These methods introduce various techniques such as embedding state information into the DNN, multi-resolution inference, multi-exit architectures, and runtime reconfig- urability to handle intermittency in energy-harvesting devices. 7 \nWe also compare our approach with recent state-of-the-art methods specifically designed for in- termittent systems, namely  Stateful  (Yen et al., 2022),  ePerceptive  (Montanari et al., 2020), and DynBal  (Yen et al., 2023). Baseline  iNAS+PT designs the network from the ground up while combining the work of iNAS (Mendis et al., 2021) and EAP (Yang et al., 2018, 2017).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 185,
    "augmented": true
  },
  {
    "text": "6 √ó  data movement benefits compared to the state-of-the-art, on a single storage and  ‚âà 4 . 2 Background and Motivation \n2.1 Storage for Continuous Learning Edge Servers \nRecent developments in continuous learning for video analytics (Bhardwaj et al., 2022; Mishra et al., 2024; Kim et al., 2024) has significantly boosted the capabilities and accuracy of learning systems. 8 √ó  latency benefit in a multi-node system.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "VI , such optimizations are able to bring around 37 √ó  speedup w.r.t. And, as will be shown later in Sec. the state-of-the-art techniques ( 1 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "On the other hand,  Clipper  uses all models in ensemble and the  Clipper-X  policy does not right size the models as aggressively as  Clipper , hence they are more expensive. Note that, all the schemes incur higher cost for twitter trace (Figure  8b ) compared to wiki trace (Figure  8a ). This is because the twitter workload is bursty, thereby leading to intermittent over-provisioned VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "4  b  , to compress the attribute data, similar steps ‚Äì  Raw Frame Input ,  Attribute Transform and Quantize , Entropy Encoding , and  Compressed Attribute Output Stream  ‚Äì are employed. Only the  Transform and Quantize  step differs from the geometry compression pipeline, which takes both the raw frame‚Äôs attribute data as well as the constructed octree as its inputs. With these inputs, the  Transform  step \n5 We consider the octree-based technique [ 56 ], [ 72 ] and RAHT [ 14 ], [ 56 ] as SOTAs for geometry and attribute compression respectively.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "3 Then for Frame-2, we obtain the its motion vectors from the codec (with a minimal overhead, as discussed in Sec. IV-A2). With such knowledge, for Frame-2, we can observe that the bounding box and the MVs mostly overlap (with an overlap ratio of 0.71 in the left case), which indicates that the objects have barely moved.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "As shown in Figure  5 ,  mixed procurement reduces the over-provisioning cost of VMs. However, we argue that there is scope to further optimize resource procurement based on the fre- quency of peak load and constant load in a given request \narrival scenario. At the same time it also minimizes latency violations equivalent to  exascale  scheme.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "[SM:Small Model (smaller model or larger model pruned and quantized using energy aware pruning [ 102 ] and NetAdapat [ 103 ]), LM:Large Model (no pruning or quan- tization), SMR:Small Model with Retraining]. 1hour for 3D Point Cloud simulated data. emerged as a preferred approach to mitigate data drift [ 20 ], [ 44 ], [ 50 ], [ 74 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "While the works relying on loop-decomposition or task partition (e.g., see (Qiu et al., 2020; Gobieski et al., 2019) and the references therein) ensure ‚Äúforward progress‚Äù, they do not guarantee an inference completion while meeting SLOs. Intermittent DNN Execution/Training:  As the applications deployed on such EH devices demand analytics, executing DNNs on EH devices and EH-WSNs have become prominent (Lv & Xu, 2022; Gobieski et al., 2019; Qiu et al., 2020; Mishra et al., 2021). However, due to computational constraints, limited memory capacity and restricted operating frequencies, many of these applications fail to complete inference execution with satisfactory SLOs, despite comprehensive software and hardware support (Mishra et al., 2021).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 214,
    "augmented": true
  },
  {
    "text": "Excluding the most general (and rare) cases where applications can have loops/cycles within a function chain [ 27 ], applications can be modeled as a  Directed Acyclic Graph  (DAG) where each ver- tex/stage is a function [ 26 ] Henceforth, we will use the terms ‚Äòfunction‚Äô and ‚Äòstage‚Äô interchangeably. We define a  workflow or  path  within an application as a sequence of vertices and the edges that connect them, starting from the first vertex (or vertices) and ending at the last vertex (or vertices). An application invokes functions in the sequence as specified by the path in the DAG.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "Unlike prior works targeting at optimizing the efÔ¨Åciency of  each computation  [28], [57], we primarily focus on reducing  the amount of computation to be performed, by exploring the intrinsic ‚Äúcompute reuse opportunities‚Äù in  360 ¬∞ VR video processing. A. Opportunities \nExploring and exploiting computation output reuse oppor- tunities is non-trivial in this context.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "). ). Collaborative inference in sensor networks involves com- bining local inferences to achieve a global understanding of the environment ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "16 MHz MCU with 64KB FRAM, 2KB SRAM, AES, 12-bit ADC, comparator, DMA, \n14 \nUART/SPI/I2C, timer. ACM SIGPLAN Notices  53, 6 (2018), 31‚Äì43. [66]  Texas Instrument Micro-controller with FRAM 2022.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "V). Therefore, in this case, \n1 According to [23], only a small portion of DNN inference run on mobile GPUs, thus, in this work, we focus on optimizing the DNN inference on mobile CPUs. Frame-2 needs to be carefully processed and full inference needs to be employed, as indicated by  4  in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Openai chatgpt. \" [123] OpenAI. https://openai.com/chatgpt/overview/ \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "To solve this issue, we propose to re-construct the expert graph automatically to balance the workload. We first form a binary tree over all selected domains where the experts are the leaf nodes at the finest granularity. We cluster the experts according to their domain similarity so that each parent node is assigned two most similar leaves.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Since processing these critical regions is in general much lighter-weight than processing a whole frame due to smaller size and less computation, the proposed partial inference is able to minimize the unnecessary computation (on the background/unimportant regions), thereby further speeding up the inference and reducing the energy consumption. Our proposed frame-level reuse shows  ‚âà 53%  of the frames to be redundant and hence skips the inference, leading to only less than  1%  accuracy loss. ‚Ä¢  Then, we implement and experimentally evaluate our pro- posal on a representative mobile device ‚Äì the Pixel 3 Phone [20] ‚Äì and collect detailed experimental results, using 6 different video streams.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "HAR has been pervasive enough given the rise of smart wearables and has been studied well enough to have ample access to resources to make a judicious evaluation. The challenge here is to  send \n1 Throughout the paper we evaluate many of our motivation results using HAR as a workload as it is one such application, where the (EH-)WSN, used as body area network, fits perfectly with RF or body movement as the har- vesting source. HAR has the nuances of human introduced unpredictability and sensor induced noises.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "These design chal- lenges, when combined with the scheduling and container provisioning policies of current serverless platforms, result in crucial inefficiencies with respect to application performance and provider-side resource utilization. For instance, in a train-ticket application [ 40 ], actions like make_reservation  can trigger different paths/workflows (sub- set of functions) within the application. Two such inefficien- cies are described below: ‚Ä¢  The majority of serverless platforms [ 32 ,  44 ,  46 ,  50 ] assume that DAGs in applications are static, implying that all com- posite functions will be invoked by a single request to the application.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "A deep dive into 7 th   iteration reveals that the micro-proÔ¨Åler chose a higher learning rate (compared to the oracle), which biased the convergence curve Ô¨Åtting and extrapolation (as discussed in ¬ß III-C ) and hence suggested a larger number of layers to be trained to achieve the required convergence. Similarly, the micro-proÔ¨Åler shows consistent behaviour while choosing the right number of batches. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "463‚Äì468, 2005. [11]  X. Jiang, J. Polastre, and D. Culler, ‚ÄúPerpetual environmentally powered sensor networks,‚Äù in  Fourth International Symposium on Information Processing in Sensor Networks (IPSN) , pp. 1057‚Äì1062, March 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "63%  ( Rollercoaster  video) to  50 . This occurs as a result of reusing the memoized results which have been computed and stored previously, ranging from 21 . 28%  ( Paris video).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "It also describes our plans for ensuring data integrity and reproducibility. 1. Types of Data and Storage \nThe project will generate seven types of data: (i) the codes and executables for the compiler that performs expert-to-chiplet mapping; (ii) source codes for scheduling support and simulator; (iii) expert repository that will hold the LLMs/expert models generated during the project; (iv) detailed LLM/expert algorithms as well as workload characterization and experimental data; (v) educational materials; (vi) a document detailing how to use the software developed during the project; and (vii) finally, lineage (provenance) data (more on this below).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "The goal of our study was to correctly predict the surface roughness from sensor data. 4: Sensitivity study and depth-of-cut, and measured the surface roughness of the grinding surface. It also incorporated the tool parameters like speed, feed \n4 \n0 0.5 1 1.5 2 2.5 3 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nInference Time (ms) \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(a) Inference time vs threshold \n0 1 2 3 4 5 6 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nAverage # Devices Encountered \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(b) Communication through (aver- age) number of devices vs Threshold \n0.78 0.8 0.82 0.84 0.86 0.88 0.9 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nCorrelation \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(c) Correlation vs threshold \n0 0.2 0.4 0.6 0.8 1 1.2 1.4 \n0.86 \n0.861 \n0.862 \n0.863 \n0.864 \n0.865 \n100 200 300 400 500 600 700 800 \nInference Time (ms) \nCorrelation \n# Cloud Estimators Correlation Inference Time \n(d) Accuracy (correlation) and infer- ence time vs # cloud estimators \nFig.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 389,
    "augmented": true
  },
  {
    "text": "To be sure that the combination will give us the desired accuracy of the larger model, we try to theoretically analyse the scenario. In our design, we solve our Ô¨Årst objective function (described in Section  4.1 ) by combining all available models which meet the latency SLO. Appendix \nA Modeling of Ensembling \nWhile performing an ensemble it is important to be sure that we can reach the desired accuracy by combining more models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "B. Kotra, M. Arunachalam, C. R. Das, and M. T. Kandemir, ‚ÄúA learning-guided hierarchical approach for biomedical image segmentation,‚Äù in  2018 31st IEEE International System-on-Chip Conference (SOCC) , 2018, pp. [17] L. Liu, H. Li, and M. Gruteser, ‚ÄúEdge Assisted Real-Time Object Detection for Mobile Augmented Reality,‚Äù in  Proceedings of the An- nual International Conference on Mobile Computing and Networking (MobiCom) , 2019. [18] H. Jiang, A. Sarma, J. Ryoo, J.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "We also provide novel learning strategies, especially when the distributed sensors do not want to share the local data with the cloud, saving crucial communication latency and energy. Our contributions include: (1) Two different edge-cloud learning and inference policies, in a distributed sensor environment, to efficiently run ran- dom forest based data analytics. We explore the impact of privacy-preserving random forest training mechanisms to help protect sensitive data generated by the sensors.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Also, a similar composition scheme is employed to organize the input, weight and output data. The ISAAC architecture is composed of 16 tiles and each tile consists of 8 IMAs which includes 4 ReRAMs along with 4 sets of peripheral circuits. An intra-tile pipeline is formed to boost the dot-product throughput.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "In Figure 5, as- suming both column and row indices of ùëá start at 0, an entry ùë° 0 4  represents the transition probability from  NGINX ‚Äôs state to  Follow ‚Äôs state and is equal to 0.2. In general, this transition probability,  ùë° ùëóùëñ , is calculated as the number of requests from ùëì ùëó to  ùëì ùëñ divided by the number of incoming requests to  ùëì ùëñ in the context of the application being considered. The Probability Vector is an  ùëõ √ó 1 column vector that cap- tures the probabilities of the model being in different states after a number of time steps have elapsed, given that the model was initialized at a known state.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks. In  2021 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pp. 1414‚Äì1419.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "For the  Social Network  application,  Kraken remains within 60 ms of the end-to-end response time of Arch  (Figure 9a), which performs the best out of all policies with respect to these metrics, while ensuring 99.94% SLO guarantees (Figure 10a) . From these graphs, it is evident that  Kraken  exhibits comparable performance to existing policies while having a minimal re- source footprint. However,  Arch  uses 4x the number of containers used by  Kraken  (Figure 10a).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "V-PCC 2   targets compressing PC videos. Apart from these methods that compress a static PC, there also exist several attempts at optimizing the compression for dynamic PCs by exploring the ‚Äútemporal redundancy‚Äù across the PC video frames. For example, a macro block (a  S √ó S √ó S  cube) based motion estimation and compensation is proposed in [ 15 ], [ 16 ], [ 48 ], [ 73 ], to further improve the compression efÔ¨Åciency.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Inter-Intra-Holo : The above two designs can be integrated to- gether into the original hologram pipeline, in either Inter-then- Intra or Intra-then-Inter fashion. In this paper, we chose the first one and denote this design as  Inter-Intra-Holo . ‚Ä¢  HORN-8:  While hardware acceleration of hologram is not a goal of this work, to qualitatively compare our GPU-based design with hardware specific accelerators, we also discuss one of the most recent ASIC implementations, HORN-8 [ 35 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "A APPENDIX A.1 Reconstructing Importance Sampling Coreset As discussed in Section 3.2.2, we use GANs to recover the data we lost while performing importance sampling. This was motivated from the observation that as we selected more number of points in importance sampling, the accuracy of the inference on the compressed data increased significantly (at times by 2%). Component Spec Power Area(mm 2 ) \nSRAM Buffers \n1kB*256+ 8kB*256+ 64kB+16*256kB \n10.372W 117.164 \nMAC Unit (8*8) 256 8.46W 32.72 \nAdder Tree and Comparator 16*16bit + 256 2.4W 21.556 \nControl ‚Äì 0.96W 12.2 Host ‚àº Cortex A78 series 11W ‚Äì Design at 592MHz with Synopsys AED 32nm library \nTotal 256 tiles 33.192W 183.64 Table 3: Area and power estimation of our design.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 219,
    "augmented": true
  },
  {
    "text": "(Sec. Such properties are leveraged as approximation opportunities to skip the ‚Äúunimportant‚Äù portions of the hologram computation, based on user‚Äôs region of focus (known as foveated rendering), and object‚Äôs distance/size from the user. 2.1) ‚Ä¢  From two open-source AR datasets [ 1 ,  58 ], we identify two prop- erties in AR hologram applications:  spatio diversity for objects , and  temporal locality for the user (viewer) interests (i.e., user typ- ically focuses on one region within a short period of time) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Every single  1920  √ó  1080  raw frame prior to encoding carries  ‚âà 23 MiB of data which, @60fps, will require processing  ‚âà 1 . 4 GiB of data per second per imaging source. 4 \nThe main reason these algorithms consume significant resources is because of the amount of data they handle.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "To- wards addressing these challenges, we design and evalu- ate  Kraken , a DAG workflow-aware resource management framework, for efficiently running such applications by uti- lizing minimum resources, while remaining SLO-compliant. Kraken  employs proactive weighted scaling of functions, where the weights are calculated using function invocation probabilities and other parameters pertaining to the appli- cation‚Äôs DAG structure. Our experimental evaluation on a 160-core cluster using  Deathstarbench  workload suite and real-world traces demonstrate that  Kraken  spawns up to 76% fewer containers, thereby improving container utilization and cluster-wide energy savings by up to 4 √ó  and 48%, respec- tively, compared to state-of-the art schedulers employed in serverless platforms.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 189,
    "augmented": true
  },
  {
    "text": "Therefore, there is considerable variation in the functions that can be invoked in DDAs, thus, negating the inherent assumption in many frameworks [ 32 ,  42 ,  44 ,  50 ] that all functions will be invoked with the same frequency as the application. Opportunity 1:  In order to reduce overprovisioning of contain- ers, it is vital to design a workflow-aware resource management (RM) framework that can dynamically scale containers for each function, as opposed to uniformly scaling for all functions. This discrepancy can lead to substantial container overprovisioning.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "We also propose  Intra-Holo  to further approximate each of the object holograms, by analyzing its cur- rent distance from the user. 7 √ó  speedup and 73% \nenergy savings. Our experimental results show that, compared to the baseline,  HoloAR  achieves 2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "The PIs are involved in several K-12 activities such as the summer CS program for girls (funded by CSE and led by Das). We plan to continue the summer program involv- ing more schools and students in coming years, where we will expose them to Generative AI and related concepts. We will also collaborate with the Penn State College of Education‚Äôs CSATS (Center for Science and the Schools) to participate in the university‚Äôs continuing outreach initiatives focused on STEM subjects.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Our policy updates  both  the teacher and student models for robust unsupervised learning. ‚Ä¢  We implement a  micro-proÔ¨Åler , which predicts the right set \nof hyper-parameters to efÔ¨Åciently perform the training tasks on an energy-harvesting edge server while operating within its power budget and minimizing data drift. ‚Ä¢  We design a  morphable hardware accelerator  that efÔ¨Å- \nciently maps training tasks, is suitable for intermittent computing, and can adapt its capabilities to reduce power emergencies without devolving to grid operation.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "|N| [ L ( S  ‚à™{ i } )  ‚àíL ( S )] \nwhere  N  is the set of all neurons,  S  is a subset of neurons not containing  i , and  L ( ¬∑ )  denotes the loss function. Define the dropout probability  p i  for neuron  i  based on its Shapley value. Neurons with lower Shapley values are more likely to be dropped: \np i  = Œ¥ œï i  +  œµ where  Œ¥  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "5a, only the soccer ball  object is located inside the viewing window in the current frame,  Frame-I , while  football  and  box  are not. Thus, only the  soccer ball  hologram is required to be com- puted for this frame, and other two can be skipped. Similarly, for the next frame,  Frame-II , now the user lifts her head a bit, hence the corresponding viewing window changes from the previous one.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "youtube.com/watch?v=WvtEXMlQQtI‚Äù, 2019. [45] Samsung, ‚ÄúExplore New Dimensions.‚Äù ‚Äùhttps://www.samsung.com/ global/galaxy/gear-vr/#display‚Äù, 2019. [44] Samsung, ‚ÄúSamsung Gear VR,‚Äù ‚Äùhttps://www.samsung.com/global/ galaxy/gear-vr/‚Äù.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Second,  which features of these inputs are salient and need more fine-grained computation, and which of them could be approximated without impacting the QoS? Towards this, we propose  HoloAR , an opportunistic and edge- friendly framework to speed up the AR holographic computation \n(a) An app. Third,  how do we make dynamic decisions of approximation based on the runtime conditions (e.g., user‚Äôs current pose and eye movements)?",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "In contrast, as explained earlier in Sec. IV, our design skips a huge amount of computations by exploiting the  EA  and  AE . ‚Ä¢  EA  (SW) : We evaluate the  InterFrame, IntraEye ( EA ) design on a GPU, as shown in the  EA  block in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "[154] Arash Tavakkol, Juan G√≥mez-Luna, Mohammad Sadrosadati, Saugata Ghose, and Onur Mutlu. MQSim: A framework for enabling realistic studies of modern Multi-Queue SSD devices. , 2(3), December 2018.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "We plan to address this in two ways. First, we will implement different KV cache management policies for different experts, depending on their accuracy requirements, context lengths, and latency tolerances. And second, we will explore EoE-specific KV cache compression strategies to optimize memory usage including quantization and sparsity optimization tech- niques.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "To ensure a required accuracy with given latency, applications have to choose from a confounding array of different types of models (shown in Figure  1 ). Therefore, it is  non-trivial for an application to choose the right model that can collectively optimize for all requirements together . WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands J.R. Gunasekaran, et al.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Therefore, we cannot always expect inference outcomes from all the sensors while doing HAR on EH-WSN. Clearly, the completion of the task is power bound: Adopting a wait-compute execution model, such that we have enough energy to complete some results, at a lower duty cycle, instead of always trying and failing would yield beneÔ¨Åts. This leaves us with the following important questions: ‚Ä¢  Are continuous inferences essential, or can we leverage the workload itself to skip some inferences without substantial accuracy loss, allowing enough energy to be accumulated for future inferences?",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "More speciÔ¨Åcally, for each of the Ô¨Åve video inputs (shown in the x-axis in Fig. 9, which is further translated to the total end-to-end energy savings shown in the right y-axis in Fig. 9), we compare the compute energy consumption incurred by six schemes with left-eye and right-eye breakdown, and present the respective compute energy in the left y-axis Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "[84] Dominik Kreuzberger, Niklas K√ºhl, and Sebastian Hirschl. Machine learning operations (mlops): Overview, definition, and architecture. IEEE Access , 11:31866‚Äì31879, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "2. 3. We quantitatively evaluate prior works [ 5 ,  9 ,  10 ] which are geared towards achieving this vision and show that they still suffer from several issues when trying to solve the complex problem of combining model and resource heterogeneity.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "38 J  per PC frame, which represents  96 . 6%  energy saving w.r.t. TMC13, while our Intra- Inter-V1 and Intra-Inter-V2 only consume  0 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Frameless  2, 1 (2020), 21. [24]  Anton Kaplanyan, Anton Sochenov, Thomas Leimk√ºhler, Mikhail Okunev, T. Goodall, and Gizem Rufo. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "PI Das has been involved with organizing the  Visit In Engineering Weekend  (VIEW) program for students entering their junior and senior years of high school, which fosters interest in engineering. Participants carry out hands-on design activities with faculty and students. We plan to provide hands-on computer architecture experience to students and show them how modern computer systems can address important societal challenges, specifically how LLMs can be used in many such domains.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "The commonly used ensemble method in classiÔ¨Åcation problems is bagging [ 33 ] that considers homogeneous weak learners, learns them independently from each other in parallel, and combines them following some kind of deterministic aver- aging process [ 18 ] or majority voting [ 49 ] process. For fur- ther details on ensemble models, we refer the reader to prior works [ 14 , 57 , 58 , 61 , 64 , 77 , 78 , 88 ]. 2.2 Related Work \nEnsembling in practice : Ensembling is supported by com- mercial cloud providers like Azure ML-studio [ 11 ] and AWS Autogluon [ 31 ] to boost the accuracy compared to single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "Deep learning for nlp. Tutorial at Association of Computational Logistics (ACL) , 2012. [72]  Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM \naccelerated MACs. V. P OWER - DYNAMIC  RCA  SCHEDULING \nGiven a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture. Challenge 2:  Software controlled dynamic RCA activation and scheduling The idea of loop tiling has been widely leveraged in RCA design to either increase system throughput by smoothing the pipelining or reduce memory accesses by improving data locality [ 34 ], [ 3 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "AI Models FYI , 2024. Available at:  https://www.aimodels.fyi . [46] Elias Frantar and Dan Alistarh.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "670‚Äì675, 2015. [45]  K. Ma, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúDynamic machine learning based matching of nonvolatile processor microarchi- tecture to harvested energy proÔ¨Åle,‚Äù in  2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD) , pp. 1038‚Äì1043, 2014.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "[20]  L. Ni, Z. Liu, H. Yu, and R. V. Joshi, ‚ÄúAn energy-efÔ¨Åcient digital ReRAM-crossbar-based cnn with bitwise parallelism,‚Äù  IEEE Journal on Exploratory Solid-State Computational Devices and Circuits , vol. 3, pp. 37‚Äì46, Dec 2017.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "NVIDIA Corporation. https://developer.nvidia.com/rtx/dlss , 2024. Nvidia rtx dlss.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "In DNN training, meticulous compute mapping, mem- ory access strategies, and operational formulas are instru- mental for the forward and backward passes. This generic design is adaptable for various workloads. For smaller DNNs without 256 kernels in any layer, a batching mode is operational with a batch size of  B  =  ‚åä A / L ‚åã images, where  L  denotes the layer with the fewest channels, and  A  the number of active tiles.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "T4, thanks to its limited compute capabilities, could not Ô¨Ånish training tasks on time. 896 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "1 Anonymous Institution, Anonymous City, Anonymous Region, Anonymous Country. Preliminary work. Correspondence to: Anonymous Author < anon.email@domain.com > .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "2009. Cacti 6.0: A tool to model large caches. [114] Naveen Muralimanohar, Rajeev Balasubramonian, and Norman P. Jouppi.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "2. To re- place these real objects, we choose six virtual holograms (Sniper, Rock, Tree, Planet, Rabbit, and Dice holograms) from the Open- Holo depthmap database [ 45 ]. The salient characteristics these videos are given in Tab.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Let  e max total   = e max cap   + e inf   + e comm   represent the maximum energy cost (for a chosen SNR mode). A baseline condition that ensures correct participation can overcome occasional penalties is: \nŒ≥  ¬∑  ‚àÜ A min  > Œ¥  +  e max total   . This inequality implies that even in a worst-case scenario for accuracy gain, the net expected benefit of correct par- ticipation surpasses the sum of potential incorrect penalties and energy costs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Furthermore, the proposed hardware is reconÔ¨Ågurable at a Ô¨Åne grain, to be able to dynamically activate different scaled computations, which can Ô¨Åt to the changing features of the underlying power resources. ‚Ä¢  Resilient computation scheduling:  We provide three knobs to schedule computation blocks in the proposed ar- chitecture: (i) loop tiling which decomposes MAC operations in a given layer (ReRAM) into small blocks, (ii) ReRAM duplication which provides opportunity to perform one-layer operations with multiple weight copies, and (iii) pipelining that can organize multiple ReRAM tiles to further exploit the har- vested power. These knobs can be integrated to form sequential or pipelined computation modes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "Restrictions apply. 0 \n20 \n40 \n60 \n1 2 3 4 5 6 7 8 9 10 \n# Layers Tranined \nTraining Iterations \n# Layers Trained-Actual # Layers Trained-Oracle \n(a) Number of layers trained. 0 \n2 \n4 \n6 \n8 \n0 \n10 \n20 \n30 \n40 \n1 2 3 4 5 6 7 8 9 10 \nConvergence Error(%) \nBatch Size \nTranining Iterations Batch Size-Actual Batch Size-Oracle Convergence Error (%)-Actual Convergence Error (%)-Oracle \n(b) Batch-size and convergence.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "3.2.2 Recoverable Coreset Construction:  The primary reason the accuracy of inferring on coreset data is lower than that of the original model is the loss of features. Typically, the sensor data are low dimensional, and hence even with a good quality of coreset construction, it is difficult to preserve all the features. However, while inferring at the host, if we are able to recover the data or reconstruct it with minimum error, the accuracy can easily be increased.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "However, regulations, resource limitations and privacy concerns often mandate these applications (both learning and inference) to be performed at the edge (Bhardwaj et al., 2022; Mishra et al., 2024). Moreover, depending on the deployment, scenario and requirements, some of these applications also demand learning to keep up with the data drift (Bhardwaj et al., 2022; Mishra et al., 2024; Kim et al., 2024; Rebuffi et al., 2017). While some of these applications rely on collecting the video data and processing them offline, many need real-time analytics for the seamless integration, operation and effectiveness of the task at hand (Bramberger et al., 2004; Apostolo et al., 2022; Grulich & Nawab, 2018).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 199,
    "augmented": true
  },
  {
    "text": "8: Evaluation proto- type ‚Äì Nvidia Jetson TX2 GPU board [36] (PMU: Power Management Unit). 360 ¬∞  VR Video Dataset:  We use the published 360¬∞ Head Movements Dataset [3], which includes head movement traces from 59 users viewing seven widely-variant 360¬∞ VR videos. 6 \nThe meta information of these VR videos are listed in Tab.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "[184] Yuanrui Zhang, Wei Ding, Jun Liu, and Mahmut Kandemir. In  Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture , pages 489‚Äì500, 2011. Optimizing data layouts for parallel computation on multicores.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "The vector index are used to point to the meta-data of the video file and then the actual video data is retrieved from the storage (Shen et al., 2005). Vector databases typically extract features from the video data to form index and those indices are then sorted using various metrics like neighborhood, maximum similarity, etc. (Fonseca & Jorge, 2003; Cao et al., 2013; Tian et al., 2023; Douze et al., 2024) for faster retrieval.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "The resultant outputs from each SDMM calculation are accumulated every cycle. This process repeats for all coefficients  a i . The final polynomial product  p  is sequentially read out by the address signal  addr ab , combined with the coefficient of  c , thereby producing the final output  d  as d  =  a  ¬∑  b  +  c .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. 4.48 \n0 2 4 6 8 10 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "the kitti vision benchmark suite,‚Äù in  2012 IEEE conference on computer vision and pattern recognition . [24] A. Geiger, P. Lenz, and R. Urtasun, ‚ÄúAre we ready for autonomous \ndriving? IEEE, 2012, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "[62] V. Zakharchenko, K. P. Choi, and J. H. Park, ‚ÄúQuality metric for spherical panoramic video,‚Äù in  Optics and Photonics for Information Processing X , K. M. Iftekharuddin, A. A. S. Awwal, M. G. V¬¥azquez, A. M¬¥arquez, and M. A. Matin, Eds., International Society for Optics and Photonics. SPIE, 2016, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "In EH-WSNs, sensors providing different views of the same scene can en- hance inference accuracy through collaborative processing. ). Techniques such as co-training, consensus learning, and en- semble methods have been explored to combine information from multiple sensors ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Fortunately, there exist opportunities to keep and transfer the intermediate computation results of the last incomplete inference to the next power cycle. Considering a transition \nfor one layer from an activation solution  ‚ü® m 1 , n 1 , aG 1 ‚ü© to ‚ü® m 2 , n 2 , aG 2 ‚ü© , we Ô¨Ånd that, if the expression  Condition trans : ( m 1 =  m 2)&( n 2  |  ( Tile count 1   √ó  n 1))&( aG 1 =  aG 2) is true for each convolution layer, the activation solution ‚ü® m 1 , n 1 , aG 1 ‚ü© with power level PL1 can be transferred to be equivalent to an execution of activation solution  ‚ü® m 2 , n 2 , aG 2 ‚ü© with PL2. However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 233,
    "augmented": true
  },
  {
    "text": "2dB when compared to TMC13, due to the macro block-based approximation for the inter-frame compression. ‚Ä¢  Our Intra-only:  this design emits out a compressed frame with  ‚âà 17%  of the original data size (including 19 %  of geometry and 81 %  of attribute) and provides PSNR values up to  48 . 5 dB (only  6 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Announcing trillium, the sixth generation of google cloud tpu, 2024. [51] Google. Google gemini. \"",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "Representation learning solves both these issues. We achieve this by clustering the feature vector of the Large DNN model. The learner (here the teacher models) need to properly classify the data, learn if the data is a new type of one of the older classes, and identify if it encounters a new class.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Clearly, the current solution is  not  sustainable, neither in terms of the load on the power grid, nor in terms of the  CO 2  footprint (1.1 √ó 10 9 lbs); reducing the power budget for continuous learning is essential, as the carbon footprint of DNN training has emerged as a prominent concern [ 21 ], [ 57 ], [ 67 ], [ 89 ], demanding careful consideration as a primary design metric. Similarly, other applications with diverse data modalities, such as LiDAR and Camera for autonomous driving, IMU, bio-sensors, and Speech for IoT, face similar issues. Although green data centers [ 58 ], [ 59 ] provide partial mit- igation, they fail to address data privacy and communication bandwidth challenges in the current context.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "Fig. 8  shows the impact of micro-proÔ¨Åling on the hyper parameter selection. This was possible by restricting the training space and by using the superior exemplar set construction by using representation learning.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "0 \n200 \n400 \n600 \n0 \n0.6 \n1.2 \n1.8 \n2.4 \n3 \nCost ($) \nModel Type \nexec_time(ms) \nMemory(GB) Cost($) \nFigure 7. Cost variation for different allocations in  serverless func- tions . Compute time (seconds) and Memory allocated (GB) is shown on left Y-axis.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2403.14353 , 2024. 20 \nTerhi Korkiakangas. Challenges in archiving and sharing video data: Considering moral, pragmatic and substantial arguments.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel. This offers a Ô¨Çexible way to tune the power consumption in a large design space, even though the kernel size, convolution count and power consumption of different layers can signiÔ¨Åcantly vary. Inter-layer parallelism  means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Developers also need to indicate the primary ob- jective between these two constraints. chooses a set of single or ensemble models required to meet the developer speciÔ¨Åed constraints. Cocktail  automatically \nDataset Application Classes Train-set Test-set ImageNet [ 29 ] Image 1000 1.2M 50K CIFAR-100 [ 50 ] Image 100 50K 10K SST-2 [ 72 ] Text 2 9.6K 1.8K SemEval [ 66 ] Text 3 50.3K 12.2K \nTable 5:  Benchmark Applications and datasets.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "To further capture the beneÔ¨Åts of the weighted autoscal- ing policy, Figure  12a  plots the number of VMs spawned over time for the top-3 most used models in the ensemble for  Const1 . Not adopting an importance sampling based weighted policy would result in equivalent number of VMs as the Bline for all models. The Bline denotes number of VMs that would be spawned without applying the weights.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "All these activities may require  retraining  the routers. We will develop techniques that can help us identify which routers need retraining and when, and schedule such retraining in a data locality and parallelism aware fashion. Since the ex- perts are pivotal in the way the prompt/query is being answered, it is equally imperative for the routers to fully utilize the expert network by directing the rel- evant queries to the right expert(s) dynamically depending on the current ex- perts being involved in the network.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Xanadu  [ 27 ] represents the policy that scales containers only along the Most Likely Path (MLP), which is the request‚Äôs expected path. Figure 2 depicts the number of containers provisioned per function for three container provisioning policies subject to a Poisson arrival trace ( ùúá = 25 requests per second (rps)) for three applications. The static provision- ing policy is representative of current platforms [ 50 ] which spawn containers for functions in a workflow-agnostic fash- ion.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "While unstable power sources have been successfully utilized for applications in the IoT space [ 17 ], [ 18 ], [ 19 ], their use has not been heavily explored for RCA design. Current RCA approaches can be divided into two categories. The approaches in the Ô¨Årst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [ 3 ], [ 4 ], [ 5 ], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [ 6 ], [ 8 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "[58] Rakesh Gupta, Anil Singh, and Deepak Kumar. Adaptive load balancing in distributed machine learning systems. Journal of Parallel and Distributed Computing , 145:45‚Äì58, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "0 \n2000 \n4000 \n6000 \nOracle Kraken \n# Containers \nNGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network. 0 \n4000 \n8000 \n12000 \nOracle Kraken \n# Containers \nNGINX ID Movie_ID Text User_Service Rating Compose_Review Movie_Review User_Review Review_Storage \n(b) Media Service. 0 \n2000 \n4000 \n6000 \nOracle Kraken \n# Containers \nNGINX Check_Reservation Get_Profiles Search Make_Reservation \n(c) Hotel Reserva- tion.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "[40]  Rui Han, Moustafa M. Ghanem, Li Guo, Yike Guo, and Michelle Osmond. Enabling cost-aware and adaptive elasticity of multi-tier cloud applications. Future Gener.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "9 : with the ensemble, the best case annotation is the ideal one with only 2 false positives). Furthermore, the feature extraction for each of the potential \nexemplars for the teacher model is hardware-assisted (¬ß V-C ), and hence poses no overhead to the inference task. ¬¥as , the teacher models perform majority voting to decide the right exemplar, which signiÔ¨Åcantly reduces false positives and true negatives (refer to the top bar in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "ResiSchedule power efÔ¨Åciency analysis \nD. Transition efÔ¨Åciency Table  VI-D  shows the ratio of inferences using smooth- transitioned partial results and total inference count number. However, a very small fraction is observed with the other, stronger power sources. These results indicate that the smooth transition strategy Transition Keep   enables a signiÔ¨Åcant fraction of the inferences for all workloads on  Piezo .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Mathematical Formulation:  Let  W  be the weight matrix of a layer. Define a binary dropout mask m  = [ m 1 , m 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Also, as discussed in Sec. V-C, the overheads brought by our decision making amount to  5%  of the DNN inference time for YOLOv4-tiny when running on CPU, which reduces the performance and energy savings for our proposed schemes. If we can deploy the decision making logic on a  custom hardware  with negligible overhead, our proposed techniques would be more effective when targeting light DNN models.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "The  PTU+EA+AE  implementation combines the  PTU  and our  EA+AE  optimizations together. We denote this design combination as  EA+AE . ‚Ä¢  PTU+EA+AE  (HW) : In addition to the GPU-based design, our proposed designs can also be integrated into any other hardware platforms, including the FPGA-based PTU [28].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "[2] W. Niu, X. Ma, S. Lin, S. Wang, X. Qian, X. Lin, Y. Wang, and B. Ren, ‚ÄúPatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-Based Weight Pruning,‚Äù in  Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , 2020, p. 907‚Äì922. 5117‚Äì5124, 2019. [3] X. Ma, F.-M. Guo, W. Niu, X. Lin, J. Tang, K. Ma, B. Ren, and Y. Wang, ‚ÄúPCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for Real-time Execution on Mobile Devices,‚Äù  arXiv preprint arXiv:1909.05073 , pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 212,
    "augmented": true
  },
  {
    "text": "Using the expert execu- tion attribute database, we can extract the expert-hardware affinity, corresponding to which the equivalent chiplet versions are integrated to design a chip (in this regard, we will also consider existing and upcoming hardware accelerators [47, 61, 115, 131, 173]). A chip can be  homogeneous  (containing the same chiplets like only GPUs or CPUs) or  heterogeneous  (having different types of compute chiplets including hardware sup- port for quantization and sparsity [109]), to serve varying use-cases of EoEs. For example, an EoE consisting of GPU-affined experts can be mapped to a GPU-only chip, whereas an EoE consisting of varying chiplet affinities can be mapped to a suitable heterogeneous chip.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 198,
    "augmented": false
  },
  {
    "text": "Designing SDMM Hardware on CSD FPGA:  The SDMM hardware is innovatively designed to perform two modular multiplications per DSP Slice. This is achieved through the implementation of signed Gaussian sampling (Liu et al., 2019), for the error-vector  e 1  and the secret-key  r 2 . In this signed representation, the Gaussian distribution ranges from  [0 , ks )  to  [ q  ‚àí ks,  0) , where  k  takes integer values  1 ,  2 ,  3 , .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "¬¥as  is  ‚âà 4 . 03%, and minimum  ‚âà 2 . 94% (maximum  ‚âà 8 .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "[2]  Andrei Frumusanu, ‚ÄúThe Snapdragon 888 vs The Exynos 2100: Cortex-X1 & 5nm, Who Does It Better?‚Äù  ‚Äùhttps://bit. ly/3OF66Tw‚Äù , 2021. 926‚Äì932.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Chih-Kai Kang, Hashan Roshantha Mendis, Chun-Han Lin, Ming-Syan Chen, and Pi-Cheng Hsiu. More is less: Model augmentation for intermittent deep inference. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , 39(11):3479‚Äì3491, 2020.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Services like Ads and News Feed [ 39 , 44 ] would require SLOs within 100ms, while facial tag recommendation [ 83 ] can tolerate up to 1000ms. A myriad of model architectures are available to train these applications which by themselves can be deployed on appli- cation frameworks like  TensorFlow  [ 1 ],  PyTorch  [ 62 ] etc. Table  1  shows the different models available for image predic- tion, that are pretrained on Keras using  ImageNet  [ 29 ] dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "One approach to achieve lower RCA power is to limit precision. The impact of different precisions on CNN accuracy has been extensively studied [ 24 ], [ 25 ], [ 26 ], [ 27 ], [ 28 ], [ 29 ], [ 30 ], [ 31 ], [ 32 ], [ 33 ]. To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "[22] E. Dong, Y. Zhu, Y. Ji, and S. Du, ‚ÄúAn improved convolution neural \network for object detection using yolov2,‚Äù in  2018 IEEE International Conference on Mechatronics and Automation (ICMA) . IEEE, 2018, pp. 1184‚Äì1188.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Csd 2000. https://scaleflux.com/products/csd-2000/ , a. (Accessed on 11/13/2023). ScaleFlux.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "[19] HEADJACK, ‚ÄúThe Best Encoding Settings For Your 4k 360 3D VR Videos + FREE Encoding Tool,‚Äù ‚Äùhttps://headjack.io/blog/best- encoding-settings-resolution-for-4k-360-3d-vr-videos/‚Äù. [20] C. Heather Bellini, W. Chen, M. Sugiyama, M. Shin, S. Alam, and D. Takayama, ‚ÄúVirtual and Augmented Reality.‚Äù ‚Äùhttps://www.goldmansachs.com/insights/pages/technology-driving- innovation-folder/virtual-and-augmented-reality/report.pdf‚Äù, 2016. [21] L. F. Hodges, ‚ÄúTutorial: Time-multiplexed Stereoscopic Computer Graphics,‚Äù  IEEE Computer Graphics and Applications , pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 205,
    "augmented": false
  },
  {
    "text": "To determine the number of requests each VM can handle in parallel, we can conduct offline profiling for different model types. 3.2.2 Dynamic Load  For applications with dynamic load ( Observation 3 ),  serverless functions  can be used to mitigate the over-provisioning cost of VMs. However, a single ap- plication can contain a mix of queries with varying latency demands.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "We analyze the accuracy-latency trade offs of each strategy and show their benefits in different scenarios. A. Appliance Energy Prediction \nThe appliance energy prediction data-set predicts the energy usage of home appliances, given the environmental parameters, \n3 \nAlgorithm 1:  Training and Inference Pseudocode \nfunction  T RAIN (Sensor Data, NodeID, CloudID) @Edge for  each node  do \nprep data(data,node); ‚ñ∑ pre-process the data at edge if  Privacy Aware  then \ntrain model() ‚ñ∑ Locally train the model send model(cloudID) \nelse \nsend data(cloudID); ‚ñ∑ Send raw data to cloud \n@Cloud for  each node  do \nif  Privacy Aware  then \nsample trees(nodeID);  ‚ñ∑ Sample trees from each node \nelse \nmerge data(); ‚ñ∑ merge raw data from all nodes train(); end function function  I NFERENCE (Data, NodeID) @Edge for  each node  do \nPredict() if  Accuracy  ‚â§ Threshold  then \nSend data(CloudID); ‚ñ∑ Send data to cloud for accuracy \nelse \nSend results(CloudID); ‚ñ∑ Send the inference result Predict@Cloud ‚ñ∑ Run Prediction at Cloud \nend function \n0 \n0.02 \n0.04 \n0.06 \n0.08 \n0.1 \n0.12 \n0.6 \n0.62 \n0.64 \n0.66 \n0.68 \n0.7 \n0.72 \n0.74 \nEdge Cloud (Shared) Cloud (Privacy) \nlatency (ms) \nCorrelation \nPearson Correlation Latency (ms) \n(a) Data from 2 homes \n0 \n0.02 \n0.04 \n0.06 \n0.08 \n0.1 \n0.5 \n0.55 \n0.6 \n0.65 \n0.7 \n0.75 \nEdge Cloud (Shared) Cloud (Privacy) \nLatency (ms) \nCorrelation \nPearson Correlation Latency (ms) \n(b) Data from 4 homes \nFig.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 406,
    "augmented": false
  },
  {
    "text": "Specifically, we introduce an  activity- aware coreset construction  technique to dynamically adapt to both activity and the available harvested energy, while conserving maximum features of the data. This reduces the communication payload size by 8 . 9 √ó .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Here, we vary the tile size (an N √ó N tile is a N √ó N pixel block) from 4 √ó 4 to the entire frame (1080 √ó 1920) on the x-axis, and the y-axis gives the fraction of ‚Äúidentical tiles‚Äù (when compared pixel-by- pixel) in  two successive frames . From this Ô¨Ågure, we can Ô¨Ånd that:  1). Small-size tiles share signiÔ¨Åcant similarities across consecutive frames.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "To analyze the benefits of using invocation frequency, we designed a probability-based policy that employs weighted container scaling. For the purposes of this experiment, we base our function weights only on invocation frequencies that are periodically calculated at the beginning of each scaling window. Figure 2 depicts the number of containers provisioned per function for three container provisioning policies subject to a Poisson arrival trace ( ùúá = 25 requests per second (rps)) for three applications.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Towards this, we take the approach of analyzing the workloads to identify approximation op- portunities. We show that, by considering various parameters like region of interest and depth of view, we can approximate the ren- dering of the virtual object to minimize the amount of computation without affecting the user experience. The objective of this paper is to maximize its energy efficiency without jeopardizing the hologram quality for AR applications.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "International Society for Optics and Photonics, SPIE, 144 ‚Äì 152. [67]  Anlan Zhang, Chendong Wang, Bo Han, and Feng Qian. 2021.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of \n180 ¬µ W to 330 ¬µ W, and the throughput is increased by 85.7%. Note that the partial activation of computation cells can be realized by partially activating the peripheral circuits of the corresponding rows and columns in the ReRAM crossbar. This resilient activation approach can effectively combat  Nonideal scenario 1 .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "However, the neural compression algorithm needs to be  compute efficient  (reusing maximum analytics pipeline), have  high compression ratio  (need to compete with H264) and  feature rich  (could be decompressed and retrieved with a reasonable loss). Furthermore, it needs to take advantage of the  data similarity between frames  to further minimize the storage footprint, and thereby reducing the form factor and need of frequent disk swapping/ maintenance. This can be achieved by using modern  neural compression algorithms  instead of the classical encoding algorithm.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "In  2014 47th Annual IEEE/ACM International Symposium on Microarchitecture , pages 458‚Äì470. IEEE, 2014. [73] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L√©lio Re- nard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Tim- oth√©e Lacroix, and William El Sayed.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "During training, a document is routed to its type in criteria  a 1  and then routed to its type in another  a 2  until all criteria in  a  are covered. For instance, a Chinese medical summarization document will be routed to the Chinese language, medical domain, and summarization skill experts layer by layer. Our solution will leverage our previous work on multi-stage summarization [186] and multi-agent framework for long-context tasks [187].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass. , m n ]  where  m i  ‚àà{ 0 ,  1 } . Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Taylor Expansion Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œª .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "These codecs can operate on generic computational hardware, such as GPUs and FPGAs, without the need for specialized video processing units, thus broadening their applicability across different device platforms. This adaptability also extends to content delivery dynamics, where neural codecs can adjust the streaming quality in real-time, responding adeptly to fluctuations in network throughput and variations in device capabilities. Such capabilities not only enhance user experience by minimizing buffering and maximizing video quality but also optimize bandwidth usage, presenting a cost-effective solution for content providers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Proceedings of Machine Learning and Systems , 6:351‚Äì366, 2024. [10] Fawaz Alazemi, Arash Azizimazreah, Bella Bose, and Lizhong Chen. Routerless network-on-chip.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "[69]  Zhuoran Zhao, Kamyar Mirzazad Barijough, and Andreas Gerstlauer. 2018. DeepThings: Distributed adaptive deep learning inference on resource-constrained IoT edge clusters.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Association for Computing Machinery. [57]  Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "For latency-sensitive applications, offloading to peers may be more viable than offloading to the cloud. Since, all the deployments are working on the same task, and have trained on similar data, we will be able to perform the analytics task within a reasonable accuracy bound. That is, if the model at the edge node is unavailable (because of resource constraints) or has produced a low-confidence result, instead of directing the prediction query to the cloud, the edge could direct it to the peers (or other deployments) on the same local network.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2403.14353 , 2024. 20 \nTerhi Korkiakangas. Challenges in archiving and sharing video data: Considering moral, pragmatic and substantial arguments.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "86% power reduction, compared to the baseline. In addition, our  Intra-Holo  scheme is more power efficient than  Inter- Holo , translating to 27 . 24 Watts , on average, when running on the edge GPU, which translates to 3 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "We assume a monotonic relationship: higher SNR increases both the capture cost and the expected ac- curacy contribution. This assumption simplifies the model by ensuring that better data quality unequivocally enhances inference performance, while also making the energy ex- penditure predictable. In addition to capture costs, partici- pation incurs inference computation cost  e inf  and communi- cation cost  e comm .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "243 \nFig. The projection transformation Ô¨Årst calculates the transformation matrix ( T  ), and then uses the transformation matrix to map each of the pixel coordinates to generate the projection matrices ( P ) for the FoV frames. 3: Detailed illustration of projection transformation.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "We believe that, by looking deeper into the frame similarities and identify- ing reuse opportunities at a ‚ÄúÔ¨Åner level‚Äù, we can signiÔ¨Åcantly reduce the number of inferences, thereby reduce the burden on the hardware. However, the number of skipped inferences there is  static . Further, if we can  dynamically  exploit this opportunistic similarity (i.e., the inference is invoked based on runtime contents), the solution can encompass most vision applications without affecting the current hardware stack.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Like the first step, this step also involves synchronizations between planes (in  Line#12 ), which can again impact parallelization and slow down the entire execution. Intuitively, the execution performance is mainly determined by the number of depth planes (the outer for-loop in the algorithm) as well as the number of pixels in each depth plane (the inner for-loop in the algorithm). To study how the number of depth planes affects the hologram performance, we profile the execution latency from a typical edge GPU device [ 36 ], generating holograms with different number of depth planes (assuming the same number of pixels in each plane), and the results are plotted in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "On the other hand, the distance between the two eyes is small and is constant for a particular user 4 . Because of this, in current designs, the projection transformation is invoked  twice as it needs to generate two different transformation matrices for the left eye and the right eye. The two transformation matrices are very ‚Äúsimilar‚Äù as they inherit a relationship between them as a function of the small pupillary distance.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "\"https://github.com/google- research-datasets/Objectron/blob/master/index/bike_annotations\". [39]  Objectron. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "If the accuracy of the interval reaches the threshold accuracy (target + error_margin), we scale down the num- ber of available models in the ensemble. For every monitoring interval, we keep track of the accuracy obtained from predicting all input images within the interval. For consecutive sampling intervals, we calculate the  Mode  (most frequently occurring) of the majority vote received for every input.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Figure  16b  plots the latency reduction and accuracy gain, compared to  InFaaS  (baseline). Cocktail  is also able to reduce the number of models by 30% and 50% for medium ensembles ( Const2  &  Const3 ) as well. As shown for  Const1 ,  Cocktail  shows similar reduction (as image-classiÔ¨Åcation) with only using 4.8 models on average, which is 40% and 26% lower than Clipper  and  Clipper-X , respectively.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "[88]  C.-H. Wu, C.-F. Hsu, T.-K. Hung, C. Griwodz, W. T. Ooi, and C.-H. Hsu, ‚ÄúQuantitative comparison of point cloud compression algorithms with pcc arena,‚Äù  IEEE Transactions on Multimedia , pp. 298 \nAuthorized licensed use limited to: Penn State University. 1‚Äì1, 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Further evaluations suggest Origin  with RR-12 to be the best Ô¨Åt for HAR. This behaviour is expected and can be attributed to the increasing number of completed inferences. The nature of the workload itself gives us an opportunity to not perform inference at a rapid rate.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Table 3 shows the accuracy of classification tasks against the different baselines and state-of-the-art methods. Class Full Power AP PT iNAS+PT Stateful ePerceptive DynBal NExUME \nR1 84.93 74.46 77.02 79.62 80.85 81.50 82.15 83.60 R2 85.85 76.21 79.18 80.36 81.95 82.60 83.25 84.50 R3 81.09 72.43 75.38 78.18 79.05 79.70 80.35 80.85 SJ 90.95 82.33 85.00 87.58 88.60 89.15 89.80 90.50 SI 94.76 85.31 88.05 89.90 91.00 91.65 92.30 93.00 Table 3: Accuracy of NExUME and other methods for industry status monitoring dataset using TI MSP board and piezoelectric energy source. We use iNAS (Mendis et al., 2021) to find the DNNs meeting the energy income and train them using our proposed DynFit.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 278,
    "augmented": true
  },
  {
    "text": "In  IEEE INFOCOM 2020-IEEE Conference on Computer Communications . Distributed inference acceleration with adap- tive DNN partitioning and offloading. 2020.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "(GiGa MACs/s)/ Power utilization \nPower consumption with resilient acti. ( ¬µ W)/ Thr. (Giga MACs/s) /Power utilization \n1 50 0/Power failure/0/0% 0/Power failure/0/0% 2 100 0/Power failure/0/0% 80/25 √ó 1 √ó 1/0.312/80% 3 500 480/25 √ó 6 √ó 1/1.872/96% 480/25 √ó 6 √ó 1/1.872/96% 4 200 0/Power failure/0/0% 160/25 √ó 2 √ó 1/0.624/80% 5 250 0/Power failure/0/0% 240/25 √ó 3 √ó 1/0.936/96% 6 750 480/25 √ó 6 √ó 1/1.872/64% 720/25 √ó 3 √ó 3/2.808/96% 7 650 480/25 √ó 6 √ó 1/1.872/74% 640/25 √ó 2 √ó 4/2.496/98% 8 350 0/Power failure/0/0% 320/25 √ó 2 √ó 2/1.248/91% \n100 \n0.4 \n1.2 \n1.6 \n2.0 \n2.4 \n2.8 \nPower ( ¬≠ W) \nThroughput (Giga MACs/s) \nPower consumption with full-size activation \nPower consumption with tile-size activation \nThroughput with full-size activation Throughput with tile-size activation \nPower trace \nAverage harvested power Average power consumption with full-size activation Average power consumption with tile-size activation \nAverage throughput with full-size activation \nAverage throughput with tile-size activation \n356.3 \n180 \n330 \n1.3 \n200 \n300 \n400 \n500 \n600 \n700 \n800 \n0.8 0.7 \nPC1 \nPC2 \nPC3 \nPC4 \nPC5 \nPC6 \nPC7 \nPC8 \n0 \n0 0 0 80 480 480 0 160 0 240 480 \n480 640 0 320 \n0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 481,
    "augmented": true
  },
  {
    "text": "By integrating the game-theoretic approach with federated learning principles, we reduce communication overhead and ensure that contri- butions to model updates come from sensors best positioned to improve accuracy under energy constraints and uncertain availability. Our key contributions are as follows: \n‚Ä¢  Game-Theoretic Participation Strategy:  We develop a novel game-theoretic model for EH-WSNs that applies to both training and inference phases. This model balances anticipated energy availability, local data quality, and global benefit to establish stable and cooperative equilibria, opti- mizing the energy-accuracy trade-offs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "In particular, we expect each individual thrust of our project to form a ‚Äúbaseline‚Äù upon which further extensions and enhancements can be built. The proposed scalable cross-layer framework will enable the exploration of novel architectural and system-level solutions in addressing the LLM design challenges. Specifically, our algorithmic layer will ad- vance state-of-the-art in LLM models and algorithms and generate an extensible framework in which more futuristic EoE networks can be explored.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "In our proposal shown in the lower Ô¨Ågure, instead of constructing the octree in a point-by-point fashion, we process all three points as one ‚Äúbatch‚Äù in the  Morton Code Generation step in parallel, and output the Ô¨Ånal bounding box cuboid with side lengths 4 √ó 3 √ó 3 (x-axis: 3-(-1) =4, y-axis: 3-0 =3, and z-axis  3 - 0  = 3 ). Obviously, both the bounding box and the octree are updated point-by-point, which forces the pipeline to be sequential. Interestingly, in order to include  P 2 , the current bounding box has to expand its side length by  4 √ó , i.e., enlarging from  2  to  8 , and now the octree also contains more levels with all three points being in its leaf level.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 209,
    "augmented": true
  },
  {
    "text": "Partial Inference:  In this case, rather than processing the whole frame, only the RoI blocks are fed into the CPU and, with the memoized feature maps from previous frame, the CPU is able to generate the desired result for the current frame as accurate as performing inference on a full frame. Fig. 7: The proposed frame-level reuse and tile/region-level reuse design blocks implementation; BB/BBox: bounding boxes from the last FI; MV: motion vectors of the current frame; FM: feature maps for each layer from the last FI.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "Our approach to address these questions relies on decen- tralizing the DNN execution and letting each sensor perform its own inference. These sensors, each individually working as a weak classiÔ¨Åer, can together form an ensemble learning \nenvironment to achieve better accuracy with lower communi- cation overhead. For each sensor to perform inference using the limited and unstable harvested energy poses a scheduling problem, as non-deterministic time is required for the EH sensors to accumulate enough energy to perform the inference.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "1%  for YOLOv4-tiny ‚Äì both w.r.t. the baseline. With the FI+SI+PI scheme on the other hand, the mAP drops  1 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "B. Intra-Frame Geometry Compression \nIn above section, we have discussed our overall proposals for both geometry and attribute compression pipelines. ‚Ä¢  Quantization:  Finally, these small residual values are quantized to further improve the compression ratio. And, as will be shown later in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "DProb and  SProb  exhibit higher overall end-to-end response times compared to  Kraken , with  SProb  experiencing a dispropor- tionately high queueing delay compared to its cold start delay. This is because it uses statically assigned function weights, which prevents it from being able to proactively spawn con- tainers according to the varying user input. This results in the majority of requests getting queued at the containers.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Although, with the help of coresets, one can efficiently offload minimal input representations to a more compute-capable device, performing accurate inference on coresets is non-trivial due to their low-dimensional nature. Towards this, we propose  Seeker , a novel approach that leverages and extends coresets to efficiently execute DNN inference across a set of EH sensor nodes and a host mobile device. From the aforementioned challenges, it is evident that we need a concoction of both hardware-driven and software optimized solutions to build next-generation EH-WSNs with the ability to perform fine-grained intermittent computing, while ensuring efficient network communication.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "8b. The latency is only decreased about  18% , while the energy saving is  22%  and  13% , as shown in Fig. 8a.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "Proceedings of Machine Learning and Systems , 6:351‚Äì366, 2024. [10] Fawaz Alazemi, Arash Azizimazreah, Bella Bose, and Lizhong Chen. Routerless network-on-chip.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "The Probability Vector is an  ùëõ √ó 1 column vector that cap- tures the probabilities of the model being in different states after a number of time steps have elapsed, given that the model was initialized at a known state. A ‚Äòtime step‚Äô refers to a unit of measuring state change in the Markov Model. For practical purposes, we fix it to be the execution time of the slowest function at the current function depth.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "This was motivated from the observation that as we selected more number of points in importance sampling, the accuracy of the inference on the compressed data increased significantly (at times by 2%). Hence, the points which were not selected while performing importance sampling still had some impor- tance and can be represented as a function containing the low level nuances of the activity performed and the sensor state. The challenge was to learn this function, i.e.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "AI Models FYI , 2024. Available at:  https://www.aimodels.fyi . [46] Elias Frantar and Dan Alistarh.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "To deal with this,  Kraken  also employs the RS  7  to scale containers up or down in response to re- quest overloading at containers (due to under-provisioning) and container over-provisioning, respectively. In case of inadequate container provisioning, the Overload Detector  7a  in the RS  7  detects the number of allocated con- tainers for each DAG stage and calculates the estimated wait times of their queued requests (Algorithm 2  b  ). If it detects requests whose wait times exceed the cost of spawning a new container (the cold start of the function), overloading is said to have occurred at the stage.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "In this work we quantitatively characterize the cost, accuracy and latency implications of hosting ML inferences on different public cloud resource of- ferings. Our evaluation shows that, prior work does not solve the problem from both dimensions of model and resource heterogeneity. Hence, to holistically address this problem, we need to solve the issues that arise from combining both model and resource heterogeneity towards optimizing for application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "This GPU is commonly used in contemporary VR devices (Oculus [39], Magic Leap [16], and GameFace [47], etc. We then analyze the results measured using these platforms. A. VR Design ConÔ¨Ågurations \nWe evaluate the following six conÔ¨Ågurations of VR stream- ing to demonstrate the effectiveness of D¬¥ej`a View: ‚Ä¢  Baseline  (SW):  We use a mobile GPU [36] to evaluate the baseline VR video streaming. ).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Cocktail is open-sourced at  https:// github.com/jashwantraj92/cocktail \n5.1 Cocktail Prototype Implementation \nCocktail  is implemented using 10KLOC of  Python . 5 Implementation and Evaluation \nWe implemented a prototype of  Cocktail  and deployed it on AWS EC2 [ 5 ] platform The details of the implementation are described below. We name this as an importance sampling  6b  technique, because the model pools are scaled proportional to their popularity.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "10  b  . Clearly, a pattern (different from the  ellipse  observed with the Equirectangular format) exists in  Œî x  and  Œî y . Note that the pattern behavior also depends on the row numbers.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Besides using dense models, ensembling [ 15 ] techniques have been used to achieve higher accuracy. Why Ensembling? An Ensemble is deÔ¨Åned as a set of clas- siÔ¨Åers whose individual decisions combined in some way to classify new examples.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Battery-free wireless imaging of underwater environments. Nature communications , 13(1):5546, 2022. 10 \nReferences \nSayed Saad Afzal, Waleed Akbar, Osvy Rodriguez, Mario Doumet, Unsoo Ha, Reza Ghaffarivar- davagh, and Fadel Adib.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "[88] snorkel.ai, ‚ÄúMaking automated data labeling a reality in modern ai,‚Äù \nhttps://snorkel.ai/automated-data-labeling/ , (Accessed on 11/21/2022). [89] E. Strubell, A. Ganesh, and A. McCallum, ‚ÄúEnergy and policy con- \nsiderations for deep learning in nlp,‚Äù  arXiv preprint arXiv:1906.02243 , 2019. [87] K. Simonyan and A. Zisserman, ‚ÄúVery deep convolutional networks for \nlarge-scale image recognition,‚Äù  arXiv preprint arXiv:1409.1556 , 2014.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 166,
    "augmented": true
  },
  {
    "text": "[25]  X. He, H. L. Cao, and B. Zhu, ‚ÄúAdvectivenet: An eulerian- lagrangian Ô¨Çuidic reservoir for point cloud processing,‚Äù  arXiv preprint arXiv:2002.00118 , 2020. [26]  J. Hu, A. Shaikh, A. Bahremand, and R. LiKamWa, ‚ÄúCharac- terizing real-time dense point cloud capture and streaming on mobile devices,‚Äù in  Proceedings of the 3rd ACM Workshop on Hot Topics in Video Analytics and Intelligent Edges , 2021, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Each worker VMs runs a client process to serve its corresponding model. The requests are served as independent parallel threads to ensure timely predictions. We use  Python Sanic  web-server for commu- nication with the master and worker VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "We then compare those design schemes on our platform (Sec. VI-C ). Finally, we provide detailed insights on how to tailor the PCC pipeline to cater to various application preferences (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "C ONCLUDING  R EMARKS \n360¬∞ VR videos have become the next trend in entertain- ment media and soon will become an integral part of the technology inÔ¨Çuencing many application domains. However, unlike planar videos, the 360¬∞ VR video streaming demands signiÔ¨Åcantly more compute power from a battery-operated headset. VII.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "IEEE, 2006. [117] Xiaonan Nie, Xupeng Miao, Shijie Cao, Lingxiao Ma, Qibin Liu, Jilong Xue, Youshan Miao, Yi Liu, Zhi Yang, and Bin Cui. Evomoe: An evolutional mixture-of-experts training framework via dense- to-sparse gate.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "For example, in Figure 1a, the Commonality  of the function  ùê∂ùëúùëöùëùùëúùë†ùëí _ ùëÉùëúùë†ùë° in the  Social Network  application is given by the fraction   4 \n7   as it is present in four out of the seven possible paths in the DAG. Using Commonality  in the weight estimation process allows  Kraken to tolerate function probability miscalculations by assigning higher weights to those functions that are statistically more likely to experience rise in usage because of their presence in a larger number of workflows. Note that we deal with the possibility of container overprovisioning due to the in- creased function weights by allowing both  Connectivity  and Commonality  to be capped at a certain value.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "2021. Optimizing image quality for holographic near-eye displays with Michelson Holography. Optica  (2021), 143‚Äì146.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Let  Q  represent the set of execution quanta, where each quanta  q  ‚ààQ  is defined by a tuple  ( l, e ) : q  = ( l, e ) Here,  l  is the number of loop iterations and  e  is the estimated energy required for these iterations. DynFit integrates closely with DynAgent, which serves as a repository of EH profiles and hardware characteristics. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 172,
    "augmented": true
  },
  {
    "text": "Restrictions apply. [59]  Park, Jounsup and Chou, Philip A. and Hwang, Jenq-Neng, ‚ÄúRate-utility optimized streaming of volumetric media for augmented reality,‚Äù 2018. [60]  W. A. Pearlman and A.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "The compiler and system software code and other design artifacts will be maintained in both source formats (e.g., C/C++/C#/Python files) as well as in binary, in an open-source fashion. Data and Metadata Standards \nThe workload characterization and experimental data will be compressed and made available to interested parties in a compressed format. 2.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "V1 has fewer objects and less movements, and thus, compared to V2, the savings on execution time and energy consumption for V1 are slightly higher, as shown in Fig. 8b and Fig. 8a.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "TABLE I: Qualitative summary of DNN vision optimiza- tion work in terms of accuracy, saving, adaptivity, hardware support, and decision making mechanism (DM). A check-mark in the Custom HW column indicates that the corresponding approach does not need custom hardware, whereas a cross means it needs. Note that a check-mark in the second and third columns means the corresponding scheme achieves high accuracy and energy/per- formance efÔ¨Åciency, respectively.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "The algorithm makes sure that no data is shared with a centralized agent (like the cloud, which performs the training action), yet the learner is able to learn by combining multiple pre-learnt models. We extended this design idea by constructing a random forest model as a combination of multiple decision trees from different learners (different deployments). This problem has been addressed in federated learning by combining the models using weight averaging [2].",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Predictive maintenance in the Industry 4.0: A systematic litera- ture review. 15 \n0 \n20 \n40 \n60 \n0 \n0.1 \n0.2 \n0.3 \n0.4 \n1 \n4 \n7 \n10 \n13 \n16 \n19 \n22 \n25 \n28 \n31 \n34 \n37 \n40 \n43 \n46 \n49 \n% Reconstruction Error \nFFT Amplitude \nFrequency (Hz) Reconstructed Original % Error \nFigure 14: An example of generator based coreset re- covery \nFigure 15: % completion of the inference at the edge for bearing fault data with different EH source. Computers & Industrial Engineering  150 (2020), 106889.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Compiler-directed application mapping for noc based chip multiprocessors. [24] Guangyu Chen, Feihui Li, and Mahmut Kandemir. In  Proceedings of the 45th annual design automation conference , pages 620‚Äì625, 2008.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "When the energy required for executing multiple QuantaTasks exceeds the available energy budget, DynInfer employs  task fusion  to combine smaller tasks into larger atomic units that can be executed within the energy constraints. Formal Definition of Task Fusion:  Let  Q  =  { q 1 , q 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Some methods pro- pose selecting a subset of sensors based on energy levels or predefined schedules ( ? ), but these can lead to suboptimal performance by not considering the sensors‚Äô data quality or potential future contributions. Several works have explored adaptive participation strate- gies that consider energy harvesting rates, energy consump- tion patterns, and application-specific requirements ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Project Timeline \nFigure 8 despicts a tentative projected timeline for the proposed work. The investigators have a very good track record of advising under- graduate students (resulting in more than 20 undergraduate honors thesis), and they will continue to do so in this project as well. We will seek REU supplements to support the undergraduate students for working on this project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "We use regression to Ô¨Ånd the weights (exponents and coefÔ¨Åcients) to the prediction curve followed by exponential smoothing to decay the weights. The rate of exponential smoothing depends on the scheduler used - while for the conservative scheduler the predictor always underestimated the power (shallow smoothing), the eager scheduling uses the direct output of the predictor (steeper smoothing). We took a history (years 2019 and 2020; from Seattle, WA; Sterling, VA; and Oak Ridge, TN) of solar energy traces from SOLRAD [ 25 ], [ 91 ] and built a weight matrix which looks into a window of 1 hour at 1 minute (average power) intervals to predict the power for next 10 minutes (1 minute granularity).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 170,
    "augmented": true
  },
  {
    "text": "Fig. Observation over 40 hours of continuous learning on the dataset suggest that the micro-proÔ¨Åler has, on average, an accuracy deviation of 2 . 8b  also shows the error rate of retraining performed by choosing the hyperparameters given by the micro-proÔ¨Åler vs an oracle selection.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "V for more details). 3b. ii Missing Object(s) : Another scenario is one in which the object(s), which have not been identiÔ¨Åed in the previous frames, are detected in the current frame, as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "This is because requests that have to wait longer than the cold start would be served faster at a newly created container than by waiting at an overloaded container. Thus, the RS  7  , in combination with the PWS  2  and re- quest batching  5  , helps  Kraken  remain SLO compliant while using minimum resources. Similarly, for stages where container overprovisioning has occurred, the RS  7  gradually scales down its allocated containers to the appropriate number, if its Function Idler module  7b  detects excess containers for serving the current load (Algorithm 2  a ).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": ";  iv)  How can inter-chiplet and inter-chip data movements be choreographed to maximize performance and minimize energy consumption for training, inference, and re-training? ;  ii)  What types of chiplet-based architectures are suitable for EoE-based LLMs, and what is the search space for chiplets? ;  iii)  What kind of reconfigurability is needed for chips to accommodate the heterogeneous and morphable aspects of EoEs?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "The major  contributions of the paper can be summarized as follows: \n‚Ä¢  From an open-source 360¬∞ VR video dataset [3],  we identify both temporal reuse and spatial locality that exists in user behavior . We formally analyze the potential ‚Äúinput invari- ability‚Äù in the  projection computation  during  360 ¬∞ video streaming, which manifests in the head movement locality (temporal reuse) and the stationarity relationship between two eyes (spatial reuse). Such invariances are leveraged as reuse opportunities to reduce the compute-heavy projection computation.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "He will lead Thrust-2 and collaborate with Das and Zhang in Thrust-4. Rui Zhang (Co-PI):  Zhang‚Äôs research expertise includes LLMs, trustworthy human-centered AI, and AI for science. He has an extensive research background and publication record in efficient methods for LLMs such as LLM pruning (NAACL 2024), LLM parameter-efficient finetuning (ACL 2022, EMNLP 2023), long-context LLMs (ACL 2022, NeurIPS 2024), data selection for LLM in-context learning (ICLR 2023).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "IV-B  and Sec. IV-C . Figure 4: Intra-frame PCC pipelines.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 24,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. 896 \nAuthorized licensed use limited to: Penn State University. T4, thanks to its limited compute capabilities, could not Ô¨Ånish training tasks on time.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "4.1 Exploring the Entire Design Space in AR Hologram Processing \nExploring the entire design space for the AR hologram processing is a non-trivial task. First of all, a large number of sensor inputs are fed into the hologram pipeline (as shown in Fig. 1b), such as IMU sensors, eye tracking or IR sensors, hand motion sensors, RGB-D im- age sensors, etc.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "C. Design and Implementation \nWe designed our both schemes (frame-level reuse in Sec. IV-A and region-level reuse in Sec. IV-B) as plugable modules to the existing compute engines (e.g., CPU, GPU, etc.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Numerous prior studies (e.g., see [21]‚Äì [23] and the references therein) have clearly shown that, regardless of the type of the compute hardware employed, the NN inferences are both compute and memory intensive. As a result, this stage is the main bottleneck in the NN applications. Output:  Following the inference stage, the resulting Feature- Maps (FMs) are used to generate the Ô¨Ånal tags/bounding-boxes and Ô¨Ånally report to the application (e.g., a cow has been identiÔ¨Åed in the image with 95% conÔ¨Ådence).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "Hello bytes, bye blocks: Pcie storage meets compute express link for memory expansion (cxl-ssd). In  Proceedings of the 14th ACM Workshop on Hot Topics in Storage and File Systems , pp. 45‚Äì51, 2022.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Bar graphs (latency) plotted using primary y-axis and line graph (#models) plotted using secondary y-axis. Const1 Const2 Const3 Const4 Query \n0 \n5 \n10 \n#Models \nClipper Clipper-X Cocktail \n(a)  Image ClassiÔ¨Åcation-Cifar-100. Const1 Const2 Const3 Const4 Query \n0.0 \n2.5 \n5.0 \n7.5 \n#Models \nClipper Clipper-X Cocktail \n(b)  Sentiment analysis.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "[35] Shichen Dong, Wen Cheng, Jiayu Qin, and Wei Wang. Qaq: Quality adaptive quantization for llm kv cache, 2024. [36] Xiaobin Dong, Kurt Keutzer, and Cong Zhang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "eural networks (DNNs). Furthermore, running inference for videos on edge devices is even more expensive than images due to the data volume and the power/energy constraints. However, DNNs are quite compute- intensive and generate very large memory footprints [1].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "The sec- ond step,  Backward-Propagate  (denoted  ‚ù∑ in Fig. Note, however, that, this step also requires sequential barriers within each plane ( Line#6  synchro- nizes the threads in a warp/block for one depth plane) and across planes ( Line#7  synchronizes the results from all the depth planes, before moving forward to the second step). Hence, as we will show later in this section, such barriers sliced into the massive parallel execution can cause load imbalance and instruction stalls, which slow down the entire execution and impact performance.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "5:  Accuracy results of the different policies described in Sec- tion III. RR indicates the extended round-robin policy in use, e.g. Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Figure 8:  Cost savings of  Cocktail  compared to three schemes. Const1 Const2 Const3 Const4 Query \n0 \n5 \n10 \n#Models \nClipper Clipper-X Cocktail \n(a)  Average number of models used in the ensemble. IRV2 \nDNet201 \nNASMob \nDNet121 \nXcep \nMNet \nIncep \nMNetV2 \nRNet50V2 \nRNet50 \nModel \n0 \n50 \n100 \nImportance(%) \n(b)  Distribution of requests served by each individual model.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "[87] Habana Labs. Rep , 2020. Habana gaudi ai processor.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "(a) HoloAR overview. (c) Intra-Holo scenario. Figure 5: Three opportunities for reducing hologram computation in an AR application.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Moreover, the reuse between both eyes is further optimized by  AE . along with  P  and  F , due to their dependencies. However, if  T 2  does not change across frames,  P  is identical to the previous frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Note that this additional eye tracking proce- dure needs to be invoked for each frame, in order to capture/reflect the current eye movements without causing nausea for the user. As a result, eye tracking needs to incur minimum overhead, while providing a fairly good accuracy. Fortunately, there already exist a large body of techniques which can track the eye movements efficiently (e.g., see [ 26 ] and [ 12 ] and the references therein).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "In comparison, Semantic- Aware-Streaming (SAS) exploits the semantic information inherent in a VR video content to precisely predict users‚Äô next head orientations [28]. These optimizations rely on the powerful cloud with a high bandwidth access, which may not be always available. However, our work focuses on edge-side optimization, which can also be implemented as a comple- mentary add-on in such cloud-assisted systems.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Immediate Rewards and Penalties: Let  Œ≥ >  0  be a scal- ing factor that translates accuracy gains into utility rewards. When sensor  s i  participates ( a i ( t ) =  P ) and contributes cor- rectly to the inference task, it receives a reward proportional to the improvement in global accuracy, denoted by  ‚àÜ A i ( t ) : \nR i ( t ) = \nÔ£± Ô£¥ Ô£≤ \nÔ£¥ Ô£≥ \nŒ≥  ¬∑  ‚àÜ A i ( t ) , if  a i ( t ) =  P and correct inference , ‚àí Œ¥, if  a i ( t ) =  P and incorrect inference , ‚àí Œ∑, if  a i ( t ) =  NP . Here,  Œ¥ >  0  penalizes incorrect participation, discourag- ing sensors from submitting low-quality data, while  Œ∑ >  0 penalizes non-participation to prevent perpetual abstention.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 251,
    "augmented": false
  },
  {
    "text": "Each (edge)  device  (which is a part of the  Deployment scenario like machine state monitoring) contains an embedded computer (e.g. raspberryPi) to sample, collect, and process the data and is also equipped with wireless communication to local/cloud server). The deployed edge devices perform the same analytics task (for example, monitoring the health of same type of machine at different sites) using a  random forest algorithm  (refer Algorithm-1).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "[34]  M. Alwani, H. Chen, M. Ferdman, and P. Milder, ‚ÄúFused-layer cnn accelerators,‚Äù in  2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp. 1‚Äì12, 2016. [35]  M. D. Lam, E. E. Rothberg, and M. E. Wolf, ‚ÄúThe cache performance and optimizations of blocked algorithms,‚Äù in  Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "387‚Äì400, 2019. [84]  veesus.com, ‚ÄúINTRODUCING ZAPPCHA ‚Äì MOBILE POINT CLOUD CAPTURE AND CLOUD-BASED STORAGE,‚Äù ‚Äùhttps://bit.ly/3xiSw0v‚Äù , 2021. [85]  Vision Lab, Nanjing University, ‚ÄúMultiscale Point Cloud Geometry Compression,‚Äù  ‚Äùhttps://bit.ly/3xiAxah‚Äù , 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "; v)  What is the estimated training time given the size of input data and choice of model architecture? ; vi)  What are the desired architectural details of accelerators employed to do training/inference? ; and vii)  What are the performance, power and accuracy tradeoffs in training or inference, given hyper-parameters like the size of training dataset and the length of prompt?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "These partnerships will also provide external insights to the project, and in particular, our collaboration with ANL enable us to access a large number and variety of compute platforms (including those with accelerators). Project Website \nA website will be maintained for the project. This website will have both ‚Äúexternal‚Äù and ‚Äúinternal‚Äù inter- faces.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "We want to emphasize that, compared to virtual reality (VR), the AR video processing typically incurs additional computational \nTable 1: Ideal latency requirements [19]. Task Ideal Latency Algo. Pose Estimate \n33  ms Kimera [53] \nEye Track \n33  ms NVGaze [26] \nScene Reconstruct \n100  ms InfiniTAM [50] \nHologram 33  ms GSW [49, 63] \ntasks and interacts with more hardware resources [ 61 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "1‚Äì6. [50]  A.-M. S. Mohamed, ‚ÄúPotential of 3d laser point cloud data usage for the tourism industry,‚Äù in  The International Conference on Civil and Architecture Engineering , vol. 12, no.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "1) How to Speedup? : First, RAHT [ 14 ] takes the initial octree (which is deepest now) as input, and invokes  RAHT and Quantization  to perform the linear transformation on the leaves with their siblings along the x, y and z dimensions, and shrinks the tree layer-by-layer. Here, we assume that the octree for these points has already been established using the geometry pipeline, and we next go through our proposed attribute pipeline step by step and explain where the envisioned beneÔ¨Åts will come from.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "However, the granularity of similarity explored in these prior works is  static , and either too coarse (e.g., skips the entire frame [9]) or too strict (e.g., still needs to compute despite very few changes). Furthermore, these changes between consecutive frames need not be explicitly calculated as they can be extracted from the hardware codecs directly, giving us a chance to capitalize on an existing funda- mental component, instead of adding new hardware blindly. Leveraging inter-frame similarity, intra-frame redundancies, and the RoIs have been investigated for different purposes, e.g., exploring pixel-similarity to encode frames and reduce bandwidth consumption [17], utilizing RoIs to reduce the com- putational footprint [18], [19], analyzing inter-frame similarity to skip inferences [9], and caching the intermediate results to avoid redundant computation [8].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 205,
    "augmented": true
  },
  {
    "text": "Ekya [ 12 ] using ResNeXt101) to annotate the data or used a heuristic on top of the teacher model (e.g. intermittent learning [ 47 ] using randomized selection, K‚ÄìLast List, or round-robin policy). As shown in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Moreover, a majority of the machines in operation, comprising much of the modern supply chain, are classical machines without any sensing or intelligence built into them. Without any smartness built into them, these classical machines often suffer from unforeseeable failures. Therefore, retrofitting such classical machines with smart sensors will help in preventing such failures and will allow taking predictive measures to increase production efficiency.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "2018. [50]  Liang Wang, Mengyuan Li, Yinqian Zhang, Thomas Ristenpart, and Michael Swift. Computer Networks  (2009).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "Habana gaudi ai processor. https://habana.ai/products/gaudi2/ , 2023. Ac- cessed: 2024-04-27.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "However, video data often comes with a large amount of inter-frame similarity (Ying et al., 2022b; Zhang et al., 2017; Zhao et al., 2020, 2021; Ying et al., 2022a). This similarity could be exploited, like in classical encoding algorithms, to further increase the compression ratio while improving the feature quality. Furthermore, neural codecs offer us the flexibility to approximate the computation (using quantization) to further enhance efficiency.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "; ii)  How can we dynamically shape the morphology of EoE systems by identifying the best design points in the search space? Our research tasks in Thrust 1 are illustrated in Figure 3. They will address the following research questions: i)  What is the search space for EoE systems, in terms of expert types, expert routing, expert model architecture, and expert composition?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "6 : Accelerator level  provides a high-level overview of the compute scheduling (where the redacted part of the hard- ware is turned off because of the lack of power). The key components of the scheduler are the ‚Äúmoving average power predictor‚Äù and the ‚Äúmicro-proÔ¨Åler‚Äù. In the  i th   kernel scheduling iteration, given the power budget and power prediction, the \nmicro-proÔ¨Åler decides the required training conÔ¨Åguration, and the control logic (conservatively) enables suitable number of tiles (say  t i  tiles of the 256 tiles).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "5 \nr2 \nr1 \nr4 \nr3 \nr5 \nOriginal Data Coreset with imp-sampling Coreset with Clustering \nFigure 4: A toy example of the coreset construction techniques in  Seeker . Imp-sampling uses a probability based importance sampling; clustering preserves the geometric shape of the original data. In each case, the points/values in  red  are communicated to the host.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Similarly, Ekya [ 12 ] only focuses on co-location of computation, and it‚Äôs efÔ¨Åciency on Ô¨Ånishing compute even on a custom hardware is shown in Fig. 4 . Green Data Centers:  As sustainability gains traction, industry has worked towards building green data centers [ 58 ], [ 59 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "In contrast, this paper revisits the  < accuracy, energy, performance >  design space, and tunes the design knobs adaptively with the changing constraints of applications over time. SpeciÔ¨Åcally, we propose and evaluate two schemes (for skipping the inference, and bypassing the compute for unimportant regions), to improve performance and save energy. Our evaluations indicate 2.2 √ó speedup and 56 %  energy saving over the baseline setting.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "None of  Naive1  and  Naive2  executions can go through power cycle  PC-i  and the power utilization is very low, as there is a signiÔ¨Åcant mismatch between the power producer and consumer. In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks. Figure 6(c) presents a Ô¨Çexible scheduling strategy applied to ResiRCA.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "In our work, local computation across the CNN applications is  ‚àº 50x more efÔ¨Åcient than transmission over Bluetooth with 3Mbps and 2.5mW. The x-axis (power efÔ¨Åciency) denotes the percentage of power cycles where the RCA can activate. C. Power utilization In order to further understand the power utilization, we use a two-dimensional plot that illustrates the features of power consumption with the ResiSchedule  strategy, as shown in Figure 10.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "We divide the data into training and testing sets, and to simulate a distributed environment, the training data is further divided into multiple different chunks (starting from 2 to 4, each part representing a household in the same neighbourhood). 2. The home owners may or may not be willing to share the sensor measurements of their home for privacy reasons.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "This data-set is particularly suited for evaluating the performance of  Salient Store  in dense, urban environments. It offers high-resolution sensor data, including LIDAR and camera recordings, across a variety of urban and suburban landscapes. Another video data-set, the  Waymo Open Data-set  (Sun et al., 2020), is one of the largest and most diverse data-sets for autonomous driving.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "InterHolo IntraHolo InterIntraHolo \nPSNR \n(a) PSNR. 0% \n20% \n40% \n60% \n80% \n100% \n0% 20%40%60%80%100% \norm. PSNR (%) \nEnergy Savings (%) \n(b) Trade-offs.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "It has been shown that the power requirement to fully activate a 128 √ó 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [ 3 ]. With this design, the presented power sources can hardly activate even a small ReRAM. In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "[33] Sarkar Snigdha Sarathi Das, Ranran Haoran Zhang, Peng Shi, Wenpeng Yin, and Rui Zhang. Unified low-resource sequence labeling by sample-aware dynamic sparse finetuning. Association for Com- putational Linguistics.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "This data-set, consisting of audio recordings, offers a different modality to test the versatility of Salient Store  in handling various types of continuous learning data beyond visual inputs. In our comparative analysis, we employ  VSS: A Video Storage System  (Haynes et al., 2021) as a ‚Äúbaseline‚Äù, given its innovative approach in optimizing video data management. VSS excels in decoupling high-level video operations from storage and retrieval processes, efficiently organizing data on disk, enhancing caching mechanisms, and reducing redundancies in multi-camera setups (Haynes et al., 2021).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "ISBN 9781450394215. doi: 10.1145/3544548.3581045. URL  https://doi.org/10.1145/3544548. 3581045 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "109‚Äì165. [56] H. R. Mendis, C.-K. Kang, and P.-c. Hsiu, ‚ÄúIntermittent-aware neu- \nral architecture search,‚Äù  ACM Transactions on Embedded Computing Systems (TECS) , vol. 24, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Major Results: No publication yet as the project started in September 2024. Broader Impacts: This project initiates several aspiring education and outreach activities supported by project research outcomes to involve, mentor, and empower female, underrepresented, disabled, and interdisciplinary students. References \n[1] NVIDIA A100 Tensor Core GPU., 2023.  https://www.nvidia.com/en-us/data-center/ a100/ .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Random sampling of the decision trees also augments the model by minimizing the data induced bias of each of the models. The random sampling method is data agnostic, and hence ensures minimal data induced bias. Random sampling of decision trees, albeit a na¬®ƒ±ve way, has been empirically shown to work well in preserving model characteristics and providing accurate predictions.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2401.08281 , 2024. Sourav Dutta and Chinwe Ekenna. The faiss library.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "Moreover, the conventional PC typically stores the geometry, while a wide array of applications, especially the ones meant for content consumption, infotainment and gaming, need the attributes to be stored as well, hence making the compres- sion even more complex. For example, TMC13 [ 56 ] and CWIPC [ 48 ] ‚Äì two state-of-the-art (SOTA) PCC techniques ‚Äì take  4 . 1 s  and  4 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Cocktail takes the accuracy of each model as a probability of cor- rectness and then iteratively constructs a model list, where the joint probability of them performing the classiÔ¨Åcation is within the accuracy target. We tolerate a 0.2% ( Acc margin ) and 5ms ( Lat margin ) variance in  Acc target  and  Lat target , respec- tively. Next, we solve for the second objective function ( O 2 ) by minimizing  ¬µ C , while maintaining the target accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "This difference, in terms of percent of SLO violations, changes from being at most 0.1% to being between 0.1 to 0.35%. This is a result of  Kraken  being more resilient at the tail of the response time distribution as it uses both  Commonality  and  Connectivity  while spawning containers. In comparison,  Comm Only  and  Conn Only  fail to spawn enough containers for each important function as they do not consider both these parameters, resulting in increased tail latency and exacerbates the SLO violations.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "248 \nFig. 7: The proposed  EA  and  AE  design blocks implementation. 35%  of that consumed by baseline.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "In  2021 IEEE 37th International Conference on Data Engineering (ICDE) , pp. 1775‚Äì1786. IEEE, 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "This design, depicted in Fig. 2, gives the programmable computational capa- \n7 \nbilities of CSDs along with the cost-effectiveness and durability of the classical HDDs. It leverages the PCIe interface for efficient ‚Äúpeer-to-peer communication‚Äù, substantially reducing communication latency and energy requirements.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Since there is a small offset between the two eyes, the projection computation needs to cap- ture the pupillary distance to generate a separate view for each eye. The Ô¨Årst input is from the user side, including the head orientation and pupillary distance. At a high level, we need two major inputs to generate the Ô¨Ånal projected frames on the display.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "We quantitatively justify the choice of using DeepARest by conducting a brick-by-brick comparison of the accuracy loss \n1056    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nwhen compared with other state-of-the-art prediction models used in prior work. Table  4  shows the root mean squared error (RMSE) in- curred by all the models. B Why DeepARest Model?",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "However, in our setup, both beneÔ¨Åt from the distributed au- toscaling and prediction policies, thus eliminating variability. Also note that  InFaas  is deployed using OnDemand instances, while both  Clipper  and  Cocktail  use spot instances. 6 Analysis of Results \nThis section discusses the experimental results of  Cocktail using the Wiki and Twitter traces.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "This leaves us with the following important questions: ‚Ä¢  Are continuous inferences essential, or can we leverage the workload itself to skip some inferences without substantial accuracy loss, allowing enough energy to be accumulated for future inferences? ‚Ä¢  Since all the sensors cannot be activated together due to the limited power, how do we effectively perform the ensemble? III.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "3 \nframe features and the motion vectors from the compute hardware to perform a novel layered neural compression. ‚Ä¢  We discuss the storage data-flow, the compute orchestration and mapping in the proposed system. This includes a hardware software co-design for compute-intensive applications along with map- ping different functions to different hardware in the data pipeline.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "If this deviation is profitable for sensor s j , we have: \nU j ( a ‚Ä≤ j ( t ) ,  a ‚àí j ( t ))  > U j ( a j ( t ) ,  a ‚àí j ( t )) . Because the other sensors‚Äô utilities do not change instan- taneously by  s j ‚Äôs unilateral action, the increment in  U j ( t ) results in: \nŒ¶( a ‚àí j ( t ) , a ‚Ä≤ j ( t ))  ‚àí Œ¶( a ( t )) = \nU j ( a ‚Ä≤ j ( t ) ,  a ‚àí j ( t ))  ‚àí U j ( a j ( t ) ,  a ‚àí j ( t ))  >  0 . Thus, any unilateral profitable deviation increases  Œ¶( a ( t )) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 243,
    "augmented": false
  },
  {
    "text": "For example, Consider two convolution operations  C 1  and  C 2  with energy requirements  E C 1  and  E C 2 , respectively. If individually  E C 1 , E C 2  > E b  but  E C 1  +  E C 2  ‚â§ E b , we fuse  C 1  and  C 2  into a single task. The fused task executes both convolutions atomically within the energy budget, avoiding the overhead of checkpointing between them.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "13‚Äì24. [29] Y. Li and W. Gao, ‚ÄúDeltaVR: Achieving High-Performance Mobile VR Dynamics through Pixel Reuse,‚Äù in  2019 18th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN) , 2019, pp. 91‚Äì103.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "by adjusting the threshold as discussed in Sec. VI-B . compression ratio (i.e., input size / compressed size).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "We call this  Eager Scheduling . when some of the tiles are half way through the compute, some other tiles can just start execution). Facilitating such schedul- ing will provide us less idle time, more forward progress and more efÔ¨Åcient use of the incoming power but at the expense of more control overheads.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Const1 Const2 Const3 Const4 Query \n0.0 \n2.5 \n5.0 \n7.5 \n#Models \nClipper Clipper-X Cocktail \n(b)  Sentiment analysis. Figure 15:  Average number of models used in the ensemble. the accuracy, while short latency models need to be ensem- bled to reach the same accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "3b, consists of a single shift block, a subtractor, and a adder, consuming much less hardware then the state-of-the-art (Fan et al., 2018). The MR, in conjunction with the multiplier, delivers the output within 2 clock cycles. The SDMM also offers a simpler controller design for multiplication and in-place product term reduction after vector-vector multiplications.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Since  Us. ¬¥as  is a continuous learning framework and learns from the live data that the camera(s) capture, data collection is simply storing the live video feed. C ONTINUOUS  L EARNING \nThe Ô¨Årst step to any data-driven learning algorithm is data collection and annotation.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Overall, Us.¬¥as demonstrates the viability of sustainable con- tinuous learning at edge servers, encompassing advancements in energy harvesting, algorithmic techniques, and hardware adaptation. III. C ONTINUOUS  L EARNING \nThe Ô¨Årst step to any data-driven learning algorithm is data collection and annotation.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Complex Compute on EH-WSNs:  To quantify the scope performing complex compute using EH-WSNs, we took hu- man activity recognition (HAR) as a workload 1 , and per- formed experiments on the MHEALTH data-set [9, 10] (see Section 5 for data-set details) using the DNNs proposed in [ 26 ,  60 ], an energy harvesting friendly DNN hardware accelerator [ 56 ] (to ensure that we are using the state of the art EH-WSN hardware) and recently proposed HAR- specific optimizations for EH systems [ 47 ]. Although, we evaluate and show the communication cost savings of  Seeker  on the battery backed CoTS hardware, we propose possible (simulated) hardware accelerator designs to fully deploying a EH-WSN capable of performing inference, compression and communication in harvested energy budget. Therefore, there has been a significant body of work [ 40 ,  42 ,  47 ,  56 ] on developing appropriate next generation hardware (most of \n3 \nthem on simulation).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 232,
    "augmented": true
  },
  {
    "text": "Initially,  Œ∏  is pre-trained offline and deployed to all sensors, enabling them to perform basic inference tasks. However, this initial model may not be optimally adapted to the complex operational reality of the network, where sensors strategically choose SNR levels, participate inter- mittently according to equilibrium strategies, and generate data distributions that deviate from the original training set. Training and Aggregation Framework \nHaving established the equilibrium participation strategies and the underlying reward-based utility functions, we now consider the training process that fine-tunes the global in- ference model  Œ∏  ‚àà R d   within this EH, multi-sensor envi- ronment.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "Traditionally, data drift has been handled by cloud-based periodic re-training using continuous learning algorithms [ 20 ], [ 74 ]. However, there are challenges in resources, privacy, and sustainability to utilize existing techniques at envisioned scales. As these applications become more ubiquitous, partic- ularly in urban deployments for tasks like trafÔ¨Åc surveillance, autonomous driving, and health analytics [ 18 ], [ 77 ], [ 90 ], demands on communication bandwidth and network reliability limit the direct streaming of diverse data (e.g., video, 3D point cloud, sensor, voice) from numerous sensor-compute nodes to the cloud.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "For instance, DeepHolo [ 33 ] proposes a binary-weighted computer- generated hologram model to recognize 3D objects. From the software/algorithm perspective, a sub-hologram technique is pro- posed with a tracked viewing-window technology to tailor the holographic computation only for the necessary information in- side of the window [ 52 ]. More recent efforts have attempted to combine holographic processing with neural network techniques.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "[43] Yuan Feng, Junlin Lv, Yukun Cao, Xike Xie, and S. Kevin Zhou. Ada-kv: Optimizing kv cache eviction by adaptive budget allocation for efficient llm inference, 2024. [44] Financial Times.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "This table, which we call the  conÔ¨Ådence matrix , gives us the conÔ¨Ådence of each sensor for each class, and can be used as a weight for majority voting. The next challenge is to adapt the conÔ¨Ådence matrix for individual users. Each user has unique expressions of behaviour classes reÔ¨Çected in the sensor data.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "4: Main idea in our partial inference scheme. To explain the high-level idea behind PI, we reconsider Frame-3 in Scenario-1 discussed in Sec. whether one frame should process the PI, and if so, reuse the cached computation results for ‚Äúunimportant‚Äù regions and only do computation for the ‚Äúregions of interest‚Äù (bounding boxes and MVs), to save computations without much accuracy loss.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "III-A , PCC takes several seconds to execute, which is signiÔ¨Åcantly higher than the ideal/real- time demand ( 100 ms ). The main reason for this inefÔ¨Åciency is the ‚Äúsequential updates‚Äù in the state-of-the-art octree- based algorithms [ 47 ] (illustrated in Fig. 2 ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "1b. On-board Battery:  It is to be noted that all of the sensors and the processing engines mentioned above are  battery-backed , as shown in Fig. This is for enabling users to freely move around in a large area without the need of connecting with a power cable constantly.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "2012. Creating and benchmarking a new dataset for physical activity monitoring.",
    "source": "Seeker.pdf",
    "type": "sliding_window_partial",
    "tokens": 16,
    "augmented": true
  },
  {
    "text": "[151] Sainbayar Sukhbaatar, Olga Golovneva, Vasu Sharma, Hu Xu, Xi Victoria Lin, Baptiste Rozi√®re, Jacob Kahn, Daniel Li, Wen tau Yih, Jason Weston, and Xian Li. Branch-train-mix: Mixing expert llms into a mixture-of-experts llm. arXiv preprint arXiv:2403.07816 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": ", m n ]  where  m i  ‚àà{ 0 ,  1 } . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Feature Map Reconstruction Error Dropout and QuantaTask Optimization: Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ≥ .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "75 √ó  by reusing the matched blocks in reference frame. To the best of our knowledge, this is the Ô¨Årst work that targets to push the PCC to the edge by taking edge device- speciÔ¨Åc constraints into account and targeting four critical metrics ‚Äì latency, energy, quality, and compression ratio. The major  contributions  of this work are the following: ‚Ä¢  We identify the spatio-temporal redundancies for optimiz- \n1 In this paper, we use ‚Äúlocality‚Äù and ‚Äúframe similarity‚Äù alternatively.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "While the margins may appear small, in industrial settings, even minor improvements in classification accuracy can have significant implications for predictive maintenance and operational efficiency. The improved performance of NExUME in this real-world application further validates its effectiveness and practical utility. By effectively managing energy constraints and adapting to intermittent power conditions, NExUME enables more reliable and accurate monitoring in industrial environments where energy harvesting is a viable power solution.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "The other line of re- search [131,151] implemented experts as individual language models, yet the experts are selected to work individually and they cannot be composed dynamically to complete complex tasks. Our approach will pro- vide a unified view of these functions and analyze a diverse combination of routing, composition, and ex- pert functions to improve the robustness and efficiency. We unify these three types of functions in two steps.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 50th Annual International Symposium on Com- puter Architecture , ISCA ‚Äô23, New York, NY, USA, 2023. [77] Mahmut Kandemir, Taylan Yemliha, SaiPrashanth Muralidhara, Shekhar Srikantaiah, Mary Jane Ir- win, and Yuanrui Zhnag. Association for Computing Machinery.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "[112] Sai Prashanth Muralidhara, Lavanya Subramanian, Onur Mutlu, Mahmut Kandemir, and Thomas Moscibroda. arXiv preprint arXiv:2306.03745 , 2023. Soft merging of experts with adaptive routing.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Each request is derived from a pool of pre-trained ML inference models for image classification (as explained in Section  2 ). Evaluation:  We evaluate our results by comparing the cost, latency and accuracy for two different workloads. We use  Apache MXNet  and  TensorFlow  frame- work to deploy and run inference on the models.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Since  U i ( t ) =  R i ( t )  ‚àí C i ( t ) , we have: \nŒ¶( a ( t )) = \nN X \ni =1 [ R i ( t )  ‚àí C i ( t )] . The terms  R i ( t )  depend on the chosen actions and correct- ness of inferences. Due to bounded  Œ≥, Œ¥,  and  Œ∑ , and the fact that  ‚àÜ A i ( t )  and energy costs are bounded, each  U i ( t ) is finite.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "This point-by-point ‚Äúupdate‚Äù makes this stage difÔ¨Åcult to parallelize. ‚Ä¢  Octree Serialization:  After the octree has been constructed, the tree is traversed in a top-to-bottom manner, in order to extract the  occupy  bits for each node, and record them in a predeÔ¨Åned order (e.g., via depth-Ô¨Årst traversal), such that the decoder can recover the octree with these occupy bits as well as the serialization order. Note that this step is also time-consuming, as shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "Since the regularizers are deterministic, their gradients ‚àá ‚Ñ¶ SNR ( Œ∏ )  and  ‚àá ‚Ñ¶ complexity ( Œ∏ )  do not introduce bias. Integration of Regularizers in Backpropagation and SGD \nDuring the training iteration  k : \n1. Forward pass:  Each participating sensor collects data ( x, y )  and evaluates  ‚Ñì ( f Œ∏ k ( x ) , y ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "The full training objective is formulated as: \nJ ( Œ∏ ) =  L ( Œ∏ ) +  Œª 1 ‚Ñ¶ SNR ( Œ∏ ) +  Œª 2 ‚Ñ¶ complexity ( Œ∏ ) , \nwhere L ( Œ∏ ) =  E ( x,y ) ‚àºD [ ‚Ñì ( f Œ∏ ( x ) , y )] , \nand  Œª 1 , Œª 2  ‚â• 0  are hyperparameters that balance accuracy, robustness, and efficiency. Gradient Computation and Backpropagation: Integrat- ing regularizers into the training process is straightforward due to their known closed-form gradients. During back- propagation, each sensor computes the gradient of the loss function  ‚àá ‚Ñì ( f Œ∏ ( x ) , y )  with respect to  Œ∏  based on locally available samples from  D .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 205,
    "augmented": false
  },
  {
    "text": "Targeting the compute-intensive holographic processing dis- cussed above,  foveated rendering  techniques have been previously proposed to approximate selective regions (i.e.,  peripheral vision ). In fact, prior research on HVS has shown that human eyes are able to observe beyond 135 ¬∞  vertically and 160 ¬∞  horizontally, but see fine details within an only around 5 ¬∞  central circle (i.e.,  foveal vision ). 2.2.2 What are the Prior Optimization Efforts?",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "ITU-T Recommendation H.265. Myoungsoo Jung. Hello bytes, bye blocks: Pcie storage meets compute express link for memory expansion (cxl-ssd).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "A similar trend is observed in other datasets. While \n15 \nSalient Store  is consistently performing better than H264, HEVC thanks to it‚Äôs novel approach of fine grained computation at times outperforms our approach. With complex and high dimensional video data, HEVC computation complexity increases exponentially, and is more pronounced because of lack of hardware support.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Copyrights for components of this work owned by others than ACM must be honored.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "4  even with DVFS, commercial off the shelf GPUs could only Ô¨Ånish  <  50% of the scheduled training task. T4, thanks to its limited compute capabilities, could not Ô¨Ånish training tasks on time. However, hardware is not the only limitation, as even with custom hardware [ 16 ] enabled with the state-of-the-art continuous learning algorithm [ 12 ] could only Ô¨Ånish  ‚âà 75% \n2 NVIDIA provides the list of supported clocks through the API ‚Äú nvidia--smi --q --d SUPPORTED_CLOCKS ‚Äù; We did not creport the results from A100 for this, as it does not offer multiple memory clocks, signiÔ¨Åcantly impacting its DVFS capabilities.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "Alternate Solutions:  Although  Us. ¬¥as  works completely using intermittent power, it is imperative to compare and contrast it with other possible solutions. TABLE  III  depicts some of such possible comparison points.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "[20] D Maltoni, V Lomonaco, ‚ÄúContinuous learning in single-incremental- \ntask scenarios,‚Äù in  Neural Networks , 2019. [21] J. Dodge, T. Prewitt, R. Tachet des Combes, E. Odmark, R. Schwartz, \nE. Strubell, A. S. Luccioni, N. A. Smith, N. DeCario, and W. Buchanan, ‚ÄúMeasuring the carbon intensity of ai in cloud instances,‚Äù in  2022 ACM Conference on Fairness, Accountability, and Transparency , 2022, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "LLaMA-3.1 405B: Pre-trained Language Model. Hugging Face Model Repository, 2023. Available at:  https://huggingface.co/meta-llama/Llama-3.1-405B .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "[52]  Stephan Reichelt, Ralf Haussler, Norbert Leister, Gerald Futterer, Hagen Stolle, and Armin Schwerdtner. 2010. Holographic 3-D Displays - Electro-holography Within the Grasp of Commercialization .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "To model the characteristics of the original functions, we invoke sleep timers within our functions to emulate their execution times (including the time for state recovery, if any). We implement each ap- plication as a workflow of chained functions in  OpenFaaS . Transitions between functions are done using function calls on the basis of pre-assigned inter-function transition proba- bilities.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Observation 3:  Only-VM based resource procurement should not be used during dynamic load as it leads to over-provisioned resources and increased cost. 2.4 Using  serverless functions  with VMs \nThe provisioning latency is a major contributor for VM over-provisioning during request surges be- cause the increased time to provision new VMs results in the increase of response latencies which in-turn leads to provisioning more VMs in advance. 0 \n500 \n1000 \n1500 \nwiki WITS berkley Twitter \nRequest Rate \nAvg Req \nMax Req \nFigure 6.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Salient Store  provides adaptive data compression using neural codecs and further enhances the data security by providing an accelerated quantum safe data encryption policy, protecting these vulnerable edge storage servers against the store now decrypt later (National Cybersecurity Center of Excellence (NCCoE), 2023) attacks. To cater towards this, in this work, we propose  Salient Store  ‚Äì a mini computational storage server (we call it ‚Äúedge storage server‚Äù) stack for managing the data archival in edge servers. 3 Data Compression using Neural Codec \nIn this section we go over the overall design and design choices for the neural codec design of Salient Store  .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "1 Anonymous Institution, Anonymous City, Anonymous Region, Anonymous Country. Correspondence to: Anonymous Author < anon.email@domain.com > . Preliminary work.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "https://docs.aws.amazon.com/step- functions/latest/dg/concepts-amazon-states-language.html. [5]  2020. AWS Lambda.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "1% \n0 20 40 60 80 100 All Succeed Atleast one succeed Failed \n9% 90% \n(a)  Inference completion breakdown when three EH sensors are working together to Ô¨Ånish the incoming inferences. In only 1% of the cases all of the sensors Ô¨Ånished inference, while 9% of the time at least one of them Ô¨Ånished. 90% of the time the inference could not start because of lack of energy.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "The underlying reason is that the smooth  Transition keep   strategy can already handle the smooth transitions with no need of power prediction support for this workload. F. Sensitivity study on duplication copy \nWe vary the ReRAM duplication granularity  G  for each layer and evaluate with  TV-RF  source. Throughput results are plotted in Figure 12 and area costs for  G 1  ‚àº G 5  can be found in Figure 13.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "5 dB (only  6 . 5 dB drop compared to TMC13). Clearly, the geometry data has been compressed very well, as opposed to the attribute data.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "[16] T. HARDWARE, ‚ÄúMagic Leap One Powered by Nvidia Tegra TX2, Available Summer.‚Äù ‚Äùhttps://support.oculus.com/248749509016567/‚Äù, 2019. [17] B. Haynes, A. Mazumdar, A. Alaghi, M. Balazinska, L. Ceze, and A. Cheung, ‚ÄúLightDB: A DBMS for Virtual Reality Video,‚Äù  Proc. VLDB Endow.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Thus, improving the computational efÔ¨Åciency of the video processing pipeline in a VR is critical. Abstract ‚ÄîThe emergence of virtual reality (VR) and aug- mented reality (AR) has revolutionized our lives by enabling a  360 ¬∞  artiÔ¨Åcial sensory stimulation across diverse domains, including, but not limited to, sports, media, healthcare, and gaming. Unlike the conventional planar video processing, where memory access is the main bottleneck, in  360 ¬∞  VR videos the compute is the primary bottleneck and contributes to more than 50%  energy consumption in battery-operated VR headsets.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "1c. With these inputs,  ‚ù∑ Perception  stage understands the current surrounding environment such as pose estimation for head rotations/directions, eye tracking for pupil centers, and scene reconstruction for the current view analysis. At a high level, this AR pipeline has three major stages:  ‚ù∂ Inputs  stage first collects the real-time information from all the on-board sensors such as IMU, IR, camera and depth image sensors.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Towards this, in the future, we plan to explore GPU-speciÔ¨Åc \n295 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "These ML models are typically trained and hosted on cloud platforms as service end- points, also known as  model-serving  framework [ 6 ,  28 ,  60 ]. From the myriad of ML Ô¨Çavours, Deep Neural Networks \n(DNNs) [ 54 ] due to their multi-faceted nature, and highly gen- eralized and accurate learning patterns [ 45 , 73 ] are dominating the landscape by making these model-serving frameworks accessible to developers. However, their high variance due to the Ô¨Çuctuations in training data along with compute and mem- ory intensiveness [ 59 , 65 , 84 ] has been a major impediment in designing models with high accuracy and low latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "Moreover, H265 is an extension of H264 with additional features like coding tree units and intra-prediction directions which demand significantly more computation. These devices, by integrating CPUs or FPGAs into the storage \n4 We do  not  consider H265 here as currently in commercial systems H264 is the standard and typically enjoys hardware support. 5 \nmedium, facilitate computation at the storage level.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Furthermore, it can measure the peak-to-median ratio in sampling windows, which can be used to decide if  serverless functions  are re- quired to balance the load. 3.2.3 Provisioning Time vs Execution Time  We know that new VMs take a few hundred seconds to start-up. However, during flash-crowds, where load-prediction fails to accurately estimate the load, \nserverless functions  can inherently be used to handle requests to meet the response latency, but by incurring higher costs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "We pro- Ô¨Åle the spot price of 4 types of  C5  EC2 VMs over a 2-week period in August 2020. When compared to the OD price , they were up to 70% cheaper. It was seen that, the spot instance prices have predictable Ô¨Çuctuations.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Yang, A. Howard, B. Chen, X. Zhang, A. Go, M. Sandler, V. Sze, and H. Adam, ‚ÄúNetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications,‚Äù in  Proceedings of the European Conference on Computer Vision , 2018, pp. 289‚Äì304.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "NExUME focuses on enabling efficient and reliable deployment of DNNs in intermittent environments, which are often constrained in terms of com- putational resources and energy availability. In many real-world applications, especially in IoT and edge computing, there is a critical need for smaller, energy-efficient models that can operate autonomously without reliance on batteries. computational and memory requirements.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "8 ms . Furthermore, estimating the user‚Äôs eye gaze,  Eye Track , requires the execution of a light-weight neural network that takes 4 . 4 ms  and achieves 2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "However, these approaches often assume some level of reliability or do not fully integrate energy harvesting dynamics into the learning process. 2.5. Multi-View Learning and Collaborative Inference \nMulti-view learning leverages multiple sources or perspec- tives to improve learning performance ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Scharw√§chter, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset. In  CVPR Workshop on the Future of Datasets in Vision , volume 2. sn, 2015.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "To explore these opportunities, Fig. For example, for the mobile video inference application considered in this paper, the input data \nare continuous video frames, and can potentially contain rich ‚Äúsimilarity‚Äù across different frames. II, most existing optimizations focus on accelerating the inference processing/computation only and not fully understand the underlying characteristics of the input data, and thus some input-speciÔ¨Åc optimization opportunities could be easily missed.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. [2] W. Niu, X. Ma, S. Lin, S. Wang, X. Qian, X. Lin, Y. Wang, and B. Ren, ‚ÄúPatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-Based Weight Pruning,‚Äù in  Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , 2020, p. 907‚Äì922.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "347‚Äì353. [15] K. Han, A. W. Min, N. S. Jeganathan, and P. S. Diefenbaugh, ‚ÄúA Hybrid Display Frame Buffer Architecture for Energy EfÔ¨Åcient Display Subsystems,‚Äù in  International Symposium on Low Power Electronics and Design (ISLPED) , 2013, pp. [16] T. HARDWARE, ‚ÄúMagic Leap One Powered by Nvidia Tegra TX2, Available Summer.‚Äù ‚Äùhttps://support.oculus.com/248749509016567/‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Our characterization indicates that, on average, around 2.3 GFLOPS is required for this projection transformation (details are discussed in Sec. Furthermore, in a typical VR headset, the above computation needs to repeat millions of times, for processing just one  360 ¬∞ frame. Note that, this projection process is quite compute-intensive.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Therefore, simpler paradigms, like random forests, still remain popular for embedded sensors [7]. However, reliably meeting real-time analyt- ics demands entirely within the limited compute and power budgets of these sensor nodes is challenging, especially for complex computational models such as DNNs. Index Terms ‚Äîedge computing, random forest, edge-cloud par- titioning, sensor network \nI. I NTRODUCTION R Etrofitting intelligent sensors nodes on legacy manufac- turing systems provides cost-effective smart manufac- turing upgrades.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Provisioned Concurrency. https://docs.aws.amazon.com/ lambda/latest/dg/configuration-concurrency.html. [4]  2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "In  2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) , pages 1‚Äì10, 2024. [41] Chris Fallin, Chris Craik, and Onur Mutlu. Chipper: A low-complexity bufferless deflection router.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Existing methods may not account for the energy constraints and participation vari- ability inherent in EH-WSNs. 3. System Model \nWe consider a network of  N EH sensors  S = { s 1 , s 2 , .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "103‚Äì118, 2022a. Swift: Adaptive video streaming with layered neural codecs. In  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Maybe Not:  While storing video data as files works for small systems, in very large-scale systems they are typically stored using vector databases (Shen et al., 2005; Pan et al., 2024). Vector databases typically extract features from the video data to form index and those indices are then sorted using various metrics like neighborhood, maximum similarity, etc. Using State-of-the-Art Video Data Storage?",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "On the other hand, the  shoe  video frames typically contain more objects (2 . Thus, chances for ap- proximating the objects outside the RoF (in  Inter-Holo ) and the objects which are relatively far-away from the user (in  Intra-Holo ) \nare limited. 1 on average), and also the ranges/sizes of the bikes are larger, compared to others.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Optimizing cpu performance for recommendation systems at-scale. In  Proceedings of the 50th Annual International Symposium on Computer Architecture , pages 1‚Äì15, 2023. [72] Natalie Enright Jerger, Ajaykumar Kannan, Zimo Li, and Gabriel H Loh.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "It is also equally important to note the impact of LLMs on the environment. A critical but often overlooked aspect of these compute-intensive operations are usage of water in cooling mechanisms in the data centers. An LLM like PaLM- 540B to be trained in a data center facility operated on 89% carbon-free energy still produces 271.43 tCO2e, which is compared to be similar to emissions of a direct round trip of a single passenger jet between San Francisco and NYC [27].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Algorithmic Advancements:  Us. ¬¥as  extends the frontier of rep- resentation learning for continuous learning by implementing it at a large scale and addressing related challenges. Prior works relied on supervised learning or K-means clustering, un- suitable for  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Given the limitations of the EH budget, such approaches typically end up dropping many samples and not inferring from them locally. Importantly, they are of- ten incapable of transmitting the raw data due to a lack of sufficient energy; for sensing tasks with modest inference requirements, performing inference and transmitting the result can take  less  energy than transmitting raw data. How- ever, to unleash the remote deployment, and sustainable, yet pervasive, computing capabilities WSNs, development of ef- ficient  energy harvesting WSNs  (EH-WSNs), both for sensing and edge-analytics, plays an essential role.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "This is further exacerbated in the case of dynamic DAGs, where the function chain for an application is not known a pri- ori. Motivated by these observations, we propose  Kraken , a workflow-aware resource management framework that minimizes the number of containers provisioned for an ap- plication DAG while ensuring SLO-compliance. We design and implement  Kraken  on  OpenFaaS  and evaluate it on a multi-node  Kubernetes -managed cluster.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "CoRR , abs/1812.01776, 2018. [26]  Daniel Crankshaw, Gur-Eyal Sela, Corey Zumar, Xiangxi Mo, Joseph E. Gonzalez, Ion Stoica, and Alexey Tumanov. Inferline: ML inference pipeline composition framework.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Proceedings of the ACM on Programming Languages , 2(4):1‚Äì25, 2018. Tvm: An automated end-to-end optimizing com- piler for deep learning. [25] Tianqi Chen, Benjamin Moreau, Chunting Zheng, Yutian Tang, Zijian Yan, Yanan Song, Yuhao Jia, Maximilian Seeger, Lingfeng Wang, and Hai Bian.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "IEEE Micro , 40(2):17‚Äì24, 2020. [104] Meta. Building meta‚Äôs genai infrastructure, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "As shown in Fig. Ekya [ 12 ] using ResNeXt101) to annotate the data or used a heuristic on top of the teacher model (e.g. intermittent learning [ 47 ] using randomized selection, K‚ÄìLast List, or round-robin policy).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Groq rocks neural networks. Microprocessor Report, Tech. Rep., jan , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. [ 50 ], [ 73 ] at a much lower rate, necessitates informed decisions regarding deployment placement and sampling rates.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "Wordcraft: story writing with large language models. arXiv preprint arXiv:2403.16303 , 2024. [177] Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Hence, properly exploiting these concepts together in an ‚Äúintegrated‚Äù fashion for better optimizing neural inferencing is very much in its infancy that this paper proposes to address. However, the granularity of similarity explored in these prior works is  static , and either too coarse (e.g., skips the entire frame [9]) or too strict (e.g., still needs to compute despite very few changes). SpeciÔ¨Åcally, we present a systematic study of integrating the  temporal correlations  and  region-based inference  in a  uniÔ¨Åed  approach and try answering the following critical questions:  (i) what \nis the scope to explore both the pixel- and computational- similarities, i.e., frame-level, region-level or pixel-level?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "An anchor-point selection algorithm (running in cloud) is also proposed to decide whether to reuse the previous results or not in [30]. For example, a dynamic RoI encoding is proposed to compress the data volume to be transferred through net- work [17]. Both require the assistance of the cloud, and hence, introduce additional costs and privacy issues.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "The Twitter trace has a large variation in peaks (average = 3332 rps, peak= 6978 rps) when compared to the Wiki trace (average = 284 rps, peak = 331 rps). Applications:  Each request is modeled after a query to one of the three applications (DDAs) we consider from the ùê∑ùëíùëéùë°‚ÑéùëÜùë°ùëéùëü benchmark suite [ 29 ]. We implement each ap- plication as a workflow of chained functions in  OpenFaaS .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisÔ¨Åxedas Lat comp = T comp ,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1. E comp =E comp tile /Lat comp \n=(E DAC   +E MAC   +E ADC )/T comp (1) \nThepowerofeachpartistakentobelineartothetiling factorsofm ornortheactualparallelismgranularityaG. TheenergyforoneReRAMrow(e DAC ),oneReRAMcell (e MAC  )andoneReRAMcolumn(e BL ,e SA‚àíRef ,e S+A )are theworst-casevaluesfromthesimulation.Table V-B 2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 233,
    "augmented": true
  },
  {
    "text": "4. Update step:  With a chosen step size  Œ± k , \nŒ∏ k +1  =  Œ∏ k  ‚àí Œ± k   b ‚àá J ( Œ∏ k ) . Diminishing Step-Size and Convergence Results \nClassical convex optimization theory (see Bottou et al.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "HotMobile ‚Äô16, 2016, pp. 57‚Äì 62. [35] mooovr, ‚ÄúRollerCoaster at Seoul Grand Park.‚Äù ‚Äùhttps://www.youtube.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "7 CONCLUSION The extremely heavy computation in hologram processing hinders the growth of the 3D display applications on AR headsets. Thus, prior efforts have proposed using accelerators or cloud for optimiz- ing the hologram computation. In contrast, this paper attempts to exploit available approximation opportunities unique in AR holo- graphic applications, and proposes a two-stage  HoloAR  scheme to speed up the execution and save energy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "The students will work on separate thrusts in the beginning (one student will be the primary contact for each thrust), but they will works together in the last year for integrating the different compo- nents of the research for a comprehensive evaluation and refinements of the proposed models, algorithms, compiler and system support. In addition, we will also include undergraduates from the Schreyer Honors College at Penn State, and specifically draw undergraduate students from underrepresented groups, who are interested in pursuing graduate studies. We will seek REU supplements to support the undergraduate students for working on this project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "678‚Äì683. [4] ‚ÄúGoogle assistant for wearables,‚Äù 2020, https://assistant.google.com/platforms/wearables/. [5] K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúSpendthrift: Machine learning based resource and fre- quency scaling for ambient energy harvesting nonvolatile processors,‚Äù in 2017 (ASP-DAC) , 2017, pp.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": ", m n ]  where  m i  ‚àà{ 0 ,  1 } . Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with L2 Dynamic Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ± . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "Motion Estimation: Utilize dedicated hardware blocks for calculating motion vectors between consecutive frames. 1:  Input:  Set of training video sequences  V 2:  Initialize:  MobileNet  M ‚ñ∑ Weights frozen 3:  Initialize:  Autoencoder  A ‚ñ∑ Trainable 4:  Initialize:  Motion Vector Extractor  V 5:  procedure  E XTRACT M OTION V ECTORS ( frame current , frame previous ) 6: motion _ vectors  ‚Üê V  ( frame current , frame previous ) 7: return  motion _ vectors 8:  end procedure 9:  procedure  F ORWARD P ASS ( video ) 10: previous _ features  ‚Üê null 11: previous _ compressed  ‚Üê null 12: for  each frame  frame  in  video  do 13: features  ‚Üê M ( frame ) ‚ñ∑ Extract features using frozen MobileNet 14: compressed  ‚Üê A.encode ( features ) ‚ñ∑ Compress features 15: if  previous _ compressed  Ã∏ =  null  then 16: motion _ vectors  ‚Üê E XTRACT M OTION V ECTORS ( frame, previous _ frame ) 17: stacked _ input  ‚Üê concatenate ( compressed, previous _ compressed, motion _ vectors ) 18: compressed  ‚Üê A.reencode ( stacked _ input ) ‚ñ∑ Stacked compression 19: end if 20: reconstructed  ‚Üê A.decode ( compressed ) ‚ñ∑ Decompress to reconstruct 21: Calculate reconstruction loss between  frame  and  reconstructed 22: previous _ frame  ‚Üê frame 23: previous _ compressed  ‚Üê compressed 24: previous _ features  ‚Üê features 25: end for 26: Backpropagate loss and update weights of  A  only 27:  end procedure 28:  while  not converged  do 29: for  each  video  in  V  do  F ORWARD P ASS ( video ) 30: end for 31:  end while \nThe implementation of layered codecs involve the following components. 1.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 436,
    "augmented": true
  },
  {
    "text": "Restrictions apply. The scaling up via mil- \n893 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Hence, the over- all cost incurred by  mixed  procurement can be higher or lower than VM-only autoscaling policies. We argue that compared to VMs there is more variability in configurations for  serverless functions  because the resources are billed at a more fine-grained 2   allocation of CPU and memory. Prior work  like Cherrypick [ 1 ] solves the resource se- lection and configuration problems from VM perspective but does not consider Serverless Functions.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Glam: Efficient scaling of language models with mixture-of-experts. In  International Conference on Machine Learning , pages 5547‚Äì5569. PMLR, 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "[61]  Nikunj C Oza. arXiv preprint arXiv:1712.06139 , 2017. TensorÔ¨Çow-serving: Flexible, high-performance ml serving.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "For  N  models, where each model has a minimum accuracy ‚Äò a ‚Äô, we model the ensemble as a coin-toss problem, where  N  biased coins (with probability of head being  a ) are tossed together, and we need to Ô¨Ånd the probability of major- ity of them being heads. For this, we need at least  ‚åä N \n2   ‚åã +  1 models to give the same results. The probability of correct prediction is given by \nN ‚àë i = ‚åä N \n2   ‚åã + 1 \n\u0012 N i \n\u0013 a i   ( 1 ‚àí a ) ( N ‚àí i ) \nModel Selection Algorithm:  To minimize  ¬µ C , we design a policy to downscale the number of models, if more than N/2+1 models vote for the same classiÔ¨Åcation result.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 178,
    "augmented": false
  },
  {
    "text": "Searching for mobilenetv3. In  Proceedings of the IEEE International Conference on Computer Vision , pages 1314‚Äì1324, 2019. [46]  Patrick Hunt, Mahadev Konar, Flavio Paiva Junqueira, and Benjamin Reed.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Note that, even with DVFS, most scheduled compute could not be Ô¨Ånished. This includes the intermittent failures ( ‚â§ 20W where no compute could be done); we included check- pointing to ensure that progress is saved in power-failures. C/S is the ratio of  C ompleted over the  S cheduled training tasks over multiple time windows of 4hours.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "For example, DeltaVR [29] adaptively reuses the redundant VR pixels across multiple VR frames to improve performance. These works focus on the pixel content reuse, which is the last stage ( Projection Mapping ) in the  360 ¬∞ video projection pipeline (discussed in Sec III). Pixel Content Reuse on VRs:  Pixel value reuse has been well-studied in VRs [17], [22], [23], [29], [33], [50], [60], [66] to improve throughput and performance.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "By integrating expert affinities (Expert‚ÄìExpert, Expert‚ÄìData, Expert‚ÄìRouter, and Expert‚ÄìComposition Function) detailed in Table 2, the system will optimize responsiveness and computational efficiency. Grouping experts in close memory proximity is expected to enhance cache efficiency and reduce latency. Data locality should benefit from prefetching and caching critical data, which would lower transfer delays and potentially speed up training and inference.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "1c), including head tracking, IMU integra- tion, reprojection, and sound processing. On top of the ILLIXR codebase, we implemented three new components ‚Äì eye tracking, pose estimation, and hologram processing. IL- LIXR already contains several AR software components (some of them are shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "These simplistic approaches ignore the interdependencies among sensor decisions and fail to account for future resource allo- cation, potentially leading to suboptimal performance over time. Alternatively, reinforcement learning or Markov Decision Process-based approaches could adaptively learn partici- pation policies that consider both immediate rewards and future states. For instance, always selecting the highest-energy sen- sors can rapidly deplete their energy reserves, reducing the network‚Äôs resilience during critical future events.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Oth- erwise, the sensor prioritizes local computation and, with the help of a moving average power predictor [ 47 ], predicts whether it can finish the quantized DNN inference with the combination of stored energy and expected income (  2a  and \n2b  ). If energy is insufficient for DNN inference, the sensor will use coreset formation to communicate the important features to the host, which completes the inference. Since the clustering based coreset is typically more accurate then those formed by importance sampling, the former is pre- ferred, when possible.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "However, their high variance due to the Ô¨Çuctuations in training data along with compute and mem- ory intensiveness [ 59 , 65 , 84 ] has been a major impediment in designing models with high accuracy and low latency. Prior model-serving frameworks like InFaas [ 83 ] are conÔ¨Åned by the accuracy and latency offered by such individual models. Unlike single-model inferences, more sophisticated tech- niques like  ensemble learning  [ 15 ] have been instrumental in allowing model-serving to further improve accuracy with multiple models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "NExUME uniquely integrates energy variability awareness directly into both the training ( DynFit ) and inference ( DynInfer ) processes, enabling DNNs to dynamically adapt computations based on real-time energy availability. This involves an innovative strategy of learning instantaneous energy-aware dynamic dropout and quantization selection during training, and an intermittency-aware task scheduler during inference. The method includes targeted fine-tuning that not only regularizes the model but also pre- vents overfitting, enhancing robustness to fluctuations in resource availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "A myriad of model architectures are available to train these applications which by themselves can be deployed on appli- cation frameworks like  TensorFlow  [ 1 ],  PyTorch  [ 62 ] etc. Table  1  shows the different models available for image predic- tion, that are pretrained on Keras using  ImageNet  [ 29 ] dataset. Services like Ads and News Feed [ 39 , 44 ] would require SLOs within 100ms, while facial tag recommendation [ 83 ] can tolerate up to 1000ms.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "[132] Joan Puigcerver, Carlos Riquelme Ruiz, Basil Mustafa, and Neil Houlsby. From Sparse to Soft Mix- tures of Experts. In  The Twelfth International Conference on Learning Representations , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "4  a  and 4  b  . SpeciÔ¨Åcally, the SOTA geometry compression pipeline includes Ô¨Åve stages which can be summarized as follows: ‚Ä¢  Raw Frame (Input):  The input raw PC frame contains several (usually millions of) points, carrying both geometry and attribute information. We illustrate the generic pipelines (for  1  geometry compression, and for 2  attribute compression) employed by the state-of- the-art intra-frame compression techniques in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "F.1.1 depth-wise Separable Convolution 2D Using Conv1D \nThe pseudo code described in Algorithm 1 implements a depth-wise separable convolution 2D (DWSConv2D) using a 1D convolution primitive function (conv1D). The DWSConv2D function takes four inputs: an input matrix, depth-wise kernels (DWsKernels), point-wise kernels (PtWsKernel), and an output matrix. The depth-wise separable convolution is performed in two main steps: depth-wise convolution and point-wise convolution.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Virtual, Augmented and Mixed Reality: Designing and Developing Augmented and Virtual Environments: 6th International Conference, VAMR 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014, Proceedings, Part I . Vol. 8525.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "1423‚Äì1428, 2018. [25]  A. K. Mishra and D. Marr, ‚ÄúWRPN & apprentice: Methods for training and inference using low-precision numerics,‚Äù  CoRR , vol. abs/1803.00227, Apr 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "; iii)  How can we continually adapt experts through expert merging, splitting, growing, and shrinking? ; ii)  How can we dynamically shape the morphology of EoE systems by identifying the best design points in the search space? ; and iv)  How do compute and memory resource constraints and runtime environments influence our algorithmic decisions?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "2   To un- derstand the impact of DVFS on energy savings and dynamic compute scaling, we implemented a simple multi-arm bandit algorithm to select the right bucket of compute frequencies (SM frequency for NVIDIA GPUs), and memory frequencies to match the power-demands of the intermittent solar source. However, these GPUs are often equipped with dynamic voltage and frequency scaling (DVFS). However, as mentioned in ¬ß I , the commercial GPUs used for DNN training are typically power hungry ( typically in 100s of Watts TDP; We exprimented with multiple GPUs, server class A6000: 300W TDP, server class A100: 250W ‚Äì 400W TDP, client class TRX3090: 350W TDP, and client class T4: 70W TDP), and are  not  equipped to handle intermittent power emergencies.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 185,
    "augmented": true
  },
  {
    "text": "C ONTINUOUS  L EARNING \nThe Ô¨Årst step to any data-driven learning algorithm is data collection and annotation. Since  Us. ¬¥as  is a continuous learning framework and learns from the live data that the camera(s) capture, data collection is simply storing the live video feed.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "2020. \"https://www.gazept.com/\". Eye Tracking and Neuromarketing Research Made Easy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "To gather input data, we plan to utilize publicly available datasets such as Wikipedia [164], Common Crawl [29], BookCorpus [199] and OpenWebText [49], along with our proprietary repositories. After necessary post-processing, these data points will be employed to train, validate, and evaluate our expert models. The insights gained from these simulations and modeling efforts will be instrumental in refining run- time performance and providing informed estimates regarding the system and hardware demands of emerging applications.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "[107] S. Zhao, H. Zhang, S. Bhuyan, C. S. Mishra, Z. Ying, M. T. Kandemir, \nA. Sivasubramaniam, and C. R. Das, ‚ÄúD¬¥eja view: Spatio-temporal compute reuse for ‚Äòenergy-efÔ¨Åcient 360 vr video streaming,‚Äù in  2020 ACM/IEEE 47th Annual International Symposium on Computer Archi- tecture (ISCA) . IEEE, 2020, pp. 241‚Äì253.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "Seeker  (RF) \nAll compute at edge Partial compute at edge \nDesign space of  ‚ÄúSeeker‚Äù \n(b) Current state-of-the-art of EH-WSN. Figure 1: A primer on energy harvesting systems: Fig- ure 1a shows the basic building blocks of an EH node equipped with sensing and computation. Some of the units change according to the harvested energy source.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. baseline InterHolo IntraHolo InterIntraHolo \nEnergy (J) \nHoloCompute Overhead \n3.68 \n1.40 1.28 \n(c) Energy consumption (J).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "(a) HoloAR overview. (b) The  Inter-Holo  and  Intra-Holo . Figure 6: The proposed  HoloAR  which includes  Inter-Holo leveraging foveated rendering, and  Intr-Holo  further ap- proximating holograms for far objects.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Table  1  provides the  P f  for 11 different models when executed on a  C5.xlarge  instance. There is a linear relationship between  P f  and the instance size. It can be seen that smaller models  (MNet, NASMob ) can be packed 2-5 √ó  more when compared to larger models  (IRV2, NASLarge) .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "[6]  2020. https://aws.amazon.com/ lambda/. Azure Durable Functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "However, one power cycle of the other power sources can usually process thousands or hundreds of inferences. TABLE V T HE RATIO OF ADDITIONAL INFERENCES ENABLED BY THE SMOOTH TRANSITION STRATEGY VS . TOTAL INFERENCES \nPiezo WiFi-h WiFi-o Thermal TV-RF \nLeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 \nE. Power predictor \nWith an accurate power predictor [ 45 ], [ 36 ], we can make more smooth transitions among different power levels.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 199,
    "augmented": false
  },
  {
    "text": "Roberto Pierdicca, Michele Sasso, Flavio Tonetto, Francesca Bonelli, Andrea Felicetti, and Marina Paolanti. Immersive insights: virtual tour analytics system for understanding visitor behavior. In Augmented Reality, Virtual Reality, and Computer Graphics: 8th International Conference, AVR 2021, Virtual Event, September 7‚Äì10, 2021, Proceedings 8 , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "2861‚Äì2865, 2017. [31]  G. Venkatesh, E. Nurvitadhi, and D. Marr, ‚ÄúAccelerating deep con- volutional networks using low-precision and sparsity,‚Äù in  2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp. [32]  I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, ‚ÄúQuantized neural networks: Training neural networks with low precision weights and activations,‚Äù  J. Mach.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "We compare against a baseline using na¬®ƒ±ve continuous learning algorithm with no representation learning. In contrast,  Us. ¬¥as uses a 2 level exemplar selection algorithm (one using the conÔ¨Ådence matrix, and then further reÔ¨Åned by the representa- tion learning).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "It offers over 1000 servers with over 40,000 processing cores, over 300 NVIDIA GPUs, 5 Petabytes (PB) of disk parallel file storage and 10 PB of archive storage, high- speed Ethernet and Infiniband interconnects, and a large software stack. The PIs also have access to NSF CloudBank, ACCESS and various NERSC resources. Other Resources:  Penn State Institute for Computational and Data Sciences (ICDS), of which Mahmut Kandemir is an associate director, provides a variety of compute, storage and network resources, various IT services, including operations, backup, technical consulting, and training material, and is compliant with specific NSF, NIH, and NIST security controls.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "¬¥as , the teacher models perform majority voting to decide the right exemplar, which signiÔ¨Åcantly reduces false positives and true negatives (refer to the top bar in Fig. 9 : with the ensemble, the best case annotation is the ideal one with only 2 false positives). Furthermore, the feature extraction for each of the potential \nexemplars for the teacher model is hardware-assisted (¬ß V-C ), and hence poses no overhead to the inference task.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "[15] T. Yang, Y. Chen, and V. Sze, ‚ÄúDesigning energy-efÔ¨Åcient convolutional neural networks using energy-aware pruning,‚Äù in  CVPR . [16] A. Reiss and D. Stricker, ‚ÄúIntroducing a new benchmarked dataset for activity monitoring,‚Äù in  ISWC . IEEE, 2017.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "In addition, Cocktail  reduces cost by 1.35 √ó  and 1.27 √ó  compared to Clipper  and  Clipper-X  policies, owing to its dynamic model selection policy, which minimizes the resource footprint of ensembling. It can be seen that,  Cocktail  is up to 1.45 √ó  more cost effective than  InFaas  for  Strict  workload. On the other hand,  Clipper  uses all models in ensemble and the  Clipper-X  policy does not right size the models as aggressively as  Clipper , hence they are more expensive.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "509‚Äì531, 2024. Yann Collet and Murray Kucherawy. Zstandard compression and the application/zstd media type.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "https://bit.ly/3PXwecP . NVIDIA Corporation. (Accessed on 11/13/2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "Reasons for InefÔ¨Åciency \nTo better understand the performance of the PCC pipeline, we characterize the ‚Äúlatency breakdown‚Äù of two state-of- the-art G-PCC techniques, i.e., PCL [ 72 ] and TMC13 [ 56 ], on a typical edge SoC platform (NVIDIA AGX Xavier) in Figs. III. M OTIVATION \nA.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Next, we iterate each MV block for Scenario-1, Scenario-2 and Scenario-3 (shown from Line  22  to Line  31 ). More speciÔ¨Åcally, if the MV block is relatively large, then we examine whether the object is moving in the current frame or has been missed by the previous frame (in Line  27-28 ). If that is the case, then full inference needs to be invoked.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "TABLE IV: Comparison against Potluck and MCDNN \nmAP Latency Energy MCDNN 36.9% 33% 35% Potluck 51.6% 63% 61% This Work 50.3% 35% 34% in Fig. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Towards this, we plan to experiment with various latency reducing/hiding techniques such as caching and prefetching by intelligently using experts based on their frequency of in- vocation. Task-2.3: Using Hot and Cold Experts: Caching and Prefetching Clearly, the optimized management of the system memory/storage hierarchy in LLM inference is of crit- ical importance [131, 146]. We intend to co-locate the expert and routers physically in the system during both training and inference time to leverage this affinity and reduce expensive data movement cost.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "The Problem Space:  To address the multi-faceted challenges of sustainable, scalable and privacy-preserving continuous learning at edge servers, several crucial problem spaces must be explored. Finally, although recent studies have suggested co-locating training and inference [ 12 ] to tackle privacy concerns without signiÔ¨Åcantly affecting the inference service, the power demand associated with equipping multiple commercial edge servers [ 7 ], [ 8 ] for both tasks hinders sustainable scaling. As a result, ‚Äúon-premise‚Äù edge servers  [ 7 ], [ 8 ] have become prime choices for local inference and prediction [ 6 ], [ 39 ], [ 85 ], [ 86 ], necessitating the handling of both learning and inference tasks to meet application needs, including privacy preservation, reduced data communication, and disaggregated computing.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "This is mainly because TMC13 performs lossless geometry compression and almost-lossless attribute com- pression in our settings. Note however that, this comes at the cost of longer processing latency, as shown in Fig. Additionally, the transform and quantization in TMC13 can output (near-)zero coefÔ¨Åcients, which signiÔ¨Åcantly increases the compression ratio.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "0 \n20 \n40 \n60 \n80 \nPercentage \nModel Type \n(a)  Different accuracy for ISO- latency. Accuracy and Latency of Different Pretrained Models. By exploring these key aspects, we envision developing a self-managed inference-serving system, which can provide for different diverse needs of applications by leveraging the \n0 50 100 150 200 250 300 350 \n20.00% \n40.00% \n60.00% \n80.00% \n100.00% \nMobileNet V1 \nMobileNEt V2 \nInception V3 \nResnet50 \nResNet50-V2 \nDenseNet-201 \nDenseNet-121 \nXxception \nNasNetMobile \nInceptionResnetV2 \nvgg16 NasNetLarge \nLatency (ms) \nAccuracy % \nTop1-Accuracy Latency \nFigure 1.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "Following this, we observe that the variation in the number of containers in  Social Network  is mainly due to the significant difference in the  Commonality  and  Connectivity of the  Compose Post  function whose batch size is only one. There is lesser difference in containers spawned by  Comm Only ,  Conn Only  and  Kraken  for  Media Service  because we have implemented  Kraken  with a cap on the additional con- tainers spawned due to  Commonality  and  Connectivity  when the sum of their values exceeds a threshold. This threshold is exceeded in  Media Service  for the majority of functions.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "To the best of our knowledge, most of these works focusing on PCC with attributes target the compression ratio, and overlook the latency or energy consumption. However, as PC is moving to mobile, one cannot ignore the latency/energy constraints, thus demanding the need for mobile friendly PCC techniques which offer the best compression, latency and energy savings while preserving the video quality. III.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "[2] ‚ÄúAchieving Compliant Data Residency and Security with Azure,‚Äù \nhttps://azure.microsoft.com/mediahandler/Ô¨Åles/resourceÔ¨Åles/achieving- compliant-data-residency-and-security-with-azure/Achieving Compliant Data Residency and Security with Azure.pdf . [3] D. B. Agusdinata, W. Liu, H. Eakin, and H. Romero, ‚ÄúSocio- \nenvironmental impacts of lithium mineral extraction: towards a research agenda,‚Äù  Environmental Research Letters , vol. 13, no.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Compressed Geometry Stream (Output):  The Ô¨Ånal com- pressed geometry output stream is ready to be stored in the memory or streamed over the network. State-of-the-Art Intra-Frame Attribute Compression:  As shown in Fig. 4  b  , to compress the attribute data, similar steps ‚Äì  Raw Frame Input ,  Attribute Transform and Quantize , Entropy Encoding , and  Compressed Attribute Output Stream  ‚Äì are employed.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "This solves majority of the bottlenecks in a performance-driven classical cloud server platform. However, video analytics for many applications (Corporation; Custom On-Device ML Models with Learn2Compress; Wright\"; \"premioinc\") are moving towards the edge. Therefore, managing and storing the hefty volume of video data brings more challenge due to the energy, compute and form-factor limitations.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": ", f n } 2:  Output:  Compressed frames  C  =  { c 1 , c 2 , . . .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "It dynamically adjusts training strategies, such as the intensity and timing of dropout and quantization, based on predictions of energy availability. This method not only conserves energy but also enhances the network‚Äôs adaptability, ensuring robust learning and inference capabilities even under stringent power constraints. Our results show a 6% to 22% improvement in accuracy over current methods, with an increase of less than 5% in computational overhead.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Figure 2. 0 \n200 \n400 \n600 \n800 \n1000 \nTime(ms) \nModel Type \n(b)  Different response latencies for ISO-accuracy. 0 \n20 \n40 \n60 \n80 \nPercentage \nModel Type \n(a)  Different accuracy for ISO- latency.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "The ReRAM devices are programmed to have different resistance values, which are used to store the weights. The inputs are fed to the x-bar, which is a two-dimensional array of ReRAM crossbar arrays. The crossbar arrays are composed of a set of row and column wires that intersect at a set of ReRAM devices (refer Figure 5b).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "D ISCUSSION \nKey insights:  Compared to other systems, the ratio of energy requirement of task vs the harvested energy is much higher here. Added with time constraints, designing such a system becomes tricky. While many of the prior works have designed their systems around inference using intermittent systems, we are one of the few works which focuses on learning, and the only work which does it on a large scale of data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "This is because, compared with the whole frame, RoIs in these two videos are large (e.g., ratio of RoI/whole frame is 4x of that ratio in V1), which increases the computation for the PI and thus decreases the its beneÔ¨Åts. Finally, P1 and P2 are two videos with several people walking around a room. As the RoIs size increases along the video (e.g., ratio of RoIs/whole frame increases from  8%  in frame20 to  53%  in frame2470), the beneÔ¨Åts from PI become increasingly lower, resulting in similar patterns for FI+SI and FI+SI+PI.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "Sun, and N. Vasconcelos, ‚ÄúDeep learning with low precision by half-wave gaussian quantization,‚Äù  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 5406‚Äì5414, 2017. [31]  G. Venkatesh, E. Nurvitadhi, and D. Marr, ‚ÄúAccelerating deep con- volutional networks using low-precision and sparsity,‚Äù in  2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "These observations call for a holistic hardware-software ‚Äúco-design‚Äù that integrates efficient expert models with custom system support and reconfigurable hardware architectures, to optimize performance, while minimizing resource consumption. How do we get there? Our proposal introduces an  Ensemble of Experts (EoE)  framework that embodies this co-design philosophy.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "In our example case, transmitting the raw data (60 data points, 32bit floating point data type) needs  240 Byte s of data trans- fer, and with coreset construction and quantization we can limit it to  36 Bytes  (for 12 clusters, each cluster center is represented by 2 Bytes of data, and radius represented by 1 Byte data), thereby  reducing the data communication volume by 85% . The host runs inference on the compressed data to detect the activity (with an accuracy of 76%). However, due to this reduced accuracy, the sensor only takes this option iff it does not have enough energy to perform the inference at the edge device (either in the 16bit or 12bit variant of the DNN - more details on DNN design is presented in Sec- tion 4).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 180,
    "augmented": false
  },
  {
    "text": "Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input/output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources. Similar hybrid arrangements have been explored in the NVP literature [ 23 ] and impose minimal design overheads. The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiÔ¨Åcations.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Segmentation:  The next step is to partition the sorted PCs (i.e., I-frame and P-frame) into several blocks/segments (similar to the term ‚Äúmacro-blocks‚Äù in 2D image encoding). 7 , compared to the irregular raw PC, after sorting the PC via Morton-code, the adjacent points are more ‚Äúregular‚Äù and geometrically closer, and thus share rich attribute similarities. SpeciÔ¨Åcally, our proposal consists of the following 4 steps: PC sorting:  As shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "However, in our setup, both beneÔ¨Åt from the distributed au- toscaling and prediction policies, thus eliminating variability. Also note that  InFaas  is deployed using OnDemand instances, while both  Clipper  and  Cocktail  use spot instances. 6 Analysis of Results \nThis section discusses the experimental results of  Cocktail using the Wiki and Twitter traces.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "google.com/project/360-videos‚Äù. [10] Google, ‚ÄúMore Ways to Watch and Play with AR and VR.‚Äù ‚Äùhttps:// blog.google/products/google-vr/more-ways-watch-and-play-ar-and-vr‚Äù. [11] Google, ‚ÄúBuild Virtual Worlds.‚Äù ‚Äùhttps://developers.google.com/vr‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "For example, PTU [28] uses a hardware-accelerated rendering unit (HAR) to mitigate energy- overheads due to on-device rendering. Hardware assist on VRs:  Various energy-efÔ¨Åcient hardware modiÔ¨Åcations [28] have been proposed to reduce energy con- sumption in the VR domain. These two characterizations indicate that such optimizations in the planar world are infeasible to be applied in 3D PT-rendering.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "The accuracy of both system might be identical (over a large number of test sets), yet for the current test case, both the models are not equally conÔ¨Ådent about the classiÔ¨Åcation. The question is, how do we measure the conÔ¨Ådence of the given classiÔ¨Åcation? It is obvious that the most conÔ¨Ådent classiÔ¨Åcation for the same class would be [1 ,  0 ,  0 ,  0] , where the model is 100% conÔ¨Ådent on class  o 1  and the most confused prediction would be  [0 .",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "03%, and minimum  ‚âà 2 . 62%) more accurate than the na¬®ƒ±ve learner. Further,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "However, since Origin  follows an activity aware scheduling with extended round-robin, it can relax the power constraint pruning if needed. In the earlier case of na¬®ƒ±ve scheduling we tried to build an efÔ¨Åcient DNN by applying energy aware pruning [15]. Instead of restricting the power constraint to the average power of the entire power trace, the constraint can be relaxed to the average power requirement of the extended round-robin \n0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 AAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baseline-2 Baseline 1 \n(a)  Accuracy with MHEALTH dataset.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 190,
    "augmented": true
  },
  {
    "text": "Since two identical head orientations lead to the same projection matrices, one opportunity to reduce computation is to  memoize  a set of head orientations as well as their corresponding compute results. Furthermore, even in cases where head orientation changes, the change is usually within a small range ‚Äì in a few consecutive frames. In fact, from this dataset we have found that, the head orientation for users does not often change within around  150 ms  period of time.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "The associated conÔ¨Ådence matrix boosts the classiÔ¨Åcation accuracy and also resolves ties while voting. IV. E VALUATION \nIn this section we explain the strategy for evaluating  Origin .",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "Prior work [ 9 ] solves an optimization problem such that the input parameters are model_type, hardware_type (CPU or GPU), and the output parameter is response latency. To do so, they suggest using offline profil- ing or results from previous executions. Unlike prior works, we suggest that the input and output parameters can be any linear combination of the three primary parameters men- tioned above, depending on the application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Vichar: A dynamic virtual channel regulator for network-on-chip routers. In  2006 39th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO‚Äô06) , pages 333‚Äì346. IEEE, 2006.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "VSS‚Äôs emphasis on video data optimization makes it a pertinent benchmark for assessing the  Salient Store  storage system‚Äôs capabilities in managing large-scale machine learning data-sets. We first implemented  Salient Store  on a workstation-class machine with two Xilinx CSDs - which colosely mimics the classical edge server setup. Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "[70]  Shulin Zhao, Haibo Zhang, Sandeepa Bhuyan, Cyan Subhra Mishra, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. 2020. D√©j√† View: Spatio-Temporal Compute Reuse for Energy-Efficient 360 ¬∞  VR Video Streaming.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Journal of the Franklin Institute , 2023. S√∂ren Becker, Johanna Vielhaben, Marcel Ackermann, Klaus-Robert M√ºller, Sebastian Lapuschkin, and Wojciech Samek. Audiomnist: Exploring explainable artificial intelligence for audio analysis on a simple benchmark.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "0 \nTime (ms) \nExec Time (ms) Stage-wise SLO (ms) \n400 \n300 \n200 \n100 \n(c) Hotel Reservation. Figure 7: Slack for various Functions in each Application. 0 \nTime (ms) \nExec Time (ms) Stage-wise SLO (ms) \n600 \n450 \n300 \n150 \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "ScaleFlux. Csd 3000. https://scaleflux.com/products/csd-3000/ , b. (Accessed on 11/13/2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "See our timeline (Figure 8) for time-span of the individual tasks. What is the Solution Space? Addressing these challenges ne- cessitates a fresh look beyond the current monolithic design for providing a democratic platform for contributing to cost-effective innovations in LLMs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "[109] Asit K. Mishra, Jorge Albericio Latorre, Jeff Pool, Darko Stosic, Dusan Stosic, Ganesh Venkatesh, Chong Yu, and Paulius Micikevicius. Accelerating sparse deep neural networks. ACM SIGARCH Computer Architecture News , 39(3):69‚Äì80, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "We will explore several directions for estimating  I W i  efficiently such as using a memory-efficient zeroth-order optimizer to estimate gradients using only forward passes [101]. To merge experts into a single one, assuming we have  n  experts each with parameter  Œ∏ i , i  = 1 , . .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "; iii)  How can fault-tolerance be factored into the training process without an unduly increase in execution latency and energy consumption? ; ii)  What are the ways of efficiently retraining routers when new experts are added into or removed from the ensemble? ; iv)  How can we identify hot experts and cold experts in LLM inference and how can such information be utilized?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Smooth schedule transitioning:  We identify smooth transition conditions to transfer as many partial results as possible from the last incomplete inference in one power cycle to the next power cycle with a different power level. We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution. In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Integration of Regularizers in Backpropagation and SGD \nDuring the training iteration  k : \n1. Forward pass:  Each participating sensor collects data ( x, y )  and evaluates  ‚Ñì ( f Œ∏ k ( x ) , y ) . Since the regularizers are deterministic, their gradients ‚àá ‚Ñ¶ SNR ( Œ∏ )  and  ‚àá ‚Ñ¶ complexity ( Œ∏ )  do not introduce bias.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Design Description of the DNN Hardware Augmentations \nCompute Mapping:  Fig. 5a  shows the high level design, architecture and different components present in our proposed accelerator. A.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": ", m n ]  where  m i  ‚àà{ 0 ,  1 } . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Feature Map Reconstruction Error Dropout and QuantaTask Optimization: Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ≥ .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "IEEE, 2021. [7] Dazhong Wu, Connor Jennings, Janis Terpenny, Robert X Gao, and Soundar Kumara. A comparative study on machine learning algorithms for smart manufacturing: tool wear prediction using random forests.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "77 √ó  speedup against VSS and a classical storage server, respectively. 5.2 Evaluation of Video Data Recovery and Quality: \nTo ensure proper video quality upon recovery, we perform a peak signal-to-noise ratio (PSNR) study of  Salient Store  with the classical encoding mechanisms H264 (ITU-T, 2019a) and H265 (HEVC) (ITU-T, 2019b). Experiments on waymo (Sun et al., 2020) dataset shows the PSNR of Salient Store  compared to the classical H264 and HEVC encoding pipeline in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "Complexity Analysis : The heuristic has a time complexity of O ( N  log  N )  due to sorting tasks based on  P   eff i   , which is acceptable for real-time applications. Complexity Analysis of DynInfer:  The time complexity of the scheduling algorithm is  O ( N  log  N ) due to sorting tasks, and the space complexity is  O ( N )  for storing task parameters. Compared to classical inference, DynInfer introduces additional overhead for scheduling and task fusion, but this is offset by the gains in reliability and efficiency under intermittent power.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "What are the Problems? While LLMs have become integral across various sectors due to their advanced capabilities, con- structing these models from scratch for specialized applica- tions presents significant challenges due to the prohibitive cost. Source: [30].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "It can be concluded from these results that, memoizing the last  two  frames is sufÔ¨Åcient for most of the cases. Memoizing more frames may not bring much additional beneÔ¨Åts because of the high sensitivity of the IMU sensors. Storing only  two \nhead orientations (in registers) and their associated  P buff  in the DRAM occupies only  ‚âà 16 MB  memory space.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "2: Similarity study. As discussed in Sec. II, most existing optimizations focus on accelerating the inference processing/computation only and not fully understand the underlying characteristics of the input data, and thus some input-speciÔ¨Åc optimization opportunities could be easily missed.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Figure 2: Function-wise Breakdown of Container Provisioning across Applications. 0 50 100 150 \nStatic Provisioning \nProbability-based \nXanadu \n# Containers \nNGINX Check_Reservation Get_Profiles Search Make_Reservation \n(c) Hotel Reservation. 0 100 200 300 \nStatic Provisioning \nProbability-based \nXanadu \n# Containers NGINX ID Movie_ID Text User_Service Rating Compose_Review Movie_Review User_Review Review_Storage \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "6.2.1 Sensitivity Study : This subsection compares  Kraken against  Oracle , which is an ideal policy that is assumed to be able to predict future load and all path probabilities with 100% accuracy and also has request batching. Consequently, Oracle  does not suffer from cold starts and minimizes con- tainers spawned. Figure 15 shows the breakdown of total number of containers spawned for each application, aver- aged across all realistic large-scale traces using the simulator.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "The host device remembers the most recent classiÔ¨Åcations by all of the sensors. After receiving or recalling prediction from all sensors, the host performs a majority voting for the Ô¨Ånal classiÔ¨Åcation. AASR thus bridges the major gaps in the design that we intend to achieve.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "VOMMs are an extension of Markov Mod- els [ 28 ], where the transition probability from the current state to the next state depends not only on the current state, but possibly on its predecessors (which we refer to as the ‚Äòcontext‚Äô of the state). Such behavior is seen in some of our workloads such as  ùëÄùëíùëëùëñùëéùëÜùëíùëüùë£ùëñùëêùëí . behavior [ 19 ,  20 ].",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Finally, Thrust-4 is devoted to developing a comprehensive empirical evaluation platform consisting of a simulator and analytical tools to evaluate and validate our design in terms of performance, energy efficiency, and model accuracy. Thrust-3 examines architectural design space for efficient mapping of experts to hardware leading to a chiplet-based design consisting of a heterogeneous platform of compute engines such as CPUs, GPUs, and accelerators. This thrust will also in- vestigate the required mechanisms for minimizing data transfer overheads and the underlying interconnect architecture to facilitate reconfigurability and fault-tolerance.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "concludes with a discussion of limitations and future work. 2. Background and Related Work \nVery basic, just the outline, compact and make robust \n2.1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1041 \nselection and procurement play a pivotal role in minimizing the latency and deployment costs. ‚Ä¢  Ensemble systems [ 27 , 80 ] are  not focused towards model deployment  in a public cloud infrastructure, where resource \n1 We refer to ensemble-learning as ensembling throughout the paper. Besides, employing linear ensembling techniques such as model averaging are compute intensive [ 80 ] and not scalable for a large number of available models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "The different methods for each component are summarized in Table 1. Each expert can vary in model size and architecture depending on the complexity of its domain. Note that  existing works have only studied a few specific points in this vast design space , lack- ing a comprehensive exploration of this search space of expert model design and implementation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "III-B , apart from identifying the locality existing in geometry data, the Morton codes can also help us capture the attribute locality. Motivated by this, we further optimize the attribute compression pipeline for a given frame, as shown in Fig. 3  and discussed in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "The relative invocation frequency of a function is measured with respect to the application it consti- tutes. We introduce weights to estimate the appropriate number of containers to be spawned for each function. A function‚Äôs weight is calculated using the relative invocation frequency of a function along with other DAG-specific parameters  (explained in the next section).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "The next step is to decode the original frame from the bitstream, and today, this is mostly done using a hardware- based h264/MPEG decoder for more energy efÔ¨Åciency. Similar to 2D videos, the  360 ¬∞ video bitstreams are encoded in H.264/MPEG formats [19] for network efÔ¨Åciency. More speciÔ¨Åcally, the  360 ¬∞ video processing pipeline can be summarized as follows: Video Decoder:  The HMD receives encoded  360 ¬∞ video bitstream from the network (YouTube [61], Facebook-360 [7], etc).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "Google Pixel 2 Review. [61]  Oren M Tepper, Hayeem L Rudy, Aaron Lefkowitz, Katie A Weimer, Shelby M Marks, Carrie S Stern, and Evan S Garfein. \"https://www.techradar.com/reviews/ google-pixel-2-review\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 7th ACM international conference on Web search and data mining , pages 173‚Äì182, 2014. [3]  Ahmed Ali-Eldin, Jonathan Westin, Bin Wang, Prateek Sharma, and Prashant Shenoy. Spotweb: Running latency-sensitive distributed web services on transient cloud servers.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Measuring massive multitask language understanding. [192] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. arXiv preprint arXiv:2110.11605 , 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "To study how these approximation decisions affect the hologram video quality, we next want to reconstruct/render the hologram from our design based on the real-time eye move- ments and head orientations, and compare the quality of the recon- structed images against the baseline using the peak signal-to-noise ratio (PSNR) [ 21 ,  44 ] metric. 7c, our  HoloAR  design running on the edge GPU [ 36 ] still saves 25% more energy than the custom HORN-8 accelerator. 5.4 Sensitivity Study \nImpact on Quality:  The prior  Inter-Holo  scheme captures the small-region of eye focus to approximate the hologram outside of RoF, and the proposed  Intra-Holo  takes advantage of the sparse computation required for the far objects to reduce the number of depth planes.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 193,
    "augmented": true
  },
  {
    "text": "[65] Connor Holmes, Masahiro Tanaka, Michael Wyatt, Ammar Ahmad Awan, Jeff Rasley, Samyam Ra- jbhandari, Reza Yazdani Aminabadi, Heyang Qin, Arash Bakhtiari, Lev Kurilenko, and Yuxiong He. Deepspeed-fastgen: High-throughput text generation for llms via mii and deepspeed-inference. arXiv preprint arXiv:2401.08671 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "Holistic Approach:  Unlike other methods that focus on either training or inference optimizations, NExUME provides a comprehensive solution that addresses both phases, leading to superior overall performance. 4.3 NExUME on Machine Status Monitoring  [Our New Dataset] \nAutomation and monitoring and analytics are the key ingredients in the upcoming Industry 4.0. To enable sustainable machine status monitoring with energy harvesting (from machine vibrations or Wifi signals) we evaluate our setup using Bridgeport machines for monitoring their status.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "[12]  S. Sudevalayam and P. Kulkarni, ‚ÄúEnergy harvesting sensor nodes: Survey and implications,‚Äù  IEEE Communications Surveys Tutorials , vol. 463‚Äì468, 2005. 13, no.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "By integrating adaptive neural architecture and energy-aware training techniques, NExUME significantly enhances the viability of deploying machine learning models in environments with limited and unreliable energy sources. The results from our extensive evaluations demonstrate that NExUME can substantially outperform traditional methods in energy-constrained settings, with improvements in accuracy and efficiency that facilitate real-world applications in remote and wearable technology. Specifically, improvements ranging from 6.10% to 17.13% over existing methods highlight NExUME‚Äôs capability to adapt dynamically to fluctuating energy conditions, ensuring both operational longevity and computational integrity.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "Transactions of the Association for Computational Linguistics , 12:283‚Äì298, 2024. [29] Common Crawl. Common crawl corpus.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Enabling fast deep learning on tiny energy-harvesting iot devices. In  2022 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pp. 921‚Äì926.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Five layer scheduling schemes: (a) Naive execution @Simple architecture; (b) Naive execution @ResiRCA architecture; (c) Se- quential resilient execution @ResiRCA architecture; (d) Pipelining resilient execution @ResiRCA architecture; and (e) Hybrid resilient execution @ResiRCA architecture \nResiRCA architecture; we call this execution style  Pipelining . For ease of explanation and simulation, we only allow full pipelining in this execution, which means MAC operations of all the layers are included in each pipeline stage. Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "Accessed: 2024-08-01. Technical report, National Institute of Standards and Technol- ogy (NIST), 2023. URL  https://www.nccoe.nist.gov/sites/default/files/2023-12/ pqc-migration-nist-sp-1800-38b-preliminary-draft.pdf .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Mathematical Formulation:  Let  W  be the weight matrix of a layer. The impact of neuron  i  on the loss function  L  can be approximated using the first-order Taylor expansion: \n‚àÜ L i  ‚âà \f\f\f\f ‚àÇ L ‚àÇ a i a i \n\f\f\f\f \nwhere  a i  is the activation of neuron  i , and   ‚àÇ L \n‚àÇ a i   is the gradient of the loss with respect to the activation. Define the dropout probability  p i  for neuron  i  based on the Taylor expansion approximation of its impact on the loss: \np i  = Œª \f\f\f  ‚àÇ L \n‚àÇ a i   a i \f\f\f  +  œµ \nwhere  Œª  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 187,
    "augmented": false
  },
  {
    "text": "After training, we merge them in the final stage to form a reinforced model. For example, as shown in Figure 3, we can split a large expert model into smaller domain-specific models and train them on smaller, focused datasets in corresponding domains. Each expert can also grow to absorb new knowledge and shrink to discard obsolete knowledge.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "While execution is relatively straightforward when maintaining a speciÔ¨Åc conÔ¨Åguration of tiling and pipelining strategy, transitions between conÔ¨Ågurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures. As part of compiling a CNN to ResiRCA, we build a proÔ¨Åling table relating each potential tiling and pipeline conÔ¨Åguration \nthat might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw. The hardware design details will be presented in Section IV.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "That is, the selection ratio of  Sequential  is much higher than the ratio of  Pipelining  in ResiSchedule  solutions in the whole power trace. ‚Ä¢  Consistent with the above observation, the entire  Sequential strategy competes with the entire  Pipelining . The reason is that the active power threshold of  Pipelining  is much higher than that of  Sequential .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "inferences w/ smooth transition vs. # all inferences vs. # addi. Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with  Transition keep   for all the workloads with these power sources. 0.0% \n0.3% \n0.0% \n0.3% \n0.0% \n0.9% \n1.9% \n2.0% \n0.0% \n0.5% \n0.0% \n20.0% \n40.0% \n60.0% \nvs. # all inferences vs. # addi.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "For example, the recent iPhone 12/13 Pro features LiDAR camera for PC recording, and similarly, Samsung Galaxy S20+/S20 Ultra contains ToF (Time of Flight) camera for the same. This makes PC-based media recording a common commodity, rather than a sophisticated pipedream. Moreover, applications like Record3D [ 44 ] enable seamless PC media streaming from phone to a wearable, encouraging a perpetually increasing PC content generation and consumption.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "jpeg.org/pc/microsoft‚Äù . [8]  Charles Loop, Qin Cai, Sergio Orts Escolano, and Philip A Chou, ‚ÄúJPEG Pleno Database: Microsoft Voxelized Upper Bodies - A Voxelized Point Cloud Dataset,‚Äù  ‚Äùhttp://plenodb. [9]  Charles Thomson, ‚ÄúReality capture 101: point clouds, pho- togrammetry and LiDAR,‚Äù  ‚Äùhttps://bit.ly/3xfqvqy‚Äù , 2019.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Technologies, ‚ÄúAeromine technologies,‚Äù https://www. aerominetechnologies.com/ , (Accessed on 04/28/2023). [97] Urban TrafÔ¨Åc Dataset, ‚Äúhttps://github.com/edge-video- services/ekya#urban-trafÔ¨Åc-dataset.‚Äù [98] O. Wayman, ‚ÄúHow urban mobility will change by 2030,‚Äù https://www.oliverwyman.com/our-expertise/insights/2022/jun/how- urban-mobility-will-change-by-2030.html , 2022, (Accessed on 08/04/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "[12] Amazon. Alexa. \" Green Algorithms 4 HPC, August 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 24,
    "augmented": true
  },
  {
    "text": "Fi- nally, Section  ? ? presents simulation results and Section  ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 19,
    "augmented": false
  },
  {
    "text": "Next, we consider a model where multiple devices from multiple deployments participate in cooperative data sharing. Furthermore, when the deployments are geo-distributed and operated by different owners, the privacy concerns on sharing the data with a third party cloud service provider becomes challenging in developing the analytics solutions. A. Data-Shared Edge-Cloud Policy \nFirst, we consider a distributed sensor model, where each device is equipped with a small compute capability to perform analytics using random forests, and each individual device is trained on its own data.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Furthermore, each teacher model has its private conÔ¨Ådence matrix on different object classes. This conÔ¨Ådence matrix serves as a weight for performing the ensemble of multiple teachers, and helps exploiting the expertise of each of the teacher models for each of the individual classes, signiÔ¨Åcantly boosting the accuracy and robustness of the data annotation. This maximizes the accuracy of the teacher, and consequently minimizes the chance of the student model learning wrong labels.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "The critical insight to be gleaned here is reusing data and compute pipeline prior to its transfer to storage could markedly diminish the costs associated with data movement. This approach would notably minimize the consumption of bandwidth and latency and curtail the compute requirements, thereby ensuring that the compute server‚Äôs resources are judiciously employed only for indispensable computations. This strategic compute-reuse could help in optimizing the efficiency and efficacy of computational operations, especially in large scale data intensive and data driven applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "\"https://www.gazept.com/\". [13]  Patrick Geneva, Kevin Eckenhoff, Woosik Lee, Y. Yang, and Guoquan Huang. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "2019. [65]  Tiancheng Xu, Boyuan Tian, and Yuhao Zhu. Tigris: Architecture and Algorithms for 3D Perception in Point Clouds.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "[102] T.-J. 10 075‚Äì10 085. Yang, Y.-H. Chen, and V. Sze, ‚ÄúDesigning energy-efÔ¨Åcient convo- \nlutional neural networks using energy-aware pruning,‚Äù in  Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed ‚Äúsmart dust‚Äù solutions [ 8 ]. The ideal parallelism granularity determination for a particular deployment should consider the balance between throughput and area. 0 20000 40000 60000 80000 100000 120000 140000 160000 \nPV HG LeNet FR G1 G2 G3 G4 (default) G5 \nArea in ¬≠ m 2 \n<2, 2, 2, 2, 2> <4, 3, 2, 3, 5> <6, 4, 3, 4, 7> <8, 5, 4, 5, 9> \n<12, 7, 6, 7, 13> \n<2, 2> <6, 2> <9, 3> <11, 5> <16, 7> \n<2, 2> <5, 2> <8, 3> <11, 4> <16, 6> \n<2, 2> <7, 2> <13, 3> <17, 4> <22, 6> \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 228,
    "augmented": false
  },
  {
    "text": "[80] Jongman Kim, Chrysostomos Nicopoulos, Dongkook Park, Vijaykrishnan Narayanan, Mazin S Yousif, and Chita R Das. A gracefully degrading and energy-efficient modular router architecture for on-chip networks. ACM SIGARCH Computer Architecture News , 34(2):4‚Äì15, 2006.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "3.2.1 Data Memoization:  Given our focus on ultra low power energy harvesting devices, any opportunities to re- duce computation and communication can noticeably aug- ment the performance and efficiency of the entire system. We look into data memoization as one such opportunity. For two instances of the same class, there should be a very high correlation in the sensor data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2404.16789 , 2024. [148] Luohe Shi, Hongyi Zhang, Yao Yao, Zuchao Li, and Hai Zhao. Keep the cost down: A review on methods to optimize llm‚Äô s kv-cache consumption, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "SIGARCH Comput. Archit. News , 39(2):1‚Äì7, August 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "Consequently, there is no data in the range  [0 , q  ‚àí 1) , allowing the maximum value of the 13-bit samples to be represented efficiently by a 6-bit signed number. . , and is symmetrically distributed around  m  = 0 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Since this method also reduces the data movements in the system, we can expect a significant reduction in energy consumption. Ad- ditionally, we will identify hot and cold ‚Äúpaths‚Äù and use this infor- mation in  prefetching  the experts and routers (which are actually spe- cialized experts) into the higher levels of the memory hierarchy, close to compute units (note that this is an example use of expert-expert and expert-router affinities). Specifically, leveraging the observed pat- terns of expert reuse (‚Äúhotness‚Äù patterns) at different locations in the EoE , our system can intelligently predict and load the experts likely needed in subsequent layers to the main memory.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "We believe this is the Ô¨Årst work that applies the Morton code-based parallel octree construction algorithm [ 31 ] to speed up PC geometry com- pression. On the other hand, for attribute compression, we propose to sort the points in the Morton code order with the goal of capturing the attribute similarities. Also, to utilize temporal locality, we propose an inter-frame compression scheme which further increases the compression efÔ¨Åciency.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "The vast majority of these applications are user-facing, and hence, have stringent SLO requirements. Abstract The growing popularity of microservices has led to the pro- liferation of online cloud service-based applications, which are typically modelled as Directed Acyclic Graphs (DAGs) comprising of tens to hundreds of microservices. Serverless functions, hav- ing short resource provisioning times and instant scalability, are suitable candidates for developing such latency-critical applications.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "We implement our design in an edge GPU platform to demonstrate the real-world applicability of our research. 7 √ó  speedup and 73% energy savings. Our experimental results show that, compared to the baseline,  HoloAR  achieves, on average, 2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "9 \n495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 \nBecause the best-response process eliminates profitable de- viations step by step and cannot cycle indefinitely, the action profile sequence generated by iterative best responses con- verges to the NE. We have shown that, with the reward-based utility function that includes correct participation rewards ( Œ≥  ¬∑  ‚àÜ A i ( t ) ), penalties for incorrect inferences ( Œ¥ ), and penalties for non- participation ( Œ∑ ), the best-response dynamics lead to a Nash equilibrium. The proof relies on constructing a potential function  Œ¶  that is strictly increased by unilateral profitable deviations and bounded above.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 259,
    "augmented": true
  },
  {
    "text": "t . P  ‚â§ P av . Energy Buffering and Power-Predictor:  To regulate, manage and ensure a stable power supply to the circuitry,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "[17] P. Chi, S. Li, Y. Cheng, Y. Lu, S. H. Kang, and Y. Xie, ‚ÄúArchitecture \ndesign with stt-ram: Opportunities and challenges,‚Äù in  2016 21st Asia and South PaciÔ¨Åc design automation conference (ASP-DAC) . IEEE, 2016, pp. 109‚Äì114.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Large language models: A survey. Available at:  https://huggingface.co/meta-llama/Llama-3.1-405B . [107] Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Ama- triain, and Jianfeng Gao.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "[97] Urban TrafÔ¨Åc Dataset, ‚Äúhttps://github.com/edge-video- services/ekya#urban-trafÔ¨Åc-dataset.‚Äù [98] O. Wayman, ‚ÄúHow urban mobility will change by 2030,‚Äù https://www.oliverwyman.com/our-expertise/insights/2022/jun/how- urban-mobility-will-change-by-2030.html , 2022, (Accessed on 08/04/2023). Technologies, ‚ÄúAeromine technologies,‚Äù https://www. aerominetechnologies.com/ , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "Instruction in Responsible Professional Practices \nThe PhD students will receive instruction in responsible and ethical professional practices regularly within the context of their work. Training will cover the fundamentals of the scientific method, data protection and ethical sharing, lab safety, and other standards of professional practice. They will also be encouraged to affiliate with one or more professional societies in their chosen field.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Sec. In this paper, the foveated rendering idea (denoted as  Inter-Holo  design) has been implemented (in Sec. 4.3) and found to work well (in \n504 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Figure 6: Intra-Frame attribute compression example. The above discussion has explored the opportunity of utilizing Morton codes to speedup the geometry compression. Recall from Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, and Hartwig Adam. Netadapt: Platform-aware neural network adaptation for mobile applications. In Proceedings of the European conference on computer vision (ECCV) , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "6 √ó  data movement benefits compared to the state-of-the-art, on a single storage and  ‚âà 4 . 8 √ó  latency benefit in a multi-node system. 2 Background and Motivation \n2.1 Storage for Continuous Learning Edge Servers \nRecent developments in continuous learning for video analytics (Bhardwaj et al., 2022; Mishra et al., 2024; Kim et al., 2024) has significantly boosted the capabilities and accuracy of learning systems.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Better refers to the improvement over iNAS+PT baseline. 13 \nA More Results on Other Platforms and EH Sources \nFigure 4: Hardware setup of NExUME using MSP-EXP430FR5994 as the edge compute, Adafruit ItsyBitsy nRF52840 Express for communicating, Energy Harvester Breakout - LTC3588 with super- capacitors as energy rectification and storage and a Pixel-5 phone as the host. Datasets Full Power MSP on Piezo AP PT iNAS+PT NExUME Better FMNIST 98.70 71.90 79.72 83.68 88.90 6.24% CIFAR10 89.81 55.05 62.00 66.98 76.29 13.90% MHEALTH 89.62 59.76 65.40 71.56 80.75 12.84% PAMAP 87.30 57.38 65.77 65.38 75.16 14.97% AudioMNIST 88.20 67.29 73.16 75.41 80.01 6.10% Table 4: Accuracy of NExUME on MSP board using vibration from a Piezoelectric harvestor.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 280,
    "augmented": true
  },
  {
    "text": "https://docs.aws.amazon.com/ sagemaker/latest/dg/deepar.html,February2020 . [5] Amazon. EC2 pricing.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "[64]  Zhuoran Song, Bangqi Fu, Feiyang Wu, Zhaoming Jiang, Li Jiang, Naifeng Jing, and Xiaoyao Liang. 2020. DRQ: dynamic region-based quantization for deep neural network acceleration.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "5) as in prior works [ 22 ,  25 ,  30 ,  47 ]. In this paper, we have gone be- yond foveated rendering ( Inter-Holo ), by proposing an optimiza- tion/approximation called  Intra-Holo , that complements the for- mer in boosting performance/energy efficiency. 4.3) and found to work well (in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Pair, and V. Gopalakrishnan, ‚ÄúToward prac- tical volumetric video streaming on commodity smartphones,‚Äù in  Proceedings of the 20th International Workshop on Mobile Computing Systems and Applications , 2019, p. 135‚Äì140. [69]  Z. Que, G. Lu, and D. Xu, ‚ÄúVoxelcontext-net: An octree based framework for point cloud compression,‚Äù in  CVPR , 2021, pp. [68]  F. Qian, B. Han, J.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "Towards this, we plot, in Fig. 8b, the average number of depth planes (across our six videos), required by the four design alternatives (configurations). We see that, the number \n4 Due to space limitation, we chose six representative categories that cover diversity across multiple video parameters.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Ambi- ent energy availability varies over time and space, leading to fluctuating sensor activity levels and intermittent participa- tion in both training and inference tasks. Some sensors may frequently become inactive or produce low-quality data due to energy scarcity or environmental noise. Consequently, the mere presence of numerous EH sensors does not guaran- tee robust and reliable performance for complex tasks such as image recognition, acoustic surveillance, or precision agriculture monitoring.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "A survey of large language models. [192] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. arXiv preprint arXiv:2303.18223 , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "Backward pass:  The sensor computes  ‚àá Œ∏ ‚Ñì ( f Œ∏ k ( x ) , y ) via standard backpropagation. To incorporate regu- larizers, the sensor (or the aggregator after collecting updates) adds  Œª 1 ‚àá ‚Ñ¶ SNR ( Œ∏ k )  and  Œª 2 ‚àá ‚Ñ¶ complexity ( Œ∏ k ) . These gradients are computed analytically since the regularizers are explicit, differentiable functions of  Œ∏ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Tributary: spot-dancing for elastic ser- vices with latency SLOs. In  ATC . [7]  Akshitha Sriraman, Abhishek Dhanotia, and Thomas Wenisch.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "2) How to Capture the Temporal Opportunity? : To identify such similarity/reuse opportunities across frames (shown in Fig. 7 ), the macro-block based state-of-the-art approach [ 48 ] Ô¨Årst needs to generate two macro block trees (where the minimum voxel dimension in this tree is of a predeÔ¨Åned size) ‚Äì one for I-Frame and the other for P-Frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "(b): The pattern between left-eye and right-eye in the  front  face in Cube Mapping [41]. the averaged PSNR [25], [40] of the Ô¨Åve videos represented in Equirectangular format [52] in Fig. 10  a  .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Proceedings of the ACM on Programming Languages , 2(4):1‚Äì25, 2018. Thorough characterization and analysis of large transformer model training at-scale. [26] Scott Cheng, Jun-Liang Lin, Murali Emani, Siddhisanket Raskar, Sam Foreman, Zhen Xie, Venka- tram Vishwanath, and Mahmut Taylan Kandemir.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "In this work, we chose to use the NVGaze technique [ 26 ] to perform eye tracking for the  Inter-Holo  design due to two main reasons. Fortunately, there already exist a large body of techniques which can track the eye movements efficiently (e.g., see [ 26 ] and [ 12 ] and the references therein). First, it provides sufficient accuracy for the AR applications ‚Äì as high as 2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "consuming one among the proposed geometry, intra- and inter- frame attribute compression techniques). As shown in Fig. We then analyze the bottleneck of our proposal and provide insights for potential architectural support to make PCC even more energy efÔ¨Åcient.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Resirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent embedded processors. In  2020 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pp. 315‚Äì327.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "2  and Sec. III , most of the existing G-PCC tech- niques [ 56 ], [ 72 ] are based on octree data structure. We illustrate the generic pipelines (for  1  geometry compression, and for 2  attribute compression) employed by the state-of- the-art intra-frame compression techniques in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "[Online]. Available: http://arxiv.org/ abs/1612.08350 [7] Facebook, ‚ÄúFacebook 360,‚Äù ‚Äùhttps://facebook360.fb.com/‚Äù, 2019. [8] Facebook Inc., ‚ÄúFacebook Oculus,‚Äù ‚Äùhttps://www.oculus.com/‚Äù.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "x  is the input text,  D  is the document for retrieval, and  T  is the length of the generated text. Underline indicates the expert function. Expert Repository.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "[11] S. Ha and S. Choi, ‚ÄúConvolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors,‚Äù in IJCNN , 2016. [12] O. Banos, C. Villalonga, R. Garc¬¥ƒ±a, A. Saez, M. Damas, J. Holgado- Terriza, S. Lee, H. Pomares, and I. Rojas, ‚ÄúDesign, implementation and validation of a novel open framework for agile development of mobile health applications,‚Äù  BioMedical Engineering OnLine , 2015. [13] O. BaÀúnos, R. Garc¬¥ƒ±a, J.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "RR indicates the extended round-robin policy in use, e.g. RR6 AAS represents AAS with RR6. policy in use.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "To cope with this, we introduce a parameter called  Commonality , which is defined as the fraction of number of unique paths that the function can be a part of with respect to the total number of unique paths. Such errors can lead to sub- optimal container allocation to DAG stages in proportion to the wrongly-calculated function weights. This may be due to change in user behavior manifesting itself as variable function input patterns.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "2019. ACM. https://doi.org/10.1145/3317550.3321443 [10]  Chengliang Zhang, Minchen Yu, Wei Wang, and Feng Yan.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "C. Hardware Implementation and Evaluation \nThe proposed morphable hardware was simulated using an in-house simulator based on ScaleSim [ 79 ]. Having an ensemble provides robust exemplar selection and improves accuracy over a single teacher. The X-Axis has different DNNs , R: ResNeXt101, T: YOLO-V3, V: VGG- 16, IL: Intermittent Learning, RR: Round Robin.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution. ‚Ä¢  Smooth schedule transitioning:  We identify smooth transition conditions to transfer as many partial results as possible from the last incomplete inference in one power cycle to the next power cycle with a different power level. In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Unlike other methods that either focus on modifying the DNN architecture or optimizing inference configurations, NExUME adapts the DNN‚Äôs computational complexity in real-time based on instantaneous energy availability, leading to more efficient use of scarce energy resources and improved accuracy. The superior performance of NExUME can be attributed to its unique integration of energy variability awareness directly into both the training (DynFit) and inference (DynInfer) processes. Dataset Platform Energy Source Stateful ePerceptive DynBal NExUME \nFMNIST MSP430FR5994 Piezoelectric 20.1 20.8 21.5 23.4 CIFAR10 Arduino Nano Thermal 16.0 16.5 17.0 18.5 MHEALTH ESP32 S3 Eye Piezoelectric 18.5 19.0 19.6 21.0 PAMAP STM32H7 Thermal 16.5 17.0 17.5 19.0 AudioMNIST Raspberry Pi Pico Piezoelectric 20.5 21.0 21.7 23.2 Table 2: Energy efficiency comparison on different hardware platforms.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 232,
    "augmented": true
  },
  {
    "text": "Figure 12:  Sensitivity analysis of VMs. by scaling up models. However,  Clipper-X  does not scale down models as frequently as  Cocktail , while ensuring similar accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "We have advised several Penn State honors students (including women and minorities) through our prior NSF projects. We will also target students from the Integrated Undergraduate/Graduate (IUG) program at Penn State (which allows students to earn both a bachelor‚Äôs and master‚Äôs degree in five years), to get involved in Generative AI research for possible graduate studies. Industry Collaboration: We have several ongoing collaborations with industries like NVIDIA, AMD, Google and Meta, who are major players in advancing deep learning technology/systems.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "6351‚Äì6360. [46] S. Lee, S. Goldt, and A. Saxe, ‚ÄúContinual learning in the teacher- \nstudent setup: Impact of task similarity,‚Äù in  International Conference on Machine Learning . PMLR, 2021, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "In  18th USENIX conference on file and storage technologies (FAST 20) , pp. { POLARDB }  meets computational storage: Efficiently support analytical workloads in  { Cloud-Native }  relational database. 18 \nWei Cao, Yang Liu, Zhushi Cheng, Ning Zheng, Wei Li, Wenjie Wu, Linqiang Ouyang, Peng Wang, Yijing Wang, Ray Kuan, et al.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Cocktail  spawns upto 50% more VMs than  InFaas , but in turns reduces accuracy loss by up to 96%. To further capture the beneÔ¨Åts of the weighted autoscal- ing policy, Figure  12a  plots the number of VMs spawned over time for the top-3 most used models in the ensemble for  Const1 . Intuitively,  InFaas  has the least number of VMs spawned because it does not ensemble models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "However, it misses the opportunities of frame-level data reuse, and hence needs to perform inference for each and every frame. II, DeepCache [8] also exploits the sim- ilarity between continuous frames at runtime, and decreases the computation via memory copies. D. Comparison against Prior Work \nAs discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Therefore, we add one more parameter to control the ratio of such blocks. Especially, for each P-block, we Ô¨Årst calculate its 2-Norm distance to its  best matched block  in I-frame. V , only part of the blocks/segments can be directly approximated by the reference block.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Restrictions apply. TABLE III: mAP (%) comparison with the baseline \nV1 V2 V3 V4 YOLOv3 51.8 55.4 42.0 59.5 YOLOv3 w/ FI+SI 51.8 55.4 41.8 59.4 YOLOv3 w/ FI+SI+PI 50.3 54.1 40.6 58.0 YOLOv4-tiny 31.8 49.3 31.3 33.5 YOLOv4-tiny w/ FI+SI 31.6 49.2 31.4 33.3 YOLOv4-tiny w/ FI+SI+PI 31.4 49.1 30.8 33.0 \n3) mAP:  To study the accuracy impact of our proposed SI and PI schemes, we summarize the mAP for our two models (YOLOv3 and YOLOv4-tiny) using four videos from VIRAT dataset [33] in Table III. One can observe that the mAP in our FI+SI scheme only drops by  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 250,
    "augmented": false
  },
  {
    "text": "The volume of research in LLMs is a testimonial to the interest in this area. 3 Related Work \nLLMs have gained significant momentum in recent years and are being used in domains like virtual as- sistants [12,16,56], website chatbots [121], tools [48,123], notetaking/summarization [52], etc. Here, we summarize the research directly related to our proposal under the following areas: Algorithms and Models:  LLMs are known for their vast parameter sizes and training datasets, with a com- \nmon belief that larger LLMs yield better performance [64].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "Figure  13  plots the average number of models (bar- left y-axis) and cumulative accuracy (line- right y-axis) for the different sampling intervals for queries with three different constraints. It can be seen that the 30s interval strikes the right balance with less than 0.2% loss in accuracy and has average number models much lesser than other intervals. This is because, increasing the interval leads to lower number of scale down operations, thus resulting in a bigger ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "https://cloud.google.com/ functions/docs/. [18]  Istemi Ekin Akkus et al . 2018.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "A Unified View of EoE Function Choices. We define three building blocks of an EoE system: ‚ÄúRouting‚Äù, ‚ÄúExpert‚Äù, and ‚ÄúComposition‚Äù. Our exploration will focus on various types of router functions to direct user queries to appropriate experts, different expert model architectures, and composition functions to  ag- gregate  expert outputs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "[123] OpenAI. Openai chatgpt. \" https://openai.com/chatgpt/overview/ \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Even though AAS provides signiÔ¨Åcantly better results com- pared to standard round-robin, it is still unable to incorporate ensemble learning. The major challenge is the inability to run inferences in all the sensors simultaneously because of the harvested energy budget. Therefore, we need to Ô¨Ånd the classiÔ¨Åcation result for all the sensors without activating them.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "4.Data Flow Management:  Design efficient data paths to handle the high throughput of video data and intermediate results between the FPGA blocks, ensuring that bandwidth and memory access bottlenecks are minimized. Layered Encoding:  Each layer of the neural codec can be implemented using parallel processing units in FPGA, allowing simultaneous processing of different frame parts or different quality layers. 3.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "VI-B . As shown in Fig. 10b , with fewer ‚Äúdirect-reuse‚Äù blocks (e.g., only  31%  of the I-blocks are directly reused in the left-most bar), the PSNR drops slightly when compared to the intra- frame compression, while the compression ratio is also the worst.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Experts can be classified via a set of diverse criteria  a , such as domain, skills, and languages. We intend to model this structure by building a  C hain Ensemble- o f- E xperts (CEoE), where layers are assigned for different classification criteria  a , and each expert in each layer is assigned for a type  t  under its classification  a , such as math in skills, medical in domains. During training, a document is routed to its type in criteria  a 1  and then routed to its type in another  a 2  until all criteria in  a  are covered.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "2012. [55]  Tomoyoshi Shimobaba, Jiantong Weng, Takahiro Sakurai, Naohisa Okada, Takashi Nishitsuji, Naoki Takada, Atsushi Shiraki, Nobuyuki Masuda, and To- moyoshi Ito. Computational Wave Optics Library for C++: CWO++ Library.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "The proposed design provides  ‚âà 2 . 6 √ó  data movement benefits compared to the state-of-the-art, on a single storage and  ‚âà 4 . 2 √ó  latency and  ‚âà 5 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "IL- LIXR already contains several AR software components (some of them are shown in Fig. Framework Prototype:  To prototype a real-life AR headset, a proper codebase and a hardware platform are essential. For our codebase, we build our proposals on top of ILLIXR [ 19 ], which is the first open-source full-system extended reality testbed.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "2020. Eye Tracking and Neuromarketing Research Made Easy. \"https://www.gazept.com/\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "This can be extended further adopting a round-robin activation schedule to both increase harvesting periods per initiated in- ference on each node while increasing the odds that at least some node is attempting an inference at any given time. Chest \nNo  Op \nRight  Wrist \nNo  Op \nLeft  Ankle \nNo  Op \nChest \nNo  Op \nNo  Op \nRight  Wrist \nNo  Op No  Op \nLeft  Ankle \nNo  Op \nNo  Op \nChest \nNo  Op \nNo  Op \nNo  Op \nRight  Wrist \nNo  Op No  Op \nNo  Op \nLeft  Ankle \nNo  Op \nNo  Op \nNo  Op Chest \nRight  Wrist Left  Ankle \nRR3 \nRR6 RR9 \nRR12 \nFig. 3:  Different Ô¨Çavors of (extended) round-robin scheduling and their execution Ô¨Çow.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "For exam- ple, to store/transmit these two arrays,  4 bytes √ó 16 = 64 bytes are needed. However, even without any compression, we only need  4 bytes √ó 3 √ó 3 = 36 bytes  to represent these 3 points. Therefore, an extra post-processing step is needed to merge these two arrays in the ‚Äúoccupy bits‚Äù style.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "In contrast, this paper attempts to exploit available ‚Äúre- dundancies‚Äù in computation by analyzing the VR projection computation pipeline. SpeciÔ¨Åcally, we propose and evaluate in detail two pluggable schemes (for taking advantage of intrinsic temporal-spatial reuse), and prototype them as microarchitec- tural augmentations using FPGA. Our experimental results show 34% computation reduction and 17% energy savings, compared to the state-of-the-art [28].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Sec. 5) as in prior works. Further, in this paper, we have gone beyond foveated rendering ( Inter-Holo ), by proposing an optimiza- tion/approximation called  Intra-Holo , that complements the former in boosting performance/energy efficiency.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "To understand these challenges, we analyze an end-to-end PC pipeline. End-to-end Pipeline:  The PC video processing pipeline, as shown in Fig. 1 , typically consists of 5 stages: 3D content generation, PC encoding, data transmission, PC decoding, render and display.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Further, we are the Ô¨Årst of a kind system to imagine sustainability Ô¨Årst and design a morphable hardware which can facilitate multiple functionality. We also compare our work against two reconÔ¨Ågurable platforms [ 15 ], [ 63 ]. We believe it will not be fair to compare the energy efÔ¨Åciency and throughput of a system like ours, which in- herently has more memory, I/O and reconÔ¨Åguration operation with a pure compute based systems mentioned in the hardware baseline.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "In  GHTC , 2018. [49]  J Zico Kolter and Marcus A Maloof. Dynamic weighted majority: An ensemble method for drifting concepts.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "1) Computation tiling:  In this work, we use loop tiling [ 35 ] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one. As shown in Figure 2, if loop tiling is applied to the unrolled MAC operations, only a tile of ReRAM cells along with their peripheral circuits is enabled to perform MAC operations. After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "K-means++ the advantages of careful seeding. In  Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms , pp. 1027‚Äì1035, 2007.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "3). Therefore, in principle, \n0 1 2 3 \nbike \nbook \nbottle \ncamera \ncerealBox \nchair \ncup \nlaptop \nshoe \nDistance/Size (m) \nCam2ObjDist. ObjSize \n(a) Object study.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "For example, AFBC [1] is proposed to efÔ¨Åciently compress video streams between the processing pipeline blocks. However, our work focuses on edge-side optimization, which can also be implemented as a comple- mentary add-on in such cloud-assisted systems. Energy Optimizations in Conventional Video Processing: In the existing planar video processing pipeline on mobile de- vices, prior works have looked at memory [1], [63], [64], dis- play [13]‚Äì[15], [34] and codec [49], [65], and identiÔ¨Åed ‚Äùmem- ory‚Äù as the major energy bottleneck.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "[16] Y. Chen, T. Luo, S. Liu, S. Zhang, L. He, J. Wang, L. Li, T. Chen, \nZ. Xu, N. Sun  et al. , ‚ÄúDadiannao: A machine-learning supercomputer,‚Äù in  2014 47th Annual IEEE/ACM International Symposium on Microar- chitecture . IEEE, 2014, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Deep Learning Dtudio, February 2020. https://docs.deepcognition.ai/ . [29]  J. Deng, W. Dong, R. Socher, L. Li, and and. Imagenet: A large-scale hierarchical image database.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 50th Annual International Symposium on Com- puter Architecture , ISCA ‚Äô23, New York, NY, USA, 2023. Association for Computing Machinery. [77] Mahmut Kandemir, Taylan Yemliha, SaiPrashanth Muralidhara, Shekhar Srikantaiah, Mary Jane Ir- win, and Yuanrui Zhnag.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "[40] Murali Emani, Sam Foreman, Varuni Sastry, Zhen Xie, Siddhisanket Raskar, William Arnold, Rajeev Thakur, Venkatram Vishwanath, Michael E. Papka, Sanjif Shanmugavelu, Darshan Gandhi, Hengyu Zhao, Dun Ma, Kiran Ranganath, Rick Weisner, Jiunn-yeu Chen, Yuting Yang, Natalia Vassilieva, Bin C. Zhang, Sylvia Howland, and Alexander Tsyplikhin. Toward a holistic performance evalua- tion of large language models across diverse ai accelerators. In  2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) , pages 1‚Äì10, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 191,
    "augmented": false
  },
  {
    "text": "3, for each of the objects, a corresponding approximation factor ( Œ≤ ) can be determined based on these insights. With the help of the pose estimation, now the AR hologram pipeline has the knowledge about the range/size of each object as well as its relative distance from the user. Next, as shown in Algo.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "2020. Objectron Dataset Annotation: laptop. \"https://github.com/ google-research-datasets/Objectron/blob/master/index/laptop_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "These two characterizations indicate that such optimizations in the planar world are infeasible to be applied in 3D PT-rendering. Hardware assist on VRs:  Various energy-efÔ¨Åcient hardware modiÔ¨Åcations [28] have been proposed to reduce energy con- sumption in the VR domain. For example, PTU [28] uses a hardware-accelerated rendering unit (HAR) to mitigate energy- overheads due to on-device rendering.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "If we allow  aG ReRAMs to perform the concerned layer‚Äôs computations in parallel, the input data should be divided into  aG  partitions. The actual parallelism granularity  aG ‚â§ G  for a layer is decided by the harvested power level. In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "The idea is to use the inverse of the L2 norm to determine the probability: \np i  = Œ± ‚à• W i ‚à• 2  +  œµ \nwhere  Œ±  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. Define a binary dropout mask  m  = [ m 1 , m 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Moreover, CSDs hold the potential to undertake critical machine learning tasks like feature extraction and clustering, streamlining tasks like neural compression. The unique combination of FPGAs‚Äô parallel processing prowess, the substantial internal bandwidth of SSDs, and their block- accessible nature position CSDs as ‚Äúideal components‚Äù for evolving smart storage solutions tailored for machine learning. To cater towards this, in this work, we propose  Salient Store  ‚Äì a mini computational storage server (we call it ‚Äúedge storage server‚Äù) stack for managing the data archival in edge servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Furthermore, no restriction on the reuse or redistribution of any artifact developed in this project will be placed for non-commercial use. 5. Also, we will prepare educational materials ‚Äì in a slide-deck form ‚Äì that can be easily used in different classes like ML and systems.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Wherever appropriate, we draw in- spiration from related works that model user web surfing \n156 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \n0 \n0.25 \n0.5 \n0.75 \n1 \nHit Rate \n(a) Social Network. This aids us in the calculation of function invocation probabilities. 0 \n0.25 \n0.5 \n0.75 \n1 \nHit Rate \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Each chip can potentially contain a set of homogeneous or heterogeneous chiplets including accelerator engines, reconfigurable engines, CPUs, GPUs, and various types of memory modules. cally create an  Expert Execution Attribute Database  containing metrics such as latency, compute utiliza- tion, memory utilization, accuracy, and power contribution, and minimum HBM needed. This database will help in various intelligent decisions such as using the most ideal hardware for an expert and dropping an expert if it does not meet the minimum required accuracy/SLO for an application.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output Y . If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "1) Partial Inference:  To further explore the computation reuse opportunities, we revisit the Ô¨Årst scenario illustrated in Fig. 3a, where the MV for Frame-3 is not highly overlapped with the bounding boxes from Frame-1 (overlap ratio = 0.60, lower than the predeÔ¨Åned threshold). This means that the object in question has been moving towards a direction, which triggers a ‚Äúposition change‚Äù event.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "The reconstruction error of a feature map  F i  is calculated as: \nRE i  =  ‚à• F i  ‚àí ÀÜ F i ‚à• 2 \nwhere   ÀÜ F i  is the reconstructed feature map, and  ‚à•¬∑ ‚à• 2  denotes the L2 norm. Mathematical Formulation:  Let  W  be the weight matrix of a layer and  F  be the feature maps produced by the layer. D.3 Feature Map Reconstruction Error Dropout with QuantaTask Optimization \nFeature Map Reconstruction Error Dropout leverages the reconstruction error of feature maps to adjust dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "The first compo- nent of this framework will employ actual machine experiments on Argonne National Lab (ANL) machines (see the collaboration letter from ANL and our preliminary results [26]). These experiments will involve not only state-of-the-art GPUs but also hardware accelerators such as Groq [5], Cerebras [96], SambaNova [131], Habana Gaudi [87], and GraphCore [54] (all available on ANL machines). The second component will be based on simulation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "Next, we evaluate the new combinations by extracting one function from each type. In this way, we aim to find the optimal combination of the choices. Method Function \nRouting Function \nMixture-of-experts Œ± i  =  SoftMax ( W i h i ‚àí 1 ) Variable size Œ± i  =  { a > k | a  ‚àà SoftMax ( W i h i ‚àí 1 ) } Top-k learned routing Œ± i  =  TopK ( SoftMax ( W i h i ‚àí 1 )) \nExpert Function \nFeedforward network h i  =  W i h i ‚àí 1 Prompt tuning h i  =  f Œ∏ i ( œï i ,  h i ‚àí 1 ) Low-rank adaptation W i  =  W ‚Ä≤ i   +  AB Large language model Œ∏  =  argmax Œ∏ \nQ T t =1   p Œ∏ ( y t | x, y j<t ) Retrieval augmented generation Œ∏  =  argmax Œ∏ \nP \nz ‚ààD   p Œ∏ ( z | x ) p Œ∏ ‚Ä≤ ( y | x, z ) \nComposition Function \nRepresentation averaging h i  =   P M j =1   Œ± i h i,j Weight summation W i  =   P M j =1   W i,j Sequential aggregation f Œ∏ ‚Ä≤  =  f œï M  ( f œï M ‚àí 1 ( ¬∑ ¬∑ ¬∑  f Œ∏ )) \nTable 1 :  Different methods for three building blocks of our EoE framework: Rout- ing, Expert, and Composition.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 405,
    "augmented": false
  },
  {
    "text": "We identify  online-pruning opportunities for inferences, which can also be exploited at  frame-level ,  region-level , and  pixel-level. ‚Ä¢  We then propose a frame-level motion vector based scheme to leverage the frame-level similarity to opportunistically skip the inference by reusing the compute results memoized by the previous frame. In order to maintain high accuracy, we also propose an adaptive technique to dynamically adjust the reuse window size based on the runtime statistics by comparing the MVs in consequent frames.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "This is because more VMs or containers have to be procured to match the resource demands. 2.3.2 Ensembling Overhead \nWhile ensembling can boost accuracy with low latency, their distinctive resource hungry nature drastically increases the deployment costs when compared to single models. However, note that the ‚ÄúPacking factor‚Äù ( P f  ) for each model also impacts the deployment costs.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "TheenergyforoneReRAMrow(e DAC ),oneReRAMcell (e MAC  )andoneReRAMcolumn(e BL ,e SA‚àíRef ,e S+A )are theworst-casevaluesfromthesimulation.Table V-B 2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies. TABLEII R ELATIONSHIPOFENERGYANDTHE R E RAM TILINGSIZEAND R E RAM COPIES . Component Energyequation DAC E DAC =e DAC √óm√óaG Computation E M AC =e MAC   √óm√ón√óaG \nADC BL E BL =e BL √ón√óaG SA-Ref E SA‚àíRef =e SA‚àíRef √ón√óaG S+A E S+A =e S+A √ón√óaG \n3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 272,
    "augmented": false
  },
  {
    "text": "It is obvious that it is not feasible to train a DNN for all types and variances of human actions. Even for the same types of activity, some attributes will vary from user to user. 70 75 80 85 90 \n70 75 80 85 90 \nIter 1 Iter 10 Iter 100 Iter 1000 \nAccuracy % \nUser 1 User 2 User 3 Base Model Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, ‚Äú24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors,‚Äù in  2019 IEEE International Solid- State Circuits Conference - (ISSCC) , pp. 388‚Äì390, 2019. [7]  W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "the  Baseline , which contributes to  20%  total energy saving. As a result, they can also be deployed on top of the PTU-based SoC. ‚Ä¢  PTU+EA+AE:  Note that, our proposed  EA  and  AE  designs are ‚Äúindependent‚Äù of the underlying hardware used.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "However, this approach presents several challenges. Current storage stacks are outfitted with robust CPUs and memory systems, which are heavily tasked with state-of-the-art storage management algorithms, as evidenced by the resource utilization outlined in TABLE 1. This would ostensibly allow for the selective transfer of only pertinent exemplar data to compute servers, thereby optimizing data movement costs.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "II, computations dominate the energy consumption in  360 ¬∞ VR video processing. R EDUCING  P ROJECTION  C OMPUTATION \nAs discussed in Sec. Further, we also observed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "597‚Äì604, 2024. 21 \nInhyuk Park, Qing Zheng, Dominic Manno, Soonyeal Yang, Jason Lee, David Bonnie, Bradley Settlemyer, Youngjae Kim, Woosuk Chung, and Gary Grider. In  Companion of the 2024 International Conference on Management of Data , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Prior studies [ 56 ,  64 ,  68 ] and our empirical analysis on the quantization vs accuracy trade-offs (see Fig. 2c) indicate the 16 and 12bit precision to maximize the accuracy of the inferences while minimizing the energy consumption. Moreover, we also implement the memoization option so that it does not have to repeat infer- ences if it encounters similar data, thereby saving substantial energy as well as delivering results with extremely low la- tency.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "1221‚Äì1230, 2013. In  Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data , pp. Query processing on smart ssds: Opportunities and challenges.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "By effectively managing energy constraints and adapting to intermittent power conditions, NExUME enables more reliable and accurate monitoring in industrial environments where energy harvesting is a viable power solution. 4.4 Sensitivity and Ablation Studies of NExUME \nTo elucidate the influence of variable SLOs and hardware-specific settings on system performance, we conducted a comprehensive sensitivity study. This study involved adjusting the acceptable latency and the capacitance of the energy harvesting setup to assess their impacts on accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "2. Comparisons on loop code and ReRAM activation with tile- size activation over full-size activation. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation \nIf we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve ‚Äúcontinuous progress‚Äù under lower power supply.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "VI. We believe that the co- optimization of deep learning and energy harvesting techniques for edge devices will further invigorate research on the next generations of intelligent and sustainable IoT platforms. A CKNOWLEDGMENTS This work was supported in part by Semiconductor Research Corporation (SRC), Center for Brain-inspired Computing (C- BRIC) and NSF Grant #1822923 (SPX: SOPHIA).",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "This is because, compared with the whole frame, RoIs in these two videos are large (e.g., ratio of RoI/whole frame is 4x of that ratio in V1), which increases the computation for the PI and thus decreases the its beneÔ¨Åts. Finally, P1 and P2 are two videos with several people walking around a room. As the RoIs size increases along the video (e.g., ratio of RoIs/whole frame increases from  8%  in frame20 to  53%  in frame2470), the beneÔ¨Åts from PI become increasingly lower, resulting in similar patterns for FI+SI and FI+SI+PI.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "Since modularity is the backbone of our proposed framework, we envision a detailed simulation of the in- dividual hardware modules (e.g., chiplets, cache/memory components, on-chip and chip-to-chip networks, \netc), as shown in Figure 7 and stitching the evaluation framework for all such discrete modules together to build an ‚Äúend-to-end‚Äù modeling platform for the proposed system. Tensor cores and matrix multiplication engines will be simulated using ScaleSim v2 [137,138], while the memory hierarchy (both DRAMs and HBMs) will be rep- resented using Ramulator [36]. The interconnects within the System on Chip (SoC) connecting different chiplets as well as within a chiplet will be modeled using gem5‚Äôs [20] on-chip network implementation, GARNET [158].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 198,
    "augmented": true
  },
  {
    "text": "While \n15 \nSalient Store  is consistently performing better than H264, HEVC thanks to it‚Äôs novel approach of fine grained computation at times outperforms our approach. A similar trend is observed in other datasets. With complex and high dimensional video data, HEVC computation complexity increases exponentially, and is more pronounced because of lack of hardware support.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "The deployed edge devices perform the same analytics task (for example, monitoring the health of same type of machine at different sites) using a  random forest algorithm  (refer Algorithm-1). Since resource constraints can preempt complete execution at the edge, and sending data to the cloud is expensive due to communication energy and latency, it is essential to explore edge-cloud co-design, where we rely on the cloud if and only if it is necessary and \n2 \nbeneficial to achieve a more accurate result. Furthermore, when the deployments are geo-distributed and operated by different owners, the privacy concerns on sharing the data with a third party cloud service provider becomes challenging in developing the analytics solutions.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "https : / / machinelearning . apple . com / research / introducing-apple-foundation-models \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "Guidelines for Hyperparameter Selection and Bounds on Reward Parameters \nThe parameters  Œ≥ ,  Œ¥,  and  Œ∑  govern the reward structure of the proposed framework, influencing whether sensors participate consistently, over-participate and waste energy, or abstain altogether. This appendix provides a systematic approach to selecting these parameters, including formal bounds, practical heuristics, and an algorithmic procedure to explore suitable values. Conceptual Role of Parameters \nThe scalar  Œ≥ >  0  represents the reward scaling for correct participation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "During back- propagation, each sensor computes the gradient of the loss function  ‚àá ‚Ñì ( f Œ∏ ( x ) , y )  with respect to  Œ∏  based on locally available samples from  D . Gradient Computation and Backpropagation: Integrat- ing regularizers into the training process is straightforward due to their known closed-form gradients. The full training objective is formulated as: \nJ ( Œ∏ ) =  L ( Œ∏ ) +  Œª 1 ‚Ñ¶ SNR ( Œ∏ ) +  Œª 2 ‚Ñ¶ complexity ( Œ∏ ) , \nwhere L ( Œ∏ ) =  E ( x,y ) ‚àºD [ ‚Ñì ( f Œ∏ ( x ) , y )] , \nand  Œª 1 , Œª 2  ‚â• 0  are hyperparameters that balance accuracy, robustness, and efficiency.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 205,
    "augmented": true
  },
  {
    "text": "5b shows the results for the PAMAP2 dataset. Following are our observations: ‚Ä¢  The overall accuracy tends to improve with increasing round-robin delay time. This behaviour is expected and can be attributed to the increasing number of completed inferences.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "Are we ready for autonomous driving? the kitti vision benchmark suite. In  2012 IEEE conference on computer vision and pattern recognition , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "The main documentation that will accom- \npany the data are project reports and research publications. Since all data will be maintained in electronic format, archiving and version control will be achieved automatically via SVN software [15]. The lecture slides/videos are expected to be stored until their useful lifetime, and they will also be made available via YouTube.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "[76] Norm Jouppi, George Kurian, Sheng Li, Peter Ma, Rahul Nagarajan, Lifeng Nai, Nishant Patil, Suvinay Subramanian, Andy Swing, Brian Towles, Clifford Young, Xiang Zhou, Zongwei Zhou, and David A Patterson. Tpu v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings. In  Proceedings of the 50th Annual International Symposium on Com- puter Architecture , ISCA ‚Äô23, New York, NY, USA, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "Thus, a typical PC frame containing  10 6 \npoints [ 49 ] require  120 M  bits of data, which is impossible to transmit in real-time to the end-user‚Äôs display, from both the latency and energy standpoints, considering a \nsteady  30 - 60  f ps  requirement. Therefore, the PC video frame is compressed in the  PC Encoding  stage, before being transmitted over the  network  to the end-user. The received frame is decoded in the  PC Decoding  stage and the decoded PC frame is forwarded to the  Render and Display  stage where it is Ô¨Ånally rendered and displayed on the screen.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "Note that, this operation, which is a matrix multiplication on each FoV pixel coordinate, can be quite compute intensive. This amounts to about  2.3 GFLOPS , which represents a substantial amount of computation, given the limited compute capabilities and power in such edge devices. In fact, the number of pixels in the FoV is usually around 1 million, and the videos stream at a rate of 30 fps for an immersive experience.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Besides, employing linear ensembling techniques such as model averaging are compute intensive [ 80 ] and not scalable for a large number of available models. ‚Ä¢  Ensemble systems [ 27 , 80 ] are  not focused towards model deployment  in a public cloud infrastructure, where resource \n1 We refer to ensemble-learning as ensembling throughout the paper. USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1041 \nselection and procurement play a pivotal role in minimizing the latency and deployment costs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "To boost the inference of DNNs, some existing works employ compression (model pruning or quantization) or enhanced hardware. However, the large number of parameters employed in DNNs can result in long inference times for vision tasks, thus making it even more challenging to deploy them in the compute- and memory-constrained mobile/edge devices. Abstract ‚ÄîDeep neural networks (DNNs) are being widely used in various computer vision tasks as they can achieve very high accuracy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "5: Overall architecture with the components and the power failure handle sequence of  Us. ¬¥as . stationary; 2. input stationary; and 3. weight stationary [ 79 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "We show that ensemble models are inherently fault- tolerant over single models, since in the former, failure of a model would incur some accuracy loss without complete failure of the requests. It is observed from our failure- resilience results that  Cocktail  can adapt to instance fail- ures by limiting the accuracy loss within 0.6%. 2 Background and Motivation \nWe start by providing a brief overview of model-serving in public cloud and ensembling, followed by a detailed analysis of their performance to motivate the need for  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "The inference process is represented as a set of tasks  T  =  { T 1 , T 2 , . 3.2 DynInfer: Intermittency-Aware Inference Scheduling \nDynInfer  optimizes the inference phase of DNNs operating under intermittent power conditions. Unlike traditional systems with stable power, intermittent environments pose unique challenges for executing inference tasks efficiently and reliably.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "1 , typically consists of 5 stages: 3D content generation, PC encoding, data transmission, PC decoding, render and display. LiDAR maps spatial relationships and shapes by measuring the time taken by signals to bounce off objects and return to the scanner, while photogrammetry takes many photos from different angles to capture the target‚Äôs geometry [ 9 ]. In the  3D Content Generation  stage, the capturing device (e.g., the iPhone) uses LiDAR scanning or photogrammetry for the PC data acquisition.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Rep., jan , 2020. [62] Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Wenfei Zhou, James Coady, David Peng, Yujie Qiao, Luke Benson, Lucy Sun, Alex Wardle-Solano, Hannah Szabo, Eka- terina Zubova, Matthew Burtell, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Alexander R. Fabbri, Wojciech Kryscinski, Semih Yavuz, Ye Liu, Xi Victoria Lin, Shafiq Joty, Yingbo Zhou, Caiming Xiong, Rex Ying, Arman Cohan, and Dragomir Radev. Folio: Natural language reasoning with first-order logic.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 233,
    "augmented": false
  },
  {
    "text": "Observing this, we propose a ‚Äúweighted accuracy metric‚Äù, where the weight of each of the model is a function of the accuracy, time needed and power availability. Furthermore, we allow some slack to the weighted accuracy so that the optimizer can choose a better set of hyperparameters if we can reach  close to  the weighted accuracy with much lower resource (power or compute) consumption. Typically, there is an inverse correlation of the convergence of the stochastic gradient descent (SGD) algorithm, the most popular training algorithm for DNNs, over the number of iterations ( n i ) [ 68 ]: l  ‚àù O ( 1 / n i )  and  l  = 1 Œ≤ 0 .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "In this direction, we plan to use/augment these models by investigating microarchitectural, architectural and system level impacts on training and inference processes. 4 Broader Impacts Research Ramifications : While LLMs have recently gained significant attention specifically in paving the way for Generative AI, the monolithic design of such models have made training and inference pro- hibitively expensive. In this context, our project takes an ambitious step to  democratize  LLM models by exploring the design space of morphable EoEs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "E XPERIMENTAL  E VALUATION AND  R ESULTS \nIn this section, we describe our evaluation methodology and evaluate both privacy-preserving and data-sharing partitioning strategies compared with a traditional random-forest approach. We apply our techniques on Appliance energy prediction data [3], and also provide a case analysis of material surface roughness prediction using real world grinding-machine sensor data. We analyze the accuracy-latency trade offs of each strategy and show their benefits in different scenarios.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "2: Similarity study. 0% \n5% \n10% \n15% \n0 2 4 6 8 10 12 14 16 Pixel-level Difference \n95% of the pixels differ within 3 \n(b) Distribution of pixel-level difference across two adjacent frames. Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Both are assumed convex and have bounded gradients. The final training objective is: \nJ ( Œ∏ ) =  L ( Œ∏ ) +  Œª 1 ‚Ñ¶ SNR ( Œ∏ ) +  Œª 2 ‚Ñ¶ complexity ( Œ∏ ) , \nwhere  Œª 1 , Œª 2  ‚â• 0  are hyperparameters controlling the influ- ence of the regularizers. ‚Ñ¶ SNR ( Œ∏ )  encourages the model to perform reasonably well across varying SNR levels, while  ‚Ñ¶ complexity ( Œ∏ )  penalizes overly complex models that might demand excessive energy or communication costs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Entropy Encoding:  To further compress the generated occupy bits vector, a typical encoding technique ‚Äì Entropy Encoding [ 35 ], [ 60 ] ‚Äì is employed. This is because that all the nodes in the tree are traversed sequentially. ‚Ä¢  Compressed Geometry Stream (Output):  The Ô¨Ånal com- pressed geometry output stream is ready to be stored in the memory or streamed over the network.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "IEEE Computer Society. In  2024 ACM/IEEE 51st Annual International Symposium on Computer Ar- chitecture (ISCA) , pages 1005‚Äì1017, Los Alamitos, CA, USA, Jul 2024. Alisa: Accelerating large language model inference via sparsity-aware kv caching.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Salient Store  utilizes the state-of- the-art neural compression which partially uses the inference/ exemplar selection pipeline along with layered neural codecs to compress the video data. It also uses the motion vectors as a latent space to effectively use the inter-frame similarity, thereby further increasing the compression ratio. Salient Store  also provides a hardware accelerated lattice-based quantum safe encryption mechanism.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "The PIs will leverage their complementary experience in developing appropriate research thrust areas within the scope of LLM to attract and engage a new cohort set of minority undergraduate students in research. We plan to provide hands-on computer architecture experience to students and show them how modern computer systems can address important societal challenges, specifically how LLMs can be used in many such domains. PI Zhang has offered an NSF REU seminar and mentored an NSF REU student on a project investigating the intersection of LLMs and code generation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "While previous works have de- signed energy-efÔ¨Åcient training hardware with support for variable precision training, none have adapted to variable energy income. Hardware Innovation:  Us.¬¥as embraces the intermittency en- tailed by harvesting and advocates for hardware adaptation (resizing) to efÔ¨Åciently manage variable power income and avoid power emergencies. The robust exemplar selection and micro-proÔ¨Åling mechanisms are discussed and evaluated in ¬ß III-B  and ¬ß III-C , respectively.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "1‚Äì26, 2022. [42] D. Kang, J. Emmons, F. Abuzaid, P. Bailis, and M. Zaharia, ‚ÄúNoscope: \nOptimizing deep cnn-based queries over video streams at scale.‚Äù  Proc. VLDB Endow.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "[11]  Yu Feng, Paul Whatmough, and Yuhao Zhu. 2019. ASV: Accelerated Stereo Vision System.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "For other high-demanding applications like AR-based surgery [ 11 ], our proposals may jeopardize the video quality, and consequently, we may need further software and/or hardware optimizations for improved user experience. Correlation with the evaluations on smartphones:  Based on our proÔ¨Åling, the power consumption of our proposal is ‚âà 4 W , which is below the peak discharge power of modern smartphones (10W [ 2 ], [ 70 ]), meaning that our proposal will work Ô¨Åne on smartphones as well. To further prove this, we also change the compute mode of Jetson AGX Xavier board to 10W, and measure the execution latency for loot video [ 54 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "14‚Äì26, 2016. [4]  P. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang, and Y. Xie, ‚ÄúPRIME: A novel processing-in-memory architecture for neural network computation in reram-based main memory,‚Äù in  2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA) , pp. 27‚Äì39, 2016.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": ", f n } 2:  Output:  Compressed frames  C  =  { c 1 , c 2 , . . .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Haibo Zhang, Prasanna Venkatesh Rengasamy, Shulin Zhao, Nachiappan Chidambaram Nachiappan, Anand Sivasubramaniam, Mahmut T. Kandemir, Ravi Iyer, and Chita R. Das. GeoInformatica , 20:59‚Äì94, 2016. Race-to-sleep + content caching + display caching: a recipe for energy-efficient video streaming on handhelds.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "We also thank the NSF Chameleon Cloud project CH-819640 for their generous compute grant. All product names used here are for identification purposes only and may be trademarks of their respective companies. This research was partially supported by NSF grants #1931531, #1955815, #1763681, #2116962, #2122155 and #2028929.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Fig. 1  depicts our experimental investigations on data drift, encompassing training and testing multiple DNNs on diverse datasets such as Urban TrafÔ¨Åc [ 12 ], [ 97 ], 3D Point Cloud [ 14 ], [ 24 ], and audio [ 78 ]. The similar trends across these results highlight the impact of varying time windows and encounter- ing diverse scene changes, leading to degradation in network accuracy by up to 30%.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Note that we deal with the possibility of container overprovisioning due to the in- creased function weights by allowing both  Connectivity  and Commonality  to be capped at a certain value. 4.1.2 Proactive Container Provisioning : Once function weights are assigned by considering the above factors, they are employed in estimating the number of containers needed per DAG stage ( Estimate_Containers  in Algorithm 1). These containers have to be provisioned in advance to service fu- ture load to shield the end user from the effects of cold starts \nand thereby meet the SLO.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "7 ms on an edge GPU 3 . This 10 √ó  performance gap between the practical scenario and the ideal case (and the large amount of power/energy consumption this task makes) motivates us to focus on holographic processing in this paper, and explore the opportunities for improv- ing the hologram computational efficiency to speed up the overall AR application execution and reduce its energy consumption. 2 In this paper, we mainly use the popular depthmap input method.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "K12 and Outreach : Our outreach plans include involvement of underrepresented groups in computer science and engineering and various K-12 related activities. One example is the Science-U camp at Penn State, which is designed to take K-12 students through a one-week journey that investigates an area of STEM in an exciting way. A detailed description of our  BPC plan  is in- cluded as a supplementary document.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "5b), limiting the memoization opportunities to those instances. Such low reuse ratio is expected because of the high sensitivity of the IMU sensors. However, a higher reuse ratio can be achieved by relaxing the precision of the IMU output.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Note that  RD upper bound  can vary across different use cases from parking lot to busy roads and hence, can be set accordingly \n1077 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "on Robotics and Automation (ICRA) . Conf. [54]  Liang Shi, Beichen Li, Changil Kim, Petr Kellnhofer, and Wojciech Matusik.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "0 200 400 600 800 1000 1200 \n1 2 4 8 16 32 64 \nExec. Latency (ms) \n# Depth Planes \nForward Backward \n(b) Latency w/ num of depth planes. Figure 4: Depthmap hologram algorithm details.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "This paper presents a novel scheduling policy along with an adaptive ensemble learner to efÔ¨Åciently perform HAR on a distributed energy-harvesting body area network. Our proposed policy,  Origin , strategically ensures efÔ¨Åcient and accurate indi- vidual inference execution at each sensor node by using a novel activity-aware scheduling approach. It also leverages the continu- ous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve Ô¨Ånal classiÔ¨Åcation accuracy.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "Now, the HC is quantized and entropy encoded, while the LC is further sent to the next  RAHT and Quantization  round and serves as the attribute of the large voxel/leaf in the upper layer. This procedure is repeated until we reach the root node. In this example, eventually the coeffs vector contains  [ 2 , 0 , 89 ] , which can be further compressed by entropy encoding.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "1 Introduction \nMachine Learning (ML) has revolutionized user experience in various cloud-based application domains such as product recommendations [ 70 ], personalized advertisements [ 44 ], and computer vision [ 13 ,  43 ]. The RM framework leverages transient virtual machine (VM) in- stances to reduce the deployment cost in a public cloud. A prototype implementation of  Cocktail  on the AWS EC2 plat- form and exhaustive evaluations using a variety of workloads demonstrate that  Cocktail  can reduce deployment cost by 1.45 √ó , while providing 2 √ó  reduction in latency and satisfy- ing the target accuracy for up to 96% of the requests, when compared to state-of-the-art model-serving frameworks.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "02%) accuracy loss. ‚Ä¢  Efficient Computation:  We augment a state-of-the-art EH-sensor node with quantized DNNs to increase the num- ber of accurate inferences at the edge (by up to 40%). We leverage data memoization to skip unnecessary compute saving inference execution time and energy.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Compiler-directed application mapping for noc based chip multiprocessors. ACM SIGPLAN Notices , 42(7):155‚Äì157, 2007. [25] Tianqi Chen, Benjamin Moreau, Chunting Zheng, Yutian Tang, Zijian Yan, Yanan Song, Yuhao Jia, Maximilian Seeger, Lingfeng Wang, and Hai Bian.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "These savings can go up to 48% compared to  Arch  for applications like  Social Network . The resultant energy savings of  Kraken  are a direct consequence of the savings in computation and memory usage from the fewer containers spawned. Only  DProb  and SProb  consume lesser energy than  Kraken  (4% lesser), due to their more aggressive container reduction approach.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Given all the other models have higher accuracy, the least accuracy we can expect with such an ensemble is 83%. This analysis forms the base of our ensemble technique, and hence proving the combination of multiple available models can be more accurate than the most accurate individual model. B Why DeepARest Model?",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "These hardware components are designed to be flex- ible and scalable, allowing customization to specific computational needs. By leveraging reconfigurable chiplet-based architectures, we aim to optimize hardware efficiency, reduce power consumption, and min- imize the environmental footprint of AI operations. Through this integrated approach, we aim to lower the barriers to entry for AI development.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": ", 1(1), June 2017. [69]  Prateek Sharma, Stephen Lee, Tian Guo, David Irwin, and Prashant Shenoy. Spotcheck: Designing a derivative iaas cloud on the spot market.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "IEEE Embedded Systems Letters , 2022. Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Green Data Centers:  As sustainability gains traction, industry has worked towards building green data centers [ 58 ], [ 59 ]. Similarly, Ekya [ 12 ] only focuses on co-location of computation, and it‚Äôs efÔ¨Åciency on Ô¨Ånishing compute even on a custom hardware is shown in Fig. 4 .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "The RM framework leverages transient virtual machine (VM) in- stances to reduce the deployment cost in a public cloud. A prototype implementation of  Cocktail  on the AWS EC2 plat- form and exhaustive evaluations using a variety of workloads demonstrate that  Cocktail  can reduce deployment cost by 1.45 √ó , while providing 2 √ó  reduction in latency and satisfy- ing the target accuracy for up to 96% of the requests, when compared to state-of-the-art model-serving frameworks. 1 Introduction \nMachine Learning (ML) has revolutionized user experience in various cloud-based application domains such as product recommendations [ 70 ], personalized advertisements [ 44 ], and computer vision [ 13 ,  43 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "PSNR (%) \nEnergy Savings (%) \n(b) Trade-offs. 0% \n20% \n40% \n60% \n80% \n100% \n0% 20%40%60%80%100% \norm. InterHolo IntraHolo InterIntraHolo \nPSNR \n(a) PSNR.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Common crawl corpus. https://commoncrawl.org , 2024. Accessed: 2024-10- 18.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "443‚Äì461, 2011. [13]  M. Mangrulkar and S. G. Akojwar, ‚ÄúA simple and efÔ¨Åcient solar energy harvesting for wireless sensor node,‚Äù in  2016 Second International Con- ference on Research in Computational Intelligence and Communication Networks (ICRCICN) , pp. 95‚Äì99, 2016.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "different load arrival patterns, we design a DeepAR- estimator (DeepARest) based prediction model. We zeroed in on the choice of using DeepARest by conducting (Table  4 ) an in-depth com- parison of the accuracy loss when compared with other state-of-the-art traditional and ML-based prediction models used in prior works [ 47 ,  86 ]. As shown in Algorithm  2 , for every model under a periodic scheduling interval of 1 minute ( T s ), we use the  Predicted _load ( L p ) at time  T  +  T p  and compare it with the  current_load  to determine the number of instances ( I n ).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "Here, we quantify the video quality with the popular Peak Signal-to-Noise Ratio (PSNR, normalized to the ground-truth; the higher, the better) [25], [40]. 5c, to provide an intuitive comparison in different scenarios. From Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "This helps us avoid unnecessary proÔ¨Åling (up to 41%). The micro-proÔ¨Åler, having run multiple sweeps, returns a set of hyper-parameters ( Œ® i ) for each model which is then stored in a history table. When introduced to a new set of constraints (change of power availability, accuracy etc.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "In fact, a recent study from CSET [100] estimates that the cost of building LLMs will move to trillions in roughly 36 months! These numbers are astonishing and underline the intense interest and investment that this domain has garnered. It is also equally important to note the impact of LLMs on the environment.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "(categorized by dotted lines) picked in the increasing order of accuracy. Each of these picked constraints (named const1 - const5 in the Figure) represents a single baseline model, whose corresponding ensemble size ranges from small (2) to large (10), as shown in Table  3 . Note that the latency is the raw model execution latency, and does not include the addi- tional network-transfer overheads incurred.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "With such knowledge, for Frame-2, we can observe that the bounding box and the MVs mostly overlap (with an overlap ratio of 0.71 in the left case), which indicates that the objects have barely moved. Thus,we can safely  skip  the inference for Frame-2, and simply reuse the result from Frame-1, as shown in  5  . However, for Frame-3, the motion vectors generated by codec (  6  ) drift away from the bounding box in Frame- 1 (with an overlap ratio of 0.6 in the right case), indicating that the object has moved/shifted a signiÔ¨Åcant distance.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "1 illustrates the data flow in an edge server, where video data are first encoded (using H264 or similar codecs), then encrypted (with RSA or similar standards), and finally stored across a distributed set of disks to ensure redundancy (e.g., RAID 5). These processes create a complex data-flow pipeline, differentiating two streams of video data: one for real-time inference and training, and another for archival. Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "In  International Conference on Machine Learning , pages 31094‚Äì 31116. PMLR, 2023. [147] Haizhou Shi, Zihao Xu, Hengyi Wang, Weiyi Qin, Wenyuan Wang, Yibin Wang, and Hao Wang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "It can be observed from this figure that, even with the most aggressive approximation introduced by  Inter-Intra-Holo , the video quality is still sufficient for most of the AR applications (30 . 7 on average) [57]. Further, to study how the tuned approximation (in Algo.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "This creates a sampling ‚Äúbias‚Äù [ 70 ] while performing the training, and often leads to catastrophic forgetting. Fig. 3  shows a typical trafÔ¨Åc distribution from Urban TrafÔ¨Åc data [ 97 ]) and the impact of sampling bias on class distribution.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "[14] L. Gong, C. Wang, X. Li, H. Chen, and X. Zhou, ‚ÄúA Power-EfÔ¨Åcient and High Performance FPGA Accelerator for Convolutional Neural Net- works: Work-in-Progress,‚Äù in  Proceedings of the Twelfth IEEE/ACM/I- FIP International Conference on Hardware/Software Codesign and System Synthesis Companion , 2017. [15] J. Wang, J. Lin, and Z. Wang, ‚ÄúEfÔ¨Åcient Hardware Architectures for Deep Convolutional Neural Network,‚Äù  IEEE Transactions on Circuits and Systems I: Regular Papers , pp. 1941‚Äì1953, 2017.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "IEEE, 2021. Jaeyoung Do, Yang-Suk Kee, Jignesh M Patel, Chanik Park, Kwanghyun Park, and David J DeWitt. Query processing on smart ssds: Opportunities and challenges.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "To prune, or not to prune: exploring the efficacy of pruning for model compression. Advances in Neural Information Processing Systems , 35:7103‚Äì7114, 2022. [198] Michael Zhu and Suyog Gupta.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "[72] Natalie Enright Jerger, Ajaykumar Kannan, Zimo Li, and Gabriel H Loh. Noc architectures for silicon interposer systems: Why pay for more wires when you can get them (from your interposer) for free? In  2014 47th Annual IEEE/ACM International Symposium on Microarchitecture , pages 458‚Äì470.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "[31]  G. Venkatesh, E. Nurvitadhi, and D. Marr, ‚ÄúAccelerating deep con- volutional networks using low-precision and sparsity,‚Äù in  2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp. 2861‚Äì2865, 2017. [32]  I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, ‚ÄúQuantized neural networks: Training neural networks with low precision weights and activations,‚Äù  J. Mach.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 136,
    "augmented": false
  },
  {
    "text": "[49]  Martin Persson, David Engstr√∂m, and Mattias Goks√∂r. In  ACM SIGGRAPH 2020 Emerging Technologies (SIGGRAPH ‚Äô20) . Association for Computing Machinery.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Image Quality Evaluation and Control of Computer-generated Holograms. 2016. In  Practical Hologra- phy XXX: Materials and Applications , Hans I. Bjelkhagen and V. Michael Bove Jr.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Recall from Fig. 3  a  that, there also exists spatial locality for attribute compression, which can be identiÔ¨Åed with the help of the Morton code. Let us now consider the example in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Allotting stage-wise SLOs to each function in a chain in proportion to their execution times reveals that there are cases where there is significant difference (slack) between the function‚Äôs expected SLO and its run-time. Figure 7 depicts this slack for all functions in the applications considered. This slack is leveraged by  Kraken  by batching multiple requests to the functions by queueing requests at their con- tainers.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "The impossibility of infinite improvement sequences guarantees the existence of an NE, and the assumptions on monotonicity, boundedness, and discounting ensure that the iterative best-response process converges to this equilibrium. The proof relies on constructing a potential function  Œ¶  that is strictly increased by unilateral profitable deviations and bounded above. ‚ñ° \nC. Proof of Convergence for the Equilibrium-Aware Training Process \nIn this appendix, we provide a comprehensive and detailed proof of the convergence theorem stated in the main text.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "Asso- ciation for Computing Machinery. [175] Ziyu Ying, Shulin Zhao, Haibo Zhang, Cyan Subhra Mishra, Sandeepa Bhuyan, Mahmut T. Kan- demir, Anand Sivasubramaniam, and Chita R. Das. Exploiting frame similarity for efficient inference on edge devices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Ensemble-spot is explained further in the next section. We compare the cost of hosting ensembles using both spot (ensemble-spot) and OD (ensemble-OD) instances with the single models hosted on OD (single-OD) instances. However, they do not right-size the model selection to include models which primarily contribute to the major- ity voting.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "However, they do not right-size the model selection to include models which primarily contribute to the major- ity voting. The beneÔ¨Åts of  P f  is contingent upon the models chosen by the model selection policy. Existing ensemble model se- lection policies used in systems like Clipper use all off-the- shelf models and assign weights to them to calculate accu- racy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Porting ai/ml models to intelligence processing units (ipus). In  Practice and Experience in Advanced Research Computing 2023: Computing for the Common Good , PEARC ‚Äô23, page 231‚Äì236, New York, NY, USA, 2023. Association for Computing Machinery.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "ITU-T Recommendation H.264. International Telecommunication Union, June 2019a. URL  https://www.itu.int/rec/T-REC-H.264 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "A storage platform entirely designed with CSDs is not pragmatic at the current time because of their exorbitant cost and power consumption (AMD, b; Cao et al., 2020) . Edge Server \nPCIe Root COmplex \nFPGA \nCSD \nCSD \nFPGA \nAccelerator \nFigure 2: High-level design of the  Salient Store  edge server - it consists of the accelerated video analytics compute along with computational storage and classical storage drives. However, a combination of CSDs with classical storage medium provides the most optimal solution and hence motivates our design.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "2020. Neural Holography. In  ACM SIGGRAPH 2020 Emerging Technologies (SIGGRAPH ‚Äô20) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Fine-tuning language models with just forward passes. Advances in Neural Information Processing Systems , 36:53038‚Äì53075, 2023. [102] Avinash Maurya, Robert Underwood, M. Mustafa Rafique, Franck Cappello, and Bogdan Nicolae.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Compression EfÔ¨Åciency:  To investigate how the compression efÔ¨Åciency changes with the above schemes, in Fig. 8c , we plot the compressed size (in megabytes) shown on the primary y-axis (left), and the PSNRs (in dB) for attributes 8   on the secondary y-axis (right), and observe that: ‚Ä¢  TMC13:  compresses the input frame size to be only  8%  of the original while preserving the best video quality (PSNR is  55 dB). This is mainly because TMC13 performs lossless geometry compression and almost-lossless attribute com- pression in our settings.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "[31] K. Simonyan and A. Zisserman, ‚ÄúVery Deep Convolutional Networks for Large-scale Image Recognition,‚Äù  arXiv preprint arXiv:1409.1556 , 2014. [32] Klaus Hinum, ‚ÄúQualcomm Adreno 640,‚Äù ‚Äùshorturl.at/btCH3‚Äù, 2018. [33] Kitware, Inc., ‚ÄúThe VIRAT Video Dataset,‚Äù ‚Äùhttps://viratdata.org‚Äù, 2011.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "USENIX Association. [36]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Nachiappan C.Nachiappan, Mahmut Taylan Kandemir, and Chita R. Das. Fifer: Tackling Resource Underutilization in the Serverless Era.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Datasets Full Power AP PT iNAS+PT Stateful ePerceptive DynBal NExUME \nFMNIST 98.70 71.90 79.72 83.68 85.40 86.25 87.50 88.90 CIFAR10 89.81 55.05 62.00 66.98 68.50 70.20 71.75 76.29 MHEALTH 89.62 59.76 65.40 71.56 73.80 74.95 76.10 80.75 PAMAP 87.30 57.38 65.77 70.33 72.20 73.35 74.50 75.16 AudioMNIST 88.20 67.29 73.16 75.41 76.80 77.95 78.60 80.01 Table 1: Accuracy comparison on TI MSP board using piezoelectric energy harvesting. As observed in Table 1, NExUME consistently outperforms the state-of-the-art methods across all datasets. For instance, on CIFAR10, NExUME achieves an accuracy of 76.29%, which is approximately 4.54% higher than DynBal, the next best method.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 285,
    "augmented": false
  },
  {
    "text": "ACM SIGARCH Computer Architecture News , 34(2):130‚Äì141, 2006. [92] Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. The dawn after the dark: An empirical study on factuality hallucination in large language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "D√©j√† View: Spatio-Temporal Compute Reuse for Energy-Efficient 360 ¬∞  VR Video Streaming. In  Proceedings of the International Symposium on Computer Architec- ture (ISCA) . 241‚Äì253.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. performs linear transformations on the attribute data of each voxel pair (the voxel in level n  and its siblings along x, y, and z dimensions) to obtain a low-pass component and a high- pass component.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "This can be extended further adopting a round-robin activation schedule to both increase harvesting periods per initiated in- ference on each node while increasing the odds that at least some node is attempting an inference at any given time. So long as the number of skipped inferences is modest, there will still likely be samples processed before an activity Ô¨Ånishes. Therefore, there is an opportunity to skip some intermediate inferences over the period of an activity in order to increase harvesting duration and the prob- ability that an initiated inference will complete.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "Otherwise, as can be seen from Line  6  to Line  8  in Algo. Scenario-3, it indicates that the object(s) in the current frame are different from the last inference outputs (i.e., ‚Äúmissed‚Äù in Scenario-2, or ‚Äúentering/exiting‚Äù in Scenario-3) and hence, requires full inference (refer to Line  5  in Algo. 2).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Deploying sufÔ¨Åcient battery resources to allow intermittency-unaware designs to operate on solar power is neither efÔ¨Åcient nor sustainable. Given enough time even na¬®ƒ±ve low power hardware can Ô¨Ånish training, but will have longer periods where the drift is exposed. C. Hyperparameters: The Right Way to Learn \nAfter Ô¨Ånalizing the training set for continuous learning, the next challenge is to learn within the power and time budget.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "5 J energy, respectively, which translate to  ‚âà 97%  energy savings w.r.t. CWIPC. Note that, although our schemes employ the GPU with an extra overhead (e.g., the GPU power is about 1065 mW ), the CPU power is reduced (e.g., around  1310 mW , lower than that in TMC13 and CWIPC) since most of the computations are ofÔ¨Çoaded to GPU.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Storage controllers, typically constrained by I/O bandwidth, are now being complemented by the vast internal bandwidth of solid-state drives (SSDs), making them prime candi- dates for near-data processing. Why Not? Exploring the realm of computational storage drives presents a tantalizing avenue for on-disk com- puting capabilities.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "These strategies ensure that the system remains operational and provides degraded but acceptable performance under severe energy constraints. Novelty in Energy-Aware Scheduling:  While energy-aware scheduling is not novel in itself, our contribution lies in adapting scheduling algorithms specifically for intermittent power environments. Existing scheduling algorithms typically assume stable energy availability and do not account for the atomicity constraints imposed by intermittent power supply.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Similarly, Ekya [ 12 ] only focuses on co-location of computation, and it‚Äôs efÔ¨Åciency on Ô¨Ånishing compute even on custom hardware is shown in Fig. 4 . 0 25 50 75 100 \nMN-BL \nTeacher \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-BL \nTeacher \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nNa√Øve w/Exemplar \nAccuracy in % \nHour-0 Hour-2 Hour-4 Hour-6 Hour-8 \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "Thus, the inner part of the output is only related to the RoIs of input; the middle part is related to both the RoIs and the BG; and the outer part is only related to the BG. Fig. 5: Back-tracing from  out  to  in  for CONV.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "‚ñ° \nC. Proof of Convergence for the Equilibrium-Aware Training Process \nIn this appendix, we provide a comprehensive and detailed proof of the convergence theorem stated in the main text. We also elaborate on how the new loss function, the introduced regularizers, and their gradients integrate into the backprop- agation and stochastic gradient descent (SGD) steps. Addi- tionally, we discuss bounds on the newly introduced hyper- parameters and provide guidelines for selecting them.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "[62]  Point Cloud Library Contributors, ‚ÄúModule kdtree - Point Cloud Library (PCL),‚Äù  ‚Äùhttps://pointclouds.org/documentation/ group kdtree.html‚Äù , 2022. [64]  Point Cloud Library Contributors, ‚ÄúPcl gpu octree,‚Äù  ‚Äùhttps: //github.com/PointCloudLibrary/pcl/tree/master/gpu/octree‚Äù , 2022. [63]  Point Cloud Library Contributors, ‚ÄúModule octree - Point Cloud Library (PCL),‚Äù  ‚Äùhttps://pointclouds.org/documentation/ group octree.html‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "‚Ä¢  CWIPC:  CWIPC takes about  4229 ms  (mainly for geometry compression as the attributes are directly entropy-encoded without any other efforts, as mentioned in Sec. From this plot, the following observations can be made: ‚Ä¢  TMC13:  TMC13 takes around  4152 ms  to compress one PC frame, including  1552 ms  for geometry compression and 2600 ms  for attribute compression. The primary y-axis (left) shows the latency in  ms  for SOTAs, whereas the secondary y-axis (right) gives the latency in  ms  for our proposals.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "MongoDB: the deÔ¨Ånitive guide: powerful and scalable data storage . \" [21]  Kristina Chodorow. In  Advances in Neural Information Processing Systems (NeurIPS) , 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "Patterns for Serverless Functions (Function-as- a-Service): A Multivocal Literature Review.. In  CLOSER . 181‚Äì192.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "[8]  2020. IBM-Composer. https://cloud.ibm.com/docs/openwhisk?topic= cloud-functions-pkg_composer.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 21st International Middleware Conference . 1‚Äì13. [44]  Arjun Singhvi, Kevin Houck, Arjun Balasubramanian, Mo- hammed Danish Shaikh, Shivaram Venkataraman, and Aditya Akella.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "\"https://github.com/ google-research-datasets/Objectron/blob/master/index/book_annotations\". [40]  Objectron. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University. The authors also greatly appreciate Dr. Yongpan Liu, Dr. Kaisheng Ma, Dr. Xulong Tang and Mr. Challapalle Nagadastagiri Reddy‚Äôs useful discussion. R EFERENCES \n[1]  C. Xia, J. Zhao, H. Cui, and X. Feng, ‚ÄúCharacterizing DNN models for edge-cloud computing,‚Äù in  2018 IEEE International Symposium on Workload Characterization (IISWC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "Discussion:  Although  Origin  is proposed and works for energy harvesting wireless sensor networks, it can also be used with battery-powered or hybrid (a combination to battery powered and EH) systems to minimize the energy footprint while maximizing the accuracy. Furthermore, it uses multiple sensors effectively and hence poses minimum risk if one of the sensors fails. This makes  Origin  versatile and suitable for systems whose intermittence comes from either or both of power or device reliability limitations, both of which will be key factors in real-world IoT deployments.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Our solution will leverage our previous work on multi-stage summarization [186] and multi-agent framework for long-context tasks [187]. Modeling Expert Type-Subtype Hierarchy with Tree Ensemble-of-Experts. Since knowledge domains often exhibit a hierarchical structure, it is natural to model an EoE using a hierarchical approach to save training and inference costs further.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Peacock Panda Quill Slug Cup Class \n0 \n50 \n100 \nAccuracy \nMNetV2 IRV2 NASLarge \nFigure 4:  Class-wise Accuracy. Figure  4  shows the class-wise accuracy for three models on 5 distinct classes. Therefore, a full-ensemble model participation is not required for all the inputs because, every model is in- dividually suited to classify certain classes of images when compared to other classes.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "\"https://github.com/google- research-datasets/Objectron/blob/master/index/bike_annotations\". 2020. Objectron Dataset Annotation: bike.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Table  4  shows the root mean squared error (RMSE) in- curred by all the models. It is evident that the LSTM and DeepAREst have lowest RMSE value. The ML models used in these experiments are pre-trained with 60% of the Twitter arrival trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "[4] ‚ÄúGoogle assistant for wearables,‚Äù 2020, https://assistant.google.com/platforms/wearables/. [5] K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúSpendthrift: Machine learning based resource and fre- quency scaling for ambient energy harvesting nonvolatile processors,‚Äù in 2017 (ASP-DAC) , 2017, pp. 678‚Äì683.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2401.04088 , 2024. [75] Ziheng Jiang, Haibin Lin, Yinmin Zhong, Qi Huang, Yangrui Chen, Zhi Zhang, Yanghua Peng, Xiang Li, Cong Xie, Shibiao Nong, Yulu Jia, Sun He, Hongmin Chen, Zhihao Bai, Qi Hou, Shipeng Yan, Ding Zhou, Yiyao Sheng, Zhuo Jiang, Haohan Xu, Haoran Wei, Zhang Zhang, Pengfei Nie, Leqi Zou, Sida Zhao, Liang Xiang, Zherui Liu, Zhe Li, Xiaoying Jia, Jianxi Ye, Xin Jin, and Xin Liu. { MegaScale } : Scaling large language model training to more than 10,000  { GPUs } .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 236,
    "augmented": false
  },
  {
    "text": "The entire process of importance sampling uses simple arithmetic operations and is therefore viable in energy-scarce situations. The host can take the sub-sampled data and perform inference. The caveat is to have a model trained on the sub-sampled data, which can be done as an one-time step.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "This re- search is supported by NSF grant #1822923 and Clean Energy Smart Manufacturing Innovation Institute award #136067. We believe that our solution can be easily deployed and be beneficial for random forest based distributed sensing-computing platforms. A CKNOWLEDGEMENTS \nWe thank the reviewers for their helpful feedback.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "To perform the convolution operation, the input signal is applied to the rows of the x-bar, and the weights are applied to the columns in a structured way. The output signal is obtained by summing the weighted input signals over a sliding window, which moves across the input signal to compute the convolution. Specifically, the weights are arranged in a way that mimics the convolution operation, such that each weight corresponds to a specific location in the input signal.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Peeking Behind the Curtains of Serverless Plat- forms. In  ATC . [9]  Neeraja J. Yadwadkar, Francisco Romero, Qian Li, and Christos Kozyrakis.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Thus, depending on the model sub- set used in the ensemble, it achieves better accuracy than the baseline at lower latencies. Note that in our example model-set, the beneÔ¨Åts of ensembling will diminish for lower \nNASLarge IRV2 Xception DNet121 NASMob \n0.5 \n1.0 \n1.5 \nAccuracy Loss(%) \nStatic Single \n(a)  Accuracy loss compared to full- ensemble. NASLarge IRV2 XceptionDNet121 NASMob 0 \n2 \n4 \n6 \nCost($) \nSingle-OD Ensemble-OD Ensemble-spot \n(b)  Cost of full-ensembling hosted on OD and Spot instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "The missing piece in complex analytics: Low latency, scalable model man- agement and serving with velox. arXiv preprint arXiv:1409.3809 , 2014. [26]  Daniel Crankshaw, Gur-Eyal Sela, Corey Zumar, Xiangxi Mo, Joseph E. Gonzalez, Ion Stoica, and Alexey Tumanov.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Next, as discussed in Sec. As for Frame-3, only the RoIs (in purple) are passed to the DNN layers (Step  3  ), and we generate the corresponding PI-outputs (in yellow) in Step  4  . Recall that, Frame-1, as the base frame, has to do the full inference (Step  1  ), and output the feature maps for each layer (Step  2  ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "The video frames are transmitted to the users, who wear a portable VR headset (like Facebook Oculus or Google Cardboard), via  Youtube  or  Facebook 360  services [7], [61]. 360 ¬∞ video streaming creates an interactive and immersive environment by connecting the user and the video content; the users are allowed to move their heads‚Äô orientation to enjoy the surroundings in all perspectives along with a 3D view, i.e., a different view for each of the eyes, and hence creating an illusion that the user is present at the scene rather than viewing it on a projected surface. They are further encoded by the conventional video encoders, as if they are planar videos, for transmission efÔ¨Åciency.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "intel.com/content/www/us/en/transportation/urban-mobility.html . (Accessed on 11/21/2022). Custom On-Device ML Models with Learn2Compress.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "¬¥as  is designed to handle dense and noisy data, it outperforms the respective state-of-the-arts (which were tuned for small, clean benchmark data). Observe that, as  Us. 903 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Output Reg. Pool Unit FC Unit \nAdder Tree \nResiRCA \nReRAM crossbar \n... \nADC&S+A \nDAC \nReRAM crossbar \nƒÇ \nTx/RX \nEnergy Harvestor Sensors \nEnergy harvesting (EH) \n... Battery (B) \nB \nEH \nƒÇ Sigmoid \n... \nReRAM Memory \nBasic MCU System \nB \nEH EH \nEH \nEH \nB \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Such capabilities not only enhance user experience by minimizing buffering and maximizing video quality but also optimize bandwidth usage, presenting a cost-effective solution for content providers. These technical advancements position neural codecs as potential game-changers in the video streaming industry (NVIDIA Corporation, 2024), promising significant improvements in efficiency, scalability, and flexibility in various streaming scenarios. One major issue with neural codecs are their lack of utilization of inter-frame similarity.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "As expected, the throughput increases as  G  grows for every benchmark. Another interesting observation is that the results of  ResiSchedule  policy can be competitive to that of  Sequential policy when  G  is small and vice versa. The main reason for this is that the  ResiSchedule  policy can efÔ¨Åciently organize more hardware resources than the  Sequential  policy when hardware resources are limited.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "Thus, it is a critical feature in projection computation executions. ‚Ä¢  Pixel values:  The pixel contents/values (denoted as  F  in Fig. 3) matter only during data transfer (from the input 360 ¬∞ frame to the framebuffer) in the projection mapping stage, after the coordinate mappings ( P  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Figure  4  shows the class-wise accuracy for three models on 5 distinct classes. It can be seen that for simpler classes like Slug,  MNetV2  can achieve similar accuracy as the bigger models, while for difÔ¨Åcult classes, like Cup and Quill, it experiences up to 3% loss in accuracy. Since the model participation for ensembling can vary based on the class of input images being classiÔ¨Åed, there is a scope to develop a dy- namic model selection policy that can leverage this class-wise variability to intelligently determine the number of models required for a given input.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "1 and Sec. ‚Ä¢  Apart from the viewing window, the dense or sparse hologram computing is also RoF-dependent, which is the main idea be- hind foveated rendering [ 25 ,  47 ,  62 ], as discussed in Sec. We use such a viewing-window based ‚Äúsub-hologram‚Äù technique which has already been proposed in prior works (such as Sub-Hologram [ 52 ]) as the  Baseline  design.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight. In the PRIME conÔ¨Åguration, the ReRAM-based Full Function (FF) subarrays have both computation and data storage capabilities. To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": ". , K  (number of refinement iterations) do 7: Run a simulation or small-scale test deployment us- ing the current  Œ≥ k , Œ¥ k , Œ∑ k . 8: Measure key indicators: participation rate, average energy depletion rate, frequency of incorrect infer- ences, and overall inference accuracy.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Such invariances are leveraged as reuse opportunities to reduce the compute-heavy projection computation. ‚Ä¢  We design two complementary schemes to capture both temporal and spatial reuse opportunities. We propose a memoization scheme, called  EA , to capture recent head orientation data for temporal reuse, and for the spatial reuse, we design the  AE  scheme, which leverages the stationary relationship between two eyes to efÔ¨Åciently reduce the amount of projection computation.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Moreover, CSDs hold the potential to undertake critical machine learning tasks like feature extraction and clustering, streamlining tasks like neural compression. The unique combination of FPGAs‚Äô parallel processing prowess, the substantial internal bandwidth of SSDs, and their block- accessible nature position CSDs as ‚Äúideal components‚Äù for evolving smart storage solutions tailored for machine learning. To cater towards this, in this work, we propose  Salient Store  ‚Äì a mini computational storage server (we call it ‚Äúedge storage server‚Äù) stack for managing the data archival in edge servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Next, we analyze the results measured using these platforms. After that, we show the general applicability of the proposed de- sign, and also present results from a sensitivity study that focuses on the quality-loss vs. energy-savings trade-offs. We conclude this section by outlining some research directions for implementing approximation-based accelerators for AR holograms.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "RR3 has 3 nodes with no no-ops and RR6 has 3 nodes with 3 no-ops. Even using a round robin execution, we observe that only 28% of the inferences are completed (shown in Fig. 1b).",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "We unify these three types of functions in two steps. Our approach will pro- vide a unified view of these functions and analyze a diverse combination of routing, composition, and ex- pert functions to improve the robustness and efficiency. The other line of re- search [131,151] implemented experts as individual language models, yet the experts are selected to work individually and they cannot be composed dynamically to complete complex tasks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Dynamic resource allocation for large-scale distributed training of deep learning models. In  Proceedings of the ACM Symposium on Cloud Computing , pages 789‚Äì800. [161] Li Wang, Wei Zhang, and Mei Huang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Therefore, Bit input / BN in meanstheactualloadeddatabits eachbatch.Theterm P ld‚àíbit denotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister. Theinputbatchnumber BN in isdeterminedbythepower budgetbecause P load <=P budget shouldalwaysbesatisÔ¨Åed. Thelatency modelfordataloadforoneconvolution operationis Lat load = Bits input /BW ld .Theterm Lat load \nrepresentsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.Theterm BW ld denotesthebandwidthof eachloadoperation.Themodelsof P store and Lat store can bederivedinasimilarfashion.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 192,
    "augmented": false
  },
  {
    "text": "We then compare those design schemes on our platform (Sec. VI-C ). Finally, we provide detailed insights on how to tailor the PCC pipeline to cater to various application preferences (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "In Section  4 , we introduce the game-theoretic model of sensor participation, motivat- ing our approach against simpler heuristics and discussing why equilibrium solutions are desirable. In Sec- tion  3 , we present the system model, detailing the EH-WSN \nsetup and data capture process. The remainder of this paper is organized as follows.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Moreover, the system must accommodate  support for intermittency inherent in sustainable power sources like solar and wind. While incorporating conventional battery storage can mitigate intermittency, it introduces environmental and sustainability challenges associated with resource extraction, production, and replacement [ 3 ], [ 5 ], [ 10 ], [ 13 ], [ 53 ], [ 66 ], [ 69 ]. An ideal solution would entail a battery-free system ( not  energy storage- free, i.e., still with some capacitive storage), circumventing these concerns and aligning with the objectives of sustainable and reliable continuous learning at the edge.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "A CKNOWLEDGMENT \nWe thank the anonymous reviewers for their helpful feedback and suggestions towards improving the paper content. This research is supported in part by NSF grants #1629915, #1763681, #1931531, #2008398, #2116962, #2122155, #2028929 and #2211018. R EFERENCES \n[1]  E. E. Aksoy, S. Baci, and S. Cavdar, ‚ÄúSalsanet: Fast road and vehicle segmentation in lidar point clouds for autonomous driving,‚Äù in  2020 IEEE intelligent vehicles symposium (IV) .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "Specifically, this thrust targets at answering the following questions: i)  What kind of simulation-emulation system is needed to carry out our experiments? ; ii)  What are the individual impacts of the op- timizations discussed in Thrusts 1-3, and what is their combined effect? ; iii)  What types of accelerator-based chiplets and chips perform better for training and inference of EoEs?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "This work provides a practical solution to achieve latency- accuracy balanced partitions for random forest based infer- ence tasks. We demonstrate the real-world applicability of our approach for two smart manufacturing deployments, and analyzed the accuracy-latency trade offs and their sensitivity to user-supplied thresholds. We believe that our solution can be easily deployed and be beneficial for random forest based distributed sensing-computing platforms.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "[14] K. Han, Z. Fang, P. Diefenbaugh, R. Forand, R. R. Iyer, and D. Newell, ‚ÄúUsing Checksum to Reduce Power Consumption of Display Systems for Low-motion Content,‚Äù in  2009 IEEE International Conference on Computer Design , 2009, pp. 47‚Äì53. [15] K. Han, A. W. Min, N. S. Jeganathan, and P. S. Diefenbaugh, ‚ÄúA Hybrid Display Frame Buffer Architecture for Energy EfÔ¨Åcient Display Subsystems,‚Äù in  International Symposium on Low Power Electronics and Design (ISLPED) , 2013, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "Unlike standard implementations where dropout rates and quantization levels are fixed or adjusted solely based on training dynamics, DynFit adjusts these parameters in real-time based on the energy profile of the device. These mechanisms include: (i)  Dynamic Dropout , which adjusts the dropout rates based on available energy to reduce computational load; (ii)  Dynamic Quantization , which modifies quantization levels in response to energy constraints to save energy; and (iii)  QuantaTask  design, which defines atomic computational units that can be executed without interruption given the energy budget. Specifically, during training, we simulate energy variability by incorporating energy traces into the training loop.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "Under these conditions, we have: \nlim k ‚Üí‚àû E [ J ( Œ∏ k )] =  J ( Œ∏ ‚àó ) and lim k ‚Üí‚àû E [ ‚à•‚àá J ( Œ∏ k ) ‚à• ] = 0 . A common choice is  Œ± k  = 1 / ‚àö \nk , but any diminishing sequence with P \nk   Œ± k  =  ‚àû and  P \nk   Œ± 2 k   <  ‚àû works. (2009)) states that for con- vex, Lipschitz-smooth objectives and unbiased gradient oracles, SGD converges to a stationary point if the step sizes  { Œ± k }  decrease at an appropriate rate.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 169,
    "augmented": true
  },
  {
    "text": "Cognitive computing and wireless communications on the edge for healthcare service robots. Computer Communications , 149:99‚Äì106, 2020. ISSN 0140- 3664. doi: https://doi.org/10.1016/j.comcom.2019.10.012.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "https://doi.org/10.1145/3357223. 3362711 [26]  Benjamin Carver, Jingyuan Zhang, Ao Wang, and Yue Cheng. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "252 \n[22] A. Holdings, ‚ÄúWhite Paper: 360-Degree Video Rendering.‚Äù ‚Äùhttps://community.arm.com/developer/tools-software/graphics/b/ blog/posts/white-paper-360-degree-video-rendering‚Äù, 2019. [23] J. Huang, Z. Chen, D. Ceylan, and H. Jin, ‚Äú6-DOF VR Videos with a Single 360-camera,‚Äù  2017 IEEE Virtual Reality (VR) , pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "6, p. 855‚Äì866, 2020. [87]  We are Luminous, ‚ÄúInteritum - Sureal VR Point Cloud Game,‚Äù \n‚Äùhttps://www.youtube.com/watch?v=P5BgrdXis68‚Äù , 2016. [88]  C.-H. Wu, C.-F. Hsu, T.-K. Hung, C. Griwodz, W. T. Ooi, and C.-H. Hsu, ‚ÄúQuantitative comparison of point cloud compression algorithms with pcc arena,‚Äù  IEEE Transactions on Multimedia , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "(Accessed on 11/13/2023). A novel accelerated implementation of rsa using parallel processing. Abhishek Rawat, Kartik Sehgal, Amartya Tiwari, Abhishek Sharma, and Ashish Joshi.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "An overview of chatbot technology. In  Proceedings of the 49th Annual International Symposium on Computer Architecture , pages 567‚Äì580, 2022. [6] Eleni Adamopoulou and Lefteris Moussiades.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Our modular, plug-and-play based approach not only allows for targeted research within individual elements of the en- semble, but also supports contributions from the broader research community. Thus, we believe our proposal is ambitious as its potential to revolutionize the training and deployment of LLMs is profound. Such incremental growth epitomizes the democratization of large-scale design efforts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "This means that only a portion of computation results from   ‚àó Tile count 1   to  Tile count 1   will be discarded. In order to not discard the acquired results, we can search the maximal   ‚àó Tile count 1   where   ‚àó Tile count 1   ‚â§ Tile count 1   to make the expression  n 2  |  ( ‚àó Tile count 1   √ó  n 1) conservatively true for each layer, and then transfer the tile count ‚àó Tile count 1  to accommodate to the new activation solution. The next power cycle‚Äôs level information cannot be known with certainty.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "if a person is walking and has taken a step, there is a high probability that the person will continue walking rather than immediately switch to another activity. Therefore, to classify the next possible activity, we activate the sensor which is most accurate for classifying the anticipated activity. Intuitively, human activities do not usually stop abruptly, i.e.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "This entire pipeline also requires sequential processing across the octree layers, which is obviously time-consuming when the number of points is large and the octree is deep. In fact, our proÔ¨Åling shows that RAHT takes around 2 seconds to process a typical frame with around 1M points, on a typical edge device. In this example, eventually the coeffs vector contains  [ 2 , 0 , 89 ] , which can be further compressed by entropy encoding.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Towards this, we plan to experiment with various latency reducing/hiding techniques such as caching and prefetching by intelligently using experts based on their frequency of in- vocation. We will dynamically classify experts as ‚Äúhot‚Äù and ‚Äúcold‚Äù experts based on their frequency of use. Hot experts are those that are more frequently invoked for generating responses because of common or recurring query topics, whereas cold experts are the ones which are less frequently utilized.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Each (edge)  device  (which is a part of the  Deployment scenario like machine state monitoring) contains an embedded computer (e.g. partition random forest compute efficiently between edge and cloud in a distributed sensor network. 1: Edge-cloud partitioning policies.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Preparation for Activities:  The two senior PIs have extensive prior experience in supervising female un- dergraduate and graduate students. Both of them have graduated 15+ female PhD and MS students (5 in last five years) and a few of them have taken up faculty positions at different schools. They have also advised a couple of female undergraduate students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "the  Baseline , which contributes to  20%  total energy saving. ‚Ä¢  PTU+EA+AE:  Note that, our proposed  EA  and  AE  designs are ‚Äúindependent‚Äù of the underlying hardware used. As a result, they can also be deployed on top of the PTU-based SoC.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "compression ratio (i.e., input size / compressed size). (b) PSNR v.s. Figure 10: (a) comparison between i: raw PC and our proposals (ii: intra, iii: intra-inter-V1, iv: intra-inter-V2).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "However, to achieve this, we need some extra information about the clus- ters. Extending this with  the point count for each cluster  allows for recon- struction of data in the original form that can be processed by DNNs trained on full-size data. The standard method of clustering-based coreset con- struction keeps the cluster center and cluster radius, which gives the geometrical shape of the entire data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "For example: \nŒ≥  ¬∑  ‚àÜ A max  < Œ∑  +  margin , \nwhere  margin  accounts for future opportunities and energy savings. A small  margin  ensures sensors do not always expend maximal energy for short-term gains. Practical Hyperparameter Tuning Strategies \n1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "2019. GrandSLAm: Guaranteeing SLAs for Jobs in Microservices Execution Frameworks. [34]  Ram Srivatsa Kannan, Lavanya Subramanian, Ashwin Raju, Jeongseob Ahn, Jason Mars, and Lingjia Tang.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Kraken  uses this load distribution to pre-provision the requisite number of containers for all functions in the application. This Load Predictor  2b  can be used in conjunction with the afore- mentioned Weight Estimator  2a  to calculate the fraction of application load each function will receive. 4.2 Request Batching Many serverless frameworks [ 5 ,  10 ,  17 ,  27 ,  44 ,  46 ,  50 ] spawn a single container to serve each incoming request to a function.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Tiantu Xu, Luis Materon Botelho, and Felix Xiaozhu Lin. Vstore: A data store for analytics on large videos. In  Proceedings of the Fourteenth EuroSys Conference 2019 , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "It can be observed from this figure that, even with the most aggressive approximation introduced by  Inter-Intra-Holo , the video quality is still sufficient for most of the AR applications (30 . Compared to the baseline, we then report the averaged PSNR [ 21 ,  44 ] of the recon- structed images from the six videos in Fig. 10a.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "In the  Inter-Holo  scenario shown in Fig. 2.2.3. 1 and Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 21,
    "augmented": true
  },
  {
    "text": "1: Edge-cloud partitioning policies. E DGE -C LOUD  P ARTITIONING  P OLICIES \nIn this section, we discuss the various policies to \nCloud  Server \nDeploy 1 \nDeploy 2 \nDeploy 3 \nDeploy n \nData_1 Data_2 Data_3 Data_n \nDevice_1 \nDevice_2 \nDevice_3 \nDevice_n \nData Shared \nRF_1 RF_2 RF_3 RF_n \nPeer connections for Policy 2 \n(a) Data Sharing Policies. Red arrows indicates peer-to-peer connections \nRandomly Sampled \nCloud  Server \nDeploy 1 \nDeploy 2 \nDeploy 3 \nDeploy n \nData_1 Data_2 Data_3 Data_n \nDevice_1 \nDevice_2 \nDevice_3 \nDevice_n \nRF_1 RF_2 RF_3 RF_n \nModel Shared \n(b) Privacy Aware Policy: models are randomly sampled \nFig.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 208,
    "augmented": true
  },
  {
    "text": "To enable such analytics, current devices rely heavily on deep \n* Work was done while at Penn State. Such an- alytics are critical for virtual/augmented reality, object recog- nition/detection for surveillance, commercial advertisement insertion/deletion, synopsis extraction, and video querying. eural networks (DNNs).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "As has been highlighted in Table 2, we plan to exploit the expert-router affinity to reduce the training com- plexity of the router at initial training time and even while fine-tuning as the ensemble of experts evolve. Unlike conventional networks, where an entire end-to-end training of the experts and routers needs to be done alike, our scheme makes use of a more targeted approach that can sig- nificantly reduce the training complexity of the routers. In our methodology, the router only needs to be fine-tuned on the dataset of the expert that it interfaces with, which is much smaller than the entire dataset.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "The Shown storage pipeline is the preliminary focus of  Salient Store  . arXiv:2410.05435v1  [cs.AR]  7 Oct 2024 \nClassification \nResults and \nActions \nUpdate \nModel Finetuning Exemplar Selection \nInference \nModel \nStacked Encoder \nStacked \nDecoder \nCompressed \nData \nQuantum-safe \nEncryption \nArchival¬† Storage (HDD) \nComputational \nStorage FPGA \nComptinuous Learning Compute \nVideo Source \nNeural Encoder \nFrame Loss \nFigure 1: Data flow pipeline of continuous learning edge servers with storage and data archival pipeline. Under review.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "The second stage,  Projection Computation  (denoted  b  in Fig. 3), uses the transformation matrix and the 2D FoV coordinates for both eyes to obtain \n4 We used an averaged pupillary distance in our evaluations [27], [37]. 3, is to determine a transformation matrix by com- bining Ô¨Åve different transforms.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Objective functions : In order to reduce cost and latency while maximizing the accuracy, we deÔ¨Åne a latency-accuracy metric ( ¬µ AL ) and cost metric ( ¬µ c ): \n¬µ AL  =   Acc target \nLat target ¬µ C  =  k  √ó N ‚àë m = 1 \ninst _ cost \nP f m \nwhere  N  is the number of models used to ensemble and inst _ cost  is the VM cost. Each model  m  has a packing factor \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1045 \nP f m  and k is a constant which depends on the VM size in terms of vCPUs (xlarge, 2xlarge, etc). Our Ô¨Årst objective function ( O 1 ) is to the maximize  ¬µ AL  such that target accuracy ( Acc target ) is reached within the target latency ( Lat target ).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 216,
    "augmented": false
  },
  {
    "text": "Our results from exhaustive experimental analysis demon- strate that  Cocktail  can minimize deployment cost by 1.4 √ó while meeting the accuracy for up-to 96% of the requests and providing 2 √ó  reduction in latency, when compared to state-of-the-art model serving systems. We show that ensemble models are inherently fault- tolerant over single models, since in the former, failure of a model would incur some accuracy loss without complete failure of the requests. 5.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "De- spite this variation, there may still be matches/recomputations within a frame between two eyes, i.e., IntraFrame-InterEye as shown in  b  in Fig. D. IntraFrame-InterEye (AE) Computation Optimization \nIn  EA , the compute can be bypassed by reusing the pre- computed results, if the head orientation matches with any of the two previously memoized head orientations (stored in reg- isters). However, we also note that these opportunities might be limited owing to the ‚Äúnon-repetitive‚Äù user behavior.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "[31] X. Liu, Q. Xiao, V. Gopalakrishnan, B. Han, F. Qian, and M. Varvello, ‚Äú360¬∞ Innovations for Panoramic Video Streaming,‚Äù in  Proceedings of the 16th ACM Workshop on Hot Topics in Networks , ser. HotNets-XVI, 2017, pp. 50‚Äì56.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "0 \n500 \n1000 \n1500 \n2000 \nTrans. Entropy Other Attri. Compression Pipeline:  \nTMC13 \n0 \n200 \n400 \n600 \n800 \nConst.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Oth- erwise, the sensor prioritizes local computation and, with the help of a moving average power predictor [ 47 ], predicts whether it can finish the quantized DNN inference with the combination of stored energy and expected income (  2a  and \n2b  ). The sensor computes the correlation (  1a  ) between the stored ground truth and the current data. If the correlation coefficient is  ‚â• ùë°‚Ñéùëüùëíùë†‚Ñéùëúùëôùëë (  1b  ) the sensor skips all computation and sends the result to the host.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Figure  9b  shows the breakdown of the percentage of re- quests ( Const1 ) served by the each model. As seen, Incep- tionResNetV2, Densenet-201, Densenet121, NasnetMobile and Xception are the top-5 most used models in the ensem- ble. Based on Table  1 , if we had statically taken the top  N / 2 most accurate models, NasNetmobile would not have been included in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Sensitivity Study:  To better understand the relationship be- tween the inference quality and the threshold, we run our model with different parameter settings, shown in Figure 4, over the cases of edge-peer and edge-cloud structures with device counts of two and four. Figure 4a shows that setting \na high threshold value will reduce the average inference time in all four cases. This effect is more obvious in the edge-peer structure since it will send the data to its nearest peer and check the prediction quality until it reaches the cloud.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "To handle dynamic load variations, a load-monitor can be designed such that it constantly moni- tors different periods of static load and peak load. Therefore, queries with strict latency requirements can be scheduled on  serverless functions , if a VM with free resources is unavailable. However, a single ap- plication can contain a mix of queries with varying latency demands.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "This is because, compared with the whole frame, RoIs in these two videos are large (e.g., ratio of RoI/whole frame is 4x of that ratio in V1), which increases the computation for the PI and thus decreases the its beneÔ¨Åts. 8d). Additionally, even with our proposed PI technique, the improvements for GL1 and HC1 with YOLOv3 model are not very signiÔ¨Åcant (e.g., the latency reduction is improved by  4% for GL1 as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "[19] H. Jiang, A. Sarma, M. Fan, J. Ryoo, M. Arunachalam, S. Naveen, and M. T. Kandemir, ‚ÄúMorphable convolutional neural network for biomedical image segmentation,‚Äù in  2021 Design, Automation Test in Europe Conference Exhibition (DATE) , 2021, pp. B. Kotra, M. Arunachalam, C. R. Das, and M. T. Kandemir, ‚ÄúA learning-guided hierarchical approach for biomedical image segmentation,‚Äù in  2018 31st IEEE International System-on-Chip Conference (SOCC) , 2018, pp. 227‚Äì232.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": "Inter-layer parallelism  means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion. This offers a Ô¨Çexible way to tune the power consumption in a large design space, even though the kernel size, convolution count and power consumption of different layers can signiÔ¨Åcantly vary. In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Continuous Learning: Accuracy \nFig. We compare against a baseline using na¬®ƒ±ve continuous learning algorithm with no representation learning. 7  shows the accuracy improvement over a time window of 8 hours by using the continuous learning algorithm.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Unfortunately, prior works mainly focused on compression ratio, but did not consider the performance and energy implications, particularly for edge devices. This paper exploits the data similarity opportunities in  both  geometry and attribute data from  both  intra-frame and inter-frame perspectives, and proposes two complementary designs for minimizing the compression latency and energy requirements for pushing the PC compression to the edge. And, more importantly, these proposals are compliant with the emerging MPEG PCC standards [ 53 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "These methods introduce various techniques such as embedding state information into the DNN, multi-resolution inference, multi-exit architectures, and runtime reconfig- urability to handle intermittency in energy-harvesting devices. We have faithfully re-implemented these methods as per the descriptions and adjusted them for a fair comparison under our setup. Results:  Table 1 shows the accuracy of our approach against the baselines and the recent state-of-the- art methods using the TI MSP board powered by piezoelectric energy harvesting.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "7 \n385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 \nEnergy Preservation: If  Œ≥  is too large, sensors might not value future energy at all. 1 ¬∑ Œ≥ ¬∑ ‚àÜ A max , helps maintain a moderate deterrent against non-participation without forcing sensors to always participate. Choosing  c  relative to typical gains, say  c  ‚âà 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 183,
    "augmented": true
  },
  {
    "text": "It also leverages the continu- ous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve Ô¨Ånal classiÔ¨Åcation accuracy. Our proposed policy,  Origin , strategically ensures efÔ¨Åcient and accurate indi- vidual inference execution at each sensor node by using a novel activity-aware scheduling approach. This paper presents a novel scheduling policy along with an adaptive ensemble learner to efÔ¨Åciently perform HAR on a distributed energy-harvesting body area network.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Especially, many levels of dependencies (i.e, various regularities of locks) exist in their pipelines ‚Äì e.g., the entire octree needs to acquire a ‚Äúmacro lock‚Äù before inserting a point and updating the tree (as shown in Fig. 5 ), during the intra-frame geometry compression; similarly, in the attribute compression shown in Fig. 6 , the points at one layer in the octree have dependencies with those at other layers, thus their processing requires acquiring locks at a ‚Äúlayer granularity‚Äù.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "This state includes the loop indices and the current value of the element being processed in  C . C.1.4 Check-pointing Mechanism \nBefore each power interruption, detected through an energy monitoring system, the algorithm saves the current state using the  SAVE_STATE  function. This ensures that no computation is lost when the power goes out.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "IEEE, 2021. In  2021 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pages 1414‚Äì1419. Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor net- works.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "4413.87 4243.51 3190.25 3135.99 \n0 1000 2000 3000 4000 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "Computer Networks , 2009. [76]  Guido Urdaneta, Guillaume Pierre, and Maarten Van Steen. Wikipedia workload analysis for decentralized hosting.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "1006.01 \n0 500 \n1000 1500 2000 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. power (mW).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "[42]  S. A. Dawwd and B. S. Mahmood, ‚ÄúA reconÔ¨Ågurable interconnected Ô¨Ålter for face recognition based on convolution neural network,‚Äù in  2009 4th International Design and Test Workshop (IDT) , pp. [41]  R. Wang and Z. Xu, ‚ÄúA pedestrian and vehicle rapid identiÔ¨Åcation model based on convolutional neural network,‚Äù in  Proceedings of the 7th International Conference on Internet Multimedia Computing and Service , ICIMCS ‚Äô15, pp. 32:1‚Äì32:4, 2015.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Therefore, resource procurement and management deci- sions need to be adjusted depending on the resource utiliza- tion/load and arrival rates. diurnal, flash-crowds etc.) Public cloud providers leave these major decisions to be ≈Çmanually handled\" by users, which is very time consuming and strenuous.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "2) Point Cloud Analysis:  To analyze objects/scenes in PCs, 3D convolutional neural networks (CNNs) have been widely used in techniques like 3D shape classiÔ¨Åcation [ 66 ], [ 67 ], [ 89 ], [ 91 ], object detection [ 38 ], [ 45 ], [ 65 ], tracking [ 22 ], [ 78 ], or segmentation [ 10 ], [ 66 ], [ 67 ], [ 89 ]. While most prior works target accuracy, Mesorasi [ 20 ] improves the compute and memory efÔ¨Åciency of 3D CNNs using delayed-aggregation and software-hardware co-design, and PointAcc [ 40 ] proposes special mapping unit and memory management for optimiza- tions. However, the huge data volume of the PC still remains \n284 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 192,
    "augmented": true
  },
  {
    "text": "[18] Maciej Besta, Syed Minhaj Hassan, Sudhakar Yalamanchili, Rachata Ausavarungnirun, Onur Mutlu, and Torsten Hoefler. On the dan- gers of stochastic parrots: Can language models be too big? In  Proceedings of the 2021 ACM conference on fairness, accountability, and transparency , pages 610‚Äì623, 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "We implement this neural codec using the FPGA in the CSDs. Algorithm 1 shows the details of the layered neural codec. FPGAs are ideal for this application due to their parallel processing capabilities and the ability to handle multiple data streams concurrently.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Hashan Roshantha Mendis, Chih-Kai Kang, and Pi-cheng Hsiu. In  13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18) , pp. 129‚Äì144, 2018.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Table 4 gives an overview of Kraken ‚Äôs policies and their implementation details. 5.2 Evaluation Methodology We evaluate the  Kraken  prototype on a 5 node  Kuber- netes  cluster with a dedicated manager node. 160 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nPolicy Component Implemented using/as \nPWS \nProbability System log info, Sparse Data Structures Commonality  &  Connectivity DAG Descriptor Load Predictor Pluggable model (EWMA) Batching Function containers persisted in memory \nRS Load Monitor Metrics from Prometheus & System logs Replica Tracker Table 4: Implementation details of  Kraken ‚Äôs policies.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 189,
    "augmented": true
  },
  {
    "text": "315‚Äì 327. [73] Ravi Teja Mullapudi, Steven Chen, Keyi Zhang, Deva Ramanan, \nKayvon Fatahalian, ‚ÄúOnline model distillation for efÔ¨Åcient video in- ference,‚Äù in  ICCV , 2019. [74] S.-A.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "IEEE, 2012, pp. 3354‚Äì 3361. [25] N. Global Monitoring Laboratory, ‚ÄúSolrad network,‚Äù  https://gml.noaa.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "Graham Gobieski, Brandon Lucia, and Nathan Beckmann. Intelligence beyond the edge: Inference on intermittent embedded systems. In  Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "The CSE department at Penn State currently maintains copies of the LLVM compiler toolset, various LLM models, as well as various ML packages and HPC libraries. Other Resources:  Penn State Institute for Computational and Data Sciences (ICDS), of which Mahmut Kandemir is an associate director, provides a variety of compute, storage and network resources, various IT services, including operations, backup, technical consulting, and training material, and is compliant with specific NSF, NIH, and NIST security controls. The department operates its own firewall infrastructure using Palo Alto, Cisco, and Sonicwall products.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "We face three issues here: 1. How does the new tile get any kernel to work on? However, in the middle of the execution if any new tiles becomes alive (because of an increase in harvested power), the scheduler immediately marks it ready to start working and the tile fetches a kernel (currently not scheduled in any of the tiles) and starts working on it.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "The types of instance used in our evaluation include all the c5 and m5 instances for EC2. By offline profiling, we estimate the number of model instances each VM can execute in par- allel without violating the model latency. Also, we estimate the right configuration of lambda functions by conduction offline experiments.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "). However, integrating game-theoretic participation strategies with machine learn- ing tasks, particularly in energy-harvesting environments, remains an area with limited exploration. 2.4.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "We consider this design as the  state-of-the-art . This is the most recent VR design that uses an FPGA for accelerating the computation. ‚Ä¢  PTU  (HW):  A recent optimized solution [28] utilizes a more energy-efÔ¨Åcient hardware accelerator, i.e., Projec- tive Transformation Unit ( PTU ), to process the compute- intensive projection operations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "2019. In search of a fast and efficient serverless dag engine. In  2019 IEEE/ACM Fourth International Parallel Data Systems Workshop (PDSW) .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Power estimations of our hardware design, modeled by Design Compiler [ 93 ], indicate that the proposed morphable accelerator approach can save up to 234.95kWH/year/edge-server, compared to running continuous learning on a state of the art DNN accelerator and 2.63MWH/year/edge-server, compared to utilizing a datacenter-scale GPU for learning on the edge. B ACKGROUND AND  M OTIVATION \nEdge servers often leverage the convenience and Ô¨Çexibil- ity of cloud interfaces, granting access to the same APIs, tools, and functionalities [ 60 ]. II.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "Based on the nature of the workflow, function chains can be classified as Static or Dynamic. 2.1.1 Static DAGs : In static function chains (or DAGs), the workflows are specified in advance by the developer (using a schema), which is then orchestrated by the provider. An application invokes functions in the sequence as specified by the path in the DAG.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "2018. In  ATC . SAND: Towards High-Performance Serverless Computing.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "P ROPOSED  S TRATEGIES \nAs discussed in Sec. III, there exist signiÔ¨Åcant similarities between two successive frames (e.g., for more than 95% of the pixels between two adjacent frames) when considering ‚Äúpixel difference‚Äù as the similarity metric. In the following two subsections, targeting inference-based video applications, we present two novel schemes that take advantage of this similarity:  frame-level pruning  and  region-level pruning .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "[30]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg. 2017. Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Parallel computations across multiple ReRAMs and loop tiling-based computation for each ReRAM are orthogonal optimizations. Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode. Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles  PC6, PC7  and  PC8 .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "0 \n2 \n4 \n6 \n8 \n60 \n70 \n80 \n90 \n60 70 100 120 150 350 \nAverage #Models \nAccuracy (%) \nLatency (ms) \naccuracy Average #Model \n(b)  Fixed Latency. Figure 14:  Sensitivity Constraints under Ô¨Åxed latency and accuracy. Bar graphs (latency) plotted using primary y-axis and line graph (#models) plotted using secondary y-axis.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Energy Variability Awareness:  By integrating energy profiles directly into the training process, NExUME ensures that the model learns to handle fluctuations in energy supply, leading to more robust performance compared to methods that do not consider energy variability during training. This allows the DNN to maintain high accuracy even under severe energy constraints. 2.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Buffer Management:  Us. ¬¥as  uses non-volatile state buffers (NVSBs, 18 count, 1 per 4x4 tiles, each of 1kB, and 2 of 4kB each) for state saving and data backup. and starts Ô¨Çushing the results for backup.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Each request from the load-generator is modelled after a query with spe- ciÔ¨Åc  <latency,accuracy>  constraints. We use 9 different prominently used text-classiÔ¨Åcation models from transformers library [ 81 ] (details available in appendix) designed using Google BERT [ 30 ] architecture trained on  SST  [ 72 ] and  SemEval  [ 66 ] dataset. The queries consist of images or sentences, which are randomly picked from the test dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Zhang, Kandemir and Das have recently started to work together. Das and Kandemir have worked together in prior and on-going NSF projects and have a history of successful collaboration, including co-advising underrepresented students. Zhang and Kandemir have recently co-authored a paper in MICRO (2024) and all three PIs have co-authored a paper in NeurIPS (2021).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Second, the four major reasons for instruction stalls in the  Forward-Propagation  step are: Data Request (21%), Execu- tion Dependency (19%), Instruction Fetch (15%), and Sync (10%), whereas in the  Backward-Propagation  step they are Read-only Loads (42%), Sync (24%), Data Request (16%), and Execution Dependency (6%). Moreover, the L1 hit rate for both these steps is as high as 99%. Thus, GPU seems to be one of the reasonable hardware candidates for mapping the hologram application.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "Our next-generation meta training and inference accelerator, 2024. [105] Meta. Building meta‚Äôs genai infrastructure, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "; and iv)  How do compute and memory resource constraints and runtime environments influence our algorithmic decisions? This thrust aims to advance the state-of-the-art by proposing an innovative framework built on a network of specialized LLM experts that can operate both independently and in collaboration. The modular nature of our system allows experts to be trained separately and then combined in multiple configurations.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "for the previous equations to hold. This changes the to- tal number of states from  ùëõ to  ùëÅ , the number of extended states, resulting in a larger Transition Matrix and Probability Vector. To calculate the required number of containers for a single function that has multiple context-independent states associated with it, we take the sum of the calculated values for all of those states.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Chiplet-based designs have shown great promise for integrating a variety of modular chips, both homogeneous and heterogeneous, on a silicon interposer [72,152] and is a great fit for our envisioned modular and fault-tolerant design. The specific questions we would like to address in this thrust compris- ing of 4 tasks include: i)  Which parts of the EoE network are most preferable for custom hardware acceleration from the performance, power, and accuracy standpoints? ;  ii)  What types of chiplet-based architectures are suitable for EoE-based LLMs, and what is the search space for chiplets?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "Although current commercial devices are capable of handling inference at the edge, the power and resource requirements of training make it impractical and unsustainable for all edge nodes to also perform continuous training off of grid power. In this work, we design  Us. ¬¥as , a sustainable continuous learning platform, which can perform video analytics by using an inter- mittent power source like solar power.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Typically, these inference serving systems are hosted using Virtual Machines (VMs), which take a few minutes to start-up. The deployment costs differ based on the provisioning times and longevity of the resource pro- cured. Due to high start-up latencies, using VMs for hosting ML services can lead to over-provisioning, espe- cially during periods of poor workload predictability (flash crowds) [ 10 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "075% ). Our experiments reveal that the proposed FL scheme can skip up to  53%  of the frames, with  very less  accuracy loss ( 0 . Moreover, the total overhead of this algorithm is only  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "PMLR, 2022. [135] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: Memory optimizations toward training trillion parameter models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "To get mAP, the precision for each class is Ô¨Årst calculated across all of the Intersection over Union (IoU [41]) thresholds, and the Ô¨Ånal mAP will be the averaged precision of all classes (the higher, the better). Datasets : We use three published video datasets (VIRAT [33], EPFL [42] and CAMPUS [43]), to study the performance and energy behavior across different videos. The IoU threshold is set as 0.5 (a widely used value in mAP calculation) in our evaluations.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2404.16789 , 2024. Keep the cost down: A review on methods to optimize llm‚Äô s kv-cache consumption, 2024. [148] Luohe Shi, Hongyi Zhang, Yao Yao, Zuchao Li, and Hai Zhao.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "We also study the sensitivity of our proposed approach to available ReRAM hardware resources. A. Throughput \nFigure 8 shows the throughput comparison of the Ô¨Åve exe- cution strategies. The bars are all normalized to  ResiSchedule .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "The ability to capture diverse conditions from the different nodes, with or without sharing data, can lead to more robust models. We focus on extending random forests models that have been deployed in smart manufacturing [7] to explore edge-cloud partitioning strategies when multiple machines cooperate in contributing to better models. Constructing an accurate random forest model, while respecting data privacy of a distributed multi user sensor network is also challenging.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Calculate the gradients and Hessians of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij , ‚àÇ 2 L ‚àÇW   2 ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) If  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the sensitivities: \np i  = Œ≤   P j ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \nmax \u0010P j ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \u0011 +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Initialize the loop iteration parameters  l . 17 \nCompute the activations  a  and apply the dropout mask: \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 412,
    "augmented": true
  },
  {
    "text": "When skipping, we can simply bypass the inference task by reusing  the inference result from the last frame; otherwise (i.e., if cannot skip), the full inference has to be performed for the current frame, in the same fashion as in the baseline. 2 is invoked to decide among the execution choices for the incoming frames ‚Äì including Skipping, Full-Inference, and Partial-Inference. FI+SI+PI:  Different from the above FI+SI scheme, in this scheme, the region level decision-making Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "General Applicability of D¬¥ej`a View : The above discussion assumes that the Equirectangular format [52] is used to represent the  360 ¬∞ videos. We want to emphasize that our underlying ideas behind the proposed  EA  and  AE  (designed for the Equirectangular format) can work irrespective of the representation formats used [48]. 71  on average) for VR video applications [26], [62].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "[69]  Prateek Sharma, Stephen Lee, Tian Guo, David Irwin, and Prashant Shenoy. Spotcheck: Designing a derivative iaas cloud on the spot market. , 1(1), June 2017.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "The broader implication of this work extends beyond technological advancements, suggesting a paradigm shift in how the machine learning community approaches the design and deployment of systems in energy-limited environments. By prioritizing energy efficiency and system adaptability, NExUME contributes to the sustainability and accessibility of machine learning solutions, enabling their deployment in regions where power infrastructure is absent or unreliable. Specifically, improvements ranging from 6.10% to 17.13% over existing methods highlight NExUME‚Äôs capability to adapt dynamically to fluctuating energy conditions, ensuring both operational longevity and computational integrity.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "To enhance the performance of EoE , we propose system optimizations that exploit the spatio-temporal locality/affinity of its components ‚Äì data, experts, routers, composition functions, and hardware. Table 2 shows how our proposed framework will exploit these affinities across (training, inference) and (algorithm, systems, architecture) dimensions. Task-2.1: Data Locality and Parallelism‚ÄìAware LLM Training Unlike traditional monolithic LLMs, our EoE -based LLM opens up new opportunities to optimize train- ing for both performance and energy efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "The next step is to decode the original frame from the bitstream, and today, this is mostly done using a hardware- based h264/MPEG decoder for more energy efÔ¨Åciency. After decoding, the  360 ¬∞ output frames are then buffered in the video buffer, waiting to be rendered. Projection:  Note that, the output frames from the decoder are still in the  spherical coordinate system .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "4) How to Do Partial-Inference? memoize  the feature maps of the middle part in the previous frame, and reuse the data for the current frame. Since the outer part maintains no information for the RoIs, it can be safely discarded.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "While LLMs have become integral across various sectors due to their advanced capabilities, con- structing these models from scratch for specialized applica- tions presents significant challenges due to the prohibitive cost. For instance, the Megatron-Turing 530B model was trained using 2K A100 GPUs over a duration of 3 months con- suming over 3 million GPU hours [149]. Similarly, it took 384 A100 GPUs to train BLOOM over 3.5 months [165] and 6144 TPU v4 chips were used to train PaLM-540B model over 50 days [27].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "The  serverless functions  are configured according to the memory requirements of each model. Figure  3a  plots the cost of hosting the iso-latency model types (shown in Figure  2a ) for a constant request arrival rates of 10, 50, 100, 200 req/sec over 1 hour duration. It can be seen that virtual machines are always cheaper compared to using  serverless functions for all constant request rates.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Moreover, the conventional PC typically stores the geometry, while a wide array of applications, especially the ones meant for content consumption, infotainment and gaming, need the attributes to be stored as well, hence making the compres- sion even more complex. 1 s  and  4 . For example, TMC13 [ 56 ] and CWIPC [ 48 ] ‚Äì two state-of-the-art (SOTA) PCC techniques ‚Äì take  4 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "[146] Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Beidi Chen, Percy Liang, Christopher R√©, Ion Stoica, and Ce Zhang. Flexgen: High-throughput generative inference of large language models with a single gpu. In  International Conference on Machine Learning , pages 31094‚Äì 31116.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "However, as we can see from  6  in Fig. 3a, only the bounding boxes (in red) and the MV (in black) are meaningful, and the remaining regions (in white) are similar with those of previous frames, which, intuitively, do not provide as much contribution to detect the ‚Äúposition change‚Äù event denoted by the colored regions. This observation reveals an opportunity to perform partial inference (PI)  by operating only on the bounding boxes and MV regions.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "To further mimic realwold scenarios of multiple cameras sending multiple streams with various stream rate, we  distributed  video data into across two CSDs in different ratio, as shown in TABLE 2. 99 √ó  better than the implementation on classical storage systems. Salient Store  on CSDs perform  ‚âà 1 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "of the scheduled training without any intermittency support. It is clear that we  can neither  use the commercial GPUs  nor rely on the standard software and algorithmic approach for intermittent training purpose as they  cannot  Ô¨Ånish the compute given the intermittent power budget. 0 0.2 0.4 0.6 0.8 \n1 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nA6000 w/DVFS RTX3090 w/DVFS Non-intermittent Custom HW w/Ekya \nOur Custom HW \nCompleted/Scheduled \nC/S Win-1 C/S Win-2 C/S Win-3 C/S Win-4 C/S Win-5 C/S mean \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 197,
    "augmented": false
  },
  {
    "text": "Researchers currently share approximately 105TB of NAS storage. The department operates its own firewall infrastructure using Palo Alto, Cisco, and Sonicwall products. The clusters offer researchers HPC and GPU con- figuration 9both A 100 and H 100)agility to target highly specialized use-cases.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Rift, ‚ÄúOculus Rift - How Does Time Warping Work?‚Äù ‚Äùhttps://www. [43] O. youtube.com/watch?v=WvtEXMlQQtI‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "This process is constant time, requiring only a single subtraction of  q . The MR hardware, highlighted in Fig. 3b, consists of a single shift block, a subtractor, and a adder, consuming much less hardware then the state-of-the-art (Fan et al., 2018).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "To further improve the compression efÔ¨Åciency, our second scheme, inter-frame compression, considers the temporal similarity among the video frames and reuses the attribute data from the previous frame for the current frame. The proposed parallelism brings around 43.7 √ó  performance improvement and 96.6 % energy savings at a cost of 1.01 √ó  larger compressed data size. Unlike existing techniques that use sequential algorithms, our Ô¨Årst design, intra-frame compression, exploits parallelism for boosting the performance of both geometry and attribute compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Although such arrays already contain the necessary information to decode the geometry information for the PC, they are  not suitable for compression tasks . For exam- ple, to store/transmit these two arrays,  4 bytes √ó 16 = 64 bytes are needed. 5 , - 1  in the parent array means that the root node has no parent, whereas  parent [ 7 ] =  4  means that for the  7 th  node (whose code is  code [ 7 ] =  511 ), the index for its parent node in the code array is 4 (whose code is  code [ 4 ] =  63 )).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, about 95% of the deltas (pixel differences in successive frames) are less than 3. The rest of this paper presents and experimentally evaluates two novel optimization strategies that exploit this similarity. It can be observed that, while the ‚Äúexact pixel match based similarity‚Äù is scarce at frame level, an alternate similarity based on the ‚Äúmagnitude of pixel differences‚Äù is abundant.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "With these depth planes, the first step,  Forward Propagation  (de- noted  ‚ù∂ in Fig. As shown in Fig. 4a, the depthmap input is first sliced into several planes ( M  depth planes in this case).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Constructing an accurate random forest model, while respecting data privacy of a distributed multi user sensor network is also challenging. Moreover, such a system demands accurately predicting the cases where the edge analytics were insufficient and the cloud must be employed for deeper analysis and accurate results. We propose a novel framework to perform intelligent edge- cloud partitioning for a distributed sensor network running random forest-based analytics.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "5a  shows the high level design, architecture and different components present in our proposed accelerator. The accelerator encompasses 256 tiles, structured in a 4 √ó 4 conÔ¨Åguration of 16 super-tiles, each harboring 4 √ó 4 tiles. These super-tiles Each tile, individually switchable ON or OFF based on power availability, houses 64 16-bit Ô¨Çoating point MAC units conÔ¨Ågured in an 8  √ó  8 systolic array for convolution operations.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "[182] Wei Zhang, Chen Liu, Xinyu Wang, and Jian Li. Efficient load balancing for distributed training of deep neural networks. In  Proceedings of the IEEE International Conference on Big Data , pages 1234‚Äì1243.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Archives of Surgery (2004), 170‚Äì174. [57]  Randall Shumaker and Lackey Stephanie. Augmented Reality in Surgery.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "https://cloud.ibm.com/docs/openwhisk?topic= cloud-functions-pkg_composer. [9] 2020. Kubernetes.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Conservatively, we choose a correlation coefficient  ‚â• 0 . 95 to predict that the two activities are the same, and hence skip the inference altogether and just com- municate only the results to the host. We store ground truth sensor data pattern for all possible labels, and when new data arrives, we find the correlation of the sampled data against the ground truth data, and if any of the correlation coefficient \n6 \nPower-Pred \n+ Decision Logic (MCU) \nCorrelation \nSensor Data \n16bit DNN (x-bar) \n12bit DNN (x-bar \nCoreset: Imp \nSmp/Clust.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "1 , our experiments, on different modalities, shows the accuracy degradation due to data drift. SpeciÔ¨Åcally focuing on video data, we observe that: using quantized MobileNet-v2 (14M paramters, 71.3% accuracy) as the small model and ResNet-101 (171M parameters, 76.4% accuracy) as the large model, the accuracy of the smaller model has degraded  >  20% over 5 sampling windows (of 4 hours each), where as the effect is minimal in the larger model. However, with a proper retraining, the smaller model could keep up with the original accuracy.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "C. Experimental Results \nWe present and compare the energy consumption of the pro- jection computation and the cor- responding video quality impact, when running the Ô¨Åve VR videos described in Tab. II, with the six design conÔ¨Ågurations discussed in Sec. V-A.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "We model two different workload mixes by using a combination of these Ô¨Åve query constraint types. Based on the decreasing order of accuracy, we categorize them into  Strict  and  Relaxed  workloads. The list of models used for them are given in the Appendix.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Although we have an intuitive feeling on the how the thresholds in Algo. 1 and Algo. 2 affect the accuracy and performance, e.g., a larger  T moving  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "We compare the cost of deploying the inference service on a group of virtual machines and  serverless functions . We use m4- large instances for VMs and we fix the number of inference queries each VM can handle in parallel, without violating response latencies based on our characterization on AWS EC2. The  serverless functions  are configured according to the memory requirements of each model.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Towards this, we propose  HoloAR , an opportunistic and edge- friendly framework to speed up the AR holographic computation \n(a) An app. (c) SW pipeline [19, 50]. (b) HW components [20, 29].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "25 ,  0 . 25 ,  0 . 25] , where the classiÔ¨Åer is equally confused between all the classes.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "A detailed description of the setup is explained in Section IV. In this section, we provide an overview of our proposed solution. A. Preamble to Origin \nHuman activity has temporal continuity, i.e.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "However, with the advent of the modern mobile devices, capturing 3D image and PC on these tiny and battery-backed devices is becoming increasingly common. For example, the recent iPhone 12/13 Pro features LiDAR camera for PC recording, and similarly, Samsung Galaxy S20+/S20 Ultra contains ToF (Time of Flight) camera for the same. Since PC generation requires sophisticated instruments like LiDAR or 3D cameras, it was typically done on server- class computers with high compute and storage capabilities.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "P load = aG√ó (Bits input /BN in )√óP ld‚àíbit   modelsloadpoweroperation. Here,theterms Bits input and BN in denotethenumberof inputbitstoserve MACoperationsforafull-sizedReRAMand thebatchnumberoftransferringtheseinputbitsrespectively . Therefore, Bit input / BN in meanstheactualloadeddatabits eachbatch.Theterm P ld‚àíbit denotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Project Timeline \nFigure 8 despicts a tentative projected timeline for the proposed work. While, we will start all four thrusts in year 1, by the middle of the second year, we expect to have our initial expert models and system support to be in place. By the end of the second year, the preliminary system support will be finalized and we will have the initial expert-to-chiplet mappings ready.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1049 \nInFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp. Latency (ms) \n(a)  Wiki-trace:  Strict  workload. InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "To perform convolution, ReRAM x-bars use a similar approach, but with a more complex circuit. The output of each ReRAM device is the product of the input and weight signals, which are added together using the crossbar wires. This results in a single output signal that represents the sum of the weighted inputs.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "The host runs inference on the compressed data to detect the activity (with an accuracy of 76%). In our example case, transmitting the raw data (60 data points, 32bit floating point data type) needs  240 Byte s of data trans- fer, and with coreset construction and quantization we can limit it to  36 Bytes  (for 12 clusters, each cluster center is represented by 2 Bytes of data, and radius represented by 1 Byte data), thereby  reducing the data communication volume by 85% . However, due to this reduced accuracy, the sensor only takes this option iff it does not have enough energy to perform the inference at the edge device (either in the 16bit or 12bit variant of the DNN - more details on DNN design is presented in Sec- tion 4).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 180,
    "augmented": true
  },
  {
    "text": "These sensor inputs play a major role in deciding which portions of the 3D voxels need to be rendered for the user to view. However, even selective rendering of the portion of a scene, which is in the field of view (FoV) of the user, on a mobile device with limited compute and power budget is challenging [ 19 ,  52 ]. This calls for finding further opportunities for optimization.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "5.5. 4.3 Inter-Holo Computation Optimization \nWe first answer how to deploy the previously proposed foveated rendering technique on AR holograms, by investigating how to leverage the temporal similarity when the user‚Äôs region of focus is only a part of the entire viewing window, as mentioned earlier in Sec. 2.2 (Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. o information.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Our training infrastructure utilizes NVIDIA A6000 GPUs with 48 GiB of memory, supported by a 24-core Intel Xeon Gold 6336Y CPU. 4.1 Development and Profiling of NExUME \nNExUME uses a combination of programming languages and technologies to optimize its functional- ity in intermittent and low-power computing environments. The software stack comprises Python3 (2.7k lines of code), CUDA (1.1k lines of code), and Embedded C (2.1k lines of code, not including DSP libraries).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Intellectual Merit: This project explores hw-sw support to transform applications into suitable device-agnostic codelets, that serve as the granularity for seamless scheduling and execution across GPUs and FPGAs. Broader Impacts: The research results from this project have been fused into different classes at Penn State, and the project has benefited from the participation of undergraduate honor students. Five PhD students, supported through this project, have graduated and one has joined as a faculty.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "11. Percentages of additional inferences with power prediction over all inferences and additional inferences with the  Transition keep \nstrategy \nThe portion of inferences added with power prediction are signiÔ¨Åcant for  Piezo  for most workloads. This is because, the Piezo  source is very weak and and the total completed number of inferences is quite small.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "We collected over 700,000 samples over a period of 2 hours for each of the sensors. We use iNAS (Mendis et al., 2021) to find the DNNs meeting the energy income and train them using our proposed DynFit. The sensor data were cleaned, normalized, and converted to the power spectrum density for further analysis.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "297 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "However, the teacher models are typically large, and with a wide parameter space can generalize the learning process better than the students. These teacher models are often factory trained. As they are less prone to drift, they need occasional updates.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "on Digital Audio Effects (DAFx-08) , 2008, p. 31. Conf. [85] Shadi Noghabi, Landon Cox, Sharad Agarwal, Ganesh Anantha- \narayanan, ‚ÄúThe emerging landscape of edge-computing,‚Äù in  ACM SIGMOBILE GetMobile , 2020.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "[85] Shadi Noghabi, Landon Cox, Sharad Agarwal, Ganesh Anantha- \narayanan, ‚ÄúThe emerging landscape of edge-computing,‚Äù in  ACM SIGMOBILE GetMobile , 2020. [87] K. Simonyan and A. Zisserman, ‚ÄúVery deep convolutional networks for \nlarge-scale image recognition,‚Äù  arXiv preprint arXiv:1409.1556 , 2014. [86] Si Young Jang, Yoonhyung Lee, Byoungheon Shin, Dongman Lee, \nDionisio Vendrell Jacinto , ‚ÄúApplication-aware iot camera virtualization for video analytics edge computing,‚Äù in  ACM/IEEE SEC , 2018.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 180,
    "augmented": true
  },
  {
    "text": "Proceedings of the ACM on Programming Languages , 2(4):1‚Äì25, 2018. [26] Scott Cheng, Jun-Liang Lin, Murali Emani, Siddhisanket Raskar, Sam Foreman, Zhen Xie, Venka- tram Vishwanath, and Mahmut Taylan Kandemir. Thorough characterization and analysis of large transformer model training at-scale.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "AWS Lambda. Serverless Functions. https://aws.amazon.com/ lambda/.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": ", 2(3), December 2018. [154] Arash Tavakkol, Juan G√≥mez-Luna, Mohammad Sadrosadati, Saugata Ghose, and Onur Mutlu. MQSim: A framework for enabling realistic studies of modern Multi-Queue SSD devices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "NASA at Home ‚Äì Virtual Tours and Apps. \"https://www.nasa.gov/ nasa-at-home-virtual-tours-and-augmented-reality\". [35]  Takashi Nishitsuji, Yota Yamamoto, Takashige Sugie, Takanori Akamatsu, Ryuji Hirayama, Hirotaka Nakayama, Takashi Kakue, Tomoyoshi Shimobaba, and Tomoyoshi Ito.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "James Jie Pan, Jianguo Wang, and Guoliang Li. In  Companion of the 2024 International Conference on Management of Data , pp. Vector database management techniques and systems.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "). Strategies in- clude adaptive aggregation methods, energy-aware training schedules, and robustness to device dropouts ( ? However, these approaches often assume some level of reliability or do not fully integrate energy harvesting dynamics into the learning process.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "For example, a dynamic RoI encoding is proposed to compress the data volume to be transferred through net- work [17]. Different from these two prior works where approximation decisions are dictated by reuse distance (e.g., the distance between two fully-inferenced frames), Potluck [12] utilized the feature vector extracted from input frames to adaptively trade off computation with reuse of the cached results. In addition to those described above, several ofÔ¨Çoading- based techniques have been proposed to speed up the inference on edge.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "Choosing  NP  con- serves energy but forfeits any contribution or associated reward. Ev- ery inference event presents a binary decision for sensor  s i : a i ( t )  ‚àà{ Participate (P) ,  Not Participate (NP) } . Choosing P  involves selecting an SNR level, incurring energy costs, and aiming to improve global accuracy.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "App DBP Total Fanout Possible Paths Max Depth Social Network 2 8 7 5 Media Service 3 7 5 6 Hotel Reservation 1 2 2 4 Table 2: Analyzing Variability in Application Workflows. For instance, from \n154 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nFeatures \nArchipelago [44] \nPower-chief [51] \nFifer [32] \nXanadu [27] \nGrandSLAm [34] \nSequoia [46] \nHybrid Histogram [42] \nCirrus [25] \nKraken \nSLO Guarantees ‚úì ‚úó ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì Dynamic DAG Applications ‚úó ‚úó ‚úó ‚úì ‚úó ‚úó ‚úó ‚úó ‚úì Slack-aware batching ‚úó ‚úó ‚úì ‚úó ‚úì ‚úó ‚úó ‚úó ‚úì Cold Start Spillover Prevention ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úì Function Weight Apportioning ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úì Energy Efficieny ‚úó ‚úì ‚úì ‚úì ‚úó ‚úó ‚úì ‚úì ‚úì Request Arrival Prediction ‚úì ‚úó ‚úì ‚úì ‚úì ‚úó ‚úì ‚úó ‚úì Satisfactory Tail Latency ‚úì ‚úó ‚úì ‚úó ‚úì ‚úì ‚úì ‚úì ‚úì \nTable 1: Comparing the features of  Kraken  with other state-of-the- art resource management frameworks. the start function  NGINX , any one of  Search ,  Make_Post , Read_Timeline  and  Follow  can be taken.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 393,
    "augmented": true
  },
  {
    "text": "3581045 . Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuscenes: A multimodal dataset for autonomous driving.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Our research aims to  bridge  this gap, focusing specifically on the exigencies of continuous learning applications. 2.2 The Problem: Understanding the Data Flow \nChallenges in Data Movement:  In both consumer applications and high-performance computing (HPC) programs, the process of data collection followed by analytics is a critical operation (Cao et al., 2020; Mailthody et al., 2019; Chapman et al., 2019; Li et al., 2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window_partial",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "The  ùê∂ùëúùëõùëõ procedure in Algorithm 1 makes use of this formula. To this end,  Kraken  makes use of a parameter called  Connec- tivity , while assigning function weights. The  Connectivity of a function is defined as the ratio of number of its descen- dant functions to the total number of functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "As these applications become more ubiquitous, partic- ularly in urban deployments for tasks like trafÔ¨Åc surveillance, autonomous driving, and health analytics [ 18 ], [ 77 ], [ 90 ], demands on communication bandwidth and network reliability limit the direct streaming of diverse data (e.g., video, 3D point cloud, sensor, voice) from numerous sensor-compute nodes to the cloud. Moreover, recent changes in privacy regulations across multiple countries [ 2 ], [ 100 ] call for preserving the privacy of citizens [ 12 ] and may preclude streaming personal data to third-party cloud services. As a result, ‚Äúon-premise‚Äù edge servers  [ 7 ], [ 8 ] have become prime choices for local inference and prediction [ 6 ], [ 39 ], [ 85 ], [ 86 ], necessitating the handling of both learning and inference tasks to meet application needs, including privacy preservation, reduced data communication, and disaggregated computing.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 213,
    "augmented": false
  },
  {
    "text": "10 \nReferences \nSayed Saad Afzal, Waleed Akbar, Osvy Rodriguez, Mario Doumet, Unsoo Ha, Reza Ghaffarivar- davagh, and Fadel Adib. Battery-free wireless imaging of underwater environments. Nature communications , 13(1):5546, 2022.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "3581045 . Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuscenes: A multimodal dataset for autonomous driving.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "13 √ó  data movement reduction, compared to classical systems. Looking ahead, the role of storage systems is poised to become even more pivotal as ML applications continue to evolve and generate larger, more complex datasets. This is particularly evident in continuous learning scenarios prevalent in applications such as autonomous driving and urban mobility, where the volume and complexity of data are immense.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Thus,  Cocktail  is inherently fault-tolerant owing to the parallel nature in computing multiple inferences for a single request. In contrast,  Cocktail  incurs a modest accuracy loss of well within 0.6% and quickly adapts to reach the target accuracy. An alternate solution would be to restart the queries in running instances but that leads to increased latencies for the 1% requests.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "8: Measure key indicators: participation rate, average energy depletion rate, frequency of incorrect infer- ences, and overall inference accuracy. 9: if  participation is too low (e.g.,  < p min ) or sensors remain idle too often  then 10: Increase  Œ≥ k  ‚Üê Œ≥ k  + ‚àÜ Œ≥  or decrease  Œ∑ k  ‚Üê Œ∑ k  ‚àí ‚àÜ Œ∑ . 11: else if  participation is too high, leading to frequent energy depletion  then 12: Decrease  Œ≥ k  ‚Üê Œ≥ k ‚àí ‚àÜ Œ≥  or increase  Œ¥ k  ‚Üê Œ¥ k +‚àÜ Œ¥ to discourage high-risk attempts.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "-18.87 \n-9.14 \n-10.2 -11.35 \n-20 \n-15 \n-10 \n-5 \n0 \n0% 20% 40% 60% 80% 100% \nRapidly Varrying \nModerately \nstable \nRelatively \nStable \nFully Powered \nLoss in accuracy in % \nContribution of Policy \nExemplar Profiler Morphable No Optimization \n(a) Contribution of components on video data \n0 \n0.1 \n0.2 \n0.3 \n0.4 \n0.5 \n0.6 \nBest Average Best Average \nUsas iCARL Usas Optimus \n# Relative Exemplars # Relative Epoch \nRelative Error wrt Oracle  \n(Lower  is better) \n(Audio) Audio MNIST (Audio) CHiME Home (3D PC) KITTI Vision \n(3D PC) nuScenes (IMU) Bearing Fault (IMU) MHEALTH \n(b)  Us. ¬¥as  beyond video data \n0 \n10 \n20 \n30 \n40 \n50 \nPredictable Sporadic Predictable Sporadic Predictable Sporadic \nLarge - Video (SA size: 256; AP: 16W) \nMedium - Audio (SA size: 128; AP: 8W) \nSmall - IMU (SA size: 128; AP: 2W) \n% of Unfinished  Compute  \ndue to Power Failure \nAverage Power Baseline SW Backup SW + NVM HW + NVM \n(c)  Us .¬¥as  hardware - different data and energy \nFig. 10: Contribution of different components of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 336,
    "augmented": true
  },
  {
    "text": "Consider the geometry compression pipeline in PCL [ 72 ], where the points are added one-by-one when constructing the octree. Initially, the bounding box is inÔ¨Ånitely small (side length is  0 , corresponding to no data); and the octree only has one root  node, which is just a ‚Äúvirtual placeholder‚Äù containing \n288 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "1. 2. We comprehensively characterize the cost, accuracy and latency implications of hosting ML inferences on different public cloud resource offerings and unravel the suitable model/resource configurations to meet the cost, latency and accuracy demands.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, we present a systematic study of integrating the  temporal correlations  and  region-based inference  in a  uniÔ¨Åed  approach and try answering the following critical questions:  (i) what \nis the scope to explore both the pixel- and computational- similarities, i.e., frame-level, region-level or pixel-level? ,  (ii) can we exploit the temporal continuity of the video steam and safely skip the inference computation for similar frames? , and if not,  (iii) can we just focus on the RoIs in the current frame and signiÔ¨Åcantly reduce the computational requirements for its inferencing?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "Towards this, we plot, in Fig. 8b, the average number of depth planes (across our six videos), required by the four design alternatives (configurations). We see that, the number \n4 Due to space limitation, we chose six representative categories that cover diversity across multiple video parameters.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "2), ER-r might lead to lower accuracy in many cases. Moreover, since all sensors are not equally capable of classifying each activity with same accuracy (Fig. Using ER-r, we can complete more total inferences, \n1 This can also be extended to larger numbers of sensors and modalities \nbut this design is limited by the accuracy of individual sensors.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "9c. These additional energy savings come from the computational reduction by partial inference, rather than computing for the entire frame. 1081 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "We first restate the key assumptions and the utility model. We then show that the iterative best- response updates cannot lead to infinite improvement cycles, implying the existence of an NE. Finally, we prove that the equilibrium is reached under the given assumptions.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Given the power and compute constraints of the IoT devices performing sensing, it is difÔ¨Åcult to execute these inference tasks on the sensing device itself, excepting a few intermittent tasks such as bio-metric authentication. Instead, to perform complex and continuous inference, such as HAR, the data is typically ofÔ¨Çoaded either to the cloud or \nto a nearby host device which in turn executes the inference or further redirects it [4] and, Ô¨Ånally, returns the results to the IoT devices responsible for data display or actuation, dependent on the inference task. Recent works [5], [6] suggest that processing data at the source is more efÔ¨Åcient that sending them to the cloud and getting the results back, owing to the power and latency overhead of data communication.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 167,
    "augmented": false
  },
  {
    "text": "Unlike prior works, we suggest that the input and output parameters can be any linear combination of the three primary parameters men- tioned above, depending on the application constraints. Note that, in contrast to cost and response-latency, accuracy can- not be determined just from the previous runs. We need some feedback from the end-user to make a correct estimate of accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Utility Function Definition \nWe define a utility function  U i ( t )  for each sensor  s i  that en- capsulates the trade-off between accuracy gains and energy \nexpenditures, as well as future opportunities. The utility function is designed to reflect both immediate rewards and long-term sustainability. Immediate Rewards and Penalties: Let  Œ≥ >  0  be a scal- ing factor that translates accuracy gains into utility rewards.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Additionally, our custom chiplet hardware will be simulated using the publicly-available RapidChiplet [68] simulator. Tensor cores and matrix multiplication engines will be simulated using ScaleSim v2 [137,138], while the memory hierarchy (both DRAMs and HBMs) will be rep- resented using Ramulator [36]. The custom cache hierarchy will be analyzed through gem5 and Cacti [114], and storage drives will be modeled using MQSim [154] and FlashSim [82].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "2   To un- derstand the impact of DVFS on energy savings and dynamic compute scaling, we implemented a simple multi-arm bandit algorithm to select the right bucket of compute frequencies (SM frequency for NVIDIA GPUs), and memory frequencies to match the power-demands of the intermittent solar source. As shown in Fig. 4  even with DVFS, commercial off the shelf GPUs could only Ô¨Ånish  <  50% of the scheduled training task.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "3 \nframe features and the motion vectors from the compute hardware to perform a novel layered neural compression. This includes a hardware software co-design for compute-intensive applications along with map- ping different functions to different hardware in the data pipeline. ‚Ä¢  We discuss the storage data-flow, the compute orchestration and mapping in the proposed system.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "If Œ≥  is too high, sensors may waste energy attempting difficult inferences. If  Œ≥  is too low, sensors will not have suffi- cient incentive to expend energy on high-SNR captures. Conceptual Role of Parameters \nThe scalar  Œ≥ >  0  represents the reward scaling for correct participation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "331‚Äì344. [24] D. A. Palmer and M. Florea, ‚ÄúNeural Processing Unit,‚Äù 2014, uS Patent 8,655,815. [25] Z.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "In addition, from an individual video‚Äôs perspective, we further observe that the  shoe  video achieves the maximum performance benefits from our schemes (specifically, 23%, 69% and 73% latency reduction with Inter-Holo ,  Intra-Holo  and  Inter-Intra-Holo , respectively, compared to the baseline). In contrast, the  bike  video achieves the minimum speedup (4%, 34% and 36% in the same order). The reason behind this is that, as shown earlier in Tab.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "However, they never considered an intermit- tent power source, nor explored jointly optimizing multiple models with power, accuracy and latency constraints. To achieve this, we design a ‚Äúmicro-proÔ¨Åler‚Äù that can look into the drift of the models as well as the power availability and decide the right hyperparameters to train the models. Prior works [ 12 ], [ 38 ], [ 68 ] have designed hyperparameter micro-proÔ¨Ålers.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "2021. HoloAR: On-the-fly Optimization of 3D Holographic Processing for Aug- mented Reality. In  MICRO-54: 54th Annual IEEE/ACM International Sympo- sium on Microarchitecture (MICRO ‚Äô21), October 18‚Äì22, 2021, Virtual Event, Greece.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "The space complexity is  O ( N )  for storing the update frequencies and additional parameters. Complexity Analysis of DynFit:  The time complexity of DynFit during training is  O ( N  ¬∑  T ) , where N  is the number of weights and  T  is the number of training iterations. The overhead introduced by monitoring update frequencies and adjusting dropout rates is negligible compared to the overall training time, as these operations are simple arithmetic computations per iteration.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "3  and discussed in Sec. III-B , apart from identifying the locality existing in geometry data, the Morton codes can also help us capture the attribute locality. Motivated by this, we further optimize the attribute compression pipeline for a given frame, as shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Therefore, this results in reduced cost and at the same time does not violate SLOs. This re-instantiates our claim that the resource procurement scheme needs to be aware of request constraints. Figure  1  shows the candidate models which can be used for a given latency and accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "Figure  3b  shows that ensemble-spot can re- duce the cost by up to 3.3 √ó  when compared to ensemble-OD. For certain baselines like IRV2, ensemble-spot is also 1.5 √ó cheaper than single-OD. However, the crucial downside of using transient VMs is that they can be unilaterally preempted by the cloud provider at any given point due to reasons like in- crease in bid-price or provider-induced random interruptions.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Therefore, this work proposes an intelligent scheduler along with efÔ¨Åcient ensemble learning to enable DNN inference in a distributed energy harvesting wireless sensor network (EH- WSN). This work proposes a novel policy,  Origin , which enables energy harvesting wireless sensors to perform efÔ¨Åcient and accurate DNN inference. SpeciÔ¨Åcally, Origin targets inherent features of sensor data from distributed body area networks in human activity recognition (HAR) tasks and leverages non- volatile processing, intelligent scheduling for energy-harvesting sensor nodes, and ensemble leaning to classify human activity with minimum accuracy loss compared to a state-of-the-art battery powered system.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 50th Annual International Symposium on Com- puter Architecture , ISCA ‚Äô23, New York, NY, USA, 2023. [76] Norm Jouppi, George Kurian, Sheng Li, Peter Ma, Rahul Nagarajan, Lifeng Nai, Nishant Patil, Suvinay Subramanian, Andy Swing, Brian Towles, Clifford Young, Xiang Zhou, Zongwei Zhou, and David A Patterson. Tpu v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "In our setup, one I-frame(intra-compressed frame) is followed by two P-frames(predicted frames), and the number of threads for MB matching is set to 4. 6 \n‚Ä¢  Intra-Only : We apply our intra-frame compression method discussed in Sec. Similarly, we have opted to use octree-based algorithm for geometry compression, and directly applied entropy encoding to the raw attributes.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Unlike traditional codecs that rely on predefined algorithms to compress video data, neural codecs utilize an end-to-end trainable system based on neural networks. These networks are trained on extensive video datasets, allowing them to dynamically adapt compression strategies based on the content‚Äôs complexity and prevailing network conditions. The architectural backbone of neural codecs typically comprises an autoencoder, where the encoder compresses the video into a compact, lower-dimensional representation, and the decoder reconstructs it back into video format.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "This is because requests that have to wait longer than the cold start would be served faster at a newly created container than by waiting at an overloaded container. Similarly, for stages where container overprovisioning has occurred, the RS  7  gradually scales down its allocated containers to the appropriate number, if its Function Idler module  7b  detects excess containers for serving the current load (Algorithm 2  a ). Thus, the RS  7  , in combination with the PWS  2  and re- quest batching  5  , helps  Kraken  remain SLO compliant while using minimum resources.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "199‚Äì208. 2020. https: //doi.org/10.1109/CLOUD.2019.00043 [32]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Nachiappan C Nachiappan, Mahmut Taylan Kandemir, and Chita R Das.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": ", 11(12):2046‚Äì2049, aug 2018. ISSN 2150-8097. doi: 10.14778/3229863.3236256. URL  https://doi.org/10.14778/3229863.3236256 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Quantifying generalization complexity for large language models, 2024. In  The Twelfth International Conference on Learning Representations , 2023. [133] Zhenting Qi, Hongyin Luo, Xuliang Huang, Zhuokai Zhao, Yibo Jiang, Xiangjun Fan, Himabindu Lakkaraju, and James Glass.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "ITU-T Recommendation H.265. International Telecommunication Union, June 2019b. URL https://www.itu.int/rec/T-REC-H.265 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "Thus, improving the computational efficiency of the holographic pipeline is critical. The objective of this paper is to maximize its energy efficiency without jeopardizing the hologram quality for AR applications. Abstract \nHologram processing is the primary bottleneck and contributes to more than 50% of energy consumption in battery-operated aug- mented reality (AR) headsets.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Fine-grained reconÔ¨Åguration:  The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes. This Ô¨Çexible reconÔ¨Ågurability enables Ô¨Åne-grained activations to exploit the harvested power. While execution is relatively straightforward when maintaining a speciÔ¨Åc conÔ¨Åguration of tiling and pipelining strategy, transitions between conÔ¨Ågurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "In  Ambient Assisted Living and Daily Activities: 6th International Work-Conference, IWAAL 2014, Belfast, UK, December 2-5, 2014. 91‚Äì98. Proceedings 6 , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Debendra Das Sharma. Compute express link¬Æ: An open industry-standard interconnect enabling het- erogeneous data-centric computing. In  2022 IEEE Symposium on High-Performance Interconnects (HOTI) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "[196] Yanqi Zhou, Nan Du, Yanping Huang, Daiyi Peng, Chang Lan, Da Huang, Siamak Shakeri, David So, Andrew Dai, Yifeng Lu, Zhifeng Chen, Quoc Le, Claire Cui, James Laudon, and Jeff Dean. Brain- formers: Trading simplicity for efficiency. pages 42531‚Äì42542.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Since fault-tolerance has become a major concern for long-running training jobs [39,75,200], our proposed chiplet-based design should be able to handle hardware and software faults in a gracefully-degraded manner. In addition, the plug-and-play nature of chiplet provides better ‚Äúfault isolation‚Äù, as only the faulty chiplet can be changed as opposed to throwing away an entire chip. In this project, we will investigate the fault-tolerance behavior of the chiplet architecture by injecting different types of faults.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Note that the conÔ¨Ådence matrix reaches the steady state of baseline accuracy within 100 iterations. This, in turn, will lead to better and more stable classiÔ¨Åcation for every individual without extensive need for retraining and updating the DNN, which might be impractical for EH-WSNs due to the high communication cost while updating the parameters. V. C ONCLUSION \nEnabling DNN inference on edge devices has been gaining recent traction, especially for tasks like HAR.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Corne Lukken and Animesh Trivedi. IEEE Transactions on Very Large Scale Integration (VLSI) Systems , 27(10):2459‚Äì2463, 2019. Optimized schoolbook polynomial multiplication for compact lattice-based cryptography on fpga.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "3 Prelude to Cocktail \nTo speciÔ¨Åcally address the cost of hosting an ensembling- based model-serving framework in public clouds without sacriÔ¨Åcing the accuracy, this section introduces an overview of the two primary design choices employed in  Cocktail . How to reduce resource footprint? The Ô¨Årst step towards making model ensembling cost effective is to minimize the \n1044    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \number of models by pruning the ensemble, which reduces the overall resource footprint.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "IV-C 1 ), and macro block-based motion compensation pipeline for inter-frame compression \n3 We use PCL [ 72 ] and TMC13 [ 56 ] library for our proÔ¨Åling, where the geometry is compressed by the octree structure in PCL, and the attributes (RGB colors) are compressed through RAHT in TMC13. 285 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "However, for the objects outside of the current RoF, since the user is not cur- rently focusing on them, a reasonable approximation would not affect the user experience that much (which implies we do not need 16 depth planes for all of them). For example, in  Frame-I  in Fig. 5b, the user is currently focusing on the  soccer ball ; mean- while the  football  is located outside of the RoF, hence, becomes a candidate for approximation.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "2020. Mesorasi: Architecture Support for Point Cloud Analytics via Delayed- aggregation. In  Proceedings of the International Symposium on Microarchitecture (MICRO) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "Moreover, in many cases, computations are also sensor input-dependent such as the IMU data for determining the head orientation, which is updated across frames , at runtime. Thus, to explore computation reuse op- portunities, we start by distinguishing between 4 complemen- tary opportunities ‚Äì  InterFrame-IntraEye (EA) ,  IntraFrame- InterEye (AE) ,  IntraFrame-IntraEye (AA) , and  InterFrame- InterEye (EE) , using a represent example shown in Fig. 4.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "A typical DNN model has two different phases, namely,  training  and inference . Among many ML paradigms, Deep Neural Net- works (DNNs), owing to their generalization and massively- parallel nature, has been predominant in making all these applications pervasive and accessible to developers. https://doi.org/10.1145/3429880.3430093 \n1 Introduction \nSustained advances in ML has fueled the proliferation of emerging applications such as product recommendation sys- tems, facial recognition systems, and intelligent personal assistants [ 7 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "9:  end for \nRegularizers and SGD Convergence: The chosen reg- ularizers  ‚Ñ¶ SNR ( Œ∏ )  and  ‚Ñ¶ complexity ( Œ∏ )  are both convex and smooth, with known closed-form gradients. This property guarantees that the inclusion of regularizers does not com- promise the convexity or smoothness of the overall objective J ( Œ∏ ) . Consequently, the stochastic gradient descent (SGD) updates retain their convergence properties, ensuring that the training process reliably optimizes  J ( Œ∏ ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "The Primary Y-Axis denotes the number of containers spawned, The secondary Y-axis indicates the percentage of SLOs met and the X-axis represents each policy. 0 \n2000 \n4000 \n6000 \nOracle Kraken \n# Containers \nNGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network. Figure 14: Simulator: Comparison of Total Number of Containers spawned VS SLOs satisfied by each policy.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Overallo- cation of containers in case of  Arch  is due to two reasons: (i) it assumes that all functions in the application will be invoked at runtime; and (ii) it spawns one container per in- vocation request. On the other hand,  Fifer  improves upon this by reducing the total number of containers spawned using request batching. However, it does not take workflow activation patterns into consideration while spawning con- tainers, leading to container overprovisioning.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1051 \n10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n82.25 \n82.50 \n82.75 \nAccuracy \n(a)  Queries under Constraint-1. 10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n81.0 \n81.2 \n81.4 \nAccuracy \n(b)  Queries under Constraint-2. 10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n79.0 \n79.2 \n79.4 \nAccuracy \n(c)  Queries under Constraint-3.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "of depth planes required by the  Inter-Holo  scheme is reduced from 23 . Figure 8: (a): Profiling the power breakdown on the edge GPU prototype [36]; and (b): Average number of depth planes required for four design configurations. 6 to 19 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Since the head mounted VR devices are battery-backed, the computations that draw high power from the battery greatly hinder the experience of watching long  360 ¬∞ videos [39]. This heavy computation has become an acceleration candi- date/target in previous works, by ofÔ¨Çoading the entire compu- tation, as is, to an accelerator (GPU [39], or FPGA [28]). However, prior works do not consider other avenues for optimizing the computation.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Datasets : We use three published video datasets (VIRAT [33], EPFL [42] and CAMPUS [43]), to study the performance and energy behavior across different videos. The important features of these six videos 4   are summarized in Table II. Neural Network Models:  We examine two DNN models in our experiments: YOLOv3 [44] and YOLOv4-tiny [37].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "In this case, the current frame is processed on the CPU to report the Ô¨Ånal result. Apart from that, the generated \n1079 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "1304‚Äì1311. https://doi.org/10. 1109/ICRA.2014.6907021 [56]  K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, J. Samp- son, M. T. Kandemir, and V. Narayanan.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "1057‚Äì1062, March 2018. [11]  X. Jiang, J. Polastre, and D. Culler, ‚ÄúPerpetual environmentally powered sensor networks,‚Äù in  Fourth International Symposium on Information Processing in Sensor Networks (IPSN) , pp. 463‚Äì468, 2005.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Furthermore, no restriction on the reuse or redistribution of any artifact developed in this project will be placed for non-commercial use. Also, we will prepare educational materials ‚Äì in a slide-deck form ‚Äì that can be easily used in different classes like ML and systems. 5.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "A. Preamble to Origin \nHuman activity has temporal continuity, i.e. A detailed description of the setup is explained in Section IV. In this section, we provide an overview of our proposed solution.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "inferences w/ smooth transition vs. # all inferences vs. # addi. inferences w/ smooth transition \nPiezo Thermal \nLeNet FR HG PV \nFig. 11.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "This strategic equilibrium un- derpins both training and inference participation decisions, ensuring that the sensors most likely to improve the global \n1 \n055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071 072 073 074 075 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109 \nmodel‚Äîgiven their energy, data quality, and network condi- tions‚Äîare the ones that engage. Rather than rely- ing on persistent, centralized updates or continuous feder- ated aggregation, we perform  periodic  or  equilibrium-driven fine-tuning rounds. To refine the global model parameters without incurring continuous on-edge training costs, we adopt a federated learning paradigm adapted to EH-WSNs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 243,
    "augmented": true
  },
  {
    "text": "However,  Arch  and Fifer  use 3.51x and 2.1x more containers than  Kraken  to \n0 \n0.25 \n0.5 \n0.75 \n1 \nArch Fifer DProb Kraken SProb Xanadu \nEnergy Consumption Rate \n(a) Energy Consumption Rate. In particular,  Arch ,  Fifer and  Kraken  show comparable latencies, with P99 values re- maining well within the SLO of 1000ms. 0 \n300 \n600 \n900 \n1200 \n0.25 0.5 0.75 0.98 0.99 \nLatency (ms) \nCDF Kraken Comm Only \nConn Only SLO \n(b) Response Time Distribution.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "Fig. 5a  shows the block diagram of the mesh interconnect, and Fig. 5b  shows the power-down sequence and signal states.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "[32]  Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. arXiv preprint arXiv:2002.08155 , 2020. Codebert: A pre-trained model for programming and natural languages.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "The Ô¨Årst frame is considered as the ‚Äúbase‚Äù, which is always fully inferenced. For the remaining frames however, we invoke Algo. IV-A.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Therefore, there is an urgent need to  minimize compute and power requirements  in archival processes. Moreover, the divergence of analytics and archival pipelines from the outset suggests that optimizing both hardware, software and data-flow used in inference, learning and archival could significantly enhance throughput and energy efficiency. This can be achieved by using modern  neural compression algorithms  instead of the classical encoding algorithm.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "[38] MYO NeuralNet , ‚ÄúCalculating the Output Size of Convolutions and Transpose Convolutions,‚Äù ‚Äùshorturl.at/ioLRV‚Äù, 2020. , p. 433‚Äì466, 1995. [37] Jacob Solawetz, Samrat Sahoo, ‚ÄúTrain YOLOv4-tiny on Custom Data - Lightning Fast Object Detection ,‚Äù ‚Äùshorturl.at/vCSVW‚Äù, 2020.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 27th International Conference on Intelligent User Interfaces , pages 841‚Äì852, 2022. Wordcraft: story writing with large language models. [178] Ted Zadouri, Ahmet √úst√ºn, Arash Ahmadian, Beyza Ermi¬∏s, Acyr Locatelli, and Sara Hooker.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Efficient load balancing for distributed training of deep neural networks. In  Proceedings of the IEEE International Conference on Big Data , pages 1234‚Äì1243. [182] Wei Zhang, Chen Liu, Xinyu Wang, and Jian Li.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "[55]  MPEG, ‚ÄúPoint Cloud Video: Redandblack,‚Äù  ‚Äùhttps://bit.ly/ 3NyQq2R‚Äù , 2022. [56]  MPEGGroup, ‚ÄúGeometry based point cloud compression (G- PCC) test model,‚Äù  ‚Äùhttps://github.com/MPEGGroup/mpeg-pcc- tmc13‚Äù , 2021. [57]  New Farmer Blogger, ‚Äú3D points clouds for immersive real es- tate and telepresence experiences,‚Äù  ‚Äùhttps://bit.ly/3AhWQR5‚Äù , 2015.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "Note that, the ensembles used in our experiments are at-least 4 models or more. For smaller ensembles, instance failures might lead to higher accuracy loss, but in our experiments, single models typically satisfy their constraints. 6.3.3 Sensitivity to Constraints \nFigure  14  plots the sensitivity of model selection policy un- der a wide-range of latency and accuracy constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Task-2.1: Data Locality and Parallelism‚ÄìAware LLM Training Unlike traditional monolithic LLMs, our EoE -based LLM opens up new opportunities to optimize train- ing for both performance and energy efficiency. Each expert in our EoE can be trained independently and faster, significantly reducing the overall training time compared to monolithic models. Additionally, by clustering and scheduling experts that share training datasets, we propose a ‚Äúlocality-aware‚Äù training strat- egy that minimizes the frequency and volume of data transfers between experts, memory and storage‚Äì a key factor in improving both performance and energy efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, considering the similarities between successive video frames, we propose a frame-level compute reuse algorithm based on the motion vectors of each frame. With frame-level reuse, we are able to skip  53%  of frames in inference with negli- gible overhead and remain within less than  1%  mAP (accuracy) drop for the object detection task. Additionally, we implement a partial inference scheme to enable region/tile-level reuse.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "To overcome these limitations,  Us. Prior works relied on supervised learning or K-means clustering, un- suitable for  Us. ¬¥as  due to its need for unsupervised data annota- tion and the inability to handle large-scale datasets with numer- ous classes.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "IV-A 1 ), RAHT for intra-frame attribute compression (Sec. IV-C 1 ), and macro block-based motion compensation pipeline for inter-frame compression \n3 We use PCL [ 72 ] and TMC13 [ 56 ] library for our proÔ¨Åling, where the geometry is compressed by the octree structure in PCL, and the attributes (RGB colors) are compressed through RAHT in TMC13. Towards this, we studied three state-of- the-art PCC pipelines ‚Äì octree-based pipeline for intra-frame geometry compression (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "Our training framework is encapsulated in Algorithm  2 , which outlines the periodic equilibrium-aware training pro- cess. This training framework is intrinsically linked to the game-theoretic participation strategies. Sensors participate \nin training rounds based on their equilibrium-driven de- cisions, ensuring that gradient updates are contributed by those sensors most capable and willing to improve the global model.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Using machine learning to enhance archival processing of social media archives. Journal on Computing and Cultural Heritage (JOCCH) , 15(3):1‚Äì23, 2022. Sailong Fan, Weiqiang Liu, James Howe, Ayesha Khalid, and Maire O‚ÄôNeill.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Restrictions apply. B. Combining Inter-frame and Intra-frame Compression \nSimply put, our intra-frame compression proposal can sig- niÔ¨Åcantly reduce the execution latency, while the inter-frame compression proposal can further improve the compression efÔ¨Åciency.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "We quantitatively compare the effective training, i.e. the ratio of number of scheduled training to the number of completed training, loss of accuracy compared to the baseline. It is clear that even with intermittent power availability  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "In this case, although the MV is smaller than the bounding boxes, its position is on the edge, indicating that a new object is entering the frame. As a result, Frame-2 is critical as it reveals new information that has not been exposed before, and thus requires performing full inference for it. Algorithm 1:  Adaptive Frame Level Reuse Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "This design optimizes the DNN execution in an energy harvesting wireless sensor network by collectively looking into all the involved components. This conÔ¨Ådence score would further update the weight matrix of the host device using a moving average method and keep updating it as the user keeps using the device. D. Origin: AASR meets ConÔ¨Ådence Matrix Combined together, the activity aware scheduler with recall (AASR) and the adaptive conÔ¨Ådence matrix we present  Origin : a holistic system where an intelligent scheduler meets an adap- tive ensemble learner.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Label Description HO dependent? Known-time Eye-dependent? T 1 Rigid body No Compile-time Left = Right T 2 An eye‚Äôs view Yes Runtime Left = Right T 3 Eye adjusting No Compile-time Left  Ã∏ =  Right T 4 Perspective No Design-time Left = Right T 5 Viewport No Design-time Left = Right \ntheir corresponding  360 ¬∞ video frame coordinates.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode. Since each single ReRAM can be activated at a Ô¨Åner granularity with tiling, the parallelism can be achieved under a Ô¨Çexible range of power consumption to match a variable power supply. In this example, the full size of ReRAM (or loop nest) is M  √ó  N  =  A  √ó  B  √ó  C  √ó  N , and the tile size of ReRAM (or loop nest) is  m  √ó  n  = 1  √ó  tb  √ó  C  √ó  tn .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Thrust-1 is aimed at in- vestigating the algorithmic foundations of our EoE paradigm that consists of an ensemble of experts, which will facilitate application-specific morphable LLMs. For executing these morphable experts on an underly- ing hardware, Thrust-2 focuses on investigating system-level issues in EoE training and inference, focusing in particular on expert scheduling and memory hierarchy management. Thrust-3 examines architectural design space for efficient mapping of experts to hardware leading to a chiplet-based design consisting of a heterogeneous platform of compute engines such as CPUs, GPUs, and accelerators.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "[36]  K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúSpendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,‚Äù in  2017 22nd Asia and South PaciÔ¨Åc Design Automation Conference (ASP-DAC) , pp. [35]  M. D. Lam, E. E. Rothberg, and M. E. Wolf, ‚ÄúThe cache performance and optimizations of blocked algorithms,‚Äù in  Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp. 63‚Äì74, 1991.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 167,
    "augmented": true
  },
  {
    "text": "Note that, the reason why the overhead in YOLOv4-tiny is higher is because, YOLOv4-tiny is already a very light-weight model, and consequently, the time spent on decision making is not negligible compared to the extremely fast inference it performs. Additional energy and latency can be saved by the FI+SI+PI scheme, as Fig. 8c-8d and Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "[139] Warren S Sarle. Finding groups in data: An introduction to cluster analysis., 1991. [140] Anup Sarma, Sonali Singh, Huaipan Jiang, Rui Zhang, Mahmut Kandemir, and Chita Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "The algorithm is designed to operate in environments where energy availability is intermittent, such as in devices powered by energy harvesting. It includes mechanisms for loop tiling, checkpointing, and resumption to manage computation across power interruptions effectively. C.1.1 Algorithm Overview \nThe GeMM operation, typically expressed as  C  =  A  √ó  B , where  A ,  B , and  C  are matrices, is imple- mented with considerations for energy limitations.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Origin  uses the DNNs of Baseline-2 for the classiÔ¨Åcation tasks. We plot the accuracy of different strategies described throughout the paper. Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Similar to the data on inference time, the effect from the increasing threshold on prediction accuracy will be more pronounced when there are more devices available and the overall trend seen in Figure 4c is the inverse of that in Figure 4a. Therefore, it is important to choose a threshold that optimizes the trade off between efficiency and accuracy. This makes it possible to find a sweet spot, given specific needs, in efficiency and accuracy trade offs.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "During the occurrence of a fault, prior known works can be used to checkpoint and migrate the execution to a newly spawned chiplet. Or, in training, new memory blocks can be spawned to support the higher KV-caching needs. Further, based on our profiling of the communication behavior across chiplets and chips, we will consider performant and adaptive interconnect designs [80, 81, 110, 116, 127] to co-optimize for latency, bandwidth, and fault tolerance.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Fig. 4 shows the latency while using the storage server and CSD for performing data writes,  normalized  to the latency of doing the same using the state of the art Alveo FPGAs. Salient Store  on CSDs perform  ‚âà 1 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "[55] M. McCloskey and N. J. Cohen, ‚ÄúCatastrophic interference in connec- \ntionist networks: The sequential learning problem,‚Äù in  Psychology of learning and motivation . [54] Markets and Markets, ‚ÄúSmart cities market analysis, industry size and \nforecast,‚Äù  https://www.marketsandmarkets.com/Market-Reports/smart- cities-market-542.html#: ‚àº :text=The%20global%20Smart%20Cities% 20Market,drive%20the%20smart%20cities%20market , 2022, (Accessed on 08/04/2023). 491, p. 229622, 2021.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "¬¥as 95.3 1.92 7 - 10 years \nTABLE III: Comparing  Us. ¬¥as  with other possible solutions. Sustainability:  To ensure sustainable and continuous learning at the edge,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "In  2008 58th Electronic Components and Technology Conference , pages 847‚Äì852. IEEE, 2008. Silicon inter- poser with tsvs (through silicon vias) and fine multilayer wiring.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "Combination of ER-r and AAS, results in more than 70% accuracy for most of the activities (Fig. 4). 0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 RR3 with AAS RR6 RR6 with AAS RR9 RR9 with AAS RR12 RR12 with AAS Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "We will also carve up short lecture materials based on the project and preserve them on departmental machines. Note that the lineage data/metadata will be updated as more characteri- zation and experimental results as well as models are collected/generated or the compiler/system software source codes are updated. 6.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "[24]  James Cadden, Thomas Unger, Yara Awad, Han Dong, Orran Krieger, and Jonathan Appavoo. 2020. SEUSS: skip redundant paths to make serverless fast.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference. In this design paradigm, the basic low power, lightweight MCU system can enjoy the advantage of continuous operation without suffering power outages, while the compute-heavy inference tasks can be ofÔ¨Çoaded to the RCA during periods when power income is sufÔ¨Åciently high and to external systems otherwise. Such a system is capable of both continuously collecting data and computing CNNs locally near data.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "360 ¬∞  Video Streaming Pipeline \nThe key  difference  between a  360 ¬∞ VR video compared to a conventional 2D video is that the former provides content-rich immersive user experience. Further, we describe the existing energy inefÔ¨Åciencies in processing  360 ¬∞ VR systems, to motivate our design for mitigating the com- putational inefÔ¨Åciencies by avoiding redundant computations. A.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Evaluation:  We evaluate our results by comparing the cost, latency and accuracy for two different workloads. Workload- 1 consists of a mix of queries which have both strict and relaxed latency requirements. We compare the execution of this workload against the following resource procure- ment schemes: (i)  util_aware , (ii)  exascale , (iii)  mixed  and (iv) Paragon .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "pages 42531‚Äì42542. PMLR, 2023. [197] Yanqi Zhou, Tao Lei, Hanxiao Liu, Nan Du, Yanping Huang, Vincent Zhao, Andrew Dai, Zhifeng Chen, Quoc Le, and James Laudon.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Discussion:  Our accuracy and latency constraints are limited to the measurements from the available pretrained models. chooses a set of single or ensemble models required to meet the developer speciÔ¨Åed constraints. Note that changing the models or/and framework would lead to minor deviations.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Furthermore, the implications of training these MoEs in terms of required architectural and system support, overall training time, accuracy, and dynamic adaption in different application domains have not been systematically investigated. Additionally, there exists significant load imbalance among experts, increased communication overhead, and complexity in routing mechanisms [42,74,131,151]. Thus, while the MoE/CoE design paradigm is promising, the overall solution space is little explored, especially for complex compositions of smaller experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "time support and hardware-based enhancements, performance- and energy-efÔ¨Åcient execution of DNN pipelines for videos on mobile devices are still open problems. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "This again indicates that, within a smaller macro block, the voxels have richer similarity with their neighbors. Temporal Locality in Attributes:  To study the temporal attribute locality across two frames, we plot the CDF of the attribute deltas among two segments in an I-frame and a P-frame in Fig. 3  b  , and a visual view of how these segments look like in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efÔ¨Åciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ]. Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efÔ¨Åciently performing inference on an IoT device if it does not have either a high power or high stability power source. In the remainder of the paper, we may shorten the term  ReRAM crossbars  to  ReRAMs .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 186,
    "augmented": true
  },
  {
    "text": "We show that uniformly scaling resources for all models in the ensemble leads to over-provisioning of resources and towards minimizing it, we build a distributed weighted auto-scaling policy that utilizes the  importance sampling technique to proactively allocate resources to every model. Further,  Cocktail  leverages transient VMs as they are cheaper, to drastically minimize the cost for hosting model- serving infrastructure in a public cloud. 2 Cocktail is ascribed to having the perfect blend of models in an ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "The impact of wrong labeling is discussed in ¬ß V . The Problem:  However, this exemplar section mechanism has an inherent Ô¨Çaw. Consider a trafÔ¨Åc camera looking at a busy street with a trafÔ¨Åc signal.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "However, harvested energy is fickle in nature, and typically \narXiv:2408.14379v1  [cs.AR]  26 Aug 2024 \nharvested sources only deliver scant microwatts of power (see Figure 1b for an overview). The sporadic nature of har- vested energy and the lossy nature of EH based storage and charging circuits calls for using the harvested energy di- rectly to perform intermittent compute rather than storing energy for some distant future use. More importantly, EH can help us build sustainable distributed sensing/monitoring infrastructure at virtually inaccessible places like oil-wells, mines, and even satellite orbits [ 14 ,  49 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 44th annual IEEE/ACM international symposium on microar- chitecture , pages 374‚Äì385, 2011. [113] Saurav Muralidharan, Sharath Turuvekere Sreenivas, Raviraj Joshi, Marcin Chochowski, Mostofa Pat- wary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, and Pavlo Molchanov. Compact language models via pruning and knowledge distillation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "This dynamic routing reduces computational overhead and energy consumption, helping in addressing the power efficiency concerns. To support this modularity, we also propose a flexible system architecture and runtime that efficiently handles queries. Smart routers dynamically direct queries to the most rele- vant experts based on domain relevance and operational dynamics, optimizing performance and resource utilization.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "3) ,which can be projected to both eyes on the HMD. 3  a  for compu- tation of the  Transformation Matrix , is used for projecting the 360 ¬∞ frame pixels onto the  2 D  FoV plane in the subsequent stages. The  Transformation  stage, shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Accessed: 2024-10-20. [137] Ananda Samajdar, Jan Moritz Joseph, Yuhao Zhu, Paul Whatmough, Matthew Mattina, and Tushar Krishna. A systematic methodology for characterizing scalability of dnn accelerators using scale-sim.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "2b. We illustrate the  360 ¬∞ video projection/projection transfor- mation 3   computation in Fig. At a high level, we need two major inputs to generate the Ô¨Ånal projected frames on the display.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "In  2020 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pp. 315‚Äì327. Resirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent embedded processors.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "2018. SAND: Towards High-Performance Serverless Computing. In  ATC .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "¬¥as  operates independently of the power grid or cloud dependency. We evaluated  Us. Sustainability:  To ensure sustainable and continuous learning at the edge,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "baseline InterHolo IntraHolo InterIntraHolo \nEnergy (J) \nHoloCompute Overhead \n3.68 \n1.40 1.28 \n(c) Energy consumption (J). Figure 7: (a) Average power consumption, (b) execution latency, and (c) energy consumption with different configurations and video inputs. 0 \n2000 \n4000 \n6000 \n2 4 6 8 10 12 14 16 \nPower (mW) \n# Depth-planes \nCPU SoC GPU Mem \n(a) Power breakdown.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Available at:  https://huggingface.co/meta-llama/Llama-3.1-405B . [107] Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Ama- triain, and Jianfeng Gao. Large language models: A survey.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Cerebras architecture deep dive: First look inside the hardware/software co-design for deep learning. IEEE Micro , 43(3):18‚Äì30, 2023. [96] Sean Lie.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Since Algo. ), we now turn to the second question raised above ‚Äì how to maintain accuracy? 2 has answered the Ô¨Årst question (i.e., for a speciÔ¨Åc frame, what is the inference choice ‚Äì FI, PI or SI?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "In both cases, due to the resource limitation of the edge devices, edge-specific model size may be reduced at the expense of accuracy. Thresholding the Edge:  The ideal case, for either of the aforementioned models, is when all the compute can be done, accurately, at the edge devices. However, to alleviate the shortcomings of less accurate predictions at the edge, some computations are routed to the cloud, expecting a better result at the expense of a higher latency.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "[11] Beverly Hills has thousands of surveillance cameras, ‚Äúhttps://bit.ly/BeverlyHillsCamera.‚Äù [12] R. Bhardwaj, Z. Xia, G. Ananthanarayanan, J. Jiang, Y. Shu, N. Kar- \nianakis, K. Hsieh, P. Bahl, and I. Stoica, ‚ÄúEkya: Continuous learning of video analytics models on edge compute servers,‚Äù in  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , 2022, pp. [7] AWS Outposts, ‚Äúhttps://aws.amazon.com/outposts/rack/hardware- specs/?nc=sn&loc=4.‚Äù [8] Azure Stack Edge, ‚Äúhttps://azure.microsoft.com/en- us/services/databox/edge/.‚Äù [9] O. Banos, C. Villalonga, R. Garc¬¥ƒ±a, A. Saez, M. Damas, J. Holgado- \nTerriza, S. Lee, H. Pomares, and I. Rojas, ‚ÄúDesign, implementation and validation of a novel open framework for agile development of mobile health applications,‚Äù  BioMedical Engineering OnLine , 2015. [10] S. Bauer, ‚ÄúExplainer: The opportunities and challenges of the lithium \nindustry,‚Äù  Di¬¥alogo Chino , 2020.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 346,
    "augmented": true
  },
  {
    "text": "Thus, we believe our proposal is ambitious as its potential to revolutionize the training and deployment of LLMs is profound. 2 Proposed Research \nA high-level view of our proposed research consisting of 4 thrusts is depicted in Figure 2. In addition to the individual tasks in each thrust, Figure 2 also shows the inter-task dependencies as well as interactions between them, highlighting our cross-layer co-design aspect.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Figure 1:  BeneÔ¨Åts of  Cocktail . Re- sults are normalized (higher the better). Second, it utilizes dis- tributed autoscaling poli- cies to reduce the la- tency variability and re- source consumption of hosting ensemble mod- els.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "1hour for 3D Point Cloud simulated data. [SM:Small Model (smaller model or larger model pruned and quantized using energy aware pruning [ 102 ] and NetAdapat [ 103 ]), LM:Large Model (no pruning or quan- tization), SMR:Small Model with Retraining]. emerged as a preferred approach to mitigate data drift [ 20 ], [ 44 ], [ 50 ], [ 74 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "In  Acm Sigplan Notices . References \n[1]  Mart√≠n Abadi. TensorÔ¨Çow: learning functions at scale.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Student Support : The project will support four PhD students for the proposed three-year duration of the project. Zhang and Kandemir have recently co-authored a paper in MICRO (2024) and all three PIs have co-authored a paper in NeurIPS (2021). The students will work on separate thrusts in the beginning (one student will be the primary contact for each thrust), but they will works together in the last year for integrating the different compo- nents of the research for a comprehensive evaluation and refinements of the proposed models, algorithms, compiler and system support.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "For example, during inference, the system can decide to map an expert onto a chip but the suitable hardware may not be directly present. In this case, the reconfigurable chiplet can be transformed into a suitable compute engine. Or, in training, new memory blocks can be spawned to support the higher KV-caching needs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "The load to each function within each applica- tion is calculated separately using the collected information. This prevents other applications from interfering with the probability calculation of shared functions. Additionally, the PWS uses a DAG descriptor, which is a file that contains a python dictionary that specifies the connectivity among functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "[37] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, \nS. Bates, S. Bhatia, N. Boden, A. Borchers  et al. , ‚ÄúIn-datacenter performance analysis of a tensor processing unit,‚Äù in  Proceedings of the 44th annual international symposium on computer architecture , 2017, pp. 1‚Äì12.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "6 s ). However, as also shown in Fig. 6 , the storage size after our compression is larger than RAHT, since each segment requires one vector storage to store its median/base and (quantized) delta values.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Finally, the candidate I-block which differs minimally with the P-block is picked as its ‚Äúbest-matched/reference‚Äù block. SpeciÔ¨Åcally, given two blocks with K-points, we use 2-norm attribute distances (see Equ. 2 ) to measure their difference: \nDi f f ( I block , P block ) =  ‚àë K i = 1 ( r iP  ‚àí r iI ) 2  +( g iP  ‚àí g iI ) 2  +( b iP  ‚àí b iI ) 2  (2) \nwhere  P block  =  { ( x iP , y iP , z iP , r iP , g iP , b iP ) } ,  I block  =  { ( x iI , y iI , z iI , r iI , g iI , b iI ) } , for  i  =  { 1 ,..., K } .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 259,
    "augmented": false
  },
  {
    "text": "As discussed earlier, Salient Store  edge storage implements a video archival by using neural compression followed by a quantum safe encryption (refer Fig. 1). To maximize the compute reuse between the compute pipeline and the archival pipeline,  Salient Store  uses apart of the neural network of the inference engine to extract features, and then further performs the encoding using the FPGA in the CSD.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "[25] N. INSTRUMENTS, ‚ÄúPeak Signal-to-Noise Ratio as an Image Quality Metric.‚Äù ‚Äùhttps://www.ni.com/en-us/innovations/white-papers/11/peak- signal-to-noise-ratio-as-an-image-quality-metric.html‚Äù, 2019. [26] B. C. Kim and C. E. Rhee, ‚ÄúCompression EfÔ¨Åciency Evaluation for Virtual Reality Videos by Projection Scheme,‚Äù  IEIE Transactions on Smart Processing & Computing , pp. [24] A. Inc., ‚ÄúRendering Omni-directional Stereo Content.‚Äù ‚Äùhttps:// developers.google.com/vr/jump/rendering-ods-content.pdf‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 182,
    "augmented": true
  },
  {
    "text": "He, J. Sun, and N. Vasconcelos, ‚ÄúDeep learning with low precision by half-wave gaussian quantization,‚Äù  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. [30]  Z. Cai, X.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "The harvested energy is \n2 \ntypically stored in either an intermediate storage like a (su- per) capacitor [ 22 ], or used for charging. For building scalable and sustainable infrastructure of battery-free EH-WSNs, the former is more feasible and will be our focus for this work. Figure 1a shows the basic building blocks of an energy har- vesting sensing/computing unit.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "One possible reason for this is that  Pipelining \nrequires loading several inputs from ReRAM memory to perform the parallel operations, which is power-expensive. This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efÔ¨Åciency when active is high. The only difference that can be observed is that, regarding LeNet  and  PV  with the power source of  Thermal , relatively speaking, the results of energy efÔ¨Åciency with  Pipelining strategy are higher than that appearing in the throughput evaluation.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "We also propose a  recoverable coreset construction  technique, which helps reconstruct the original data from the compressed form with minimum (as low as 0 . 9 √ó . 02%) accuracy loss.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Even today, more than 10 million users enjoy  360 ¬∞ videos \nusing Google Cardboard [10], Samsung Gear VR [44], and Oculus VR [8], to experience  360 ¬∞ video [7], art museum [9], live stadium [46], etc. The  360 ¬∞ videos are created by capturing scenes in all directions typically using omnidirectional cameras or a set of cameras. They are further encoded by the conventional video encoders, as if they are planar videos, for transmission efÔ¨Åciency.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Towards effective indexing for very large video sequence database. 730‚Äì741, 2005. In  Proceedings of the 2005 ACM SIGMOD international conference on Management of data , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "The PIs will seek funding for these activities from Penn State, and in particular from the ICDS (Institute for Computational and Data Sciences). For example, PI Zhang will lead a workshop for high school students featured with an LLM and society seminar and a Computational Linguistics Olympiad competition to inspire students‚Äô interests in CS and AI. Additionally, PI Kandemir will organize an LLM workshop targeting high school teachers, discussing topics such as capabilities of LLMs, how their power and limits can be explained to students, and ethical considerations in using the LLM-based tools.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Video Type (Cam movement/focus of attention direction) \nFrame Rate (fps) \n#Frames Bit Rate (kbps) \nV1 Rhinos [4] Stationary cam, no focus direction 30 3280 13462 \nV2 Timelapse [56] \nStationary cam, fast-moving objects, no focus direction \n30 2730 15581 \nV3 Rollercoaster [35] \nFast-moving cam hooked in front of a rollercoaster, uni-direction focus \n29.97 6194 16075 \nV4 Paris [51] \nStationary cam, smooth scene cuts, no focus direction \n59.94 14629 14268 \nV5 Elephants [5] Stationary cam, uni-direction focus 30 5510 16522 \nthis work, we are focusing on reusing computation results rather than reducing the content maintenance/transfer, and hence do not consider that optimization. ‚Ä¢  Video meta-information:  This contains the additional infor- mation, such as frame rates, video semantics/types, etc., about the video inputs. This feature can only be used as an add-on, along with other inputs to further improve compute reuse scope.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 259,
    "augmented": false
  },
  {
    "text": "Peter Foster, Siddharth Sigtia, Sacha Krstulovic, Jon Barker, and Mark D Plumbley. 267‚Äì274. IEEE, 2003.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "For relevance in comparison to prior work [ 27 ,  83 ] we chose image inference as our ensemble workload. While ensembling is applicable in other classiÔ¨Åcation workloads like product recommendations [ 24 , 53 ], text classiÔ¨Åcation [ 71 ] etc, the observations drawn are generic and applicable to other applications. 2.3 Pros and Cons of Model Ensembling \nIn this section, we quantitatively evaluate (i) how effective ensembles are in terms of accuracy and latency compared to single models, and (ii) the challenges in deploying en- semble frameworks in a cost-effective fashion on a public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "From Sparse to Soft Mix- tures of Experts. [132] Joan Puigcerver, Carlos Riquelme Ruiz, Basil Mustafa, and Neil Houlsby. In  The Twelfth International Conference on Learning Representations , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "3. We propose detailed design choices that can adopted to- wards designing a self-managed inference-serving system. In addition, we design a scheme named Paragon on top of AWS platform, which incorporates some of the proposed design choices.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Grouping experts in close memory proximity is expected to enhance cache efficiency and reduce latency. Data locality should benefit from prefetching and caching critical data, which would lower transfer delays and potentially speed up training and inference. By integrating expert affinities (Expert‚ÄìExpert, Expert‚ÄìData, Expert‚ÄìRouter, and Expert‚ÄìComposition Function) detailed in Table 2, the system will optimize responsiveness and computational efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "References \n[1] NVIDIA A100 Tensor Core GPU., 2023.  https://www.nvidia.com/en-us/data-center/ a100/ . [2] NVIDIA H100 Tensor Core GPU, 2023. https://www.nvidia.com/en-us/data-center/ technologies/hopper-architecture/ . [3] Exploring llms - real-world case studies in ai-generated art & literature.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "[103] T.-J. 5687‚Äì5695. Yang, Y.-H. Chen, and V. Sze, ‚ÄúDesigning energy-efÔ¨Åcient convo- \nlutional neural networks using energy-aware pruning,‚Äù in  Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "V. C ONCLUSION \nEnabling DNN inference on edge devices has been gaining recent traction, especially for tasks like HAR. However, the compute heavy DNNs make it challenging because of their \npower requirements, especially in EH-WSNs. Our proposal, Origin , holistically looks into multiple aspects of deploying a DNN on an EH-WSN for the purpose of HAR.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "These tailored models enable accurate inference with high throughput and reduced resource footprint, with some compressed models having approximately 50 √ó  fewer parameters [ 30 ], but with a greater susceptibility to data drift [ 42 ], [ 55 ]. Data drift emerges as a signiÔ¨Åcant concern in real-world systems as the live data diverges from the original training data, and the environment undergoes rapid changes [ 12 ]. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Figure  13  plots the average number of models (bar- left y-axis) and cumulative accuracy (line- right y-axis) for the different sampling intervals for queries with three different constraints. It can be seen that the 30s interval strikes the right balance with less than 0.2% loss in accuracy and has average number models much lesser than other intervals. This is because, increasing the interval leads to lower number of scale down operations, thus resulting in a bigger ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "We would also like to thank Dr. Jack Sampson, Dr. Aasheesh Kolli and Dr. Timothy Zhu for their feedback on this paper. [2] K. Boos, D. Chu, and E. Cuervo, ‚ÄúFlashBack: Immersive Virtual Reality on Mobile Devices via Rendering Memoization,‚Äù in  Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services , ser. R EFERENCES \n[1] Arm Holdings, ‚ÄúArm Frame Buffer Compression (AFBC).‚Äù ‚Äùhttps: //developer.arm.com/architectures/media-architectures/afbc‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "Our FPGA results can further provide 18% more computation and 9% more total energy savings, compared to the state-of-the-art design. Com- pared to the state-of-the-art hardware-modiÔ¨Åed PTU, our soft- ware implementation can still provide 16% computation and 8% total energy savings. More speciÔ¨Åcally, for each of the Ô¨Åve video inputs (shown in the x-axis in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "However, as PC is moving to mobile, one cannot ignore the latency/energy constraints, thus demanding the need for mobile friendly PCC techniques which offer the best compression, latency and energy savings while preserving the video quality. III. To the best of our knowledge, most of these works focusing on PCC with attributes target the compression ratio, and overlook the latency or energy consumption.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "We perform an analysis on the MHELATH [ 9 ,  10 ] data set (we take a overlapping moving window of 60 data points sampled at 50Hz from 3 different IMUs, overlap size: 30 data points) to find a trade-off between the coreset size (directly related to the communication cost) and the inference accuracy. Empirically, we observe that ac- curately preserving the features for each class requires  20 data points  using importance sampling or  12 clusters  (see Fig. 6) using clustering based techniques.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "Unlike their compute architecture, storage and archival system for these edge servers has often been under-emphasized. Abstract \nAs continuous learning based video analytics continue to evolve, the role of effi- cient edge servers in efficiently managing vast and dynamic datasets is becoming increasingly crucial. This is unfortunate as they contribute significantly to the data management and data movement, especially in a emerging complute landscape where date storage and data protection has be- come one of the key concerns.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Task-2.6: Fault-Tolerant Expert Training Fault-tolerance of monolithic LLM models has been a major concern due to the long-running training jobs on a large number of GPUs [27, 149, 165]. This unified strategy ensures rapid, accurate query responses and high throughput within the infrastructure‚Äôs memory and computational constraints. Custom composition functions are anticipated to further speed up the integration of diverse expert outputs, thereby improving overall response times.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Intra-Holo:  We evaluate our  Intra-Holo  design again on a mobile GPU as shown in Fig. Note that, this implementation is purely done in software, without any hardware modification. 6b  b  .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Key Assumptions and Conditions \n1. Convexity of  ‚Ñì . The loss  ‚Ñì ( f Œ∏ ( x ) , y )  is convex in  Œ∏ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "2: Auto-labeling in  Us. general, robust and larger model (typically with hundreds of millions of parameters [ 43 ], [ 99 ]) helps in annotating the data. ¬¥as : Select frames only with low conÔ¨Ådence as they might contain potentially new information, and use ensemble learning to improve the labeling.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "494‚Äì506. [109] B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, ‚ÄúLearning transferable \narchitectures for scalable image recognition,‚Äù in  Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8697‚Äì8710.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "The reason why YOLOv4-tiny saves more is that the PI beneÔ¨Åts more in a ‚Äúshallow‚Äù model with a relatively larger room to skip. For example, YOLOv3 takes, on average,  0 . 75 √ó  of the baseline latency to perform the PI on a frame in video HC1 [43], whereas YOLOv4-tiny takes only  ‚àº 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "for different cases. After Ô¨Åltering out the ‚Äúno change in MV‚Äù cases for SI in Line  19  in Algo.1, we next fuse all of the MVs together and Ô¨Ålter the small ones (i.e., noises) out (shown in Line  21 ). Next, we iterate each MV block for Scenario-1, Scenario-2 and Scenario-3 (shown from Line  22  to Line  31 ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "This is due to: 1). the octree can be constructed \n1x 1x \n43.5x \n34.2x \n35.2x \n0 40 80 120 160 200 \n0 \n2000 \n4000 \n6000 \n8000 \nTMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 \nRedandblack Longdress Loot Soldier Andrew10 Phil10 Avg. TMC13.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 242,
    "augmented": true
  },
  {
    "text": "Three demo examples of reconstructed images by OpenHolo are shown in Fig. 9: viewing a whole-hologram from different pupil positions in Fig. 9a; viewing an entire hologram (in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "of 0.5% than  Clipper  (not plotted). The accuracy gain seen in  CIFAR-100  is lesser than ImageNet dataset because the class-based weighted voting works effectively when handling large number of classes (100 in  CIFAR  vs 1000 in ImageNet). Nevertheless,  Cocktail  is able to deliver the accuracy at 2x lower latency than  InFaaS  and 1.35x lower cost than Clipper.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Here‚Äôs a simplified breakdown of the process: \n1. Energy Capture : The setup begins with a harvester, such as a solar panel, piezoelectric sensor, or thermocouple. These devices are designed to collect energy from their surround- ings‚Äîlight, mechanical vibrations, or heat, respectively.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "5.3). Finally, based on our findings, we discuss future direc- tions that may help one design custom hardware accelerators for AR holograms (Sec. 5.5).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Trapezoid: A versatile accelerator for dense and sparse matrix multiplications. In  2024 ACM/IEEE 51st Annual International Symposium on Computer Architec- ture (ISCA) , pages 931‚Äì945. IEEE, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "System Model \nWe consider a network of  N EH sensors  S = { s 1 , s 2 , . Existing methods may not account for the energy constraints and participation vari- ability inherent in EH-WSNs. 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Although accuracy is a close measurement of the conÔ¨Ådence of the classiÔ¨Åcation, it does not truly reÔ¨Çect it. For example, let us consider two DNN classiÔ¨Åers ( C 1  and C 2 ) classifying between 4 different classes  ( o 1 , o 2 , o 3 , o 4 ) . The Ô¨Ånal probability vector from the last layer (soft- max function)  V C 1 = [0 .",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Our approach to address these questions relies on decen- tralizing the DNN execution and letting each sensor perform its own inference. These sensors, each individually working as a weak classiÔ¨Åer, can together form an ensemble learning \nenvironment to achieve better accuracy with lower communi- cation overhead. For each sensor to perform inference using the limited and unstable harvested energy poses a scheduling problem, as non-deterministic time is required for the EH sensors to accumulate enough energy to perform the inference.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "While model compression [27]‚Äì[29] tries to compress the entire weight matrix while preserving accuracy, pruning goes over individual weights/kernels and drops the unimportant ones. 2) Model Compression and Pruning:  To make DNNs mo- bile friendly, there have been several works in compressing and pruning large models. Model compression is typically achieved by tensor decomposition or low rank compression, i.e., by representing the higher dimensional parameter matrix in a compressed low rank form.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "This means that the object in question has been moving towards a direction, which triggers a ‚Äúposition change‚Äù event. 1) Partial Inference:  To further explore the computation reuse opportunities, we revisit the Ô¨Årst scenario illustrated in Fig. 3a, where the MV for Frame-3 is not highly overlapped with the bounding boxes from Frame-1 (overlap ratio = 0.60, lower than the predeÔ¨Åned threshold).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "However, it is  not  desirable to execute the infer- ence on the mid- dle part, since, in order to do so, one needs to prepare an input larger than the inner region (due to the various kernel sizes in the convolution, e.g.,  3  √ó  3 ,  5  √ó  5  [38]), which eventually turns out to be the FI. Thus, the inner part has to be fully infer- enced. IV-B2, the RoIs are essen- tial to the out- put results.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "We evaluate this baseline by profiling its performance and energy consumption from a mobile GPU [36]. This software-based viewing window optimization is considered to be the state-of-the-art at an algorithm level, and we refer to it as Baseline  in this study. ‚Ä¢  Inter-Holo:  We evaluate the  Inter-Holo  design on a mobile GPU [ 36 ] using a framework similar to the state-of-the-art IL- LIXR framework [ 19 ], with one additional eye tracking task (as shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "This stage mostly comprises of memory operations, and thus is not a compute bottleneck. Our discussion in this section is summarized in Tab. I.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "As opposed to prior works [ 5 ,  10 ], which try to combine serverless functions with VMs to hide the start-up latencies of VMs, our primary interest lies in exploring the different key aspects  to address when hosting DNN-based ML pre- diction serving systems in public cloud, as given below: ‚Ä¢  Diverse Models:  How to make the users oblivious of model selection from the extensive pool of models, for satis- fying the accuracy, and latency requirements? ‚Ä¢  Heterogeneous Public Cloud Resources:  What are the different options available in terms of combining different VM-based cloud services and serverless functions for a given user requirement? ‚Ä¢  Configuring Resources:  From the diverse options, how to right-size VMs and appropriately configure the serverless functions to efficiently cater to user specified cost, accuracy and latency constraint?",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 193,
    "augmented": true
  },
  {
    "text": "From the software/algorithm perspective, a sub-hologram technique is pro- posed with a tracked viewing-window technology to tailor the holographic computation only for the necessary information in- side of the window [ 52 ]. More recent efforts have attempted to combine holographic processing with neural network techniques. For instance, DeepHolo [ 33 ] proposes a binary-weighted computer- generated hologram model to recognize 3D objects.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "10 075‚Äì10 085. [102] T.-J. Yang, Y.-H. Chen, and V. Sze, ‚ÄúDesigning energy-efÔ¨Åcient convo- \nlutional neural networks using energy-aware pruning,‚Äù in  Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Component Energyequation DAC E DAC =e DAC √óm√óaG Computation E M AC =e MAC   √óm√ón√óaG \nADC BL E BL =e BL √ón√óaG SA-Ref E SA‚àíRef =e SA‚àíRef √ón√óaG S+A E S+A =e S+A √ón√óaG \n3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated. Asaresult,thesepartialsumsneedtobe mergedoncethe (tile)traversalofanentireReRAMiscomplete.Thesum mergingoperationisperformedbyanAdderTreeasillustrated inFigure3. Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint of P merg   <P budget shouldbealways met.Therefore,the power P merge   andlatency Lat merge   ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofÔ¨Çine.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 276,
    "augmented": false
  },
  {
    "text": "188‚Äì191. IEEE, 2021. Tong Chen, Haojie Liu, Qiu Shen, Tao Yue, Xun Cao, and Zhan Ma.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Thus, to explore computation reuse op- portunities, we start by distinguishing between 4 complemen- tary opportunities ‚Äì  InterFrame-IntraEye (EA) ,  IntraFrame- InterEye (AE) ,  IntraFrame-IntraEye (AA) , and  InterFrame- InterEye (EE) , using a represent example shown in Fig. Moreover, in many cases, computations are also sensor input-dependent such as the IMU data for determining the head orientation, which is updated across frames , at runtime. 4.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "This figure shows a clear pattern of trade-offs between more-energy-savings vs. more-quality-drop. 3) affect the energy savings achieved, we report five design points in Fig. 10b.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Moreover, these AR infotainment applications have helped many of us through the recent global pandemic by bringing us the liveliness of the virtual outdoors, while we were confined to our homes, and more AR capa- ble mobile devices penetrating the market with cheaper price tags have made AR applications pervasive and made the virtual world easily accessible for users on the tip of their fingers. However, even the state-of-the-art mobile devices with high bandwidth cannot meet the heavy compute and real-time demands of the AR applications, leading to very low quality of service (QoS) ‚Äì in some cases as low as 1 frame per second (fps) [ 19 ,  54 ]. Further, \n1 To give a quantitative estimation of the popularity of the game, a Pok√©mon GO event at Safari Zone New Taipei City, Taiwan in October 2019 had a total of 327,000 attendees and they walked around 4.5 million kilometers to catch 50 Million Pok√©mons [5].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 217,
    "augmented": false
  },
  {
    "text": "Better refers to the improvement over iNAS+PT baseline. Datasets Full Power Arduino on RF AP PT iNAS+PT NExUME Better FMNIST 98.70 74.44 79.63 83.61 90.44 8.17% CIFAR10 89.81 58.11 63.91 65.01 79.60 22.44% MHEALTH 89.62 63.52 67.40 74.30 83.86 12.87% PAMAP 87.30 61.39 67.24 69.45 77.00 10.87% AudioMNIST 88.20 66.11 74.28 76.60 78.87 2.97% Table 6: Accuracy of NExUME on Arduino nano board using WiFi based RF harvester. Better refers to the improvement over iNAS+PT baseline.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 205,
    "augmented": false
  },
  {
    "text": "Chih-Hsuan Yen, Hashan Roshantha Mendis, Tei-Wei Kuo, and Pi-Cheng Hsiu. Stateful neural networks for intermittent systems. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , 41(11):4229‚Äì4240, 2022.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "More recently, another foveated rendering based CGH reconstruction technique has been proposed to accelerate calculations with negligible effect for the viewer [ 22 ]. For instance, a real-time gaze-tracked foveated rendering system is proposed to yield performance and memory savings by avoiding shading up to 70% of the pixels for VR headsets [ 47 ]. Similarly, a prototype AR display also takes advan- tage of foveated rendering by tracking the user‚Äôs gaze and providing low-resolution images to the peripheral area to reduce computa- tion and improve display resolution [ 25 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "[67] Shaomang Huang, Jianfeng Pan, and Hanzhong Zheng. Ccoe: A compact llm with collaboration of experts. arXiv preprint arXiv:2407.11686 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "[180] Hengrui Zhang, August Ning, Rohan Baskar Prabhakar, and David Wentzlaff. Association for Computing Machinery. Llmcompass: En- abling efficient hardware design for large language model inference.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Source: [30]. What are the Problems? While LLMs have become integral across various sectors due to their advanced capabilities, con- structing these models from scratch for specialized applica- tions presents significant challenges due to the prohibitive cost.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "[186] Yusen Zhang, Ansong Ni, Ziming Mao, Chen Henry Wu, Chenguang Zhu, Budhaditya Deb, Ahmed Awadallah, Dragomir Radev, and Rui Zhang. Summ n : A multi-stage summarization framework for long input dialogues and documents. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1592‚Äì1604, Dublin, Ireland, May 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Adaptability:  Although  Seeker  is meant for EH-WSNs, the coreset based data representation can easily be used in any commercial device for efficient communication. We develop a non-volatile hardware accelerator, with mul- tiple quantization support, for efficient DNN inference. ‚Ä¢  Detailed Evaluation:  We provide a detailed evaluation of our system and the proposed hardware design.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "ACM, 2022. [98] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "3  and discussed in Sec. Proposed Intra-Frame Attribute Compression:  As shown in Fig. ‚Ä¢  Post Processing:  Using these relationship arrays, the Ô¨Ånal step is to post-process them to obtain the occupy bits for each node, and output the compressed geometry stream.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "To be sure that the combination will give us the desired accuracy of the larger model, we try to theoretically analyse the scenario. We formulate the problem conservatively as following. We perform an inference by ensembling ‚ÄôN‚Äô models, and each of these models have accuracy ‚Äôa‚Äô.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "The major  contributions  of this work are the following: ‚Ä¢  We identify the spatio-temporal redundancies for optimiz- \n1 In this paper, we use ‚Äúlocality‚Äù and ‚Äúframe similarity‚Äù alternatively. ing the PCC using a public PC dataset [ 18 ]. We also demonstrate that, such spatio-temporal localities can be precisely captured by Morton codes [ 30 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "R EFERENCES \n[1] T.-J. Yang, A. Howard, B. Chen, X. Zhang, A. This research is supported in part by NSF grants #1931531, #1955815, #2116962, #2122155 and #2028929.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "An application invokes functions in the sequence as specified by the path in the DAG. Based on the nature of the workflow, function chains can be classified as Static or Dynamic. 2.1.1 Static DAGs : In static function chains (or DAGs), the workflows are specified in advance by the developer (using a schema), which is then orchestrated by the provider.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Aligned with the departmental BPC plan, the students working on this project will participate in various diversity, equity, inclusion and belonging (DEIB) DEIB activities. ‚Ä¢  Summer Camp for Middle School Girls:  PI Das has been involved with organization of week-long sum- mer camps (funded by the CSE Department) targeted at middle school girls since 2017. Our earlier camps have already introduced participants to basic concepts in programming, building vision systems that assist visually impaired and learning skills towards building a basic embedded vision system, program- ming for robotics and exposure to various emerging tools in computing.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "Finetune \n(b) Recovering a sub-sampling with GAN. Figure 7: Recovering data from the coresets. based coresets can achieve an accuracy of  ‚âà 85%.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "2017. Re- alistic dynamic facial textures from a single image using gans. In Proceedings of the IEEE International Conference on Computer Vision .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Figure 4a shows that setting \na high threshold value will reduce the average inference time in all four cases. Sensitivity Study:  To better understand the relationship be- tween the inference quality and the threshold, we run our model with different parameter settings, shown in Figure 4, over the cases of edge-peer and edge-cloud structures with device counts of two and four. This effect is more obvious in the edge-peer structure since it will send the data to its nearest peer and check the prediction quality until it reaches the cloud.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "The added recall functionality enables ensemble learning. Moreover, the host device, which performs the ensemble, is equipped with a conÔ¨Ådence matrix, which adapts to the user and performs weighted majority voting instead of a na¬®ƒ±ve majority voting. The associated conÔ¨Ådence matrix boosts the classiÔ¨Åcation accuracy and also resolves ties while voting.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "However, due to complex interaction between multiple storage nodes, especially where some of the data needed to arrive at different nodes via network, in Fig. 6, we observe a significant change in the latency compared to a single storage node. We do not observe much change in the data volume.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "2 it is clear that not all the sensors are equally good at classifying various ac- tivities; in fact, this builds the foundation of AASR. The idea of making the ensemble task activity aware has similarities to weighted majority voting, where we assign weights to the individual learners participating in the ensemble, such that a higher accuracy classiÔ¨Åer contributes more weight towards the Ô¨Ånal result. However, from Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Consequently, the stochastic gradient descent (SGD) updates retain their convergence properties, ensuring that the training process reliably optimizes  J ( Œ∏ ) . 6 \n330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 \n6. Implementation and Evaluation \n6.1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, compared to the black line (only 10 blocks), the attribute in yellow line ( 10 4 \nblocks, each of them is  1000 √ó  smaller) exhibits a better similarity (i.e., left-shift towards the y-axis). ‚Ä¢  When partitioning the macro blocks in an even more Ô¨Åne grain fashion, as shown in the green line with  10 5   segments, now the CDF curve is pushed towards left even further. This again indicates that, within a smaller macro block, the voxels have richer similarity with their neighbors.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "[147] Haizhou Shi, Zihao Xu, Hengyi Wang, Weiyi Qin, Wenyuan Wang, Yibin Wang, and Hao Wang. Con- tinual learning of large language models: A comprehensive survey. arXiv preprint arXiv:2404.16789 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "Mouse: Inference in non-volatile memory for energy harvesting applications. In  2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp. 400‚Äì414.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Model compression is typically achieved by tensor decomposition or low rank compression, i.e., by representing the higher dimensional parameter matrix in a compressed low rank form. In contrast, pruning looks at the contribution of each individual weight. While some of the weights contribute more towards accuracy, some contribute less; and the ones contributing less are dropped to reduce the parameter size as well as compute and memory footprints.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "This leaves an optimization space in trading between communication cost vs. accuracy, i.e. Therefore, when performing inference on the compressed coresets representation, the inference ac- curacy goes down, albeit not significant compared to other lossy compression methods (we can again refer to Table 1 for the relevant comparisons). However, even after preserving important fea- tures, the constructed corests are lossy representation of the original data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "A systematic methodology for characterizing scalability of dnn accelerators using scale-sim. In  2020 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) , pages 58‚Äì68. IEEE, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Neurocomputing , 234:11‚Äì26, 2017. A survey of deep neural network architectures and their applications. [55]  Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoy- anov.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "5 , - 1  in the parent array means that the root node has no parent, whereas  parent [ 7 ] =  4  means that for the  7 th  node (whose code is  code [ 7 ] =  511 ), the index for its parent node in the code array is 4 (whose code is  code [ 4 ] =  63 )). Although such arrays already contain the necessary information to decode the geometry information for the PC, they are  not suitable for compression tasks . For exam- ple, to store/transmit these two arrays,  4 bytes √ó 16 = 64 bytes are needed.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": ". . Aggregator \nMaster VM \nUser Requests \n‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ \nQueries Cost aware Procurement \nImportance Sampling \nModel-1  Model-2  Model-3  Model-4  Model-n  \noutput \nHeterogeneity \nPrediction Policy \nAutoscaler \nResource Controller \nLoad Balancer \nÔÅ± argmax O 1  (latency) ÔÅ± argmin O 2  (accuracy) \nCPU GPU CPU GPU \nObjectives \n1a \n3 \n4b \n1b \n2 4 \n4a \n4b \n1 \n6 \n6b \n6a \nw1 w2 w3 wk w4 \n3 \n5  Bin-Packing \nWeight Matrix \nL \nN \nFigure 5:  High-level overview of  Cocktail  design.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "[45] OpenHolo. \"https://docs.opencv.org/2.4/doc/tutorials/gpu/gpu-basics-similarity/gpu- basics-similarity.html\". 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 2nd European Workshop on Machine Learning and Systems , EuroMLSys ‚Äô22, pp. Live video analytics as a service. Guilherme H. Apostolo, Pablo Bauszat, Vinod Nigade, Henri E. Bal, and Lin Wang.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 27th ACM Symposium on Operating Systems Principles , pages 1‚Äì15, 2019. [60]  Christopher Olston, Noah Fiedel, Kiril Gorovoy, Jeremiah Harmsen, Li Lao, Fangwei Li, Vinu Rajashekhar, Sukriti Ramesh, and Jordan Soyke. TensorÔ¨Çow-serving: Flexible, high-performance ml serving.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "The Ô¨Ålter SRAM has 256 banks (one per tile), each with a size of 1kB (double buffered, 512B per buffer per bank). Input data broadcast to all tiles is managed by a 64kB double- buffered input feature map SRAM (32kB each), requiring ‚åà [ X  √ó Y  √ó Z ] / 1024 ‚åâ iterations for full input loading, with each buffer loaded  [ X  √ó Y  √ó  Z ] / 2048 times. Data streaming and partial compute storage are facilitated by four double buffered SRAM structures, with the \nweights residing in a double buffered multi-banked SRAM.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "TMC13, while our Intra- Inter-V1 and Intra-Inter-V2 only consume  0 . 52 J  and  0 . 5 J energy, respectively, which translate to  ‚âà 97%  energy savings w.r.t.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Our experiments on a representative mobile device (Pixel 3 Phone) show that the proposed partial inference scheme achieves  2 √ó speedup over the baseline approach that performs full inference on every frame. We integrate these two data reuse algorithms to accelerate the neural network inference and improve its energy efÔ¨Åciency. Additionally, we implement a partial inference scheme to enable region/tile-level reuse.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "These accuracy improvements can be attributed to  Origin‚Äôs  use of a conÔ¨Ådence matrix in classiÔ¨Åcation, as opposed to the baseline models, which only perform majority voting based ensembling. For certain cases like climbing in PAMAP2, and running in MHEALTH,  Origin  is more accurate than Baseline-1. Note that both the baselines are running on a fully powered system whereas  Origin runs entirely on harvested energy.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "The cost is normalized to reactive scaling scheme. 1 hour sample of the real-world trace for request arrival time generation. Each request is derived from a pool of pre-trained ML inference models for image classification (as explained in Section  2 ).",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Treatment of uncertainty using ensemble methods: Comparison of sequential data assimilation and bayesian model averaging. Water Resources Research , 43(1), 2007. [78]  Jasper A Vrugt and Bruce A Robinson.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "Figure 3: Microarchitectural designs of HSPM and SDMM: Hardware modules for polynomial multiplication in LBC. unit commences the modular multiplication of each coefficient  a i  with the entirety of  b ‚Äôs coefficients in parallel. This process repeats for all coefficients  a i .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Opt. (2019), A258‚ÄìA266. [63]  Yang Wu, Jun Wang, Chun Chen, Chan-Juan Liu, Feng-Ming Jin, and Ni Chen.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "[18] Maciej Besta, Syed Minhaj Hassan, Sudhakar Yalamanchili, Rachata Ausavarungnirun, Onur Mutlu, and Torsten Hoefler. ACM SIGPLAN Notices , 53(2):43‚Äì55, 2018. Slim noc: A low-diameter on-chip network topology for high energy efficiency and scalability.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Abstract ‚ÄîMany recent works have shown substantial efÔ¨Åciency boosts from performing inference tasks on Internet of Things (IoT) nodes rather than merely transmitting raw sensor data. However, such tasks, e.g., convolutional neural networks (CNN), are very compute intensive. They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "[176] Huizi Yu, Lizhou Fan, Lingyao Li, Jiayan Zhou, Zihui Ma, Lu Xian, Wenyue Hua, Sijia He, Mingyu Jin, Yongfeng Zhang, Ashvin Gandhi, and Xin Ma. Large language models in biomedical and health informatics: A review with bibliometric analysis. arXiv preprint arXiv:2403.16303 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Figure 8: (a): Profiling the power breakdown on the edge GPU prototype [36]; and (b): Average number of depth planes required for four design configurations. of depth planes required by the  Inter-Holo  scheme is reduced from 23 . 6 to 19 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "For example, ATW [38] is a post-render technique, which sits between rendering (our focus) and display. To reduce the impact by the long-latency from rendering, ATW either guesses the next head-orientation or only considers the rotation (no translation), then skews two already-rendered planar FoV frames to remove judders [43]. Note that, this computation still happens in planar-format, and remains the same between two-eyes for one frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "During the eight harvested power cycles, the ReRAM can be ON during power cycles  PC3, PC6  and  PC7  and OFF with the other Ô¨Åve power cycles. Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four  25  √ó  6  ReRAM crossbars, each can be mapped to six kernels, all sized  5 √ó 5 √ó 1 . In the default case, the RCA works under an either ON or OFF mode with a power threshold of 80 ¬µ W .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "ùê∂ùëúùëöùëùùë¢ùë°ùëí _ ùëÉùëüùëúùëè , \n158 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nin Algorithm 1, first estimates the invocation probabilities of a function‚Äôs immediate predecessors and uses it along with system log information and load measurements of the function to calculate its invocation probability. Connectivity:  In addition to function invocation probabil- ities, it is necessary to also account for the effects of cold starts on DDAs while estimating function weights. Cold start spillovers (that often occur due to container underprovision- ing), as described in Section 2, can impact the response la- tency of applications harshly.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "Law, K. Lee, J. Lu, P. Noordhuis, M. Smelyanskiy, L. Xiong, and X. Wang. Applied machine learning at facebook: A datacenter infrastructure perspective. In  2018 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 620‚Äì629, Feb 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Although the intra-cluster data distribution will be different from the original, it will still preserve the overall geometry with a certain degree of approximation which the DNN could learn to accommodate. Experimentally, on the MHELATH dataset, we observe that inferring on the synthesized reconstructions of cluster \n0 \n20 \n40 \n60 \n80 \n100 \nWalking Climbing Cycling Running Jogging Jumping \n% Accuracy \nk= 12 (Baseline) K= 15 k =10 k = 8 k=6 \nFigure 6: Accuracy with different #clusters (k). Clustering Recovery \nOriginal Data Coreset Recovered Data \n(a) Recovering a cluster with uniform random re-distribution.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "For example, in  Hotel Reservation (Figure 1c), if only one path (say,  NGINX - Make_Reservation ) is always chosen, it represents a static function chain. 2.1.1 Static DAGs : In static function chains (or DAGs), the workflows are specified in advance by the developer (using a schema), which is then orchestrated by the provider. This re- sults in a predetermined path being traversed in the event of an application invocation.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "Considering the scale, scope and workload of our problem, limits direct comparisons, except for comparing their exemplar selection method (refer Fig. 9 ). Similarly, Ekya [ 12 ] only focuses on co-location of computation, and it‚Äôs efÔ¨Åciency on Ô¨Ånishing compute even on custom hardware is shown in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Throughput results are plotted in Figure 12 and area costs for  G 1  ‚àº G 5  can be found in Figure 13. F. Sensitivity study on duplication copy \nWe vary the ReRAM duplication granularity  G  for each layer and evaluate with  TV-RF  source. The underlying reason is that the smooth  Transition keep   strategy can already handle the smooth transitions with no need of power prediction support for this workload.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "VI , our results indicate  37 √ó  speedup for the geometry compression. And, as we show later in Sec. In comparison, given a GPU-based system with  k parallel cores, our design requires only  O ( ‚àë D i = 1   N i / k )  time ( N i is #nodes in layer ‚àí i ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Therefore, it does not use any of the computations that are used in the inference and learning pipeline. Then, the question is:  is there a way we can reuse the computations used for the inference to help us in encoding the data? The answer is  neural codecs  (Ma et al., 2019; Chen et al., 2017).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "During the data loading phase, the 256 coefficients of polynomial  b  are input serially into a 6-bit shift register. Simultaneously, the first coefficient  a 0  of polynomial  a  is fed in parallel to all 128 SDMM units. Post-loading, each SDMM \n11 \n6bit shift  register \nSDMM SDMM \n13bit register \nControl logic \na \nb \nc \nb c \nd \n(a) HSPM micro-architecture.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Our key contributions are as follows: \n‚Ä¢  Game-Theoretic Participation Strategy:  We develop a novel game-theoretic model for EH-WSNs that applies to both training and inference phases. By integrating the game-theoretic approach with federated learning principles, we reduce communication overhead and ensure that contri- butions to model updates come from sensors best positioned to improve accuracy under energy constraints and uncertain availability. This model balances anticipated energy availability, local data quality, and global benefit to establish stable and cooperative equilibria, opti- mizing the energy-accuracy trade-offs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "We refer to this effect as  Cold Start Spillover . Fig- ure 3 compares the performance degradation resulting from underprovisioning both Critical and Non-Critical functions. The (Critical, Non-Critical) function pairs chosen for this experiment were ( Make_Post ,  Text ), ( ID ,  Rating ) and ( NGINX , Search ) for  Social Network ,  Media Service  and  Hotel Reserva- tion , respectively.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "In rare cases (once in over 2000 cases), the generator induced arti- facts which could result in wrong classifications. However, this error could be rectified with further fine tuning. A.2 More Results on Bearing Fault Data We repeated our experiments with similar experimental setup on the bearing fault data set [ 53 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Define the dropout probability  p i  for neuron  i  based on the Taylor expansion approximation of its impact on the loss: \np i  = Œª \f\f\f  ‚àÇ L \n‚àÇ a i   a i \f\f\f  +  œµ \nwhere  Œª  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. The impact of neuron  i  on the loss function  L  can be approximated using the first-order Taylor expansion: \n‚àÜ L i  ‚âà \f\f\f\f ‚àÇ L ‚àÇ a i a i \n\f\f\f\f \nwhere  a i  is the activation of neuron  i , and   ‚àÇ L \n‚àÇ a i   is the gradient of the loss with respect to the activation. Mathematical Formulation:  Let  W  be the weight matrix of a layer.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 187,
    "augmented": true
  },
  {
    "text": "ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [ 8 ] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets. It includes four ReRAMs, each 32x32. The inputs and weights are binary and the output is adaptive between 1-3 bits.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Load/store parameters of the ReRAM memory are from NVSim [ 40 ]. However, for other functional units, we assign a Ô¨Åxed latency. For the ReRAM circuit simulation, we quantify power and performance of our design in HSPice [ 38 ] using 20nm \nFinFET ReRAM parameters from [ 39 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Note that this step is slightly different from the one in the prior pipeline shown in Fig. 4  a  . Instead of updating and storing the occupy bits for each node during the process of adding points, now the outputs of this step are several arrays (Morton codes array, parent array, etc.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "https://codewith.mu/en/. 2019. [52]  Ben Mussay, Margarita Osadchy, Vladimir Braverman, Samson Zhou, and Dan Feldman.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "4.2 HoloAR Overview \nDriven by the above discussion and the potential approximation opportunities presented by the  Inter-Holo  and  Intra-Holo  scenarios, we propose  HoloAR , a novel framework for holographic process- ing in AR applications to improve  both  the performance and en- ergy consumption of the hologram processing, without affecting user experience. HoloAR  aims to reduce the amount of hologram computations as much as possible by carefully approximating the hologram computing for select objects, while maintaining an ac- ceptable video quality. The overall design of our proposed  HoloAR framework is illustrated in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "Then, remove operations are repeatedly used to prune the system. If the number of experts is still larger than needed, a clustering algorithm (e.g., AGNES [139], and topic clus- tering [160]) can be employed to combine experts with the highest cluster scores, thus reducing the total number of experts. Once the user specifies target domains, the algorithm locates the most irrelevant domains in the graph (either branch or leaf) until the number of experts fits within the memory constraints or the relevance reaches a threshold.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "3) Our proposed policy,  Origin , combines an adaptive conÔ¨Å- dence matrix and the activity aware scheduler to perform efÔ¨Åcient and accurate classiÔ¨Åcation. The adaptive conÔ¨Ådence matrix, which weights the output of each sensor depending upon the classiÔ¨Åcation result, is updated on each successful classiÔ¨Åcation. 4) Finally, we provide a detailed evaluation of  Origin , and show that, even when powered by an unreliable EH source, the efÔ¨Åciency achieved by the this system results in better accuracy than that of a fully powered system running state of the art classiÔ¨Åers optimized for energy efÔ¨Åciency.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "We perform an inference by ensembling ‚ÄôN‚Äô models, and each of these models have accuracy ‚Äôa‚Äô. Therefore the prob- ability of any model giving a correct classiÔ¨Åcation is ‚Äôa‚Äô. We assume the output to be correct if majority of them, i.e.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "503 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \n(a) Viewing W-CGH from different eye-center positions. Eye-center coordi- nates from left to right:  (0, 11mm) ,  (0, 12mm) ,  (0, 13mm) , and  (0, 14mm) . (b) Viewing W-CGH from different focal distances.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "2  b  and  c  . Reasons for InefÔ¨Åciency \nTo better understand the performance of the PCC pipeline, we characterize the ‚Äúlatency breakdown‚Äù of two state-of- the-art G-PCC techniques, i.e., PCL [ 72 ] and TMC13 [ 56 ], on a typical edge SoC platform (NVIDIA AGX Xavier) in Figs. Overall, the entire PCC pipeline takes around 3.5 seconds 3 , which prevents one from employing such techniques in an edge device.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "4) How to Do Partial-Inference? :  Next, we revisit the example scenario discussed in Fig. 3a, and give the details of the proposed partial inference (PI) scheme in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "Furthermore, the feature extraction for each of the potential \nexemplars for the teacher model is hardware-assisted (¬ß V-C ), and hence poses no overhead to the inference task. 0 \n9 \n18 \n27 \nR Y V R+Y R+V Y+V R+Y+V IL-RR IL-K-Last List \n# Exemplars \n#Exemplars Selected (Best Case) #Exemplars Selected (Worst Case) Average Exemplars \nFig. 9: Impact of multiple teachers on exemplar selection.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "ACM, 2017. [171] Dongjie Yang, XiaoDong Han, Yan Gao, Yao Hu, Shilin Zhang, and Hai Zhao. Pyramidinfer: Pyramid kv cache compression for high-throughput llm inference, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Each depth plane processes the forward-propagation from the hologram plane independently, and each pixel on a particular depth plane goes through the exact processing sequence ( HP2DP in  Line#5 ; more details can be found in [ 4 ,  18 ]). This makes hard- ware parallelization and pipelining easier on a block/tensor type of architecture such as GPUs. Note, however, that, this step also requires sequential barriers within each plane ( Line#6  synchro- nizes the threads in a warp/block for one depth plane) and across planes ( Line#7  synchronizes the results from all the depth planes, before moving forward to the second step).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "Recently,  Point Cloud  (PC) consisting of millions of points, which capture the 3D geometry and attributes (e.g. RGB colors), has become an important modality for such realistic representations for applications like AR/VR, \n* Work was done while at Penn State. gaming, autonomous driving, etc.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Nature communications , 13(1):5546, 2022. Krizhevsky Alex. Learning multiple layers of features from tiny images.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "This is because, for encoding purpose, the original  360 ¬∞ videos are projected into the 2D plane (usually represented in 2D format such as Equirectangular [52], Cubemap [41], etc.). Projection:  Note that, the output frames from the decoder are still in the  spherical coordinate system . Therefore, unlike the 2D video processing where the display can directly read \n242 \n59% \n29% \n6%  6% \nCompute \nMemory Decode Display \n(a) Power breakdown.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "At runtime, ResiSchecule dynamically selects activation solutions from either  Sequential  or  Pipelining  in each power cycle, depending on which can provide a better throughput. We refer to this as ResiSchedule . Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "[36]  D. Le Gall, ‚ÄúMpeg: A video compression standard for multimedia applications,‚Äù  Commun. ACM , p. 46‚Äì58, 1991. [37]  K. Lee, J. Yi, Y. Lee, S. Choi, and Y. M. Kim,  GROOT: A Real-Time Streaming System of High-Fidelity Volumetric Videos .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Further, the simulator was integrated with CACTI [ 62 ] and DRAMSIM3 [ 49 ] to estimate access latency, power, and simulate the memory access pattern. Rather than including a cycle accurate CPU (host) simulator to orchestrate the compute, we used a simple program to act as proxy for the host CPU and send control signals to schedule and orchestrate the compute on the systolic array. To correctly estimate accelerator power and area, we implemented a register-transfer level model using System Verilog and syn- thesized using Synopsys Design Compiler [ 93 ] with a 32nm library [ 94 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Wu, ‚ÄúChasing carbon: The elusive environmental footprint of computing,‚Äù  IEEE Micro , vol. Wei, \nD. Brooks, and C.-J. [29] U. Gupta, Y. G. Kim, S. Lee, J. Tse, H.-H. S. Lee, G.-Y.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "https://www.xilinx.com/products/ design-tools/vitis/xrt.html . (Accessed on 11/20/2023). Guilherme H. Apostolo, Pablo Bauszat, Vinod Nigade, Henri E. Bal, and Lin Wang.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "All decisions related to VM au- toscaling, bin-packing and load-prediction are reliant on the centralized mongodb database, which can become a potential bottleneck in terms of scalability and consistency. This can be mitigated by using fast distributed solutions like Redis [ 16 ] and Zookeeper [ 46 ]. The DeepARest model is pre-trained using 60% of the arrival trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "This motivates us to investigate which component is the major perfor- mance and energy bottleneck, charging most of the ‚Äúperformance- and/or energy-taxes‚Äù from the battery-backed AR headsets. 2.2 Motivation \n2.2.1 What is the Major Bottleneck? 5 fps, and the battery life can be as short as just 1 hour.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "7: Update model parameters: \nŒ∏ k +1  =  Œ∏ k  ‚àí Œ± k   b ‚àá J ( Œ∏ k ) . 5: A subset of sensors, determined by the equilibrium, send their gradient estimates to the aggregator. 6: The aggregator forms an unbiased estimate of the full gradient: \nb ‚àá J ( Œ∏ k ) =  b ‚àá L ( Œ∏ k ) +  Œª 1 ‚àá ‚Ñ¶ SNR ( Œ∏ k ) \n+ Œª 2 ‚àá ‚Ñ¶ complexity ( Œ∏ k ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "While striking a few similarities with  Cocktail , it is practically limited to image-classiÔ¨Åcation applications with very few classes and does not address re- source provisioning challenges. Several works [ 37 , 38 ] like MArk [ 86 ] proposed SLO and cost aware resource procure- ment policies for model-serving. Although our heterogeneous instance procurement policy has some similarities with MArk, it is signiÔ¨Åcantly different because we consider ensemble models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "In an effort to optimize video compression beyond traditional and current neural codec capabilities, we introduce an enhanced layered neural codec that utilizes both intra-frame and inter-frame redundancies. Our approach extends the layered neural codecs by incorporating motion vectors as a latent space, akin to the macroblock techniques used in H.264, to maximize inter-frame compression efficiency. 8 \nAlgorithm 1  Neural Encoding and Compression using the video data inference pipeline.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Else- vier. [49]  Reem E Mohamed, Ahmed I Saleh, Maher Abdelrazzak, and Ahmed S Samra. 2018.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "We prototyped our proposed  EA  and  AE  design blocks using System Verilog in Xilinx Vivado 2019.2 [58], targeting the Xil- \ninx Zynq-7000 SoC ZC706 board running at 100MHz (same as state-of-the-art EVR [28]). The evaluation shows that our  EA and  AE  designs consume only  2 mW  and  65 mW , respectively, and are able to deliver around  100  fps, which is more than sufÔ¨Åcient for the current VR application requirements. V. E VALUATION \nWe compare our proposed  EA  and  AE  designs with six different VR streaming setups, by evaluating the computation and the total energy consumption.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "There are diverse applications that are typically developed, trained and hosted as web services. 2 Background and Motivation \nWe start by providing a brief overview of model-serving in public cloud and ensembling, followed by a detailed analysis of their performance to motivate the need for  Cocktail . 2.1 Model Serving in Public Cloud \nFigure  2  shows the overall architecture of a model-serving framework.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "2019. MArk: Exploiting Cloud Services for Cost-Effective, SLO-Aware Machine Learning Inference Serving. In  ATC .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Using Scene Viewer to Display Interactive 3D Models in AR from an Android App or Browser. [4]  Stephen A Benton and V Michael Bove Jr. 2008. \"https://developers.google.com/ar/develop/java/ scene-viewer\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "2020. shorturl.at/jmnpD [53]  Antoni Rosinol, Marcus Abate, Yun Chang, and Luca Carlone. Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "4). Combination of ER-r and AAS, results in more than 70% accuracy for most of the activities (Fig. 0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 RR3 with AAS RR6 RR6 with AAS RR9 RR9 with AAS RR12 RR12 with AAS Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Graham Gobieski, Nathan Beckmann, and Brandon Lucia. Accessed: 2024-11-27. case.edu/bearingdatacenter/download-data-file , 2018.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "We observe that, for the MHEALTH dataset, RR12- Origin  is 2.72% more accu- rate than the Baseline-2. For the PAMAP2 data-set, RR12- Origin  is 2.53% better than Baseline-2. For certain cases like climbing in PAMAP2, and running in MHEALTH,  Origin  is more accurate than Baseline-1.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2024 Conference on Human Information Interaction and Retrieval , pages 391‚Äì395, 2024. [122] Journal of the American Medical Informatics Association. Efficient healthcare with large language models: optimizing clinical workflow and enhancing patient care.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "Since the clustering based coreset is typically more accurate then those formed by importance sampling, the former is pre- ferred, when possible. We increase the frequency of cluster- based formation by using custom, energy efficient hardware. With the help of an activity-aware and recoverable coreset construction and low-power hardware design, we can effi- ciently communicate inferences or compressed data to the host device with minimum power and latency overheads.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "AI-based modeling and data-driven evaluation for smart farming-oriented big data architecture using IoT with energy harvesting capabilities. Sus- tainable Energy Technologies and Assessments  52 (2022), 102093. [62]  Alanson P Sample, Daniel J Yeager, Pauline S Powledge, Alexander V Mamishev, and Joshua R Smith.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "The DACs and ADCs are used to convert the digital input and weight signals into analog signals that can be applied to the rows and columns of the x-bar. The shift registers are used to apply the weight signals in a structured way, and the hold capacitors are used to store the analog signals during the multiplication-addition operation. Similarly, for performing convolution, the ReRAM x-bar typically includes additional components, such as delay lines and adders.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "We introduce weights to estimate the appropriate number of containers to be spawned for each function. A function‚Äôs weight is calculated using the relative invocation frequency of a function along with other DAG-specific parameters  (explained in the next section). The relative invocation frequency of a function is measured with respect to the application it consti- tutes.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Even though the accuracy claim of the models was nearly 85%, in the Ô¨Årst iteration, the accuracy drops below 80% because of the added noise. As the conÔ¨Ådence matrix gets updated with the newer conÔ¨Ådence values sent from the sensor, we can see (from Fig. 6), that Origin  keeps up with the claimed accuracy (base accuracy), and at times outperforms it.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "[47]  D. Meagher, ‚ÄúGeometric modeling using octree encoding,‚Äù Computer Graphics and Image Processing , pp. 129‚Äì147, 1982. [46]  Mayank Raj, ‚ÄúPoint Clouds and its signiÔ¨Åcance in AR,‚Äù  ‚Äùhttps: //bit.ly/3uknBjT‚Äù , 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Furthermore, in the retail and business sectors, LLM-powered AI chatbots have been shown to reduce the time taken to process an order by 50% to 70%, demonstrating significant efficiency gains even in industries traditionally reliant on human interaction. 2012  ‚Äô14   ‚Äô16   ‚Äô18   ‚Äô20   ‚Äô22   ‚Äô24  \n10B \n 100M \n     1M \n   10K \n    100 \nTraining Compute (petaFLOPs) \nYear \nInceptionV3 \nResNet \nAlexNet \nXception \nDenseNet201 ELMo \nWav2Vec 2.0 MoCo ResNet50 \nTransformer \nGPT-1 \nBERT Large \nMegatron-NLG \nGPT-2 1.5B \nGPT3-175B \nMT NLG 530B \nBLOOM PaLM \nGPT-MoE-1.8T Transformers=16x/year \nBefore Transformers=3x/year \nFigure 1 :  Trend of increasing compute power requirements for training. Source: [30].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 198,
    "augmented": true
  },
  {
    "text": "Hence, our scheme does not lose any accuracy, and still saves  43%  energy. However, due to the static window size employed, Euphrates [9] leads to as much as  6%  accuracy drop in this video segment, which is hardly acceptable by most applications. Apart from the above mentioned optimizations at the layer- level (DeepCache) and the frame-level (Euphrates), recall that, in Table I, we indicated (in the last column) the Decision Making Logic (DM) the previously proposed optimization strategies employ.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2112.09691 , 2021. Siwei Ma, Xinfeng Zhang, Chuanmin Jia, Zhenghui Zhao, Shiqi Wang, and Shanshe Wang. Image and video compression with neural networks: A review.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "2) Model Compression and Pruning:  To make DNNs mo- bile friendly, there have been several works in compressing and pruning large models. Several hardware-based approaches such as NPUs [24] or ASICs [25], [26] have been proposed to speedup the inference; however, they only work on a narrow set of speciÔ¨Åc applications and/or platforms. Al- though DNN inference is highly structured and embarrassingly parallel, the limited resources on the mobile devices, alongside \nthe required off-chip data movements, poses a signiÔ¨Åcant challenge leading to higher latency.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "Bashima Islam and Shahriar Nirjon. Zygarde: Time-sensitive on-device deep inference and adaptation on intermittently-powered systems. arXiv preprint arXiv:1905.03854 , 2019.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "In  2008 IEEE Virtual Reality Conference . 2008. Hybrid Feature Tracking and User Interaction for Markerless Augmented Reality.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": ",  ii) how to integrate such optimizations into the entire geometry compression pipeline? , and  iii) what are the resulting beneÔ¨Åts and overheads? 1) How to Increase Parallelism?",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Further, all sensors might not be able to participate in the ensemble due to the Ô¨Åckle nature of harvested energy. Therefore, this work proposes an intelligent scheduler along with efÔ¨Åcient ensemble learning to enable DNN inference in a distributed energy harvesting wireless sensor network (EH- WSN). This demands the aggregation process for the ensemble to be robust, yet light weight in order to perform accurate classiÔ¨Åcation with minimum overhead.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "In Section  4 , we introduce the game-theoretic model of sensor participation, motivat- ing our approach against simpler heuristics and discussing why equilibrium solutions are desirable. Section  5  outlines the training and fine-tuning framework that integrates the equilibrium strategies into a federated learning paradigm. Fi- nally, Section  ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Exploiting frame similarity for efficient inference on edge devices. In  2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) , pages 1073‚Äì1084, 2022. [176] Huizi Yu, Lizhou Fan, Lingyao Li, Jiayan Zhou, Zihui Ma, Lu Xian, Wenyue Hua, Sijia He, Mingyu Jin, Yongfeng Zhang, Ashvin Gandhi, and Xin Ma.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "When compared to the OD price , they were up to 70% cheaper. Note that, we set the bidding price conser- vatively to 40% of OD. This price gap is cap- italized in  Cocktail  to reduce the cost of instances consumed by ensembling.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "2020. The ifs and buts of less is more: a serverless computing reality check. [37]  J√∂rn Kuhlenkamp, Sebastian Werner, and Stefan Tai.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Similar to the intra- frame proposals discussed in Sec. IV , we again use a simple \n290 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Wireless Personal Communications 101, 2 (2018), 1019‚Äì1055. [50]  Thaha Mohammed, Carlee Joe-Wong, Rohit Babbar, and Mario Di Francesco. 2020.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Regular re-tuning may be warranted as oper- ating conditions, energy harvesting patterns, or accuracy requirements evolve over the network‚Äôs lifetime. The above guidelines and the explo- ration algorithm provide a structured approach to selecting and refining  Œ≥, Œ¥,  and  Œ∑ . By starting from theoretically in- formed baseline conditions and iteratively refining through simulation-based feedback, it is possible to reach a stable set of parameters that promotes balanced participation, discour- ages perpetual abstention, and prevents excessive energy expenditure.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Since there is a small offset between the two eyes, the projection computation needs to cap- ture the pupillary distance to generate a separate view for each eye. Therefore, the output of the projection computation is  two projection matrices, each indicating the mapping between each coordinate in  360 ¬∞ video frame and a 2D coordinate on screen for the left and right eye. Note that, this projection process is quite compute-intensive.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Skipper: Enabling efficient snn training through activation- checkpointing and time-skipping. In  2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO) , pages 565‚Äì581, 2022. [151] Sainbayar Sukhbaatar, Olga Golovneva, Vasu Sharma, Hu Xu, Xi Victoria Lin, Baptiste Rozi√®re, Jacob Kahn, Daniel Li, Wen tau Yih, Jason Weston, and Xian Li.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "[50]  Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-100 (cana- dian institute for advanced research), 2010.  http://www.cs.toronto. edu/~kriz/cifar.html .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "; vi) What are the additional complexities and opportunities KV-caches bring in an EoE environment? ; and vii)  What are the various combinations of algorithmic constructs, runtime software configurations, and architectural features, and how can their ‚Äúaffinity‚Äù be synergistically leveraged to enhance the efficiency of training and inference processes? .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "2 \n110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 \n2.3. Game-Theoretic Models in Sensor Networks \nGame theory provides a powerful framework for modeling and analyzing strategic interactions in distributed systems, including sensor networks ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Mathematical Formulation:  The Shapley value  œï i  of neuron  i  is a measure of its contribution to the overall network performance. D.5 Neuron Shapley Value Dropout with QuantaTask Optimization \nNeuron Shapley Value Dropout applies the concept of Shapley values from game theory (Aas et al., 2021) to assess neuron importance for dropout, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout with learnable mask parameters, along with the QuantaTask optimization to handle energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "Opportunistic computing in gpu architectures. In  Pro- ceedings of the 46th International Symposium on Computer Architecture , ISCA ‚Äô19, page 210‚Äì223, New York, NY, USA, 2019. Association for Computing Machinery.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "In summary, our research presents a comprehensive vision for the future of storage systems in ML, where computational storage \n17 \ndevices play a key role in advancing the, performance, efficiency, and capabilities of storage servers, thereby contributing significantly to the broader field of ML. References \nAchieving Compliant Data Residency and Security with Azure. Achieving Compliant Data Res- idency and Security with Azure.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "baseline InterHolo IntraHolo InterIntraHolo \nAvg. Power (mW) \n(a) Avg. power (mW).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "[48] F. Suard, A. Rakotomamonjy, A. Bensrhair, and A. Broggi, ‚ÄúPedestrian detection using infrared images and histograms of oriented gradients,‚Äù in  2006 IEEE Intelligent Vehicles Symposium , 2006, pp. 206‚Äì212. 1084 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Additionally, as the step- size of full-inference is Ô¨Åxed, it cannot adaptively update its cache based on the video content. On the other hand, Euphrates makes use of the motion information collected from the Image Signal Processor (ISP), and search the RoIs by combining the MVs of the current frame with the inference result of reference frame, and consequently, decrease the number of inference. Different from these two prior works where approximation decisions are dictated by reuse distance (e.g., the distance between two fully-inferenced frames), Potluck [12] utilized the feature vector extracted from input frames to adaptively trade off computation with reuse of the cached results.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction. II. M OTIVATION \nTo avoid negatively impacting the underlying system‚Äôs QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "10th IEEE Real-Time and Embedded Technology and Applications Symposium, 2004. , pp. 174‚Äì181, 2004. doi: 10.1109/ RTTAS.2004.1317262. Barry Brown, Mathias Broth, and Erik Vinkhuyzen.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Current hardware accel- erators like GPUs, and even specialized processors like Groq [61], Cerebras [86,96], Graphcore [54,115], and SambaNova [131], are not efficiently utilized due to limitations in memory bandwidth, interconnects, and data handling capabilities. The resulting power needs have recently triggered data center providers to install their own power plants [44,53,136,155]. These hardware inefficiencies lead to suboptimal performance and increased energy consumption.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "2.3 Pros and Cons of Model Ensembling \nIn this section, we quantitatively evaluate (i) how effective ensembles are in terms of accuracy and latency compared to single models, and (ii) the challenges in deploying en- semble frameworks in a cost-effective fashion on a public cloud. For relevance in comparison to prior work [ 27 ,  83 ] we chose image inference as our ensemble workload. While ensembling is applicable in other classiÔ¨Åcation workloads like product recommendations [ 24 , 53 ], text classiÔ¨Åcation [ 71 ] etc, the observations drawn are generic and applicable to other applications.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "11: Tile utilization against available power:  Us. ¬¥as  with eager scheduling vs an oracle scheduler. 0 \n100 \n200 \n300 \n1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 \n# TIles Utilized \nTraning Iteration \n#Tiles-Oracle Œ∑d≈ù≈Øƒû∆êÕ≤h∆îƒÑ∆ê DadianNao ≈µƒûƒÇ≈∂Õ≤h∆îƒÑ∆ê Mean-DaDianNao \n(a) Monotonically increasing \n0 \n50 \n100 \n1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46 49 \n#Tiles Utilized \nTraining Iteration \n#Tiles-Oracle d≈ù≈Øƒû∆êÕ≤h∆îƒÑ∆ê DaDianNao DƒûƒÇ≈∂Õ≤h∆îƒÑ∆ê Mean-DaDianNao \n(b) Rapidly varying \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 187,
    "augmented": true
  },
  {
    "text": "and the other represent experts (E1, E2, etc.). An edge between a dataset and an expert indicates that the ex- pert is trained on that dataset (i.e., expert-data affinity). Given memory capacity constraints, we frame the problem as identifying sets of experts to train together such that the data reuse among the selected experts, in a training step, is maximized and the combined data and parameter requirements of the set fit within the available memory.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "These statistics underscore the profound signiÔ¨Åcance and transformative potential of these data-driven realms, delineat- ing their pivotal role in shaping the landscape of computing technology, from algorithms to architecture. What distinguishes these data is their diverse origin, span- ning from IoT devices to wearables, and their acquisition from challenging environments, including autonomous driving and urban mobility scenarios. Amidst the myriad of data-driven domains, urban mobility, smart cities, autonomous driving, and the Internet of Things (IoT) emerge as some of the most rapidly expanding Ô¨Åelds contributing to the global economy, amounting to more than 4 trillion US dollars [ 1 ], [ 54 ], [ 76 ], [ 98 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "Energy Consumption:  Fig. 8b  plots the energy consumptions (in  J ) for the SOTA works on the primary y-axis (left), and our proposals on the secondary y-axis (right). Clearly, TMC13 and CWIPC are two of the most energy-consuming schemes, which consume  11 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Sweden data collection & processing. (Accessed on 11/13/2023). www.dlapiperdataprotection.com.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Further, the other 5 models are used by up to 25% of the images. Not including them in the ensemble would have led to severe loss in accuracy. But, our dynamic policy with the class-based weighted voting, adapts to input images in a given interval by accurately selecting the best performing model for each class.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "(2)  Œ¥  appropriately penalizes incorrect inferences, discouraging low-quality data contri- butions. (3)  Œ∑ > Œ¥  to prevent sensors from consistently abstaining, thereby promoting overall network engagement. These guidelines help in balancing immediate utility gains with long-term energy sustainability, ensuring that the game- theoretic model drives desirable participation behaviors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "They do not seem to leverage the fact that the transformation matrices are unique for each head orientation and memoizing them will save re-calculating the transformation matrix ( T  ) as well as the projection matrix ( P ). ‚Ä¢  Even if they do realize such opportunities, the projection matrix ( P ) is very big ( ‚âà 8 MB , details in Sec. IV-C), and one edge VR headset cannot afford to memoize them for all  possible head orientations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "While fully powered,  Us. ¬¥as  is competitive in terms of energy efÔ¨Åciency for training-only tasks. We include details on the energy efÔ¨Åciency of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Figure 2 shows the accuracy of various policies on 2-home and 4-home setups. Further, we apply our policies to the distributed data and train random forest models (both for the edge and the cloud). Following are the key observations from our experiments.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Despite the lower accuracy gains,  Cocktail  is able to reduce the cost (Figure  17 ) of model-serving by 1.45 √ó  and 1.37 √ó for Wiki trace compared to  InFaaS  and  Clipper , respectively. 7 Concluding Remarks \nThere is an imminent need to develop model serving systems that can deliver highly accurate, low latency predictions at re- duced cost. In this paper, we propose and evaluate  Cocktail , a cost-effective model serving system that exploits ensembling techniques to meet high accuracy under low latency goals.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Start with small values of  Œª 1  and  Œª 2  to avoid over- whelming the primary loss  L ( Œ∏ ) . Gradually increase them if the model relies too heavily on high-SNR data or becomes too complex. 2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "He, M. A. Qureshi, L. Qiu, J. Li, F. Li, and L. Han, ‚ÄúRubiks: Practical 360-Degree Streaming for Smartphones,‚Äù in  Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services , 2018, pp. 482‚Äì494. [19] HEADJACK, ‚ÄúThe Best Encoding Settings For Your 4k 360 3D VR Videos + FREE Encoding Tool,‚Äù ‚Äùhttps://headjack.io/blog/best- encoding-settings-resolution-for-4k-360-3d-vr-videos/‚Äù.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pp. 509‚Äì531, 2024. { GRACE } : { Loss-Resilient }{ Real-Time }  video through neural codecs.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "At the beginning of each kernel scheduling iteration, the micro-proÔ¨Åler decides the right conÔ¨Åguration, and the control distributes equal number of kernels to each active tile (given  A  active kernel, and  K total kernels, each tile gets  ‚åä K / A ‚åã kernels to execute). However, in the middle of the execution if any new tiles becomes alive (because of an increase in harvested power), the scheduler immediately marks it ready to start working and the tile fetches a kernel (currently not scheduled in any of the tiles) and starts working on it. The conservative scheduler ensures that no tile loses power before Ô¨Ånishing the current scheduled kernel.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 21st International Middleware Conference . 356‚Äì370. Xanadu: Mitigating cascading cold starts in serverless function chain deploy- ments.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "3 Related Work \nLLMs have gained significant momentum in recent years and are being used in domains like virtual as- sistants [12,16,56], website chatbots [121], tools [48,123], notetaking/summarization [52], etc. The volume of research in LLMs is a testimonial to the interest in this area. Here, we summarize the research directly related to our proposal under the following areas: Algorithms and Models:  LLMs are known for their vast parameter sizes and training datasets, with a com- \nmon belief that larger LLMs yield better performance [64].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "The reason is that the active power threshold of  Pipelining  is much higher than that of  Sequential . As a result, fewer power cycles of Pipelining  are available than that of  Sequential . However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "The external interface will contain links to the publicly-available LLM/expert models and algorithms, compiler, system software and simulator codes and experimental data as they become available, whereas the internal link will be used to facilitate code sharing among the students and the PIs, as well as tracking the progress of code development and publication-related efforts. Broadening Participation in Computing (BPC) Plan: Connected \nSince this is a connected BPC plan, we only discuss the planned activities for the PIs, as specified in the submission guidelines. This website will have both ‚Äúexternal‚Äù and ‚Äúinternal‚Äù inter- faces.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "This, in turn, increases the cost of deployment (shown in Figure  5 ), compared to baseline  reactive  scheme. WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands J.R. Gunasekaran, et al. It can be seen that although both  util_aware  and  exascale  can reduce SLO vi- olations (shown in Figure  5 ), they still suffer from 20% to 30% over-provisioned VMs across all four traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Towards this, we studied three state-of- the-art PCC pipelines ‚Äì octree-based pipeline for intra-frame geometry compression (Sec. IV-A 1 ), RAHT for intra-frame attribute compression (Sec. IV-C 1 ), and macro block-based motion compensation pipeline for inter-frame compression \n3 We use PCL [ 72 ] and TMC13 [ 56 ] library for our proÔ¨Åling, where the geometry is compressed by the octree structure in PCL, and the attributes (RGB colors) are compressed through RAHT in TMC13.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "IEEE, 2024. Trapezoid: A versatile accelerator for dense and sparse matrix multiplications. In  2024 ACM/IEEE 51st Annual International Symposium on Computer Architec- ture (ISCA) , pages 931‚Äì945.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Although iNAS enhances network selection, its lack of intermittency awareness significantly impacts accuracy. 4.5 Limitations and Discussion \nWe recognize that modern architectures like Transformers have become prevalent in the ML commu- nity due to their superior performance on large-scale datasets. However, deploying such architectures on ultra-low-power, energy-harvesting devices presents significant challenges due to their substantial \n9 \n200 250 300 350 400 450 500 550 600 \nLatency (ms) \n78 80 82 84 86 88 90 92 94 \nAccuracy (%) \nAccuracy vs. Latency for Different Classes \nR1 R2 R3 SJ SI \n(a) Accuracy vs Latency \n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 Capacitance (F) \n78 \n80 \n82 \n84 \n86 \n88 \n90 \n92 \nAccuracy (%) \nAccuracy vs. Capacitance for Different Classes \nR1 R2 R3 SJ SI \n(b) Accuracy vs Capacitance \nFMNIST CIFAR10 MHEALTH PAMAP AudioMNISTMachine Dataset \n0 \n20 \n40 \n60 \n80 \n100 \nAccuracy (%) \nAbalation Study \nDN DN+DF DN+DF+DI \n(c) Ablation Study Figure 3: Sensitivity and ablation study.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 308,
    "augmented": false
  },
  {
    "text": "1: Edge-cloud partitioning policies. partition random forest compute efficiently between edge and cloud in a distributed sensor network. Each (edge)  device  (which is a part of the  Deployment scenario like machine state monitoring) contains an embedded computer (e.g.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "The source codes for the compiler and systems software support, as well as simulator source code will be maintained in Penn State as long as they are needed. They will be made available to the broad research community and other interested parties via a GitHub license. Types of Data and Storage \nThe project will generate seven types of data: (i) the codes and executables for the compiler that performs expert-to-chiplet mapping; (ii) source codes for scheduling support and simulator; (iii) expert repository that will hold the LLMs/expert models generated during the project; (iv) detailed LLM/expert algorithms as well as workload characterization and experimental data; (v) educational materials; (vi) a document detailing how to use the software developed during the project; and (vii) finally, lineage (provenance) data (more on this below).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 187,
    "augmented": true
  },
  {
    "text": "Therefore, there is considerable variation in the functions that can be invoked in DDAs, thus, negating the inherent assumption in many frameworks [ 32 ,  42 ,  44 ,  50 ] that all functions will be invoked with the same frequency as the application. This discrepancy can lead to substantial container overprovisioning. Opportunity 1:  In order to reduce overprovisioning of contain- ers, it is vital to design a workflow-aware resource management (RM) framework that can dynamically scale containers for each function, as opposed to uniformly scaling for all functions.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "ACM Interna- tional Symposium on Eye Tracking Research and Applications (ETRA) . Privacy-Aware Eye Tracking Using Differential Privacy. In  Proc.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "The conventional \nmethod, where the sensors collect the data and send it to the cloud or any other host device (such as connected mobile phones) is not an effective option as communicating large data demands more power, which is both highly variable and scarce in EH systems. Therefore, the better option, from a communication cost perspective, is to execute the inferences on the individual sensors and use an ensemble learning method (like majority voting) to aggregate these results for the Ô¨Ånal classiÔ¨Åcation. 1% \n0 20 40 60 80 100 All Succeed Atleast one succeed Failed \n9% 90% \n(a)  Inference completion breakdown when three EH sensors are working together to Ô¨Ånish the incoming inferences.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nLatency \n(c)  Twitter-trace:  Strict  workload. InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp. Latency (ms) \n(d)  Twitter-trace:  Relaxed  workload.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "103‚Äì118, Renton, WA, April 2022b. USENIX Association. ISBN 978-1-939133-27-4.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the ACM Symposium on Cloud Computing (Santa Cruz, CA, USA)  (SoCC ‚Äô19) . Association for Computing Ma- chinery, New York, NY, USA, 13‚Äì24. https://doi.org/10.1145/3357223.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "ITU-T Recommendation H.264. ITU-T. High efficiency video coding. International Telecommunication Union, June 2019b.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Given the limitations of the EH budget, such approaches typically end up dropping many samples and not inferring from them locally. On this front, recent works [ 43 ,  44 ,  47 ] have specifically optimized DNN infer- ence execution at the EH-edge nodes by utilizing adaptive dynamic check pointing, intelligent scheduling and ensem- ble learning. The sporadic nature of har- vested energy and the lossy nature of EH based storage and charging circuits calls for using the harvested energy di- rectly to perform intermittent compute rather than storing energy for some distant future use.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "An overview of chatbot technology. Springer, 2020. In  IFIP interna- tional conference on artificial intelligence applications and innovations , pages 373‚Äì383.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "2, pp. 292‚Äì308, 2019. [16] Y. Chen, T. Luo, S. Liu, S. Zhang, L. He, J. Wang, L. Li, T. Chen, \nZ. Xu, N. Sun  et al.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "0 20 40 60 80 100 \n0 20 40 60 80 100 \nClass Distribution \nAccuracy (%) \nBaseline Train-Win-1 Train-Win-2 Train-Win-4 Appeared \nFig. 3: Distribution of different classes on a typical trafÔ¨Åc pattern and the impact of training on the sampling bias. The ‚Äùappeared‚Äú line represents the percentage of the frames in which the corresponding class is present, e.g.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Intermittent DNN Execution/Training:  As the applications deployed on such EH devices demand analytics, executing DNNs on EH devices and EH-WSNs have become prominent (Lv & Xu, 2022; Gobieski et al., 2019; Qiu et al., 2020; Mishra et al., 2021). However, due to computational constraints, limited memory capacity and restricted operating frequencies, many of these applications fail to complete inference execution with satisfactory SLOs, despite comprehensive software and hardware support (Mishra et al., 2021). While the works relying on loop-decomposition or task partition (e.g., see (Qiu et al., 2020; Gobieski et al., 2019) and the references therein) ensure ‚Äúforward progress‚Äù, they do not guarantee an inference completion while meeting SLOs.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 214,
    "augmented": false
  },
  {
    "text": "609‚Äì622. [58] Xilinx, ‚ÄúVivado Design Hub - Installation and Licensing,‚Äù ‚Äùhttps://www.xilinx.com/support/documentation-navigation/design- hubs/dh0013-vivado-installation-and-licensing-hub.html‚Äù. [57] C. Xie, X. Zhang, A. Li, X. Fu, and S. Song, ‚ÄúPIM-VR: Erasing Motion Anomalies In Highly-Interactive Virtual Reality World with Customized Memory Cube,‚Äù in  Proceedings of the International Symposium on High- Performance Computer Architecture (HPCA) , 2019, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 165,
    "augmented": true
  },
  {
    "text": "However, accuracy being a Ô¨Çoating point number, is expensive in terms of energy to store and lookup. B. Activity Aware Scheduling \nTo enable the activity awareness we keep a small lookup table of accuracy of all the sensors over all the classes.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "High-SNR data capture improves the sensor‚Äôs con- tribution to global accuracy but consumes more energy. Let e cap ( SNR )  denote the energy required for capture at a given SNR level. We assume a monotonic relationship: higher SNR increases both the capture cost and the expected ac- curacy contribution.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "These works focus on the pixel content reuse, which is the last stage ( Projection Mapping ) in the  360 ¬∞ video projection pipeline (discussed in Sec III). However, none of these existing schemes leverage reducing the large amounts of ‚Äúredundant‚Äù computations in the preceding stage (projection computation). 251 \nOur proposed  EA  and  AE  designs focus on these intensive projection computations, and as such are orthogonal to these prior efforts.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "But, our dynamic policy with the class-based weighted voting, adapts to input images in a given interval by accurately selecting the best performing model for each class. To further demonstrate the effectiveness of our dynamic model selection, Figure  10b , 10c  plots the number models in every sampling interval along with cumulative accuracy and window accuracy within each sampling interval for three schemes. We observe that  Cocktail  can effectively scale up and scale down the mod- els while maintaining the cumulative accuracy well within the threshold.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Sensors must carefully balance immediate accuracy gains against conserving energy for future tasks, while also antici- pating the behavior of other sensors that may be collaborat- ing or competing. Conversely, simplistic policies‚Äîsuch as se- lecting only the highest-energy sensors‚Äîignore factors like data relevance, sensor quality, and the strategic implications of current participation on future network states. This challenge motivates the need for intelligent, context- aware participation strategies that dynamically determine which sensors should engage during both the  training phase‚Äîwhere global model parameters are periodically fine-tuned or updated‚Äîand the  inference  phase‚Äîwhere newly observed data are aggregated to produce predictions.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "To the best of our knowledge, this is the Ô¨Årst work that focuses on low power and reconÔ¨Ågurable RCA design from both the hardware and software angles targeting energy harvesting systems. ResiRCA allows an RCA to adapt to changing harvested energy and, with our co-designed scheduling approach, ResiSchedule, it can achieve very high throughput. Such a system is capable of both continuously collecting data and computing CNNs locally near data.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "To better under- stand which of these are the best candidates ( features , using machine learning parlance) for memoization and whether they are sufÔ¨Åcient or not, we next discuss input parameters and their impact on the computation: ‚Ä¢  Head orientation:  Any changes in this affect the matrix T 2  as discussed in Tab. What (features) to Memoize? As discussed earlier, at any moment during VR video processing, the execution pipeline is not only impacted by the head orientation, but also by other features such as video frame rate, video types/semantics information, pixel values, user interactions.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Table 1 provides an estimation of resource utilization on commercial systems underscoring the fact that compressing, encrypting and reliably storing the data, especially for (intermittent) edge servers is a bigger challenge in contrast to classical cloud storage servers. The Challenges:  In edge computing architectures, the  lack of data reuse  between the analytics and video data archival poses significant challenges. Classically, video data is streamed simultaneously to compute and storage systems for various processing tasks, such as inference, exemplar selection, and storage, thereby increasing I/O bandwidth and system processing demands.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Once the scheduled ( t i ) tiles are completed, the micro-proÔ¨Åler again Ô¨Ånds the right conÔ¨Åguration for the  i  +  1 th   iteration and the scheduler again conservatively enables  t i + 1  number of tiles suitable for the power budget. Note that the power requirement of each tile is known in advance (please refer to ¬ß V , TABLE  I  for details). The  t i + 1  tiles fetch the next  t i + 1  kernels from the GKDQ and the process continues.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Connectivity:  In addition to function invocation probabil- ities, it is necessary to also account for the effects of cold starts on DDAs while estimating function weights. Cold start spillovers (that often occur due to container underprovision- ing), as described in Section 2, can impact the response la- tency of applications harshly. ùê∂ùëúùëöùëùùë¢ùë°ùëí _ ùëÉùëüùëúùëè , \n158 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nin Algorithm 1, first estimates the invocation probabilities of a function‚Äôs immediate predecessors and uses it along with system log information and load measurements of the function to calculate its invocation probability.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "The DeepARest prediction model which is not in the critical decision-making path runs as a background process incurring 2.2 ms latency on average. The  mongodb  database is a centralized server, which resides on the head-node. We measure the overall average latency incurred due to all reads/writes in the database, which is well within 1.5ms.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "References \n[1]  [n.d.]. Twitter Stream traces. https://archive.org/details/twitterstream.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "We maintain a request queue at every model pool. Load Balancer : Apart from procuring instances, it is quintessential to design a load balancing and bin-packing  5 strategy to fully utilize all the provisioned instances. In order to increase the utilization of all instances in a pool at any given time, the load balancer submits every request from the queue to the lease remaining free slots (viz.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "B. However, since the whole computation/rendering process takes place on a battery-backed device [39], one needs to consider the ‚Äúenergy efÔ¨Åciency‚Äù of this computation, i.e., even though we can meet the performance requirements of such video, energy efÔ¨Åciency needs to be improved. Motivation \nTo understand the energy proÔ¨Åle in the current VR devices, we characterize the energy consumption of  360 ¬∞ video pro- cessing on a prototype [36] (conÔ¨Ågured similar to a com- mercial VR device [39], discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "The results of Naive1  are the worst because it lacks both adequate hardware resources and scheduling Ô¨Çexibility. Although  Naive2  is based on the  ResiRCA  architecture, the throughput is still relatively low because it lacks scheduling adaptation to Ô¨Åt to the changing harvested power. ‚Ä¢  The results of  ResiSchedule  are very close or equal to that of  Sequential  under most cases.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "ViVo: Visibility-aware Mobile Volumetric Video Streaming. In  Proceedings of the ACM/IEEE International Conference on Mobile Computing and Networking (MobiCom) . 1‚Äì13.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "V). Frame-2 needs to be carefully processed and full inference needs to be employed, as indicated by  4  in Fig. Therefore, in this case, \n1 According to [23], only a small portion of DNN inference run on mobile GPUs, thus, in this work, we focus on optimizing the DNN inference on mobile CPUs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "[42]  S. A. Dawwd and B. S. Mahmood, ‚ÄúA reconÔ¨Ågurable interconnected Ô¨Ålter for face recognition based on convolution neural network,‚Äù in  2009 4th International Design and Test Workshop (IDT) , pp. 1‚Äì6, 2009. [43]  Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, ‚ÄúGradient-based learning applied to document recognition,‚Äù  Proceedings of the IEEE , vol.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Hence, inspired from prior work [ 27 , 86 ], we de- sign an adaptive packing policy such that it takes into account the number of requests to schedule at time  T  and  P f  for every instance. GPU instances are cost-effective when packed with a large batch of requests for execution. The requests are sent to GPU instances only if the load matches the  P f  of the instance.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Conventionally, training is much more compute intensive (compared to an inference), takes many iterations and hence has been given considerable attention for better accuracy and convergence time. These inference queries are typically administered with strict response laten- cies of under one second [ 4 ]. However, given the preva- lence and demand of inferences, serving them on public cloud with a tight bound of latency, throughput and cost is becoming increasingly more challenging [ 7 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Lastly, we apply coarse-grain power gating to conÔ¨Ågure the number of duplicated ReRAMs. SpeciÔ¨Åcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows. We modify the column multiplexers to enable variable active columns and turn off the ADCs of inactive channels.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "And Ô¨Ånally, we quantize these deltas for achieving higher compression ratio. 2) What are the Pros and Cons? In this example, two vectors (as there are two segments) store the Ô¨Ånal data, including  Mid  =  51 , Delta  = [ 0 , 0 ]  for the Ô¨Årst one segment, and  Mid  =  54 , Delta  = [ 0 ]  for the second.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "730‚Äì741, 2005. Vibhaalakshmi Sivaraman, Pantea Karimi, Vedantha Venkatapathy, Mehrdad Khani, Sadjad Fouladi, Mohammad Alizadeh, Fr√©do Durand, and Vivienne Sze. Gemino: Practical and robust neural compression for video conferencing.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Hence, to enhance the Ô¨Çexibility of our proposed design for trading off the compression efÔ¨Åciency with the quality, we can use the  percentage of ‚Äúdirect-reuse‚Äù blocks  as a  tunable design knob , for which, users can choose the appropriate value based on their preferences (i.e., fewer ‚Äúdirect-reuse‚Äù blocks with higher PSNR vs. more ‚Äúdirect-reuse‚Äù blocks with higher compression efÔ¨Åciency). 10b , with fewer ‚Äúdirect-reuse‚Äù blocks (e.g., only  31%  of the I-blocks are directly reused in the left-most bar), the PSNR drops slightly when compared to the intra- frame compression, while the compression ratio is also the worst. On the other side, by increasing the percentage of the ‚Äúdirect-reuse‚Äù blocks, the compression efÔ¨Åciency also increases, at the cost of a PSNR degradation (e.g., the PSNR reduces to  38 dB with 83 %  ‚Äúdirect-reuse‚Äù blocks).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 222,
    "augmented": true
  },
  {
    "text": "[194] Zexuan Zhong, Mengzhou Xia, Danqi Chen, and Mike Lewis. Lory: Fully Differentiable Mixture-of- Experts for Autoregressive Language Model Pre-training. IEEE Computer Society.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "VI-B ). ‚Ä¢  Our Intra-only:  The performance of above two tech- niques has two orders of gap with the  ‚âà 100 ms  real- time requirement [ 19 ]. ‚Ä¢  CWIPC:  CWIPC takes about  4229 ms  (mainly for geometry compression as the attributes are directly entropy-encoded without any other efforts, as mentioned in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "[42]  M. Liu, ‚ÄúRobotic online path planning on point cloud,‚Äù  IEEE transactions on cybernetics , vol. 46, no. 5, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "26, no. 8, pp. [15]  R. L. de Queiroz and P. A. Chou, ‚ÄúMotion-compensated compression of dynamic voxelized point clouds,‚Äù  IEEE Transactions on Image Processing , vol.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Horovod: fast and easy distributed deep learning in tensor- flow, 2018. [142] Shaip. Large language models in healthcare: Breakthroughs, use cases, and challenges.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme. We refer to this as ResiSchedule . At runtime, ResiSchecule dynamically selects activation solutions from either  Sequential  or  Pipelining  in each power cycle, depending on which can provide a better throughput.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM. With this, the RCA can be active in a very large power range and Ô¨Ånd more opportunities to make execution progress. Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles  PC6, PC7  and  PC8 .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "[23]  X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, ‚ÄúA high- efÔ¨Åciency dual-channel photovoltaic power system for nonvolatile sensor nodes,‚Äù in  2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA) , pp. 1‚Äì2, Aug 2014. [24]  X.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "These services allow end-users to submit queries via web server interface. There are diverse applications that are typically developed, trained and hosted as web services. Since these inference requests are often user-facing, it is imperative to administer them under a strict service level ob- jective (SLO).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "arXiv , 2023. Centimani: Enabling fast AI accelerator selection for DNN training with a novel performance predictor. [169] Zhen Xie, Murali Emani, Xiaodong Yu, Dingwen Tao, Xin He, Pengfei Su, Keren Zhou, and Venka- tram Vishwanath.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a \n3-bit resolution, which is a high performance but also a high power consuming design. The inputs and weights are binary and the output is adaptive between 1-3 bits. The serial-input non-weighted product (SINWP) structure [ 6 ] is the Ô¨Årst work to propose multi-bit input/weight and output design from the circuit level, adopting a 2-bit input, 3-bit weight, and 4-bit output scheme.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "A hierarchical K-means+ (or DBSCAN) clustering approach learns representations for exemplar se- lection. Additionally, a novel power-aware micro-proÔ¨Åling policy is adapted to determine optimal hyper-parameters for a variable-power environment. The robust exemplar selection and micro-proÔ¨Åling mechanisms are discussed and evaluated in ¬ß III-B  and ¬ß III-C , respectively.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Towards this, we propose  Cocktail , a cost effective ensembling-based model serving framework. Cock- tail  comprises of two key components: (i) a dynamic model selection framework, which reduces the number of models in the ensemble, while satisfying the accuracy and latency requirements; (ii) an adaptive resource management (RM) framework that employs a distributed proactive autoscaling policy, to efÔ¨Åciently allocate resources for the models. The RM framework leverages transient virtual machine (VM) in- stances to reduce the deployment cost in a public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "This discounting ensures diminish- ing returns for postponing beneficial participation or indefi- nitely waiting for ideal conditions. The presence of the discount factor  Œ≤  further stabilizes the process. With  Œ≤  ‚àà [0 ,  1) , sensors value future utility less than immediate utility.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Optimizing resource allocation in gpu clusters for deep learning training. IEEE Transactions on Parallel and Distributed Systems , 32(8):1987‚Äì2000, 2021. [80] Jongman Kim, Chrysostomos Nicopoulos, Dongkook Park, Vijaykrishnan Narayanan, Mazin S Yousif, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "This resilient activation approach can effectively combat  Nonideal scenario 1 . With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of \n180 ¬µ W to 330 ¬µ W, and the throughput is increased by 85.7%. Note that the partial activation of computation cells can be realized by partially activating the peripheral circuits of the corresponding rows and columns in the ReRAM crossbar.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "Despite providing significant performance and energy-efficiency benefits, these prior works still miss out on even more selective rendering of viewed hologram images - beyond just the FoV and/or regions of the user‚Äôs focus. This is the primary motivation of this paper, where we explore trade-offs between hologram quality and processing costs. These trade-offs are not very straightforward due to the following  challenges : First,  among all of the inputs to the AR headset (shown later in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Also, we estimate the right configuration of lambda functions by conduction offline experiments. For the model selection problem, we maintain an offline model cache which consists of the de- tails of individual model latency and accuracy profiled by executing on c4 Àô large VM. The scheduler will pick the right model combinations from the cache based on the application requirements.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Extending this with  the point count for each cluster  allows for recon- struction of data in the original form that can be processed by DNNs trained on full-size data. These reconstructed data sets can be synthesized simply by uniformly distributing the points within each cluster. Although the intra-cluster data distribution will be different from the original, it will still preserve the overall geometry with a certain degree of approximation which the DNN could learn to accommodate.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "\"http://info.nvidia.com/rs/156-OFN-742/images/Jetson_AGX_ Xavier_New_Era_Autonomous_Machines.pdf\". [37] Nvidia. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "Accelerating hpc applications using computational storage devices. 1878‚Äì1885, 2019a. In  2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "The main idea behind RAHT is to use the attribute values in a lower octree level to predict the values in the upper level. In contrast, Predicting Transform and Lifting Transform are based on the hierarchical nearest-neighbor interpolation [ 80 ]. Apart from these methods that compress a static PC, there also exist several attempts at optimizing the compression for dynamic PCs by exploring the ‚Äútemporal redundancy‚Äù across the PC video frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "HC1 on the other hand is a garden video, with people walking around, riding \nbike, etc. GL1 and HC1 are other two videos from the CAMPUS [43] dataset. GL1 is also a parking lot video, but with many more objects and movements than V1 and V2.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "In exemplar selection, the entire dataset is analyzed to detect classes with unique features, i.e., the images that are much different from the training data distribution or new classes that were not included in the training data. This process involves ‚Äúrepresentation learning‚Äù (Rebuffi et al., 2017), where data is transformed into ‚Äúfeature vectors‚Äù using deep neural networks, followed by unsupervised learning techniques like k-means clustering. The goal is to identify unique or new classes of data for training while archiving known classes.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "In  Cock- tail , we leverage these transient VMs such as spot instances to drastically reduce the cost of deploying ensembling model framework. Figure  3b  shows that ensemble-spot can re- duce the cost by up to 3.3 √ó  when compared to ensemble-OD. As an example, we host full-ensembling on AWS spot instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "It is to be noted that, when a user‚Äôs head orientation is changed, the Projection Computation stage needs to  recompute the transformations to reÔ¨Çect the user‚Äôs head movement. The VR headset allows users to freely move their heads and eyes at any time to any degree. Hence, the projection transformation computation has to be executed at every frame to reÔ¨Çect user movements in real-time, and the whole process is very compute intensive (36 times per second [3]) and power hungry.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "memoize  the feature maps of the middle part in the previous frame, and reuse the data for the current frame. Since the outer part maintains no information for the RoIs, it can be safely discarded. 4) How to Do Partial-Inference?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "EfÔ¨Åcientnet: Rethinking model scaling for convolutional neural networks. arXiv preprint arXiv:1905.11946 , 2019. [74]  P. Thinakaran, J. R. Gunasekaran, B. Sharma, M. T. Kandemir, and C. R. Das.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Burscale: Using burstable instances for cost-effective autoscaling in the public cloud. In  Proceedings of the ACM Symposium on Cloud Computing , New York, NY, USA, 2019. Association for Computing Machinery.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "FPGAs are ideal for this application due to their parallel processing capabilities and the ability to handle multiple data streams concurrently. 9 \nAlgorithm 2  Training Auto-Encoder with Motion Vectors and Stacked Compression while freezing the inference model. 1:  Input:  Set of training video sequences  V 2:  Initialize:  MobileNet  M ‚ñ∑ Weights frozen 3:  Initialize:  Autoencoder  A ‚ñ∑ Trainable 4:  Initialize:  Motion Vector Extractor  V 5:  procedure  E XTRACT M OTION V ECTORS ( frame current , frame previous ) 6: motion _ vectors  ‚Üê V  ( frame current , frame previous ) 7: return  motion _ vectors 8:  end procedure 9:  procedure  F ORWARD P ASS ( video ) 10: previous _ features  ‚Üê null 11: previous _ compressed  ‚Üê null 12: for  each frame  frame  in  video  do 13: features  ‚Üê M ( frame ) ‚ñ∑ Extract features using frozen MobileNet 14: compressed  ‚Üê A.encode ( features ) ‚ñ∑ Compress features 15: if  previous _ compressed  Ã∏ =  null  then 16: motion _ vectors  ‚Üê E XTRACT M OTION V ECTORS ( frame, previous _ frame ) 17: stacked _ input  ‚Üê concatenate ( compressed, previous _ compressed, motion _ vectors ) 18: compressed  ‚Üê A.reencode ( stacked _ input ) ‚ñ∑ Stacked compression 19: end if 20: reconstructed  ‚Üê A.decode ( compressed ) ‚ñ∑ Decompress to reconstruct 21: Calculate reconstruction loss between  frame  and  reconstructed 22: previous _ frame  ‚Üê frame 23: previous _ compressed  ‚Üê compressed 24: previous _ features  ‚Üê features 25: end for 26: Backpropagate loss and update weights of  A  only 27:  end procedure 28:  while  not converged  do 29: for  each  video  in  V  do  F ORWARD P ASS ( video ) 30: end for 31:  end while \nThe implementation of layered codecs involve the following components.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 468,
    "augmented": false
  },
  {
    "text": "Second, its execution latency when running on our edge GPU prototype [ 36 ] is within 4 . 5 ms , which contributes to less than 1% of the entire hologram processing pipeline latency. With the RoF attained from the eye tracking, the next question we need to answer is how to deploy the approximation opportuni- ties discussed above in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Specifi- cally, there are two classes of applications that would probably achieve only limited benefits from our approach. First, for the quality-critical applications such as AR surgery [ 56 ], ultra-high resolution/quality of holograms are typically required. In this case, offloading computations to a resource-rich cluster/cloud system would be a more reasonable design choice (instead of approximating on the edge).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "[20] Google, ‚ÄúPixel Phone Hardware Tech Specs,‚Äù ‚Äùhttps://bit.ly/397dCUB‚Äù. [22] M. Motamedi, D. D. Fong, and S. Ghiasi, ‚ÄúFast and Energy-EfÔ¨Åcient CNN Inference on IoT Devices,‚Äù  CoRR , 2016. [21] Y. Liu, Y. Wang, R. Yu, M. Li, V. Sharma, and Y. Wang, ‚ÄúOpti- mizing CNN Model Inference on CPUs,‚Äù in  Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference , 2019, p. 1025‚Äì1040.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "Swayam [ 34 ] is relatively similar to our work as it han- \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1043 \nBaseline(BL) NASLarge IRV2 Xception DNet121 NASMob #Models 10 8 7 5 2 BL_Latency 311(ms) 152(ms) 120(ms) 100(ms) 98(ms) E_Latency 152(ms) 120(ms) 103(ms) 89(ms) 44(ms) \nTable 3:  Comparing latency of Ensembling (E_Latency) with single (baseline) models. dles container provisioning and load-balancing, speciÔ¨Åcally catered for single model inferences. Cocktail‚Äôs  autoscaling policy strikes parallels with Swayam‚Äôs distributed autoscaling; however, we further incorporate novel importance sampling techniques to reduce over-provisioning for under-used models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 234,
    "augmented": false
  },
  {
    "text": "Our experiments shows that DNN inference using  Origin , running on a harvested energy only system, is more accurate than energy-constraint- optimized DNNs, running on a fully-powered system. Although the current work is limited to HAR, this can further be extended to many suitable tasks which need to leverage a distributed sensor system for DNN inference. We believe that the co- optimization of deep learning and energy harvesting techniques for edge devices will further invigorate research on the next generations of intelligent and sustainable IoT platforms.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Need for Specialized Hardware:  One of the major chal- lenges in deploying learning tasks using EH-WSNs is to find the proper hardware platform. The current commercial- of-the-shelf (CotS) hardware capable of performing such \nHarvester \nAmbient Energy \nAC-DC Converter Impedance \nMatching \nDC-DC Converter \nController \nPower Management/\n \nConditioning \nEnergy Storage¬†\n \nSensor/ Compute \n(a) High-level overview of an energy harvesting sys- tem. Communicate elsewhere \n0-50 50-500 500-1k 1k-10k > 10k Harvested/available power in the sensor node (¬µW) \nCompute at the edge \nCOTS high-end wearables  (bat.)",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "3. 2. If participating: capturing data at their cho- sen SNR, performing inference, and computing local gradients  ‚àá ‚Ñì ( f Œ∏ k ( x ) , y )  on their locally available samples drawn from  D .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "2: Overview of  360 ¬∞  video projection. Fig. (c) Head movement and pupillary distance as inputs.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "More speciÔ¨Åcally, for each of the Ô¨Åve video inputs (shown in the x-axis in Fig. 9), we compare the compute energy consumption incurred by six schemes with left-eye and right-eye breakdown, and present the respective compute energy in the left y-axis Fig. 9, which is further translated to the total end-to-end energy savings shown in the right y-axis in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Partici- pation during training follows the same equilibrium model: sensors decide whether to compute and send gradients based on their current energy states, predicted future utilities, and the established reward structure. By aggregating these gradi- ent updates over multiple training rounds, the aggregator ap- proximates the gradient  ‚àá J ( Œ∏ )  and performs an SGD step. Our training framework is encapsulated in Algorithm  2 , which outlines the periodic equilibrium-aware training pro- cess.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "These devices are designed to collect energy from their surround- ings‚Äîlight, mechanical vibrations, or heat, respectively. 2. Power Conditioning : Once energy is harvested, it often needs to be converted and stabilized for use.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Seeker  lever- ages the concept of NVP, and employs a flexible store and execute method using the state of the art ReRAM crossbar architecture [ 47 ] to perform inference at the edge. It aug- ments the sensor nodes with two different quantized DNNs (16 bit and 12 bit) to increase the number of completed in- ferences at the sensor node itself. Prior studies [ 56 ,  64 ,  68 ] and our empirical analysis on the quantization vs accuracy trade-offs (see Fig.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "S YSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives. Below, we provide an overview of the RCA interfaces and our system integration model and then discuss the two main steps to map a CNN to ResiRCA:  ofÔ¨Çine compilation  and  runtime execution . A. ResiRCA overview \nFigure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "We conclude this section by outlining some research directions for implementing approximation-based accelerators for AR holograms. 501 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \nTable 2: Salient features of the six videos used in this study. No.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "To address these shortcomings, the advent of layered neural codecs marks a significant advancement (Dasari et al., 2022a). Layered neural codecs, by design, encode video into multiple, distinct layers of data, each enhancing the video quality incrementally. This allows for dynamic adaptation to network fluctuations and client-side computational capabilities, thereby optimizing the streaming experience.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Furthermore, neural codecs offer us the flexibility to approximate the computation (using quantization) to further enhance efficiency. Since they also use the computation blocks of the standard neural network, they can be jointly trained along with the classifier network to perform as the feature extraction and encoding backbone, thereby maximizing the utilization of the inference pipeline, and reducing the computation needed for compression. This  maximizes data and resource reuse , and the pipeline for inference and compression do not diverge from the get going.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Large language models: A survey. arXiv preprint arXiv:2402.06196 , 2024. [108] Asit K Mishra, Xiangyu Dong, Guangyu Sun, Yuan Xie, Narayanan Vijaykrishnan, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "By addressing the challenges of intermittent computing, our work contributes to the broader goal of enabling pervasive, sustainable intelligence at the edge. NExUME is especially advantageous in intermittent environments, and its utility extends to ultra- low-power or energy scavenging systems. Moreover, we believe that advancing the capabilities of smaller models in intermittent environments is crucial for widespread adoption of sustainable, battery-free devices in various domains, including environmental monitoring, industrial IoT, and healthcare.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "[163] Zihao Wang, Bin Cui, and Shaoduo Gan. Squeezeattention: 2d management of kv-cache in llm infer- ence via layer-wise optimal budget, 2024. [164] Wikimedia Foundation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Towards this, we profiled the hologram processing on the edge GPU [ 36 ] using the NVPROF tool [ 37 ], and observed the follow- ing: First, the SM utilization for both the steps is very high, i.e., 74% for  Forward-Propagation  and 90% for  Backward-Propagation . This is because the execution is massively parallel at the depth plane level as well as at the pixel level. Moreover, the L1 hit rate for both these steps is as high as 99%.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Traditional approaches often assume con- tinuous participation of all sensors, which is impractical in energy-constrained environments ( ? ). Some methods pro- pose selecting a subset of sensors based on energy levels or predefined schedules ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Experimental results with six videos show that the combined compression schemes provide 34.0 √ó  speedup compared to a state-of-the-art scheme, with minimal impact on quality and compression ratio. Keywords -point cloud compression; edge computing; video processing; energy-efÔ¨Åciency; \nI. I NTRODUCTION \nAs the world is increasingly becoming virtual and moving closer towards automation, accurate 3D representation of real-life objects in the virtual domain, be it for life-like graphics or efÔ¨Åcient autonomous driving, is becoming es- sential. Recently,  Point Cloud  (PC) consisting of millions of points, which capture the 3D geometry and attributes (e.g.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "[47]  Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R. Das. 2017. Phoenix: A \nConstraint-Aware Scheduler for Heterogeneous Datacenters.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "We also tested this idea in our framework (with YOLOv3 [44] and YOLOv4-tiny [37] as the available models) and set \nthe energy budget for the scheduler to be the total energy consumption resulting from our approach. As can be seen from Table IV, MCDNN yields similar latency/energy savings with our approach, but with signiÔ¨Åcantly lower accuracy ( 36 . Different from the three prior works discussed above, which mainly focus on one model, MCDNN targets a multi-model system and proposes a runtime scheduler to improve the accuracy as much as possible within a limited energy budget.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Apart from the above mentioned optimizations at the layer- level (DeepCache) and the frame-level (Euphrates), recall that, in Table I, we indicated (in the last column) the Decision Making Logic (DM) the previously proposed optimization strategies employ. Hence, our scheme does not lose any accuracy, and still saves  43%  energy. However, due to the static window size employed, Euphrates [9] leads to as much as  6%  accuracy drop in this video segment, which is hardly acceptable by most applications.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "The proposed  HoloAR  on the edge GPU cannot achieve such strict la- tency requirement, and can cause lagging, e.g., the eye could move to another area, while the hologram is still being computed for the previous focus region. We postpone optimizations for such applications to a future work. 5.5 Future Work \nDespite the hardware-agnostic nature of  HoloAR , it is still in- teresting to study how to deploy our idea on an ASIC hardware, and co-design the next-generation accelerator on edge for the AR hologram.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "ISBN 978-1-939133-27-4. URL  https://www.usenix.org/ conference/nsdi22/presentation/dasari . Maureen Daum, Brandon Haynes, Dong He, Amrita Mazumdar, and Magdalena Balazinska.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "0 \n2 \n4 \n6 \n8 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nNormalized Data Volume \nCompute Server VSS Storage Server \n(c) Data Volume. Figure 5: Performance of  Salient Store  on larger compute and storage nodes. 0 \n0.5 \n1 \n1.5 \n2 \n2.5 \n3 \n3.5 \nKittiVision nuScenes CHIME Cityscapes Waymo \nNormazed Compute Latency \nCompute Server VSS Storage Server \n(b) Latency.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "By doing this,  Us. ¬¥as  keeps  both  the student and the teacher models ‚Äúupdated.‚Äù Since the feature space of the teacher model is updated using K-means+, the major computation is the training of the student model using the exemplar data. Although efÔ¨Åcient hardware accelerators [ 16 ], [ 27 ], [ 80 ] have been developed to do the same, these ac- celerators are typically designed with a ‚Äúthroughput-Ô¨Årst‚Äù \n895 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "70 75 80 85 90 \n70 75 80 85 90 \nIter 1 Iter 10 Iter 100 Iter 1000 \nAccuracy % \nUser 1 User 2 User 3 Base Model Fig. 6:  Accuracy over time for different users: the conÔ¨Ådence matrix adapts to the behaviour and activity pattern of the user and learns over time to give stable if not better accuracy. These variations can cause misclassiÔ¨Åcations and the adaptive nature of the conÔ¨Ådence matrix mitigates this.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "The DACs and ADCs are used to convert the digital input and weight signals into analog signals that can be applied to the rows and columns of the x-bar. The shift registers are used to apply the weight signals in a structured way, and the hold capacitors are used to store the analog signals during the multiplication-addition operation. Similarly, for performing convolution, the ReRAM x-bar typically includes additional components, such as delay lines and adders.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Hence, the projection transformation computation has to be executed at every frame to reÔ¨Çect user movements in real-time, and the whole process is very compute intensive (36 times per second [3]) and power hungry. However, it is too conservative to execute the projection transformation in a short period of time even for the same set of inputs. Intuitively, if the inputs of the transformation computation do not change, the output of the transformation will also be same.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "There exists a constant  L >  0 such that for all  Œ∏, Œ∏ ‚Ä≤ , \n‚à•‚àá L ( Œ∏ )  ‚àí‚àá L ( Œ∏ ‚Ä≤ ) ‚à•‚â§ L ‚à• Œ∏  ‚àí Œ∏ ‚Ä≤ ‚à• . This ensures that  L ( Œ∏ )  is Lipschitz-smooth. 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "This conÔ¨Ådence score would further update the weight matrix of the host device using a moving average method and keep updating it as the user keeps using the device. D. Origin: AASR meets ConÔ¨Ådence Matrix Combined together, the activity aware scheduler with recall (AASR) and the adaptive conÔ¨Ådence matrix we present  Origin : a holistic system where an intelligent scheduler meets an adap- tive ensemble learner. This design optimizes the DNN execution in an energy harvesting wireless sensor network by collectively looking into all the involved components.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Thus, depending on the model sub- set used in the ensemble, it achieves better accuracy than the baseline at lower latencies. We observe a similar trend of higher en- semble accuracy for other four baseline models with a latency reduction of up to 1.3 √ó . Even a 10ms reduction in latency is of signiÔ¨Åcant importance to the providers [ 35 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "1: A  360 ¬∞  video processing pipeline on a battery-backed stereoscopic HMD with an Inertial Measurement Unit (IMU) and an SoC equipped with a GPU [28], [39]. II. B ACKGROUND AND  M OTIVATION \nBefore getting into the details of the existing issues and possible solutions, we Ô¨Årst outline the computation pipeline of the state-of-the-art  360 ¬∞ VR streaming (Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Observation 3:  Only-VM based resource procurement should not be used during dynamic load as it leads to over-provisioned resources and increased cost. Cost ($) is shown in right Y-axis. Compute time (seconds) and Memory allocated (GB) is shown on left Y-axis.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "[4] J. Albericio, P. Judd, T. Hetherington, T. Aamodt, N. E. Jerger, and \nA. Moshovos, ‚ÄúCnvlutin: Ineffectual-neuron-free deep neural network computing,‚Äù  ACM SIGARCH Computer Architecture News , vol. 12, p. 123001, 2018. 13, no.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "To explore the search space, we plan to investigate four design choices: what types of chiplets are needed in a chip, how the EoE can be mapped to our chip, how the memory hierarchy can be tailored for a given EoE mapping, and how the chiplets and chips can be interconnected, as illustrated in Figure 6. We can create a chiplet version of each hardware of interest, and use them as plug-and-play mod- ules, while combining them to create a variety of chips. Although datacenters also try to take leverage of the diversity of heterogeneous computing platforms, they are much slower and very expensive during adop- tion [50,104,105].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "1c) on a typical edge prototype [ 36 ] running a set of state-of-the-art AR-related tasks [ 19 ,  26 ,  49 ,  50 , 53 ], and compared the collected results against ideal execution latencies for the same set of tasks (i.e., the maximum latency within which the task needs to finish before its next invocation). 2.2 Motivation \n2.2.1 What is the Major Bottleneck? To identify the major performance bottlenecks in the current AR headsets, we characterized the execution latency of the software pipeline (discussed above in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "1037‚Äì1050. [20]  Y. Feng, B. Tian, T. Xu, P. Whatmough, and Y. Zhu, ‚ÄúMesorasi: Architecture support for point cloud analytics via delayed- aggregation,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2020, pp. 10 766‚Äì10 773.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Optimal Brain Damage Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ≤ . Define the energy budget  E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Each worker VM runs tensorÔ¨Çow-serving [ 60 ] to serve the inference requests. We use  Python Sanic  web-server for commu- nication with the master and worker VMs. Load Balancer : The master VMs runs a separate thread to monitor the importance sampling of all individual model pools.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "[64]  Point Cloud Library Contributors, ‚ÄúPcl gpu octree,‚Äù  ‚Äùhttps: //github.com/PointCloudLibrary/pcl/tree/master/gpu/octree‚Äù , 2022. [65]  C. R. Qi, W. Liu, C. Wu, H. Su, and L. J. Guibas, ‚ÄúFrustum pointnets for 3d object detection from rgb-d data,‚Äù in  Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018. [66]  C. R. Qi, H. Su, K. Mo, and L. J. Guibas, ‚ÄúPointnet: Deep learning on point sets for 3d classiÔ¨Åcation and segmentation,‚Äù in  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 201,
    "augmented": false
  },
  {
    "text": "Thrust-3 examines architectural design space for efficient mapping of experts to hardware leading to a chiplet-based design consisting of a heterogeneous platform of compute engines such as CPUs, GPUs, and accelerators. Thrust-1 is aimed at in- vestigating the algorithmic foundations of our EoE paradigm that consists of an ensemble of experts, which will facilitate application-specific morphable LLMs. For executing these morphable experts on an underly- ing hardware, Thrust-2 focuses on investigating system-level issues in EoE training and inference, focusing in particular on expert scheduling and memory hierarchy management.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "IEEE, 2020. 400‚Äì414. Ali Saffari, Sin Yong Tan, Mohamad Katanbaf, Homagni Saha, Joshua R Smith, and Soumik Sarkar.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "For instance, DeepHolo [ 33 ] proposes a binary-weighted computer- generated hologram model to recognize 3D objects. Furthermore, another convolution neural network (CNN) model is trained and deployed on mobile devices to synthesize a photorealistic colour 3D hologram from a single RGB-depth image in real time [ 54 ]. Apart from neural network techniques, foveated rendering is another promising performance optimization for reducing computational costs [ 2 ,  22 ,  24 ,  25 ,  30 ,  47 ,  62 ], as summarized in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "Oresti Banos, Rafael Garcia, Juan A Holgado-Terriza, Miguel Damas, Hector Pomares, Ignacio Rojas, Alejandro Saez, and Claudia Villalonga. mhealthdroid: a novel framework for agile development of mobile health applications. In  Ambient Assisted Living and Daily Activities: 6th International Work-Conference, IWAAL 2014, Belfast, UK, December 2-5, 2014.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "3  b  , two blocks (a set of points) which are located close to one another are likely to contain similar color pixels. In the example shown in Fig. 7 , the Ô¨Årst frame, I- Frame, contains three points ‚Äì  P 0  with geometry data  [ 0 , 0 , 0 ] and an attribute value  50 ,  P 1  with  [ 12 , 8 , 13 ]  for geometry and 52  for attribute, and  P 2  with  [ 19 , 26 , 58 ]  for geometry and 20  for attribute.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Fig. VSS‚Äôs emphasis on video data optimization makes it a pertinent benchmark for assessing the  Salient Store  storage system‚Äôs capabilities in managing large-scale machine learning data-sets. We first implemented  Salient Store  on a workstation-class machine with two Xilinx CSDs - which colosely mimics the classical edge server setup.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "A case for heterogeneous on-chip inter- connects for cmps. ACM SIGARCH Computer Architecture News , 39(3):389‚Äì400, 2011. [110] Asit K Mishra, Narayanan Vijaykrishnan, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Key takeaway :  The cost-effectiveness of transient instances, is naturally suitable for hosting ensemble models. Fast  Cache \nMobileNet NasNet \nResNet50 DenseNet121 \nDynamic Model  Selection \n. .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "By modeling each sensor as a rational player optimizing its own utility, we can derive participation patterns that are robust against unilateral deviations. In contrast, a game-theoretic framework provides equilib- rium guarantees, ensuring stable and cooperative partici- pation strategies. This stability is crucial for maintaining long-term network per- formance without necessitating continuous recalibration or extensive communication overhead.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "[34]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg. A review on ensembles for the class imbalance problem: Bagging-, boosting-, and hybrid-based ap- proaches. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews) , 42(4):463‚Äì484, 2012.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Deployment Training Completed \nMean Power Consumed (W) \nMean Power \nWasted (W) \nCarbon Footprint (lbs/yr) Us. ¬¥as 11 17.2 3.54 8.33 DaDianNao (persistent) 6 6.4 10.8 128.0712 DaDianNao (Software Only) 4 5.8 12.46 135.964 DaDianNao (actual) 2 2.09 24.73 199.70 Edge Cloud 0 0 ‚Äì Cloud 1 200 0 2233.8 Max Power = 32W; Min Power = 12W; Training Scheduled = 12 \nTABLE IV: Comparing  Us. ¬¥as  hardware with other state of the art offerings for both performance and sustainability.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "Our exploration will focus on various types of router functions to direct user queries to appropriate experts, different expert model architectures, and composition functions to  ag- gregate  expert outputs. These components form the foundation for constructing a ‚Äúmorphable ecosystem of experts‚Äù through dynamic routing and composition. The different methods for each component are summarized in Table 1.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "The Effect of EA:  With this  EA  memoization, once a new head orientation is received, we Ô¨Årst search it in the two head orientation registers. If there is a match, the associated  P buff will return the memory address of the saved  P  so that we can reuse  P  and skip the  entire  coordinate projection computation (refer to  a  in Fig. 4), with only  1%  overhead w.r.t.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "7: Update model parameters: \nŒ∏ k +1  =  Œ∏ k  ‚àí Œ± k   b ‚àá J ( Œ∏ k ) . 8: Broadcast  Œ∏ k +1  to all sensors. 9:  end for \nRegularizers and SGD Convergence: The chosen reg- ularizers  ‚Ñ¶ SNR ( Œ∏ )  and  ‚Ñ¶ complexity ( Œ∏ )  are both convex and smooth, with known closed-form gradients.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "The unit compute (only a 3  √ó  3 convolution per tile) that  Us. ¬¥as  can perform is much smaller than the other accelerators, limiting its throughput but increasing its modularity of handling intermittent power failures (or power changes). Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "315‚Äì327. IEEE, 2020. Attila Reiss and Didier Stricker.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "6.2.2 BeneÔ¨Åts from Autoscaling \nFigure  11  plots the reduction in the number of VMs used by all four schemes. It can be seen that both  Cocktail  and  Clipper-X spawn 49% and 20% fewer VMs than  Clipper  for workload-1 on Twitter trace. Cocktail  spawns 29% lesser VMs on top of Clipper-X , because it is not aggressive enough like  Cocktail to downscale more models at every interval.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Keep in balance: Runtime-reconfigurable intermittent deep inference. ACM Transactions on Embedded Computing Systems , 22(5s):1‚Äì25, 2023. 13 \nA More Results on Other Platforms and EH Sources \nFigure 4: Hardware setup of NExUME using MSP-EXP430FR5994 as the edge compute, Adafruit ItsyBitsy nRF52840 Express for communicating, Energy Harvester Breakout - LTC3588 with super- capacitors as energy rectification and storage and a Pixel-5 phone as the host.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "9, that only 28%  of the compute energy is consumed w.r.t. the  Baseline ( 22%  for the left-eye,  6%  for the right-eye), translating to a  37%  total energy saving. Impact on Quality : The proposed  AE  scheme captures the pattern between both the eyes with only the  1 st  row of the frame, and then uses the same pattern to  bypass  the projection computation for the remaining rows of the right eye.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "For example, as shown in Figure 3, we can split a large expert model into smaller domain-specific models and train them on smaller, focused datasets in corresponding domains. After training, we merge them in the final stage to form a reinforced model. Each expert can also grow to absorb new knowledge and shrink to discard obsolete knowledge.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "With the target of achieving an efficient execution, we first want to understand the execution behavior. Towards this, for each EoE dataflow over varieties of off-the-shelf hardware platforms including general purpose cores, GPUs, and hardware accel- erators like TPU [50] and SN40L [131] among others, we will investigate the performance, compute and memory utilization, accuracy contribution, and power metrics for every single expert to list the key bot- tleneck kernels. Also, we will identify the most common or frequently accessed experts within and across EoEs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "The fickle nature of harvested energy has posed a major chal- lenge in performing any useful computation, as any useful forward progress gets lost when the traditional computing systems lose power. For building scalable and sustainable infrastructure of battery-free EH-WSNs, the former is more feasible and will be our focus for this work. To tackle this, a significant amount of work has been done on check-pointing, and compiler level tweaks, which help maximize the forward progress on such devices [ 39 ,  43 ,  44 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs. We perform cycle-accurate simulation for the MAC computations based on tile activation and the data load/store process. However, for other functional units, we assign a Ô¨Åxed latency.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "IV-B2, the RoIs are essen- tial to the out- put results. Thus, the inner part has to be fully infer- enced. However, it is  not  desirable to execute the infer- ence on the mid- dle part, since, in order to do so, one needs to prepare an input larger than the inner region (due to the various kernel sizes in the convolution, e.g.,  3  √ó  3 ,  5  √ó  5  [38]), which eventually turns out to be the FI.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "[58]  Julian Steil, Inken Hagestedt, Michael Xuelin Huang, and Andreas Bulling. Springer. 8525.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "III. S IMILARITY IN  V IDEO  A PPLICATIONS \nDue to the limited computing resources and the strict power/energy budget constraints [2], enabling high-quality fast inference on mobile devices is very challenging for DNN applications (e.g., object detection for videos). In fact, the inference of VGG-16 [31], which is a popular DNN model, takes 240  ms  to execute on an embedded Adreno 640 [32] GPU, which is far from  real-time .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "2019. Data-independent neural pruning via coresets. arXiv preprint arXiv:1907.04018  (2019).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "(Accessed on 11/13/2023). Debendra Das Sharma. Compute express link (cxl): Enabling heterogeneous data-centric computing with heterogeneous memory hierarchy.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "[6] Alibaba, ‚ÄúMNN: Mobile Neural Network,‚Äù ‚Äùhttps://github.com/alibaba/ MNN‚Äù, 2019. [7] S. Han, H. Shen, M. Philipose, S. Agarwal, A. Wolman, and A. Krishna- murthy, ‚ÄúMcdnn: An approximation-based execution framework for deep stream processing under resource constraints,‚Äù in  Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services , 2016, p. 123‚Äì136. [8] M. Xu, M. Zhu, Y. Liu, F. X. Lin, and X. Liu, ‚ÄúDeepCache: Principled Cache for Mobile Deep Vision,‚Äù in  Proceedings of the Annual Interna- tional Conference on Mobile Computing and Networking (MobiCom) , 2018, p. 129‚Äì144.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 211,
    "augmented": false
  },
  {
    "text": "[15]  R. L. de Queiroz and P. A. Chou, ‚ÄúMotion-compensated compression of dynamic voxelized point clouds,‚Äù  IEEE Transactions on Image Processing , vol. 26, no. 8, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "[30]  Xiaoxu Meng, Ruofei Du, and Amitabh Varshney. Eye-dominance-guided Foveated Rendering. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "[63]  Heyang Qin, Syed Zawad, Yanqi Zhou, Lei Yang, Dongfang Zhao, and Feng Yan. Swift machine learning model serving scheduling: a region \nbased reinforcement learning approach. In  Advances in neural information processing systems , pages 8026‚Äì8037, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "We denote this design combination as  EA+AE . ‚Ä¢  EA+AE  (SW) : The above two designs can be seamlessly integrated into the original SoC, with the  EA  block placed before the GPU and the  AE  block after the GPU. 7.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "TABLE I A N EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT - CYCLE POWER TRACE . Power cycle \nHarv. Power ( ¬µ W) \nPower consumption with full-size acti.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "In this section, we Ô¨Årst describe the experimental platforms, datasets and measurement tools used in this study. V. E VALUATION \nWe compare our proposed  EA  and  AE  designs with six different VR streaming setups, by evaluating the computation and the total energy consumption. We then analyze the results measured using these platforms.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": ", m n ]  where  m i  ‚àà{ 0 ,  1 } . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Taylor Expansion Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œª .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "Notably,  Kraken  spawns nearly 80% less containers for  Social Network  in comparison to  Arch . Kraken  is seen to reduce con- tainer overprovisioning when applications have numerous possible workflows and enough slack per function to exploit. Container overprovisioning is inflated 15% more than the corresponding real system re- sult, due to the large-scale traces.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "1184‚Äì1188. [22] E. Dong, Y. Zhu, Y. Ji, and S. Du, ‚ÄúAn improved convolution neural \network for object detection using yolov2,‚Äù in  2018 IEEE International Conference on Mechatronics and Automation (ICMA) . IEEE, 2018, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Wearing a head mounted display (HMD), a user navigates in a virtual world by  looking around , or  moving around  [55], to interact with the virtual world. 360 ¬∞  Video Streaming Pipeline \nThe key  difference  between a  360 ¬∞ VR video compared to a conventional 2D video is that the former provides content-rich immersive user experience. As shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "360 ¬∞ video streaming creates an interactive and immersive environment by connecting the user and the video content; the users are allowed to move their heads‚Äô orientation to enjoy the surroundings in all perspectives along with a 3D view, i.e., a different view for each of the eyes, and hence creating an illusion that the user is present at the scene rather than viewing it on a projected surface. This immersive experience comes at the cost of additional computations - not only is the video being streamed,  the streaming itself changes with the head orientation. Moreover, streaming requires two projections for both the eyes.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "Our modular, plug-and-play based approach not only allows for targeted research within individual elements of the en- semble, but also supports contributions from the broader research community. The concept of an ‚Äúensemble‚Äù serves as a foundational element, uniting our diverse research thrusts: a comprehensive set of models, a suite of accelerators, and an array of simulation and evaluation frameworks. Finally, Thrust-4 is devoted to developing a comprehensive empirical evaluation platform consisting of a simulator and analytical tools to evaluate and validate our design in terms of performance, energy efficiency, and model accuracy.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "The cluster centers for each data ( Œº y  for class  y ) are calculated as  Œº y  =   1 \nP y   ‚àë p ‚àà P y   Œ¶ ( p ) , where  P y  is the number of samples belonging to class (or cluster  y ), and  Œ¶  is the feature extraction function working on the data  p . In the original training phase, these feature vectors are separated using K-means [ 74 ] or other clustering. These clusters represent the classes in the high dimensional feature space.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "Comparing Energy Efficiency of CPU, GPU and FPGA Implementations for Vision Kernels. In  15th IEEE International Conference on Embedded Software and Systems . 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "[3] Exploring llms - real-world case studies in ai-generated art & literature. https://www. tome01.com/exploring-llms-real-world-case-studies-in-ai-generated-art- literature , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "An alternate solution would be to restart the queries in running instances but that leads to increased latencies for the 1% requests. In contrast,  Cocktail  incurs a modest accuracy loss of well within 0.6% and quickly adapts to reach the target accuracy. Thus,  Cocktail  is inherently fault-tolerant owing to the parallel nature in computing multiple inferences for a single request.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "31, no. 1, 2017. [35] Z. Jackson, ‚ÄúFree spoken digit dataset (fsdd),‚Äù https://github.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "However, these approaches often assume some level of reliability or do not fully integrate energy harvesting dynamics into the learning process. 2.5. Multi-View Learning and Collaborative Inference \nMulti-view learning leverages multiple sources or perspec- tives to improve learning performance ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "This effect is more obvious in the edge-peer structure since it will send the data to its nearest peer and check the prediction quality until it reaches the cloud. Figure 4b also shows how network structure amplifies the effect of changing threshold value. Therefore, it is important to choose a threshold that optimizes the trade off between efficiency and accuracy.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "[38]  Anup Mohan, Harshad Sane, Kshitij Doshi, Saikrishna Edupuganti, Naren Nayak, and Vadim Sukhomlinov. IEEE, 154‚Äì161. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "[10]  2020. Microsoft Azure Serverless Functions. https://azure.microsoft.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 21,
    "augmented": false
  },
  {
    "text": "5.5 Future Work \nDespite the hardware-agnostic nature of  HoloAR , it is still in- teresting to study how to deploy our idea on an ASIC hardware, and co-design the next-generation accelerator on edge for the AR hologram. Towards this, we plan to explore three critical questions in our future work: First, how many processing units (PUs) are required and just sufficient for most of the cases in a typical AR holographic application? To answer this, we plan to characterize the number of depth planes needed in various AR applications, and guide the optimal design choices (i.e., number of PUs, frequency, input and output buffer size, etc.)",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "time \n0% \n20% \n40% \n60% \n80% \n(c) FI+SI+PI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead Partial \n(d) FI+SI+PI exec. time \nFig. 8: Performance and energy improvements for YOLOv3 w.r.t.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "517‚Äì531, New York, NY, USA, 2017. Race-to-sleep + content caching + display caching: a recipe for energy-efficient video streaming on handhelds. In  Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture , MICRO-50 ‚Äô17, pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Serverless function chains are formed by stitching together various individual serverless functions using some form of synchronization to provide the func- tionality of a full-fledged application. Function chains are supported in commercial serverless platforms such as AWS Step Functions [4, 23], IBM Cloud Functions [8], and Azure Durable functions [ 6 ]. 2.1 Serverless Function Chains (DAGs) Many applications are modeled as function chains and typically administered under strict SLOs (hundreds of mil- liseconds) [ 30 ].",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "1) How to Increase Parallelism? : Fig. 5  shows an example of geometry compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "If a match is detected, then the corresponding  P i ‚àí 2 buff   or  P i ‚àí 2 buff   buffer address pointer is directly returned. If no match is found, the OCE is invoked for the entire left eye and only the Ô¨Årst row for the right eye, and then terminates by an external signal sent from our  AE  block, and bypasses the computation for rest rows. In the proposed AE  design, the  Œî  pattern buffer is Ô¨Årst initialized by subtract- ing  Result [1] .R  from  Result [1] .L , as shown in the  AE  block in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Dodge, T. Prewitt, R. Tachet des Combes, E. Odmark, R. Schwartz, \nE. Strubell, A. S. Luccioni, N. A. Smith, N. DeCario, and W. Buchanan, ‚ÄúMeasuring the carbon intensity of ai in cloud instances,‚Äù in  2022 ACM Conference on Fairness, Accountability, and Transparency , 2022, pp. [22] E. Dong, Y. Zhu, Y. Ji, and S. Du, ‚ÄúAn improved convolution neural \network for object detection using yolov2,‚Äù in  2018 IEEE International Conference on Mechatronics and Automation (ICMA) . 1877‚Äì1894.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 176,
    "augmented": true
  },
  {
    "text": "Cloud programming sim- plified: A berkeley view on serverless computing. arXiv preprint arXiv:1902.03383  (2019). [34]  Ram Srivatsa Kannan, Lavanya Subramanian, Ashwin Raju, Jeongseob Ahn, Jason Mars, and Lingjia Tang.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "2 Background and Motivation \n2.1 Storage for Continuous Learning Edge Servers \nRecent developments in continuous learning for video analytics (Bhardwaj et al., 2022; Mishra et al., 2024; Kim et al., 2024) has significantly boosted the capabilities and accuracy of learning systems. The major focus of these works have been building compute platforms with efficient scheduling (Bhardwaj et al., 2022; Mishra et al., 2024), and reconfigurable hardware design (Kim et al., 2024; Mishra et al., 2024). This solves majority of the bottlenecks in a performance-driven classical cloud server platform.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 165,
    "augmented": false
  },
  {
    "text": "ZED Software Development Kit. \"https://www.stereolabs.com/developers/release/\". [60]  techradar.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "The chain structure connects experts in a sequential manner, ideal for tasks requiring a series of expert skills; the tree struc- ture models a type-subtype hierarchy; and the graph structure enables complex expert communication and collaboration. Each morphology is described in detail below: Modeling Diverse Expert Types with Chain Ensemble-of-Experts. Experts can be classified via a set of diverse criteria  a , such as domain, skills, and languages.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Andreas Geiger, Philip Lenz, and Raquel Urtasun. IEEE, 2015. Are we ready for autonomous driving?",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "In  NSDI . [23]  Jyothi Prasad Buddha and Reshma Beesetty. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "199‚Äì204. [4] Discovery, ‚ÄúCaring for Rhinos: Discovery VR (360 Video).‚Äù ‚Äùhttps:// www.youtube.com/watch?v=7IWp875pCxQ‚Äù, 2019. [5] Discovery, ‚ÄúElephants on the Brink.‚Äù ‚Äùhttps://www.youtube.com/watch?",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Cocktail‚Äôs  autoscaling policy strikes parallels with Swayam‚Äôs distributed autoscaling; however, we further incorporate novel importance sampling techniques to reduce over-provisioning for under-used models. Table  2  provides a comprehensive comparison of  Cocktail with the most relevant works across key dimensions. 2.3 Pros and Cons of Model Ensembling \nIn this section, we quantitatively evaluate (i) how effective ensembles are in terms of accuracy and latency compared to single models, and (ii) the challenges in deploying en- semble frameworks in a cost-effective fashion on a public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2007.03051 , 2020. [15] Apache Software Foundation. Apache¬Æ Subversion¬Æ.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "t . P  ‚â§ P av . Energy Buffering and Power-Predictor:  To regulate, manage and ensure a stable power supply to the circuitry,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "the state-of-the-art techniques ( 1 . 55 s latency in prior works vs.  42 ms latency in ours). To better understand where the beneÔ¨Åt comes from, next we go over a simple example, given in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "2. Data and Metadata Standards \nThe workload characterization and experimental data will be compressed and made available to interested parties in a compressed format. The compiler and system software code and other design artifacts will be maintained in both source formats (e.g., C/C++/C#/Python files) as well as in binary, in an open-source fashion.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "4.3) and found to work well (in Sec. 5) as in prior works [ 22 ,  25 ,  30 ,  47 ]. In this paper, we have gone be- yond foveated rendering ( Inter-Holo ), by proposing an optimiza- tion/approximation called  Intra-Holo , that complements the for- mer in boosting performance/energy efficiency.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "ResiRCA architecture overview \nto the network. The RCA is powered by harvesting ambient energy and employs a separate, very small capacitor as its only energy storage medium, primarily for power smoothing, similar to prior energy-harvesting NVP designs [ 17 ], [ 21 ], rather than as a task-scaled energy reservoir [ 22 ]. Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input/output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "In contrast, our work prioritizes the integration of this dynamism in both the network architecture search (NAS) and the training phases, adapting more effectively to fluctuating energy and compute conditions. Essentially, the DNN is trained to manage within a static resource budget, ignoring the ‚Äúdynamism‚Äù of the resources . 3 NExUME Framework \nTo address the issues with  intermittency-aware  DNN training and inference, we propose NExUME: ( N eural  Ex ecution  U nder Inter M ittent  E nvironments).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "5: Overall architecture with the components and the power failure handle sequence of  Us. ¬¥as  introduces a design philosophy for building a morphable hardware, and it can easily be adapted by any of the systolic array based commercial off the shelf (or research prototype) DNN training accelerators. DNN Compute Mapping:  Typically there are three ways of mapping DNN compute into a systolic array, namely, 1. output \nDRAM \nRepresntation Learning \nMicro-profiler \nActivation \nNormalize & Pooling \nHost \nPower Predictor  Examplar \nGlobal Scratch-pad \nDouble Buffered IF Map \nDouble Buffered Filter \nSTT-RAM S \nSTT-RAM N \nNVSB-SE \nNVSB-NW \nDouble Buffered \nOF Map \nP-SUM \nW \nArbiter \n2xNVSB \nP- MUX \nTile-Q \nPE-Block \nSouth Control \nMaster \nNorth \nControl \n(a) High-level arch \no-Path De-Mux \n4x4 STiles w/ 8x8 SA each 128 cycles \n(64 x16)x 16bits Results \nPower off Warning from \nPredictor \nNext \nTile \nTo arbiter \n& Fabric \nclk \nw-pdown \nstate on pwr warning (>256 cycles) off \nbackup \ndat Compute \npath tile arbiter & fabric \nfab-state \n!pdown \n4kB NVSB \nNext STile \n128 Cycles \nFilter \ni-Path mux \nFrom IF or NVSB of failed PE  \ni-Path mux \nPrev STile Next STile \nWork-Q \nLogic \nOutput \nFilter \n8x8 Priority \nMux \n512B NVSB if FULL \nWr-Q \n(b) Power-down/ Failure handling \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 403,
    "augmented": true
  },
  {
    "text": "After the pattern between left eye and right eye is captured, an external signal is propagated to the OCE to bypass the further original projection computations. Consequently, the projection computation results ( Result [2 :  n ] .R ) for the remaining rows of the right eye can be easily reconstructed by adding  Result [2 :  n ] .L  and the  Œî . We prototyped our proposed  EA  and  AE  design blocks using System Verilog in Xilinx Vivado 2019.2 [58], targeting the Xil- \ninx Zynq-7000 SoC ZC706 board running at 100MHz (same as state-of-the-art EVR [28]).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 166,
    "augmented": false
  },
  {
    "text": "For certain cases like climbing in PAMAP2, and running in MHEALTH,  Origin  is more accurate than Baseline-1. These accuracy improvements can be attributed to  Origin‚Äôs  use of a conÔ¨Ådence matrix in classiÔ¨Åcation, as opposed to the baseline models, which only perform majority voting based ensembling. Note that both the baselines are running on a fully powered system whereas  Origin runs entirely on harvested energy.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Here, we assume that the octree for these points has already been established using the geometry pipeline, and we next go through our proposed attribute pipeline step by step and explain where the envisioned beneÔ¨Åts will come from. 1) How to Speedup? : First, RAHT [ 14 ] takes the initial octree (which is deepest now) as input, and invokes  RAHT and Quantization  to perform the linear transformation on the leaves with their siblings along the x, y and z dimensions, and shrinks the tree layer-by-layer.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "[56] B. Worldwide, ‚ÄúNYC 360 Timelapse.‚Äù ‚Äùhttps://www.youtube.com/ watch?v=CIw8R8thnm8‚Äù, 2019. [57] C. Xie, X. Zhang, A. Li, X. Fu, and S. Song, ‚ÄúPIM-VR: Erasing Motion Anomalies In Highly-Interactive Virtual Reality World with Customized Memory Cube,‚Äù in  Proceedings of the International Symposium on High- Performance Computer Architecture (HPCA) , 2019, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "Specifically,  Seeker  reaches 86.8% top-1 accuracy in com- parison to the 81.2% accuracy of the baseline system. Our evalu- ations show that, even when powered by an unreliable EH source,  Seeker ‚Äôs coreset-based optimizations result in bet- ter accuracy than that of a fully-powered system running a state-of-the-art classifier optimized for energy efficiency. ‚Ä¢  Detailed Evaluation:  We provide a detailed evaluation of our system and the proposed hardware design.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "However, accuracy being a Ô¨Çoating point number, is expensive in terms of energy to store and lookup. To minimize this overhead, instead of storing the accuracy, we store the rank of the sensors for individual activities. After a sensor detects an activity, it anticipates the next activity to be the current classiÔ¨Åed activity, looks up for the best sensor, and signals to activate it for the upcoming inference.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "International Telecommunication Union, June 2019b. URL https://www.itu.int/rec/T-REC-H.265 . ITU-T Recommendation H.265.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Clearly, TMC13 and CWIPC are two of the most energy-consuming schemes, which consume  11 . 3 J  and  19 . 8 J , respectively, for one PC frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "These student models, thanks to their lack of robustness (which is often, but not always, related to the smaller footprint they have, and thereby lacking the parameter space to generalize better), are susceptible to data drift and hence are continuously retrained. or by developing an application speciÔ¨Åc model from scratch along with the said optimizations. However, the teacher models are typically large, and with a wide parameter space can generalize the learning process better than the students.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Studying inter-core data reuse in multi- cores. ACM SIGMETRICS Performance Evaluation Review , 39(1):25‚Äì36, 2011. [186] Yusen Zhang, Ansong Ni, Ziming Mao, Chen Henry Wu, Chenguang Zhu, Budhaditya Deb, Ahmed Awadallah, Dragomir Radev, and Rui Zhang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "[24] A. Geiger, P. Lenz, and R. Urtasun, ‚ÄúAre we ready for autonomous \ndriving? the kitti vision benchmark suite,‚Äù in  2012 IEEE conference on computer vision and pattern recognition . IEEE, 2012, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "However, due to this reduced accuracy, the sensor only takes this option iff it does not have enough energy to perform the inference at the edge device (either in the 16bit or 12bit variant of the DNN - more details on DNN design is presented in Sec- tion 4). This problem has not been explored in details, as coresets are typically considered as an  ùõº ‚àí approximate representation of the data ( ùõº being the error/approximation parameter) [ 7 ] and never needed proper recovery. This raises a question:  is it possible to generate a more useful  approximation, via reconstruction, of the data that we lost while forming the coresets?",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "Specifically, leveraging the observed pat- terns of expert reuse (‚Äúhotness‚Äù patterns) at different locations in the EoE , our system can intelligently predict and load the experts likely needed in subsequent layers to the main memory. Since this method also reduces the data movements in the system, we can expect a significant reduction in energy consumption. Ad- ditionally, we will identify hot and cold ‚Äúpaths‚Äù and use this infor- mation in  prefetching  the experts and routers (which are actually spe- cialized experts) into the higher levels of the memory hierarchy, close to compute units (note that this is an example use of expert-expert and expert-router affinities).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.‚Äù \nThe above statement can be used verbatim in such cases, but we encourage authors to think about whether there is content which does warrant further discussion, as this statement will be apparent if the paper is later flagged for ethics review. Guidelines for Hyperparameter Selection and Bounds on Reward Parameters \nThe parameters  Œ≥ ,  Œ¥,  and  Œ∑  govern the reward structure of the proposed framework, influencing whether sensors participate consistently, over-participate and waste energy, or abstain altogether. References \nA.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "Spotweb: Running latency-sensitive distributed web services on transient cloud servers. In  Proceedings of the 28th Inter- national Symposium on High-Performance Parallel and Distributed Computing , pages 1‚Äì12, 2019. [4]  Amazon.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "This data-set, consisting of audio recordings, offers a different modality to test the versatility of Salient Store  in handling various types of continuous learning data beyond visual inputs. In our comparative analysis, we employ  VSS: A Video Storage System  (Haynes et al., 2021) as a ‚Äúbaseline‚Äù, given its innovative approach in optimizing video data management. VSS excels in decoupling high-level video operations from storage and retrieval processes, efficiently organizing data on disk, enhancing caching mechanisms, and reducing redundancies in multi-camera setups (Haynes et al., 2021).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Define the energy budget  E b  for a single quanta and for the entire inference. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Neuron Shapley Value Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ¥ . Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "ResiSchedule power efÔ¨Åciency analysis \nD. Transition efÔ¨Åciency Table  VI-D  shows the ratio of inferences using smooth- transitioned partial results and total inference count number. 10. 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 \n0 0.10.20.30.40.50.60.70.80.9 1 \nPower Utilization \nPower efficiency \nPiezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "Privacy-Aware Eye Tracking Using Differential Privacy. In  Proc. ACM Interna- tional Symposium on Eye Tracking Research and Applications (ETRA) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "1081 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "c) An example of macro blocks segmented using Morton codes in two frames. pixels) within one frame, as well as temporal locality (similar pixel values in corresponding locations across consecutive frames) [ 36 ]. This observation motivates us to ask the question:  Do such similarities also exist in the PC streams?",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "S√∂ren Becker, Johanna Vielhaben, Marcel Ackermann, Klaus-Robert M√ºller, Sebastian Lapuschkin, and Wojciech Samek. Audiomnist: Exploring explainable artificial intelligence for audio analysis on a simple benchmark. Journal of the Franklin Institute , 2023.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Training Objective and Regularization: To enhance ro- bustness and efficiency, we incorporate regularizers that pe- nalize undesirable model properties. By aligning update events with periods when sensors are most likely to participate meaningfully, we ensure that the global model is refined efficiently without imposing excessive en- ergy demands on the sensors. Specifically, we intro- duce two regularizers:  (1)  ‚Ñ¶ SNR ( Œ∏ ) : Encourages the model to maintain performance across varying SNR levels, pre- venting over-reliance on high-SNR data.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "‚Ä¢  We go beyond the compute and look into future-proofing the storage server by equipping it with quantum safe lattice-based encryption technique. We detail the design of the hardware accelerated encryption and maximize the resource reuse between the exemplar selection and encryption. We maximize the hardware utilization by reusing compute kernels from the compression pipeline.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "IEEE, 2020. 25‚Äì32. In  2020 IEEE International Conference on Smart Computing (SMARTCOMP) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "Mikl√≥s Ajtai. Generating hard instances of lattice problems. In  Proceedings of the twenty-eighth annual ACM symposium on Theory of computing , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "), we now turn to the second question raised above ‚Äì how to maintain accuracy? ‚Äì and study the layers in DNN to explore how to identify which parts are important and which are not. 3) How to Maintain Accuracy?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "2021. Efficient Volu- metric Video Streaming Through Super Resolution. In  Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "Design conÔ¨Ågurations \nBaseline:  We evaluate the baseline video object detection on an edge CPU 1 , where every frame is fully inferenced. FI+SI:  We evaluate our FI+SI scheme that skips the inference by utilizing MVs, as discussed in Sec. IV-A.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "6.3.3 Sensitivity to Constraints \nFigure  14  plots the sensitivity of model selection policy un- der a wide-range of latency and accuracy constraints. In Figure  14a , we vary the latency under six different constant accuracy categories. It can be seen that for Ô¨Åxed accuracy of 72%, 78% and 80%, the average number of models increase with increase in latency, but drops to 1 for the highest latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Exploring fault-tolerant network-on-chip architectures. In  International Conference on Dependable Systems and Networks (DSN‚Äô06) , pages 93‚Äì104. IEEE, 2006.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "[44] J. Redmon and A. Farhadi, ‚ÄúYOLOv3: An Incremental Improvement,‚Äù CoRR , 2018. [45] B.-G. Han, J.-G. Lee, K.-T. Lim, and D.-H. Choi, ‚ÄúDesign of a Scalable and Fast YOLO for Edge-Computing Devices,‚Äù  Sensors , 2020. [43] Y. Xu, X. Liu, L. Qin, and S.-C. Zhu, ‚ÄúCross-View People Tracking by Scene-Centered Spatio-Temporal Parsing,‚Äù in  Proceedings of the Thirty- First AAAI Conference on ArtiÔ¨Åcial Intelligence , 2017, p. 4299‚Äì4305.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 178,
    "augmented": true
  },
  {
    "text": "These partnerships will also provide external insights to the project, and in particular, our collaboration with ANL enable us to access a large number and variety of compute platforms (including those with accelerators). Project Website \nA website will be maintained for the project. This website will have both ‚Äúexternal‚Äù and ‚Äúinternal‚Äù inter- faces.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Advances in Neural Information Processing Systems , 35:7103‚Äì7114, 2022. Mixture-of-experts with expert choice routing. [197] Yanqi Zhou, Tao Lei, Hanxiao Liu, Nan Du, Yanping Huang, Vincent Zhao, Andrew Dai, Zhifeng Chen, Quoc Le, and James Laudon.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "We collected over 700,000 samples over a period of 2 hours for each of the sensors. The sensor data were cleaned, normalized, and converted to the power spectrum density for further analysis. We use iNAS (Mendis et al., 2021) to find the DNNs meeting the energy income and train them using our proposed DynFit.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "[2] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub KoneÀácn`y, Stefano Mazzocchi, Brendan McMahan, et al. Towards federated learning at scale: System design. Proceedings of Machine Learning and Systems , 1:374‚Äì 388, 2019.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "‚Ä¢  The results of  ResiSchedule  are very close or equal to that of  Sequential  under most cases. When we track the simulation cycles, it is found that the throughput of  Sequential  solution \nResiSchedule \nPiezo WiFi-home WiFi-office Thermal TV-RF \nFig. 8.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "At runtime, each time when entering a new power cycle, we Ô¨Årst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level. Then, the execution process the ‚Äú data loading ‚Üí Mac computing ‚Üí data storing ‚Äù steps in a sequential way to perform convolution operations. The hardware design details will be presented in Section V. \nIV.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Note that since the other option ‚Äì first  Intra-Holo , then  Inter-Holo  ‚Äì is theoreti- cally identical to the proposed  Inter-Intra-Holo , we skip its detailed discussion due to space limitation. 4.5 Design and Implementation \nOptimization Choices:  Our main goal in this paper is to reduce the amount of hologram computation by appropriate approxima- tion, in order to speed up hologram processing, to satisfy the real- time requirement as well as to reduce the energy consumption and prolong the battery life of the AR device, while maintaining the QoS. Our proposal is fundamentally different from prior optimizations targeting various architectures or execution environments, such as customized hardware accelerators [ 35 ], cloud assistance [ 16 ,  27 ,  67 ], or neural network training/inferencing [ 33 ,  54 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 192,
    "augmented": false
  },
  {
    "text": "‚Ä¢  T 4 , also known as the  perspective transformation  ma- trix, maps all  360 ¬∞ coordinates onto 2D coordinates. This transformation depends only on the HMD characteristics, including, but not limited to, the display size and resolution, and hence, is known apriori (at design-time). ‚Ä¢  T 5 , the last transformation to be applied, performs a view- port transformation 5 , bringing the projected points to the coordinates used to index the pixels on the HMD.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "4 DESIGN IMPLEMENTATION OF  SEEKER \nBy leveraging the coreset construction techniques discussed in Section 3, we design  Seeker: A synergistic sensor host ecosys- tem . Figure 5 gives a pictorial representation of the overall design of  Seeker  and its various components. Seeker  lever- ages the concept of NVP, and employs a flexible store and execute method using the state of the art ReRAM crossbar architecture [ 47 ] to perform inference at the edge.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "In this scheme, one can observe from Fig. 9 that, the compute consumes less energy than the  Baseline , i.e., only  72%  on average. This occurs as a result of reusing the memoized results which have been computed and stored previously, ranging from 21 .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Image and video compression with neural networks: A review. arXiv preprint arXiv:2112.09691 , 2021. Siwei Ma, Xinfeng Zhang, Chuanmin Jia, Zhenghui Zhao, Shiqi Wang, and Shanshe Wang.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Large language models in healthcare: Breakthroughs, use cases, and challenges. Shaip , 2024. [143] Akbar Sharifi, Emre Kultursay, Mahmut Kandemir, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Since the clustering based coreset is typically more accurate then those formed by importance sampling, the former is pre- ferred, when possible. With the help of an activity-aware and recoverable coreset construction and low-power hardware design, we can effi- ciently communicate inferences or compressed data to the host device with minimum power and latency overheads. We increase the frequency of cluster- based formation by using custom, energy efficient hardware.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Perform the forward pass with the updated dropout mask to obtain the output  Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the L2 norm of the weights, along with the QuantaTask optimization to handle energy constraints. D.2 Optimal Brain Damage Dropout with QuantaTask Optimization \nOptimal Brain Damage Dropout leverages a simplified version of the Optimal Brain Damage pruning method to adjust dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "While some of these applications rely on collecting the video data and processing them offline, many need real-time analytics for the seamless integration, operation and effectiveness of the task at hand (Bramberger et al., 2004; Apostolo et al., 2022; Grulich & Nawab, 2018). 1 Introduction \nVideo analytics, powered by deep neural networks (DNNs) has become the key component of multiple applications including but not limited to autonomous driving (Brown et al., 2023; Fang et al., 2023; Huang et al., 2023), urban mobility (Corporation; Custom On-Device ML Models with Learn2Compress), surveillance and monitoring (Bozcan & Kayacan, 2020; Dutta & Ekenna, 2019; Pichierri et al., 2023), video streaming and conferencing (Dasari et al., 2022b; Cheng et al., 2024; Sivaraman et al., 2024), telemedicine (Wan et al., 2020), and tourism (Zhu et al., 2024; Pierdicca et al., 2021; Godovykh et al., 2022). This paper pro- vides a comprehensive overview of the potential of CSDs to revolutionize storage, making them not just data repositories but active participants in the computational process.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 334,
    "augmented": true
  },
  {
    "text": "changes. The micro-proÔ¨Åler optimizes the weighted accuracy ( A w  = \nW i \nA i   / ‚àë W i ; ‚àÄ i  ‚â§ # models ; W i  =  f ( time , dri ft , compute )  with a user-deÔ¨Åned slack value of  Œ¥ ), with respect to available power ( P av ): max A w ;  s . t .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "This discounting ensures diminish- ing returns for postponing beneficial participation or indefi- nitely waiting for ideal conditions. As a result, sensors do not continually defer improvements, preventing complex long-term cycles. 9 \n495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 \nBecause the best-response process eliminates profitable de- viations step by step and cannot cycle indefinitely, the action profile sequence generated by iterative best responses con- verges to the NE.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 209,
    "augmented": false
  },
  {
    "text": "GPU instances are cost-effective when packed with a large batch of requests for execution. Hence, inspired from prior work [ 27 , 86 ], we de- sign an adaptive packing policy such that it takes into account the number of requests to schedule at time  T  and  P f  for every instance. The requests are sent to GPU instances only if the load matches the  P f  of the instance.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "[91] Feihui Li, Chrysostomos Nicopoulos, Thomas Richardson, Yuan Xie, Vijaykrishnan Narayanan, and Mahmut Kandemir. Design and management of 3d chip multiprocessors using network-in-memory. ACM SIGARCH Computer Architecture News , 34(2):130‚Äì141, 2006.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "0 25 50 75 100 \nMN-BL \nTeacher \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-BL \nTeacher \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nNa√Øve w/Exemplar \nAccuracy in % \nHour-0 Hour-2 Hour-4 Hour-6 Hour-8 \nFig. 7: Accuracy boost due to proper exemplar selection over 8 hours of time window. Labels: MN ‚Äì MobileNet-V2, BL ‚Äì Baseline, Teacher ‚Äì the ensemble of teacher models, MN‚Äì#: targeted MobileNet-V2 model for the particular time of day.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Samsung Newsroom. Samsung electronics develops second-generation smartssd computational storage drive with upgraded processing functionality. https://bit.ly/3PXwecP .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "2. If sensors rarely par- ticipate, increase  Œ≥  or decrease  Œ∑ . Iterative Refinement:  Use simulation or small-scale ex- perimental runs to refine parameters.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "The reason behind this is that, as shown earlier in Tab. 2, the  bike  video usually has only one object per frame (1 . 1 on average), and also the ranges/sizes of the bikes are larger, compared to others.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Al- though DNN inference is highly structured and embarrassingly parallel, the limited resources on the mobile devices, alongside \nthe required off-chip data movements, poses a signiÔ¨Åcant challenge leading to higher latency. Several hardware-based approaches such as NPUs [24] or ASICs [25], [26] have been proposed to speedup the inference; however, they only work on a narrow set of speciÔ¨Åc applications and/or platforms. 2) Model Compression and Pruning:  To make DNNs mo- bile friendly, there have been several works in compressing and pruning large models.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Amidst the myriad of data-driven domains, urban mobility, smart cities, autonomous driving, and the Internet of Things (IoT) emerge as some of the most rapidly expanding Ô¨Åelds contributing to the global economy, amounting to more than 4 trillion US dollars [ 1 ], [ 54 ], [ 76 ], [ 98 ]. These statistics underscore the profound signiÔ¨Åcance and transformative potential of these data-driven realms, delineat- ing their pivotal role in shaping the landscape of computing technology, from algorithms to architecture. What distinguishes these data is their diverse origin, span- ning from IoT devices to wearables, and their acquisition from challenging environments, including autonomous driving and urban mobility scenarios.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "90% of the time the inference could not start because of lack of energy. 0 20 40 60 80 100 Succeed Failed \n72% 28% \n(b)  Inference completion breakdown when three EH sensors are working in round robin fashion, where one of the sensors performs inference while the other two are accumulating energy. 28% of the time the sensors could Ô¨Ånish the inference, while 72% of the time the inference failed as the sensor could not harvest enough energy while not performing any inference.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "[27] S. M. LaValle, ‚ÄúThe Geometry of Virtual Worlds.‚Äù ‚Äùhttp://msl.cs.uiuc. [26] B. C. Kim and C. E. Rhee, ‚ÄúCompression EfÔ¨Åciency Evaluation for Virtual Reality Videos by Projection Scheme,‚Äù  IEIE Transactions on Smart Processing & Computing , pp. 102‚Äì108, 2017.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "In our exper- iments we configure the memory allocation to the lambda function such that individual query latency is within the user-specified latency constraint. We conducted character- ization experiments on AWS Lambda, currently the most predominant serverless function provider, to study the mem- ory allocated vs computation time trade-off. Figure  7  shows the computation time and cost for executing 1 million infer- ence queries for three different model types with different memory allocations.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "1027‚Äì1035, 2007. Bahman Bahmani, Benjamin Moseley, Andrea Vattani, Ravi Kumar, and Sergei Vassilvitskii. Scalable k-means++.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "b  If exploiting the  EA  opportunity is not possible, we take advantage of the  AE  opportunity, by performing computation for only one eye (and construct the result for the other eye). C. InterFrame-IntraEye (EA) Computation Optimization \nWe plan to leverage the  EA  opportunity when the user‚Äôs head orientation does not change. Intuitively, as mentioned earlier in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "The initial conÔ¨Ådence matrix, derived from the test cases, would be programmed into the host device. Further, after each successful classiÔ¨Åcation, the sensors would send the conÔ¨Ådence score for that classiÔ¨Åer along with the output class. This conÔ¨Ådence score would further update the weight matrix of the host device using a moving average method and keep updating it as the user keeps using the device.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "A check-mark in the Custom HW column indicates that the corresponding approach does not need custom hardware, whereas a cross means it needs. Accuracy Saving Adaptivity Custom HW DM MCDNN [7] \u0017 \u0013 \u0013 \u0013 Resource Budget Potluck [12] \u0013 \u0017 \u0013 \u0013 Feature Vector Euphrates [9] \u0013 \u0013 \u0017 \u0017 Reuse Distance DeepCache [8] \u0013 \u0017 \u0017 \u0013 Reuse Distance This Work \u0013 \u0013 \u0013 \u0013 Motion Vector \ncan be relatively low (as in Potluck [12] and DeepCache [8]). Additionally, sometimes sudden changes in subsequent frames (e.g., with a new object in the frame), require adaptive decisions, which cannot be achieved by Euphrates [9] and DeepCache [8].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "(b): The pattern between left-eye and right-eye in the  front  face in Cube Mapping [41]. the averaged PSNR [25], [40] of the Ô¨Åve videos represented in Equirectangular format [52] in Fig. 10  a  .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "8097. International Society for Optics and Photonics, 80971H. Real-time Generation of Fully Optimized Holograms for Optical Trapping Applications. In  Optical Trapping and Optical Micromanipulation VIII , Vol.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Softsku: Optimizing server architectures for microservice diversity@ scale. In  ISCA . [8]  Liang Wang, Mengyuan Li, Yinqian Zhang, Thomas Ristenpart, and Michael Swift.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "904 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. 109‚Äì114.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "This design is more concise even than the SINWP [ 6 ], because we target low power as the primary goal. To increase efÔ¨Åciency further our design supports aggressive power gating and other circuit techniques to dynamically reconÔ¨Ågure active tile sizes and shut-off inactive ReRAMs. SpeciÔ¨Åcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "We identify two interlinked factors, in the context of DDAs, that need to be accounted for when making container scaling decisions. A significant amount of research [ 18 ,  22 ,  24 ,  38 ,  39 ,  43 ,  52 ] has been focused to- wards reducing cold-start overheads (in particular, proactive container provisioning [ 3 ,  32 ,  44 ,  46 ]). However, in the case of DDAs, DBPs make it unclear as to how many containers should be provisioned in advance for the functions along each path in the DAG.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "[50]  Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Journal of Machine Learning Research , 8(Dec):2755‚Äì2790, 2007. Dynamic weighted majority: An ensemble method for drifting concepts.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "This dual-stream processing consumes considerable system resources such as CPU, memory, and energy, further complicating the management for intermittently powered systems like U s. √°s (Mishra et al., 2024) where data integrity and security must be maintained during power disruptions   1 . These processes create a complex data-flow pipeline, differentiating two streams of video data: one for real-time inference and training, and another for archival. Table 1 provides an estimation of resource utilization on commercial systems underscoring the fact that compressing, encrypting and reliably storing the data, especially for (intermittent) edge servers is a bigger challenge in contrast to classical cloud storage servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "[101] Sadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason D Lee, Danqi Chen, and San- jeev Arora. Accessed: 2023-10-20. Fine-tuning language models with just forward passes.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Figure  9b  shows the breakdown of the percentage of re- quests ( Const1 ) served by the each model. As seen, Incep- tionResNetV2, Densenet-201, Densenet121, NasnetMobile and Xception are the top-5 most used models in the ensem- ble. Based on Table  1 , if we had statically taken the top  N / 2 most accurate models, NasNetmobile would not have been included in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "https://mikhail.io/ serverless/coldstarts/azure/. [16]  Feb 24, 2020. Intel Power Gadget.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "Scalability in perception for autonomous driving: Waymo open dataset. Caine. In  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "Platform Freq. Note that  Us. ¬¥as  hardware is not outperforming any of them as the goal was greater  scheduling Ô¨Çexibility  for power tracking rather than performance or area.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Since the primary contribution in  Cocktail  is to provide high accuracy and low latency predictions at cheaper cost, appli- cation developers can adapt the prediction algorithm to their needs or even plug-in their own prediction models. DeepARest is 10% better than LSTM model. It is evident that the LSTM and DeepAREst have lowest RMSE value.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "However, it is challenging to design an optimal point cloud \n282 \n2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO) \n978-1-6654-6272-3/22/$31.00 ¬©2022 IEEE DOI 10.1109/MICRO56248.2022.00031 \n2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO) | 978-1-6654-6272-3/22/$31.00 ¬©2022 IEEE | DOI: 10.1109/MICRO56248.2022.00031 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Our experiments show that PCC is the most expensive computation in a PC processing pipeline that takes  ‚âà 4 seconds , especially when deployed in mobile/edge devices, and hence, is a major contributor to the performance, video quality, and transmission energy, for the entire PC pipeline.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 212,
    "augmented": true
  },
  {
    "text": "Mentoring Plan \nThis project will accommodate a total of 4 PhD students, as discussed in our Management and Coordi- nation Plan. The PIs will perform the following mentoring activities for these PhD students: \nOrientation and Expectation Setting \nThe PIs will engage in in-depth conversations with PhD students, to set clear expectations, goals, and deliverables for the project period. After the initial meetings with the PhD students, the students will be asked to complete a worksheet to ensure alignment on objectives.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Since model execution typically demands either a large memory footprint or high bandwidth or both, using both large capacity DDR and fast memory HBM memory blocks in our chip can be explored to effectively meet these memory requirements. In addition, in the cases of heavy data movement within a chiplet, the register file, scratch- pad memory, and cache hierarchy can be configured for more effectiveness. Or, having a fine-grained pro- grammer control via pragmas/annotations can help to efficiently utilize the caches.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Although we use specific combinations of applications and traces to highlight the improvements, the results are similar for other workload mixes as well. Container Utilization:  Figure 11 plots the average num- ber of requests executed per container (Jobs per container) \n2 MLP misprediction rates are not shown in any Figure \n162 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \n0 \n100 \n200 \n300 \nArch Fifer DProb Kraken SProb Xanadu \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(a) Social Network. 0 \n150 \n300 \n450 \n600 \nArch Fifer DProb Kraken SProb Xanadu \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 198,
    "augmented": false
  },
  {
    "text": "Note that, this projection process is quite compute-intensive. Therefore, the output of the projection computation is  two projection matrices, each indicating the mapping between each coordinate in  360 ¬∞ video frame and a 2D coordinate on screen for the left and right eye. Since there is a small offset between the two eyes, the projection computation needs to cap- ture the pupillary distance to generate a separate view for each eye.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "III, the transformation matrix ( T  ) is determined by the head orientation, which is sampled from the built-in IMU sensors. 4. We observe that, if the head orientation does not change across two frames, the Ô¨Åve transforms and the  360 ¬∞ coordinate inputs remain the same, thereby providing ample opportunities for directly  reusing \n245 \nthe compute results from the previous frame ( P 1 ), as shown in  a  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Known-time Eye-dependent? T 1 Rigid body No Compile-time Left = Right T 2 An eye‚Äôs view Yes Runtime Left = Right T 3 Eye adjusting No Compile-time Left  Ã∏ =  Right T 4 Perspective No Design-time Left = Right T 5 Viewport No Design-time Left = Right \ntheir corresponding  360 ¬∞ video frame coordinates. Label Description HO dependent?",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "In  Harvard Brain Science Initiative , Boston, MA, 2024. Available at:  https://brain.harvard.edu . [126] Bowen Pan, Yikang Shen, Haokun Liu, Mayank Mishra, Gaoyuan Zhang, Aude Oliva, Colin Raffel, and Rameswar Panda.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "2017. Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency. [4]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "https://archive.org/details/twitterstream. Accessed: 2020-05-07. [2]  2019.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "Even if we were able to design a proper scheduling policy, for a conventional ensemble, all the sensors involved need to Ô¨Ånish their computation. Therefore, different DNNs are needed to process data from these different locations. Consequently, the power requirement and the latency of these DNNs may vary and synchronizing them for collective execution would require scheduling that addresses these differences in resource requirements.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "[125] Will Orwig and Daniel Schacter. arXiv preprint arXiv:2303.08774 , 2023. Gpt-4 tech- nical report.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "We also conducted experiments with a strategy mimicking Potluck [12] on V1 [33] by employing the down-sampled image as the feature vector. As can be observed from Table IV, Potluck [12] provides very good accuracy ‚Äì  51 . 6% , which is slightly better than  50 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Available at:  https://brain.harvard.edu . [126] Bowen Pan, Yikang Shen, Haokun Liu, Mayank Mishra, Gaoyuan Zhang, Aude Oliva, Colin Raffel, and Rameswar Panda. In  Harvard Brain Science Initiative , Boston, MA, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Graphcore intelligence processing unit (ipu). Accessed: 2024-04-27. https://www.graphcore.ai/ products/ipu , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "Note that, this implementation is purely done in software, without any hardware modification. ‚Ä¢  Intra-Holo:  We evaluate our  Intra-Holo  design again on a mobile GPU as shown in Fig. 6b  b  .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "TABLE I: Projection Computation description. 3), uses the transformation matrix and the 2D FoV coordinates for both eyes to obtain \n4 We used an averaged pupillary distance in our evaluations [27], [37]. Label Description HO dependent?",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "\"https://docs.opencv.org/2.4/doc/tutorials/gpu/gpu-basics-similarity/gpu- basics-similarity.html\". [45] OpenHolo. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "8a . For each video, these Ô¨Åve designs are listed on the x-axis. The primary y-axis (left) shows the latency in  ms  for SOTAs, whereas the secondary y-axis (right) gives the latency in  ms  for our proposals.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "7. A  Decision Maker  is placed be- fore the original compute engine (CPU in this example) to dynamically decide how to process the incoming frame, and opportunistically bypass the computation, i.e., either  1  Full Inference (FI) or  2  Skip Inference (SI), or reduce the compute by only processing RoIs, when opted for  3  Partial Inference (PI), with a little overhead ( 0 . 5%  w.r.t.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Michael Mesnier. 224‚Äì238, 2019. In  Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "In addition, our  Intra-Holo  scheme is more power efficient than  Inter- Holo , translating to 27 . 72% power reduction with respect to the baseline. This indicates that the optimization scope of the distance- based  Intra-Holo  is larger than that of the RoF-based  Inter-Holo , which provides more sparsity in the hologram computing.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "For each sensor to perform inference using the limited and unstable harvested energy poses a scheduling problem, as non-deterministic time is required for the EH sensors to accumulate enough energy to perform the inference. This scheduling is made even more difÔ¨Åcult as each sensor can harvest and consume different amounts of energy depending upon their location, have different sensor sampling rate, and require different DNNs to be executed. Further, all sensors might not be able to participate in the ensemble due to the Ô¨Åckle nature of harvested energy.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Batching reduces the number of containers spawned for each function by a factor of its batch size (Algorithm 1  b  ). The batch size \nfor a function,  ùëì , is defined as  BatchSize  ( ùëì )  = j StageSLO  ( ùëì ) ExecTime  ( ùëì ) k \n(Algorithm 1  b  ). Note that  ExecTime (f)  is estimated by aver- aging the execution times of the function obtained through \n159 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "Nash Equilibrium and Stability: A Nash equilibrium (NE) represents a stable action profile  a ‚àó ( t )  where no sensor can unilaterally improve its utility by deviating from its current strategy: \nU i ( a ‚àó i   ( t ) ,  a ‚àó ‚àí i ( t ))  ‚â• U i ( a i ( t ) ,  a ‚àó ‚àí i ( t )) ‚àÄ a i ( t ) ,  ‚àÄ i. 4 \n220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 \nAchieving an NE ensures that sensor participation patterns are stable; once equilibrium is reached, no single sensor ben- efits from changing its participation decision independently. This stability is critical for maintaining consistent network performance and energy sustainability over time.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 292,
    "augmented": false
  },
  {
    "text": "II). Typically, the resolution of the IMU traces can be as high as 20 bits per Ô¨Åeld [3], [28]. From the dataset, we report the average reuse distance, i.e., the average number of preceding frames with same head orientation to be memoized, and show it in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "The inputs and weights are binary and the output is adaptive between 1-3 bits. The serial-input non-weighted product (SINWP) structure [ 6 ] is the Ô¨Årst work to propose multi-bit input/weight and output design from the circuit level, adopting a 2-bit input, 3-bit weight, and 4-bit output scheme. Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a \n3-bit resolution, which is a high performance but also a high power consuming design.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "In order to effectively handle mis-predictions in load,  Kraken  also employs a Reactive Scaler (RS)  7  that consists of two major components. First, is an Overload De- tector  7a  that keeps track of request overloading at functions by monitoring queuing delays at containers. Subsequently, it triggers container scaling  6  by calculating the additional containers needed to mitigate the delay.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "These optimizations have been attempted at different levels, including model compression (pruning [2], [3], quantization [4]), compiler support [2], [5]‚Äì [7], runtime systems [7]‚Äì[13], and hardware enhancements [9], [14], [15]. Let us now summarize the pros and cons of four representative state-of-the-art works which include var- ious levels of optimizations as aforementioned, and compare them with our work. DeepCache [8] has been proposed for trading layer-wise intermediate data memoization/caching for computation savings, but it ignores the frame-wise reuse op- portunities.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 5a  Salient Store \n14 \n0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nNormalized Latecy \nCompute Server \nVSS \nStorage Server \nFigure 6: Impact of scaling to multiple storage nodes. keeps up with the accuracy of the traditional compression system thanks to the robust layered coding algorithm.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Second, How do we maintain high power efficiency of PUs during runtime? In some cases where a small amount of hologram computation required, not all of the PUs on-board are needed to be active. We plan to design and imple- ment a clock/power gating technology to switch off the un-utilized PUs and save power/energy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 52nd Annual Design Automation Conference , pp. Ambient energy harvesting nonvolatile processors: From circuit to system. 11 \nYongpan Liu, Zewei Li, Hehe Li, Yiqun Wang, Xueqing Li, Kaisheng Ma, Shuangchen Li, Meng-Fan Chang, Sampson John, Yuan Xie, et al.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "[2]  Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang. Laser: A scalable response prediction platform for online advertising. In  Proceedings of the 7th ACM international conference on Web search and data mining , pages 173‚Äì182, 2014.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Each sensor observes the environment from a distinct van- tage point. Time is slotted and indexed by  t  ‚àà N . In each time slot, the network may perform an inference event, dur- ing which sensors have the opportunity to contribute data that enhances the accuracy of a global inference task, such as object detection or environmental classification.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "( T s ) is set to 1 minute as it is the typical instance provisioning time for EC2 VMs. To calculate ( L p ), we sample the arrival rate in adjacent windows of size  W over the past S seconds. Using the global arrival rate from all windows, the model predicts ( L p ) for  T p  time units from  T .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Kubernetes. [9] 2020. https://cloud.ibm.com/docs/openwhisk?topic= cloud-functions-pkg_composer.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "While some of the weights contribute more towards accuracy, some contribute less; and the ones contributing less are dropped to reduce the parameter size as well as compute and memory footprints. On the other hand, quantization, which has recently gained a lot of traction, trying to quantize the parameters to lower precision [25]. Combined with specialized hardware support, quantization can reduce the amount of computation, memory footprint, and energy consumption.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)  (2020), 10766‚Äì10773. [10]  Yu Feng, Boyuan Tian, Tiancheng Xu, Paul Whatmough, and Yuhao Zhu. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Restrictions apply. [89]  W. Wu, Z. Qi, and L. Fuxin, ‚ÄúPointconv: Deep convolutional networks on 3d point clouds,‚Äù in  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. [90]  T. Xu, B. Tian, and Y. Zhu, ‚ÄúTigris: Architecture and algorithms for 3d perception in point clouds,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2019, p. 629‚Äì642.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "End-to-end Pipeline:  The PC video processing pipeline, as shown in Fig. 1 , typically consists of 5 stages: 3D content generation, PC encoding, data transmission, PC decoding, render and display. To understand these challenges, we analyze an end-to-end PC pipeline.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Using the expert execu- tion attribute database, we can extract the expert-hardware affinity, corresponding to which the equivalent chiplet versions are integrated to design a chip (in this regard, we will also consider existing and upcoming hardware accelerators [47, 61, 115, 131, 173]). A chip can be  homogeneous  (containing the same chiplets like only GPUs or CPUs) or  heterogeneous  (having different types of compute chiplets including hardware sup- port for quantization and sparsity [109]), to serve varying use-cases of EoEs. For example, an EoE consisting of GPU-affined experts can be mapped to a GPU-only chip, whereas an EoE consisting of varying chiplet affinities can be mapped to a suitable heterogeneous chip.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 198,
    "augmented": true
  },
  {
    "text": "[78]  Jasper A Vrugt and Bruce A Robinson. Treatment of uncertainty using ensemble methods: Comparison of sequential data assimilation and bayesian model averaging. Water Resources Research , 43(1), 2007.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "The results will be disseminated through timely scientific publications in respected conferences and journals throughout the project period. Note that the education activities, undergraduate involvement efforts, outreach and BPC activities, and industry collaboration efforts (discussed earlier in the broader impact section of the proposal) will continue throughout the entire project duration. Year 3 \nTHRUST-I:Algorithmic  \nSupport for Ensemble  \nof Experts \n2.1 Data Locality and Parallelism-Aware LLM Training \nTHRUST 2: System  \nSupport for Expert  \nScheduling and Data  \nMovements \n3.1 Expert/Hardware Co-Characterization \nTHRUST 3:  Chiplet- \nbased Adaptive and  \nReconfigurable  \nHardware Platform \nCurriculum Development, Undergraduate Research Involvement, Training in Galaxy Community, Industry Outreach, Result  \nDissemination  \nBPC, K-12, Undergraduate Honors, Science-U \n1.1 EoE Design Space Exploration \n1.2 Constructing Morphology of EoE \n2.2 Router Retraining \n2.3 Using Hot and Cold Experts: Caching and Prefetching \n3.2 Chiplet-Based Modular Hardware Platform \n1.3 Continual Adaptation of LLM Experts \n3.3 Handling Unforeseen Cases using Reconfiguration \nTHRUST 4:  \nEvaluation  \nand Fine  \nTuning \n4.1 Evaluation Infrastructure: Experiments + Simulation + Analytical Modeling \n1.4 Algorithmic Choices Informed by System & Hardware Constraints \nYear 2 \nYear 1 \n2.4 KV Cache Management \n2.5 Runtime Support \n2.6 Fault Tolerance \n4.2 Methodology \n3.4 Going beyond with Hardware Software Co-optimization \nFigure 8 :  Project timeline that shows both research and educational/outreach efforts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 373,
    "augmented": false
  },
  {
    "text": "¬¥as  with eager scheduling vs an oracle scheduler. Us. ¬¥as  closely tracks oracle, where as DaDianNao [ 16 ] falls short.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "3‚Äì18. [30]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg. In  Proceedings of the Twenty-Fourth International Conference on Archi- tectural Support for Programming Languages and Operating Systems .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "To explore the search space, we plan to investigate four design choices: what types of chiplets are needed in a chip, how the EoE can be mapped to our chip, how the memory hierarchy can be tailored for a given EoE mapping, and how the chiplets and chips can be interconnected, as illustrated in Figure 6. This database will help in various intelligent decisions such as using the most ideal hardware for an expert and dropping an expert if it does not meet the minimum required accuracy/SLO for an application. Task-3.2: Chiplet-Based Modular Hardware Platform After identifying the device affinity and the execution attributes of each expert, towards the goal of design- ing a suitable hardware platform, we envision mapping these experts onto appropriate chiplets which may differ across experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 167,
    "augmented": true
  },
  {
    "text": "VII. C ONCLUDING  R EMARKS \n360¬∞ VR videos have become the next trend in entertain- ment media and soon will become an integral part of the technology inÔ¨Çuencing many application domains. However, unlike planar videos, the 360¬∞ VR video streaming demands signiÔ¨Åcantly more compute power from a battery-operated headset.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Our proposed frame-level reuse shows  ‚âà 53%  of the frames to be redundant and hence skips the inference, leading to only less than  1%  accuracy loss. Combining the frame-level reuse with the partial inference gives  2 . 2 √ó  performance improvement on average, and up to  80%  energy savings, while losing less than  2%  accuracy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "However, the  Paragon  scheme is 10% more cost-effective than mixed and at the same time ensures similar SLOs. This is because the  Paragon  scheme is aware of the latency requirements of individual queries and does not blindly offload queries to lambdas when there is increase in load. Therefore, this results in reduced cost and at the same time does not violate SLOs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "While probability-based container provisioning can significantly reduce the number of containers, the presence of container cold-starts leads to SLO violations (requests not meeting their expected response latency). Note that variability in application usage patterns can lead to changes in function probabilities within each DDA, which the policy will have to account for. Challenge 2: Adaptive Container Provisioning.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "https://dumps.wikimedia.org/ , 2024. [164] Wikimedia Foundation. Wikipedia database dumps.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "If we can deploy the decision making logic on a  custom hardware  with negligible overhead, our proposed techniques would be more effective when targeting light DNN models. VI. C ONCLUDING  R EMARKS \nPushing DNN-assisted video analysis into edge is the cur- rent trend in applications like surveillance, assisted surgery, and VR/AR [23].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "5s, pp. 1‚Äì27, 2021. [57] Meta, ‚ÄúSharing our progress on combating climate change = https://about.fb.com/news/2022/11/metas-progress-on-combating- climate-change/ ,‚Äù (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "2.2. Participation Strategies in EH-WSNs \nEfficient participation strategies are critical in EH-WSNs to optimize network performance while conserving limited energy resources. Traditional approaches often assume con- tinuous participation of all sensors, which is impractical in energy-constrained environments ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "We identify two interlinked factors, in the context of DDAs, that need to be accounted for when making container scaling decisions. The first, is what we call  critical functions . These are functions within a DAG that have a high number of descendant functions that are linked to it and we use the \n155 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "To study how the number of depth planes affects the hologram performance, we profile the execution latency from a typical edge GPU device [ 36 ], generating holograms with different number of depth planes (assuming the same number of pixels in each plane), and the results are plotted in Fig. 4b. From this figure, one can observe the following: First, in general, these two steps take similar times to execute, due to the similar procedures they \nAlgorithm 1:  Depthmap Hologram Algorithm [4, 18].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Motivated by these challenges, we propose  NExUME  ( N eural  Ex ecution  U nder Inter M ittent E nvironments), a novel framework designed specifically for environments with intermittent power and EH-WSNs, with potential applications in any ultra-low-power inference system. NExUME uniquely integrates energy variability awareness directly into both the training ( DynFit ) and inference ( DynInfer ) processes, enabling DNNs to dynamically adapt computations based on real-time energy availability. This calls for revisiting the entire training process; we need to train the DNN in such a way that it is aware of the intermittency and adapts  to it.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": "Figure  3a , shows the accuracy comparison of the baseline (single) and static ensemble (ex- plained in Section  3 ) compared to the full-ensemble. The latency numbers for the baseline models and the corresponding ensemble models along with the size of the ensemble are shown in Table  3 . In majority voting, every model votes for a prediction for each input, and the Ô¨Ånal output prediction is the one that receives more than half of the votes.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "8a . The primary y-axis (left) shows the latency in  ms  for SOTAs, whereas the secondary y-axis (right) gives the latency in  ms  for our proposals. For each video, these Ô¨Åve designs are listed on the x-axis.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "9b), we can observe that YOLOv4-tiny spends less time on inference than YOLOv3 ( 42%  versus  47% ). 8b) and YOLOv4-tiny (see Fig. However, the overhead this scheme brings when applied to YOLOv3 ( 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "A significant amount of research [ 18 ,  22 ,  24 ,  38 ,  39 ,  43 ,  52 ] has been focused to- wards reducing cold-start overheads (in particular, proactive container provisioning [ 3 ,  32 ,  44 ,  46 ]). However, in the case of DDAs, DBPs make it unclear as to how many containers should be provisioned in advance for the functions along each path in the DAG. We identify two interlinked factors, in the context of DDAs, that need to be accounted for when making container scaling decisions.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "[22]  S. Giancola, J. Zarzar, and B. Ghanem, ‚ÄúLeveraging shape completion for 3d siamese tracking,‚Äù in  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. [23] Google, ‚ÄúDraco,‚Äù  ‚Äùhttps://github.com/google/draco‚Äù , 2021. [24]  B. Han, Y. Liu, and F. Qian,  ViVo: Visibility-Aware Mobile Volumetric Video Streaming .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Participation in- volves: \n1. Determining if they have enough energy and incentive (based on the established equilibrium strategy and reward parameters  Œ≥, Œ¥, Œ∑ ). 2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "This grant enables the PIs as well as the project team to access, among other resources, hundreds of Intel Xeon nodes, various types of NVIDIA GPUs (A100 and V100), and two large storage arrays consisting of various types of HDDs, SSDs, FPGAs, as well as 4 computational storage devices (Samsung SmartSSD). The PIs will also have access to the Argonne National Laboratory Aurora Exascale Supercomputer ‚Äì a collection of LLM accelerators for our testbed and experimental evaluations. Finally, our partnership with ANL (see the attached collaboration letter) allows us to access ANL re- sources, including hardware accelerators for LLM.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "P load = aG√ó (Bits input /BN in )√óP ld‚àíbit   modelsloadpoweroperation. 1)Loadandstore: P load and P store   denotethepower consumedbyloadingthedatafromthepureReRAMmem- oryintotheinputregistersandstoringthedatafromthe outputregistersintotheReRAM memory . Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solution m,n,aG  wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,P load ,P comp andP store ,andtheyareperformed insequence.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 208,
    "augmented": true
  },
  {
    "text": "These policies can be collectively used for cost-effective prediction serving with- out compromising on latency and accuracy. Towards this, we discuss the trade-offs of intermixing resources like serverless functions along with VMs and identify the key challenges associated with configuring these resources. We propose multiple key-policies to make resource manage- ment; (i) latency aware, (ii) multi-dimensional SLO aware, and (iii) request load variation aware.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Experimental Platform and Datasets \nPlatforms : We used the Google Pixel 3 Android Phone [20] as our experimental platform. B. 2 is invoked to decide among the execution choices for the incoming frames ‚Äì including Skipping, Full-Inference, and Partial-Inference.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "‚Ä¢  CWIPC:  Overall, when employing the CWIPC, the output frame size reduces to around  14%  of the original input frame (including 63 %  of geometry and 37 %  of attribute data). Note however that, this comes at the cost of longer processing latency, as shown in Fig. 8a .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "By demonstrating the viability of a battery-less edge server for video analytics, Us.¬¥as spearheads the adoption of similarly sustainable systems for other do- mains. While the initial scope is limited to urban mobility applications, the concept‚Äôs adaptability extends to various domains, including autonomous driving, smart industries, and remote sensing: Section  V-D  performs an initial exploration of how techniques from Us.¬¥as will apply to other domains. Algorithmic Advancements:  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "8b) and YOLOv4-tiny (see Fig. 9b), we can observe that YOLOv4-tiny spends less time on inference than YOLOv3 ( 42%  versus  47% ). However, the overhead this scheme brings when applied to YOLOv3 ( 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "[47] H. Bay, T. Tuytelaars, and L. Van Gool, ‚ÄúSurf: Speeded up robust features,‚Äù in  European conference on computer vision , 2006, pp. 404‚Äì 417. [48] F. Suard, A. Rakotomamonjy, A. Bensrhair, and A. Broggi, ‚ÄúPedestrian detection using infrared images and histograms of oriented gradients,‚Äù in  2006 IEEE Intelligent Vehicles Symposium , 2006, pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "By keeping  Œª 1 , Œª 2  within reasonable bounds, we ensure that the modified gradient   b ‚àá J ( Œ∏ )  remains well-behaved, preserving the conditions for SGD convergence. We have shown that under the stated assump- tions‚Äîconvexity and smoothness of ‚Ñì , convexity and bounded gradients of  ‚Ñ¶ SNR  and  ‚Ñ¶ complexity , stationarity of  D  induced by equilibrium strategies, and unbiased gradient estimates‚Äîthe diminishing step-size SGD applied to  J ( Œ∏ )  converges in expectation to a stationary point  Œ∏ ‚àó . The equilibrium ensures  D  remains stable, allowing classi- cal stochastic optimization theory to hold.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 167,
    "augmented": false
  },
  {
    "text": "frame (or skip the current frame). We next discuss the motion vector concept, which is used in our approach. 2) Motion Vectors:  The motion vector (MV), which is built upon pixel differences, can be a good candidate to capture the reusability in video analytics.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Ensemble pruning via individual contribution ordering. In  Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ‚Äô10, page 871‚Äì880, New York, NY, USA, 2010. Association for Computing Machinery.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai , Febru- ary 2024. Accessed: 2023-10-20. [5] Dennis Abts, Garrin Kimmell, Andrew Ling, John Kim, Matt Boyd, Andrew Bitar, Sahil Parmar, Ibrahim Ahmed, Roberto DiCecco, David Han, John Thompson, Michael Bye, Jennifer Hwang, Jeremy Fowers, Peter Lillian, Ashwin Murthy, Elyas Mehtabuddin, Chetan Tekur, Thomas Sohmers, Kris Kang, Stephen Maresh, and Jonathan Ross.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, we propose and evaluate in detail two pluggable schemes (for taking advantage of intrinsic temporal-spatial reuse), and prototype them as microarchitec- tural augmentations using FPGA. In contrast, this paper attempts to exploit available ‚Äúre- dundancies‚Äù in computation by analyzing the VR projection computation pipeline. Our experimental results show 34% computation reduction and 17% energy savings, compared to the state-of-the-art [28].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "B. What are the potential opportunities? Increasing Geometry Compression Parallelism Using Morton Code:  As mentioned earlier, the reason why the ‚Äúsequential update‚Äù is necessary is that, during the interme- diate stages, the  global  Octree (the Ô¨Ånal tree constructed at the last step) is unknown until the last point is inserted in the tree.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "For example, as shown in Figure 3, we can split a large expert model into smaller domain-specific models and train them on smaller, focused datasets in corresponding domains. To this end, we propose a method for continual adaptation of EoE systems by  LLM expert split, merge, grow, and shrink . This allows us to perform flexible and efficient ‚Äúneighborhood training‚Äù by localizing  the training parameters and  freezing  the rest of the parameters as much as possible to save cost.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "However,  T 2  can change at runtime, and if any element in  T 2 is changed, the transformation matrix needs re-computation \nFig. This also determines the ‚Äúorder of computation‚Äù, which is Ô¨Årst  T  , then  P , and Ô¨Ånally  F . ‚Ä¢  Input (in-)Variability:  It should be clear from the discus- sion above that  T 1 ,  T 3  T 4 , and  T 5  can be determined apriori.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Us. While fully powered,  Us. ¬¥as  also consumes more power than the other accelerators since it also performs the exemplar selection along with the DNN training, and also houses NV-SRAM buffers for hardware check-pointing.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Salient Store  also provides a hardware accelerated lattice-based quantum safe encryption mechanism. To tightly integrate these solutions to the storage space, while providing data security,  Salient Store uses computational storage devices (CSDs) (AMD, b) which reduce the energy consumption while keeping the compute pipeline unaltered. Our main  contributions  include: \n‚Ä¢  We propose design of a hybrid storage pipeline equipped with computational storage drives (CSDs) where the different drives could communicate with each other in a peer-to-peer fashion.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "In addition to these, we will also use LLM/application-level metrics such as LLMOps (an extension of MLOps [84] tailored for LLMs). To evaluate the effectiveness of our optimizations and compare them against state- of-the-art, in addition to the standalone LLM/EoE systems, we will use various applications that employ LLMs (e.g., text generation, summarization, chatbot, language translation, and sentiment analysis) as well as emerging benchmarks like HellaSwag [195], TruthfulQA [97], GLUE [159], and MMLU [191]. To gather input data, we plan to utilize publicly available datasets such as Wikipedia [164], Common Crawl [29], BookCorpus [199] and OpenWebText [49], along with our proprietary repositories.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 190,
    "augmented": false
  },
  {
    "text": "Roberto Pierdicca, Michele Sasso, Flavio Tonetto, Francesca Bonelli, Andrea Felicetti, and Marina Paolanti. 5537‚Äì5543, 2023. doi: 10. 1109/ICRA48891.2023.10160700.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Here, each expert is specialized to solve tasks in specific domains, languages, or skills. Experts can be trained individually and continually adapted to generate new experts. Expert models are also ‚Äúcomposable‚Äù, so that they can be chosen dynamically according to inputs and then grouped together to solve difficult tasks, which require a combination of skills and knowledge sources.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "is mapped from position  [( x 360 ) 0 r ,  ( y 360 ) 0 r ]  on the  360 ¬∞ frame. This encourages us to further study whether this distance vector changes with head orientation or not, and also whether it is invariant for any particular frame ‚Äì if yes, then how? To study the relationship between the coordinate projection re- sults between both eyes, for the  same  two coordinates  [ x i , y i ] on both  2 D  FoV frames, we determine the distance vector ( ‚Éó d ) i   between their equirectangular counterparts, represented in Equation 3: \n( ‚Éó d ) i   = [( x 360 ) i r   ‚àí ( x 360 ) i l ,  ( y 360 ) i r   ‚àí ( y 360 ) i l ] ‚ä§ (3) \nThe knowledge of distance vector   ‚Éó d  is critical to explore the AE  opportunity, because if it was known apriori, then we only need to process the entire projection transformation to generate the mapping results ( P L ) for one eye, and then deduce the coordinate projection computation results for the other ( P R ) by simply adding   ‚Éó d  with  P L .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 299,
    "augmented": true
  },
  {
    "text": "The only difference that can be observed is that, regarding LeNet  and  PV  with the power source of  Thermal , relatively speaking, the results of energy efÔ¨Åciency with  Pipelining strategy are higher than that appearing in the throughput evaluation. The results show that ResiRCA and ResiSchedule achieve average energy efÔ¨Åciency improvements of 14 √ó  compared to a baseline RCA with intermittency-unaware scheduling. Overall, the normalized results of energy efÔ¨Åciency are very similar to those of the throughput evaluation.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "The backward pass emphasizes gradient computation through backpropaga- tion, which is crucial for weight updates. The gradient of the loss function concerning the weights is computed through the formula ‚àÇ L ‚àÇ K mi jc   =  ‚àë U ‚àí 1 \nu = 0   ‚àë V ‚àí 1 \nv = 0 \n‚àÇ L ‚àÇ A muv   ¬∑  X ( u + i )( v +  j ) c . This gra- dient computation, fundamental for learning, is meticulously mapped across the systolic array, ensuring precise and efÔ¨Åcient backpropagation.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "shorturl.at/jmnpD [53]  Antoni Rosinol, Marcus Abate, Yun Chang, and Luca Carlone. IntechOpen. Holographic 3-D Displays - Electro-holography Within the Grasp of Commercialization .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "3) The latency difference between the data shared model and privacy preserved model is not so prominent due to the lower data volume. The models generated are simple, and hence does not have significant difference in execution time at the cloud. Sensitivity Study:  To better understand the relationship be- tween the inference quality and the threshold, we run our model with different parameter settings, shown in Figure 4, over the cases of edge-peer and edge-cloud structures with device counts of two and four.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "[23] Guangyu Chen and Feihui Li. Application mapping for chip multiprocessors. In  Proceedings of the 45th annual design automation conference , pages 620‚Äì625, 2008.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "IEEE, 2015. Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving?",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "4. Stationary distribution  D . The equilibrium participa- tion strategies induce a stationary effective distribution D .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 24,
    "augmented": false
  },
  {
    "text": "the  Baseline  method. V-A. These energy results are normalized w.r.t.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "[37]  J√∂rn Kuhlenkamp, Sebastian Werner, and Stefan Tai. 2020. The ifs and buts of less is more: a serverless computing reality check.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Decoupling compute tasks needed for storing the data from the host CPU and embedding them directly within storage devices, particularly through CSDs, has demonstrated significant performance and energy benefits. Tasks traditionally performed at the storage controller level are now being offloaded to CSDs, often accelerated using FPGA primitives (Kim et al., 2021; AMD & Xilinx; AMD, a). Moreover, CSDs hold the potential to undertake critical machine learning tasks like feature extraction and clustering, streamlining tasks like neural compression.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Figure 16:  Latency reduction (%) plotted as bar graph(primary y- axis) and accuracy gains (%) plotted as line graph (secondary y-axis) over InFaaS. Strict Relaxed 0 \n25 \n50 \n75 \n100 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace. Strict Relaxed 0 \n20 \n40 \n60 \n80 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(a)  Wiki Trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "64% of the time and the correct number of layers for 87 . 06% of the time. Along with that, the micro-proÔ¨Åler selects correct batch size 82 .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "Cold start spillovers (that often occur due to container underprovision- ing), as described in Section 2, can impact the response la- tency of applications harshly. Provisioning critical functions with more containers helps throttle this at the source. To this end,  Kraken  makes use of a parameter called  Connec- tivity , while assigning function weights.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "To further prove this, we also change the compute mode of Jetson AGX Xavier board to 10W, and measure the execution latency for loot video [ 54 ]. Such similar performance demonstrates that our proposal is expected to work well for low-power edge devices like smartphones as well. We observe that the total execution latency when using 10W mode is 1.29x of that when using 15W mode (the mode for collecting the main results).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Algorithm Compression Ratio Accuracy Loss (%) Fourier Decomposition 3 - 5 9.1 - 18.3 DCT 3 - 5 5.8 - 16.2 DWT 3 - 6 5.3 - 12.7 Coreset 3 - 10 0.02 - 0.76 Table 1: Accuracy trade-off of different compression techniques: Low-dimensional data loses important fea- tures under lossy compression, dropping inference ac- curacy significantly compared to the original data. HAR has been pervasive enough given the rise of smart wearables and has been studied well enough to have ample access to resources to make a judicious evaluation. Further, we also evaluate one more emerging application from predictive maintenance domain.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "1. It also describes our plans for ensuring data integrity and reproducibility. Types of Data and Storage \nThe project will generate seven types of data: (i) the codes and executables for the compiler that performs expert-to-chiplet mapping; (ii) source codes for scheduling support and simulator; (iii) expert repository that will hold the LLMs/expert models generated during the project; (iv) detailed LLM/expert algorithms as well as workload characterization and experimental data; (v) educational materials; (vi) a document detailing how to use the software developed during the project; and (vii) finally, lineage (provenance) data (more on this below).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "This can be illustrated with a simple use-case scenario. In the following two subsections, targeting inference-based video applications, we present two novel schemes that take advantage of this similarity:  frame-level pruning  and  region-level pruning . A. Frame-Level Pruning \n1) Shortcomings of Pixel-by-Pixel Comparison:  We believe a solution based on exact pixel-by-pixel matching would be too strict and would not be suitable for DNN-based applications.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "(ii) Underutilized energy:  When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level. In this case, the unused energy will be wasted, resulting in low energy efÔ¨Åciency. Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four  25  √ó  6  ReRAM crossbars, each can be mapped to six kernels, all sized  5 √ó 5 √ó 1 .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Instead of updating and storing the occupy bits for each node during the process of adding points, now the outputs of this step are several arrays (Morton codes array, parent array, etc. ), which reveal the geometrical relationship across the nodes. ‚Ä¢  Post Processing:  Using these relationship arrays, the Ô¨Ånal step is to post-process them to obtain the occupy bits for each node, and output the compressed geometry stream.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "This fulfils requirement  4  . For the DNNs in question, coresets can achieve sufficient compression ratios to make communication energy-competitive with computation, as well as opening up new opportunities for optimizing DNN in- ference on the coreset, rather than original data. They are also an effective way to con- struct a representation of the data set with high compression ratios [ 8 ,  17 ] without incurring unacceptable accuracy losses and thus useful for achieving  3  .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "72 (with real solar power trace) and minimum of 89 . 14 (with synthetic power trace) accuracy. The micro-proÔ¨Åler, having run multiple sweeps, returns a set of hyper-parameters ( Œ® i ) for each model which is then stored in a history table.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Both these schemes suffer from over- provisioning VMs because (i) we cannot always accurately predict the future load, and (ii) resource utilization is not always the right indicator for increased load. Each request in the trace is associated with an ML inference query, which is randomly picked from our model pool. We conduct simulation experiments to compare the schemes, using the profiled values (explained in Section  2.2 ) for four different well-known request arrival traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Table 1 provides an estimation of resource utilization on commercial systems underscoring the fact that compressing, encrypting and reliably storing the data, especially for (intermittent) edge servers is a bigger challenge in contrast to classical cloud storage servers. Classically, video data is streamed simultaneously to compute and storage systems for various processing tasks, such as inference, exemplar selection, and storage, thereby increasing I/O bandwidth and system processing demands. The Challenges:  In edge computing architectures, the  lack of data reuse  between the analytics and video data archival poses significant challenges.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Towards this, we build a lookup table by averaging the variance of output vectors of multiple test cases. The higher the variance the more conÔ¨Ådent is the classiÔ¨Åcation. This table, which we call the  conÔ¨Ådence matrix , gives us the conÔ¨Ådence of each sensor for each class, and can be used as a weight for majority voting.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "(c) illustrates the trade-off between the precision level and reuse ratio. (a) Distance vector. -5 5 15 25 \n1 225 449 673 897 1121 1345 1569 1793 2017 2241 \nDistance \nPixel ID \ndistanceY distanceX \n-10 \n-5 \n0 \n5 \n10 \n0 10 20 \nDistance-x \nDistance-y \n(b) (0.00, 1.57, -0.73) \n-20 0 20 40 60 \n1 202 403 604 805 1006 1207 1408 1609 1810 2011 2212 \nDistance \nPixel ID \ndistanceY distanceX \n-10 -5 0 5 10 \n0 20 40 60 \nDistance-x \nDistance-y \n(c) (0.52, 1.05, -0.73) \nFig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "For sustainability, we use solar power to perform our compute. For annotating the incoming video stream we use three teachers models, namely, ResNet101 [ 32 ], YOLOV2 [ 22 ], and VGG16 [ 87 ]. Since our dataset is from Bellevue, WA, we took the SOLRAD solar radiation data [ 25 ] (managed and published by National Oceanic and Atmospheric Administra- tion, NOAA) of Seattle, WA (the SOLRAD center closest to Bellevue and hence we believe is a good approximation).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "2017. [33]  Naoya Muramatsu, Chun Wei Ooi, Yuta Itoh, and Yoichi Ochiai. Deep- Holo: Recognizing 3D Objects Using a Binary-Weighted Computer-Generated Hologram.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "This task dynamically adapts to changing traffic patterns and environmental conditions. Urban Mobility ‚Äì A Case Study in Continuous Learning:  To thoroughly understand this data flow, let us examine ‚Äúurban mobility‚Äù, a prevalent continuous learning task (Bhardwaj et al., 2022). These data are can then be moved to a central facility where they can be further treated for efficient retrieval ans on demand streaming.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power. Therefore, the the RCA should be built on the basis of a low power hardware design that is upwardly reconÔ¨Ågurable to higher power scenarios rather than the reverse. One approach to achieve lower RCA power is to limit precision.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "The lecture slides/videos are expected to be stored until their useful lifetime, and they will also be made available via YouTube. Finally, the curriculum materials will be stored as long as they are used to enhance the courses that PIs teach at Penn State. We will also carve up short lecture materials based on the project and preserve them on departmental machines.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "We discuss the edge storage architecture followed by the choice of neural codec and their design. 3 Data Compression using Neural Codec \nIn this section we go over the overall design and design choices for the neural codec design of Salient Store  . 3.1 Salient Store  Storage Architecture: \nSalient Store  edge storage architecture is crafted to optimize data-flow and computational effi- ciency in continuous learning edge servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "CherryPick: Adap- tively Unearthing the Best Cloud Configurations for Big Data Analytics. In  (NSDI) . [2]  Marc Brooker, Andreea Florescu, Diana-Maria Popa, Rolf Neugebauer, Alexandru Agache, Alexandra Iordache, Anthony Liguori, and Phil Piwonka.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "50% 60% 70% 80% 90% 100% \n0.07% 0.28% 0.40% 1.10% 1.30% \nAccuracy Drop \n(a) V1 \n50% \n60% \n70% \n80% \n90% \n100% \n0.70%0.80%1.10%1.30% 2% \nAccuracy Drop \n(b) V2 \nFig. 10: Tradeoff between accuracy drop and energy saving for (a) V1 and (b) V2 picked from the VIRAT [33] dataset. the baseline; Region Level Reuse Scheme (e.g., FI+SI+PI) has better performance, because this ‚Äúshallow‚Äù model beneÔ¨Åts more from partial inference.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "For the remaining frames however, we invoke Algo. 1 to make the frame-level decision (i.e., either do the full inference or skip) 3 . When skipping, we can simply bypass the inference task by reusing  the inference result from the last frame; otherwise (i.e., if cannot skip), the full inference has to be performed for the current frame, in the same fashion as in the baseline.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "This indicates two memoization buffers are sufÔ¨Åcient. 5: In  EA , (a) shows that, on average, how many frame(s) from the current frame to a previous one with the same head orientation, as denoted as reuse distance. to Ground Truth(G) \nPrecision \nReuseRatio PSNR \n(c) Precision vs. reuse ratio tradeoffs \nFig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Moreover, the reuse between both eyes is further optimized by  AE . along with  P  and  F , due to their dependencies. However, if  T 2  does not change across frames,  P  is identical to the previous frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Accessed: 2024-04-27. [55] Yuxian Gu, Li Dong, Furu Wei, and Minlie Huang. Minillm: Knowledge distillation of large language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Workload:  As shown in Table  5  we use image-classiÔ¨Åcation and Sentiment Analysis (text) applications with two datasets each for our evaluation. Sentiment analysis outputs the sen- timent of a given sentence as positive negative and (or) neu- tral. We use 9 different prominently used text-classiÔ¨Åcation models from transformers library [ 81 ] (details available in appendix) designed using Google BERT [ 30 ] architecture trained on  SST  [ 72 ] and  SemEval  [ 66 ] dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "6. Data Lineage and Reproducibility \nAll three PIs are fully committed to ‚Äúreproducibility‚Äù and open access policy. In addition to the data de- scribed above, they will also generate and maintain ‚Äúannotations‚Äù attached to i) the libraries used in com- piler and runtime system source codes, and ii) the characterization and experimental data generated by the project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "In fact, a recent study from CSET [100] estimates that the cost of building LLMs will move to trillions in roughly 36 months! It is also equally important to note the impact of LLMs on the environment. These numbers are astonishing and underline the intense interest and investment that this domain has garnered.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "[104] C.-H. Go, M. Sandler, V. Sze, \nand H. Adam, ‚ÄúNetadapt: Platform-aware neural network adaptation for mobile applications,‚Äù in  Proceedings of the European Conference on Computer Vision (ECCV) , 2018, pp. 285‚Äì300.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "2016. (2019). [47]  Anjul Patney, Marco Salvi, Joohwan Kim, Anton Kaplanyan, Chris Wyman, Nir Benty, David Luebke, and Aaron Lefohn.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "[9]  Charles Thomson, ‚ÄúReality capture 101: point clouds, pho- togrammetry and LiDAR,‚Äù  ‚Äùhttps://bit.ly/3xfqvqy‚Äù , 2019. [10]  C. Choy, J. Gwak, and S. Savarese, ‚Äú4d spatio-temporal convnets: Minkowski convolutional neural networks,‚Äù in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. [11]  A. Corning, ‚ÄúAR/VR in the OR ‚Äì Surgical Applications of Augmented and Virtual Reality,‚Äù  ‚Äùshorturl.at/fqwAJ‚Äù , 2021.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "[187] Yusen Zhang, Ruoxi Sun, Yanfei Chen, Tomas Pfister, Rui Zhang, and Sercan √ñ Arik. Chain of agents: Large language models collaborating on long-context tasks. In  Advances in Neural Information Process- ing Systems , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "1 and Sec. 2.2.3. In the  Inter-Holo  scenario shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 21,
    "augmented": false
  },
  {
    "text": "Next, we solve for the second objective function ( O 2 ) by minimizing  ¬µ C , while maintaining the target accuracy. For  N  models, where each model has a minimum accuracy ‚Äò a ‚Äô, we model the ensemble as a coin-toss problem, where  N  biased coins (with probability of head being  a ) are tossed together, and we need to Ô¨Ånd the probability of major- ity of them being heads. min ¬µ C  : \b Acc target  ‚â• Acc target  ¬± Acc margin \n( O 2 )  is solved by resizing the model list of size  N  and fur- ther through intelligence resource procurement (described in section  4.2 ), and thus maximizing  P f  and minimizing  k  simul- taneously.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 173,
    "augmented": true
  },
  {
    "text": "As can be seen from Table IV, MCDNN yields similar latency/energy savings with our approach, but with signiÔ¨Åcantly lower accuracy ( 36 . 9% ). This is mainly because, in MCDNN, the scheduler tends to choose YOLOv4-tiny due to the low energy budget.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "The Ô¨Årst iteration shows the accuracy with the unchanged conÔ¨Ådence matrix. The noisy data is generated by adding a Gaussian noise (with maximum SNR of 20dB) over the unseen test data. Even though the accuracy claim of the models was nearly 85%, in the Ô¨Årst iteration, the accuracy drops below 80% because of the added noise.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "6 , compared to RAHT, our proposal reuses the intermediate Morton codes, which have been computed during the geome- try compression, to precisely identify the points with similar attributes from a set of irregular points. This is expected to be much faster than RAHT, and in fact, our experimental results show  ‚âà 49 √ó  speedup (53 ms  vs 2 . 6 s ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Sun, ‚ÄúIdentity mappings in deep resid- \nual networks,‚Äù in  European conference on computer vision . [32] K. He, X. Zhang, S. Ren, and J. Springer, 2016, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "4.2 NExUME on Publicly Available Datasets \nDatasets:  For image data, we consider the Fashion-MNIST (Xiao et al., 2017) and CIFAR10 (Alex, 2009) datasets; for time series sensor data, we focus on popular human activity recognition (HAR) datasets, MHEALTH (Banos et al., 2014) and PAMAP2 (Reiss & Stricker, 2012); and for audio, we use the AudioMNIST (Becker et al., 2023) dataset. Inference Deployment Embedded Platforms:  For commercially off-the-shelf micro-controllers, we choose Texas Instruments MSP430FR5994 (Instruments, 2024a), and Arduino Nano 33 BLE Sense (Arduino, 2024) as our deployment platforms with a Pixel-5 phone as the host device. The host device is used for data logging‚Äîcollecting SLOs, violations, power failures, etc., along with running the ‚Äúbaseline‚Äù inferences without intermittency.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 256,
    "augmented": false
  },
  {
    "text": "Motivated by such degradation of  peripheral visual acuity , foveated rendering  reduces computational costs for the peripheral region, and maintains high/normal resolution only for the foveal re- gion [ 2 ,  22 ,  24 ,  25 ,  30 ,  47 ,  62 ]. In fact, prior research on HVS has shown that human eyes are able to observe beyond 135 ¬∞  vertically and 160 ¬∞  horizontally, but see fine details within an only around 5 ¬∞  central circle (i.e.,  foveal vision ). For instance, a real-time gaze-tracked foveated rendering system is proposed to yield performance and memory savings by avoiding shading up to 70% of the pixels for VR headsets [ 47 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "This processing can be quite time-consuming, and our proÔ¨Åling shows that it usually takes  ‚âà 5 . Instead, our proposal takes advantage of the Morton code generated in the geometry compression, which is a good indicator for attribute similarity (as discussed earlier in Sec. 9 s  to compress one predicted PC frame even when running on 4 CPU threads.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Recently,  Point Cloud  (PC) consisting of millions of points, which capture the 3D geometry and attributes (e.g. RGB colors), has become an important modality for such realistic representations for applications like AR/VR, \n* Work was done while at Penn State. gaming, autonomous driving, etc.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Latency (ms) \n(d)  Twitter-trace:  Relaxed  workload. Figure 7:  Latency Distribution of  InFaas ,  Clipper  and  Cocktail  for two workload mixes using both Wiki and Twitter traces. Strict Relaxed 0 \n20 \n40 \n60 \n80 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(a)  Wiki Trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "This leads us to our next question ‚Äì  Can we do better? To explore the reuse opportunities at a Ô¨Åner granularity, we now dive into a tile/region-level study. 1) Partial Inference:  To further explore the computation reuse opportunities, we revisit the Ô¨Årst scenario illustrated in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Abstract ‚ÄîMany recent works have shown substantial efÔ¨Åciency boosts from performing inference tasks on Internet of Things (IoT) nodes rather than merely transmitting raw sensor data. However, such tasks, e.g., convolutional neural networks (CNN), are very compute intensive. They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "The challenge was to learn this function, i.e. A similar problem, in terms of generating faces, paintings etc. to de- vice a transformation function which can mimic the sensor signal given the aactivity and the sensor states.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "), GPU (to execute hologram), Mem (for data accesses), and the SoC (the remaining hardware components, e.g., codec, network), with different number of depth planes (ranging from 2 to 16), as shown in Fig. 8a. One can observe from this figure that, when the number of depth planes is increased, the power consumptions of  SoC  and  CPU  do not change much, while, in contrast, both the GPU  and  Mem  consume more power.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Our experimental results show 34% computation reduction and 17% energy savings, compared to the state-of-the-art [28]. In the future, we would also like to explore other opportunities to improve energy efÔ¨Åciency and tune the computation pipelines to cater more towards VR applications. We believe, given that the current VR devices are battery-backed, these kinds of energy savings and performance improvements will not only enable the users to experience longer videos, but also encourage both industry \nand academia to work further on improving the pipeline to make VR more pervasive and versatile.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": ". Define a binary dropout mask  m  = [ m 1 , m 2 , . The idea is to use the sensitivity to determine the probability: \np i  = Œ≤   P \nj ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \nmax \u0010P \nj ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \u0011 +  œµ \nwhere  Œ≤  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "Moreover, the two  P 1  points are located closely (i.e.,  [ 12 , 8 , 13 ]  vs  [ 12 , 8 , 12 ] ), and contain very similar attribute values ( 52  vs  51 ). Thus, the P-Frame can also be further compressed by reusing the P 1  data in the previous I-Frame, without losing too much quality. On the other hand, the two  P 2  points are relatively far away from each other and their attribute inputs are quite different, offering little reuse opportunity.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "Thorough characterization and analysis of large transformer model training at-scale. Proc. ACM Meas.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "Abstract ‚ÄîAs Point Clouds (PCs) gain popularity in processing millions of data points for 3D rendering in many applications, efÔ¨Åcient data compression becomes a critical issue. This is because compression is the primary bottleneck in minimizing the latency and energy consumption of existing PC pipelines. Data compression becomes even more critical as PC processing is pushed to edge devices with limited compute and power budgets.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Restrictions apply. A. Video Inference on Mobile Platforms \nThe key difference between a video-based DNN application and other popular DNN inferencing applications like natural language processing (NLP) or speech-to-text is that, the former interacts with video frames which are either captured from the camera or downloaded/streamed from internet and hence, has a strict latency requirement for performing inferencing within the frame deadline.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "The reconstruction error of a feature map  F i  is calculated as: \nRE i  =  ‚à• F i  ‚àí ÀÜ F i ‚à• 2 \nwhere   ÀÜ F i  is the reconstructed feature map, and  ‚à•¬∑ ‚à• 2  denotes the L2 norm. Define the dropout probability  p i  for neuron  i  based on the reconstruction error of its corresponding feature map. The idea is to use the reconstruction error to determine the probability: \np i  = Œ≥  RE i max( RE ) +  œµ \n18 \nwhere  Œ≥  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "All these are possible avenues for optimization and demand a detailed study of the computa- \ntion pipeline, the workloads, user behavior, etc., to Ô¨Ånd a way to further improve the state-of-the-art. ‚Ä¢  Furthermore, a software-only approach may not give us the desired solution as some of these additional execution cycles, control and data path manipulations may need ar- chitectural support, especially to reduce memory and power overheads on edge VRs. Therefore, we believe that, achiev- ing beneÔ¨Åts by exploiting the  EA  and  AE  opportunities needs an extensive study and a careful design, especially from an architectural perspective, to maximize the beneÔ¨Åts.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "https://www.eideticom. com/media/attachments/2020/06/03/noload-compression-zfs.pdf . (Accessed on 11/13/2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Since we have multiple teacher models, each of them contributes to the exemplar set, making it robust and removing bias. To efÔ¨Åciently implement the exemplar selection algorithm,  Us. ¬¥as implements the major portions using ‚Äúcustom hardware‚Äù (dis- cussed in ¬ß IV-A ).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "[51] F. G. VR360, ‚ÄúVirtual guided tour of Paris.‚Äù ‚Äùhttps://www.youtube.com/ watch?v=sJxiPiAaB4k‚Äù, 2019. [52] Wikepedia, ‚ÄúEquirectangular Projection.‚Äù ‚Äùhttps://en.wikipedia.org/wiki/ Equirectangular projection‚Äù, 2019. [53] Wikipedia, ‚ÄúPixel 2,‚Äù ‚Äùhttps://en.wikipedia.org/wiki/Pixel 2‚Äù.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Define the energy budget E b  for a single quanta and for the entire inference. Let  Q  represent the set of execution quanta, where each quanta  q  ‚ààQ  is defined by a tuple  ( l, e ) : q  = ( l, e ) Here,  l  is the number of loop iterations and  e  is the estimated energy required for these iterations. The goal is to optimize the loop iteration parameter  l  such that the energy consumption  E q  for each quanta  q  is within the energy budget  E b : \nminimize X \nq ‚ààQ E q subject to E q  ‚â§ E b \nTraining with Learning Sparse Masks Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask parameters  z , and scaling factor  Œ± .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 197,
    "augmented": true
  },
  {
    "text": "In  2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS) , pages 742‚Äì755, 2019. [191] Tianyu Zhao, Sharan Narang, Kelvin Guu, Angela Fan, Oriol Vinyals, William W Cohen, and Wei Lu. Measuring massive multitask language understanding.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "As shown in Fig. ¬¥as to effectively perform more computation with an intermittent power source. 11b ,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "Aligned with the departmental BPC plan, the students working on this project will participate in various diversity, equity, inclusion and belonging (DEIB) DEIB activities. ‚Ä¢  Summer Camp for Middle School Girls:  PI Das has been involved with organization of week-long sum- mer camps (funded by the CSE Department) targeted at middle school girls since 2017. Our earlier camps have already introduced participants to basic concepts in programming, building vision systems that assist visually impaired and learning skills towards building a basic embedded vision system, program- ming for robotics and exposure to various emerging tools in computing.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "[103] T.-J. Yang, A. Howard, B. Chen, X. Zhang, A. Go, M. Sandler, V. Sze, \nand H. Adam, ‚ÄúNetadapt: Platform-aware neural network adaptation for mobile applications,‚Äù in  Proceedings of the European Conference on Computer Vision (ECCV) , 2018, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "The interplay of multiple sensors making similar decisions un- der uncertainty and energy constraints naturally suggests a game-theoretic framework for modeling their interactions. Because sensors have limited energy and the net- work may operate for extended periods, each sensor must consider the future implications of its current actions. Choosing  NP  con- serves energy but forfeits any contribution or associated reward.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "7. IV-B) as plugable modules to the existing compute engines (e.g., CPU, GPU, etc. ), as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "The points within one segment are geometrically close to each other, and hence their attributes are also likely to be similar. Thanks to this, for each segment, we just need to store one medium  value as  Base  and several  residual  values as  Deltas (which are mostly small, due to similarity). And Ô¨Ånally, we quantize these deltas for achieving higher compression ratio.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "As shown in Figure 3a, the accuracy improves with increased latency, but with diminishing returns. Similarly, Figure 3b demonstrates that, while increasing capacitance should theoretically stabilize the system, its charging characteristics can lead to extended charging times, thus exceeding the latency SLO. This study involved adjusting the acceptable latency and the capacitance of the energy harvesting setup to assess their impacts on accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "These factors collectively restrict innovation, limit accessibility, and contribute to significant environmental impact due to high power consumption and carbon emissions, conflicting with global commitments to achieve carbon neutrality [14,17]. Thrust 2: System Support for  \nExpert Scheduling & Data  \nMovements \nThrust 1: Algorithmic Support for  \nEnsemble of Experts (EoE) \nThrust 3: Chiplet-based  \nAdaptive & Reconfigurable  \nHardware Platform \nExpert  Repository \n2.1 Data Locality &  \nParallelism-aware  \nTraining \n? 1.1 EoE Design Space Exploration 1.2 Constructing Morphology  \nof EoE \n1.3 Continual Adaptation of  \nExperts \nExperts \nExpert Routing  Functions \nComposition  \nfunctions Independent training possible \nExplore \nStore \nExplore Morphologies \nTree EoE Graph EoE \nChain EoE \nSplitting \nMerging \nGrowing Shrinking \nMinimal Retrain Overheads \n1.4 Algorithmic Choices informed  \nby System & Hardware  \nConstraints MORPH (Graph Pruning/ \nGraph  Reconstruction/  \nExpert  Selection) \nBased  \non \n... \nSystem/Resource  Constraints \n2.2 Router  Retraining \nSystems Constraints/Decisions \n?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 259,
    "augmented": false
  },
  {
    "text": "[43]  Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, ‚ÄúGradient-based learning applied to document recognition,‚Äù  Proceedings of the IEEE , vol. 86, pp. 2278‚Äì2324, Nov 1998.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "On the other hand, for applications that demand very small compressed data sizes to transfer through the network, the threshold condition can be relaxed to favor the  direct reuse  more. Further, for the P-frame, as discussed above, the pre-deÔ¨Åned threshold for determining the block matching (i.e., is the  <  I , P  >  block pair good/similar match or bad/dissimilar match) can be tuned according to the application preference, e.g., for applications which favor good quality, more post-intra-encoded blocks (e.g., store and encode the deltas instead of simply reusing) are preferred. SpeciÔ¨Åcally, in our design, the PC frames are encoded in an ‚ÄúIPP‚Äù fashion, where each I-frame is followed by two P-frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "The actual parallelism granularity  aG ‚â§ G  for a layer is decided by the harvested power level. If we allow  aG ReRAMs to perform the concerned layer‚Äôs computations in parallel, the input data should be divided into  aG  partitions. In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "1 , our experiments, on different modalities, shows the accuracy degradation due to data drift. However, with a proper retraining, the smaller model could keep up with the original accuracy. SpeciÔ¨Åcally focuing on video data, we observe that: using quantized MobileNet-v2 (14M paramters, 71.3% accuracy) as the small model and ResNet-101 (171M parameters, 76.4% accuracy) as the large model, the accuracy of the smaller model has degraded  >  20% over 5 sampling windows (of 4 hours each), where as the effect is minimal in the larger model.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "2017. PowerChief: Intelligent power allocation for multi-stage applications to improve responsiveness on power con- strained CMP. In  Computer Architecture News .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "Figure 10: (a) comparison between i: raw PC and our proposals (ii: intra, iii: intra-inter-V1, iv: intra-inter-V2). (b) PSNR v.s. compression ratio (i.e., input size / compressed size).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "With this design idea, the system can keep making forward progress over a large range of power incomes. Sections  V-A - V-C  develop a dynamic activation strategy for different power levels and Section  V-D discusses the transition strategy between dynamic activation solutions. A. Computation decomposition and parallelism \nIf the harvested power  P   budget   is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Large language models in healthcare: Breakthroughs, use cases, and challenges. Horovod: fast and easy distributed deep learning in tensor- flow, 2018. [142] Shaip.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "The batch size \nfor a function,  ùëì , is defined as  BatchSize  ( ùëì )  = j StageSLO  ( ùëì ) ExecTime  ( ùëì ) k \n(Algorithm 1  b  ). Batching reduces the number of containers spawned for each function by a factor of its batch size (Algorithm 1  b  ). Note that  ExecTime (f)  is estimated by aver- aging the execution times of the function obtained through \n159 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "These codecs can operate on generic computational hardware, such as GPUs and FPGAs, without the need for specialized video processing units, thus broadening their applicability across different device platforms. Such capabilities not only enhance user experience by minimizing buffering and maximizing video quality but also optimize bandwidth usage, presenting a cost-effective solution for content providers. This adaptability also extends to content delivery dynamics, where neural codecs can adjust the streaming quality in real-time, responding adeptly to fluctuations in network throughput and variations in device capabilities.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "In Augmented Reality, Virtual Reality, and Computer Graphics: 8th International Conference, AVR 2021, Virtual Event, September 7‚Äì10, 2021, Proceedings 8 , pp. 135‚Äì155. Springer, 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "305‚Äì308. [50] A. Vlachos, ‚ÄúAdvanced VR Rendering in Valve.‚Äù ‚Äùhttp: //media.steampowered.com/apps/valve/2015/Alex Vlachos Advanced VR Rendering GDC2015.pdf‚Äù, 2019. [51] F. G. VR360, ‚ÄúVirtual guided tour of Paris.‚Äù ‚Äùhttps://www.youtube.com/ watch?v=sJxiPiAaB4k‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Most of these works rely on software checkpointing (static and dynamic (Maeng & Lucia, 2018), refer ¬ßAppendix C) to save and restore, while some of the prior works developed nonvolatile hardware (Ma et al., 2016, 2017) which inherently takes care of the checkpointing. Considering the scope of these initiatives, it is crucial to acknowledge that, despite the substantial support for energy harvesting and intermittency management, developing intermittency-aware applications and hardware necessitates multi-dimensional efforts that span from theoretical foundations to circuit design. Intermittent DNN Execution/Training:  As the applications deployed on such EH devices demand analytics, executing DNNs on EH devices and EH-WSNs have become prominent (Lv & Xu, 2022; Gobieski et al., 2019; Qiu et al., 2020; Mishra et al., 2021).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 226,
    "augmented": true
  },
  {
    "text": "5a ) incorporates all the aforementioned points. Note that,  Us. ¬¥as  introduces a design philosophy for building a morphable hardware, and it can easily be adapted by any of the systolic array based commercial off the shelf (or research prototype) DNN training accelerators.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "[53]  MPEG, ‚ÄúMPEG Point Cloud Compression,‚Äù  ‚Äùhttps://mpeg- pcc.org‚Äù , 2022. [54]  MPEG, ‚ÄúPoint Cloud Video: Loot,‚Äù  ‚Äùhttps://bit.ly/3QXDsPf‚Äù , 2022. [55]  MPEG, ‚ÄúPoint Cloud Video: Redandblack,‚Äù  ‚Äùhttps://bit.ly/ 3NyQq2R‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "The relative invocation frequency of a function is measured with respect to the application it consti- tutes. The same function belonging to multiple applications can, therefore, have distinct weights in each application. To analyze the benefits of using invocation frequency, we designed a probability-based policy that employs weighted container scaling.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "The RCA is powered by harvesting ambient energy and employs a separate, very small capacitor as its only energy storage medium, primarily for power smoothing, similar to prior energy-harvesting NVP designs [ 17 ], [ 21 ], rather than as a task-scaled energy reservoir [ 22 ]. ResiRCA architecture overview \nto the network. Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input/output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Our game-theoretic model enables sensors to make optimal participation de- cisions based on energy levels, data quality, and collective inference impact, fostering cooperative behavior while managing individual energy con- straints. The federated learning framework ac- commodates intermittent participation and vari- able data quality, ensuring robust model training despite sensor unreliability. Simulation results demonstrate that our integrated approach signif- icantly enhances inference accuracy and energy efficiency compared to traditional participation strategies.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "https://www.ti.com/ product/MSP430FR5994 , 2024a. Accessed: 05/19/2024. Texas Instruments.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Accessed: 2024-04-27. [129] Ashutosh Pattnaik, Xulong Tang, Onur Kayiran, Adwait Jog, Asit Mishra, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. Opportunistic computing in gpu architectures.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "164 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \n98.80% \n99.20% \n99.60% \n100.00% \n0 \n10000 \n20000 \n30000 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(a) Social Network. Other \n3 These results are not shown in any graph. 98.50% \n99.00% \n99.50% \n100.00% \n0 \n10000 \n20000 \n30000 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 167,
    "augmented": true
  },
  {
    "text": "9. 4) Model-SpeciÔ¨Åc Analysis:  To study how the inference behavior changes across different DNN models, we next compare the performance and the energy consumption of two DNN models used in this work (YOLOv3 and YOLOv4-tiny), and plot the results in Fig. 8 and Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Furthermore, the proposed hardware is reconÔ¨Ågurable at a Ô¨Åne grain, to be able to dynamically activate different scaled computations, which can Ô¨Åt to the changing features of the underlying power resources. These knobs can be integrated to form sequential or pipelined computation modes. ‚Ä¢  Resilient computation scheduling:  We provide three knobs to schedule computation blocks in the proposed ar- chitecture: (i) loop tiling which decomposes MAC operations in a given layer (ReRAM) into small blocks, (ii) ReRAM duplication which provides opportunity to perform one-layer operations with multiple weight copies, and (iii) pipelining that can organize multiple ReRAM tiles to further exploit the har- vested power.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "As models grow larger, they re- quire exponentially more data, but the Chinchilla Law [64] indicates that, beyond a certain point, increasing model size without proportional data scaling yields diminishing returns. This scarcity of high-quality data constrains the effective training of larger models. In addition, the availability of clean and high-quality data is reaching physical limits.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "These processes create a complex data-flow pipeline, differentiating two streams of video data: one for real-time inference and training, and another for archival. This dual-stream processing consumes considerable system resources such as CPU, memory, and energy, further complicating the management for intermittently powered systems like U s. √°s (Mishra et al., 2024) where data integrity and security must be maintained during power disruptions   1 . Table 1 provides an estimation of resource utilization on commercial systems underscoring the fact that compressing, encrypting and reliably storing the data, especially for (intermittent) edge servers is a bigger challenge in contrast to classical cloud storage servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "To search for the best architecture for the given intermittent environ- ment, DynNAS utilizes the approach proposed by iNAS (Mendis et al., 2021). After the network architecture is determined, DynFit is used to train the network considering energy intermittency, and DynInfer is employed to perform inference under intermittent power conditions. In this section, we elaborate on the key components, focusing on DynFit and DynInfer, and explain how they uniquely adapt DNN training and inference to intermittent power conditions.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "This is because, the Piezo  source is very weak and and the total completed number of inferences is quite small. Speculative action supported by power prediction can keep quite a few incomplete inferences to be completed in the next power cycle. This can also explain why the portions with the power source of  Thermal  are very small.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "0 \n1 \n2 \n3 \n4 \n5 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nNorm. Encryption Latency \nRSA Software RSA FPGA Lattice Software \nFigure 7: Proposed encryption vs the state-of-the-art normalized to the FPGA implementation of the lattice based encryption. Since majority of the storage systems are not limited to one storage server, but are spread across multiple servers, we scaled  Salient Store  by deploying it in a distributed fashion.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Although efÔ¨Åcient hardware accelerators [ 16 ], [ 27 ], [ 80 ] have been developed to do the same, these ac- celerators are typically designed with a ‚Äúthroughput-Ô¨Årst‚Äù \n895 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Optimizing data layouts for parallel computation on multicores. In  2011 International Conference on Parallel Architectures and Compilation Techniques , pages 143‚Äì154. IEEE, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Towards information-theoretic k-means clustering for image indexing. 11621‚Äì11631, 2020. Jie Cao, Zhiang Wu, Junjie Wu, and Wenjie Liu.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "R EDUCING  P ROJECTION  C OMPUTATION \nAs discussed in Sec. However, if  T 2  does not change across frames,  P  is identical to the previous frame. IV.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": ", and  How can we leverage ‚Äúapproximation opportunities‚Äù (based on the two observations above) to speed up hologram processing and save energy, while still maintaining a high QoS? Driven by these observations, we next want to study the details of hologram with the goal of addressing two critical questions:  What are the problems in the current state-of-the-art hologram software and hardware? 3 HOLOGRAPHIC PROCESSING STUDY \nTo leverage the opportunities in the holographic processing from a RGB-D (i.e., RGB and depth) image, we need to first understand the detailed execution of the entire hologram processing from both the algorithm and hardware perspectives.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "The output currents I1 and I2 are then computed as follows: \nI  =  I 1 +  I 2 =  G 1  √ó  V  1 +  G 2  √ó  V  2 \n23 \n(a) Re-RAM Cell \n(b) A Full Re-RAM tile \nFigure 5: DNN computation using ReRAM xBAR. Here, the output currents I1 and I2 are the result of the multiplication of the input voltages V1 and V2 by their respective weight values, which are summed together using the crossbar wires. Please refer to Figure 5a for more details.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "3. Battery (B) \nB \nEH \nƒÇ Sigmoid \n... \nReRAM Memory \nBasic MCU System \nB \nEH EH \nEH \nEH \nB \nFig. ResiRCA architecture overview \nto the network.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "[9]  Y. Feng, Shaoshan Liu, and Yuhao Zhu. ArXiv  (2021). 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "We use two different datasets, MHEALTH [12], [13], and PAMAP2 [16], [17], for our evaluation which follow the similar sensor setup described in Section IV-A. The DNNs were trained on the training data-sets using the Keras [18] framework. C. Accuracy Results \nBaseline:  We choose two baselines for our evaluation: 1) Baseline-1 consists of the original DNNs built along the lines of [11], [14] (without any pruning).",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "[3]  A. ShaÔ¨Åee, A. Nag, N. Muralimanohar, R. Balasubramonian, J. P. Strachan, M. Hu, R. S. Williams, and V. Srikumar, ‚ÄúISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars,‚Äù in  2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA) , pp. 14‚Äì26, 2016.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "1‚Äì12, 2016. [34]  M. Alwani, H. Chen, M. Ferdman, and P. Milder, ‚ÄúFused-layer cnn accelerators,‚Äù in  2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp. [35]  M. D. Lam, E. E. Rothberg, and M. E. Wolf, ‚ÄúThe cache performance and optimizations of blocked algorithms,‚Äù in  Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "In this section, we discuss the effectiveness of NExUME across two distinct types of environments, highlighting its versatility and broad applicability. Firstly, we evaluate NExUME using publicly available datasets (¬ß4.2) commonly utilized in embedded applications across multiple modalities‚Äîincluding image, time series sensor, and audio data. These datasets represent typical use cases in embedded systems where energy efficiency and minimal computational overhead are crucial.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "IEEE Access , 11:31866‚Äì31879, 2023. [85] Harsh Kumar, Jonathan Vincentius, Ewan Jordan, and Ashton Anderson. Human creativity in the age of llms: Randomized experiments on divergent and convergent thinking.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Implementation Methodology:  We developed a proto- type on top of Amazon EC2 and Lambda services to evaluate the some of the benefits of our proposed design choices. We use AWS as the testbed for conducting extensive experiments. The types of instance used in our evaluation include all the c5 and m5 instances for EC2.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Activation solution transition FSM \nThe convolution computations of one inference may not be completed while transitioning to a new power level. For small-scale applications with strong harvested power supply, discarding the incomplete execution may have only modest overheads. However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Again, the  box  object is still outside of the viewing window and thus, we do not need to compute its hologram. We use such a viewing-window based ‚Äúsub-hologram‚Äù technique which has already been proposed in prior works (such as Sub-Hologram [ 52 ]) as the  Baseline  design. Note also that, since the  soccer ball  hologram has been already generated in Frame-I , we can skip its computation.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Both the PWS and RS collect metrics, such as the current container count, load history and request rate for a function for a given time window, from  Prometheus  and the  Kubernetes system log, using the Replica Tracker and Load Monitor mod- ules. Although fetching function metrics incurs a latency in the order of tens of milliseconds, it is performed in the back- ground (during autoscaling) and hence, does not affect the critical path. The load to each function within each applica- tion is calculated separately using the collected information.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "1‚Äì51 vol.1. [35] Google Developers, ‚ÄúMediaCodec,‚Äù ‚Äùshorturl.at/mCHV4‚Äù, 2021. [36] S. S. Beauchemin and J. L. Barron, ‚ÄúThe Computation of Optical Flow,‚Äù ACM Comput.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Discussion:  For applications that are latency tolerant, we can potentially redirect requests from failed instances to existing instances, which would lead to increased tail latency. Thus,  Cocktail  is inherently fault-tolerant owing to the parallel nature in computing multiple inferences for a single request. We observe similar accuracy loss or lower for different probability failures of 5%, 10% and 25%, respectively (results/charts omitted in the interest of space).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "performing single shot  object detection for trafÔ¨Åc monitoring using the MobileNetV2  [ 51 ] model on the urban trafÔ¨Åc data set [ 97 ]. This is a trafÔ¨Åc video dataset containing 62GB of videos recorded from Ô¨Åve pole-mounted Ô¨Åsh-eye cameras in the city of Bellevue, WA, USA. Each video stream is recorded with a resolution of 1280  √ó  720 at 30fps.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Hence, rather than simply measuring the weights only in terms of function invocation frequency, we also need to account for DAG specific factors like  Commonality  and  Con- nectivity . The above discourse motivates us to rethink the design of serverless RM frameworks to cater to DDAs as well. One key driver for the design lies in a  Probability Estimation Model  for individual functions, which is explained below.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "4th EURASIP Conference focused on Video/Image Processing and Multimedia Communications (IEEE Cat. No.03EX667) , 2003, pp. 1‚Äì51 vol.1.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Motivated by this, we explore possibilities of designing an efficient synergistic sensor-host ecosystem (involving the EH-WSNs and host), where we try to maximize the compute at the sensor nodes, yet for the incomplete tasks, we use coresets to compress and send the data to the host where the rest of the computations could occur. H S/C \nM \nH: Harvest\n S/C: Sense & \nCompute\n M: Communicate \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nDecompress + Infer \n+ Ensemble¬† \nSensor state transition sensor \nHost Legend: \nFigure 3: An example of EH Sensor-Host ecosystem - the sensor transitions between multiple states and executes the compute as store and execute fashion [ 47 ]. [ 7 ,  8 ,  36 ,  37 ], they can also be quantized [ 37 ] to further reduce their computation and memory footprints.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 208,
    "augmented": true
  },
  {
    "text": "Inference with Learning Sparse Masks Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Otherwise, maintain or reduce the dropout rate to improve accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Solar energy harvesting for smart farming using nanomaterial and machine learning. In  IOP Conference Series: Materials Science and Engineering , Vol. 981.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Finally, if the frame falls under the category in which objects have not been signiÔ¨Åcantly displaced, then it is labeled as ‚ÄúPI‚Äù (as shown in Line  9  in Algo. 2, the overlapped area of each MV and BBox is examined to determine whether the object has moved ‚Äútoo far away‚Äù or not; if it has, the ‚ÄúFI‚Äù is triggered. Otherwise, as can be seen from Line  6  to Line  8  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Note that  Œ±  can be adjusted based on the application preference, e.g., shifting the  x  =  Œ±  line to the right results in more macro blocks in the I-frame being directly reused for compressing the P-frame, i.e., higher compression ratio, with a cost of quality drop (more details in Sec. V ). ‚Ä¢  Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "We will freeze some neurons of the expert while expanding the network with new parameters and retraining it on new datasets. To incorporate new knowledge, we will explore novel algorithms for expert-growing via life-long learning [147]. On the other hand, for knowledge integrity and resource efficiency, we will also explore innovative directions for expert shrinking by unlearning outdated knowledge that is no longer required.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Springer, 2005. [19]  Michael Alan Chang, Bredan Tschaen, Theophilus Benson, and Lau- rent Vanbever. Chaos monkey: Increasing sdn reliability through systematic network destruction.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "2021. SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA ¬© 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8638-8/21/11...$15.00 https://doi.org/10.1145/3472883.3486992 \nKeywords serverless, resource-management, scheduling, queuing \nACM Reference Format: Vivek M. Bhasi, Jashwant Raj Gunasekaran, Prashanth Thinakaran, Cyan Subhra Mishra, Mahmut Taylan Kandemir, and Chita Das.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Ensemble selection from libraries of models. In  Proceedings of the twenty-Ô¨Årst international conference on Machine learning , page 18, 2004. [17]  Rich Caruana, Alexandru Niculescu-Mizil, Geoff Crew, and Alex Ksikes.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Holographic Displays on AR:  Another large body of prior works focus on optimizing the holographic displays for the next- generation AR headsets [ 6 ,  17 ,  23 ]. For example, Michelson proposes a holographic display technology that optimizes image quality for emerging near-eye displays using two SLMs and camera-in-the- loop calibration [ 7 ]. Neural-Holography proposes an algorithmic hologram generation framework that uses camera-in-the-loop train- ing to achieve unprecedented image fidelity and real-time frame rates [ 48 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Do not distribute. Under review by the International Conference on Machine Learning (ICML). Preliminary work.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 24,
    "augmented": true
  },
  {
    "text": "Input data broadcast to all tiles is managed by a 64kB double- buffered input feature map SRAM (32kB each), requiring ‚åà [ X  √ó Y  √ó Z ] / 1024 ‚åâ iterations for full input loading, with each buffer loaded  [ X  √ó Y  √ó  Z ] / 2048 times. The convolution map transforms  [ X  √ó Y  √ó  Z ]   M √ó C √ó W √ó H ‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí [ M  √ó U  √ó V ]  to yield an output tensor of dimensions  [ M  √ó  U  √ó  V ] , supported by a 256 banked double buffered output feature map SRAM, each bank of size 8kB (4kB/buffer). A 128kB SRAM serves as a scratchpad for storing activations, transposes, and intermediate differentials during the backward pass.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 213,
    "augmented": false
  },
  {
    "text": "For example, a per- formance counter exposing data movement traffic in NoC can be used by runtime support to shuffle the expert to chiplet mappings. Thus, by investigating all the HW-SW co-optimizer pairs, we envision boosting the overall performance. In addition, the plug-and-play nature of chiplet provides better ‚Äúfault isolation‚Äù, as only the faulty chiplet can be changed as opposed to throwing away an entire chip.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "[26]  J. Hu, A. Shaikh, A. Bahremand, and R. LiKamWa, ‚ÄúCharac- terizing real-time dense point cloud capture and streaming on mobile devices,‚Äù in  Proceedings of the 3rd ACM Workshop on Hot Topics in Video Analytics and Intelligent Edges , 2021, pp. 1‚Äì6. 296 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "With the PI scheme, as shown in Fig. 8d and Fig. 8a.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pp. Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl: Incremental classifier and representation learning.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "https://doi.org/10.1145/3466752. 3480056 \n1 INTRODUCTION Augmented reality (AR) has gained recent traction in both the con- sumer and research communities, thanks to the advances in efficient and low power computing technologies, high-speed communica- tion, and specialized hardware platforms. These technologies have become an important part of our daily life, in the form of creative photography, content creation, gaming, online shopping, virtual touring, and educational and non-educational training, etc.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "[15]  William H Beluch, Tim Genewein, Andreas N√ºrnberger, and Jan M K√∂hler. Machine learning , 36(1-2):105‚Äì139, 1999. An empirical comparison of voting classiÔ¨Åcation algorithms: Bagging, boosting, and variants.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "This model balances anticipated energy availability, local data quality, and global benefit to establish stable and cooperative equilibria, opti- mizing the energy-accuracy trade-offs. Unlike con- tinuous on-edge training, we employ periodic or triggered fine-tuning sessions aligned with equilibrium strategies, en- suring robust and progressively improving global models. ‚Ä¢  Federated Learning Integration:  We introduce a fed- erated learning-based framework tailored for intermittent participation and heterogeneous data quality.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "tome01.com/exploring-llms-real-world-case-studies-in-ai-generated-art- literature , 2024. Accessed: 2024-10-22. [4] The state of ai in early 2024: Gen ai adoption spikes and starts to generate value.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "[15] K. Han, A. W. Min, N. S. Jeganathan, and P. S. Diefenbaugh, ‚ÄúA Hybrid Display Frame Buffer Architecture for Energy EfÔ¨Åcient Display Subsystems,‚Äù in  International Symposium on Low Power Electronics and Design (ISLPED) , 2013, pp. 347‚Äì353. [16] T. HARDWARE, ‚ÄúMagic Leap One Powered by Nvidia Tegra TX2, Available Summer.‚Äù ‚Äùhttps://support.oculus.com/248749509016567/‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "To perform multiplication-addition, we first apply the input voltages V1 and V2 to the rows of the crossbar array. The conductance values G1 and G2 of the ReRAM devices are set to the corresponding weight values for the multiplication operation. The output currents I1 and I2 are then computed as follows: \nI  =  I 1 +  I 2 =  G 1  √ó  V  1 +  G 2  √ó  V  2 \n23 \n(a) Re-RAM Cell \n(b) A Full Re-RAM tile \nFigure 5: DNN computation using ReRAM xBAR.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "We outperform the MCDNN [7] and Euphrates [9] in terms of accuracy, and Potluck [12] and DeepCache [8] in terms of performance improvement. II. B ACKGROUND AND  R ELATED  W ORK \nIn this section, we start our discussion by explaining a typical DNN execution on mobile devices for video analytics.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "If it be- comes too large and slow to run, increase  Œª 2 . By keeping  Œª 1 , Œª 2  within reasonable bounds, we ensure that the modified gradient   b ‚àá J ( Œ∏ )  remains well-behaved, preserving the conditions for SGD convergence. If the model overfits high-SNR data, increase  Œª 1 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "1109/ICRA.2014.6907021 [56]  K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, J. Samp- son, M. T. Kandemir, and V. Narayanan. 2020. ResiRCA: A Resilient Energy Harvesting ReRAM Crossbar-Based Accelerator for Intelligent Embedded Processors.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Temporal Locality for the User Interests:  As also established by prior foveated rendering proposals, the foveal vision (or Region of Focus, RoF) is only a small region in the current scene and can be traced by eye tracking techniques [ 26 ]. Therefore, one opportunity to reduce the amount of computation is to  approximate  the hologram processing based on the objects‚Äô distances and sizes. 3a, the bike  object is closer to the user, and also has a larger range/size ( size=farmost-nearest ); thus, more information is required to create the hologram for the  bike  for maintaining fairly good QoS than the  chair .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "Augmented Reality in Surgery. Archives of Surgery (2004), 170‚Äì174. [57]  Randall Shumaker and Lackey Stephanie.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "Re- sults are normalized (higher the better). Second, it utilizes dis- tributed autoscaling poli- cies to reduce the la- tency variability and re- source consumption of hosting ensemble mod- els. Figure 1:  BeneÔ¨Åts of  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Moreover, we also implement the memoization option so that it does not have to repeat infer- ences if it encounters similar data, thereby saving substantial energy as well as delivering results with extremely low la- tency. Prior studies [ 56 ,  64 ,  68 ] and our empirical analysis on the quantization vs accuracy trade-offs (see Fig. 2c) indicate the 16 and 12bit precision to maximize the accuracy of the inferences while minimizing the energy consumption.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "¬¥as on a real-world trafÔ¨Åc dataset indicates that our continuous learning approach simultaneously improves both accuracy and efÔ¨Åciency: Us. ¬¥as offers a 4.96% greater mean accuracy than prior approaches while our morphable accelerator that adapts to solar variance can save up to  { 234.95kWH, 2.63MWH } /year/edge-server compared to a  { DNN accelerator, data center scale GPU } , respectively. Our evaluation of Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Strict Relaxed 0 \n50 \n100 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace. Strict Relaxed 0 \n20 \n40 \n60 \n80 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(a)  Wiki Trace. Figure 8:  Cost savings of  Cocktail  compared to three schemes.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "1 Introduction \nMachine Learning (ML) has revolutionized user experience in various cloud-based application domains such as product recommendations [ 70 ], personalized advertisements [ 44 ], and computer vision [ 13 ,  43 ]. It is imperative for these applications to deliver accurate predic- tions at sub-millisecond latencies [ 27 , 34 , 35 , 39 , 44 , 83 ] as they critically impact the user experience. For instance, Facebook [ 44 ,  82 ] serves trillions of inference requests for user-interactive ap- plications like ranking new-feeds, classifying photos, etc.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "Yang, A. Howard, B. Chen, X. Zhang, A. 289‚Äì304. Go, M. Sandler, V. Sze, and H. Adam, ‚ÄúNetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications,‚Äù in  Proceedings of the European Conference on Computer Vision , 2018, pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "We use  Python Sanic  web-server for commu- nication with the master and worker VMs. Each worker VM runs tensorÔ¨Çow-serving [ 60 ] to serve the inference requests. Load Balancer : The master VMs runs a separate thread to monitor the importance sampling of all individual model pools.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Figure  16a  plots the latency reduction and accuracy boost when compared to  InFaaS  (baseline). While able to reduce 60% of the models used in the ensemble,  Cocktail  also re- duces latency by up to 50% and boosts accuracy by up to 1.2%. Cocktail  was also able to deliver modest accuracy gain \n1052    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nConst1 Const2 Const3 Const4 \nBaseline \n0 \n20 \n40 \nLatency-reduction \n0.50 \n0.75 \n1.00 \nAccuracy-Gain \n(a)  Image ClassiÔ¨Åcation:Cifar100.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "To address this, we need to study the impact of head orientation on the computation and whether we can establish a relationship between the computation executed for both the eyes to get rid of any existing redundancies. All these are possible avenues for optimization and demand a detailed study of the computa- \ntion pipeline, the workloads, user behavior, etc., to Ô¨Ånd a way to further improve the state-of-the-art. IV-C), and one edge VR headset cannot afford to memoize them for all  possible head orientations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "These works focus on the pixel content reuse, which is the last stage ( Projection Mapping ) in the  360 ¬∞ video projection pipeline (discussed in Sec III). However, none of these existing schemes leverage reducing the large amounts of ‚Äúredundant‚Äù computations in the preceding stage (projection computation). 251 \nOur proposed  EA  and  AE  designs focus on these intensive projection computations, and as such are orthogonal to these prior efforts.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "1. Because of this, recently, alternate hardware-based solutions have been proposed to improve the com- putational efficiency by replacing the expensive transcendental cal- culations with lookup table (LUT) based memoization [ 35 ], or miti- gating the data movement overheads by employing a customized buffer on-chip [ 32 ], or simply offloading computations to cloud then streaming back [ 16 ,  27 ,  67 ]. While such an approach improved the computational efficiency and reduced power consumption to some extent, rethinking the design of hologram software/hardware con- sidering the unique features of the AR holographic applications (as discussed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "[98] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning. ACM, 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "Designing HSPM Accelerator on CSD FPGA:  The HSPM hardware is characterized by its fully parallelized design, incorporating 128 Multiply-Accumulate (MAC) units for handling polynomials of degree  n  = 256 . Each MAC unit within the HSPM architecture is capable of conducting two parallel modular multiplications. This is achieved through the use of a single Digital Signal Processing (DSP) block that operates on signed data representation.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "[ 7 ,  8 ,  36 ,  37 ], they can also be quantized [ 37 ] to further reduce their computation and memory footprints. Motivated by this, we explore possibilities of designing an efficient synergistic sensor-host ecosystem (involving the EH-WSNs and host), where we try to maximize the compute at the sensor nodes, yet for the incomplete tasks, we use coresets to compress and send the data to the host where the rest of the computations could occur. H S/C \nM \nH: Harvest\n S/C: Sense & \nCompute\n M: Communicate \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nDecompress + Infer \n+ Ensemble¬† \nSensor state transition sensor \nHost Legend: \nFigure 3: An example of EH Sensor-Host ecosystem - the sensor transitions between multiple states and executes the compute as store and execute fashion [ 47 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 208,
    "augmented": false
  },
  {
    "text": "IEEE, 2017, pp. 550‚Äì555. [51]  C. Moreno, Y. Chen, and M. Li, ‚ÄúA dynamic compression technique for streaming kinect-based point cloud data,‚Äù in 2017 International Conference on Computing, Networking and Communications (ICNC) .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Thus,  Kraken  makes use of PWS and RS to scale containers to meet the target SLOs while simul- taneously minimizing the number of containers by making use of function invocation probabilities, function batching, and container eviction, where appropriate. Subsequently, it triggers container scaling  6  by calculating the additional containers needed to mitigate the delay. Second, a Function Idler component  7b  evicts containers from memory  6  when an excess is detected.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "For two instances of the same class, there should be a very high correlation in the sensor data. We empirically measure this by testing for correlation between the sensor signatures of different classes. Conservatively, we choose a correlation coefficient  ‚â• 0 .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "In  2019 IEEE International Conference on Cluster Computing (CLUSTER) . 1‚Äì13. https://doi.org/10.1109/CLUSTER.2019.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "From this figure, one can observe the following: First, in general, these two steps take similar times to execute, due to the similar procedures they \nAlgorithm 1:  Depthmap Hologram Algorithm [4, 18]. Input : M : Number of depth planes Input : DP [ i ] : Pixels in the  i th   depth plane Output: Holo–¥ram : Generated hologram \n1  procedure  Depthmap _ Holo–¥ram ( M ,  DP ) // main \n2 // Step-1: Forward-propagate \n3 for  i  in  [ 1 ,  M ]  do // planes in parallel \n4 for  p  in  DP[i]  do // pixels in parallel \n5 IntraPlane i  =  HP 2 DP ( i ,  p ) \n6 IntraBlockSync (IntraPlane[i]) \n7 Inter BlockSync () \n8 // Step-2: Backward-propagate \n9 for  i  in  [ 1 ,  M ]  do // in parallel \n10 for  p ‚Ä≤   in  IntraPlane[i]  do // in parallel \n11 Hologram[ p ‚Ä≤ ] +=  DP 2 HP ( i ,  p ‚Ä≤ ) \n12 Inter BlockSync () \n13 return  { Holo–¥ram } \nemploy, as shown in Algo. 1.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 302,
    "augmented": true
  },
  {
    "text": "the learner classiÔ¨Åed  ‚âà 4.5 frames/100-frames (on an average) as exemplar data. And, over 40 hours of continuous learning, we get  ‚âà 5.02 frames/100-frames as exemplar data (resulting in  ‚âà 17.4% of total accelerator time). Performance-Power Trade-offs:  As Table  II  suggest,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "¬¥as \n592 168.2 22.7 (17.2 if only train) 4016 159.42 Fully powered, DNN Compute only 287.44 Fully powered, DNN  Œº ‚àí proÔ¨Åler 255.39 EH +  Œº ‚àí proÔ¨Åle + NV-mems + resizing RAM + Host 159.40 \nTABLE II: Comparison with prior accelerator-based platforms. (GOps) \nEnergy Eff. (GOps/W) DaDianNao [ 16 ] 606 67.3 16.3 4964 304.54 CNVLUTIN [ 4 ] 606 70.1 17.4 4964 285.29 Activation Sparse [ 80 ] 667 292 19.2 5466 284.69 EyerissV2 [ 15 ] 200MHz N/A N/A 153.6G 8b Ô¨Åxed pt/s 193.7 FlexBlock [ 63 ] 333MHz 160.3 (65nm) 34.4 (when same #PEs) 4504 131.03 \nUs.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 238,
    "augmented": true
  },
  {
    "text": "To correctly estimate accelerator power and area, we implemented a register-transfer level model using System Verilog and syn- thesized using Synopsys Design Compiler [ 93 ] with a 32nm library [ 94 ]. Table  I  lists the estimated power consumption and area of the major components. Instead of simulating the CPU, we tested the K-means clustering and cluster optimization on a mobile SoC with 8 √ó  ARM Cortex A78 series CPU.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "2019. Progress in Virtual Reality and Augmented Reality Based on Holographic Display. Appl.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 19,
    "augmented": false
  },
  {
    "text": "13‚Äì24. [30] L. Liu, R. Zhong, W. Zhang, Y. Liu, J. Zhang, L. Zhang, and M. Gruteser, ‚ÄúCutting the Cord: Designing a High-quality Untethered VR System with Low Latency Remote Rendering,‚Äù in  Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services , ser. MobiSys ‚Äô18, 2018, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1049 \nInFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp. Latency (ms) \n(a)  Wiki-trace:  Strict  workload. InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "The sensitivity of each weight W ij  is calculated using the second-order Taylor expansion of the loss function  L : \n‚àÜ L ‚âà 1 \n2 \nX \ni,j \n‚àÇ 2 L ‚àÇW   2 ij ( W ij ) 2 \nwhere ‚àÇ 2 L ‚àÇW   2 ij   is the second-order derivative (Hessian) of the loss with respect to the weights. Define the dropout probability  p i  for neuron  i  based on the sensitivity of its corresponding weights. The idea is to use the sensitivity to determine the probability: \np i  = Œ≤   P \nj ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \nmax \u0010P \nj ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \u0011 +  œµ \nwhere  Œ≤  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 218,
    "augmented": false
  },
  {
    "text": "Unbiased gradient estimates. When the aggregator requests a training update, a subset of sensors, deter- mined by equilibrium conditions, provide local gradi- ents. Although not all sensors participate every time, the equilibrium ensures a stable pattern of participation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "[99] Zichang Liu, Aditya Desai, Fangshuo Liao, Weitao Wang, Victor Xie, Zhaozhuo Xu, Anastasios Kyril- lidis, and Anshumali Shrivastava. In  Proceedings of the 37th International Conference on Neural Information Processing Systems , NIPS ‚Äô23, Red Hook, NY, USA, 2024. Scissorhands: exploiting the persistence of importance hypothesis for llm kv cache compression at test time.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "TABLE II: Salient features of the six videos used in this study. Videos # Frames # Avg. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Graphcore intelligence processing unit (ipu). https://www.graphcore.ai/ products/ipu , 2023. Accessed: 2024-04-27.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Distilling the essence of raw video to reduce memory usage and energy at edge devices. In  Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture , MICRO ‚Äô52, page 657‚Äì669, New York, NY, USA, 2019. Association for Computing Machinery.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "2. \nto evaluate the accuracy, and plot the experimental results in Fig. 8 and Fig. 9.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "Michael Mesnier. Intel labs showcases multi-vendor, computational storage plat- form. https://community.intel.com/t5/Blogs/Tech-Innovation/Data-Center/ Intel-Labs-Showcases-Multi-Vendor-Computational-Storage-Platform/post/ 1404651 , August 2022.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Association for Com- putational Linguistics. [33] Sarkar Snigdha Sarathi Das, Ranran Haoran Zhang, Peng Shi, Wenpeng Yin, and Rui Zhang. Unified low-resource sequence labeling by sample-aware dynamic sparse finetuning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Therefore, the standard data compression techniques are not very useful, let alone their energy efficient (such as quantized versions [ 33 ]) counterparts. For data compression in EH-WSNs, we need the compression algorithm to be  1  light weight  (for energy efficiency),  2  feature preserving  (for higher accuracy),  3 having a high compression ratio  (for communication effi- ciency), and  4  context agnostic  (for better generalization); i.e., our deployment scenario demands a  smaller representa- tive form  of the data that still  preserves enough application- specific features to perform meaningful classifications in a given DNN . Why Coresets?",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "Consequently, they exhibit up to 0.24% more SLO Violations compared to  Kraken , for this workload mix. Latency Distribution:  The end-to-end latency distribution for all policies for the  Social Network  application with the Twitter trace is plotted in Figure 12. In particular,  Arch ,  Fifer and  Kraken  show comparable latencies, with P99 values re- maining well within the SLO of 1000ms.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "The PIs are involved in several K-12 activities such as the summer CS program for girls (funded by CSE and led by Das). We will also collaborate with the Penn State College of Education‚Äôs CSATS (Center for Science and the Schools) to participate in the university‚Äôs continuing outreach initiatives focused on STEM subjects. We plan to continue the summer program involv- ing more schools and students in coming years, where we will expose them to Generative AI and related concepts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "The resulting power needs have recently triggered data center providers to install their own power plants [44,53,136,155]. Furthermore, as depicted in Figure 1, Bill Dally, the Chief Scientist at NVIDIA, summarizes [30] how the compute needs for training have increased with model com- plexity, placing immense strain on existing computing systems. This scarcity of high-quality data constrains the effective training of larger models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "To re- place these real objects, we choose six virtual holograms (Sniper, Rock, Tree, Planet, Rabbit, and Dice holograms) from the Open- Holo depthmap database [ 45 ]. Note that the real-object and the corresponding virtual-hologram are randomly mapped because, theoretically, different mappings have no impact on the perfor- mance speedup and energy saving results (shown in Sec. 5.3).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Our approach will em- body the best of both the worlds ‚Äì taking the deeper system level insights from real hardware/simulators and extending it to large scale by analytically modeling their behavior as a complex system. Custom Accelerator  \nChip \nSystolic  \nArray \nCache Hierarchy \nDRAM/ \nHBM \nChiplet \nInterconnect  \network \nCacti/gem5 \nScaleSimv2 \nRamulator \nRapid  Chiplet \nMQSim/ FlashSim \ngem5 \nGARNET \nGPGPU  \nSim \nHardware  \nstats \nTraining  dataset Analytical  \nmodels \nEstimation for: ‚Ä¢ Time ‚Ä¢ H/W choice ‚Ä¢ Power ‚Ä¢ Cost ‚Ä¢ Accuracy \nLatency  \nstats \nAccuracy \nstats \nUser Input \nEoE \nSoftware  \nRuntime  \nHARDWARE SIMULATION ENVIRONMENT \nINFERENCE \nTRAINING \nFigure 7 :  An end-to-end evaluation environment \nTask-4.2: Methodology We plan to compare our proposed optimizations against state-of-the-art MoEs [38, 42, 57, 74, 83, 89], CoEs [60, 67, 131, 151] and monolithic LLMs [107, 192] on state-of-the-art GPUs, CPUs, and custom acceler- ators (e.g., Groq, Cerebras, SambaNova, Habana Gaudi, and GraphCore). In our evaluation, we will employ both architecture-level and LLM/application-level met- rics.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 337,
    "augmented": false
  },
  {
    "text": "The Ô¨Ånal probability vector from the last layer (soft- max function)  V C 1 = [0 . 94 ,  0 . 01 ,  0 .",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "[13]  2021. AWS Lambda Cold Starts. https://mikhail.io/serverless/ coldstarts/aws/.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Therefore,  designing a training platform to perform continuous learning with the intermittent solar power and within the typical harvested budget  would be the best solution. Typ- ically, inference tasks have signiÔ¨Åcantly less compute time and power requirement, and commercial off the shelf devices, like edgeTPU [ 19 ] can perform object detection using the aforementioned compressed models at a reasonable frame rate (at times  ‚â• 71  f ps ). Furthermore, solar power has reasonably predictability characteristics.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "USENIX Association. [36]  Bernhard Korte and Jens Vygen. 2018.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "https://doi.org/10.1109/CLUSTER.2019. 8891040 [49]  Guido Urdaneta, Guillaume Pierre, and Maarten Van Steen. 2009.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "We explain the details below. Resource Types : We use both CPU and GPU instances  4a depending on the request arrival load. GPU instances are cost-effective when packed with a large batch of requests for execution.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Note, however, that none of these existing schemes target at reducing the amount of ‚Äúunnecessary‚Äù computations in the AR holographic applications. In addition to the  Inter-Holo  de- sign, our proposed  Intra-Holo  technique focuses on computation approximation opportunities, and as such, it is orthogonal to these prior efforts. 7 CONCLUSION The extremely heavy computation in hologram processing hinders the growth of the 3D display applications on AR headsets.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "2. Iterative Refinement:  Use simulation or small-scale ex- perimental runs to refine parameters. If sensors rarely par- ticipate, increase  Œ≥  or decrease  Œ∑ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "2019. Data-independent neural pruning via coresets. arXiv preprint arXiv:1907.04018  (2019).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Note that, this implementation is purely done in software, without any hardware modiÔ¨Åcation. ‚Ä¢  AE  (SW) : We evaluate the  IntraFrame, InterEye ( AE ) design on a GPU, and bypasses the projection computation for the right-eye by  reconstructing  the results with a learned pattern, as shown in the  AE  block in Fig. 7.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "[9] Amey Agrawal, Nitin Kedia, Jayashree Mohan, Ashish Panwar, Nipun Kwatra, Bhargav Gulavani, Ramachandran Ramjee, and Alexey Tumanov. Vidur: A large-scale simulation framework for llm inference. Proceedings of Machine Learning and Systems , 6:351‚Äì366, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "0 \n150 \n300 \n450 \n600 \nOracle Kraken Oracle Kraken Oracle Kraken \nSocial Network Media Service Hotel Reservation \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(a) E2E Response Time Break- down. 275 \n290 \n305 \n320 \n600 \n700 \n800 \n1 10 19 28 37 46 55 \nRequests/second \n# Containers \nSampling interval (minutes) \nOracle Kraken Trace \n(b) Containers spawned over time. Figure 16: Simulator: Comparison of End-to-End (E2E) Response Times and Containers Spawned Over Time (60 minutes) of  Kraken and  Oracle .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "\"https://github.com/ google-research-datasets/Objectron/blob/master/index/laptop_annotations\". [43]  Objectron. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "[28] Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva. Transactions of the Association for Computational Linguistics , 12:283‚Äì298, 2024. Evaluating the ripple effects of knowledge editing in language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "; iii)  What types of accelerator-based chiplets and chips perform better for training and inference of EoEs? ; v)  What is the estimated training time given the size of input data and choice of model architecture? ; iv)  Should we build separate training and inference chiplets/chips, or would a unified chip/chiplet suffice?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "The most common algorithms used fod the said operations are High-Speed Schoolbook Polynomial Multiplication (HSPM) and Pipelined Systolic Dimension Modular Multiplier (SDMM), and we propose to accelrate the same using the FPGAs in the CSDs. The data locality due to the SSD and the high throughput due to the FPGA could facilitate swift polynomial processing and refined modular multiplications using DSP slices, thereby accelerating the encryption process. Designing HSPM Accelerator on CSD FPGA:  The HSPM hardware is characterized by its fully parallelized design, incorporating 128 Multiply-Accumulate (MAC) units for handling polynomials of degree  n  = 256 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "In  IEEE CLOUD , 2019. [38]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Cyan Subhra Mishra, Mahmut Taylan Kandemir, and Chita R. Das. Towards designing a self-managed machine learning inference serving system inpublic cloud, 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Plastic and reconstructive surgery  (2017), 1066‚Äì1070. [62]  Lingjie Wei and Yuji Sakamoto. Mixed Reality with HoloLens: Where Virtual Reality Meets Augmented Reality in the Operating Room.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Monotonicity of the Potential Function \nConsider a unilateral deviation by a single sensor  s j  from an action  a j ( t )  to a different action  a ‚Ä≤ j ( t ) . Such a deviation affects only  U j ( t ) , not the utilities of other sensors directly in a one-step change. If this deviation is profitable for sensor s j , we have: \nU j ( a ‚Ä≤ j ( t ) ,  a ‚àí j ( t ))  > U j ( a j ( t ) ,  a ‚àí j ( t )) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "21 \nInhyuk Park, Qing Zheng, Dominic Manno, Soonyeal Yang, Jason Lee, David Bonnie, Bradley Settlemyer, Youngjae Kim, Woosuk Chung, and Gary Grider. Kv-csd: A hardware-accelerated key-value store for data-intensive applications. dimensions , 30:33.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "243 \nFig. 3: Detailed illustration of projection transformation. The projection transformation Ô¨Årst calculates the transformation matrix ( T  ), and then uses the transformation matrix to map each of the pixel coordinates to generate the projection matrices ( P ) for the FoV frames.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "These codecs can operate on generic computational hardware, such as GPUs and FPGAs, without the need for specialized video processing units, thus broadening their applicability across different device platforms. Moreover, neural codecs excel in adaptability, offering robust performance across variable bandwidth and computational conditions, making them particularly suited for real-time streaming environments. This process benefits significantly from residual learning techniques, where each successive layer in the network aims to correct errors from the previous layers, thereby enhancing the reconstructed video quality incrementally with each additional decoding layer.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "2278‚Äì2324, Nov 1998. [44]  H. Lin, M. Hsu, and W. Chen, ‚ÄúHuman hand gesture recognition using a convolution neural network,‚Äù in  2014 IEEE International Conference on Automation Science and Engineering (CASE) , pp. 1038‚Äì1043, 2014.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Check for sufficient energy before launching a ‚ÄòQuantaTask‚Äò. 4. Fuse multiple ‚ÄòQuantaTask‚Äòs to minimize load/store operations.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "285‚Äì300, 2018. Chih-Hsuan Yen, Hashan Roshantha Mendis, Tei-Wei Kuo, and Pi-Cheng Hsiu. In Proceedings of the European conference on computer vision (ECCV) , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7. Since a power predictor itself consumes power, it makes sense to employ it for large-scale applications under weak power sources where discarding a portion of computations may impose a big loss or for the scenarios where power level transitions happen frequently. VI.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Strict Relaxed 0 \n20 \n40 \n60 \n80 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(a)  Wiki Trace. Strict Relaxed 0 \n50 \n100 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace. Figure 8:  Cost savings of  Cocktail  compared to three schemes.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "(c) Viewing S-CGH from different focal distances. Focal distance from left to right:  0.3m ,  0.4m ,  0.5m , and  0.6m . (b) Viewing W-CGH from different focal distances.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Thus, the existence of a Nash equilibrium follows directly from the finiteness of utilities, the monotonicity of  Œ¶ , and the impossibility of infinite improvement sequences. Convergence to the Nash Equilibrium \nThe final step is to show that the iterative best-response dy- namics indeed converge to the NE identified above. Since each sensor‚Äôs best-response update seeks to maximize its own utility, sensors will continue to deviate as long as prof- itable deviations exist.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Challenges include aligning hetero- geneous data, managing communication costs, and dealing with unreliable or missing inputs. Existing methods may not account for the energy constraints and participation vari- ability inherent in EH-WSNs. ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "[33]  M. Courbariaux, Y. Bengio, and J.-P. David, ‚ÄúBinaryconnect: Training deep neural networks with binary weights during propagations,‚Äù in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 , NIPS‚Äô15, pp. 3123‚Äì3131, 2015. [34]  M. Alwani, H. Chen, M. Ferdman, and P. Milder, ‚ÄúFused-layer cnn accelerators,‚Äù in  2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "90% of the time the inference could not start because of lack of energy. 0 20 40 60 80 100 Succeed Failed \n72% 28% \n(b)  Inference completion breakdown when three EH sensors are working in round robin fashion, where one of the sensors performs inference while the other two are accumulating energy. 28% of the time the sensors could Ô¨Ånish the inference, while 72% of the time the inference failed as the sensor could not harvest enough energy while not performing any inference.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "2. Theoretical Analysis : The heuristic prioritizes tasks based on effective priority  P   eff i = p i E i   √ó  œï i , where  œï i  accounts for deadline urgency. This balances task importance against energy consumption, leading to efficient utilization of available energy.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "To this end,  Kraken  makes use of a parameter called  Connec- tivity , while assigning function weights. The  Connectivity of a function is defined as the ratio of number of its descen- dant functions to the total number of functions. The  ùê∂ùëúùëõùëõ procedure in Algorithm 1 makes use of this formula.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "10(a), one can observe that, for V1, the energy saving is about  56% with only  0 . 07%  accuracy drop; however, if the application is willing/tolerant to live with  1 . 3%  accuracy drop, then  21% more energy can be saved (amounting to  77%  energy reduction compared to the baseline).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Prior to scaling-up instances, we need to estimate the cost  4b of running them along with existing instances. At any given time  T , based on the predicted load ( L p ) and running instances R N , we use a cost-aware greedy policy to determine the num- ber of additional instances required to serve as  A n  =  L p  ‚àí C r , where  C r  =  ‚àë N i = 1   P f i , is the request load which can be handled with  R N . To procure  A n  instances, we greedily calculate the least cost instance as  min ‚àÄ i ‚àà instances Cost i  √ó A n / P f i .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "9 √ó . This reduces the communication payload size by 8 . Specifically, we introduce an  activity- aware coreset construction  technique to dynamically adapt to both activity and the available harvested energy, while conserving maximum features of the data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Existing Approaches:  Although there has been signiÔ¨Åcant re- search [ 40 ], [ 41 ], [ 47 ], [ 52 ], [ 56 ], [ 61 ], [ 72 ], [ 104 ] on enabling machine learning in intermittently powered devices, a major- ity of it focuses on performing inference. Finally, we assume the exact same setup of the Urban trafÔ¨Åc dataset and hence have 5 different MobileNetV2 models trying to classify the trafÔ¨Åc they are facing, and learning from the streaming data. We vary the training intervals to see the effect of frequency of retraining.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": ", s N }  deployed to monitor a common scene. Each sensor observes the environment from a distinct van- tage point. .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "And second, we will explore EoE-specific KV cache compression strategies to optimize memory usage including quantization and sparsity optimization tech- niques. An example would be: first, dividing the available KV cache space among experts and then, across the attention heads in each expert, with the goal of allocating more cache space to experts and attention heads that can benefit most from that space (compared to other experts/attention heads). Task-2.5: Runtime Support Our runtime support system will serve as the cohesive glue that efficiently manages system resources, models, and data in real-time with minimal overhead.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Case Study: Edge Cloud Partitioning in Smart Industries \nThe evolution of industry 4.0 [4] standard is bringing intelligent sensing and analytics into the industrial and man- ufacturing segment. Modern smart machines come with inte- grated sensors with built-in communication protocols to send data to either an attached computer, a base station or cloud. B.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "0 \n0.25 \n0.5 \n0.75 \n1 \nHit Rate \n(b) Media Service. Figure 4: Function Hit Rate for an Evenly Distributed Load across all Paths in each Application. 0 \n0.25 \n0.5 \n0.75 \n1 \nHit Rate \n(c) Hotel Reservation.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Similarly, it took 384 A100 GPUs to train BLOOM over 3.5 months [165] and 6144 TPU v4 chips were used to train PaLM-540B model over 50 days [27]. While LLMs have become integral across various sectors due to their advanced capabilities, con- structing these models from scratch for specialized applica- tions presents significant challenges due to the prohibitive cost. For instance, the Megatron-Turing 530B model was trained using 2K A100 GPUs over a duration of 3 months con- suming over 3 million GPU hours [149].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "6.2 Simulator Results Since the real-system is limited to a 160-core cluster, we use our in-house simulator, which can simulate an 11k-core cluster, to study the scalability of  Kraken . We mimic a large scale Poisson arrival trace ( ùúá = 1000rps), Wiki ( ùúá = 284 rps) and Twitter ( ùúá = 3332 rps) traces. Figure 14 plots the con- tainers spawned versus the SLO guarantees for each appli- cation for all traces.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "Under these conditions, we have: \nlim k ‚Üí‚àû E [ J ( Œ∏ k )] =  J ( Œ∏ ‚àó ) and lim k ‚Üí‚àû E [ ‚à•‚àá J ( Œ∏ k ) ‚à• ] = 0 . This implies  Œ∏ k  converges in expectation to a stationary point  Œ∏ ‚àó of  J ( Œ∏ ) . Equilibrium Stability and Impact on Stationarity \nThe key subtlety is that  D  depends on equilibrium strategies.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "As previ- ously discussed in Section  3 , spot instances interruptions can lead to intermittent loss in accuracy as certain models will be unavailable in the ensemble. However for large ensembles (5 models are more), the intermittent accuracy loss is very low. Figure  12b  plots the failure analysis results for top three constraints by comparing the ensemble accuracy to the target accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Overall,  Cocktail  was able to deliver an accuracy of 83% and 79.5% on average for the  Strict  and  Relaxed  workloads, respectively. This translates to 1.5% and 1% better accuracy than  Clipper  and  InFaas . We do not plot the results for Clipper-X , which achieves similar accuracy to  Cocktail , but uses more models as explained in Section  6.2.1 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "0 \n500 \n1000 \n1500 \nwiki WITS berkley Twitter \nRequest Rate \nAvg Req \nMax Req \nFigure 6. Peak-to-median ratio. Prior works  [ 5 ,  10 ] try to hide the pro- visioning latency of VMs by using  server- less functions  as a handover mechanism when starting new VMs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "We pro- Ô¨Åle the spot price of 4 types of  C5  EC2 VMs over a 2-week period in August 2020. It was seen that, the spot instance prices have predictable Ô¨Çuctuations. When compared to the OD price , they were up to 70% cheaper.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "T L = T 5  √ó  T 4  √ó  T   L 3   √ó  T 2   √ó  T 1 T R = T 5  √ó  T 4  √ó  T   R 3   √ó  T 2   √ó  T 1 (1) \nThese Ô¨Åve transforms are of dimension of  4 √ó 4  ( 3  dimensions for rotation;  1  for translation), thus producing  4  √ó  4  T L  and T R  matrices [27]. Note that, given an arbitrary FoV frame, these transformation matrices remain the same for all the pixel \n5 A Viewport Transformation is the process of transforming a 2D coordinate objects to device coordinates [27]. 244 \ncoordinates in that frame, thus are evaluated only  once  for that frame, and account for only  4 .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "This fulfils requirement  4  . They are also an effective way to con- struct a representation of the data set with high compression ratios [ 8 ,  17 ] without incurring unacceptable accuracy losses and thus useful for achieving  3  . For the DNNs in question, coresets can achieve sufficient compression ratios to make communication energy-competitive with computation, as well as opening up new opportunities for optimizing DNN in- ference on the coreset, rather than original data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "2.1 Serverless Function Chains (DAGs) Many applications are modeled as function chains and typically administered under strict SLOs (hundreds of mil- liseconds) [ 30 ]. Furthermore,  Kraken  guarantees SLO requirements for up to 99.97% of requests. 2 Background and Motivation We start with providing an overview of serverless DAGs along with related work (Table 1) and discuss the challenges which motivate the need for  Kraken .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, in our design, the PC frames are encoded in an ‚ÄúIPP‚Äù fashion, where each I-frame is followed by two P-frames. Further, for the P-frame, as discussed above, the pre-deÔ¨Åned threshold for determining the block matching (i.e., is the  <  I , P  >  block pair good/similar match or bad/dissimilar match) can be tuned according to the application preference, e.g., for applications which favor good quality, more post-intra-encoded blocks (e.g., store and encode the deltas instead of simply reusing) are preferred. On the other hand, for applications that demand very small compressed data sizes to transfer through the network, the threshold condition can be relaxed to favor the  direct reuse  more.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "US Patent 7,809,601. [70]  Steven A Shaya, Neal Matheson, John Anthony Singarayar, Nikiforos Kollias, and Jeffrey Adam Bloom. Intelligent performance-based prod- uct recommendation system, October 5 2010.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "[59]  Stereolabs. 2020. ZED Software Development Kit.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 16,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Dynamic DAGs, where only a subset of functions within each DAG are invoked per request type, necessitate the ap- portioning of containers to each function. Recent frame- works like Xanadu [ 27 ], predict the most likely functions to be used in the DAG. This results in container provisioning along a single function chain.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Csd 3000. https://scaleflux.com/products/csd-3000/ , b. (Accessed on 11/13/2023). ScaleFlux.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Beyond 800 s , they quickly recover back to the required accuracy because additional instances are spawned in place of failed instances. However, in the case of InFaas , this would lead to 1% failed requests due to requests being dropped from the failed instances. An alternate solution would be to restart the queries in running instances but that leads to increased latencies for the 1% requests.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Index Terms ‚Äîedge computing, random forest, edge-cloud par- titioning, sensor network \nI. I NTRODUCTION R Etrofitting intelligent sensors nodes on legacy manufac- turing systems provides cost-effective smart manufac- turing upgrades. This work explores policies for partitioning random forest approaches, which are widely used for inference tasks in smart manufacturing, among sets of devices with different resources and data visibility. We demonstrate, using both publicly available datasets and a real-world grinding machine deployment, that our privacy-preserving approach to partitioning and training offers superior latency-accuracy trade- offs to purely on-edge computation while still achieving much of the benefits from data-sharing cloud offload strategies.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 170,
    "augmented": true
  },
  {
    "text": "For example, Michelson proposes a holographic display technology that optimizes image quality for emerging near-eye displays using two SLMs and camera-in-the- loop calibration [ 7 ]. Holographic Displays on AR:  Another large body of prior works focus on optimizing the holographic displays for the next- generation AR headsets [ 6 ,  17 ,  23 ]. Neural-Holography proposes an algorithmic hologram generation framework that uses camera-in-the-loop train- ing to achieve unprecedented image fidelity and real-time frame rates [ 48 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "However, the computation and power demands of deep neural network (DNN) based inference pose signiÔ¨Åcant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN). Moreover, managing inferences requiring responses from multiple energy- harvesting nodes imposes challenges at the system level in addition to the constraints at each node. This paper presents a novel scheduling policy along with an adaptive ensemble learner to efÔ¨Åciently perform HAR on a distributed energy-harvesting body area network.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Efficient Volu- metric Video Streaming Through Super Resolution. In  Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications . 2021.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": ";  iv)  How can inter-chiplet and inter-chip data movements be choreographed to maximize performance and minimize energy consumption for training, inference, and re-training? . ; and v)  What are the hardware-software co-design opportunities towards an efficient cross-stack system?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "0 500 1000 1500 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers \nNGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network. 0 500 1000 1500 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers NGINX ID Movie_ID Text User_Service Rating Compose_Review Movie_Review User_Review Review_Storage \n(b) Media Service. 0 200 400 600 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers \nNGINX Check_Reservation \nGet_Profiles Search \nMake_Reservation \n(c) Hotel Reservation.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "[59] Microsoft, ‚ÄúBuilding world-class sustainable datacenters and investing \nin solar power in arizona,‚Äù https://blogs.microsoft.com/on-the- issues/2019/07/30/building-world-class-sustainable-datacenters-and- investing-in-solar-power-in-arizona/ , (Accessed on 04/28/2023). 905 \nAuthorized licensed use limited to: Penn State University. [60] Microsoft-Rocket-Video-Analytics-Platform, \n‚Äúhttps://github.com/microsoft/Microsoft-Rocket-Video-Analytics- Platform.‚Äù [61] C. S. Mishra, J. Sampson, M. T. Kandemir, and V. Narayanan, ‚ÄúOrigin: \nEnabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks,‚Äù in  DATE , 2021.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 217,
    "augmented": true
  },
  {
    "text": "This can be illustrated with a simple use-case scenario. Con- sider an object detection scenario where a multi-color LED bulb on a Christmas tree identiÔ¨Åed as an object of interest, glowing red in Frame i , changes to blue in Frame i + 1 . In such a case, as the pixel values of the identiÔ¨Åed object have changed, Frame i + 1  cannot reuse the result (LED bulb) from Frame i  even though it should ideally be able to do so in an object detection application.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "Additionally, profiling devices to ascertain their energy consumption, computational capabilities, and memory footprint necessitates detailed micro- profiling using embedded programming. However, the efficacy of DynFit and iNAS is contingent upon the breadth and depth of the available dataset. NExUME is especially advantageous in intermittent environments, and its utility extends to ultra- low-power or energy scavenging systems.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint of P merg   <P budget shouldbealways met.Therefore,the power P merge   andlatency Lat merge   ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofÔ¨Çine. Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs. 4)Activationtransitioncost:Theexecutiontransitionfrom onetiletoanotherinsideonepowercycleorfromoneactivation solutiontoanotherindifferentpowerlevelsalsocostspower P trans andlatency Lat trans .Activationtransitionimpliesthat weneedtoenablethecorrespondingcircuitsoftheto-be- activatedrowsandcolumnswhileshuttingdowntheothers.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 211,
    "augmented": true
  },
  {
    "text": "Apache¬Æ Subversion¬Æ. [16] Apple. https://subversion.apache.org/ , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "This design optimizes the DNN execution in an energy harvesting wireless sensor network by collectively looking into all the involved components. The DNNs as indi- viduals are optimized before to meet the power budget. In the earlier case of na¬®ƒ±ve scheduling we tried to build an efÔ¨Åcient DNN by applying energy aware pruning [15].",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "5.3 Large Scale Simulation To evaluate the effectiveness of  Kraken  in large-scale sys- tems, we built a high fidelity, multi-threaded simulator in Python using container cold start latencies and function execution times profiled from our real-system counterpart. It simulates the working of DDAs running on a serverless framework that are subjected to both real-world (Twitter and Wiki) and synthetic (Poisson-based) traces. We have validated its correctness by correlating various metrics of interest generated from experiments run on the real system with scaled-down versions of the same traces (average ar- rival rate of  ‚àº 100rps).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "[70]  Tiago Zonta, Cristiano Andr√© da Costa, Rodrigo da Rosa Righi, Miro- mar Jose de Lima, Eduardo Silveira da Trindade, and Guann Pyng Li. IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems  37, 11 (2018), 2348‚Äì 2359. DeepThings: Distributed adaptive deep learning inference on resource-constrained IoT edge clusters.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "As discussed, maintaining  Œ∑ > Œ¥  encourages sensors to at least attempt participation rather than always remain offline. The parameter  Œ∑ >  0  penalizes non-participation, ensuring that sensors do not remain idle indefinitely. Formal Bounds and Conditions \nTo ensure balanced behavior, it is helpful to relate  Œ≥, Œ¥,  and Œ∑  to typical values of accuracy improvement and energy costs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "However, in the speciÔ¨Åc context of video applications, the ‚Äútemporal continuity nature‚Äù of the video data presents itself as an opportunity that is yet to be fully exploited. As a sample work, Euphrates [9] employs MVs to detect small changes between frames and skips unnecessary inferences. However, the number of skipped inferences there is  static .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "(2019), 212:1‚Äì212:13. [25]  Jonghyun Kim, Youngmo Jeong, Michael Stengel, Kaan Ak≈üit, Rachel Albert, Ben Boudaoud, Trey Greer, Joohwan Kim, Ward Lopes, Zander Majercik, Peter Shirley, Josef Spjut, Morgan McGuire, and David Luebke. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "By characterizing accuracy  vs.  latency of ensemble models, we identify that prudently selecting a subset of available models under a given latency can achieve the target ac- curacy. We leverage this in  Cocktail , to design a novel dynamic model selection policy, which ensures accuracy with signiÔ¨Åcantly reduced number of models. 2.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "We analyze the accuracy-latency trade offs of each strategy and show their benefits in different scenarios. We apply our techniques on Appliance energy prediction data [3], and also provide a case analysis of material surface roughness prediction using real world grinding-machine sensor data. E XPERIMENTAL  E VALUATION AND  R ESULTS \nIn this section, we describe our evaluation methodology and evaluate both privacy-preserving and data-sharing partitioning strategies compared with a traditional random-forest approach.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "NExUME demonstrates superior performance across all operating classes, achieving the highest accuracy in each case. For example, for the spindle idle (SI) class, NExUME attains an accuracy of 93.00%, outperforming DynBal by 0.70%. While the margins may appear small, in industrial settings, even minor improvements in classification accuracy can have significant implications for predictive maintenance and operational efficiency.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "In  USENIX Middleware Conference . [31]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Mahmut Tay- lan Kandemir, Bhuvan Urgaonkar, George Kesidis, and Chita Das. Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "In this case, the reconfigurable chiplet can be transformed into a suitable compute engine. Or, in training, new memory blocks can be spawned to support the higher KV-caching needs. For example, during inference, the system can decide to map an expert onto a chip but the suitable hardware may not be directly present.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "When the traversal completes, an  Adder Tree  will be used to merge the partial sums for ReRAM columns and obtain the Ô¨Ånal MAC result. 2) Computation parallelism: Intra-layer parallelism  means overlapping the layer computations on duplicated copies of ReRAMs that store the same weights for one layer. We use parallelism granularity  G  to denote the duplication count as deÔ¨Åned in [ 5 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "[60]  Fernando Moya Rueda, Ren√© Grzeszick, Gernot A. Fink, Sascha Feld- horst, and Michael ten Hompel. 2018. Convolutional Neural Networks for Human Activity Recognition Using Body-Worn Sensors.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "International Telecommunication Union, June 2019a. URL  https://www.itu.int/rec/T-REC-H.264 . ITU-T Recommendation H.264.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "99.00% \n99.25% \n99.50% \n99.75% \n100.00% \n0 \n3000 \n6000 \n9000 \n12000 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(c) Hotel Reservation. Figure 14: Simulator: Comparison of Total Number of Containers spawned VS SLOs satisfied by each policy. 98.50% \n99.00% \n99.50% \n100.00% \n0 \n10000 \n20000 \n30000 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "VI , our proposal drops the quality a little bit (PSNR  ‚âà 80 dB in our design). Thus, as we discuss later in Sec. 43 , 0 , 0 ]  (-0.43=-1+1/7 √ó 4), which is slightly different from the original  [ 0 , 0 , 0 ] , whereas the other two points,  P 1  and  P 2 , are exactly same as the original ones.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. o information.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "1 and 6 . 7, by the  Intra-Holo and  Inter-Intra-Holo  schemes, respectively. The above observations from these two figures explain the power benefits of our proposed designs.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Therefore, common functions have a higher chance of experiencing increased load due to be- ing present in multiple paths. It can be seen that functions which are common to a larger number of paths are invoked at a higher rate by such a request arrival pattern. Consequently, higher weights have to be assigned to such functions to ensure resilience in the presence of varying application usage patterns.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Many prior works [ 2 , 25 , 35 , 63 , 74 , 75 ] have extensively tried to reduce model latency by reducing overheads due to shared resources and hardware interference. There are mainstream commercial systems which automate single model-serving like TF-Serving [ 60 ], SageMaker [ 6 ], AzureML [ 10 ], Deep-Studio [ 28 ] etc. We believe that our proposed policies can be complementary and beneÔ¨Åcial to these prior works to reduce the cost and resource footprint of ensembling.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "Especially, VR and AR are now gaining traction because of their versatile nature of providing an immersive sensory experience, which is not possible with the conventional systems ‚Äì especially in the domain of video streaming. They are emerging as one of the most important entertainment markets and Goldman Sachs predicts that, by 2025, around 79 million users will use online video streaming from the VR/AR ecosystem, resulting in a multi-billion dollar market [20], penetrating the Ô¨Åelds of media streaming, VR gaming, education, medicine, communication and many more. Even today, more than 10 million users enjoy  360 ¬∞ videos \nusing Google Cardboard [10], Samsung Gear VR [44], and Oculus VR [8], to experience  360 ¬∞ video [7], art museum [9], live stadium [46], etc.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "This research was partially supported by NSF grants #1931531, #1955815, #1763681, #2116962, #2122155 and #2028929. We also thank the NSF Chameleon Cloud project CH-819640 for their generous compute grant. All product names used here are for identification purposes only and may be trademarks of their respective companies.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "This is mainly because, in MCDNN, the scheduler tends to choose YOLOv4-tiny due to the low energy budget. E. Future Work \nAs shown in Sections IV-A and IV-B, our inference decision (FI, SI, or PI) is made by comparing the overlap between the MVs and the previous frame‚Äôs BBoxes, or the ratio of the MVs size to the previous BBoxes, with a preset thresholds. Although we have an intuitive feeling on the how the thresholds in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "https://notebooklm.google/ \", 2024. [53] Google Blog. Google and kairos power nuclear energy agreement.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Display:  After the projection, the two generated FoV frames are stored in 2D format in the video buffer. The display controller just needs to read them from DRAM to the screen. To summarize, compared to 2D video processing,  360 ¬∞ video processing incurs additional projection computation.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "4, pp. 3, no. [47] S. Lee, B. Islam, Y. Luo, and S. Nirjon, ‚ÄúIntermittent learning: On- \ndevice machine learning on intermittently powered system,‚Äù  Proceed- ings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Since the ex- perts are pivotal in the way the prompt/query is being answered, it is equally imperative for the routers to fully utilize the expert network by directing the rel- evant queries to the right expert(s) dynamically depending on the current ex- perts being involved in the network. To achieve this, the router needs to be re- trained/fine-tuned according to the state of the expert network by taking advan- tage of expert-router affinity to the greatest extent possible. Unlike conventional networks, where an entire end-to-end training of the experts and routers needs to be done alike, our scheme makes use of a more targeted approach that can sig- nificantly reduce the training complexity of the routers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "[47] H. Bay, T. Tuytelaars, and L. Van Gool, ‚ÄúSurf: Speeded up robust features,‚Äù in  European conference on computer vision , 2006, pp. [45] B.-G. Han, J.-G. Lee, K.-T. Lim, and D.-H. Choi, ‚ÄúDesign of a Scalable and Fast YOLO for Edge-Computing Devices,‚Äù  Sensors , 2020. [46] PyTorch Development Team, ‚ÄúPyTorch,‚Äù ‚Äùhttps://github.com/pytorch/ pytorch‚Äù, 2016.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "Latency (ms) \n(d)  Twitter-trace:  Relaxed  workload. InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp. InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nLatency \n(c)  Twitter-trace:  Strict  workload.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "It effectively addresses the operational efficiency and response quality within the constraints of stringent SLOs and a minimum accuracy rate. By integrating expert affinities (Expert‚ÄìExpert, Expert‚ÄìData, Expert‚ÄìRouter, and Expert‚ÄìComposition Function) detailed in Table 2, the system will optimize responsiveness and computational efficiency. Task-2.5: Runtime Support Our runtime support system will serve as the cohesive glue that efficiently manages system resources, models, and data in real-time with minimal overhead.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "3 on average, as shown in Tab. 2), thereby gaining more opportunities to reduce the amount of computations for all the objects in the current frame. On the other hand, the  shoe  video frames typically contain more objects (2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "9. Note that these latency and energy results are  normalized  with respect to the baseline (FI for all frames). From these results, we can make the following observations.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "This adaptive strategy ensures that all weights are adequately trained despite the dynamic adjustments. Complexity Analysis of DynFit:  The time complexity of DynFit during training is  O ( N  ¬∑  T ) , where N  is the number of weights and  T  is the number of training iterations. Dropout scheduling techniques are incorporated, where dropout rates are increased or decreased over time based on the training progress and energy availability, mitigating potential overfitting introduced by static dropout variations.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "First, we use a synthetic Poisson-based request arrival rate with an average rate  ùúá =  100. Second, we use real-world request arrival traces from Wiki [ 49 ] and Twitter [ 1 ] by running each experiment for about an hour. The Twitter trace has a large variation in peaks (average = 3332 rps, peak= 6978 rps) when compared to the Wiki trace (average = 284 rps, peak = 331 rps).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "3a, one of the most common cases in videos is that the object(s) (which have been identiÔ¨Åed in previous frames, i.e., Frame-1) move around in the current frame (i.e., Frame-2 , Frame-3). In such scenarios, to explore the reusability exposed by motion vectors,  1  we Ô¨Årst process the full inference in CPU 1   for Frame-1, and  2  identify the objects as well as their positions (i.e., bounding boxes). 3 Then for Frame-2, we obtain the its motion vectors from the codec (with a minimal overhead, as discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Further, among the Ô¨Åve stages in the pipeline, octree construction & serialization for geometry compression and RAHT for attribute compression are the two major bottlenecks which take  1 s  and  2 s , respectively. Overall, the entire PCC pipeline takes around 3.5 seconds 3 , which prevents one from employing such techniques in an edge device. Driven by these observations, we investigate the reasons behind such inefÔ¨Åciencies, and further explore the potential opportunities for speeding up the PC compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "But, because of the larger data volume, the number of computations per- formed at the edge diminished significantly (refer Figure 15). We also conducted an empirical study on number of clusters required, and found out that the bearing set data needs about 15 to 20 clusters to maintain the inference accuracy. We took the learning from multiple domain specific litera- tures [ 19 ,  29 ,  53 ] to isolate the frequency regions specific to the fault pattern to minimize the computations.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Our Intra-Inter-V1 (Quality-oriented):  To further reduce the frame size, this design exploits the temporal locality across PC frames. IV  that, the Morton codes can precisely describe the geometry relations among points (thus, ensuring a good geometry compression), but sometimes they may not work well for the attributes, especially when the spatial locality is not rich for some blocks/frames. As a result, the data size becomes 5%  less than our intra-only design (e.g., only 12 %  of the original size), while dropping the quality by  6 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "[58] Xilinx, ‚ÄúVivado Design Hub - Installation and Licensing,‚Äù ‚Äùhttps://www.xilinx.com/support/documentation-navigation/design- hubs/dh0013-vivado-installation-and-licensing-hub.html‚Äù. [59] Xilinx, ‚ÄúVivado Design Suite - HLx Editions.‚Äù ‚Äùhttps://www.xilinx.com/ products/design-tools/vivado.html‚Äù, 2019. [60] xinreality, ‚ÄúAsynchronous Spacewarp.‚Äù ‚Äùhttps://xinreality.com/wiki/ Asynchronous Spacewarp‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 169,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. Considering the global control always enqueues any idle tile with work, whenever the tile has no work left, it steals a kernel from the most \n899 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "2018. [39]  Edward Oakes, Leon Yang, Dennis Zhou, Kevin Houck, Tyler Harter, Andrea Arpaci-Dusseau, and Remzi Arpaci-Dusseau. In  11th  { USENIX }  Workshop on Hot Topics in Cloud Computing (HotCloud 19) .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "The data set is divided into 2 chunks creating a two home set up and the similar is done for a 4 home setup. such as temperature and humidity of different regions of the home as well as the locality (from weather station data [3] with 14803 training samples and 4932 testing samples). This data set directly fits our use case for two reasons - 1.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "In a sense, our annotations will make the data originating from this project more actionable and easily repro- ducible. The data lineage information will also help the project to reduce its ‚Äústorage footprint‚Äù. To generate such annotations, where appropriate, we plan to use well-established data lineage tools such as Keboola [78] and Octopai [120].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Prior works relied on supervised learning or K-means clustering, un- suitable for  Us. Algorithmic Advancements:  Us. ¬¥as  extends the frontier of rep- resentation learning for continuous learning by implementing it at a large scale and addressing related challenges.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "[41] OpenGL, ‚ÄúCubemaps - Learn OpenGL.‚Äù ‚Äùhttps://learnopengl.com/ Advanced-OpenGL/Cubemaps‚Äù, 2019. [42] OpenGL, ‚ÄúThe Industry‚Äôs Foundation for High Performance Graphics.‚Äù ‚Äùhttps://www.opengl.org/‚Äù, 2019. [43] O.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "time \n0% \n20% \n40% \n60% \n80% \n(c) FI+SI+PI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead Partial \n(d) FI+SI+PI exec. Videos # Frames # Avg. Objects Static/Dynamic Object/Full Frame Description V1  [33] 20655 Medium Medium Small A few people and cars move in the parking lot V2  [33] 9075 Medium Medium Small More activities of people in the parking lot GL1  [43] 6477 More Dynamic Medium More activities of people and cars in the parking lot HC1  [43] 6000 More Dynamic Medium People do exercises in a garden P1  [42] 3915 Less Dynamic Small-Large Several people walk around in a room P2  [42] 2955 Medium Dynamic Small-Large More people than P1 in the room \n0% \n20% \n40% \n60% \n80% \n(a) FI+SI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead \n(b) FI+SI exec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 244,
    "augmented": true
  },
  {
    "text": "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands ¬© 2020 Association for Computing Machinery.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "However, this error could be rectified with further fine tuning. In rare cases (once in over 2000 cases), the generator induced arti- facts which could result in wrong classifications. A.2 More Results on Bearing Fault Data We repeated our experiments with similar experimental setup on the bearing fault data set [ 53 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "[70]  Ricci Rox, ‚ÄúPower-hungry Snapdragon 8 Gen 1 gets trounced by the Apple A15 Bionic in real-world gaming test,‚Äù  ‚Äùhttps: //bit.ly/3P086pp‚Äù , 2022. [71]  Richard Durant, ‚ÄúPointerra: Attractive Opportunity If Growth Can Be Sustained,‚Äù  ‚Äùhttps://bit.ly/3nvfRrx‚Äù , 2021. [72]  R. B. Rusu and S. Cousins, ‚Äú3D is here: Point Cloud Library (PCL),‚Äù in  IEEE International Conference on Robotics and Automation (ICRA) , 2011.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "Prior works have contributed towards reducing the parameter count and the compute complexity through model pruning [63, 98, 198], knowledge distillation [55,93,113], quantization [22,46,95] along with mixture of experts (MoE) [69], includ- ing dense MoE [37,117,126,166], sparse MoE [42,74,89,145], soft MoE [111,132,178,194], and composition of experts (CoE) [59, 131, 196, 197]. Differentiating from prior art, our approach introduces a novel modu- lar, collaborative framework of LLM experts, where individual experts can be trained independently and connected in various configurations. This enables flexible, diverse ways of expert adaptation and localized training to keep pace with rapidly changing knowledge and user needs, while also facilitating cross-layer optimization for system and architecture design.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 203,
    "augmented": false
  },
  {
    "text": "As opposed to prior works [ 5 ,  10 ], which try to combine serverless functions with VMs to hide the start-up latencies of VMs, our primary interest lies in exploring the different key aspects  to address when hosting DNN-based ML pre- diction serving systems in public cloud, as given below: ‚Ä¢  Diverse Models:  How to make the users oblivious of model selection from the extensive pool of models, for satis- fying the accuracy, and latency requirements? ‚Ä¢  Heterogeneous Public Cloud Resources:  What are the different options available in terms of combining different VM-based cloud services and serverless functions for a given user requirement? ‚Ä¢  Configuring Resources:  From the diverse options, how to right-size VMs and appropriately configure the serverless functions to efficiently cater to user specified cost, accuracy and latency constraint?",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 193,
    "augmented": false
  },
  {
    "text": "To ensure a required accuracy with given latency, applications have to choose from a confounding array of different types of models (shown in Figure  1 ). These inference queries are typically administered with strict response laten- cies of under one second [ 4 ]. Based on the application needs, prediction queries require different compute resources, and have different accuracy, latency, and cost requirements.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "In  2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) , pp. Exploiting frame similarity for efficient inference on edge devices. 1073‚Äì1084, 2022b.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "1‚Äì2, Aug 2014. [24]  X. [23]  X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, ‚ÄúA high- efÔ¨Åciency dual-channel photovoltaic power system for nonvolatile sensor nodes,‚Äù in  2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "In  Ambient Assisted Living and Daily Activities: 6th International Work-Conference, IWAAL 2014, Belfast, UK, December 2-5, 2014. mhealthdroid: a novel framework for agile development of mobile health applications. Oresti Banos, Rafael Garcia, Juan A Holgado-Terriza, Miguel Damas, Hector Pomares, Ignacio Rojas, Alejandro Saez, and Claudia Villalonga.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "[151] Sainbayar Sukhbaatar, Olga Golovneva, Vasu Sharma, Hu Xu, Xi Victoria Lin, Baptiste Rozi√®re, Jacob Kahn, Daniel Li, Wen tau Yih, Jason Weston, and Xian Li. In  2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO) , pages 565‚Äì581, 2022. Skipper: Enabling efficient snn training through activation- checkpointing and time-skipping.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "[7]  W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, ‚ÄúA 65nm 1mb nonvolatile computing-in-memory ReRAM macro with sub-16ns multiply-and-accumulate for binary DNN AI edge processors,‚Äù in  2018 IEEE International Solid - State Circuits Conference (ISSCC) , pp. 494‚Äì496, 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "[167] Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han. SmoothQuant: Ac- curate and efficient post-training quantization for large language models. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors,  Pro- ceedings of the 40th International Conference on Machine Learning , volume 202 of  Proceedings of Machine Learning Research , pages 38087‚Äì38099.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "9d, DeepCache can only save  38% and  45%  on execution time for YOLOv3 and YOLOv4-tiny, respectively, which are less than both FI+SI (e.g., 52% for YOLOv3; 53% for YOLOv4-tiny) and FI+SI+PI (e.g., 55% for YOLOv3; 61% for YOLOv4-tiny) schemes. II-B3. Another hardware-based optimization has been proposed in Euphrates [9], as discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Driven by these observations, we investigate the reasons behind such inefÔ¨Åciencies, and further explore the potential opportunities for speeding up the PC compression. Before delving into the details of our approach which aims to close the performance gap between ‚Äúseconds‚Äù in practical and ‚Äúhundreds of milliseconds‚Äù in ideal settings, we Ô¨Årst investigate the reasons behind the inefÔ¨Åciencies of the prior techniques. Towards this, we studied three state-of- the-art PCC pipelines ‚Äì octree-based pipeline for intra-frame geometry compression (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "A survey on hallucination in large lan- guage models: Principles, taxonomy, challenges, and open questions. [66] Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. arXiv preprint arXiv:2401.08671 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "9: Performance and energy improvements for YOLOv4-tiny w.r.t. time \nFig. the baseline; Region Level Reuse Scheme (e.g., FI+SI+PI) has better performance, because this ‚Äúshallow‚Äù model beneÔ¨Åts more from partial inference.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "2.2.3 on top of the existing hologram pipeline. As shown by  Line#5  and  Line#7  in Algo. With the RoF attained from the eye tracking, the next question we need to answer is how to deploy the approximation opportuni- ties discussed above in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Intuitively, human activities do not usually stop abruptly, i.e. if a person is walking and has taken a step, there is a high probability that the person will continue walking rather than immediately switch to another activity. Therefore, to classify the next possible activity, we activate the sensor which is most accurate for classifying the anticipated activity.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "\"https://www.ni.com/en-us/innovations/white-papers/11/peak- signal-to-noise-ratio-as-an-image-quality-metric.html\". [22]  Yeon-Gyeong Ju and Jae-Hyeung Park. 2018.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "). Collaborative inference in sensor networks involves com- bining local inferences to achieve a global understanding of the environment ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "Diverse Collaborations \nFinally, the PhD students in the project will be encouraged to engage in collaborations with researchers from diverse backgrounds and disciplinary areas to enhance their collaboration and communication skills. Lab Resources:  The PIs collectively have more than 6,000 sq. Facilities, Equipment, and Other Resources \nThe participants of the proposed project have access to the facilities and resources described below.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Preparation for Activities:  The two senior PIs have extensive prior experience in supervising female un- dergraduate and graduate students. Both of them have graduated 15+ female PhD and MS students (5 in last five years) and a few of them have taken up faculty positions at different schools. They have also advised a couple of female undergraduate students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "[38] Nan Du, Yanping Huang, Andrew M. Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten Bosma, Zong- wei Zhou, Tao Wang, Yu Emma Wang, Kellie Webster, Marie Pellat, Kevin Robinson, Kathy Meier- Hellstern, Toju Duke, Lucas Dixon, Kun Zhang, Quoc V. Le, Yonghui Wu, Zhifeng Chen, and Claire Cui. 2023. Glam: Efficient scaling of language models with mixture-of-experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 167,
    "augmented": true
  },
  {
    "text": "3 \nframe features and the motion vectors from the compute hardware to perform a novel layered neural compression. One of the successful submissions ‚Äì which was later defined as a standard ‚Äì uses lattice-based encryption algorithm (Micciancio & Regev, 2009) and will be the focus of our work. The hybrid storage system is capable of taking the computed \n2 Given a powerful enough computer like quantum computers, RSA encrypted data can be decrypted, and therefore National Institute of Standards and Technology (NIST) called for proposals to develop post quantum cryptography algorithms (National Institute of Standards and Technology (NIST), 2024), and defined a standard for the same.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "(II) Computational Approximation : To address (I) and maintain continuous operation, EH-WSNs may skip some compute during energy shortfalls by dropping neurons (zero padding) or by approximating computations (quantization). Adding further approximation to save energy atop an already heavily reduced network can propagate errors through the layers, leading to significant accuracy drops (Islam & Nirjon, 2019; Kang et al., 2022; Lv & Xu, 2022; Kang et al., 2020), further violating SLOs. In certain energy-critical scenarios, even EH-WSNs applying state-of-the-art techniques fail to consistently meet SLOs, sometimes skipping entire inferences to deliver results on time.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 183,
    "augmented": false
  },
  {
    "text": "For certain cases like climbing in PAMAP2, and running in MHEALTH,  Origin  is more accurate than Baseline-1. For the PAMAP2 data-set, RR12- Origin  is 2.53% better than Baseline-2. We observe that, for the MHEALTH dataset, RR12- Origin  is 2.72% more accu- rate than the Baseline-2.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "III-A , PCC takes several seconds to execute, which is signiÔ¨Åcantly higher than the ideal/real- time demand ( 100 ms ). The main reason for this inefÔ¨Åciency is the ‚Äúsequential updates‚Äù in the state-of-the-art octree- based algorithms [ 47 ] (illustrated in Fig. 2 ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "A CKNOWLEDGMENTS \nWe would like to offer our thanks to the anonymous reviewers for their detailed feedback, which has greatly helped to improve and reÔ¨Åne this paper. VIII. ¬¥as  can save up to 200lbs of  CO 2  per year compared to a state of the art accelerator running on the grid.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "5  shows an example of geometry compression. SpeciÔ¨Åcally, there are three points in the this frame:  P 0 ‚Äôs coordinates are  [ 0 , 0 , 0 ] , P 1 ‚Äôs are  [ ‚àí 1 , 0 , 0 ] , and  P 2 ‚Äôs are  [ 3 , 3 , 3 ] . Consider the geometry compression pipeline in PCL [ 72 ], where the points are added one-by-one when constructing the octree.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Note that these compres- sion and pruning approaches can be performed at compile time, and they typically need Ô¨Åne-tuning to retain accuracy. 3) System Support for Exploiting Pixel and Computa- tion Similarities: State-of-the-art proposals such as Deep- Cache [8], and Euphrates [9] have explored the temporal similarity at runtime for DNN inference on video streams. Combined with specialized hardware support, quantization can reduce the amount of computation, memory footprint, and energy consumption.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "¬¥as \n592 168.2 22.7 (17.2 if only train) 4016 159.42 Fully powered, DNN Compute only 287.44 Fully powered, DNN  Œº ‚àí proÔ¨Åler 255.39 EH +  Œº ‚àí proÔ¨Åle + NV-mems + resizing RAM + Host 159.40 \nTABLE II: Comparison with prior accelerator-based platforms. The systolic array accelerator time multiplexes between per- forming feature extraction for exemplar selection and running the training. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "[8] Niket Agarwal, Tushar Krishna, Li-Shiuan Peh, and Niraj K Jha. Garnet: A detailed on-chip network model inside a full-system simulator. In  2009 IEEE international symposium on performance analysis of systems and software , pages 33‚Äì42.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "The parameter  Œ∑ >  0  penalizes non-participation, ensuring that sensors do not remain idle indefinitely. As discussed, maintaining  Œ∑ > Œ¥  encourages sensors to at least attempt participation rather than always remain offline. Formal Bounds and Conditions \nTo ensure balanced behavior, it is helpful to relate  Œ≥, Œ¥,  and Œ∑  to typical values of accuracy improvement and energy costs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "The scaling up via mil- \n893 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "In this context, our project takes an ambitious step to  democratize  LLM models by exploring the design space of morphable EoEs. It will lead to a more systematic, scalable, robust, cus- tomized and cost-effective LLM models for various application domains. The proposed scalable cross-layer framework will enable the exploration of novel architectural and system-level solutions in addressing the LLM design challenges.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "[55] M. McCloskey and N. J. Cohen, ‚ÄúCatastrophic interference in connec- \ntionist networks: The sequential learning problem,‚Äù in  Psychology of learning and motivation . Elsevier, 1989, vol. 24, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": ". , and is symmetrically distributed around  m  = 0 . Consequently, there is no data in the range  [0 , q  ‚àí 1) , allowing the maximum value of the 13-bit samples to be represented efficiently by a 6-bit signed number.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Therefore, Bit input / BN in meanstheactualloadeddatabits eachbatch.Theterm P ld‚àíbit denotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister. P load = aG√ó (Bits input /BN in )√óP ld‚àíbit   modelsloadpoweroperation. Here,theterms Bits input and BN in denotethenumberof inputbitstoserve MACoperationsforafull-sizedReRAMand thebatchnumberoftransferringtheseinputbitsrespectively .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "In Fig- ure 6(a), a naive scheduling strategy is employed on a  Simple architecture . In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very Ô¨Åne-grain fashion. 3) Execution strategies:  Figure 6 shows Ô¨Åve different execution strategies for a two-layer convolution execution experiencing two power cycles with different levels.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "The impact of wrong labeling is discussed in ¬ß V . The Problem:  However, this exemplar section mechanism has an inherent Ô¨Çaw. Consider a trafÔ¨Åc camera looking at a busy street with a trafÔ¨Åc signal.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "1522‚Äì1525. [20] Google, ‚ÄúPixel Phone Hardware Tech Specs,‚Äù ‚Äùhttps://bit.ly/397dCUB‚Äù. [19] H. Jiang, A. Sarma, M. Fan, J. Ryoo, M. Arunachalam, S. Naveen, and M. T. Kandemir, ‚ÄúMorphable convolutional neural network for biomedical image segmentation,‚Äù in  2021 Design, Automation Test in Europe Conference Exhibition (DATE) , 2021, pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "Modeling Expert Type-Subtype Hierarchy with Tree Ensemble-of-Experts. Our solution will leverage our previous work on multi-stage summarization [186] and multi-agent framework for long-context tasks [187]. Since knowledge domains often exhibit a hierarchical structure, it is natural to model an EoE using a hierarchical approach to save training and inference costs further.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "How- ever, to unleash the remote deployment, and sustainable, yet pervasive, computing capabilities WSNs, development of ef- ficient  energy harvesting WSNs  (EH-WSNs), both for sensing and edge-analytics, plays an essential role. These wireless sensing (EH or otherwise) devices have long relied on compression techniques to mitigate data com- munication overheads [ 32 ,  33 ,  45 ]. However, when applied to low-dimensional sensor data, classical lossy compression techniques tend to discard or distort some important fea- tures, which significantly degrades the inference accuracy.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Why Ensembling? An Ensemble is deÔ¨Åned as a set of clas- siÔ¨Åers whose individual decisions combined in some way to classify new examples. Besides using dense models, ensembling [ 15 ] techniques have been used to achieve higher accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Cocktail takes the accuracy of each model as a probability of cor- rectness and then iteratively constructs a model list, where the joint probability of them performing the classiÔ¨Åcation is within the accuracy target. Next, we solve for the second objective function ( O 2 ) by minimizing  ¬µ C , while maintaining the target accuracy. We tolerate a 0.2% ( Acc margin ) and 5ms ( Lat margin ) variance in  Acc target  and  Lat target , respec- tively.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Bounding and Selecting Hyperparameters  Œª 1 , Œª 2 \nThe choice of  Œª 1  and  Œª 2  affects the curvature of  J ( Œ∏ )  and can influence convergence speed and the location of  Œ∏ ‚àó . They may alter the shape of  J ( Œ∏ ) , encouraging certain regions of parameter space, but they do not prevent convergence. On the con- trary, they may help by smoothing out undesirable minima or limiting model complexity.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Therefore, unlike the 2D video processing where the display can directly read \n242 \n59% \n29% \n6%  6% \nCompute \nMemory Decode Display \n(a) Power breakdown. (b) Overview of  360 ¬∞  video projection. (c) Head movement and pupillary distance as inputs.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "For example, each expert in chains and trees can produce intermediate results, and they can be aggregated into the final manager expert to produce the ultimate result. Task-1.3: Continual Adaptation of EoE through Morphable LLM Experts LLMs require continual learning to keep pace with rapidly evolving knowledge and user demands. How- ever, traditional monolithic LLMs are not well-suited for frequent updates, because training monolithic LLMs often involves wholesale replacement which is prohibitively expensive and challenging.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Over- all, our experimental results show that, on an average,  D¬¥ej`a View  can provide  54%  compute reduction, which translates to  28%  total energy savings compared to the baseline setup. ‚Ä¢  We evaluate our integrated design, including both  EA  and AE , using an open-source 360¬∞ VR video dataset [3] with the traces of 20 users watching 5 different VR videos. Compared to a state-of-the-art scheme [28], our design provides  34%  reduction in projection computations, which translates to  17%  additional energy savings.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "6 , the storage size after our compression is larger than RAHT, since each segment requires one vector storage to store its median/base and (quantized) delta values. 6 s ). However, as also shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Magic Leap 1 is a Wearable Computer for Enterprise Produc- tivity. \"https://www.magicleap.com/en-us/magic-leap-1\". [30]  Xiaoxu Meng, Ruofei Du, and Amitabh Varshney.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Viewer in-consumption engagement in pro- environmental tourism videos: A video analytics approach. Journal of Travel Research , pp. 00472875231219634, 2024.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "This claim is supported by research showing the positive impact of increasing model and dataset size on accuracy [66,92]. Here, we summarize the research directly related to our proposal under the following areas: Algorithms and Models:  LLMs are known for their vast parameter sizes and training datasets, with a com- \nmon belief that larger LLMs yield better performance [64]. Prior works have contributed towards reducing the parameter count and the compute complexity through model pruning [63, 98, 198], knowledge distillation [55,93,113], quantization [22,46,95] along with mixture of experts (MoE) [69], includ- ing dense MoE [37,117,126,166], sparse MoE [42,74,89,145], soft MoE [111,132,178,194], and composition of experts (CoE) [59, 131, 196, 197].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 205,
    "augmented": true
  },
  {
    "text": "Considering the compute mapping of the DNN training, almost all of these de- signs are based on a ‚Äúsystolic architecture‚Äù, performing chains of multiplication and accumulations (MACs). However, these devices take a ‚Äúthroughput-Ô¨Årst‚Äù approach, to minimize the time consumption and seldom optimize power consumption Ô¨Årst. There have also been signiÔ¨Åcant efforts in designing and optimizing specialized DNN training accelerators [ 16 ], [ 27 ], [ 81 ], and many commercial organizations have already devel- oped their own accelerators [ 37 ], [ 95 ] as well.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "These display quality optimizations are orthogonal to our approximation-based proposal, and our approach can be used along with such optimizations. Volumetric Video Streaming, Compression, and Other Opti- mizations:  Volumetric sensor inputs such as LiDAR have large vol- ume and require significant computational power and bandwidth to process/transmit. Targeting them, prior efforts have proposed to optimize their compression ratio, processing performance, and energy efficiency [ 8 ‚Äì 10 ,  16 ,  27 ,  67 ‚Äì 70 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "R EFERENCES \n[1]  C. Xia, J. Zhao, H. Cui, and X. Feng, ‚ÄúCharacterizing DNN models for edge-cloud computing,‚Äù in  2018 IEEE International Symposium on Workload Characterization (IISWC) , pp. 82‚Äì83, 2018. [2]  L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, ‚ÄúSwitched by input: Power efÔ¨Åcient structure for RRAM-based convolutional neural network,‚Äù in  2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "Opportunity 1:  In order to reduce overprovisioning of contain- ers, it is vital to design a workflow-aware resource management (RM) framework that can dynamically scale containers for each function, as opposed to uniformly scaling for all functions. To design such a policy, the RM framework needs to know each function‚Äôs invocation frequency, which is a good estimator of its relative popularity. We introduce weights to estimate the appropriate number of containers to be spawned for each function.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Prior model-serving frameworks like InFaas [ 83 ] are conÔ¨Åned by the accuracy and latency offered by such individual models. However, their high variance due to the Ô¨Çuctuations in training data along with compute and mem- ory intensiveness [ 59 , 65 , 84 ] has been a major impediment in designing models with high accuracy and low latency. Unlike single-model inferences, more sophisticated tech- niques like  ensemble learning  [ 15 ] have been instrumental in allowing model-serving to further improve accuracy with multiple models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the ACM Symposium on Cloud Computing , New York, NY, USA, 2019. Association for Computing Machinery. Burscale: Using burstable instances for cost-effective autoscaling in the public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "https://www.xilinx.com/products/design-tools/ vitis/vitis-platform.html , a. (Accessed on 11/13/2023). AMD.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "Gshard: Scaling giant models with conditional computation and automatic sharding. [91] Feihui Li, Chrysostomos Nicopoulos, Thomas Richardson, Yuan Xie, Vijaykrishnan Narayanan, and Mahmut Kandemir. arXiv preprint arXiv:2006.16668 , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "The llama 3 herd of models. arXiv preprint arXiv:2407.21783 , 2024. [40] Murali Emani, Sam Foreman, Varuni Sastry, Zhen Xie, Siddhisanket Raskar, William Arnold, Rajeev Thakur, Venkatram Vishwanath, Michael E. Papka, Sanjif Shanmugavelu, Darshan Gandhi, Hengyu Zhao, Dun Ma, Kiran Ranganath, Rick Weisner, Jiunn-yeu Chen, Yuting Yang, Natalia Vassilieva, Bin C. Zhang, Sylvia Howland, and Alexander Tsyplikhin.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 169,
    "augmented": false
  },
  {
    "text": "Given extremely long training latencies, we cannot rely on simulation alone as it would take extremely long running times. Observing this, we propose to develop an evaluation framework with three components. The first compo- nent of this framework will employ actual machine experiments on Argonne National Lab (ANL) machines (see the collaboration letter from ANL and our preliminary results [26]).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "99.00% \n99.25% \n99.50% \n99.75% \n100.00% \n0 \n300 \n600 \n900 \n1200 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(b) Media Service. 98.50% \n99.00% \n99.50% \n100.00% \n0 \n200 \n400 \n600 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(c) Hotel Reservation. Figure 10: Real System: Comparison of Total Number of Containers spawned VS SLOs satisfied by each policy.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "[13] AMD. https://developer.amazon.com/en-US/alexa/alexa-ai \", 2024. Alexa. \"",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "In  The Efficient Natural Language and Speech Processing Workshop with NeurIPS , volume 9, 2023. Llm-mq: Mixed-precision quantization for efficient llm deployment. [96] Sean Lie.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Although datacenters also try to take leverage of the diversity of heterogeneous computing platforms, they are much slower and very expensive during adop- tion [50,104,105]. Instead, our chip creation strategy can quickly and frugally take advantage of upcoming accelerators not only from industrial sources but also from academic institutions. Using the expert execu- tion attribute database, we can extract the expert-hardware affinity, corresponding to which the equivalent chiplet versions are integrated to design a chip (in this regard, we will also consider existing and upcoming hardware accelerators [47, 61, 115, 131, 173]).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Takeaway : The Morton codes generated as an intermediate result during geometry compression not only improve the geometry compression by increasing pipeline parallelism, but also help to capture/identify the attribute similarities within a frame as well as across frames. Motivated by this observation, we next propose schemes that can utilize Morton codes for both  geometry and attribute compression in point clouds. IV.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Using the Seattle SOLRAD power trace for January 1, 2022, we simulated 40 hours of continuous learning with 5 different models on Urban TrafÔ¨Åc data [ 97 ] and  Us. We evaluated  Us. ¬¥as  against DaDian- Nao, a power-efÔ¨Åcient DNN training accelerator, with some modiÔ¨Åcations for comparison.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Association for Computational Linguistics. In Kevin Duh, Helena Gomez, and Steven Bethard, editors,  Findings of the Association for Computational Linguistics: NAACL 2024 , pages 1417‚Äì1428, Mexico City, Mexico, June 2024. [182] Wei Zhang, Chen Liu, Xinyu Wang, and Jian Li.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "II. B ACKGROUND AND  M OTIVATION \nBefore getting into the details of the existing issues and possible solutions, we Ô¨Årst outline the computation pipeline of the state-of-the-art  360 ¬∞ VR streaming (Fig. 1: A  360 ¬∞  video processing pipeline on a battery-backed stereoscopic HMD with an Inertial Measurement Unit (IMU) and an SoC equipped with a GPU [28], [39].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "We set the SLO at 1000ms. We compare these metrics for  Kraken  against the container provisioning policies of Archipelago [ 44 ],  Fifer  [ 32 ] and  Xanadu  [ 27 ], which we will, henceforth, refer to as  Arch ,  Fifer  and  Xanadu , respectively. Additionally, we compare  Kraken  against policies with (a) statically assigned function probabilities ( SProb ) and (b) func- tion probabilities that dynamically adapt to changing invoca- tion patterns ( DProb ).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "1‚Äì5. IEEE, 2020. In 2020 IEEE International Symposium on Circuits and Systems (ISCAS) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2001.08023 , 2020. [50] Google. Announcing trillium, the sixth generation of google cloud tpu, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "¬¥as  optimizes the entire solution space, maximizing hardware reuse for exemplar selection and micro- proÔ¨Åling while addressing the training task. The system can turn off individual compute-tiles to accommodate runtime power variability (see ¬ß IV-B ) and enable seamless operation during power reductions. Overall, Us.¬¥as demonstrates the viability of sustainable con- tinuous learning at edge servers, encompassing advancements in energy harvesting, algorithmic techniques, and hardware adaptation.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Task Ideal Latency Algo. Pose Estimate \n33  ms Kimera [53] \nEye Track \n33  ms NVGaze [26] \nScene Reconstruct \n100  ms InfiniTAM [50] \nHologram 33  ms GSW [49, 63] \ntasks and interacts with more hardware resources [ 61 ]. We want to emphasize that, compared to virtual reality (VR), the AR video processing typically incurs additional computational \nTable 1: Ideal latency requirements [19].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Figure 2 depicts the number of containers provisioned per function for three container provisioning policies subject to a Poisson arrival trace ( ùúá = 25 requests per second (rps)) for three applications. The static provision- ing policy is representative of current platforms [ 50 ] which spawn containers for functions in a workflow-agnostic fash- ion. Xanadu  [ 27 ] represents the policy that scales containers only along the Most Likely Path (MLP), which is the request‚Äôs expected path.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "-18.87 \n-9.14 \n-10.2 -11.35 \n-20 \n-15 \n-10 \n-5 \n0 \n0% 20% 40% 60% 80% 100% \nRapidly Varrying \nModerately \nstable \nRelatively \nStable \nFully Powered \nLoss in accuracy in % \nContribution of Policy \nExemplar Profiler Morphable No Optimization \n(a) Contribution of components on video data \n0 \n0.1 \n0.2 \n0.3 \n0.4 \n0.5 \n0.6 \nBest Average Best Average \nUsas iCARL Usas Optimus \n# Relative Exemplars # Relative Epoch \nRelative Error wrt Oracle  \n(Lower  is better) \n(Audio) Audio MNIST (Audio) CHiME Home (3D PC) KITTI Vision \n(3D PC) nuScenes (IMU) Bearing Fault (IMU) MHEALTH \n(b)  Us. ¬¥as  beyond video data \n0 \n10 \n20 \n30 \n40 \n50 \nPredictable Sporadic Predictable Sporadic Predictable Sporadic \nLarge - Video (SA size: 256; AP: 16W) \nMedium - Audio (SA size: 128; AP: 8W) \nSmall - IMU (SA size: 128; AP: 2W) \n% of Unfinished  Compute  \ndue to Power Failure \nAverage Power Baseline SW Backup SW + NVM HW + NVM \n(c)  Us .¬¥as  hardware - different data and energy \nFig. 10: Contribution of different components of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 336,
    "augmented": false
  },
  {
    "text": "This immersive experience comes at the cost of additional computations - not only is the video being streamed,  the streaming itself changes with the head orientation. Moreover, streaming requires two projections for both the eyes. 360 ¬∞ video streaming creates an interactive and immersive environment by connecting the user and the video content; the users are allowed to move their heads‚Äô orientation to enjoy the surroundings in all perspectives along with a 3D view, i.e., a different view for each of the eyes, and hence creating an illusion that the user is present at the scene rather than viewing it on a projected surface.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": ". . ,  Q m  such that, for each subset  Q j ,   P q i ‚ààQ j   E q i   ‚â§ E b , and  m  is minimized.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "2020. Distributed inference acceleration with adap- tive DNN partitioning and offloading. In  IEEE INFOCOM 2020-IEEE Conference on Computer Communications .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "403‚Äì406. IEEE, 2018. In  2018 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "In Figure 5, as- suming both column and row indices of ùëá start at 0, an entry ùë° 0 4  represents the transition probability from  NGINX ‚Äôs state to  Follow ‚Äôs state and is equal to 0.2. An additional state,  end , is added to represent the state the model transitions to after a path in the DAG is completely executed. An example of a Transition Matrix for the  Social Network , with 11 functions, is depicted in Figure 5.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "To calculate the required number of containers for a single function that has multiple context-independent states associated with it, we take the sum of the calculated values for all of those states. Users submit requests in the form of invocation triggers to applications  1  hosted on a Serverless platform. 4 Overall Design of Kraken \nKraken 1   leverages the function weight estimation model from the above section along with several other design choices as outlined in this section (Figure 6).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "[5] W. Amit Katwala, ‚ÄúThe spiralling environmental cost of our lithium \nbattery addiction,‚Äù https://www.wired.co.uk/article/lithium-batteries- environment-impact , May 2018, (Accessed on 07/08/2023). [7] AWS Outposts, ‚Äúhttps://aws.amazon.com/outposts/rack/hardware- specs/?nc=sn&loc=4.‚Äù [8] Azure Stack Edge, ‚Äúhttps://azure.microsoft.com/en- us/services/databox/edge/.‚Äù [9] O. Banos, C. Villalonga, R. Garc¬¥ƒ±a, A. Saez, M. Damas, J. Holgado- \nTerriza, S. Lee, H. Pomares, and I. Rojas, ‚ÄúDesign, implementation and validation of a novel open framework for agile development of mobile health applications,‚Äù  BioMedical Engineering OnLine , 2015. [6] G. Ananthanarayanan, V. Bahl, P. Bod¬¥ƒ±k, K. Chintalapudi, M. Philipose, \nL. R. Sivalingam, and S. Sinha, ‚ÄúReal-time Video Analytics ‚Äì the killer app for edge computing,‚Äù  IEEE Computer , 2017.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 308,
    "augmented": true
  },
  {
    "text": "Batching reduces the number of containers spawned for each function by a factor of its batch size (Algorithm 1  b  ). Requests are batched onto containers in a fashion similar to the First Fit Bin Packing algorithm [ 36 ]. This slack is leveraged by  Kraken  by batching multiple requests to the functions by queueing requests at their con- tainers.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "When needed, this material will be ported to other formats as well. Metadata will most likely be needed as a part of curriculum development process and training. These will be stored in XML and web formats.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Third, the presence of conditional branches in some DAGs can lead to uncertainties in determining which functions will \n153 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. be invoked by different requests to the same application. For instance, in a train-ticket application [ 40 ], actions like make_reservation  can trigger different paths/workflows (sub- set of functions) within the application.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "com/ . (Accessed on 09/12/2023). [121] Julius Odede and Ingo Frommholz.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "[28]  T. Huang and Y. Liu, ‚Äú3d point cloud geometry compression on deep learning,‚Äù in  Proceedings of the 27th ACM International Conference on Multimedia , 2019, p. 890‚Äì898. Restrictions apply. [27]  L. Huang, S. Wang, K. Wong, J. Liu, and R. Urtasun, ‚ÄúOctsqueeze: Octree-structured entropy model for lidar com- pression,‚Äù in  CVPR , 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "All these DNNs are executed with the state-of-the-art checkpointing and scheduling approach (Maeng & Lucia, 2018). Baseline  Full Power  is a DNN designed by iNAS (Mendis et al., 2021) for running while the system is battery-powered and has to hit a target SLO (latency < 500ms). Baseline  AP  is a DNN compressed to fit the average power of the energy harvesting (EH) environment using iNAS (Mendis et al., 2021) and energy-aware pruning (EAP) (Yang et al., 2017, 2018).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Cifar-100 (cana- dian institute for advanced research), 2010.  http://www.cs.toronto. edu/~kriz/cifar.html . [50]  Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "[52] Google. Google notebooklm. \" https://notebooklm.google/ \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "Journal of the Franklin Institute , 2023. ISSN 0016-0032. doi: https: //doi.org/10.1016/j.jfranklin.2023.11.038. URL  https://www.sciencedirect.com/science/ article/pii/S0016003223007536 .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "13‚Äì24. [30] L. Liu, R. Zhong, W. Zhang, Y. Liu, J. Zhang, L. Zhang, and M. Gruteser, ‚ÄúCutting the Cord: Designing a High-quality Untethered VR System with Low Latency Remote Rendering,‚Äù in  Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services , ser. MobiSys ‚Äô18, 2018, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "In fact, if frame-2 does not vary much with respect to frame-1, intuitively, there would be temporal locality between the two frames. Thus, to further improve the attribute compression efÔ¨Åciency, in the next section, we investigate the inter-frame similarity opportunity. Instead of throwing more compute power, we want to emphasize that, the discussion in this section only focuses on the attribute locality within one frame, which has ignored the potential localities among consecutive frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Although parameters  Œ∏  can theoretically be updated through on-edge training, we assume that frequent retraining in situ is prohibitively expensive given energy constraints. Thus, Œ∏  remains largely static post-deployment. Sensors focus on inference using their local copies of  f Œ∏ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Although the spike-based scheme [ 5 ] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input/output data. ‚Ä¢  For the ReRAM circuit concerned works [ 6 ], [ 8 ], although they are lightweight, they  cannot  be dynamically reconÔ¨Ågured to adapt changing power levels. It is known that the energy harvesting system often suffers from power failures and works in an intermittent mode; so, the spike-based data injection scheme is not favorable.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "To address this, energy harvesting (EH) technolo- gies have emerged as a viable solution, enabling sensors to convert ambient energy (e.g., solar, thermal, or vibration) into electrical power. Introduction \nThe rapid proliferation of the Internet of Things (IoT) has sparked a tremendous growth in the scale and diversity of sensor deployments, from smart homes to expansive in- dustrial and environmental monitoring systems. As these networks continue to expand, sustaining continuous opera- tion in the face of finite power sources becomes a paramount concern.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "(Sec. 2.2) ‚Ä¢  To capture these two approximation opportunities from both the user and object perspectives, first, the prior  foveated ren- dering  idea (denoted as  Inter-Holo  design) has been imple- mented (in Sec. 4.3) and found to work well (in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Modeling Expert Collaboration with Graph Ensemble-of-Experts. This procedure repeats  ‚åä L/k ‚åã times in a single run where  L  is the number of layers in LLM. When training, a document of NLP is first routed to CS in the first layer, then routed to AI, and NLP.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "4. 2 Cocktail is ascribed to having the perfect blend of models in an ensemble. Applications \nImage  Recognition NLP Recommender  Systems \nModels \nVM \nVM \nVM VM VM \nVM \nFrameworks \nCloud \nResources \nSLO \nAccuracy \nLatency \nUsers \nBurstables Spot CPU GPU \nCost \nLatency \nFigure 2:  The overall framework for model-serving in public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "This research was partially supported by NSF grants #1931531, #1955815, #1763681, #1908793, #1526750, #2116962, #2122155, #2028929 ,and we thank NSF Chameleon Cloud project CH-819640 for their generous compute grant. All product names used in this publication are for identiÔ¨Åcation purposes only and may be trademarks of their respective companies. References \n[1]  Mart√≠n Abadi.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "We also assume that energy resources, accuracy gains, and reward/penalty parameters are finite and bounded, and that sensors have consistent estimation mechanisms for  ‚àÜ A i ( t ) and   ÀÜ E i ( t  + 1) . Potential Function Construction \nTo prove convergence, we define a potential function that reflects the collective utility of the sensor network: \nŒ¶( a ( t )) = \nN X \ni =1 U i ( a i ( t ) ,  a ‚àí i ( t )) . Since  U i ( t ) =  R i ( t )  ‚àí C i ( t ) , we have: \nŒ¶( a ( t )) = \nN X \ni =1 [ R i ( t )  ‚àí C i ( t )] .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 203,
    "augmented": true
  },
  {
    "text": "We outperform the MCDNN [7] and Euphrates [9] in terms of accuracy, and Potluck [12] and DeepCache [8] in terms of performance improvement. B ACKGROUND AND  R ELATED  W ORK \nIn this section, we start our discussion by explaining a typical DNN execution on mobile devices for video analytics. II.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "A. Preamble to Origin \nHuman activity has temporal continuity, i.e. most activ- ities last for some duration (in the range of hundreds of milliseconds to seconds). Therefore, there is an opportunity to skip some intermediate inferences over the period of an activity in order to increase harvesting duration and the prob- ability that an initiated inference will complete.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "III. Origin : A N INTELLIGENT SCHEDULER MEETS A LIGHT WEIGHT AND ADAPTIVE ENSEMBLE LEARNER \nWe design a EH-WSN setup for HAR, where the user has three EH inertial measurement units (IMUs), at the \nchest, left ankle and right wrist 1 . It is obvious that the raw data sensed by each sensor would be different, even for the same activity, because of the difference in move- ment and dynamics.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "In  2008 IEEE Virtual Reality Conference . 145‚Äì152. [29]  Magic Leap.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "[31]  T. Karras, ‚ÄúMaximizing parallelism in the construction of bvhs, octrees, and k-d trees,‚Äù in  Proceedings of the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics , 2012, p. 33‚Äì37. 118‚Äì123, 2019. [30]  Jeroen Baert, ‚ÄúMorton encoding/decoding through bit inter- leaving: Implementations,‚Äù  ‚Äùhttps://bit.ly/30Rf506‚Äù , 2013.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "[8]  2020. https://github.com/rakyll/hey. [7] 2020. hey HTTP Load Testing Tool.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "class ] 23: end for 24: P class  ‚Üê max ( weighted _ vote , key  =  class ) 25: returnP class 26:  end procedure \n4.1.1 Class-based Weighted Majority Voting \nThe model selection policy described above ensures that we only use the necessary models in the majority voting. In or- der to increase the accuracy of majority voting, we design a weighted majority voting policy  3  . The weight matrix is designed by considering the accuracy of each model for each class, giving us a weight matrix of  L √ó N  dimension, where  L is the number of unique labels and  N  is the number of models used in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Related Work \n1) Point Cloud Use-cases:  Recently, PC is being widely used in various Ô¨Åelds, such as AR/VR [ 46 ], [ 81 ], telepres- ence [ 43 ], [ 57 ], [ 86 ], virtual tourism [ 12 ], [ 50 ], teleopera- tion [ 83 ], telemedicine [ 51 ], video streaming [ 24 ], [ 37 ] and gaming [ 81 ], [ 87 ], etc. where both geometry and attributes are essential as the contents are consumed by people for infotainment purpose. Almost all of these applications can be categorized as interactive volumetric video streaming.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "The sensor computes the correlation (  1a  ) between the stored ground truth and the current data. The sensor also stores one ground truth trace for each activity. The moving window is designed using a counter to shift the streaming data.)",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "IV. E VALUATION \nIn this section we explain the strategy for evaluating  Origin . The associated conÔ¨Ådence matrix boosts the classiÔ¨Åcation accuracy and also resolves ties while voting.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "360 ¬∞  Video Streaming Pipeline \nThe key  difference  between a  360 ¬∞ VR video compared to a conventional 2D video is that the former provides content-rich immersive user experience. Wearing a head mounted display (HMD), a user navigates in a virtual world by  looking around , or  moving around  [55], to interact with the virtual world. As shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "We first restate the key assumptions and the utility model. B. Equilibrium Existence and Convergence with Reward-Based Utility \nIn this appendix, we provide a detailed and formal proof that the best-response dynamics, incorporating the newly defined reward-based utility functions, converge to a Nash equilibrium (NE). Regular re-tuning may be warranted as oper- ating conditions, energy harvesting patterns, or accuracy requirements evolve over the network‚Äôs lifetime.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "[31] X. Liu, Q. Xiao, V. Gopalakrishnan, B. Han, F. Qian, and M. Varvello, ‚Äú360¬∞ Innovations for Panoramic Video Streaming,‚Äù in  Proceedings of the 16th ACM Workshop on Hot Topics in Networks , ser. MobiSys ‚Äô18, 2018, pp. 68‚Äì80.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "[43]  Johann Hauswald, Michael A. Laurenzano, Yunqi Zhang, Cheng Li, Austin Rovinski, Arjun Khurana, Ronald G. Dreslinski, Trevor Mudge, Vinicius Petrucci, Lingjia Tang, and Jason Mars. In  ASPLOS , 2015. Sirius: An open end-to-end voice and vision personal assistant and its implications for future warehouse scale computers.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "(a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation \nIf we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve ‚Äúcontinuous progress‚Äù under lower power supply. This is because the starting power requirement of the RCA is reduced, and the system can thus get through power failures and translate even the low input energy into forward progress. If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles  PC2, PC4, PC5  and  PC8  under limited power budget, as depicted in Table II and Figure 1.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 211,
    "augmented": false
  },
  {
    "text": "Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four  25  √ó  6  ReRAM crossbars, each can be mapped to six kernels, all sized  5 √ó 5 √ó 1 . In this case, the unused energy will be wasted, resulting in low energy efÔ¨Åciency. (ii) Underutilized energy:  When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "We propose a novel and efficient approach for continual learning of EoE. Domain-Based Expert Splitting and Merging. Each expert can also grow to absorb new knowledge and shrink to discard obsolete knowledge.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "PI Das has been involved with organizing the  Visit In Engineering Weekend  (VIEW) program for students entering their junior and senior years of high school, which fosters interest in engineering. ‚Ä¢  Undergraduate Research Experience:  The PIs have participated in the Summer Research Opportunities internship program that hosts students from under-represented communities with interest in pursuing graduate studies. The PIs will seek funding for these activities from Penn State, and in particular from the ICDS (Institute for Computational and Data Sciences).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Both  InFaas and  Clipper  share  Cocktail ‚Äôs implementation setup to ensure a fair comparison with respect to our design and execution environment. For instance, both  Clipper  and  InFaas  employ variants of a reactive autoscaler as described in Section  4.2.2 . However, in our setup, both beneÔ¨Åt from the distributed au- toscaling and prediction policies, thus eliminating variability.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Qlora: Efficient finetuning of quantized llms. [35] Shichen Dong, Wen Cheng, Jiayu Qin, and Wei Wang. Advances in Neural Information Processing Systems , 36, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "To leverage this opportunity, we next study the coordinate projection results relationship between left-eye and right-eye. If there exists a simple mechanism to describe the difference between the two projection matrices of the two eyes ( P L  and  P R ), one can simplify the computation from matrix  multiplications  to matrix  additions . Distance Vector Study:  Let us further look into the detailed mapping of a  360 ¬∞ frame (in equirectangular format) onto a 2 D  FoV frame in the Projection Mapping stage (refer  c  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "Instead of restricting the power constraint to the average power of the entire power trace, the constraint can be relaxed to the average power requirement of the extended round-robin \n0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 AAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baseline-2 Baseline 1 \n(a)  Accuracy with MHEALTH dataset. 0 20 40 60 80 100 \nWalking Climbing Cycling Running Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 CAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baselin-2 Baseline-1 \n(b)  Accuracy with PAMAP2 dataset. Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 231,
    "augmented": false
  },
  {
    "text": "6 , the storage size after our compression is larger than RAHT, since each segment requires one vector storage to store its median/base and (quantized) delta values. Although the  48 √ó  speedup brought by our proposal is promising in terms of performance gain, the observed 2 √ó  compression inefÔ¨Åciency needs to be addressed. 3) How to Further Improve the Compression EfÔ¨Åciency for Attributes?",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type. In CNNs, for instance, MACs between the feature map data and kernel weights comprise nearly 90% of the total operations [ 2 ], [ 3 ]. Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efÔ¨Åciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "Salient Store  , with its intelligent data orchestration and acceleration, can provide up to  6 . 18 √ó  latency and  6 . 13 √ó  data movement reduction, compared to classical systems.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "[43] Y. Xu, X. Liu, L. Qin, and S.-C. Zhu, ‚ÄúCross-View People Tracking by Scene-Centered Spatio-Temporal Parsing,‚Äù in  Proceedings of the Thirty- First AAAI Conference on ArtiÔ¨Åcial Intelligence , 2017, p. 4299‚Äì4305. [44] J. Redmon and A. Farhadi, ‚ÄúYOLOv3: An Incremental Improvement,‚Äù CoRR , 2018. [45] B.-G. Han, J.-G. Lee, K.-T. Lim, and D.-H. Choi, ‚ÄúDesign of a Scalable and Fast YOLO for Edge-Computing Devices,‚Äù  Sensors , 2020.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 178,
    "augmented": false
  },
  {
    "text": "Frugalml: How to use ml prediction apis more accurately and cheaply. [20] Lingjiao Chen, Matei Zaharia, and James Zou. In  Advances in Neural Information Processing Systems (NeurIPS) , 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "We plot the accuracy of different strategies described throughout the paper. Fig. Origin  uses the DNNs of Baseline-2 for the classiÔ¨Åcation tasks.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "To meet the heavy compute demands of these applications, most of AR applications are run using high-end desktop/server-class GPUs [ 18 ,  55 ], or specialized hardware accelerators [ 35 ] on cloud platforms [ 16 ,  27 ]. the limited battery capacity prevents users from enjoying their AR devices for extended periods of time. However, since most of these applications are now running on low-power mobile devices, and frequent communi- cation of data to and from cloud via wireless medium is inefficient, optimization of an AR pipeline to maximize the compute and en- ergy efficiency, while providing adequate QoS, at an edge device is an architectural challenge.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "3. Tune  Œª 1 , Œª 2  based on validation performance. If the model overfits high-SNR data, increase  Œª 1 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "From this figure, one can observe the following: First, in general, these two steps take similar times to execute, due to the similar procedures they \nAlgorithm 1:  Depthmap Hologram Algorithm [4, 18]. To study how the number of depth planes affects the hologram performance, we profile the execution latency from a typical edge GPU device [ 36 ], generating holograms with different number of depth planes (assuming the same number of pixels in each plane), and the results are plotted in Fig. 4b.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "The modular nature of our system allows experts to be trained separately and then combined in multiple configurations. This offers two key advantages: first, it enables agile adaptation and targeted training to respond to evolving knowledge domains and user requirements; and second, it allows for optimization across different system layers to improve both architectural efficiency and overall performance. Tree Structure \nGraph¬† Structure \nChain Structure \nExpert¬† Function \nForward¬† \nPass \nType/ Subtype \nRouter 1 Router 2 \nRouter 1 \nRouter 2 \nCompo- \nsition \nTask-1.1 to Task-1.2 \nTask-1.2 to Task-1.4 \nTask-1.2 to Task-1.3 \nExpert Splitting \nData \nData \nData \nExpert Merging \nAn Expert from¬† Trained¬† EoE  Model¬†¬† \nTrain ¬†on Domain Datasets \nReinforced  EoE  Expert \nwith New Knowledge \nRemove ¬†Components of Expert¬† Add  Components of Expert \nContinual Learning \nAvaliable¬† Accelerators \nRemove Uncommon¬† \nPathes \nUser¬† Preferences Remove Unwanted \nExperts & Reform \nUser Logs \nRemove Unavaliable \nExperts & Reform \n¬† Experts \nUser Selected/ Unavaliable¬†Experts \nCommonly Routed¬† \nPath \nEoE  Network \nMemory Constraint \nAccelerator \nConstraint \nDomain Experts Skill Experts \nLanguage Experts Data Experts \nMedical Science Law Finance Math Code Retrieval \nDocument Table Image \nGraph \nEN CN TR HI \nSumma- \nrization \nFigure 3 :  An overview of four tasks in Thrust-1.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 295,
    "augmented": false
  },
  {
    "text": "For example, if  ùëÉùêø ùë° is estimated to be 25 requests, then from Figure 5, we obtain the number of containers needed for functions at depth,  ùëë =  1, by multiplying 25 with  ùëÉ 1  (which is  ùëá 1 ¬∑ P 0 ). Consequently, the total number of containers re- quired for each function in the application can be computed \n157 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. Notation Meaning T Transition Matrix P ùëë Probability Vector for functions at depth,  d n # functions in application or # states in model f  ùëñ ,  f ùëó functions along row,  i  or column,  j  in  T t  ùëóùëñ Transition probability from  f  ùëó ùë°ùëú f ùëñ W ùëù Probability calculation time window t Request arrival time d # time steps for which transitions are done PL ùë° Scalar that represents the anticipated # requests at time,  t NC ùëë ùë° # containers needed for functions at depth  d , at time  t Table 3: Notations used in Equations.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 263,
    "augmented": false
  },
  {
    "text": "2019. JETSON AGX XAVIER AND THE NEW ERA OF AUTONOMOUS MACHINES. \"http://info.nvidia.com/rs/156-OFN-742/images/Jetson_AGX_ Xavier_New_Era_Autonomous_Machines.pdf\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "IV , and then treat the obtained delta values as new attributes, and Ô¨Ånally feed them again to the encoder to further increase the compression efÔ¨Åciency). ‚Ä¢  Intra-Inter-V1 : As mentioned in Sec. V , only part of the blocks/segments can be directly approximated by the reference block.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Underline indicates the expert function. Expert Repository. x  is the input text,  D  is the document for retrieval, and  T  is the length of the generated text.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Towards Foveated Rendering for Gaze-Tracked Virtual Reality. ACM Trans. 2016.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:1907.11692 , 2019. [56]  Zhenyu Lu, Xindong Wu, Xingquan Zhu, and Josh Bongard. Ensemble pruning via individual contribution ordering.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Fifer: Tackling Resource Underutilization in the Serverless Era. In  USENIX Middleware Conference , 2020. [37]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Mahmut Taylan Kandemir, Bhuvan Urgaonkar, George Kesidis, and Chita Das.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "5a, only the soccer ball  object is located inside the viewing window in the current frame,  Frame-I , while  football  and  box  are not. 5. ‚Ä¢  In the  Viewing-Window  scenario shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "[15]  2021. Expedia Case Study - Amazon AWS. https://mikhail.io/ serverless/coldstarts/azure/.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "ACM SIGARCH Computer Architecture News , 39(3):69‚Äì80, 2011. [109] Asit K. Mishra, Jorge Albericio Latorre, Jeff Pool, Darko Stosic, Dusan Stosic, Ganesh Venkatesh, Chong Yu, and Paulius Micikevicius. Accelerating sparse deep neural networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "517‚Äì531. [69]  Haibo Zhang, Shulin Zhao, Ashutosh Pattnaik, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 7b, overall, the  Inter-Holo  scheme provides a 1 . 15 √ó  speedup compared to the baseline.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "9a. Moreover, when adopting the FI+SI+PI, compared with the FI+SI, around  12%  more energy can be saved, as shown in Fig. 9c.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "[55]  Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoy- anov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "In this regard, the metric  throughput  measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios. The Ô¨Årst one is that we expect more energy can be used for program progress. The other is more subtle in that we expect the power can be consumed quickly in order to receive more energy from outside.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "We will continue to develop new week-long courses introducing students to LLMs/Generative AI and inspiring them through hands-on application and system building activities. PI Zhang has participated in the 2024 summer camp, and he will lead this effort for the future years. Our earlier camps have already introduced participants to basic concepts in programming, building vision systems that assist visually impaired and learning skills towards building a basic embedded vision system, program- ming for robotics and exposure to various emerging tools in computing.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "2019. Archipelago: A scalable low-latency serverless platform. [44]  Arjun Singhvi, Kevin Houck, Arjun Balasubramanian, Mo- hammed Danish Shaikh, Shivaram Venkataraman, and Aditya Akella.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "2004. Journal of Artificial Intelligence Research  22 (2004), 385‚Äì421. On Prediction Using Variable Order Markov Models.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "We solve this issue by a adopting a thresholding mechanism based on model confidence, and accordingly decide to consult the cloud for better accuracy on less-confident local predictions. If the user task can tolerate lower accuracy prediction, or the user is more conservative about the cost associated with sending a request to the cloud, they could decide to change the threshold according to their requirements. Deciding a proper threshold is application and quality of service dependent and remains a user tunable parameter.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "We used Pytorch [46] to proÔ¨Åle the accuracy behavior of two videos picked from VIRAT [33] dataset, and show that our proposal can adaptively support such alternate design choices. More speciÔ¨Åcally, the  < accuracy-loss, energy- savings >  pairs are plotted in Fig. 10.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "[171] Dongjie Yang, XiaoDong Han, Yan Gao, Yao Hu, Shilin Zhang, and Hai Zhao. Pyramidinfer: Pyramid kv cache compression for high-throughput llm inference, 2024. ACM, 2017.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Yang Yang, Zhi Guan, Huiping Sun, and Zhong Chen. Accelerating rsa with fine-grained parallelism using gpu. In  Information Security Practice and Experience: 11th International Conference, ISPEC 2015, Beijing, China, May 5-8, 2015, Proceedings , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "The Problem Space:  To address the multi-faceted challenges of sustainable, scalable and privacy-preserving continuous learning at edge servers, several crucial problem spaces must be explored. Firstly, the issue of  (non-)supervision  arises, demanding the ability to label data without human interven- tion to preserve privacy during the learning process. While recent works [ 12 ], [ 46 ] have attempted to tackle this concern through student-teacher paradigms, efÔ¨Åciently deploying such approaches in complex data modalities (e.g., multi-class video, 3D point cloud) remains a formidable challenge.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "Note that this step is slightly different from the one in the prior pipeline shown in Fig. ‚Ä¢  Octree Construction 4 :  Using the Morton codes generated in the previous step, now the octree can be constructed in parallel by employing techniques similar to [ 31 ], [ 64 ]. This additional pre-processing step can draw an overall layout for all the points, which will further help to parallelize the octree construction.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "In  2019 IEEE International Conference on Cluster Computing (CLUSTER) , pages 1‚Äì13, 2019. Kube-knots: Resource harvesting through dynamic container orchestration in gpu- based datacenters. [157] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "[52]  Stephan Reichelt, Ralf Haussler, Norbert Leister, Gerald Futterer, Hagen Stolle, and Armin Schwerdtner. In  15th IEEE International Conference on Embedded Software and Systems . 1‚Äì8.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "II. B ACKGROUND AND  R ELATED  W ORK \nA. Background \nPoint Cloud in Real Life:  Point Cloud (PC) is a set of points which represent objects or shapes in a 3D space where each point/voxel (3D equivalent of a 2D pixel) contains its 3D location (x, y, z coordinates), as well as some attributes (e.g., colors, normal, etc.).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "[15]  Stuart Golodetz, Michael Sapienza, Julien Valentin, Vibhav Vineet, Ming-Ming Cheng, Anurag Arnab, Victor Adrian Prisacariu, Olaf Kaehler, Carl Yuheng Ren, David W. Murray, Shahram Izadi, and Philip H.S. \"https://medium.com/demagsign/meet-the-humans- of-the-future-holograms-digital-humans-and-deep-fakes-35024b881545\". Torr.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output. With this design setting, the ReRAM size only needs to be equal to the kernel size, and the ReRAM scale does not need to be extended using a bit composing scheme (e.g. as in ISAAC [ 3 ]).",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "This  maximizes data and resource reuse , and the pipeline for inference and compression do not diverge from the get going. Furthermore, neural codecs offer us the flexibility to approximate the computation (using quantization) to further enhance efficiency. Since they also use the computation blocks of the standard neural network, they can be jointly trained along with the classifier network to perform as the feature extraction and encoding backbone, thereby maximizing the utilization of the inference pipeline, and reducing the computation needed for compression.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "In 2020 IEEE International Symposium on Circuits and Systems (ISCAS) , pp. 1‚Äì5. IEEE, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "Else- vier. Seeker , accounting for the available energy budget, con- siders the following decisions:  D0:  Test for data similarity using correlation, and if similarity is found then communi- cate the results to the host;  D1:  DNN at sensor with raw data + Communicate the results to the host;  D2:  Try Quantized \n8 \nStart Current Data \nLast Data \nCorrelation \nPower Predictor\nAbstract to predictive maintenance . With the help of an activity-aware and recoverable coreset construction and low-power hardware design, we can effi- ciently communicate inferences or compressed data to the host device with minimum power and latency overheads.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "A. Inter-Frame Attribute Compression \n1) What is the Temporal Opportunity? :  As we have shown earlier in Fig. 3  b  , two blocks (a set of points) which are located close to one another are likely to contain similar color pixels.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "And (2), inserting the new point into the current octree. In this case, the side length of the bounding box cube becomes 2 , and now  P 0  is located inside the bounding box. In this case,  P 0 is located in the  7 th  child of the  root  node, and the  root  node now stores the occupy information, which is  00000001  (the right-most  1  indicates a ‚Äúchild‚Äù in  7 th  leaf node).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "D√©j√† View: Spatio-Temporal Compute Reuse for Energy-Efficient 360 ¬∞  VR Video Streaming. [70]  Shulin Zhao, Haibo Zhang, Sandeepa Bhuyan, Cyan Subhra Mishra, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "The rate of exponential smoothing depends on the scheduler used - while for the conservative scheduler the predictor always underestimated the power (shallow smoothing), the eager scheduling uses the direct output of the predictor (steeper smoothing). In either case, the predictor predicts the power with  ‚âà 95% (peak of 98 . 72 (with real solar power trace) and minimum of 89 .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "By tackling the dual challenges of sensor unreliability and energy scarcity through a rigorous game-theoretic and fed- erated learning lens, our work addresses a critical gap in the design of sustainable, intelligent EH-WSNs. ‚Ä¢  Demonstrated Performance Gains:  Through simula- tions  (add simulation details later) , we show that our inte- grated framework outperforms baseline approaches‚Äîsuch as always-on participation or simplistic energy-based selec- tion‚Äîby achieving higher inference accuracy, lower energy consumption, and more sustainable long-term operation in EH-WSNs. Sensors strategically decide when to ex- pend energy on local model updates and when to engage in inference tasks, ultimately maximizing their long-term contribution to the network‚Äôs performance.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 182,
    "augmented": true
  },
  {
    "text": "[16] Y. Chen, T. Luo, S. Liu, S. Zhang, L. He, J. Wang, L. Li, T. Chen, \nZ. Xu, N. Sun  et al. , ‚ÄúDadiannao: A machine-learning supercomputer,‚Äù in  2014 47th Annual IEEE/ACM International Symposium on Microar- chitecture . IEEE, 2014, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Deep Learning mit Python und Keras: Das Praxis- Handbuch vom Entwickler der Keras-Bibliothek . MITP-Verlags GmbH & Co. KG, 2018. [22]  Francois Chollet.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "6.3 Sensitivity Analysis \nIn this section, we analyze the sensitivity of  Cocktail  with respect to various design choices which include (i) sampling interval of the accuracy measurements, (ii) spot-instance fail- ure rate and (iii) type of datasets and applications. 6.3.1 Sampling Interval \nTo study the sensitivity with respect to the sampling interval for measure accuracy loss/gain, we use four different intervals of 10s, 30s, 60s and 120s. Figure  13  plots the average number of models (bar- left y-axis) and cumulative accuracy (line- right y-axis) for the different sampling intervals for queries with three different constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "An Ensemble is deÔ¨Åned as a set of clas- siÔ¨Åers whose individual decisions combined in some way to classify new examples. This has proved to be more accurate than traditional single large models because it inherently re- duces incorrect predictions due to variance and bias. The commonly used ensemble method in classiÔ¨Åcation problems is bagging [ 33 ] that considers homogeneous weak learners, learns them independently from each other in parallel, and combines them following some kind of deterministic aver- aging process [ 18 ] or majority voting [ 49 ] process.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "In this paper, the foveated rendering idea (denoted as  Inter-Holo  design) has been implemented (in Sec. 4.3) and found to work well (in \n504 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "com/ . [121] Julius Odede and Ingo Frommholz. (Accessed on 09/12/2023).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "Sensors must carefully balance immediate accuracy gains against conserving energy for future tasks, while also antici- pating the behavior of other sensors that may be collaborat- ing or competing. To address these interdependent decisions, we employ a game-theoretic framework. Unlike simple heuristic meth- ods that ignore future resource allocation or complex ap- proaches like reinforcement learning that may be too costly to implement, game theory provides equilibrium guaran- tees.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Co-locating this compute along with the inference and training would definitely hinder the critical path. 3 We assume the data to be eventually available in the data repository, where they can be properly stored for efficient lookup. This can be done by periodically transporting the data by swapping out storage bays.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "The details are described below. Algorithm 2  Reactive Scaling \n1:  for  Every Monitor_Interval= DR  do 2: Reactive_Resource_Manager ( ‚àÄ ùëìùë¢ùëõùëêùë°ùëñùëúùëõùë† ) 3:  procedure  Reactive_Resource_Manager( func ) 4: cl  ‚Üê ùê∂ùë¢ùëüùëüùëíùëõùë° _ ùêøùëúùëéùëë ( ùëìùë¢ùëõùëê ) 5: func.existing_con  ‚Üê ùê∂ùë¢ùëüùëüùëíùëõùë° _ ùëÖùëíùëùùëôùëñùëêùëéùë† ( ùëìùë¢ùëõùëê ) 6: if l c ùëô f ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m ‚â§ func.existing_con  then  a \n7: reqd_con  ‚Üê l c ùëô f ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m \n8: else 9: #_delayed_requests  ‚Üê Delay_Estimator ( ùëìùë¢ùëõùëê )  b 10: extra_con  ‚Üê l  #_delayed_requests \nf ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m \nc 11: reqd_con  ‚Üê func.existing_con + extra_con 12: Scale_Containers ( ùëìùë¢ùëõùëê,ùëüùëíùëûùëë _ ùëêùëúùëõ ) \nOpenFaaS  is deployed on top of  Kubernetes  [ 9 ], which acts as the chief container orchestrator. 5.1 Prototype Implementation Kraken  is implemented primarily using Python and Go on top of  OpenFaaS  [ 11 ], an open-source serverless platform.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 330,
    "augmented": true
  },
  {
    "text": "The tile-level shows how each tile consists of multiple such PEs and will be working on one kernel at a time. The accelerator-level shows that the entire accelerator is made of multiple such tiles (4x4 in the toy example). Inputs are broadcast into each tile so that each tile can work on a kernel.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "3) matter only during data transfer (from the input 360 ¬∞ frame to the framebuffer) in the projection mapping stage, after the coordinate mappings ( P  in Fig. ‚Ä¢  Pixel values:  The pixel contents/values (denoted as  F  in Fig. Thus, it is a critical feature in projection computation executions.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Random sampling of the decision trees also augments the model by minimizing the data induced bias of each of the models. The random sampling method is data agnostic, and hence ensures minimal data induced bias. Random sampling of decision trees, albeit a na¬®ƒ±ve way, has been empirically shown to work well in preserving model characteristics and providing accurate predictions.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "[35]  G. G. Langdon, ‚ÄúAn introduction to arithmetic coding,‚Äù  IBM Journal of Research and Development , pp. 135‚Äì149, 1984. [36]  D. Le Gall, ‚ÄúMpeg: A video compression standard for multimedia applications,‚Äù  Commun.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "abs/1803.00227, Apr 2018. [26]  S. Han, H. Mao, and W. J. Dally, ‚ÄúDeep compression: Compressing deep neural network with pruning, trained quantization and huffman coding,‚Äù CoRR , vol. abs/1510.00149, 2015.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "We use a two-level data annotation mechanism: exemplar identiÔ¨Åcation based on the \n1 Vedic goddess of dawn in Hinduism [ 36 ]; emphasizing the dawn of sustainable continuous learning and signiÔ¨Åcance of solar power in our design. Our policy updates  both  the teacher and student models for robust unsupervised learning. conÔ¨Ådence matrix of the student model, followed by a repre- sentation learning based exemplar selection by ensembling multiple teacher models.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "This similarity could be exploited, like in classical encoding algorithms, to further increase the compression ratio while improving the feature quality. However, video data often comes with a large amount of inter-frame similarity (Ying et al., 2022b; Zhang et al., 2017; Zhao et al., 2020, 2021; Ying et al., 2022a). Furthermore, neural codecs offer us the flexibility to approximate the computation (using quantization) to further enhance efficiency.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "7 √ó  speedup and 73% energy savings. CCS CONCEPTS \n‚Ä¢  Computing methodologies  ‚Üí Ray tracing ;  ‚Ä¢  Computer sys- tems organization  ‚Üí Embedded software ;  ‚Ä¢  Human-centered computing  ‚Üí Visual analytics . ‚àó Work was done as a student at Penn State.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Routerless network-on-chip. In 2018 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 492‚Äì503. IEEE, 2018.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "[6] Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor net- works. IEEE Transactions on Big Data , 2020.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "If the student (or the edge model) is conÔ¨Ådent about the classiÔ¨Åcation (e.g. a clear frame with no new objects, or a frame similar to one of the training samples), then that frame is discarded as it potentially contains little to no new information. However, if the student is not conÔ¨Ådent on the classiÔ¨Åcation, the frame is then saved as a potential exemplar (we will further reÔ¨Åne this in ¬ß III-B ).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "We also plan develop recruiting relationships with HBCUs. All these efforts should help us in broadening participation in this project. Aligned with the departmental BPC plan, the students working on this project will participate in various diversity, equity, inclusion and belonging (DEIB) DEIB activities.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Depending on the application type, the maximum ensemble size can vary from tens to hundreds of models. The entire model framework is typically hosted on re- sources like VMs or containers in public cloud. These re- sources are available in different types including CPU/GPU instances, burstables and transient instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "285‚Äì289. [6]  M. Beg, Y. C. Chang, and T. F. Tang, ‚ÄúPerformance evaluation of error resilient tools for mpeg-4 video transmission over a mobile channel,‚Äù in  2002 IEEE International Conference on Personal Wireless Communications , 2002, pp. [7]  P. J. Besl and N. D. McKay, ‚ÄúMethod for registration of 3-d shapes,‚Äù in  Sensor fusion IV: control paradigms and data structures , 1992, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "The cost metric is the billing cost from AWS, and the accuracy metric is measured as the percentage of requests that meet the target accuracy requirements. The response latency metric includes model inference latency, communication/network latency and syn- chronization overheads. Queries that do not meet response latency requirements (>700ms) are considered as SLO vio- lations.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "As data and model dimensions decrease, the hardware assistance‚Äôs impact becomes more pronounced, making  Us. ¬¥as  an excellent solution for continuous learning across diverse application sizes. Along with morphable hardware, the exemplar selection and the micro-proÔ¨Åler play an important role for the success of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "In  Information Security Practice and Experience: 11th International Conference, ISPEC 2015, Beijing, China, May 5-8, 2015, Proceedings , pp. Accelerating rsa with fine-grained parallelism using gpu. Yang Yang, Zhi Guan, Huiping Sun, and Zhong Chen.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "dlapiperdataprotection.com/index.html?t=collection-and-processing&c=SE . (Accessed on 11/21/2022). Tiantu Xu, Luis Materon Botelho, and Felix Xiaozhu Lin.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Using Commonality  in the weight estimation process allows  Kraken to tolerate function probability miscalculations by assigning higher weights to those functions that are statistically more likely to experience rise in usage because of their presence in a larger number of workflows. For example, in Figure 1a, the Commonality  of the function  ùê∂ùëúùëöùëùùëúùë†ùëí _ ùëÉùëúùë†ùë° in the  Social Network  application is given by the fraction   4 \n7   as it is present in four out of the seven possible paths in the DAG. Note that we deal with the possibility of container overprovisioning due to the in- creased function weights by allowing both  Connectivity  and Commonality  to be capped at a certain value.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "The weight for each function corresponds to the state transition probability from the start state to the current one (note that this may require possibly transitioning through a number of intermediate states). An application DAG can map neatly onto a Markov model wherein the functions within the application DAG are mod- eled as states of the VOMM. The process of one function invoking another function corresponds to a transition from the caller function state to the callee function state.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Yang Yang, Zhi Guan, Huiping Sun, and Zhong Chen. In  Proceedings of the Fourteenth EuroSys Conference 2019 , pp. 1‚Äì17, 2019.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Through offline profiling or initial runs, we can de- termine the right memory allocation for a given response latency. This would lead to a reduction in cold-start latencies incurred for users with the same type of requests. 3.2.4 Configuring Serverless Functions  In keeping with  Observation 5 , it is quintessential to configure the mem- ory allocation of  serverless functions  to meet the application SLOs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Abstract ‚ÄîDeep neural networks (DNNs) are being widely used in various computer vision tasks as they can achieve very high accuracy. However, the large number of parameters employed in DNNs can result in long inference times for vision tasks, thus making it even more challenging to deploy them in the compute- and memory-constrained mobile/edge devices. To boost the inference of DNNs, some existing works employ compression (model pruning or quantization) or enhanced hardware.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "The equilibrium ensures  D  remains stable, allowing classi- cal stochastic optimization theory to hold. By keeping  Œª 1 , Œª 2  within reasonable bounds, we ensure that the modified gradient   b ‚àá J ( Œ∏ )  remains well-behaved, preserving the conditions for SGD convergence. We have shown that under the stated assump- tions‚Äîconvexity and smoothness of ‚Ñì , convexity and bounded gradients of  ‚Ñ¶ SNR  and  ‚Ñ¶ complexity , stationarity of  D  induced by equilibrium strategies, and unbiased gradient estimates‚Äîthe diminishing step-size SGD applied to  J ( Œ∏ )  converges in expectation to a stationary point  Œ∏ ‚àó .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 167,
    "augmented": true
  },
  {
    "text": "Accessed: 2023-10-20. [5] Dennis Abts, Garrin Kimmell, Andrew Ling, John Kim, Matt Boyd, Andrew Bitar, Sahil Parmar, Ibrahim Ahmed, Roberto DiCecco, David Han, John Thompson, Michael Bye, Jennifer Hwang, Jeremy Fowers, Peter Lillian, Ashwin Murthy, Elyas Mehtabuddin, Chetan Tekur, Thomas Sohmers, Kris Kang, Stephen Maresh, and Jonathan Ross. mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai , Febru- ary 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": "Available at:  https://youtu. be/gofI47kfD28?t=685  [Accessed: 10/24/2024]. [31] Reetuparna Das, Onur Mutlu, Thomas Moscibroda, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "The order of the VOMM denotes the number of predecessors that influence the tran- sition decision. Such behavior is seen in some of our workloads such as  ùëÄùëíùëëùëñùëéùëÜùëíùëüùë£ùëñùëêùëí . An application DAG can map neatly onto a Markov model wherein the functions within the application DAG are mod- eled as states of the VOMM.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "All data mentioned above will be accessible via our website dedicated to the project. No ethical and privacy issues will be associated with the data, and the data will not contain any personal information and will not be copyrighted. When appropriate, the PIs will also try to share their research findings with the broad research community via posts, talks, and seminars.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "629‚Äì642. [66]  Hiroshi Yoshikawa, Takeshi Yamaguchi, and Hiroki Uetake. 2016.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Holographic Displays on AR:  Another large body of prior works focus on optimizing the holographic displays for the next- generation AR headsets [ 6 ,  17 ,  23 ]. Further, in this paper, we have gone beyond foveated rendering ( Inter-Holo ), by proposing an optimiza- tion/approximation called  Intra-Holo , that complements the former in boosting performance/energy efficiency. This enhancement is ideally suited for holographic processing at the edge, without re- quiring additional hardware, cloud assistance, or machine learning framework.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "[26] G. Gobieski, B. Lucia, and N. Beckmann, ‚ÄúIntelligence beyond the \nedge: Inference on intermittent embedded systems,‚Äù in  ASPLOS . ACM, 2019. [27] Z. Gong, H. Ji, C. W. Fletcher, C. J. Hughes, and J. Torrellas, \n‚ÄúSparsetrain: Leveraging dynamic sparsity in software for training dnns on general-purpose simd processors,‚Äù in  Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques , 2020, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Tools, Platforms and Frameworks for LLM Evaluation:  Although they do not capture system insights, a few mathematical models [133] have been proposed to estimate the complexity of LLM training process. Additionally, a few simulators [9, 180] have been proposed to estimate time and cost of inferences. In this direction, we plan to use/augment these models by investigating microarchitectural, architectural and system level impacts on training and inference processes.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "AMD. Smartssd computational storage drive. https://www.xilinx.com/applications/ data-center/computational-storage/smartssd.html , b.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "This observation motivates us to ask the question:  Do such similarities also exist in the PC streams? c) An example of macro blocks segmented using Morton codes in two frames. pixels) within one frame, as well as temporal locality (similar pixel values in corresponding locations across consecutive frames) [ 36 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "We do not plot the results for Clipper-X , which achieves similar accuracy to  Cocktail , but uses more models as explained in Section  6.2.1 . Cost Comparison:  Figure  8  plots the cost savings of Cocktail  when compared to  InFaas ,  Clipper  and  Clipper-X policies. It can be seen that,  Cocktail  is up to 1.45 √ó  more cost effective than  InFaas  for  Strict  workload.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "[47] H. Bay, T. Tuytelaars, and L. Van Gool, ‚ÄúSurf: Speeded up robust features,‚Äù in  European conference on computer vision , 2006, pp. 404‚Äì 417. [48] F. Suard, A. Rakotomamonjy, A. Bensrhair, and A. Broggi, ‚ÄúPedestrian detection using infrared images and histograms of oriented gradients,‚Äù in  2006 IEEE Intelligent Vehicles Symposium , 2006, pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "This work explores policies for partitioning random forest approaches, which are widely used for inference tasks in smart manufacturing, among sets of devices with different resources and data visibility. However, the limited compute at these edge devices requires trade-offs in efficient edge-cloud partitioning and raises data privacy issues. Abstract ‚Äî Intelligent edge sensors that augment legacy ‚Äùun- intelligent‚Äù manufacturing systems provides cost-effective func- tional upgrades.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Restrictions apply. 0 \n20 \n40 \n60 \n1 2 3 4 5 6 7 8 9 10 \n# Layers Tranined \nTraining Iterations \n# Layers Trained-Actual # Layers Trained-Oracle \n(a) Number of layers trained. 0 \n2 \n4 \n6 \n8 \n0 \n10 \n20 \n30 \n40 \n1 2 3 4 5 6 7 8 9 10 \nConvergence Error(%) \nBatch Size \nTranining Iterations Batch Size-Actual Batch Size-Oracle Convergence Error (%)-Actual Convergence Error (%)-Oracle \n(b) Batch-size and convergence.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "[81] A. Sarma, S. Singh, H. Jiang, A. Pattnaik, A. K. Mishra, V. Narayanan, \nM. T. Kandemir, and C. R. Das, ‚ÄúExploiting activation based gradient output sparsity to accelerate backpropagation in cnns,‚Äù  arXiv preprint arXiv:2109.07710 , 2021. [82] scale.com, ‚ÄúData labeling: The authoritative guide,‚Äù https://scale.com/guides/data-labeling-annotation-guide#data-labeling- for-computer-vision , (Accessed on 11/21/2022). [80] A. Sarma, S. Singh, H. Jiang, A. Pattnaik, A. K. Mishra, V. Narayanan, \nM. T. Kandemir, and C. R. Das, ‚ÄúExploiting activation based gradient output sparsity to accelerate backpropagation in cnns,‚Äù  arXiv preprint arXiv:2109.07710 , 2021.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 269,
    "augmented": true
  },
  {
    "text": "The x-axis (power efÔ¨Åciency) denotes the percentage of power cycles where the RCA can activate. The y-axis (power utilization), on the other hand, denotes the percentage of valid power during activations which is actually utilized for computation and data transfer. An ideal system would be at the point (1,1).",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "However, requiring all sensors to partic- ipate at all times is impractical, as it drains energy reserves too quickly. Conversely, simplistic policies‚Äîsuch as se- lecting only the highest-energy sensors‚Äîignore factors like data relevance, sensor quality, and the strategic implications of current participation on future network states. Multiple sensors observing the same phenomenon from different angles can collectively provide more comprehensive and reliable insights than any single sensor could.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "[38]  B. Li, ‚Äú3d fully convolutional network for vehicle detection in point cloud,‚Äù in  2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2017, pp. [39]  L. Li, Z. Li, V. Zakharchenko, J. Chen, and H. Li, ‚ÄúAdvanced 3d motion prediction for video-based dynamic point cloud compression,‚Äù  IEEE Transactions on Image Processing , pp. 1513‚Äì1518.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Our evaluation of Us. To address these challenges, we propose Us. ¬¥as, an ap- proach combining algorithmic adjustments, hardware-software co-design, and morphable acceleration hardware to enable the training of workloads on these edge servers to be powered by re- newable, but intermittent, solar power that can sustainably scale alongside data sources.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": ". , f n } 2:  Output:  Compressed frames  C  =  { c 1 , c 2 , . .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Here, we assume that the octree for these points has already been established using the geometry pipeline, and we next go through our proposed attribute pipeline step by step and explain where the envisioned beneÔ¨Åts will come from. Let us now consider the example in Fig. 6 with three points ‚Äì  P 0  with geometry data of  [ 0 , 0 , 0 ]  and one attribute value of  50  (in this example, we set the attribute as a scalar for simplicity; normally, the attribute should be a vector, e.g., RGBs),  P 1  with a  [ ‚àí 1 , 0 , 0 ]  geometry and  52  as the attribute, and  P 2  with a  [ 3 , 3 , 3 ]  geometry and  54  as the attribute.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 176,
    "augmented": true
  },
  {
    "text": "Further, to study how the tuned approximation (in Algo. 2 and Algo. 3) affect the energy savings achieved, we report five design points in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "There are two major problems with performing DNN inference under intermittent power. Despite these advancements, achieving consistent and accurate inference‚Äîthereby meeting service level objectives (SLOs)‚Äîin such intermittent environments remains a significant challenge, exacerbated by unpredictable resources, form-factor limitations, and variable computational availability, particularly when employing task-optimized deep neural networks (DNNs). However, the intermittent and limited energy income of these deployments demands optimizations for ML applications at the algorithm (Yang et al., 2017; Shen et al., 2022; Mendis et al., 2021), orchestration (Maeng & Lucia, 2018; Mishra et al., 2021), compilation (Gobieski et al., 2018), and hardware development (Qiu et al., 2020; Islam et al., 2022; Mishra et al., 2024) layers.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 220,
    "augmented": true
  },
  {
    "text": "We will also collaborate with the Penn State College of Education‚Äôs CSATS (Center for Science and the Schools) to participate in the university‚Äôs continuing outreach initiatives focused on STEM subjects. The PIs plan to recruit new women and minorities for this project as well. The PIs have supervised several women PhD students, and are currently advising a total of 6 female PhD students in their groups.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Convexity of  ‚Ñì . The loss  ‚Ñì ( f Œ∏ ( x ) , y )  is convex in  Œ∏ . Key Assumptions and Conditions \n1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "However,  Cocktail‚Äôs  resource management is more adaptive to changing request loads and does not drop accuracy. Pretzel [ 52 ] and Inferline [ 26 ] are built on top of Clipper to optimize the prediction pipeline and cost due to load variations, respectively. Many prior works [ 2 , 25 , 35 , 63 , 74 , 75 ] have extensively tried to reduce model latency by reducing overheads due to shared resources and hardware interference.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Whenever all the local work queue counter hits zero along with the layer kernel counter, the control moves to schedule the next layer (or previous layer in backward propagation) for computation. Note that we do not delve into the details of the computa- tional primitives involved in training the DNN as several prior works [ 15 ], [ 16 ], [ 80 ] provide a very detailed accounting of it (for both forward and backward pass) along with the hardware and control requirements. We treat the convolution scheduling (using input stationary and at a kernel level) in a morphable systolic hardware to be the main challenge and explain it.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "4  b  , to compress the attribute data, similar steps ‚Äì  Raw Frame Input ,  Attribute Transform and Quantize , Entropy Encoding , and  Compressed Attribute Output Stream  ‚Äì are employed. Only the  Transform and Quantize  step differs from the geometry compression pipeline, which takes both the raw frame‚Äôs attribute data as well as the constructed octree as its inputs. With these inputs, the  Transform  step \n5 We consider the octree-based technique [ 56 ], [ 72 ] and RAHT [ 14 ], [ 56 ] as SOTAs for geometry and attribute compression respectively.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "We refer to such functions as Dynamic Branch Points (DBPs), and the chains they are a part of as Dynamic Function Chains. In such cases, deploying containers without prior knowledge about the possible paths in the workflow leads to sub-optimal con- tainer provisioning for individual functions. Figure 1 shows the DAGs for three Dynamic Function Chains.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Vr in tourism: A new call for virtual tourism experience amid and after the covid-19 pandemic. IEEE, 2012. Maksim Godovykh, Carissa Baker, and Alan Fyall.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": ". . do 3: The aggregator signals that a training update round is imminent.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "8 consists of a 512-core Volta GPU, a 4Kp60 HEVC \n249 \ncodec, 16GB LPDDR4x memory, 32GB eMMC storage, and a power management unit (PMU) that exposes the real-time power traces to users. Experimental Platforms and Datasets \nEvaluation Platforms:  The  Baseline  GPU platform described in Fig. To evaluate our design implementation in hardware, we use an FPGA platform, which is the same as the state-of-the-art PTU [28], with a 100MHz system clock, onboard conÔ¨Åguration circuitry, 2x16MB Quad SPI Flash, 1GB DDR2 Component Memory, and also a hardware PMU.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "List of Project Personnel and Partner Institutions \n1. Chitaranjan Das; Pennsylvania State University; PI 2. ft., including desks with workstations and peripherals.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Learn. Res. [32]  I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, ‚ÄúQuantized neural networks: Training neural networks with low precision weights and activations,‚Äù  J. Mach.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "To summarize, the performance inefÔ¨Åciencies in prior works can be primarily attributed to the lack of parallelism of these algorithms. Motivated by this observation, we next plan to improve the compression performance by exploiting various parallelism opportunities, which have been ignored, to the best of our knowledge, by the prior research but are essential in employing PCC in edge device settings. B.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "An ideal solution would entail a battery-free system ( not  energy storage- free, i.e., still with some capacitive storage), circumventing these concerns and aligning with the objectives of sustainable and reliable continuous learning at the edge. To these ends, we propose Us.¬¥as,   1   a HW-SW co-design approach to building sustainable, scalable, drift-mitigating edge analytics platforms using harvested power to support continuous learning. Us.¬¥as, unlike prior edge-focused analytics approaches (e.g., Ekya [ 12 ]), detaches the inference and train- ing hardware, as the training task is the major source of the compute, power, and time consumption.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "Still, the savings in terms of cost will be signiÔ¨Åcant because even removing one model from the ensemble amounts to  ‚àº 20% cost savings in the long run ( Clipper  vs  Clipper-X  ensemble in Figure  8 ). The percentage of model-reduction is lower for  Const2 , 3 and 4 because, the total models used in the ensemble is less than  Const1  (8, 7 and 6 models, respectively). Clipper , on the other hand, is static and always uses all the models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "How- ever, most prior works focus on improving model structure and implementing custom accelerators. As opposed to the prior work, in this paper, we target the video data that are processed by edge devices, and study the similarity between frames. To boost the inference of DNNs, some existing works employ compression (model pruning or quantization) or enhanced hardware.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "[4] J. Wu, C. Leng, Y. Wang, Q. Hu, and J. Cheng, ‚ÄúQuantized Convo- lutional Neural Networks for Mobile Devices,‚Äù in  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2016, pp. 4820‚Äì4828. 5117‚Äì5124, 2019.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Lab Resources:  The PIs collectively have more than 6,000 sq. The prototyping efforts in the proposed research will be carried out primarily in the research labs at Penn State, directed by Das, Kandemir, and Zhang. ft. of laboratory space including three conference rooms and more than 60 desks with PCs, peripherals, and virtual meeting equipment.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Data Annotation \nPicking the Important Ones:  Typically, edge models are ca- pable of inferring at the frame rate of the camera (at times, 30fps to 60fps) [ 19 ]. A. There has been a signiÔ¨Åcant body of work on frame similarity and saliency [ 45 ], [ 84 ], [ 101 ], [ 105 ], [ 107 ], [ 108 ], and those details remain beyond the scope of this work.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "We also describe the challenges in enabling complex compute on such devices and the need for hardware-software co-design to enable specialized intermittent computing in EH-WSNs. Finally, we define the scope of our work and focus on the problem specifics while alluding to probable solutions. Figure 1a shows the basic building blocks of an energy har- vesting sensing/computing unit.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "83 538‚Äì83 547, 2020. 1‚Äì8. [33]  N. Koh, P. K. Jayaraman, and J. Zheng, ‚ÄúParallel point cloud compression using truncated octree,‚Äù in  2020 International Conference on Cyberworlds (CW) , 2020, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the ACM SIGMETRICS joint international conference on Measurement and modeling of computer systems , pages 13‚Äì24, 2011. [145] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": ", p. 433‚Äì466, 1995. [37] Jacob Solawetz, Samrat Sahoo, ‚ÄúTrain YOLOv4-tiny on Custom Data - Lightning Fast Object Detection ,‚Äù ‚Äùshorturl.at/vCSVW‚Äù, 2020. [38] MYO NeuralNet , ‚ÄúCalculating the Output Size of Convolutions and Transpose Convolutions,‚Äù ‚Äùshorturl.at/ioLRV‚Äù, 2020.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Using the Seattle SOLRAD power trace for January 1, 2022, we simulated 40 hours of continuous learning with 5 different models on Urban TrafÔ¨Åc data [ 97 ] and  Us. ¬¥as  hardware. The results, summarized in Table  IV , demonstrate the effectiveness of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "experts are equally relevant, we will prioritize those with available accelerators to improve performance. EoE Graph Pruning for Memory Constraint. Given a memory budget that limits the number of experts the system can host, the EoE network must  adapt  its structure to meet user needs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "1a, where a physical car being driven on a highway is replaced by the corresponding virtual/augmented holographic car in a real-time fashion such that, instead of viewing the real cars, the AR user views the virtual ones. To implement such ap- plications, today‚Äôs AR headsets are usually equipped with various hardware components for sensing and processing, as depicted in Fig. 1b.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "IV. I NTRA -F RAME  C OMPRESSION  D ESIGN \nAs discussed in Sec. III-A , PCC takes several seconds to execute, which is signiÔ¨Åcantly higher than the ideal/real- time demand ( 100 ms ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "For example, in  Hotel Reservation (Figure 1c), if only one path (say,  NGINX - Make_Reservation ) is always chosen, it represents a static function chain. Hence- forth, we refer to static function chains as Static DAG Ap- plications (SDAs). Clearly, having prior knowledge of what functions will be invoked for an application makes container provisioning easier for SDAs.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "This data set directly fits our use case for two reasons - 1. In the real world, these sensors would be distributed in different homes, and each home will have its own idiosyncrasies. 2.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "IEEE Press, 2019. doi: 10.1109/ICRA.2019.8794073. 19 \nEideticom and Los Alamos National Laboratory. URL  https://doi.org/10.1109/ICRA.2019.8794073 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "2a. Overall,  360 ¬∞ VR video processing consumes 3.4  Watts , which is  2 . 27 √ó  the power compared to its planar counter- parts (1.5  Watts ).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "[32]  Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. [31]  Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola. Autogluon-tabular: Robust and accurate automl for structured data, 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Therefore, simpler paradigms, like random forests, still remain popular for embedded sensors [7]. Additionally. techniques that bal- ance communication and computation costs while partitioning the compute between the edge and a resource-rich server have been deployed.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "The results from the workers are  ensembled  using an weighted majority voting aggregator  3  to agree upon a correct prediction. The participating models are made available in a model cache  1b for faster access and avoid re-computation for requests having similar constraints. Then, individual queries are dispatched to instances pools  2  dedicated for each model.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Considering the energy available, the predictor makes an informed decision on how to proceed. The compiler deconstructs the program into jobs to perform seamless program execution. These jobs form the functional program execution DAG.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, with limited energy budget or available models, MCDNN suffers from accuracy drops. Also, if the approximation opportunity incurs high overhead and/or the decision is made based on high-level features, the scope for performance/energy savings \n1073 \n2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) \n2575-8411/22/$31.00 ¬©2022 IEEE DOI 10.1109/ICDCS54860.2022.00107 \n2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) | 978-1-6654-7177-0/22/$31.00 ¬©2022 IEEE | DOI: 10.1109/ICDCS54860.2022.00107 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 196,
    "augmented": false
  },
  {
    "text": "The network works at a super-tile (STile) granularity and each arbiter node uses an 8x8 priority- mux. The network only gets activated when it gets a  w-pdown warning signal from the predictor. 5b  shows the power-down sequence and signal states.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "or decomposed as multiple units called ‚Äúkernels‚Äù (or ‚ÄúÔ¨Ålters‚Äù). In a typical convolutional neural network (CNN), each kernel is convoluted over the entire input feature map, and hence there is an ‚Äúinter-kernel parallelism‚Äù (all kernels of a single layer can be executed in parallel) and ‚Äúintra-kernel parallelism‚Äù (multiple computes in a convolution can happen in parallel). This property is true both for the forward pass and the backward pass of the standard CNN training.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "[44] Financial Times. Amazon buys stake in nuclear energy developer in push to power data centres. https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. [18] A. F. CNBC, ‚ÄúHow trafÔ¨Åc sensors and cameras are trans- forming city streets,‚Äù  https://www.cnbc.com/2021/02/22/how-trafÔ¨Åc- sensors-and-cameras-are-transforming-city-streets.html , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "CoRR , abs/1812.01776, 2018. [27]  Daniel Crankshaw, Xin Wang, Guilio Zhou, Michael J. Franklin, Joseph E. Gonzalez, and Ion Stoica. Clipper: A low-latency online pre- diction serving system.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "For practical purposes, we fix it to be the execution time of the slowest function at the current function depth. A ‚Äòtime step‚Äô refers to a unit of measuring state change in the Markov Model. The Probability Vector is an  ùëõ √ó 1 column vector that cap- tures the probabilities of the model being in different states after a number of time steps have elapsed, given that the model was initialized at a known state.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Fig. 8c  shows the time distribution of the accel- erator between performing exemplar selection and training. It also shows the number of exemplar frames per 100 frame, i.e., of any 100 frame encountered, how many of those will contain a relatively new data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "A matching circuit, including components like buck or boost converters, adjusts the voltage to the appropriate level, ensuring the device receives the correct current and voltage. Energy Storage : Finally, to ensure a continuous power supply even when the immediate energy source is inconsistent (like when a cloud passes over a solar panel), the system includes a temporary storage unit, such as a super-capacitor. 4.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Output Reg. A. ResiRCA overview \nFigure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system. The baseline, battery-powered MCU system samples data at a Ô¨Åxed rate, supported by the provisioned battery, and transmits either sensor data or the results of RCA processing \nDAC DAC DAC DAC DAC DAC \nMCU \nMemory I/O Ports \nInterconnected Bus \nClock \nPower \nIntelligent Embedded System \n... \n... \nADC&S+A \nDAC \nInput Reg.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "bounding boxes for the object detection task and the feature maps for each layer during the inference are intermediately stored in memory as a ‚Äúcheckpoint‚Äù. By referring this, it can potentially beneÔ¨Åt an inference to be performed later by either completely skipping it (SI) or reducing the computation (PI). Skip Inference:  When the current frame is identiÔ¨Åed as ‚Äúclonable‚Äù by the previous frame, the CPU is released without any inference execution request.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "These factors collectively restrict innovation, limit accessibility, and contribute to significant environmental impact due to high power consumption and carbon emissions, conflicting with global commitments to achieve carbon neutrality [14,17]. 1.1 EoE Design Space Exploration 1.2 Constructing Morphology  \nof EoE \n1.3 Continual Adaptation of  \nExperts \nExperts \nExpert Routing  Functions \nComposition  \nfunctions Independent training possible \nExplore \nStore \nExplore Morphologies \nTree EoE Graph EoE \nChain EoE \nSplitting \nMerging \nGrowing Shrinking \nMinimal Retrain Overheads \n1.4 Algorithmic Choices informed  \nby System & Hardware  \nConstraints MORPH (Graph Pruning/ \nGraph  Reconstruction/  \nExpert  Selection) \nBased  \non \n... \nSystem/Resource  Constraints \n2.2 Router  Retraining \nSystems Constraints/Decisions \n? Thrust 2: System Support for  \nExpert Scheduling & Data  \nMovements \nThrust 1: Algorithmic Support for  \nEnsemble of Experts (EoE) \nThrust 3: Chiplet-based  \nAdaptive & Reconfigurable  \nHardware Platform \nExpert  Repository \n2.1 Data Locality &  \nParallelism-aware  \nTraining \n?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 259,
    "augmented": true
  },
  {
    "text": "Comparisons on power consumption and throughput with tile-size over full-size activation \nFrom the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property. Under this context, if the power dominant RCA works in a Ô¨Åxed high-power mode, as in traditional RCA designs, there would be large mismatches between the harvested power and the consumed power. These mismatches can lead to the following two ‚Äúnonideal‚Äù working scenarios: (i) Unutilized energy:  As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "Infinity fabric. \" https://www.amd.com/content/dam/amd/en/documents/ instinct-tech-docs/data-sheets/amd-instinct-mi300x-platform-data-sheet. [13] AMD.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "4 Evaluation and Initial Results \nThis section introduces how an ML-serving framework can capitalize on the design choices discussed in Section  3 . We design three different experiments to study the effects on cost of ML servings due to (i) varying SLOs and (ii) varying application constraints. Implementation Methodology:  We developed a proto- type on top of Amazon EC2 and Lambda services to evaluate the some of the benefits of our proposed design choices.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "30 \n35 \n40 \n45 \n50 \n0 0.2 0.4 0.6 0.8 1 \nPSNR (dB) \nBits per Pixel \nH264 H265 Salient Store \nFigure 8: Compression and Recovery efficiency. 0 \n10 \n20 \n30 \n40 \n1 2 3 4 5 6 \nEncoding Latency (s) \nNumber of Layers \nH264 HEVC Salient Store \nFigure 9: Encoding Latency using layered coding. 5.3 Evaluation of Lattice Based Encryption \nOne of the major contribution of  Salient Store  is accelerating the lattice-based encryption with the help of FPGAs on the storage nodes.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "Common func- tions refer to those which are a part of two or more paths within an application DAG. Figure 4 shows the ‚Äòhit rate‚Äô of \nfunctions within an application that is subject to a constant load where any path in the application is equally likely to be picked. It can be seen that functions which are common to a larger number of paths are invoked at a higher rate by such a request arrival pattern.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "496 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 0.2 8.0 13.8 4.4 \n120.0 \n6.0 \n341.7 \n0 100 200 300 400 \nIMU/IR \nCamera \nPose \nEstimate \nEye Track \nScene \nReconstruct \nReproject \nHologram \nInputs Perception Visual \nLatency (ms) \nOur  focus \nFigure 2: A comparison of latency requirements results col- lected from our practical setting and ideal cases shown in Table 1. 2.2.2 What are the Prior Optimization Efforts?",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "1‚Äì4, 2013. [15]  V. Leonov, T. Torfs, P. Fiorini, and C. Van Hoof, ‚ÄúThermoelectric converters of human warmth for self-powered wireless sensor nodes,‚Äù IEEE Sensors Journal , vol. 7, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "https://www. dlapiperdataprotection.com/index.html?t=collection-and-processing&c=SE . Sweden data collection & processing.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efÔ¨Åciently performing inference on an IoT device if it does not have either a high power or high stability power source. Given form factor constraints on energy storage, the former may be challenging, and energy-harvesting from sources such as solar, thermal, kinetic and radio frequency [ 11 ], [ 12 ], [ 13 ], [ 14 ], [ 15 ], [ 16 ] is notoriously unstable. While unstable power sources have been successfully utilized for applications in the IoT space [ 17 ], [ 18 ], [ 19 ], their use has not been heavily explored for RCA design.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 170,
    "augmented": false
  },
  {
    "text": "Secondly, these compression algorithms are not context-aware, and hence lose relevant \n4 \nfeatures during the process of compression resulting in de- graded inference accuracy (refer Table 1 for details). A key insight is that, while these compression techniques work very well for high dimensional data (e.g. images), inference on low-dimensional sensor data (such as inertial measure- ment unit or IMU vibration data) is much more sensitive to lossy compression as separating between features might be difficult to do.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Tributary: spot-dancing for elastic services with latency SLOs. In  ATC , 2018. [41]  Aaron Harlap, Andrew Chung, Alexey Tumanov, Gregory R. Ganger, and Phillip B. Gibbons.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "In the original training phase, these feature vectors are separated using K-means [ 74 ] or other clustering. We achieve this by clustering the feature vector of the Large DNN model. Fundamentally, we use the larger DNN models as feature extractors which turn the data into a feature vector.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "This data-set is particularly suited for evaluating the performance of  Salient Store  in dense, urban environments. Another video data-set, the  Waymo Open Data-set  (Sun et al., 2020), is one of the largest and most diverse data-sets for autonomous driving. It offers high-resolution sensor data, including LIDAR and camera recordings, across a variety of urban and suburban landscapes.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "2) We leverage temporal continuity of human activity, and persist the last successful classiÔ¨Åcation result of a sensor. We use aggressive recall which reduces the number of total inferences performed and mitigates the requirement that all of the sensors be involved in the ensemble process during each inference. 3) Our proposed policy,  Origin , combines an adaptive conÔ¨Å- dence matrix and the activity aware scheduler to perform efÔ¨Åcient and accurate classiÔ¨Åcation.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Unlike prior works targeting at optimizing the efÔ¨Åciency of  each computation  [28], [57], we primarily focus on reducing  the amount of computation to be performed, by exploring the intrinsic ‚Äúcompute reuse opportunities‚Äù in  360 ¬∞ VR video processing. Further, we also observed in Sec. III that, the main reason behind this is that the compute is executed repeatedly both within a single frame (due to offset between the eyes) and across frames (due to changes in head orientation at runtime).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "The PIs will seek funding for these activities from Penn State, and in particular from the ICDS (Institute for Computational and Data Sciences). ‚Ä¢  Undergraduate Research Experience:  The PIs have participated in the Summer Research Opportunities internship program that hosts students from under-represented communities with interest in pursuing graduate studies. PI Das has been involved with organizing the  Visit In Engineering Weekend  (VIEW) program for students entering their junior and senior years of high school, which fosters interest in engineering.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Industry Collaboration: We have several ongoing collaborations with industries like NVIDIA, AMD, Google and Meta, who are major players in advancing deep learning technology/systems. We plan to collaborate with them on various aspects of this project as well, and explore opportunities for technology transfer. Furthermore, the PIs will leverage additional connections through their former students working in these companies.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "1  a  ). B. Related Work \n1) Point Cloud Use-cases:  Recently, PC is being widely used in various Ô¨Åelds, such as AR/VR [ 46 ], [ 81 ], telepres- ence [ 43 ], [ 57 ], [ 86 ], virtual tourism [ 12 ], [ 50 ], teleopera- tion [ 83 ], telemedicine [ 51 ], video streaming [ 24 ], [ 37 ] and gaming [ 81 ], [ 87 ], etc.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "is mapped from position  [( x 360 ) 0 r ,  ( y 360 ) 0 r ]  on the  360 ¬∞ frame. To study the relationship between the coordinate projection re- sults between both eyes, for the  same  two coordinates  [ x i , y i ] on both  2 D  FoV frames, we determine the distance vector ( ‚Éó d ) i   between their equirectangular counterparts, represented in Equation 3: \n( ‚Éó d ) i   = [( x 360 ) i r   ‚àí ( x 360 ) i l ,  ( y 360 ) i r   ‚àí ( y 360 ) i l ] ‚ä§ (3) \nThe knowledge of distance vector   ‚Éó d  is critical to explore the AE  opportunity, because if it was known apriori, then we only need to process the entire projection transformation to generate the mapping results ( P L ) for one eye, and then deduce the coordinate projection computation results for the other ( P R ) by simply adding   ‚Éó d  with  P L . This encourages us to further study whether this distance vector changes with head orientation or not, and also whether it is invariant for any particular frame ‚Äì if yes, then how?",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 299,
    "augmented": false
  },
  {
    "text": "IEEE, 2018. [11] Green Algorithms. Green Algorithms 4 HPC, August 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "As shown in Figure  5 ,  mixed procurement reduces the over-provisioning cost of VMs. At the same time it also minimizes latency violations equivalent to  exascale  scheme. However, we argue that there is scope to further optimize resource procurement based on the fre- quency of peak load and constant load in a given request \narrival scenario.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "7: The proposed  EA  and  AE  design blocks implementation. E. Design Considerations and Implementation \nWe designed both our schemes as modular and scalable additions to the existing pipeline (refer the  EA  and  AE  blocks shown in Fig. 7).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "ACM SIGPLAN Notices , 53(2):43‚Äì55, 2018. [19] Srikant Bharadwaj, Jieming Yin, Bradford Beckmann, and Tushar Krishna. Kite: A family of hetero- geneous interposer topologies enabled via accurate interconnect modeling.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "We next quantify how many depth planes can be reduced by our approximation scheme. Towards this, we plot, in Fig. 1) with more holographic data accesses (fetched from the host-side memory).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "(Sec. V ) ‚Äì and reached the following  conclusions : the primary reason behind their performance inefÔ¨Åciencies is what can be termed as ‚Äúunder-parallelism‚Äù, i.e., not being able to fully exploit parallelism during compression. Especially, many levels of dependencies (i.e, various regularities of locks) exist in their pipelines ‚Äì e.g., the entire octree needs to acquire a ‚Äúmacro lock‚Äù before inserting a point and updating the tree (as shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Measuring massive multitask language understanding. arXiv preprint arXiv:2110.11605 , 2021. [192] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "This problem has been addressed in federated learning by combining the models using weight averaging [2]. The algorithm makes sure that no data is shared with a centralized agent (like the cloud, which performs the training action), yet the learner is able to learn by combining multiple pre-learnt models. We extended this design idea by constructing a random forest model as a combination of multiple decision trees from different learners (different deployments).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "9, which is further translated to the total end-to-end energy savings shown in the right y-axis in Fig. 9. From this Ô¨Ågure, we observe that: ‚Ä¢  Baseline:  In  Baseline , since there are no optimizations, the projection operations for both eyes consume equal energy (on GPU), i.e., each eye‚Äôs compute consumes  50%  energy.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "[143] Akbar Sharifi, Emre Kultursay, Mahmut Kandemir, and Chita R Das. In  2012 45th Annual IEEE/ACM International Symposium on Microarchitecture , pages 294‚Äì304. Addressing end-to-end memory access latency in noc-based multicores.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Keboola, the platform that automates data lineage. https://www.keboola.com/ product/data-lineage . (Accessed on 09/12/2023).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Clearly, TMC13 and CWIPC are two of the most energy-consuming schemes, which consume  11 . 3 J  and  19 . 8 J , respectively, for one PC frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "C ONCLUDING  R EMARKS \nPushing DNN-assisted video analysis into edge is the cur- rent trend in applications like surveillance, assisted surgery, and VR/AR [23]. Along this trend, prior approaches have targeted improving either accuracy or performance. In contrast, this paper revisits the  < accuracy, energy, performance >  design space, and tunes the design knobs adaptively with the changing constraints of applications over time.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "This requires knowledge of the head orientation or the direction of gaze, which can be read at runtime from the IMU sensors embedded in the VR headset. ‚Ä¢  T 2  gives us  eyes‚Äô view ; i.e., this changes the virtual world‚Äôs coordinate frame to match the frame of the eye. ‚Ä¢  T 3  transforms the  360 ¬∞ coordinates from a  monocular view to a  stereoscopic view .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "During training, a document is routed to its type in criteria  a 1  and then routed to its type in another  a 2  until all criteria in  a  are covered. Our solution will leverage our previous work on multi-stage summarization [186] and multi-agent framework for long-context tasks [187]. For instance, a Chinese medical summarization document will be routed to the Chinese language, medical domain, and summarization skill experts layer by layer.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "\"https://www. Zynq UltraScale+ MPSoC ZCU102 Evaluation Kit. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "Prior works, trying to tackle this conflict between computa- tion, communication, power-requirement and quality of ser- vice (QoS), have pursued three major approaches: inference effort partitioning optimizations [ 22 ,  30 ,  31 ,  50 ], mitigation of energy provisioning limitations [ 24 ,  40 ,  43 ,  47 ,  56 ], and minimizing communication overheads [32, 33, 36, 37, 45]. While several studies have shown the benefits of performing more inference closer to the point of data collection [ 23 ,  30 ,  31 ,  40 ,  56 ] and have ap- plied these techniques to more powerful edge devices, their form-factor-imposed limited energy storage, low-power op- eration points, and deployment scenarios have been a major impediment in executing compute-intensive inference tasks directly on such platforms. In contrast, communicating the data, often after little preprocessing, although popular, is not cheap in terms of power requirement, and often poses a challenge for remotely deployed and ultra low power WSNs.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 246,
    "augmented": true
  },
  {
    "text": "A similar problem, in terms of generating faces, paintings etc. given some latent space has already been solved using GANs [ 54 ]. Motivated by this, we designed a GANs to regenerate the lost data points while performing importance sampling.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Searching for mobilenetv3. [46]  Patrick Hunt, Mahadev Konar, Flavio Paiva Junqueira, and Benjamin Reed. In  Proceedings of the IEEE International Conference on Computer Vision , pages 1314‚Äì1324, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "The primary innovation lies in leveraging motion vectors to identify and encode only the changes between frames, rather than re-encoding entire frames. . , c n } 3:  Initialize MobileNet Model  M 4:  Initialize Autoencoder Decoder  D 5:  Initialize Motion Vector Extractor  V 6:  procedure  E XTRACT F EATURES ( frame ) 7: features  ‚Üê M ( frame ) ‚ñ∑ Extract features using MobileNet 8: return  features 9:  end procedure 10:  procedure  C OMPRESS F EATURES ( features ) 11: compressed  ‚Üê D ( features ) ‚ñ∑ Compress using autoencoder 12: return  compressed 13:  end procedure 14:  procedure  C ALCULATE M OTION V ECTORS ( frame current , frame previous ) 15: motion _ vectors  ‚Üê V  ( frame current , frame previous ) 16: return  motion _ vectors 17:  end procedure 18:  procedure  S TACK C OMPRESSION ( current _ compressed, motion _ vectors ) 19: return  some compression algorithm using  current _ compressed  and  motion _ vectors 20:  end procedure 21:  for  i  ‚Üê 1  to  n  do 22: features i  ‚Üê E XTRACT F EATURES ( f i ) 23: c i  ‚Üê C OMPRESS F EATURES ( features i ) 24: if  i >  1  then 25: m i  ‚Üê C ALCULATE M OTION V ECTORS ( f i , f i ‚àí 1 ) 26: c i  ‚Üê S TACK C OMPRESSION ( c i , m i ) 27: end if 28: C [ i ]  ‚Üê c i 29:  end for \nBy exploiting the temporal correlations between consecutive frames, our codec can significantly reduce the required bitrate while maintaining high video quality.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 442,
    "augmented": true
  },
  {
    "text": "Bearing fault data. https://engineering. case.edu/bearingdatacenter/download-data-file , 2018.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "Note that  Us. ¬¥as  hardware is not outperforming any of them as the goal was greater  scheduling Ô¨Çexibility  for power tracking rather than performance or area. Platform Freq.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "[13] R. Bird, Z. J. Baum, X. Yu, and J. Ma, ‚ÄúThe regulatory environment \nfor lithium-ion battery recycling,‚Äù 2022. [11] Beverly Hills has thousands of surveillance cameras, ‚Äúhttps://bit.ly/BeverlyHillsCamera.‚Äù [12] R. Bhardwaj, Z. Xia, G. Ananthanarayanan, J. Jiang, Y. Shu, N. Kar- \nianakis, K. Hsieh, P. Bahl, and I. Stoica, ‚ÄúEkya: Continuous learning of video analytics models on edge compute servers,‚Äù in  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , 2022, pp. 119‚Äì135.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 185,
    "augmented": true
  },
  {
    "text": "2020. Hyperion: A 3D Visualization Platform for Optical Design of Folded Systems. Frameless  2, 1 (2020), 21.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "In  2009 IEEE international symposium on performance analysis of systems and software , pages 33‚Äì42. IEEE, 2009. [9] Amey Agrawal, Nitin Kedia, Jayashree Mohan, Ashish Panwar, Nipun Kwatra, Bhargav Gulavani, Ramachandran Ramjee, and Alexey Tumanov.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Similarly, the original hologram engine can still be reused without any reprogramming, except for the first argument, i.e., the number of depth planes for this particular object, as shown in  Line#5  of Algo. 3. 3, for each of the objects, a corresponding approximation factor ( Œ≤ ) can be determined based on these insights.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Here, each expert is specialized to solve tasks in specific domains, languages, or skills. The main objective of this morphable design is to minimize the resource requirements and training/inference time compared to gigantic monolithic models, while maintaining required accuracy needs. Each expert model is a smaller language model with several orders of magnitude fewer parameters versus monolithic LLMs such as GPT-4 [124].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "IV-A, the bounding boxes (BBoxes, in red) are extracted by the ‚Äúfull-inferenced‚Äù previous frame, and the MVs are obtained from the current frame (Frame-3). Next, based on these inputs including the BBoxes as well as MVs, Algo. 2 is invoked to decide how to process this frame (FI, PI, or SI).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "[41] A. Rosebrock, ‚ÄúIntersection over Union (IoU) for Object Detection,‚Äù ‚Äùshorturl.at/gszOR‚Äù, 2016. [40] L. Liu and M. T. Zsu,  Encyclopedia of Database Systems , 1st ed. Springer Publishing Company, Incorporated, 2009.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "This is because, serverless functions are billed based on of number of invocations, compute time and memory requirement of the function. However, increased memory allocation leads to faster execution time owing to powerful compute-core allocation, but exacerbates the billing cost. Therefore, these apparent deficiencies of choosing the appropriate resource type and model type for a given user re- quirement motivates the central question of this work:  Does there exist an optimal resource procurement system which can balance the goals of diverse user requirements for accuracy, latency and cost, by efficiently mapping model parameters to heterogeneous resource specifications?",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Impact on Quality : The proposed  AE  scheme captures the pattern between both the eyes with only the  1 st  row of the frame, and then uses the same pattern to  bypass  the projection computation for the remaining rows of the right eye. 6b and 6c, the  i th-row‚Äôs pattern may not be exactly the same as the  j th-row. Note that, as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "With these sensors and compute resources in place, an AR head- set executes a set of software tasks, either entirely or selectively based on the applications‚Äô requirements [ 19 ]. Without loss of gener- ality, a typical AR pipeline [ 19 ] is shown in Fig. 1c.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "The improvement brought by PI for YOLOv4-tiny model is more signiÔ¨Åcant as shown in Fig. 9c and Fig.9d, where the latency is further decreased by  36%  (V1P) and  35%  (V2P), while the energy saving is increased by  41%  and  40% , indicating that our PI technique is quite effective. 6) Tradeoffs between Accuracy and Energy Consumption: So far in our evaluation, we wanted to minimize the accuracy impact (see Table III).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "For example, smaller experts may be mapped to individual chiplets (or can be colocated in the same chiplet), while a large expert may be mapped to multiple chiplets. Or, multiple low hot experts can be assigned to one chiplet, and high hot experts can be distributed across chiplets. Further, neighboring experts can be mapped to adjacent chiplets for improving physical proximity and reducing data movement costs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "To determine the number of requests each VM can handle in parallel, we can conduct offline profiling for different model types. For applications where the request load is fairly constant over time, only VM-based resources can be procured to serve the requests. 3.2 Resource selection \n3.2.1 Static Load  From  Observation 2 , it is clear that, be- sides model selection, it is crucial to select and configure the right resource to satisfy the application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "As discussed in Fig. 3a, another enabler for computation reduction is the relative distance between the camera/user and the objects, i.e.,  left-right . As one can observe from the  Intra- Holo  scenario shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Further, we also study the overheads introduced by our design modiÔ¨Åcations to perform a fair comparison with the state-of-the-art. This can help us identify and isolate proper memoization candidates for carefully tweaking our design decisions to maximize the reuse beneÔ¨Åts. What (features) to Memoize?",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Employing predictive energy harvesting models to anticipate energy availability and adjust computations proactively. In extreme cases, the system can enter into a low-power standby mode and resume operation when sufficient energy is available. These strategies ensure that the system remains operational and provides degraded but acceptable performance under severe energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "IEEE, 2015. 1‚Äì5. In  2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Further, we mapped these AR software components to an edge GPU prototype [ 36 ], from which the power breakdown across different components such as SoC, memory, CPU, and GPU are measured through the on-board Texas Instruments INA 3221 voltage monitor IC hard- ware, and the performance of execution status is sampled by the Nvidia NVPROF [ 37 ] profiling tool, which enables the collection of a timeline of CUDA-related activities on both the CPU and GPU, including kernel execution, memory transfer, CUDA API calls and events/metrics for CUDA kernels. 5 EVALUATION We evaluate our proposed  HoloAR  design by comparing the execu- tion latency and total energy consumption with four different AR hologram setups. On top of the ILLIXR codebase, we implemented three new components ‚Äì eye tracking, pose estimation, and hologram processing.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 204,
    "augmented": true
  },
  {
    "text": "Accessed: 2024-10-20. [54] Graphcore. Graphcore intelligence processing unit (ipu).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 26,
    "augmented": false
  },
  {
    "text": "4.2.1 Resource Controller \nResource controller determines the cost-effective combina- tion of instances to be procured. We explain the details below. We explain in detail the resource procurement and autoscaling policy employed in  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "II. E DGE -C LOUD  P ARTITIONING  P OLICIES \nIn this section, we discuss the various policies to \nCloud  Server \nDeploy 1 \nDeploy 2 \nDeploy 3 \nDeploy n \nData_1 Data_2 Data_3 Data_n \nDevice_1 \nDevice_2 \nDevice_3 \nDevice_n \nData Shared \nRF_1 RF_2 RF_3 RF_n \nPeer connections for Policy 2 \n(a) Data Sharing Policies. Finally, we provide a sensitivity analysis to understand the effect of different hyper-parameters on the accuracy and latency.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "This is because both policies spawn a container per request, resulting in almost zero queueing. The relatively high cold start-induced delay experienced by  Xanadu  can be attributed to the reactive scaling it uses to cope with MLP mispredictions. Kraken  exhibits delay characteristics simi- lar to  Fifer  owing to both policies having batching and a similar container pre-deployment policy.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "A critical but often overlooked aspect of these compute-intensive operations are usage of water in cooling mechanisms in the data centers. A study [94] on the same highlights the opera- tional water consumption footprint for LLM training and inference and points out that, in the United States, on average, for every 30 inference requests on a small model like GPT-3 results in consumption of 500mL of water. In fact, for training GPT-3, on an average, 5.4 million liters of water is consumed!",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "We will then perform ‚Äúunlearning‚Äù by parameter-efficient fine-tuning to update the most relevant parameters. Task-1.4: Algorithmic Choices Informed by System and Hardware Constraints Our EoE system optimization is fundamentally a co-design problem across the algorithm, system, and architecture layers. As the above tasks develop optimal algorithms for dynamic morphable LLMs, they introduce many types of ‚Äúaffinities‚Äù (listed in Table 2) to facilitate our system and architectural level opti- mizations, which are investigated in Thrusts 2 and 3, respectively.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "[15]  William H Beluch, Tim Genewein, Andreas N√ºrnberger, and Jan M K√∂hler. The power of ensembles for active learning in image classiÔ¨Å- cation. In  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 9368‚Äì9377, 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "As in the case of  T 4 , this transformation is also HMD design- dependent and is known at design-time. ‚Ä¢  T 5 , the last transformation to be applied, performs a view- port transformation 5 , bringing the projected points to the coordinates used to index the pixels on the HMD. Note that, the  product  of these Ô¨Åve transforms gives us the Ô¨Ånal transformation matrices ( T L  and  T R ), which together convert the  3 D  coordinates of the  360 ¬∞ frame to the  2 D  coordinates suitable for HMD.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Scharw√§chter, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset. In  CVPR Workshop on the Future of Datasets in Vision , volume 2. sn, 2015.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "It can be observed from this figure that, even with the most aggressive approximation introduced by  Inter-Intra-Holo , the video quality is still sufficient for most of the AR applications (30 . Further, to study how the tuned approximation (in Algo. 7 on average) [57].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "In  SoCC . [4]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg. Stratus: Cost-aware Container Scheduling in the Public Cloud.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "7 that, the results of the left-eye are generated by the Original Compute Engine (GPU in this case) and fed into the  AE  block with the Ô¨Årst row for the right-eye, to store the pattern into the Delta Buffer. After that, the computation for the right-eye can be easily reconstructed by the left- eye‚Äôs compute results and the pattern, which only consumes 13%  energy compared to the  Baseline . Therefore, as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Eye-dominance-guided Foveated Rendering. IEEE Transactions on Visualization and Computer Graphics (2020), 1972‚Äì1980. [31]  Microsoft.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2211.05100 , 2022. [166] Xun Wu, Shaohan Huang, and Furu Wei. Mixture of lora experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Method Function \nRouting Function \nMixture-of-experts Œ± i  =  SoftMax ( W i h i ‚àí 1 ) Variable size Œ± i  =  { a > k | a  ‚àà SoftMax ( W i h i ‚àí 1 ) } Top-k learned routing Œ± i  =  TopK ( SoftMax ( W i h i ‚àí 1 )) \nExpert Function \nFeedforward network h i  =  W i h i ‚àí 1 Prompt tuning h i  =  f Œ∏ i ( œï i ,  h i ‚àí 1 ) Low-rank adaptation W i  =  W ‚Ä≤ i   +  AB Large language model Œ∏  =  argmax Œ∏ \nQ T t =1   p Œ∏ ( y t | x, y j<t ) Retrieval augmented generation Œ∏  =  argmax Œ∏ \nP \nz ‚ààD   p Œ∏ ( z | x ) p Œ∏ ‚Ä≤ ( y | x, z ) \nComposition Function \nRepresentation averaging h i  =   P M j =1   Œ± i h i,j Weight summation W i  =   P M j =1   W i,j Sequential aggregation f Œ∏ ‚Ä≤  =  f œï M  ( f œï M ‚àí 1 ( ¬∑ ¬∑ ¬∑  f Œ∏ )) \nTable 1 :  Different methods for three building blocks of our EoE framework: Rout- ing, Expert, and Composition. In this way, we aim to find the optimal combination of the choices. Next, we evaluate the new combinations by extracting one function from each type.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 405,
    "augmented": true
  },
  {
    "text": ":  The proposed inter- frame attribute compression further improves the compres- sion efÔ¨Åciency by skipping the redundant storage for the same/similar segments matched across frames, with extra latency overhead (but still much better than the state-of-the- art ‚Äì  139 ms  vs  5 . 9 s ). In this example, for compressing the P-Frame, one pointer (for  S 1  which contains  P 0  and  P 1 ) and only one post-intra-encoded compressed delta (for  P 2 ) are required for storage, instead of storing all three.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "IV-A 2  for intra-frame compression, to further compress these deltas. 3) What are the Pros and Cons? :  The proposed inter- frame attribute compression further improves the compres- sion efÔ¨Åciency by skipping the redundant storage for the same/similar segments matched across frames, with extra latency overhead (but still much better than the state-of-the- art ‚Äì  139 ms  vs  5 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "They will have access to courses on Effective Communi- cation and Presentation Skills. Improving Skills \nThe students will participate in regular research group meetings, where they will describe their work to colleagues and collaborate on solving research problems, fostering communication, programming skills, and other types of technical skills. Instruction in Responsible Professional Practices \nThe PhD students will receive instruction in responsible and ethical professional practices regularly within the context of their work.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "The idea is to use the reconstruction error to determine the probability: \np i  = Œ≥  RE i max( RE ) +  œµ \n18 \nwhere  Œ≥  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. Define a binary dropout mask  m  = [ m 1 , m 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "By the end of the second year, the preliminary system support will be finalized and we will have the initial expert-to-chiplet mappings ready. Around mid-way in the third year, we will have all three main pieces of the project (algorithmic enhancements, system support and architectural support) ready. By the end of the project, the entire framework along with sample expert models, algorithms, system support and documentation will be in the public domain.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Truthfulqa: Measuring how models mimic human falsehoods. [97] Zi Lin, Diana Jin, and Saurabh Singh. IEEE Micro , 43(3):18‚Äì30, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "3. Adaptive Tuning:  If conditions change over time, adjust Œ≥, Œ¥,  and  Œ∑  dynamically based on observed participation rates, accuracy levels, and energy depletion patterns. Exploration Algorithm \nAlgorithm  3  outlines a systematic approach to exploring suit- able hyperparameter values.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "8 , T area  = 0 . 25 and  RD upper bound  = 10  in Algo. 8 , T missed  = 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Training and Aggregation Framework \nHaving established the equilibrium participation strategies and the underlying reward-based utility functions, we now consider the training process that fine-tunes the global in- ference model  Œ∏  ‚àà R d   within this EH, multi-sensor envi- ronment. Initially,  Œ∏  is pre-trained offline and deployed to all sensors, enabling them to perform basic inference tasks. However, this initial model may not be optimally adapted to the complex operational reality of the network, where sensors strategically choose SNR levels, participate inter- mittently according to equilibrium strategies, and generate data distributions that deviate from the original training set.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "However, this research direction only accounts for fixed lower and upper bounds of energy and compute capacities, overlooking the ‚Äúsporadic‚Äù nature of energy availability and the elasticity of the compute hardware (i.e., the ability to dynamically scale frequency, compute, and memory). Moreover, while the DNN is designed to operate within a specific power window, it is  not  trained to adapt to these fluctuations. One major issue is, most of the works leverage ‚Äúpre-existing‚Äù DNNs, which are typically designed for running on a stable resource environment, while being deployed on an intermittent environment with pseudo notion of stability via check-pointing, and therefore, one direction of works (Mendis et al., 2021) looks for performing network architecture search for intermittent devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 168,
    "augmented": true
  },
  {
    "text": "Further, all sensors might not be able to participate in the ensemble due to the Ô¨Åckle nature of harvested energy. This demands the aggregation process for the ensemble to be robust, yet light weight in order to perform accurate classiÔ¨Åcation with minimum overhead. Therefore, this work proposes an intelligent scheduler along with efÔ¨Åcient ensemble learning to enable DNN inference in a distributed energy harvesting wireless sensor network (EH- WSN).",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Adaptive Weighted Gerchberg-Saxton Algorithm for Generation of Phase- only Hologram with Artifacts Suppression. Opt. Express  (2021), 1412‚Äì1427.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "0 \n2 \n4 \n6 \n8 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nRelative Latency \n2 to 1 4 to 1 6 to 1 \nFigure 11: Impact of increasing the number of CSDs in the system (the baseline system has a SSD-to-CSD ratio 8 to 1). 16 \n0 \n2 \n4 \n6 \n8 \n10 \n12 \n14 \nKittiVision nuScenes CHIME Cityscapes Waymo \nRelative Latecny \n2 Nodes 3 Nodes 4 Nodes 5 Nodes 6 Nodes \nFigure 10: Change of data movement latency with respect to the number of storage servers. Similarly, Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "TABLE  III  depicts some of such possible comparison points. The possible alternate solu- tions being battery-backed custom HW [ 16 ], battery-backed commercial GPU and Ô¨Åxed power budget with store and \n902 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "If the request takes a different path,  Xanadu provisions containers along the path actually taken, in a reactive  fashion, and scales down the containers it provi- sioned along the MLP. Consequently,  Xanadu , when subject to moderate/heavy load, over-provisions containers by 32% compared to the Probability-based policy (from Figure 2) as a result of being locked into provisioning containers for the MLP until it is able to recalculate it. Xanadu  [ 27 ] represents the policy that scales containers only along the Most Likely Path (MLP), which is the request‚Äôs expected path.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "Latency (ms) \nHoloCompute Overhead \n876.81 \n430.15 393.07 \n(b) Exec. latency (ms). 4.48 \n0 2 4 6 8 10 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "[11] 2020. com/en-us/services/functions/. https://azure.microsoft.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "Hence, by memorizing or  recalling  the most recent classiÔ¨Åcation result, we can get the inference result of a sensor even without activating it. Even though the sensors are running in the round-robin fashion, the non-participating sensors can still impact the classiÔ¨Åcation result by virtue of  recalling their most recent classiÔ¨Åcation. Combining the  Recall  with AAS (which we term as AASR - Activity Aware Scheduling with Recall) opens possibilities for getting a more accurate classiÔ¨Åcation.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Multi-View Learning and Collaborative Inference \nMulti-view learning leverages multiple sources or perspec- tives to improve learning performance ( ? In EH-WSNs, sensors providing different views of the same scene can en- hance inference accuracy through collaborative processing. ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Finally, most of the coreset construction algorithms are simple (hence can achieve  1  ) and do not need complex operations (like cosine, exponential, etc. For the DNNs in question, coresets can achieve sufficient compression ratios to make communication energy-competitive with computation, as well as opening up new opportunities for optimizing DNN in- ference on the coreset, rather than original data. [ 7 ,  8 ,  36 ,  37 ], they can also be quantized [ 37 ] to further reduce their computation and memory footprints.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "have a huge impact on the convergence and accuracy of the models. For each edge servers to handle multiple steams with multiple drifts, we need to jointly optimize the hyper-parameters for maximizing accuracy with minimum power and resource budget. To achieve this, we design a ‚Äúmicro-proÔ¨Åler‚Äù that can look into the drift of the models as well as the power availability and decide the right hyperparameters to train the models.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Consistent with the above observation, the entire  Sequential strategy competes with the entire  Pipelining . That is, the selection ratio of  Sequential  is much higher than the ratio of  Pipelining  in ResiSchedule  solutions in the whole power trace. The reason is that the active power threshold of  Pipelining  is much higher than that of  Sequential .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "2), we profiled a set of applications and found that the  hologram  processing is the primary bottleneck in terms of computation, energy consumption, and execution latency. The heavy compute demand of the hologram (re)construction has made this a promising candidate for acceleration, and prior works have tried to offload it to cloud [ 16 ,  27 ,  67 ] and specialized accelerators [35] to achieve high throughput, but doing so has led the communication with the edge device to be a major bottleneck. Others have proposed to design efficient and lightweight deep neu- ral networks (DNNs) to achieve high quality scene rendering at the edge device itself, but this requires model retraining/tuning for a particular user [ 33 ,  54 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 169,
    "augmented": false
  },
  {
    "text": "A. Energy Harvester and Sensor Setup \nOur evaluation setup consists of three sensors at three dif- ferent locations. First sensor at the chest, second on the right wrist and last sensor on the left ankle.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "3. Inter-Intra-Holo:  It is to be noted that, when the user eye track- ing and pose estimation are available simultaneously for hologram processing, the  Inter-Holo  and  Intra-Holo  schemes can be both ap- plied to achieve maximum amount of energy savings and perfor- mance benefits. In this paper, we refer to this combined scheme as  Inter-Intra-Holo .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Our extensive ex- perimental evaluation using  DeathStarbench  workload suite and real-world traces demonstrates that  Kraken  spawns up to 76% fewer containers, thereby improving container uti- lization and saving cluster-wide energy by up to 4 √ó  and 48%, respectively, when compared to state-of-the art schedulers employed in serverless platforms. We design and implement  Kraken  on  OpenFaaS  and evaluate it on a multi-node  Kubernetes -managed cluster. CCS Concepts ‚Ä¢  Computer systems organization  ‚Üí Cloud Comput- ing ;  Resource-Management ; Scheduling.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. 12 \nTien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. arXiv preprint arXiv:1708.07747 , 2017.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "ISSN 0140- 3664. doi: https://doi.org/10.1016/j.comcom.2019.10.012. Cognitive computing and wireless communications on the edge for healthcare service robots. Computer Communications , 149:99‚Äì106, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "4 \nThe main reason these algorithms consume significant resources is because of the amount of data they handle. Every single  1920  √ó  1080  raw frame prior to encoding carries  ‚âà 23 MiB of data which, @60fps, will require processing  ‚âà 1 . 4 GiB of data per second per imaging source.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Data compression becomes even more critical as PC processing is pushed to edge devices with limited compute and power budgets. In this paper, we propose and evaluate two complementary schemes, intra-frame compression and inter-frame compression, to speed up the PC compression, without losing much quality or compression efÔ¨Åciency. Unlike existing techniques that use sequential algorithms, our Ô¨Årst design, intra-frame compression, exploits parallelism for boosting the performance of both geometry and attribute compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "1080 \nAuthorized licensed use limited to: Penn State University. 3  in Algo. 2 4 The ground-truth annotations for the EPFL and CAMPUS datasets were not available to us; so, in this work, we primarily focused on the VIRAT dataset to evaluate the accuracy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "However, since most of these applications are now running on low-power mobile devices, and frequent communi- cation of data to and from cloud via wireless medium is inefficient, optimization of an AR pipeline to maximize the compute and en- ergy efficiency, while providing adequate QoS, at an edge device is an architectural challenge. These sensor inputs play a major role in deciding which portions of the 3D voxels need to be rendered for the user to view. Furthermore, existing AR headsets are typically equipped with multiple sensors for head orientation, eye tracking, motion detection, etc., to provide an interactive and life- like experience.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "This slack is leveraged by  Kraken  by batching multiple requests to the functions by queueing requests at their con- tainers. Requests are batched onto containers in a fashion similar to the First Fit Bin Packing algorithm [ 36 ]. Batching reduces the number of containers spawned for each function by a factor of its batch size (Algorithm 1  b  ).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "‚Ä¢  PTU:  In the current state-of-the-art scheme, which is the hardware-based PTU [28], they explored the energy- efÔ¨Åcient hardware accelerator (namely, PTU) to replace power-hungry GPU. the  Baseline , with only  10%  for the right-eye, translating to  28%  total energy saving. Due to this, one can observe from Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "SPIE, 2016, pp. 57 ‚Äì 65. [63] H. Zhang, P. V. Rengasamy, S. Zhao, N. C. Nachiappan, A. Sivasub- ramaniam, M. T. Kandemir, R. Iyer, and C. R. Das, ‚ÄúRace-to-sleep + Content Caching + Display Caching: A Recipe for Energy-efÔ¨Åcient Video Streaming on Handhelds,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2017, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "The most common algorithms used fod the said operations are High-Speed Schoolbook Polynomial Multiplication (HSPM) and Pipelined Systolic Dimension Modular Multiplier (SDMM), and we propose to accelrate the same using the FPGAs in the CSDs. Note that, within the LBC algorithm, certain components, specifically polynomial multiplications, exhibit similarities to operations performed in CNNs. These similarities open up the possibility of reusing hardware designed for CNN operations to accelerate LBC computations.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "[33]  Naoya Muramatsu, Chun Wei Ooi, Yuta Itoh, and Yoichi Ochiai. Second Version of HoloLens HPU will Incorporate AI Coprocessor for Implementing DNNs. \"https://www.microsoft.com/en- us/research/blog/second-version-hololens-hpu-will-incorporate-ai- coprocessor-implementing-dnns/\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "3, pp. [20]  L. Ni, Z. Liu, H. Yu, and R. V. Joshi, ‚ÄúAn energy-efÔ¨Åcient digital ReRAM-crossbar-based cnn with bitwise parallelism,‚Äù  IEEE Journal on Exploratory Solid-State Computational Devices and Circuits , vol. 37‚Äì46, Dec 2017.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "OLAS proposes an overlap-add stereogram algorithm, which uses overlapping hogels to encode the view-dependent light- ing effects of a light field into a hologram, achieving better quality than other holographic stereograms [ 46 ]. Neural-Holography proposes an algorithmic hologram generation framework that uses camera-in-the-loop train- ing to achieve unprecedented image fidelity and real-time frame rates [ 48 ]. These display quality optimizations are orthogonal to our approximation-based proposal, and our approach can be used along with such optimizations.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "This reduces software overheads and latencies for handling power emergencies and hence can guarantee better QoS for complex and longer tasks even when power is deeply unreliable. These software-based solutions exhibit inefficiencies with respect to energy and time due to performing multiple save- and-restore cycles [ 23 ,  56 ]: while some of these operations are necessary, unnecessary checkpoints will also be conser- vatively performed to ensure forward-progress. Therefore, recent works [ 39 ‚Äì 42 ,  56 ] propose the use of a NVP, where the non-volatility of the hardware itself takes care of saving and resuming the program execution.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "Complexity Analysis of DynFit:  The time complexity of DynFit during training is  O ( N  ¬∑  T ) , where N  is the number of weights and  T  is the number of training iterations. The overhead introduced by monitoring update frequencies and adjusting dropout rates is negligible compared to the overall training time, as these operations are simple arithmetic computations per iteration. The space complexity is  O ( N )  for storing the update frequencies and additional parameters.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Since each sensor‚Äôs best-response update seeks to maximize its own utility, sensors will continue to deviate as long as prof- itable deviations exist. Our argument shows that profitable deviations must terminate. Under the assumptions that ‚àÜ A i ( t )  is non-decreasing and that sensors have consistent energy and accuracy estimates, no cyclical behavior can persist.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Consider a trafÔ¨Åc camera looking at a busy street with a trafÔ¨Åc signal. Due to the trafÔ¨Åc distribution (e.g., more cars than buses), the camera typically sees a varied distribution of different classes, which might reÔ¨Çect in the exemplar set. Moreover, some static objects (trafÔ¨Åc light, stop sign, etc.)",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "append ( addModel ) 17: end if 18:  end procedure 19:  procedure  W EIGHTED _V OTING ( Models ) 20: for  model in  ‚àÄ Models  do 21: class  ‚Üê model . drop ( to _ be _ dropped ) 13: end if 14: else 15: addModel  ‚Üê find _ models ( remaining _ models ) 16: Models . Algorithm 1  Model Selection and Weighted Majority Voting \n1:  procedure  F ULL _E NSEMBLE (M ODEL L IST , SLO) 2: for  model  ‚àà ModelList  do 3: if  model.latency  ‚â§ SLO.latency  then 4: Model.add(model) 5: end if 6: end for O 1 7:  end procedure 8:  procedure  D YNAMIC _M ODEL _S CALING ( Models ) 9: if  curr_accuracy  ‚â• accuracy_threshold  then \n10: if  max vote  >   N \n2   + 1  then  O 2 \n11: to _ be _ dropped  ‚Üê max vote  ‚àí N \n2   + 1 12: Models .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 266,
    "augmented": true
  },
  {
    "text": ". , T N } , where each task  T i  is characterized by its energy requirement  E i , execution time  œÑ i , priority  p i , deadline  D i , and criticality level  c i . At any given time  t , the available energy is denoted as  E b ( t ) .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "[163] Zihao Wang, Bin Cui, and Shaoduo Gan. Squeezeattention: 2d management of kv-cache in llm infer- ence via layer-wise optimal budget, 2024. [164] Wikimedia Foundation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output Y .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Swift machine learning model serving scheduling: a region \nbased reinforcement learning approach. [64]  Xueheng Qiu, Le Zhang, Ye Ren, Ponnuthurai N Suganthan, and Gehan Amaratunga. In  Proceedings of the Inter- national Conference for High Performance Computing, Networking, Storage and Analysis , pages 1‚Äì23, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "If it detects requests whose wait times exceed the cost of spawning a new container (the cold start of the function), overloading is said to have occurred at the stage. In such a scenario,  Kraken batches these requests (# _ ùëëùëíùëôùëéùë¶ùëíùëë _ ùëüùëíùëûùë¢ùëíùë†ùë°ùë† in Algorithm 2) onto a newly-spawned container(s) (Algorithm 2  c  ). This is because requests that have to wait longer than the cold start would be served faster at a newly created container than by waiting at an overloaded container.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Further optimizations such as eye- dominance (i.e., HVS prefers scene perception from one eye over the other) and learning-based foveated rendering are orthogonal to this core idea and beyond the scope of this paper [24, 30]. Such differential resolution within an image can reduce computational costs without significantly impacting user experience [ 25 ,  47 ,  62 ]. Despite providing significant performance and energy-efficiency benefits, these prior works still miss out on even more selective rendering of viewed hologram images - beyond just the FoV and/or regions of the user‚Äôs focus.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "[78]  J. Sun, Y. Xie, S. Zhang, G. Zhang, H. Bao, and X. Zhou, ‚ÄúYou Don‚Äôt Only Look Once: Constructing spatial-temporal memory for integrated 3d object detection and tracking,‚Äù  ICCV , 2021. [79]  M. A. S. Teixeira, H. B. Santos, A. S. d. Oliveira, L. V. Arruda, and F. Neves, ‚ÄúRobots perception through 3d point cloud sensors,‚Äù in  Robot Operating System (ROS) .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "In the proposed  AE  scheme, one can observe that for the left-eye computation, the energy consumption is the same as in the  Baseline . Recall from the  AE  design logic in Fig. 7 that, the results of the left-eye are generated by the Original Compute Engine (GPU in this case) and fed into the  AE  block with the Ô¨Årst row for the right-eye, to store the pattern into the Delta Buffer.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "B. Why have  EA / AE  Opportunities been previously Ignored? Based on the above discussion, in this work, we focus on EA  and  AE  opportunities.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference. In this design paradigm, the basic low power, lightweight MCU system can enjoy the advantage of continuous operation without suffering power outages, while the compute-heavy inference tasks can be ofÔ¨Çoaded to the RCA during periods when power income is sufÔ¨Åciently high and to external systems otherwise. Such a system is capable of both continuously collecting data and computing CNNs locally near data.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "[151] Sainbayar Sukhbaatar, Olga Golovneva, Vasu Sharma, Hu Xu, Xi Victoria Lin, Baptiste Rozi√®re, Jacob Kahn, Daniel Li, Wen tau Yih, Jason Weston, and Xian Li. Branch-train-mix: Mixing expert llms into a mixture-of-experts llm. arXiv preprint arXiv:2403.07816 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "1%  for YOLOv4-tiny ‚Äì both w.r.t. the baseline. With the FI+SI+PI scheme on the other hand, the mAP drops  1 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Rather than capitalizing on such design hacks, we need to develop prediction policies to estimate load correctly. Also, we suggest service providers should handle the pre-warming decision by knowing model-wise usage statistics to enable instance sharing, which uses the same models. This would lead to a reduction in cold-start latencies incurred for users with the same type of requests.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "Figure  9b  shows the most used models in decreasing order of importance. The au- toscaling policy effectively utilizes this importance factor in regular intervals of 5 minutes. Despite using multiple models for a single inference, importance sampling combined with aggressive model pruning, greatly reduces the resource foot- print which directly translates to the cost savings in  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "4 Optimizing Lattice-Based Cryptography \nFollowed by the video compression, in this section, we discuss the quantum safe encryption technique. The backpropagation is applied only to the layers of the autoencoder, ensuring that the feature extractor‚Äôs parameters remain intact. This approach not only preserves the integrity of the visual features derived from MobileNet but also tailors the compression mechanism to be highly adaptive to the content-specific characteristics captured by these features.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "The efficiency of data movement significantly influences the performance and energy consumption of large-scale systems (Park et al. ). Our research aims to  bridge  this gap, focusing specifically on the exigencies of continuous learning applications. 2.2 The Problem: Understanding the Data Flow \nChallenges in Data Movement:  In both consumer applications and high-performance computing (HPC) programs, the process of data collection followed by analytics is a critical operation (Cao et al., 2020; Mailthody et al., 2019; Chapman et al., 2019; Li et al., 2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "Journal of Research Practice , 10(1), 2014. Challenges in archiving and sharing video data: Considering moral, pragmatic and substantial arguments. Dur E Shahwar Kundi, Song Bian, Ayesha Khalid, Chenghua Wang, M√°ire O‚ÄôNeill, and Weiqiang Liu.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Unbiased gradient estimates. When the aggregator requests a training update, a subset of sensors, deter- mined by equilibrium conditions, provide local gradi- ents. Although not all sensors participate every time, the equilibrium ensures a stable pattern of participation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "by utilizing the spatial locality with Morton code for attribute compression, instead of performing transforms through octree layers, in our proposal, only simple subtractions are needed for computing deltas. in parallel with the help of Morton codes, which speeds up the geometry compression by  37 √ó ; 2). Further, all the points are processed in parallel; 3).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "This alignment minimizes unnecessary energy ex- penditure and maximizes the efficacy of each training round. Sensors participate \nin training rounds based on their equilibrium-driven de- cisions, ensuring that gradient updates are contributed by those sensors most capable and willing to improve the global model. Algorithm 2  Periodic Equilibrium-Aware Training Algo- rithm \n1:  Initialization:  Initialize  Œ∏ 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Thus, while the MoE/CoE design paradigm is promising, the overall solution space is little explored, especially for complex compositions of smaller experts. These observations call for a holistic hardware-software ‚Äúco-design‚Äù that integrates efficient expert models with custom system support and reconfigurable hardware architectures, to optimize performance, while minimizing resource consumption. Therefore, it is imperative to investigate the modular LLM design space in depth not only to mitigate the above issues, but also to facilitate democratization by allowing anyone to use and contribute in a ‚Äúplug-and-play‚Äù fashion.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "In smart manufacturing, multiple machines, even of the identical make and model, can generate different artifacts while encountering the same fault due to different physical interference such as resonant frequency and ambient tem- perature. The ability to capture diverse conditions from the different nodes, with or without sharing data, can lead to more robust models. Although model sharing, instead of data sharing, solves some of the challenges [5], such approaches are not trivial to deploy in classical learning paradigms, like random forests.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "A Case for Managed and Model-Less Inference Serv- ing. In  HotOS . ACM.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "This is similar to an online bin-packing algorithm. We use an idle-timeout limit for 10 minutes to recycle unused \ninstances from every model pool. Hence, greedily assigning requests enables early scale down of lightly loaded instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "A.2 More Results on Bearing Fault Data We repeated our experiments with similar experimental setup on the bearing fault data set [ 53 ]. The bearing fault data is sampled at a much higher frequency (48KHz) than the HAR data, and hence require a larger DNN, larger num- ber of importance sampling, and more number of clusters. We took the learning from multiple domain specific litera- tures [ 19 ,  29 ,  53 ] to isolate the frequency regions specific to the fault pattern to minimize the computations.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "42 √ó  speedup is achieved when employing Intra-Holo  (with only 0 . 44% overhead), and 2 . 68 √ó  when employ- ing  Inter-Intra-Holo  (with only 0 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "‚Ä¢  EA  (SW) : We evaluate the  InterFrame, IntraEye ( EA ) design on a GPU, as shown in the  EA  block in Fig. 7. Note that, this implementation is purely done in software, without any hardware modiÔ¨Åcation.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "TABLE I: Qualitative summary of DNN vision optimiza- tion work in terms of accuracy, saving, adaptivity, hardware support, and decision making mechanism (DM). Note that a check-mark in the second and third columns means the corresponding scheme achieves high accuracy and energy/per- formance efÔ¨Åciency, respectively. A check-mark in the Custom HW column indicates that the corresponding approach does not need custom hardware, whereas a cross means it needs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "6 , the points at one layer in the octree have dependencies with those at other layers, thus their processing requires acquiring locks at a ‚Äúlayer granularity‚Äù. Even with the optimizations in [ 33 ], where the octree construction stage can be performed in parallel, there are still several synchronization points, resulting to limited parallelism. To summarize, the performance inefÔ¨Åciencies in prior works can be primarily attributed to the lack of parallelism of these algorithms.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "to resume and remap the compute. This problem reduces in both input stationary and weight stationary, but at the cost of throughput [ 80 ]. Typically, the input feature maps are larger than the (individual) weights, and more importantly large weights can easily be represented \n897 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "In our experiments, we observe that, in most cases, the accuracy of the peers are similar to that of the edge node. Therefore the case of consulting a peer only becomes beneficial when the communication latency and energy to the peer is much less than to the cloud. B.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "The quantized DNNs benefit from lower compute and memory footprints, but need specialized fine-tuning and often suffer from lower ac- curacy. Similarly, other approximation-via-data-reduction techniques, such as sub-sampling, did not perform inference with a desirable accuracy. Collectively, the aforementioned figures demonstrate that the harvested energy budget is insuf- ficient to perform  all  inferences with acceptable accuracy on currently proposed EH-WSN systems.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "The DeepARest prediction model which is not in the critical decision-making path runs as a background process incurring 2.2 ms latency on average. The weighted majority voting takes 0.5ms and the model selection policy takes 0.7ms. The time taken to spawn new VM takes about 60s to 100s de- pending on the size of the VM instance.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Conf. on Digital Audio Effects (DAFx-08) , 2008, p. 31. [85] Shadi Noghabi, Landon Cox, Sharad Agarwal, Ganesh Anantha- \narayanan, ‚ÄúThe emerging landscape of edge-computing,‚Äù in  ACM SIGMOBILE GetMobile , 2020.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "[57]  Randall Shumaker and Lackey Stephanie. 2014. Virtual, Augmented and Mixed Reality: Designing and Developing Augmented and Virtual Environments: 6th International Conference, VAMR 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014, Proceedings, Part I .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Baseline  iNAS+PT designs the network from the ground up while combining the work of iNAS (Mendis et al., 2021) and EAP (Yang et al., 2018, 2017). 7 \nWe also compare our approach with recent state-of-the-art methods specifically designed for in- termittent systems, namely  Stateful  (Yen et al., 2022),  ePerceptive  (Montanari et al., 2020), and DynBal  (Yen et al., 2023). These methods introduce various techniques such as embedding state information into the DNN, multi-resolution inference, multi-exit architectures, and runtime reconfig- urability to handle intermittency in energy-harvesting devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 185,
    "augmented": false
  },
  {
    "text": "These are then communicated to the host device for inference. Since clus- tering better preserves the geometry of the distribution, we observe that inferences with coresets constructed using clus- tering are more accurate than using importance sampling, and therefore can be preferred over the former whenever there is enough energy. 3.2 Communication vs Accuracy We can tune the aforementioned coreset construction tech- niques allow a variable number of features depending on the available energy, i.e.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "¬¥as \n592 168.2 22.7 (17.2 if only train) 4016 159.42 Fully powered, DNN Compute only 287.44 Fully powered, DNN  Œº ‚àí proÔ¨Åler 255.39 EH +  Œº ‚àí proÔ¨Åle + NV-mems + resizing RAM + Host 159.40 \nTABLE II: Comparison with prior accelerator-based platforms. The systolic array accelerator time multiplexes between per- forming feature extraction for exemplar selection and running the training. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "13‚Äì18, 2021. Tianyi Shen, Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. In  Proceedings of the 5th International Workshop on Embedded and Mobile Deep Learning , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "give more importance in choosing the data which are unique and, in our case, contribute significant to the inference (i.e. having a high enough magnitude in the frequency response of the sensor signal). The intuition is that any importance sampling scheme produces an unbiased estimator [ 8 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "URL  https://doi.org/ 10.1145/3517207.3526973 . David Arthur and Sergei Vassilvitskii. K-means++ the advantages of careful seeding.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Datasets Full Power AP PT iNAS+PT Stateful ePerceptive DynBal NExUME \nFMNIST 98.70 71.90 79.72 83.68 85.40 86.25 87.50 88.90 CIFAR10 89.81 55.05 62.00 66.98 68.50 70.20 71.75 76.29 MHEALTH 89.62 59.76 65.40 71.56 73.80 74.95 76.10 80.75 PAMAP 87.30 57.38 65.77 70.33 72.20 73.35 74.50 75.16 AudioMNIST 88.20 67.29 73.16 75.41 76.80 77.95 78.60 80.01 Table 1: Accuracy comparison on TI MSP board using piezoelectric energy harvesting. As observed in Table 1, NExUME consistently outperforms the state-of-the-art methods across all datasets. For instance, on CIFAR10, NExUME achieves an accuracy of 76.29%, which is approximately 4.54% higher than DynBal, the next best method.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 285,
    "augmented": true
  },
  {
    "text": "The relatively high cold start-induced delay experienced by  Xanadu  can be attributed to the reactive scaling it uses to cope with MLP mispredictions. This is because both policies spawn a container per request, resulting in almost zero queueing. Kraken  exhibits delay characteristics simi- lar to  Fifer  owing to both policies having batching and a similar container pre-deployment policy.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "[11]  A. Corning, ‚ÄúAR/VR in the OR ‚Äì Surgical Applications of Augmented and Virtual Reality,‚Äù  ‚Äùshorturl.at/fqwAJ‚Äù , 2021. [12]  T. Cosso, I. Ferrando, and A. Orlando, ‚ÄúHigh-precision laser scanning for cave tourism 3d reconstruction of the pollera cave, italy,‚Äù  GIM INTERNATIONAL-THE WORLDWIDE MAG- AZINE FOR GEOMATICS , vol. 29, no.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Then, the Ô¨Ånal ac- curacy of this ensemble would be the probability of at least ‚åä N / 2 ‚åã + 1 of them giving a correct result. To we model this problem as a coin-toss problem involving N  biased coins with having probability of occurrence of head to be  a . Relating this to our problem, each coin represents a model, and an occurrence of head represents the model giving the correct classiÔ¨Åcation.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "URL  https://doi.org/10.14778/3229863.3236256 . Brandon Haynes, Maureen Daum, Dong He, Amrita Mazumdar, Magdalena Balazinska, Alvin Cheung, and Luis Ceze. Vss: A storage system for video analytics.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "As previ- ously discussed in Section  3 , spot instances interruptions can lead to intermittent loss in accuracy as certain models will be unavailable in the ensemble. 6.3.2 Cocktail Failure Resilience \nWe use spot instances to host models in  Cocktail . The average number of models is in primary axis and cumulative accuracy in secondary axis.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the ACM Symposium on Cloud Computing (Santa Cruz, CA, USA)  (SoCC ‚Äô19) . Association for Computing Ma- chinery, New York, NY, USA, 13‚Äì24. https://doi.org/10.1145/3357223.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "B ACKGROUND AND  M OTIVATION \nEdge servers often leverage the convenience and Ô¨Çexibil- ity of cloud interfaces, granting access to the same APIs, tools, and functionalities [ 60 ]. However, due to their inherent limitations in resources, such as weak GPUs and smaller memory capacities [ 83 ], these servers often resort to ‚Äúcus- tomized‚Äù analytics services to maximize throughput and meet SLAs, including specialized DNN models tailored for edge deployments [ 51 ], [ 75 ], which are compressed, quantized, and optimized for the targeted hardware [ 30 ], [ 103 ], [ 109 ]. These tailored models enable accurate inference with high throughput and reduced resource footprint, with some compressed models having approximately 50 √ó  fewer parameters [ 30 ], but with a greater susceptibility to data drift [ 42 ], [ 55 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 193,
    "augmented": false
  },
  {
    "text": "Springer, 2023. Weiqiang Liu, Sailong Fan, Ayesha Khalid, Ciara Rafferty, and M√°ire O‚ÄôNeill. Optimized schoolbook polynomial multiplication for compact lattice-based cryptography on fpga.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "The cost incorporates energy consumption and future op- portunities. Here,  Œ≥ >  0  scales the reward for correct participation, Œ¥ >  0  penalizes incorrect inference, and  Œ∑ >  0  penalizes non-participation, with  Œ∑ > Œ¥  ensuring that remaining idle \n8 \n440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 \nis more penalizing than at least attempting participation. The immediate reward for sensor  s i  is defined as: \nR i ( t ) = \nÔ£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ \nÔ£¥ Ô£¥ Ô£¥ Ô£≥ \nŒ≥  ¬∑  ‚àÜ A i ( t ) , if  a i ( t ) =  P and inference is correct , \n‚àí Œ¥, if  a i ( t ) =  P and inference is incorrect , \n‚àí Œ∑, if  a i ( t ) =  NP .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 315,
    "augmented": true
  },
  {
    "text": "; ii)  What are the ways of efficiently retraining routers when new experts are added into or removed from the ensemble? ; iii)  How can fault-tolerance be factored into the training process without an unduly increase in execution latency and energy consumption? ; iv)  How can we identify hot experts and cold experts in LLM inference and how can such information be utilized?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "3) matter only during data transfer (from the input 360 ¬∞ frame to the framebuffer) in the projection mapping stage, after the coordinate mappings ( P  in Fig. 3) are gener- ated. Potentially, content-based optimizations (e.g., content cache [63]) can beneÔ¨Åt the data transfer; however, they are not attractive candidates to leverage compute reuse, which is the major power-hungry stage (as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "¬¥as  is competitive in terms of energy efÔ¨Åciency for training-only tasks. We include details on the energy efÔ¨Åciency of  Us. While fully powered,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Figure 11:  Number of VMs spawned for all four schemes. Strict Relaxed 0 \n25 \n50 \n75 \n#VMs \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace. 0 1000 2000 3000 Time interval (10s) \n0 \n50 \n100 \n#VMs \nBline model1 model2 model3 \n(a)  Cumulative #VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Input :  RD : Reuse Distance Input :  BBs : Bounding Boxes in Previous Frames Input :  MV s : Motion Vectors for Current Frame Output:  Do Full Inference : Decisions \n1  procedure  Moving ( BBs ,  mv ) // Scenario1 \n2 if  0  < max { overlapped.area } ‚â§ T moving  √ó  mv.area  then \n3 return  True \n4 else \n5 return  False \n6  procedure  Missed ( BBs ,  mv ) // Scenario2 \n7 if  mv.area  ‚â• T missed  √ó  min { BBs.area }  then \n8 return  True \n9 else \n10 return  False \n11  procedure  Entering/Exiting ( mv ) // Scenario3 \n12 if  mv  is at edge  then \n13 return  True \n14 else \n15 return  False \n16  procedure  Frame _ Decision ( RD ,  BBs ,  MV s ) // main \n17 if  RD  ‚â• RD upper bound  then \n18 return  True \n19 if  MV s  ==  ‚àÖ then \n20 return  False \n21 Fuse and Filter the  MV s \n22 if  BBs  ==  ‚àÖ then \n23 if  MV s is large  then \n24 return  True \n25 else \n26 return  False \n27 for  mv  in  MV s  do \n28 if  mv.area  > T area √ó minBBs.area  then \n29 if  Moving ( BBs , mv )  or  Missed ( BBs , mv )  then \n30 return  True \n31 if  Entering/Exiting ( mv )  then \n32 return  True \n33 return  False \n4) Algorithm:  To handle the three common scenarios dis- cussed above, we propose our  adaptive  frame level (FL) reuse algorithm to determine whether to invoke full inference (FI) or skip inference (SI) for the current frame ‚Äì as shown in Line  16 in Algo. 1. Algorithm 1:  Adaptive Frame Level Reuse Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 478,
    "augmented": true
  },
  {
    "text": "7. In our  EA  design, the last two head orientations are  cached  in local SRAM ( Comp 1  and  Comp 2  in the  EA block) and their corresponding projection computation results are stored in DRAM ( P i ‚àí 2 buff   and  P i ‚àí 1 buff ). In the  Baseline , the OCE takes the head orientation as its input, processes the entire projection transformation for each pixel coordinate in the FoV region, and then stores the compute results for both eyes in DRAM for the subsequent mapping stage from the  360 ¬∞ frame to framebuffer.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "This approach helps context-based search like looking for particular objects, events, or attributes (Douze et al., 2024). However, it is obvious that this approach, albeit good for streaming and retrieval, are not entirely space-efficient, and at times can increase the data volume by many folds (Douze et al., 2024). The vector index are used to point to the meta-data of the video file and then the actual video data is retrieved from the storage (Shen et al., 2005).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "[11]  Yu Feng, Paul Whatmough, and Yuhao Zhu. 2019. ASV: Accelerated Stereo Vision System.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Key Assumptions and Conditions \n1. The final training objective is: \nJ ( Œ∏ ) =  L ( Œ∏ ) +  Œª 1 ‚Ñ¶ SNR ( Œ∏ ) +  Œª 2 ‚Ñ¶ complexity ( Œ∏ ) , \nwhere  Œª 1 , Œª 2  ‚â• 0  are hyperparameters controlling the influ- ence of the regularizers. Our goal is to show that by running a diminishing step-size SGD on  J ( Œ∏ ) , using unbiased gradient estimates from the equilibrium distribution  D , the parameters  { Œ∏ k }  converge in expectation to a stationary point  Œ∏ ‚àó of  J ( Œ∏ ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "Observe that, as  Us. ¬¥as  is designed to handle dense and noisy data, it outperforms the respective state-of-the-arts (which were tuned for small, clean benchmark data). 903 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "The reason is that the active power threshold of  Pipelining  is much higher than that of  Sequential . As a result, fewer power cycles of Pipelining  are available than that of  Sequential . However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Sensors employ this best-response mechanism, continuously updating their participation decisions based on the evolving network state and the actions of other sensors. Over repeated iterations, under suitable conditions, this process converges to a Nash equilibrium where participation strategies are mutually optimal. Existence and Convergence of Equilibrium: \nTheorem 4.1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Vikram Sharma Mailthody, Zaid Qureshi, Weixin Liang, Ziyan Feng, Simon Garcia De Gonzalo, Youjie Li, Hubertus Franke, Jinjun Xiong, Jian Huang, and Wen-mei Hwu. Deepstore: In-storage acceleration for intelligent queries. In  Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Master-Worker Architecture : The master node handles the major tasks such as (i) concord model selection policy, (ii) request dispatch to workers VMs as asynchronous future tasks using  Python asyncio  library, and (iii) ensembling the pre- diction from the worker VMs. Also all VM speciÔ¨Åc metrics such as current_load, CPU utilization, etc. reside in the mas- ter node.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Once the current head orientation is received, the  EA  block Ô¨Årst compares it with the memoized  Comp 1  and  Comp 2 . In our  EA  design, the last two head orientations are  cached  in local SRAM ( Comp 1  and  Comp 2  in the  EA block) and their corresponding projection computation results are stored in DRAM ( P i ‚àí 2 buff   and  P i ‚àí 1 buff ). If a match is detected, then the corresponding  P i ‚àí 2 buff   or  P i ‚àí 2 buff   buffer address pointer is directly returned.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "Formal Definition of Task Fusion:  Let  Q  =  { q 1 , q 2 , . . When the energy required for executing multiple QuantaTasks exceeds the available energy budget, DynInfer employs  task fusion  to combine smaller tasks into larger atomic units that can be executed within the energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "5 dB (only  6 . ‚Ä¢  Our Intra-only:  this design emits out a compressed frame with  ‚âà 17%  of the original data size (including 19 %  of geometry and 81 %  of attribute) and provides PSNR values up to  48 . 2dB when compared to TMC13, due to the macro block-based approximation for the inter-frame compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "The underlying idea is to use spike counts to represent the data value. They propose intra-layer and inter-layer parallelism to support the training phase by reducing potential stalls. ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [ 8 ] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "3%  accuracy drop, then  21% more energy can be saved (amounting to  77%  energy reduction compared to the baseline). 10(b). A similar trend can also be observed in V2, as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2405.07518 , 2024. Sambanova sn40l: Scaling the ai memory wall with dataflow and composition of experts. [132] Joan Puigcerver, Carlos Riquelme Ruiz, Basil Mustafa, and Neil Houlsby.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Complex Compute on EH-WSNs:  To quantify the scope performing complex compute using EH-WSNs, we took hu- man activity recognition (HAR) as a workload 1 , and per- formed experiments on the MHEALTH data-set [9, 10] (see Section 5 for data-set details) using the DNNs proposed in [ 26 ,  60 ], an energy harvesting friendly DNN hardware accelerator [ 56 ] (to ensure that we are using the state of the art EH-WSN hardware) and recently proposed HAR- specific optimizations for EH systems [ 47 ]. Our analysis (see Figure 2a) shows that the state-of-the-art system still only finishes  ‚âà 58 . 7% of the inferences scheduled on a sensor.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 179,
    "augmented": false
  },
  {
    "text": "The DeepAREst [ 4 ] model was trained using  Keras  [ 22 ] and  Tensorflow , over 100 epochs with 2 layers, 32 neurons and a batch-size of 1. Model Cache : We keep track of the model selected for en- sembling on a per request constraint basis. The constraints are deÔ¨Åned as  <latency,accuracy>  pair.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Silicon inter- poser with tsvs (through silicon vias) and fine multilayer wiring. [152] Masahiro Sunohara, Takayuki Tokunaga, Takashi Kurihara, and Mitsutoshi Higashi. arXiv preprint arXiv:2403.07816 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Technical report, National Institute of Standards and Technol- ogy (NIST), 2023. Post-quantum cryptography migration: Nist sp 1800-38b preliminary draft. National Cybersecurity Center of Excellence (NCCoE).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Lattice-based cryptography. In  Post-quantum cryptography , pp. Daniele Micciancio and Oded Regev.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "C \nC \nC controlling circuit \nFig. 5. Lightweight ReRAM circuit design \npower ReRAM cells.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 21,
    "augmented": false
  },
  {
    "text": "2016. Towards Foveated Rendering for Gaze-Tracked Virtual Reality. ACM Trans.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "This observation motivates us to ask the question:  Do such similarities also exist in the PC streams? If so, can we leverage Morton code (containing location information) to capture such similarities as well? Spatial Locality in Attributes:  Towards exploring the attribute similarity within one frame, we partition a frame (whose points are Ô¨Årst sorted in Morton-code order) from the 8iVFB dataset [ 18 ] into  10 ,  10 2 ,  10 4   and  10 5   macro blocks , plot the CDF of the range for attribute delta ( Max red  ‚àí Min red ) within one segment/macro block in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "At equilibrium, sensors strike a balance between accurate data contribution and energy conservation, result- ing in a stable pattern of participation and SNR choices. Over time, this induces a stationary, albeit non-trivial, effec- tive data distribution  D . Learning Approach: Our approach diverges from classi- cal Learning paradigms.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Neurons with lower Shapley values are more likely to be dropped: \np i  = Œ¥ œï i  +  œµ where  Œ¥  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. |N| [ L ( S  ‚à™{ i } )  ‚àíL ( S )] \nwhere  N  is the set of all neurons,  S  is a subset of neurons not containing  i , and  L ( ¬∑ )  denotes the loss function. Define the dropout probability  p i  for neuron  i  based on its Shapley value.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "0 \n1 \n2 \n3 \n4 \n0 \n0.5 \n1 \n1.5 \nutil_aware exascale mixed paragon \nSLO Violations \nNormalized Cost \nCost SLO violations \n(a)  Workload-1: Berkeley Trace. We implement a load generator, which uses a \nWoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands J.R. Gunasekaran, et al. The scheduler will pick the right model combinations from the cache based on the application requirements.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Curran Associates, Inc., 2021. [141] Alexander Sergeev and Mike Del Balso. Horovod: fast and easy distributed deep learning in tensor- flow, 2018.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "[74] Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bam- ford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Energy Efficiency:  We measure the energy-consumption as total Energy consumed divided over total time. Xanadu  experiences a sudden rise in tail latency, with it being 100ms more than that of  Kraken , while using 96% more containers. This is due to  Xanadu ‚Äôs MLP misprediction and the resultant container over-provisioning.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Learning multiple layers of features from tiny images. https://www. cs.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 18,
    "augmented": false
  },
  {
    "text": "2 \nData Task Algorithm % CPU Utilization % DRAM Utilization 16 Core Xeon Peak Average All Encryptions RSA512 2.18 14.56 5.85 All Decryptions RSA512 3.45 17.2 6.12 \n3D PC Compression OctTree 26.78 78.2 32.54 Inflation OctTree 29.24 81.56 36.18 \nVideo \nCompression ZStd 24.7 62.54 24.5 Inflation ZStd 22.6 79.18 29.43 Compression H264 12.85 52.46 21.4 Inflation H264 14.2 69.46 26.18 All (un)RAID Unraid 11.25 29.4 19.24 Table 1: Resource utilization while running different algorithms under classical data archival pipeline for multiple data modalities in an AWS h1.4xlarge storage-optimized instance. Classically, video data is streamed simultaneously to compute and storage systems for various processing tasks, such as inference, exemplar selection, and storage, thereby increasing I/O bandwidth and system processing demands. This processing complexity necessitates substantial compute and memory resources, escalating power consumption \n1 Management and retrieval of data typically utilize a vector database like file-system, although this is beyond the scope of this discussion.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 292,
    "augmented": true
  },
  {
    "text": "11621‚Äì11631, 2020. Jie Cao, Zhiang Wu, Junjie Wu, and Wenjie Liu. Towards information-theoretic k-means clustering for image indexing.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Existing scheduling algorithms typically assume stable energy availability and do not account for the atomicity constraints imposed by intermittent power supply. Our scheduling approach uniquely integrates: 1. Real-time energy availability into scheduling decisions.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "‚Ä¢  CWIPC:  CWIPC takes about  4229 ms  (mainly for geometry compression as the attributes are directly entropy-encoded without any other efforts, as mentioned in Sec. VI-B ). ‚Ä¢  Our Intra-only:  The performance of above two tech- niques has two orders of gap with the  ‚âà 100 ms  real- time requirement [ 19 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "GrandSLAm: Guaranteeing SLAs for Jobs in Microservices Execution Frameworks. In  EuroSys . [35]  Kate Keahey, Jason Anderson, Zhuo Zhen, Pierre Riteau, Paul Ruth, Dan Stanzione, Mert Cevik, Jacob Colleran, Haryadi S. Gunawi, Cody Hammock, Joe Mambretti, Alexander Barnes, Fran√ßois Halbach, Alex Rocha, and Joe Stubbs.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "the kitti vision benchmark suite. Are we ready for autonomous driving? In  2012 IEEE conference on computer vision and pattern recognition , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "[28]  T. Huang and Y. Liu, ‚Äú3d point cloud geometry compression on deep learning,‚Äù in  Proceedings of the 27th ACM International Conference on Multimedia , 2019, p. 890‚Äì898. [29]  E. S. Jang, M. Preda, K. Mammou, A. M. Tourapis, J. Kim, D. B. Graziosi, S. Rhyu, and M. Budagavi, ‚ÄúVideo-based point-cloud-compression standard in mpeg: From evidence collection to committee draft [standards in a nutshell],‚Äù  IEEE Signal Processing Magazine , pp. 118‚Äì123, 2019.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "However, a single ap- plication can contain a mix of queries with varying latency demands. Therefore, queries with strict latency requirements can be scheduled on  serverless functions , if a VM with free resources is unavailable. To handle dynamic load variations, a load-monitor can be designed such that it constantly moni- tors different periods of static load and peak load.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "2 is invoked to decide how to process this frame (FI, PI, or SI). As one can see from Line  2  of this algorithm, if the frame has been labeled as ‚ÄúSkip‚Äù by Algo. 1, it can be safely bypassed.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "299 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "The scaling up via mil- \n893 \nAuthorized licensed use limited to: Penn State University. ¬¥as  lies in its battery-free operation, which aligns with the current global push for sustainable computing. Battery-Free Operation:  A key highlight of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "For scenarios with larger and predictable energy income, software-based backup and restore mechanisms can offer signiÔ¨Åcant beneÔ¨Åts, as the energy consumed for such operations is typically a small fraction of the overall energy income. Predictive actions for saving the system state can be easily taken. However, in situations with sporadic energy income, the hardware-assisted scheduling becomes paramount.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "ScaleFlux. ACM Transactions on Reconfigurable Technology and Systems (TRETS) , 15(2):1‚Äì29, 2022. Csd 2000. https://scaleflux.com/products/csd-2000/ , a.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "By effectively managing energy constraints and adapting to intermittent power conditions, NExUME enables more reliable and accurate monitoring in industrial environments where energy harvesting is a viable power solution. The improved performance of NExUME in this real-world application further validates its effectiveness and practical utility. While the margins may appear small, in industrial settings, even minor improvements in classification accuracy can have significant implications for predictive maintenance and operational efficiency.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Observe that, as  Us. We demonstrate this by testing the exemplar selection and the Œº ‚àí proÔ¨Åler with different modalities of data. Our workloads included Audio [ 23 ], [ 35 ](speech classiÔ¨Åcation), 3D Point Clouds [ 14 ], [ 24 ](object classiÔ¨Åcation) and Inertial Measure- ment Unit sensor data [ 9 ], [ 106 ](fault and activity detection).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "3) System Support for Exploiting Pixel and Computa- tion Similarities: State-of-the-art proposals such as Deep- Cache [8], and Euphrates [9] have explored the temporal similarity at runtime for DNN inference on video streams. Therefore, in Sec. V, we perform a detailed comparison of our work against these prior works.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "com/learning-center/solar-insolation-maps.html/#Map1 , (Accessed on 11/21/2022). [92] ‚ÄúSurveillance camera statistics: which cities have the most cctv \ncameras?‚Äù https://www.comparitech.com/vpn-privacy/the-worlds- most-surveilled-cities/ , (Accessed on 11/21/2022). [93] Synopsys, ‚ÄúDesign compiler,‚Äù https://www.synopsys.com/ implementation-and-signoff/rtl-synthesis-test/dc-ultra.html , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "In fact, we observe the \n3 We use ‚Äúprojection transformation‚Äù and ‚Äú 360 ¬∞ video projection‚Äù inter- changeably. 243 \nFig. Intuitively, if the inputs of the transformation computation do not change, the output of the transformation will also be same.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Transforma Insights. Iot & ai market forecasts. https://transformainsights.com/research/ tam/market , 2023.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Finally, the energy saving achieved by the  Inter-Intra-Holo  scheme is about 73%, meaning that it only consumes 27% of the baseline energy. To put the energy-efficiency of our designs into perspective, we compared their energy consumption against the state-of-the-art HORN-8 hardware accelerator [ 35 ]. Due to the unavailability of the hardware RTL, we estimated its energy consumption based on the published characterization numbers from the Jetson GPU plat- form with the ZCU102 FPGA[ 64 ] (which is similar to the HORN-8 prototype) [ 51 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "No token left behind: Reliable kv cache compression via importance-aware mixed precision quantization, 2024. [173] Yifan Yang, Joel S Emer, and Daniel Sanchez. Trapezoid: A versatile accelerator for dense and sparse matrix multiplications.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Google and kairos power nuclear energy agreement. https://blog.google/ outreach-initiatives/sustainability/google-kairos-power-nuclear-energy- agreement/ , 2024. Accessed: 2024-10-20.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "[33]  Eric Jonas, Johann Schleier-Smith, Vikram Sreekanti, Chia-Che Tsai, Anurag Khandelwal, Qifan Pu, Vaishaal Shankar, Joao Carreira, Karl Krauth, Neeraja Yadwadkar, et al . 2019. Cloud programming sim- plified: A berkeley view on serverless computing.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "of ICT-ROBOT, ThBT3 , vol. [4]  S. Ayukawa, N. Tokudome, S. Enokida, and T. Nishida, ‚ÄúTime- series lidar data superimposition for autonomous driving,‚Äù  Proc. 3, 2016.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "At a high level, we need two major inputs to generate the Ô¨Ånal projected frames on the display. The Ô¨Årst input is from the user side, including the head orientation and pupillary distance. Since there is a small offset between the two eyes, the projection computation needs to cap- ture the pupillary distance to generate a separate view for each eye.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "2020. \"https://github.com/google- research-datasets/Objectron/blob/master/index/shoe_annotations\". Objectron Dataset Annotation: shoe.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "[51] F. G. VR360, ‚ÄúVirtual guided tour of Paris.‚Äù ‚Äùhttps://www.youtube.com/ watch?v=sJxiPiAaB4k‚Äù, 2019. [50] A. Vlachos, ‚ÄúAdvanced VR Rendering in Valve.‚Äù ‚Äùhttp: //media.steampowered.com/apps/valve/2015/Alex Vlachos Advanced VR Rendering GDC2015.pdf‚Äù, 2019. 305‚Äì308.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Acknowledgments \nWe are indebted to our shepherd Manya Ghobadi, the anony- mous reviewers and Anup Sarma for their insightful com- ments to improve the clarity of the presentation. Special mention to Nachiappan Chidambaram N. for his intellec- tual contributions. This research was partially supported by NSF grants #1931531, #1955815, #1763681, #1908793, #1526750, #2116962, #2122155, #2028929 ,and we thank NSF Chameleon Cloud project CH-819640 for their generous compute grant.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "Thus, the existence of a Nash equilibrium follows directly from the finiteness of utilities, the monotonicity of  Œ¶ , and the impossibility of infinite improvement sequences. Existence of a Nash Equilibrium \nSince no infinite sequence of profitable unilateral deviations can occur, the best-response dynamics must terminate in a state where no sensor can unilaterally improve its utility. By definition, this state is a Nash equilibrium  a ‚àó ( t ) : \nU i ( a ‚àó i   ( t ) ,  a ‚àó ‚àí i ( t ))  ‚â• U i ( a i ( t ) ,  a ‚àó ‚àí i ( t )) ‚àÄ a i ( t ) ,  ‚àÄ i.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 191,
    "augmented": true
  },
  {
    "text": "The  EA  block is placed before the original compute engine (OCE, e.g., GPU) to opportunistically bypass the projection computation. However, when  AE  cannot take advantage of memoization due to a head orientation change, then the compute is distributed across the OCE ( 51% ) and  AE block ( 49% ); to be precise, only the entire coordinates on the left screen and the Ô¨Årst row on the right-screen are processed by the OCE ‚Äì the remaining rows on the right screen are reconstructed by the less power-hungry  AE  block. 7).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "7 ) ( 10 ‚àí i )   =  0 . Given all the other models have higher accuracy, the least accuracy we can expect with such an ensemble is 83%. 83 \nThis corresponds to an accuracy of 83%, which is greater than our required accuracy of 82%).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Cocktail is open-sourced at  https:// github.com/jashwantraj92/cocktail \n5.1 Cocktail Prototype Implementation \nCocktail  is implemented using 10KLOC of  Python . We de- signed  Cocktail  as a client-server architecture, where one master VM receives all the incoming requests which are sent to individual model worker VMs. Master-Worker Architecture : The master node handles the major tasks such as (i) concord model selection policy, (ii) request dispatch to workers VMs as asynchronous future tasks using  Python asyncio  library, and (iii) ensembling the pre- diction from the worker VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Fig. Due to the limited number of segments, one can observe that some highlighted blocks are not well matched. 3  c  illustrates an example with 20 segments in I-Frame and P-Frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "[37] Shihan Dou, Enyu Zhou, Yan Liu, Songyang Gao, Jun Zhao, Wei Shen, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, and Xuanjing Huang. The art of balancing: Revolutionizing mixture of experts for maintaining world knowledge in language model alignment. 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "URL  https://csrc.nist.gov/projects/ post-quantum-cryptography . Accessed: 2024-08-01. Samsung Newsroom.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "rel.gov/gis/solar-resource-maps.html , (Accessed on 11/21/2022). [65] NVIDIA T4 for Virtualization, ‚Äúhttp://bit.ly/3EÔ¨ÅuWg.‚Äù [66] I. of Energy Research, ‚ÄúThe environmental impact of lithium \nbatteries,‚Äù https://www.instituteforenergyresearch.org/renewable/the- environmental-impact-of-lithium-batteries/ , November 2020, (Accessed on 07/08/2023). [67] D. Patterson, J. Gonzalez, Q.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "IEEE, 2005. [14]  Eric Bauer and Ron Kohavi. An empirical comparison of voting classiÔ¨Åcation algorithms: Bagging, boosting, and variants.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Our experiments shows that DNN inference using  Origin , running on a harvested energy only system, is more accurate than energy-constraint- optimized DNNs, running on a fully-powered system. We believe that the co- optimization of deep learning and energy harvesting techniques for edge devices will further invigorate research on the next generations of intelligent and sustainable IoT platforms. Although the current work is limited to HAR, this can further be extended to many suitable tasks which need to leverage a distributed sensor system for DNN inference.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "To further capture the beneÔ¨Åts of the weighted autoscal- ing policy, Figure  12a  plots the number of VMs spawned over time for the top-3 most used models in the ensemble for  Const1 . The Bline denotes number of VMs that would be spawned without applying the weights. Not adopting an importance sampling based weighted policy would result in equivalent number of VMs as the Bline for all models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "We monitor the update frequency  F p  of each weight  w p  over a window of  T  iterations: \nF p  =  1 \nT \nT X \nt =1 U p ( t ) , U p ( t ) = \u001a 1 , if  w p  is updated at iteration  t 0 , otherwise (4) \nWeights with  F p  < Œ∏ low  are considered under-trained, and those with  F p  > Œ∏ high  are considered overfitting. We adjust dropout rates and apply L2 regularization accordingly to balance the training process. This adaptive strategy ensures that all weights are adequately trained despite the dynamic adjustments.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "¬¥as  hardware with other state of the art offerings for both performance and sustainability. D. Towards Other Applications and Domains \nThe morphable hardware design of  Us. ¬¥as  plays a crucial role in efÔ¨Åciently handling varying energy income and workloads.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "For example, a per- formance counter exposing data movement traffic in NoC can be used by runtime support to shuffle the expert to chiplet mappings. Additionally, the hardware can expose various performance counters to the software. Further, in some specific cases of unknown constraints, the software can indicate an expert to  migrate  to another chiplet.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "[85]  Vision Lab, Nanjing University, ‚ÄúMultiscale Point Cloud Geometry Compression,‚Äù  ‚Äùhttps://bit.ly/3xiAxah‚Äù , 2020. [86]  Z.-R. Wang, C.-G. Yang, and S.-L. Dai, ‚ÄúA fast compression framework based on 3d point cloud data for telepresence,‚Äù  Int. J. Autom.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "For example, an EoE consisting of GPU-affined experts can be mapped to a GPU-only chip, whereas an EoE consisting of varying chiplet affinities can be mapped to a suitable heterogeneous chip. For executing an EoE, we can explore various expert-to-chiplet mapping strategies such as one-to-one, one-to-many, many-to-one, and many-to-many, including EoE mapping to multiple chips. For example, smaller experts may be mapped to individual chiplets (or can be colocated in the same chiplet), while a large expert may be mapped to multiple chiplets.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "See our timeline (Figure 8) for time-span of the individual tasks. Hierarchy \nL1 $ \n2.4 KV Cache  Management \nCompression \nHardware-aware policies \nTailored Token  Eviction \nEnsuring Coherence \nThrust 4:  \nEvaluation &  \nFine Tuning \n2.5 Runtime  \nSupport \nSLO  Guarantee \nAccuracy \n2.6 Fault Tolerant  \nExpert Training \nIsolated  Training Redundancy \nCheckpoint /Recovery \nAlgorithmic Characteristics \nDynamic Re-routing \nCross-Layer Evaluation \n3.1 Expert/Hardware  \nCo-Characterization \nExperts Hardware \nProfile  Expert Execution Attribute Database \n3.2 Chiplet-based Modular  \nHardware Platform \n3.3 Reconfiguration 3.4 Hardware-Software  \nCo-Optimization \n4.1 Evaluation Infrastructure 4.2 Methodology \nExpert,  EoE Chiplet,  Chip Chiplet, Chip Reconfigure Chiplet,  Network \nMonitor & Control \nExposed Hardware Knobs \nPath Frequency \nAccelerator Availabililty \nExperiments on  Testbeds \nAnalytical Model \nSimulation \nTraining  Dataset \nMetrics of  Interest \n‚Ä¢ Latency ‚Ä¢ Power ‚Ä¢ Accuracy ‚Ä¢ Cost \nMemory  Constraints \nGPU \nCPU \nAccel \nAccel \nReconfig \nPlug-n-Play  \nChiplets \nExpert-to-Chiplet  \nMapping Homogeneous and  Heterogeneous Chips \nCustom  Interconnection  \nNetwork \nFigure 2 :  Overview of the proposed project. The included numbers indicate task IDs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 308,
    "augmented": true
  },
  {
    "text": "Table 4 gives an overview of Kraken ‚Äôs policies and their implementation details. 160 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nPolicy Component Implemented using/as \nPWS \nProbability System log info, Sparse Data Structures Commonality  &  Connectivity DAG Descriptor Load Predictor Pluggable model (EWMA) Batching Function containers persisted in memory \nRS Load Monitor Metrics from Prometheus & System logs Replica Tracker Table 4: Implementation details of  Kraken ‚Äôs policies. 5.2 Evaluation Methodology We evaluate the  Kraken  prototype on a 5 node  Kuber- netes  cluster with a dedicated manager node.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 189,
    "augmented": false
  },
  {
    "text": "We propose both software modiÔ¨Åcations for existing compute pipeline and microarchitectural additions for further enhancement. We evaluate our design by implementing the software enhancements on an NVIDIA Jetson TX2 GPU board and our microarchitectural additions on a Xilinx Zynq-7000 FPGA model using Ô¨Åve video workloads. Experimental results show that  D¬¥ej`a View  can provide  34%  computation reduction and  17%  energy saving, compared to the state-of-the-art design.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "Note that both the baselines are running on a fully powered system whereas  Origin runs entirely on harvested energy. In practice, we can extend Origin  further to other multi-sensor data-sets for HAR. Discussion:  Although  Origin  is proposed and works for energy harvesting wireless sensor networks, it can also be used with battery-powered or hybrid (a combination to battery powered and EH) systems to minimize the energy footprint while maximizing the accuracy.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1041 \nselection and procurement play a pivotal role in minimizing the latency and deployment costs. Further, the resource provi- sioning strategies employed in single model-serving systems are  not directly extendable  to ensemble systems. These shortcomings collectively motivate the central premise of this work:  how to solve the complex optimiza- tion problem of cost, accuracy and latency for an ensem- bling framework?",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "In  The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays , pp. 262‚Äì272, 2021. Sahand Salamat, Hui Zhang, Yang Seok Ki, and Tajana Rosing.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "0 \n2000 \n4000 \n6000 \nOracle Kraken \n# Containers \nNGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network. 0 \n4000 \n8000 \n12000 \nOracle Kraken \n# Containers \nNGINX ID Movie_ID Text User_Service Rating Compose_Review Movie_Review User_Review Review_Storage \n(b) Media Service. 0 \n2000 \n4000 \n6000 \nOracle Kraken \n# Containers \nNGINX Check_Reservation Get_Profiles Search Make_Reservation \n(c) Hotel Reserva- tion.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "IEEE Transactions on Knowledge and Data Engineering , 2023. Db-lsh 2.0: Locality-sensitive hashing with query-based dynamic bucketing. Yao Tian, Xi Zhao, and Xiaofang Zhou.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "De- spite this variation, there may still be matches/recomputations within a frame between two eyes, i.e., IntraFrame-InterEye as shown in  b  in Fig. 4. To leverage this opportunity, we next study the coordinate projection results relationship between left-eye and right-eye.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "4.1.1 Estimating function weights : Since workflows in SDAs are pre-determined, pre-deploying resources for them is straightforward in comparison to DDAs, whose workflow activation patterns are not known a priori. For DDAs, de- ploying containers for each function in proportion to the application load will inevitably lead to resource wastage. To address this, we design a Weight Estimator  2a  to assign weights to all functions so as to allocate resources in propor- tion to them.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "This optimizer allows for dynamic adjustments of dropout rates and quantization levels based on real-time energy availability, thus maintaining learning stability and improving model accuracy under power constraints. ‚Ä¢  DynInfer : An intermittency- and platform-aware task scheduler that optimizes computational tasks for intermittent power supply, ensuring consistent and reliable DNN operation. DynInfer leverages software-compiler-hardware co-design to manage and deploy tasks.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "5, pp. [43]  Marek Kowalski, Jacek Naruniec, ‚ÄúLiveScan3D-Hololens,‚Äù \n‚Äùhttps://github.com/MarekKowalski/LiveScan3D-Hololens‚Äù , 2020. 1217‚Äì1228, 2015.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "5a ) incorporates all the aforementioned points. Note that,  Us. ¬¥as  introduces a design philosophy for building a morphable hardware, and it can easily be adapted by any of the systolic array based commercial off the shelf (or research prototype) DNN training accelerators.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "To capture the current RoF, an additional eye track- ing step is introduced before the hologram computations, as shown in Fig. This eye tracking step takes the current IR sensor im- ages as its input, and analyzes the user‚Äôs current gaze area as well as \nAlgorithm 2:  Inter-Holo algorithm. 6b \na  .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "In order to increase the utilization of all instances in a pool at any given time, the load balancer submits every request from the queue to the lease remaining free slots (viz. instance packing factor P f  ). This is similar to an online bin-packing algorithm.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "3) How to Further Improve the Compression EfÔ¨Åciency for Attributes? :  Towards further improving the compression efÔ¨Åciency, one could consider different options. Instead of throwing more compute power, we want to emphasize that, the discussion in this section only focuses on the attribute locality within one frame, which has ignored the potential localities among consecutive frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Fig. 5:  Accuracy results of the different policies described in Sec- tion III. RR indicates the extended round-robin policy in use, e.g.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "Further, we also observed in Sec. III that, the main reason behind this is that the compute is executed repeatedly both within a single frame (due to offset between the eyes) and across frames (due to changes in head orientation at runtime). Unlike prior works targeting at optimizing the efÔ¨Åciency of  each computation  [28], [57], we primarily focus on reducing  the amount of computation to be performed, by exploring the intrinsic ‚Äúcompute reuse opportunities‚Äù in  360 ¬∞ VR video processing.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "power Input \nPV [41] \nInput 1@50 √ó 50 Conv1 8@6 √ó 6 √ó 1 36 √ó 8 752.2 ¬µ W 8@45 √ó 45 Conv2 12@3 √ó 3 √ó 8 72 √ó 12 1125.6 ¬µ W 12@20 √ó 20 Conv3 16@3 √ó 3 √ó 12 108 √ó 16 1526 ¬µ W 16@8 √ó 8 Conv4 10@3 √ó 3 √ó 16 144 √ó 10 1114 ¬µ W 10@6 √ó 6 Conv5 6@3 √ó 3 √ó 10 90 √ó 6 676.2 ¬µ W 6@4 √ó 4 \nFR [42] \nInput 1@32 √ó 32 Conv1 4@5 √ó 5 √ó 1 25 √ó 4 377.4 ¬µ W 4@28 √ó 28 Conv2 16@4 √ó 4 √ó 4 64 √ó 16 1433.6 ¬µ W 16@10 √ó 10 \nLeNet [43] \nInput 1@32 √ó 32 Conv1 6@5 √ó 5 √ó 1 25 √ó 6 539.7 ¬µ W 6@28 √ó 28 Conv2 16@5 √ó 5 √ó 6 150 √ó 16 1614.2 ¬µ W 16@10 √ó 10 \nHG [44] \nInput 1@28 √ó 28 Conv1 6@5 √ó 5 √ó 1 25 √ó 6 539.7 ¬µ W 6@24 √ó 24 Conv2 12@4 √ó 4 √ó 6 96 √ó 12 1176 ¬µ W 12@8 √ó 8 \nFor each application on each power trace, we report the throughput and energy efÔ¨Åciency under the Ô¨Åve different execution strategies. We then demonstrate the beneÔ¨Åts from the proposed smooth transition strategy and power prediction. We also study the sensitivity of our proposed approach to available ReRAM hardware resources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 420,
    "augmented": false
  },
  {
    "text": "Fi- nally, Section  ? Section  5  outlines the training and fine-tuning framework that integrates the equilibrium strategies into a federated learning paradigm. In Section  4 , we introduce the game-theoretic model of sensor participation, motivat- ing our approach against simpler heuristics and discussing why equilibrium solutions are desirable.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "[183] Yuanrui Zhang, Wei Ding, Mahmut Kandemir, Jun Liu, and Ohyoung Jang. A data layout optimiza- tion framework for nuca-based multicores. In  Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture , pages 489‚Äì500, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "118‚Äì123, 2019. [30]  Jeroen Baert, ‚ÄúMorton encoding/decoding through bit inter- leaving: Implementations,‚Äù  ‚Äùhttps://bit.ly/30Rf506‚Äù , 2013. [31]  T. Karras, ‚ÄúMaximizing parallelism in the construction of bvhs, octrees, and k-d trees,‚Äù in  Proceedings of the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics , 2012, p. 33‚Äì37.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "[2] W. Niu, X. Ma, S. Lin, S. Wang, X. Qian, X. Lin, Y. Wang, and B. Ren, ‚ÄúPatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-Based Weight Pruning,‚Äù in  Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , 2020, p. 907‚Äì922. [3] X. Ma, F.-M. Guo, W. Niu, X. Lin, J. Tang, K. Ma, B. Ren, and Y. Wang, ‚ÄúPCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for Real-time Execution on Mobile Devices,‚Äù  arXiv preprint arXiv:1909.05073 , pp. 5117‚Äì5124, 2019.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 212,
    "augmented": false
  },
  {
    "text": "Under equilibrium conditions, the distribution  D  is stationary or at least sta- tionary over sufficiently large timescales. The expected loss is L ( Œ∏ ) =  E ( x,y ) ‚àºD [ ‚Ñì ( f Œ∏ ( x ) , y )] . Let  D  denote the effective data distribution induced by the equilibrium strategies of the sensors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Datasets : We use three published video datasets (VIRAT [33], EPFL [42] and CAMPUS [43]), to study the performance and energy behavior across different videos. The important features of these six videos 4   are summarized in Table II. Neural Network Models:  We examine two DNN models in our experiments: YOLOv3 [44] and YOLOv4-tiny [37].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "[7]  Amazon. https://aws.amazon.com/sagemaker/, February 2018. Azure Low priority batch VMs., February 2018. https://docs.microsoft.com/en-us/azure/batch/batch-low-pri-vms .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Increasing Geometry Compression Parallelism Using Morton Code:  As mentioned earlier, the reason why the ‚Äúsequential update‚Äù is necessary is that, during the interme- diate stages, the  global  Octree (the Ô¨Ånal tree constructed at the last step) is unknown until the last point is inserted in the tree. To relax this constraint, if the PCs can be  sorted based on a geometrical order, then the topographic structure of the global tree can be known at the beginning, thus Ô¨Åxing the tree structure and not requiring to be updated in a point-by-point fashion. As a result, these points can processed in  parallel .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "3: Accuracy-latency comparison of different policies with differ- ent distributed setup. The edge execution is done on a raspberry Pi, and the cloud is mimicked by a desktop class machine. Considering the scale of the problem, the execution time on a desktop machine is almost same as a larger cluster that we typically find in a cloud.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "To give an example, we selected a segment of frames (i.e.,  Frame#6750  to  Frame#6850 ) from V1 [33], in which the objects move more aggressively than other segments. In this scenario, our scheme Ô¨Ågures out that more movements exist from large MV blocks, and dynam- ically adjusts the inference decisions. Hence, our scheme does not lose any accuracy, and still saves  43%  energy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "5.5). 2 BACKGROUND AND MOTIVATION \nBefore diving deep into the problems and possible solutions asso- ciated with holographic processing, we first present the hardware \n495 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \nand software pipelines of a typical holographic AR application (in Fig. 1).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "For consecutive sampling intervals, we calculate the  Mode  (most frequently occurring) of the majority vote received for every input. If the  Mode  is greater than needed votes  ‚åä N / 2 ‚åã +  1  we prune the models to  ‚åä N / 2 ‚åã + 1 . While down-scaling, we drop the models with the least prediction accuracy in that interval.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "[46] S. Lee, S. Goldt, and A. Saxe, ‚ÄúContinual learning in the teacher- \nstudent setup: Impact of task similarity,‚Äù in  International Conference on Machine Learning . PMLR, 2021, pp. 6351‚Äì6360.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "4 Œ≤  =  approxFactors (cam2ObjDists[obj]) \n5 Holograms[obj] = Algorithm1( 16  √ó  Œ≤ , obj) \n6 return  { Holo–¥rams } \nIn the  Inter-Holo  design, the hologram computation can be ap- proximated by identifying the region of focus from eye tracking. However, the scope of this approximation opportunity might be limited due to the strict 16 depth planes requirement for all objects inside the RoF, regardless of their distance from the user. In fact, there may still be another level of opportunity for approximating the objects in long distance ( Intra-Holo , shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "The objective of this paper is to maximize its energy efficiency without jeopardizing the hologram quality for AR applications. Towards this, we take the approach of analyzing the workloads to identify approximation op- portunities. We show that, by considering various parameters like region of interest and depth of view, we can approximate the ren- dering of the virtual object to minimize the amount of computation without affecting the user experience.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "To avoid this, in  Us. ¬¥as , the teacher models perform majority voting to decide the right exemplar, which signiÔ¨Åcantly reduces false positives and true negatives (refer to the top bar in Fig. The exemplar set signiÔ¨Åcantly impacts the accuracy in two ways: 1. missing valid exemplars will result in the student model missing out in learning vital information, increasing its drift, and 2. a wrong annotation by the teacher can also result in the student learning wrong labels, resulting in increased mis-predictions.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Real-time Generation of Fully Optimized Holograms for Optical Trapping Applications. In  Optical Trapping and Optical Micromanipulation VIII , Vol. 8097. International Society for Optics and Photonics, 80971H.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "ASV: Accelerated Stereo Vision System. In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 643‚Äì656.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "[56]  Jeffrey H. Shuhaiber. 2004. Augmented Reality in Surgery.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 20,
    "augmented": false
  },
  {
    "text": "Zhang and Kandemir have recently co-authored a paper in MICRO (2024) and all three PIs have co-authored a paper in NeurIPS (2021). Student Support : The project will support four PhD students for the proposed three-year duration of the project. The students will work on separate thrusts in the beginning (one student will be the primary contact for each thrust), but they will works together in the last year for integrating the different compo- nents of the research for a comprehensive evaluation and refinements of the proposed models, algorithms, compiler and system support.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "As a result, Frame-2 is critical as it reveals new information that has not been exposed before, and thus requires performing full inference for it. Algorithm 1:  Adaptive Frame Level Reuse Algo. In this case, although the MV is smaller than the bounding boxes, its position is on the edge, indicating that a new object is entering the frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Unlike simple heuristic meth- ods that ignore future resource allocation or complex ap- proaches like reinforcement learning that may be too costly to implement, game theory provides equilibrium guaran- tees. Sensors must carefully balance immediate accuracy gains against conserving energy for future tasks, while also antici- pating the behavior of other sensors that may be collaborat- ing or competing. To address these interdependent decisions, we employ a game-theoretic framework.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "general, robust and larger model (typically with hundreds of millions of parameters [ 43 ], [ 99 ]) helps in annotating the data. There has been a signiÔ¨Åcant body of work on frame similarity and saliency [ 45 ], [ 84 ], [ 101 ], [ 105 ], [ 107 ], [ 108 ], and those details remain beyond the scope of this work. However, because of the heavy compute requirements, the teacher model runs with a much slower frame rate and annotates only some (important) frames.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Coresets, primarily used in computational geometry [ 7 ], have been recently used [ 36 ,  37 ] for machine learning and sensor networks. Since coresets were designed to preserve the geometry of the data, we believe that they can be crafted to preserve features, and therefore be use- ful for performing accurate inference in subsequent stages, and thereby satisfying  2  . Furthermore, constructing core- sets do not need any application information, i.e.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "give more importance in choosing the data which are unique and, in our case, contribute significant to the inference (i.e. The intuition is that any importance sampling scheme produces an unbiased estimator [ 8 ]. having a high enough magnitude in the frequency response of the sensor signal).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "To further improve the compression efÔ¨Åciency, our second scheme, inter-frame compression, considers the temporal similarity among the video frames and reuses the attribute data from the previous frame for the current frame. We implement our designs on an NVIDIA Jetson AGX Xavier edge GPU board. Experimental results with six videos show that the combined compression schemes provide 34.0 √ó  speedup compared to a state-of-the-art scheme, with minimal impact on quality and compression ratio.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "In each case, the points/values in  red  are communicated to the host. Imp-sampling uses a probability based importance sampling; clustering preserves the geometric shape of the original data. 5 \nr2 \nr1 \nr4 \nr3 \nr5 \nOriginal Data Coreset with imp-sampling Coreset with Clustering \nFigure 4: A toy example of the coreset construction techniques in  Seeker .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "ACM Transactions on Embedded Computing Systems (TECS) , 20(5s):1‚Äì27, 2021. Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks. Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight. In the PRIME conÔ¨Åguration, the ReRAM-based Full Function (FF) subarrays have both computation and data storage capabilities. To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Extending this with  the point count for each cluster  allows for recon- struction of data in the original form that can be processed by DNNs trained on full-size data. These reconstructed data sets can be synthesized simply by uniformly distributing the points within each cluster. Although the intra-cluster data distribution will be different from the original, it will still preserve the overall geometry with a certain degree of approximation which the DNN could learn to accommodate.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "Further, the gap between the dotted red and green (1000 blocks) is smaller compared to that between the solid yellow and black lines (corresponding to a 20 block partitioning), thus indicating that a Ô¨Åner partition granularity can observe less variance in the temporal \n286 \nAuthorized licensed use limited to: Penn State University. ‚Ä¢  Considering the dotted lines with 1000 segments parti- tioned from I- and P- Frames, the green line represents the smallest delta between two segments, which indicates the upper-bound/the scope of the attribute similarity, whereas the red line represents the largest delta/the least similarity among the segments. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 166,
    "augmented": true
  },
  {
    "text": "[60] Suchin Gururangan, Margaret Li, Mike Lewis, Weijia Shi, Tim Althoff, Noah A Smith, and Luke Zettlemoyer. Scaling expert language models with unsupervised domain discovery. arXiv preprint arXiv:2303.14177 , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. -18.87 \n-9.14 \n-10.2 -11.35 \n-20 \n-15 \n-10 \n-5 \n0 \n0% 20% 40% 60% 80% 100% \nRapidly Varrying \nModerately \nstable \nRelatively \nStable \nFully Powered \nLoss in accuracy in % \nContribution of Policy \nExemplar Profiler Morphable No Optimization \n(a) Contribution of components on video data \n0 \n0.1 \n0.2 \n0.3 \n0.4 \n0.5 \n0.6 \nBest Average Best Average \nUsas iCARL Usas Optimus \n# Relative Exemplars # Relative Epoch \nRelative Error wrt Oracle  \n(Lower  is better) \n(Audio) Audio MNIST (Audio) CHiME Home (3D PC) KITTI Vision \n(3D PC) nuScenes (IMU) Bearing Fault (IMU) MHEALTH \n(b)  Us. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 225,
    "augmented": true
  },
  {
    "text": "However, only a fraction of these containers are actually spawned, as determined by the function‚Äôs batch size. The batch size denotes the number of requests per function each container can simultaneously serve without exceed- ing the SLO. In order to effectively handle mis-predictions in load,  Kraken  also employs a Reactive Scaler (RS)  7  that consists of two major components.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Thrust-3 examines architectural design space for efficient mapping of experts to hardware leading to a chiplet-based design consisting of a heterogeneous platform of compute engines such as CPUs, GPUs, and accelerators. This thrust will also in- vestigate the required mechanisms for minimizing data transfer overheads and the underlying interconnect architecture to facilitate reconfigurability and fault-tolerance. Finally, Thrust-4 is devoted to developing a comprehensive empirical evaluation platform consisting of a simulator and analytical tools to evaluate and validate our design in terms of performance, energy efficiency, and model accuracy.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Other settings are not changed (they remain the same as in the Intra-Inter-V1 version). C. Results \nWe Ô¨Årst compare the execution latency, energy con- sumption, quality (PSNR [peak signal-to-noise ratio]), and compression efÔ¨Åciency (compressed size) in Fig. 8 , when using various designs explained in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "5c, SLAT reduces the data communication volume up to  ‚âà 5 . 63 √ó  compared to the classical approaches, thereby saving bandwidth (reduces bandwidth by  ‚âà 36% , public cloud has strict regulations on measuring the actual bandwidth, and hence we report the approximate result from the traffic pattern) and energy. 0 \n1 \n2 \n3 \n4 \n5 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nNorm.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "2019. Appl. Progress in Virtual Reality and Augmented Reality Based on Holographic Display.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 19,
    "augmented": true
  },
  {
    "text": "5  shows an example of geometry compression. 1) How to Increase Parallelism? : Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "The chosen action profile is a ( t ) = ( a 1 ( t ) , . 18:  end for \nRestatement of the Utility Function and Assumptions \nRecall that at each inference event  t , each sensor  s i  chooses an action  a i ( t )  ‚àà{ P ,  NP } . Otherwise, continue refine- ment.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "The DeepAREst [ 4 ] model was trained using  Keras  [ 22 ] and  Tensorflow , over 100 epochs with 2 layers, 32 neurons and a batch-size of 1. The constraints are deÔ¨Åned as  <latency,accuracy>  pair. Model Cache : We keep track of the model selected for en- sembling on a per request constraint basis.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Both G-PCC and V-PCC are widely adopted in MPEG standard [ 53 ], and since our proposals begin with G-PCC, thus, is also compliant with the MPEG PCC standard. NN-PCC 2   takes the raw PC as input, and feeds it into a pretrained 3D CNN, which outputs the compressed PC stream [ 28 ], [ 82 ]. Several recent efforts have been put into optimizing the 3D CNN to increase the compression ratio and/or decrease the number of parameters in the neural network model [ 27 ], [ 69 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "We employ an alternating optimization strategy, iteratively optimizing subsets of variables while keeping others fixed. (3) \nFormulation of the Composite Optimization Problem:  The problem is non-convex due to the discrete nature of quantization levels and dropout rates. Our method differs from standard approaches by integrating energy constraints directly into the optimization, ensuring that the network learns to adapt its parameters based on energy availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "2020. OpenVINS: A Research Platform for Visual-Inertial Estimation. 2020 IEEE International Conference on Robotics and Automation (ICRA)  (2020), 4666‚Äì4672.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "2018. Adaptive deep learning model selection on embedded systems. ACM SIGPLAN Notices  53, 6 (2018), 31‚Äì43.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "We want to emphasize that our underlying ideas behind the proposed  EA  and  AE  (designed for the Equirectangular format) can work irrespective of the representation formats used [48]. For example, similar to the distance vector study in Fig. 6b and Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "To address these chal- lenges, we propose  Seeker , a hardware-software co-design approach for increasing on-sensor computation, reducing communication volume, and maximizing inference comple- tion, without violating the quality of service, in EH-WSNs co- ordinated by a mobile device. Moreover, these tasks often require responses from multiple physically distributed EH sensor nodes, which impose crucial system optimization challenges in addition to per-node constraints. However, the computation and power de- mands of Deep Neural Network (DNN)-based inference pose significant challenges in an energy-harvesting wireless sen- sor network (EH-WSN).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efÔ¨Åciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ]. In the remainder of the paper, we may shorten the term  ReRAM crossbars  to  ReRAMs . Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efÔ¨Åciently performing inference on an IoT device if it does not have either a high power or high stability power source.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 186,
    "augmented": false
  },
  {
    "text": "Framework Prototype:  To prototype a real-life AR headset, a proper codebase and a hardware platform are essential. For our codebase, we build our proposals on top of ILLIXR [ 19 ], which is the first open-source full-system extended reality testbed. IL- LIXR already contains several AR software components (some of them are shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "0 20 40 60 80 100 \n0 20 40 60 80 100 \nClass Distribution \nAccuracy (%) \nBaseline Train-Win-1 Train-Win-2 Train-Win-4 Appeared \nFig. Restrictions apply. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "However, data annotation or labeling is more challenging. Classically, once data is collected, it is classiÔ¨Åed, labeled, and bounded by borders (bounding box) mostly using manual labor (at times with software assistance) or crowd sourcing [ 33 ], [ 82 ], [ 88 ]. ¬¥as  is a continuous learning framework and learns from the live data that the camera(s) capture, data collection is simply storing the live video feed.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Github copilot. \" https://github.com/features/copilot \", 2024. [49] Mohammad Gokaslan, Girish Mishra, and Andrea Madotto.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "502 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 4413.87 4243.51 3190.25 3135.99 \n0 1000 2000 3000 4000 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. We see that, the number \n4 Due to space limitation, we chose six representative categories that cover diversity across multiple video parameters.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Input : Poses : pose sensors Input : Objs : set of virtual objects Output: Holo–¥rams : Generated holograms \n1  procedure  Intra _ Holo ( Poses ,  Objs ) // main \n2 Cam2ObjDists =  PoseEstimation ( Poses ) \n3 for  obj  in  Objs  do // approx. 4 Œ≤  =  approxFactors (cam2ObjDists[obj]) \n5 Holograms[obj] = Algorithm1( 16  √ó  Œ≤ , obj) \n6 return  { Holo–¥rams } \nIn the  Inter-Holo  design, the hologram computation can be ap- proximated by identifying the region of focus from eye tracking. based on dist.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 200,
    "augmented": true
  },
  {
    "text": "We implement our design in an edge GPU platform to demonstrate the real-world applicability of our research. Our experimental results show that, compared to the baseline,  HoloAR  achieves, on average, 2 . 7 √ó  speedup and 73% energy savings.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "These variations can cause misclassiÔ¨Åcations and the adaptive nature of the conÔ¨Ådence matrix mitigates this. 6:  Accuracy over time for different users: the conÔ¨Ådence matrix adapts to the behaviour and activity pattern of the user and learns over time to give stable if not better accuracy. 70 75 80 85 90 \n70 75 80 85 90 \nIter 1 Iter 10 Iter 100 Iter 1000 \nAccuracy % \nUser 1 User 2 User 3 Base Model Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "We will seek REU supplements to support the undergraduate students for working on this project. The investigators have a very good track record of advising under- graduate students (resulting in more than 20 undergraduate honors thesis), and they will continue to do so in this project as well. Project Timeline \nFigure 8 despicts a tentative projected timeline for the proposed work.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "[25]  A. K. Mishra and D. Marr, ‚ÄúWRPN & apprentice: Methods for training and inference using low-precision numerics,‚Äù  CoRR , vol. 1423‚Äì1428, 2018. abs/1803.00227, Apr 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Because of the LUT memoization and power ef- ficiency optimizations [ 35 ], HORN-8 saves around 48% power 5 . Due to the unavailability of the hardware RTL, we estimated its energy consumption based on the published characterization numbers from the Jetson GPU plat- form with the ZCU102 FPGA[ 64 ] (which is similar to the HORN-8 prototype) [ 51 ]. However, HORN-8 does not explore the approximation opportuni- ties to speedup the hologram execution.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "To correctly estimate accelerator power and area, we implemented a register-transfer level model using System Verilog and syn- thesized using Synopsys Design Compiler [ 93 ] with a 32nm library [ 94 ]. Further, the simulator was integrated with CACTI [ 62 ] and DRAMSIM3 [ 49 ] to estimate access latency, power, and simulate the memory access pattern. Rather than including a cycle accurate CPU (host) simulator to orchestrate the compute, we used a simple program to act as proxy for the host CPU and send control signals to schedule and orchestrate the compute on the systolic array.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 5687‚Äì5695, 2017. Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, and Hartwig Adam.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Abstract \nEnergy-harvesting wireless sensor networks (EH- WSNs) offer sustainable solutions for large-scale IoT deployments but face challenges due to the unreliability and intermittent availability of in- dividual sensors. We propose a comprehensive framework that integrates a game-theoretic partici- pation strategy with a federated learning approach tailored for EH-WSNs. Our game-theoretic model enables sensors to make optimal participation de- cisions based on energy levels, data quality, and collective inference impact, fostering cooperative behavior while managing individual energy con- straints.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "[2] ‚ÄúUse fall detection with apple watch,‚Äù 2020, https://support.apple.com/en- us/HT208944. A CKNOWLEDGMENTS This work was supported in part by Semiconductor Research Corporation (SRC), Center for Brain-inspired Computing (C- BRIC) and NSF Grant #1822923 (SPX: SOPHIA). R EFERENCES \n[1] ‚ÄúTaking an ecg with the ecg app on apple watch series 4 or later,‚Äù 2020, https://support.apple.com/en-us/HT208955.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "In networks of energy harvested sensors, the power-hungry nature of commu- nication results in intermittent coordination failures due to one or more of the sensors, or even the fusing node itself, lacking sufÔ¨Åcient energy at the time that inter-node communication is required. However, these node-level optimizations are not entirely sufÔ¨Åcient for sensor networks with multiple sensors collectively working together to achieve a goal, which are very common. Although fusing sensor data is not uncommon, it requires one central location where the inference can take place, requiring the communication of sensed data.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "To further minimize the impact of failures, we will investigate known fault-tolerance techniques from the distributed computing domain to support graceful degradation of training. A few techniques we plan to study include: i)  Exploiting Redundancy : Selectively training multiple experts on similar/over- lapping tasks (which are deemed critical to performance/accuracy) provides a fallback mechanism in case one of them fails. Here, the redundant experts should ideally be distributed across multiple nodes; ii) Isolated Training : In the event of changes to experts, our approach enables retraining by accounting for min- imum number of neighboring experts/routers; this will inherently facilitate fault tolerance, thereby allow- ing retraining of the EoE with minimum overhead in the event of expert failures; iii)  Checkpointing/Rollback Recovery : Techniques such as checkpointing weights/gradients periodically with rollback recovery in the event of expert failures can allow training to progress from the latest checkpoint (versus restarting the en- tire training); and finally, iv)  Dynamic Expert Re-routing:  In the event that an expert on one node fails, our system-level framework will communicate with the algorithm-level routers to dynamically decide which experts (on which node) should be used instead.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 296,
    "augmented": false
  },
  {
    "text": "2017. Markov chains: From Theory to Implementation and Experimentation . John Wiley & Sons.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 26,
    "augmented": true
  },
  {
    "text": "While larger models with more parameters may exhibit limited data drift due to their increased capacity to generalize, deploying such large models on edge compute nodes can be difÔ¨Åcult due to \ninherent limitations in form factor, energy efÔ¨Åciency, thermal constraints, and compute resources. To accommodate these constraints, it is a common practice to employ compressed Deep Neural Network (DNN) models, that are quantized, distilled, or otherwise reduced in size. Mitigating Data Drift:  Dealing with data drift in edge com- pute nodes presents a signiÔ¨Åcant challenge.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Figure 1 depicts the DAGs of three such applications from the  ùê∑ùëíùëéùë°‚ÑéùëÜùë°ùëéùëü benchmark suite [ 29 ], and Table 2 summarizes the various workflows that can be triggered by an incoming request to them. ‚ÄòTotal fan-out‚Äô and ‚ÄòMax Depth‚Äô denotes the total number of outgoing branches and maximum distance between the start function and any other function in a DAG, respectively. Note that each func- tion triggers only one other function in the application at a time.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Ziyu Ying, Shulin Zhao, Haibo Zhang, Cyan Subhra Mishra, Sandeepa Bhuyan, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. 2022.00031. Exploiting frame similarity for efficient inference on edge devices.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "(categorized by dotted lines) picked in the increasing order of accuracy. We use one constraint (blue dots) each from Ô¨Åve different regions \n1048    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \n0 \n100 \n200 \n300 \n400 \n70 75 80 85 \nLatency (ms) \nAccuracy (%) \nConst1     Const2       Const3   Const4  Const5 \nFigure 6:  Constraints used in our workloads. As an example for the  Imagenet  dataset shown in Figure  6 , each constraint is a representative of <latency, accuracy> com- bination offered by single models (shown in Table  1 ).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "Along with morphable hardware, the exemplar selection and the micro-proÔ¨Åler play an important role for the success of  Us. ¬¥as . When power is highly uncertain, the morphable hardware also strongly contributes, however, as the power proÔ¨Åle becomes stable, the algorithmic contributions dominate.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Mouse: Inference in non-volatile memory for energy harvesting applications. 400‚Äì414. In  2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "Although intermittency-aware NAS (Mendis et al., 2021), could alleviate certain problems, they often assume fixed resource constraints and do not account for real-time energy fluctuations. Moreover, existing works like Keep in Balance (Yen et al., 2023), Stateful Neural Networks (Yen et al., 2022), ePerceptive (Montanari et al., 2020), and Zygarde (Islam & Nirjon, 2019) address aspects of intermittent computing but do not integrate energy variability awareness directly into the training and inference processes to enable dynamic adaptation. This calls for revisiting the entire training process; we need to train the DNN in such a way that it is aware of the intermittency and adapts  to it.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 182,
    "augmented": false
  },
  {
    "text": "For example, PTU [28] uses a hardware-accelerated rendering unit (HAR) to mitigate energy- overheads due to on-device rendering. In this work, we pro- pose two optimizations, i.e.,  EA  and  AE , which can be coupled with the existing  360 ¬∞ video compute engine (without any hardware modiÔ¨Åcations), and are even more energy efÔ¨Åcient than the existing state-of-the-art  PTU  (discussed in Sec. V).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Table I shows the accuracy comparison between the RR12- Origin  with both the baselines. We observe that, for the MHEALTH dataset, RR12- Origin  is 2.72% more accu- rate than the Baseline-2. In case of abundant energy supply, one can use a round robin policy Ô¨Åt for the given EH source.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "9 in most cases and 0 . 6 in some of the worst cases (refer Figure 14 for an example). In rare cases (once in over 2000 cases), the generator induced arti- facts which could result in wrong classifications.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Although, multiple task-dedicated models are typically deployed to enhance accuracy and reduce sampling bias [ 70 ], particularly in scenarios like trafÔ¨Åc monitoring, where different time periods exhibit distinct trafÔ¨Åc patterns, they are not immune to data drift. The temporal locality of (video like) data has shown models to effectively learn from recent data. emerged as a preferred approach to mitigate data drift [ 20 ], [ 44 ], [ 50 ], [ 74 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Towards information-theoretic k-means clustering for image indexing. Signal Processing , 93(7):2026‚Äì2037, 2013. 18 \nWei Cao, Yang Liu, Zhushi Cheng, Ning Zheng, Wei Li, Wenjie Wu, Linqiang Ouyang, Peng Wang, Yijing Wang, Ray Kuan, et al.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "C. Hardware Implementation and Evaluation \nThe proposed morphable hardware was simulated using an in-house simulator based on ScaleSim [ 79 ]. We included a wrapper around ScaleSim to  dynamically  change the con- Ô¨Åguration of the systolic array. Further, the simulator was integrated with CACTI [ 62 ] and DRAMSIM3 [ 49 ] to estimate access latency, power, and simulate the memory access pattern.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Strict Relaxed 0 \n25 \n50 \n75 \n#VMs \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace. Figure 11:  Number of VMs spawned for all four schemes. 0 1000 2000 3000 Time interval (10s) \n0 \n50 \n100 \n#VMs \nBline model1 model2 model3 \n(a)  Cumulative #VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "5a, only the soccer ball  object is located inside the viewing window in the current frame,  Frame-I , while  football  and  box  are not. Thus, only the  soccer ball  hologram is required to be com- puted for this frame, and other two can be skipped. Similarly, for the next frame,  Frame-II , now the user lifts her head a bit, hence the corresponding viewing window changes from the previous one.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Fig. 8b  also shows the error rate of retraining performed by choosing the hyperparameters given by the micro-proÔ¨Åler vs an oracle selection. Observation over 40 hours of continuous learning on the dataset suggest that the micro-proÔ¨Åler has, on average, an accuracy deviation of 2 .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "The second trace is production twitter [ 48 ] trace which is bursty with unexpected load spikes. We use the Ô¨Årst 1 hour sample of both the traces and they are scaled to have an average request rate of 50 req/sec. Workload:  As shown in Table  5  we use image-classiÔ¨Åcation and Sentiment Analysis (text) applications with two datasets each for our evaluation.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Figure 2: Function-wise Breakdown of Container Provisioning across Applications. 98.10% \n98.55% \n99.00% \n99.45% \n99.90% \n0 \n200 \n400 \n600 \n800 \nCritical Non-Critical Critical Non-Critical Critical Non-Critical \nSocial Network Media Service Hotel Reservation \nPercentage \nResponse Time (ms) \nEnd-to-End Response Time SLO Guarantee \nFigure 3: Performance Deterioration resulting from Container De- ficiency at Critical Functions. The Primary Y-axis denotes the Av- erage End-to-End Response Time, the Secondary Y-axis represents the percentage of SLOs satisfied and the X-axis indicates the Appli- cation under consideration.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, it is equipped with a 512-core Volta GPU, a 8-core ARMv8 64-bit CPU, and 32GB 256- Bit LPDDR4x Memory. Methodology \n1) Evaluation Platform:  To evaluate and compare the proposed intra- and inter-compression designs with the state-of-the-art works, we use the NVIDIA Jetson AGX Xavier board [ 58 ], which is an edge development board, and is well-known to simulate the realistic edge development environment. A.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Restrictions apply. 27, p. 28, 2009. [62] N. Muralimanohar, R. Balasubramonian, and N. P. Jouppi, ‚ÄúCacti 6.0: \nA tool to model large caches,‚Äù  HP laboratories , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Fig. memoize  the feature maps of the middle part in the previous frame, and reuse the data for the current frame. 6: Partial-inference steps for Frame-3 in Scenario-1.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "The second component will be based on simulation. The first compo- nent of this framework will employ actual machine experiments on Argonne National Lab (ANL) machines (see the collaboration letter from ANL and our preliminary results [26]). These experiments will involve not only state-of-the-art GPUs but also hardware accelerators such as Groq [5], Cerebras [96], SambaNova [131], Habana Gaudi [87], and GraphCore [54] (all available on ANL machines).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "Note that these probabilities are not visible to  Kraken , but are only used to model function invocation patterns. We set the SLO at 1000ms. Metrics and Resource Management Policies:  We use the following metrics for evaluation: (i) average number of containers spawned, (ii) percentage of requests satisfy- ing the SLO (SLO guarantees), (iii) average application re- sponse times, (iv) end-to-end request latency percentiles, (v) container utilization, and (vi) cluster-wide energy sav- ings.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "0% \n20% \n40% \n60% \n80% \n(a) FI+SI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead \n(b) FI+SI exec. time \n0% \n20% \n40% \n60% \n80% \n(c) FI+SI+PI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead Partial \n(d) FI+SI+PI exec. time \nFig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "The end-to-end response time to send the image to a worker VM and get the prediction back, was dominated by about 300ms (at maximum) of payload transfer time. D Instance conÔ¨Åguration and Pricing \nInstance vCPUs Memory Price C5a.xlarge 4 8 GiB $0.154 C5a.2xlarge 8 16 GiB $0.308 C5a.4xlarge 16 32 GiB $0.616 C5a.8xlarge 32 64 GiB $1.232 \nTable 7:  ConÔ¨Åguration and Pricing for EC2 C5 instances. E CIFAR-100 and BERT Models \nTable  8  shows the different models available for image predic- tion, that are pretrained on Keras using  CIFAR-100  dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 169,
    "augmented": false
  },
  {
    "text": "The cost is normalized to reactive scaling scheme. Figure 8. Comparison of the resource procurement cost for two different traces using five different schemes.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "By exploring these key aspects, we envision developing a self-managed inference-serving system, which can provide for different diverse needs of applications by leveraging the \n0 50 100 150 200 250 300 350 \n20.00% \n40.00% \n60.00% \n80.00% \n100.00% \nMobileNet V1 \nMobileNEt V2 \nInception V3 \nResnet50 \nResNet50-V2 \nDenseNet-201 \nDenseNet-121 \nXxception \nNasNetMobile \nInceptionResnetV2 \nvgg16 NasNetLarge \nLatency (ms) \nAccuracy % \nTop1-Accuracy Latency \nFigure 1. ‚Ä¢  Bring in Tune : Based on the dynamically changing query arrivals over time, what is the right way to combine model diversity along with resource heterogeneity without com- promising the user-specified requirements? ‚Ä¢  Configuring Resources:  From the diverse options, how to right-size VMs and appropriately configure the serverless functions to efficiently cater to user specified cost, accuracy and latency constraint?",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 225,
    "augmented": true
  },
  {
    "text": "25] , where the classiÔ¨Åer is equally confused between all the classes. Therefore, a good metric for the conÔ¨Ådence would be the vari- ance of the output probability vector. The higher the variance the more conÔ¨Ådent is the classiÔ¨Åcation.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Experiments on waymo (Sun et al., 2020) dataset shows the PSNR of Salient Store  compared to the classical H264 and HEVC encoding pipeline in Fig. 8. While \n15 \nSalient Store  is consistently performing better than H264, HEVC thanks to it‚Äôs novel approach of fine grained computation at times outperforms our approach.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "3 Then for Frame-2, we obtain the its motion vectors from the codec (with a minimal overhead, as discussed in Sec. IV-A2). With such knowledge, for Frame-2, we can observe that the bounding box and the MVs mostly overlap (with an overlap ratio of 0.71 in the left case), which indicates that the objects have barely moved.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "For example, the total 168  Tiles  and one  IMA  element of the ISAAC architecture [ 3 ] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets. Furthermore, the hierarchy they adopt with multiple ReRAMs targets primarily high throughput, leading to high power consumption on the whole RCA. ‚Ä¢  The architecture-centric works [ 3 ], [ 4 ], [ 5 ] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "[8]  Charles Loop, Qin Cai, Sergio Orts Escolano, and Philip A Chou, ‚ÄúJPEG Pleno Database: Microsoft Voxelized Upper Bodies - A Voxelized Point Cloud Dataset,‚Äù  ‚Äùhttp://plenodb. 586‚Äì606. [7]  P. J. Besl and N. D. McKay, ‚ÄúMethod for registration of 3-d shapes,‚Äù in  Sensor fusion IV: control paradigms and data structures , 1992, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "compression (PCC) pipeline which is  fast  (within or close to real-time),  accurate  (with good quality), and  efÔ¨Åcient (with high compression ratio). The state-of-the-art PCC pipeline typically utilizes tree structures like  Octree  [ 63 ] or kd-tree  [ 62 ] for compression, and often, the tree construction becomes a bottleneck due to lack of parallelization. Moreover, the conventional PC typically stores the geometry, while a wide array of applications, especially the ones meant for content consumption, infotainment and gaming, need the attributes to be stored as well, hence making the compres- sion even more complex.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "As shown in Algorithm  2 , weights are determined by frequency in which a particular model is chosen for requests ( get_popularity ) with respect to other models in the ensemble. USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1047 \nThe weights are multiplied with the predicted load to scale instances  (launch_workers)  for every model pool. We name this as an importance sampling  6b  technique, because the model pools are scaled proportional to their popularity.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Furthermore,  Kraken  guarantees SLO requirements for up to 99.97% of requests. 2 Background and Motivation We start with providing an overview of serverless DAGs along with related work (Table 1) and discuss the challenges which motivate the need for  Kraken . 2.1 Serverless Function Chains (DAGs) Many applications are modeled as function chains and typically administered under strict SLOs (hundreds of mil- liseconds) [ 30 ].",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "ACM Meas. Proc. Thorough characterization and analysis of large transformer model training at-scale.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "382‚Äì394, 2020. Keni Qiu, Nicholas Jao, Mengying Zhao, Cyan Subhra Mishra, Gulsum Gudukbay, Sethu Jose, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Resirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent embedded processors.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Such an- alytics are critical for virtual/augmented reality, object recog- nition/detection for surveillance, commercial advertisement insertion/deletion, synopsis extraction, and video querying. Index Terms ‚ÄîMobile Computing, DNN Inference, Energy EfÔ¨Åcient, Video Analysis, Motion Vector, Object Detection \nI. I NTRODUCTION \nWhile video processing has become extremely popular on mobile devices, the next wave of emerging applications are likely to be those that analyze videos in a  faster  and  more efÔ¨Åcient  fashion, to provide sophisticated intelligence. Additionally, the experimental analysis indicates that our approach outperforms the state-of-the-art work with respect to accuracy and/or performance/energy savings.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "Ô¨Ånish training on the exemplars (described in ¬ß III-B ) as soon as possible and also reach the desired accuracy ‚Äì but to do this within the harvested budget. Prior works [ 34 ], [ 48 ], [ 68 ] suggest that selecting the right hyper-parameters (like batch size, learning rate, number of layers to train etc.) have a huge impact on the convergence and accuracy of the models.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Specifically,  Seeker  reaches 86.8% top-1 accuracy in com- parison to the 81.2% accuracy of the baseline system. 2 BACKGROUND AND MOTIVATION \nIn this section, we provide a background of the current state- of-the-art in performing sensing and computations on EH- WSNs. We also describe the challenges in enabling complex compute on such devices and the need for hardware-software co-design to enable specialized intermittent computing in EH-WSNs.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "This approach can be further refined by, for instance, adjusting the weights taking into account a) availability/proximity of appropriate compute to the nodes (data should ideally be present on nodes which can leverage well-suited accelerators with relative ease), and b) load balancing across nodes to prevent overburdening specific nodes (thus, avoiding performance interference). Task-2.2: Router Retraining As stated earlier, our morphable LLMs will function in a plug-and-play fashion in which we will introduce new experts into the current ensemble incrementally, drop unneeded experts from an ensemble, or replace existing experts with others. All these activities may require  retraining  the routers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "This is because, the Piezo  source is very weak and and the total completed number of inferences is quite small. Speculative action supported by power prediction can keep quite a few incomplete inferences to be completed in the next power cycle. This can also explain why the portions with the power source of  Thermal  are very small.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Given memory capacity constraints, we frame the problem as identifying sets of experts to train together such that the data reuse among the selected experts, in a training step, is maximized and the combined data and parameter requirements of the set fit within the available memory. For example, in Figure 4(a), assuming for simplicity that memory can hold at most three experts and three datasets, this locality-aware approach would perform training in three steps. D1 \nD2 \nD3 \nD4 \nD5 \nD6 \nD7 \nD8 \nE1 \nE2 \nE3 \nE4 \nE5 \nE6 \nE7 \nE8 \nStep-1: {E1, E5, E7} use {D1, D2, D5} \nStep-2: {E2, E3, E6} use {D3, D6, D7} \nStep-3: {E4, E8} use {D4, D8} \n(a) \n(b) \nFigure 4 :  Bipartite graph to perform data locality- aware expert training.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 213,
    "augmented": false
  },
  {
    "text": "8c-8d and Fig. 9c-9d show, i.e.,  55%  latency and  56%  energy saving in YOLOv3, and  61%  latency and  64% energy saving in YOLOv4-tiny. The reason why YOLOv4-tiny saves more is that the PI beneÔ¨Åts more in a ‚Äúshallow‚Äù model with a relatively larger room to skip.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "E DGE -C LOUD  P ARTITIONING  P OLICIES \nIn this section, we discuss the various policies to \nCloud  Server \nDeploy 1 \nDeploy 2 \nDeploy 3 \nDeploy n \nData_1 Data_2 Data_3 Data_n \nDevice_1 \nDevice_2 \nDevice_3 \nDevice_n \nData Shared \nRF_1 RF_2 RF_3 RF_n \nPeer connections for Policy 2 \n(a) Data Sharing Policies. Red arrows indicates peer-to-peer connections \nRandomly Sampled \nCloud  Server \nDeploy 1 \nDeploy 2 \nDeploy 3 \nDeploy n \nData_1 Data_2 Data_3 Data_n \nDevice_1 \nDevice_2 \nDevice_3 \nDevice_n \nRF_1 RF_2 RF_3 RF_n \nModel Shared \n(b) Privacy Aware Policy: models are randomly sampled \nFig. 1: Edge-cloud partitioning policies.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 208,
    "augmented": false
  },
  {
    "text": "This strategic equilibrium un- derpins both training and inference participation decisions, ensuring that the sensors most likely to improve the global \n1 \n055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071 072 073 074 075 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109 \nmodel‚Äîgiven their energy, data quality, and network condi- tions‚Äîare the ones that engage. To refine the global model parameters without incurring continuous on-edge training costs, we adopt a federated learning paradigm adapted to EH-WSNs. Rather than rely- ing on persistent, centralized updates or continuous feder- ated aggregation, we perform  periodic  or  equilibrium-driven fine-tuning rounds.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 243,
    "augmented": false
  },
  {
    "text": "[4]  Stephen A Benton and V Michael Bove Jr. 2008. Holographic Imaging . John Wiley & Sons.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "Also, a similar composition scheme is employed to organize the input, weight and output data. An intra-tile pipeline is formed to boost the dot-product throughput. The ISAAC architecture is composed of 16 tiles and each tile consists of 8 IMAs which includes 4 ReRAMs along with 4 sets of peripheral circuits.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Restrictions apply. optimizations such as compile-time instruction fusion for better parallelism, or provide additional architectural support for our proposal by investigating the hardware designs with respect to FPGA modules or customized ASICs, to optimize the bottleneck stage and make PCC on edge devices even faster/more efÔ¨Åcient (e.g.,  ‚âà 33 ms  for  30  f ps  display refresh rate). A CKNOWLEDGMENT \nWe thank the anonymous reviewers for their helpful feedback and suggestions towards improving the paper content.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "IEEE, 2020. [136] Reuters. Meta strikes geothermal energy deal with sage geosystems to power data centers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "1 as two ma- jor steps (more details on the depthmap hologram algorithm can be found elsewhere [ 4 ,  18 ,  55 ,  63 ]). 4a and Algo. As shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "This is because the twitter workload is bursty, thereby leading to intermittent over-provisioned VMs. 6.2 Key Sources of Improvements \nThe major improvements in terms of cost, latency, and accu- \nracy in  Cocktail  are explained below. For brevity in explana- tion, the results are averaged across Wiki and Twitter traces for strict workload.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Such a system is capable of both continuously collecting data and computing CNNs locally near data. ResiRCA allows an RCA to adapt to changing harvested energy and, with our co-designed scheduling approach, ResiSchedule, it can achieve very high throughput. To the best of our knowledge, this is the Ô¨Årst work that focuses on low power and reconÔ¨Ågurable RCA design from both the hardware and software angles targeting energy harvesting systems.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Unlike the prior octree-based works [ 56 ], [ 72 ] which mainly focus on the compression efÔ¨Åciency (i.e., attaining higher compression ratio and good quality simultaneously) with sequential updates and longer execution latency, in this work, we focus primarily on speeding up the PCC at the  edge and achieving the real-time target mentioned above without losing much quality or compression ratio. III-B  that Morton codes can reveal opportunities for both geometry similarity (owing to the fact that the Morton code itself is the reÔ¨Çection of the geometrical relationship between points) and attribute similarity (the RGB attributes of two adjacent points are more likely to be similar). A. Intra-frame Compression \nIn this subsection, we Ô¨Årst present the state-of-the-art intra- frame geometry and attribute compression techniques and discuss their inefÔ¨Åciencies.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 183,
    "augmented": true
  },
  {
    "text": ". Task fusion is formalized as finding a partition of  Q  into subsets Q 1 ,  Q 2 , . However, if   P \ni   E q i   > E b , we aim to fuse tasks to minimize checkpointing overhead.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "[118] NVIDIA. Nvidia‚Äôs deep learning data parallelism strategies for high-performance training, 2021. [119] Nvidia.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "2) Motion Vectors:  The motion vector (MV), which is built upon pixel differences, can be a good candidate to capture the reusability in video analytics. A MV is a 2-D vector that provides an offset from the coordinates in the decoded frame to the coordinates in a reference frame [34], which can be directly obtained from the codec [35] without any post-processing. As opposed to the software-based ‚Äúoptical Ô¨Çow‚Äù solution widely used in the computer vision domain [36], collecting the MV from the  codec hardware  is quite light-weight.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "The  ùê∂ùëúùëõùëõ procedure in Algorithm 1 makes use of this formula. For ex- ample, in Figure 1c, the  Connectivity  of  ùê∂‚Ñéùëíùëêùëò _ ùëÖùëíùë†ùëíùëüùë£ùëéùë°ùëñùëúùëõ is   2 \n5   since it has two descendants and there is a total of five functions. Bringing  Connectivity  into the weight estimation process helps  Kraken  assign a higher weight to critical func- tions, in turn, ensuring that more containers are assigned to them, resulting in improved response times for the functions themselves, as well as their descendants.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Yang, Y.-H. Chen, and V. Sze, ‚ÄúDesigning energy-efÔ¨Åcient convo- \nlutional neural networks using energy-aware pruning,‚Äù in  Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 5687‚Äì5695. [103] T.-J.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "2018. [65]  Ben Taylor, Vicent Sanz Marco, Willy Wolff, Yehia Elkhatib, and Zheng Wang. IEEE.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "2.4. Federated Learning in Resource-Constrained Environments \nFederated learning enables multiple devices to collabora- tively train a global model without sharing raw data, pre- serving privacy and reducing communication overhead ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Philipp M. Grulich and Faisal Nawab. Collaborative edge and cloud neural networks for real-time video processing. Proc.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "wikipedia.org/wiki/AMOLED‚Äù, 2019. [55] Wikipedia, ‚ÄúVirtual Reality.‚Äù ‚Äùhttps://en.wikipedia.org/wiki/Peak signal-to-noise ratio#: ‚àº :targetText=Typical \\ %20values%20for% 20the%20PSNR,20 \\ %20dB%20to%2025%20dB.‚Äù, 2019. [56] B.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "In this example, eventually the coeffs vector contains  [ 2 , 0 , 89 ] , which can be further compressed by entropy encoding. This entire pipeline also requires sequential processing across the octree layers, which is obviously time-consuming when the number of points is large and the octree is deep. In fact, our proÔ¨Åling shows that RAHT takes around 2 seconds to process a typical frame with around 1M points, on a typical edge device.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "A deep dive into 7 th   iteration reveals that the micro-proÔ¨Åler chose a higher learning rate (compared to the oracle), which biased the convergence curve Ô¨Åtting and extrapolation (as discussed in ¬ß III-C ) and hence suggested a larger number of layers to be trained to achieve the required convergence. Note that the hyperparameter selected in iteration 7 by the micro- proÔ¨Åler performs as good as the the oracle model in terms of achieving accuracy, albeit by performing more computation. Over 10 training iterations, we observed the micro-proÔ¨Åler to be con- sistent with the oracle (except for one case of iteration 7).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "2020. \"https://github.com/ google-research-datasets/Objectron/blob/master/index/laptop_annotations\". [43]  Objectron.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "HoloLens 2 Tech Specs. \"https://www.microsoft.com/en- us/p/holoLens-2/91pnzzznzwcp/?activetab=pivot:techspecstab\". [32]  Microsoft Research Blog.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "IV-B3, the FI-output (the neighbors of the partial inference outputs ‚Äì pink color) from the previous frame is critical to maintain the accuracy of the output for the current frame. Thus, the full inference outputs are accordingly padded around the partial inference outputs via memory copy (Step  5  ). Next, as discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "With the help of DynFit, DynInfer provides  6% ‚Äì 22%  accuracy improvements with  ‚â§ 5%  additional compute over existing methods. DynInfer leverages software-compiler-hardware co-design to manage and deploy tasks. ‚Ä¢  Dataset : A first-of-its-kind machine status monitoring dataset, involving multiple types of EH sensors mounted at various locations on a Bridgeport machine to monitor its activity status, facilitating research in predictive maintenance and Industry 4.0 applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Each expert can also grow to absorb new knowledge and shrink to discard obsolete knowledge. Domain-Based Expert Splitting and Merging. We propose a novel and efficient approach for continual learning of EoE.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "06% of the time. B. Impact on Exemplar Selection \nUs.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 15,
    "augmented": false
  },
  {
    "text": "[67]  Rambabu Vatti, Nagarjuna Vatti, K Mahender, Prasanna Lakshmi Vatti, and B Krishnaveni. 2020. Solar energy harvesting for smart farming using nanomaterial and machine learning.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs. 5)Powerandlatencymodels:Theaboveanalysiscaptures thepowerconsumptionandexecutionlatencyofprocessing oneconvolutionlayer .Itisassumedthatallofthesesteps areperformedinsequence.Puttingthemalltogether,for convolutionlayerLk,thepowerandlatencypaircanbemodeled asinEquation2and3. P LK  =(P ld √ó Lat ld Lk   +P comp √ó Lat comp Lk \n+P st √ó Lat st Lk   +P merge  √ó Lat merge Lk )/Lat Lk (2) \nLat LK  = Lat ld Lk   + Lat comp Lk + Lat st Lk   + Lat merge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC ‚â• 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 328,
    "augmented": false
  },
  {
    "text": "Arduino nano 33 ble sense with headers. Arduino. https://store-usa.arduino.cc/products/ arduino-nano-33-ble-sense-with-headers , 2024.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "298 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "While down-scaling, we drop the models with the least prediction accuracy in that interval. If there is a tie, we drop the model with least packing factor ( P f  ). It can so happen that dropping models can lead to drop in accuracy for certain intervals, because the class of images being predicted are different.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Experimental Platforms and Datasets \nEvaluation Platforms:  The  Baseline  GPU platform described in Fig. 8 consists of a 512-core Volta GPU, a 4Kp60 HEVC \n249 \ncodec, 16GB LPDDR4x memory, 32GB eMMC storage, and a power management unit (PMU) that exposes the real-time power traces to users. To evaluate our design implementation in hardware, we use an FPGA platform, which is the same as the state-of-the-art PTU [28], with a 100MHz system clock, onboard conÔ¨Åguration circuitry, 2x16MB Quad SPI Flash, 1GB DDR2 Component Memory, and also a hardware PMU.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "C.1.2 Function Definitions \n‚Ä¢  SAVE_STATE : Saves the current indices and the partial result of the output matrix  C  to non-volatile memory to allow recovery after a power interruption. ‚Ä¢  LOAD_STATE : Retrieves the last saved indices and partial result from non-volatile memory to resume computation. 15 \nC.1.3 Loop Tiling \nThe algorithm uses loop tiling to divide the computation into smaller blocks that can be managed between power interruptions.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "John Wiley & Sons. [29]  Yu Gan, Yanqi Zhang, Dailun Cheng, Ankitha Shetty, Priyal Rathi, Nayan Katarki, Ariana Bruno, Justin Hu, Brian Ritchken, Brendon Jackson, et al . 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "[79]  M. A. S. Teixeira, H. B. Santos, A. S. d. Oliveira, L. V. Arruda, and F. Neves, ‚ÄúRobots perception through 3d point cloud sensors,‚Äù in  Robot Operating System (ROS) . Springer, 2017, pp. 525‚Äì561.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Exploring Extended Reality with ILLIXR: A new Playground for Architecture Research. arXiv:cs.DC/2004.04643 \n505 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \n[20]  IFIXIT. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Therefore, the overhead introduced due to the additional pose estimation step is negligible compared to the baseline latency, thereby opening up opportunities for significant energy savings and performance speedup as demonstrated later in Sec. 5. With the help of the pose estimation, now the AR hologram pipeline has the knowledge about the range/size of each object as well as its relative distance from the user.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Combined with specialized hardware support, quantization can reduce the amount of computation, memory footprint, and energy consumption. Note that these compres- sion and pruning approaches can be performed at compile time, and they typically need Ô¨Åne-tuning to retain accuracy. 3) System Support for Exploiting Pixel and Computa- tion Similarities: State-of-the-art proposals such as Deep- Cache [8], and Euphrates [9] have explored the temporal similarity at runtime for DNN inference on video streams.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Over-provisioning of  util_aware  and  exascale , nor- malized to a baseline  reactive  scheme for four traces. 2.3 Over-provisioning VMs \nReal-world request arrivals rates are usually not constant as they significantly vary over time (e.g. diurnal, flash-crowds etc.)",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "The idea is to use the sensitivity to determine the probability: \np i  = Œ≤   P \nj ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \nmax \u0010P \nj ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \u0011 +  œµ \nwhere  Œ≤  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. The sensitivity of each weight W ij  is calculated using the second-order Taylor expansion of the loss function  L : \n‚àÜ L ‚âà 1 \n2 \nX \ni,j \n‚àÇ 2 L ‚àÇW   2 ij ( W ij ) 2 \nwhere ‚àÇ 2 L ‚àÇW   2 ij   is the second-order derivative (Hessian) of the loss with respect to the weights. Define the dropout probability  p i  for neuron  i  based on the sensitivity of its corresponding weights.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 218,
    "augmented": true
  },
  {
    "text": "¬¥as  is a continuous learning framework and learns from the live data that the camera(s) capture, data collection is simply storing the live video feed. However, data annotation or labeling is more challenging. Classically, once data is collected, it is classiÔ¨Åed, labeled, and bounded by borders (bounding box) mostly using manual labor (at times with software assistance) or crowd sourcing [ 33 ], [ 82 ], [ 88 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "In  Proceedings of 10th International Workshop on Accelerating Analytics and Data Management Systems (ADMS‚Äô19) , 2019. Jianyu Chen, Maurice Daverveldt, and Zaid Al-Ars. Fpga acceleration of zstd compression algorithm.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Accessed: 2024-10- 18. [30] Bill Dally. Directions in deep learning hardware.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "5c). In fact, there may still be another level of opportunity for approximating the objects in long distance ( Intra-Holo , shown in Fig. To lever- age this opportunity, we need to know where the user is located in the world and what the objects in the world look like [ 13 ,  19 ,  53 ,  59 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "[5]  L. Song, X. Qian, H. Li, and Y. Chen, ‚ÄúPipelayer: A pipelined ReRAM- Based accelerator for deep learning,‚Äù in  2017 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pp. 541‚Äì552, 2017. 27‚Äì39, 2016.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "In  Imaging and Applied Optics Congress . Optical Society of America, HF3G.1. [19]  Muhammad Huzaifa, Rishi Desai, Samuel Grayson, Xutao Jiang, Ying Jing, Jae Lee, Fang Lu, Yihan Pang, Joseph Ravichandran, Finn Sinclair, Boyuan Tian, Hengzhi Yuan, Jeffrey Zhang, and Sarita V. Adve.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "The higher the variance the more conÔ¨Ådent is the classiÔ¨Åcation. Towards this, we build a lookup table by averaging the variance of output vectors of multiple test cases. This table, which we call the  conÔ¨Ådence matrix , gives us the conÔ¨Ådence of each sensor for each class, and can be used as a weight for majority voting.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "The distance of this feature vector from the other cluster center is called ‚ÄúclassiÔ¨Åcation loss‚Äù [ 74 ], and this re-triggers clustering with an updated number of clusters. Over multiple time windows, the representation learner goes through all the possible exemplars selected by using the conÔ¨Ådence matrix and creates an exemplar set with same number of examples from each possible class. Since we have multiple teacher models, each of them contributes to the exemplar set, making it robust and removing bias.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Better refers to the improvement over iNAS+PT baseline. B Details on Energy Harvesting \nA typical energy harvesting (EH) setup captures and converts environmental energy into usable electrical power, which can then support various electronic devices. Here‚Äôs a simplified breakdown of the process: \n1.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Abstract The growing popularity of microservices has led to the pro- liferation of online cloud service-based applications, which are typically modelled as Directed Acyclic Graphs (DAGs) comprising of tens to hundreds of microservices. The vast majority of these applications are user-facing, and hence, have stringent SLO requirements. Serverless functions, hav- ing short resource provisioning times and instant scalability, are suitable candidates for developing such latency-critical applications.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "The next step is to decode the original frame from the bitstream, and today, this is mostly done using a hardware- based h264/MPEG decoder for more energy efÔ¨Åciency. After decoding, the  360 ¬∞ output frames are then buffered in the video buffer, waiting to be rendered. Projection:  Note that, the output frames from the decoder are still in the  spherical coordinate system .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM \naccelerated MACs. Moreover, we allow parallelism along different dimensions to seamlessly integrate it with loop tiling, and as a result, a range of scalable computations that can Ô¨Åt in different power supplies are achieved. With this design idea, the system can keep making forward progress over a large range of power incomes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "For example, in  Frame-I  in Fig. 5b, the user is currently focusing on the  soccer ball ; mean- while the  football  is located outside of the RoF, hence, becomes a candidate for approximation. However, for the objects outside of the current RoF, since the user is not cur- rently focusing on them, a reasonable approximation would not affect the user experience that much (which implies we do not need 16 depth planes for all of them).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "18, pp. 6869‚Äì6898, Jan. 2017. [33]  M. Courbariaux, Y. Bengio, and J.-P. David, ‚ÄúBinaryconnect: Training deep neural networks with binary weights during propagations,‚Äù in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 , NIPS‚Äô15, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "eural networks (DNNs). However, DNNs are quite compute- intensive and generate very large memory footprints [1]. Furthermore, running inference for videos on edge devices is even more expensive than images due to the data volume and the power/energy constraints.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "[56]  Zhenyu Lu, Xindong Wu, Xingquan Zhu, and Josh Bongard. arXiv preprint arXiv:1907.11692 , 2019. Ensemble pruning via individual contribution ordering.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "classes of images. These 11 models are a representative set to classify all images belonging to 1000 classes in  Imagenet. Depending on the application type, the maximum ensemble size can vary from tens to hundreds of models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Typically, there is an inverse correlation of the convergence of the stochastic gradient descent (SGD) algorithm, the most popular training algorithm for DNNs, over the number of iterations ( n i ) [ 68 ]: l  ‚àù O ( 1 / n i )  and  l  = 1 Œ≤ 0 . Furthermore, we allow some slack to the weighted accuracy so that the optimizer can choose a better set of hyperparameters if we can reach  close to  the weighted accuracy with much lower resource (power or compute) consumption. Observing this, we propose a ‚Äúweighted accuracy metric‚Äù, where the weight of each of the model is a function of the accuracy, time needed and power availability.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "Existence and Convergence of Equilibrium: \nTheorem 4.1. Suppose that each utility function  U i ( t )  is non-decreasing in  ‚àÜ A i ( t ) , that energy constraints and dis- counting ensure diminishing marginal returns for repeated deviations, and that sensors have consistent estimation of ‚àÜ A i ( t )  and   ÀÜ E i ( t  + 1) . Then, the iterative best-response updates described in Algorithm  1  converge to a Nash equi- librium action profile  a ‚àó ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Finally,  ‚ù∏ Visual  stage combines the physical world with the virtual information (which is generated in real-time) together, and renders the final images (both the physical scene as well as the virtual frame augmented with it) for the user to view. We want to emphasize that, compared to virtual reality (VR), the AR video processing typically incurs additional computational \nTable 1: Ideal latency requirements [19]. With these inputs,  ‚ù∑ Perception  stage understands the current surrounding environment such as pose estimation for head rotations/directions, eye tracking for pupil centers, and scene reconstruction for the current view analysis.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "We consider this design as the  state-of-the-art . However, PTU  only optimizes the energy per compute through accel- eration, with exactly the ‚Äúsame amount of computations‚Äù as in the baseline design. In contrast, as explained earlier in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Furthermore, we also present a qualitative com- parison on the maintenance cycle needed for these solutions. ¬¥as  is objectively Ô¨Ånishing more tasks (except compared to a system with a consistently high power availability). It is clear that even with intermittent power availability  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Figure 7: Slack for various Functions in each Application. offline profiling and  StageSLO (f)  is allotted in proportion to it. The batch size represents the number of requests that can be served by a function without violating the allotted stage-wise SLO.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": ". , a N ( t )) . The immediate reward for sensor  s i  is defined as: \nR i ( t ) = \nÔ£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ \nÔ£¥ Ô£¥ Ô£¥ Ô£≥ \nŒ≥  ¬∑  ‚àÜ A i ( t ) , if  a i ( t ) =  P and inference is correct , \n‚àí Œ¥, if  a i ( t ) =  P and inference is incorrect , \n‚àí Œ∑, if  a i ( t ) =  NP .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Hence, the projection transformation computation has to be executed at every frame to reÔ¨Çect user movements in real-time, and the whole process is very compute intensive (36 times per second [3]) and power hungry. The VR headset allows users to freely move their heads and eyes at any time to any degree. It is to be noted that, when a user‚Äôs head orientation is changed, the Projection Computation stage needs to  recompute the transformations to reÔ¨Çect the user‚Äôs head movement.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "\"https://github.com/google- research-datasets/Objectron/blob/master/index/cup_annotations\". [42]  Objectron. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Initialize the loop iteration parameters  l . Compute the activations  a  and apply the dropout mask: \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output. Calculate the gradients of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the reconstruction error of the feature maps: \np i  = Œ≥  RE i max( RE ) +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 358,
    "augmented": false
  },
  {
    "text": "Pyramidinfer: Pyramid kv cache compression for high-throughput llm inference, 2024. [172] June Yong Yang, Byeongwook Kim, Jeongin Bae, Beomseok Kwon, Gunho Park, Eunho Yang, Se Jung Kwon, and Dongsoo Lee. No token left behind: Reliable kv cache compression via importance-aware mixed precision quantization, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "D√©j√† view: Spatio-temporal compute reuse for‚Äò energy- efficient 360¬∞ vr video streaming. In  2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA) , pp. Shulin Zhao, Haibo Zhang, Sandeepa Bhuyan, Cyan Subhra Mishra, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Targeting them, prior efforts have proposed to optimize their compression ratio, processing performance, and energy efficiency [ 8 ‚Äì 10 ,  16 ,  27 ,  67 ‚Äì 70 ]. For example, ASV lever- ages characteristics unique to stereo vision and proposes algorith- mic and computational optimizations to improve performance and energy-efficiency of ‚Äúdepth from stereo‚Äù [ 11 ]. Tigris proposes an algorithm-architecture co-design system specialized for point cloud registration, to improve real-time performance and energy effi- ciency for 3D perception applications [ 65 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Coresets, primarily used in computational geometry [ 7 ], have been recently used [ 36 ,  37 ] for machine learning and sensor networks. Furthermore, constructing core- sets do not need any application information, i.e. Since coresets were designed to preserve the geometry of the data, we believe that they can be crafted to preserve features, and therefore be use- ful for performing accurate inference in subsequent stages, and thereby satisfying  2  .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Further, we also observed in Sec. 2.2, holographic processing dominates the la- tency and energy consumption in the AR video pipeline. 4 PROPOSED STRATEGIES \nAs discussed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "While the works relying on loop-decomposition or task partition (e.g., see (Qiu et al., 2020; Gobieski et al., 2019) and the references therein) ensure ‚Äúforward progress‚Äù, they do not guarantee an inference completion while meeting SLOs. One major issue is, most of the works leverage ‚Äúpre-existing‚Äù DNNs, which are typically designed for running on a stable resource environment, while being deployed on an intermittent environment with pseudo notion of stability via check-pointing, and therefore, one direction of works (Mendis et al., 2021) looks for performing network architecture search for intermittent devices. Optimizing DNNs for the energy constraints (Yang et al., 2018, 2017), or performing early exit and depth-first slicing (Lv & Xu, 2022; Islam & Nirjon, 2019) does ensure more forward progress, but such approaches compromise accuracy while often imposing scheduling overheads and higher memory footprint.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 228,
    "augmented": true
  },
  {
    "text": "165 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. All product names used here are for identification purposes only and may be trademarks of their respective companies. References \n[1]  [n.d.].",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Adaptive mixtures of local experts. Neural computation , 3(1):79‚Äì87, 1991. [70] Rishabh Jain, Vivek M Bhasi, Adwait Jog, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, with the Morton codes for all the points (i.e., the intermediate results from geometry compression without any additional overhead), we Ô¨Årst sort these points in the Morton code order, and then segment these sorted points into several blocks which can help to gather the points with similar positions/coordinates into one segment. ‚Ä¢  Mid + Residual:  Within each segment, since the points are located in small regions, their attribute values tend to have similar numbers. Therefore, instead of recording the exact attribute values for all the points within a segment, we only need to Ô¨Ånd the ‚Äú median value ‚Äù of these attributes (as base) and then compute and compress the  residual values (as deltas) for these points.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "[58]  Julian Steil, Inken Hagestedt, Michael Xuelin Huang, and Andreas Bulling. 2019. Privacy-Aware Eye Tracking Using Differential Privacy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "2.4. Federated Learning in Resource-Constrained Environments \nFederated learning enables multiple devices to collabora- tively train a global model without sharing raw data, pre- serving privacy and reducing communication overhead ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "(c) Viewing S-CGH from different focal distances. Focal distance from left to right:  0.3m ,  0.4m ,  0.5m , and  0.6m \nFigure 9: A demo of viewing/rendering the virtual planet whole-hologram (W-CGH, generated from all of the depth planes, i.e., from  1-st  to  16-th ) or sub-hologram (S-CGH, generated from only a subset of the depth planes, from 9-th  to  12-th  in this case) with different configurations. (a): Viewing the W-CGH from different eye-center positions.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "75 ms  latency to execute, which is less than 1% of the total hologram processing time. Therefore, the overhead introduced due to the additional pose estimation step is negligible compared to the baseline latency, thereby opening up opportunities for significant energy savings and performance speedup as demonstrated later in Sec. Our profiling on the edge GPU prototype [ 36 ] shows that Kimera-VIO takes, on av- erage, 13 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "The display controller just needs to read them from DRAM to the screen. To summarize, compared to 2D video processing,  360 ¬∞ video processing incurs additional projection computation. Display:  After the projection, the two generated FoV frames are stored in 2D format in the video buffer.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "{ MegaScale } : Scaling large language model training to more than 10,000  { GPUs } . In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pages 745‚Äì760, 2024. [76] Norm Jouppi, George Kurian, Sheng Li, Peter Ma, Rahul Nagarajan, Lifeng Nai, Nishant Patil, Suvinay Subramanian, Andy Swing, Brian Towles, Clifford Young, Xiang Zhou, Zongwei Zhou, and David A Patterson.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Finally, Thrust-4 is devoted to developing a comprehensive empirical evaluation platform consisting of a simulator and analytical tools to evaluate and validate our design in terms of performance, energy efficiency, and model accuracy. The concept of an ‚Äúensemble‚Äù serves as a foundational element, uniting our diverse research thrusts: a comprehensive set of models, a suite of accelerators, and an array of simulation and evaluation frameworks. Our modular, plug-and-play based approach not only allows for targeted research within individual elements of the en- semble, but also supports contributions from the broader research community.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four  25  √ó  6  ReRAM crossbars, each can be mapped to six kernels, all sized  5 √ó 5 √ó 1 . In the default case, the RCA works under an either ON or OFF mode with a power threshold of 80 ¬µ W . During the eight harvested power cycles, the ReRAM can be ON during power cycles  PC3, PC6  and  PC7  and OFF with the other Ô¨Åve power cycles.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "However, it is too conservative to execute the projection transformation in a short period of time even for the same set of inputs. Intuitively, if the inputs of the transformation computation do not change, the output of the transformation will also be same. Hence, the projection transformation computation has to be executed at every frame to reÔ¨Çect user movements in real-time, and the whole process is very compute intensive (36 times per second [3]) and power hungry.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "The tail latency (measured at P99) for  DProb almost exceeds the SLO, whereas it does so for  SProb . Figure 13: Real System: Normalized Energy Consumption of all Schemes and Response Time Distribution of  Kraken ,  Comm Only and  Conn Only achieve this. 0 \n300 \n600 \n900 \n1200 \n0.25 0.5 0.75 0.98 0.99 \nLatency (ms) \nCDF Kraken Comm Only \nConn Only SLO \n(b) Response Time Distribution.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "We illustrate the details of depthmap hologram processing in Fig. 4a and Algo. 3 HOLOGRAPHIC PROCESSING STUDY \nTo leverage the opportunities in the holographic processing from a RGB-D (i.e., RGB and depth) image, we need to first understand the detailed execution of the entire hologram processing from both the algorithm and hardware perspectives.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "2. Motion Estimation: Utilize dedicated hardware blocks for calculating motion vectors between consecutive frames. This step can leverage FPGA‚Äôs DSP slices for fast cross-correlation or block matching algorithms.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Note that the power predictors used in prior works are meant for Ô¨Åckle energy harvesting scenarios like piezoelectric (movement), or RF (WiFi). We have adjusted the time window size. We took a history (years 2019 and 2020; from Seattle, WA; Sterling, VA; and Oak Ridge, TN) of solar energy traces from SOLRAD [ 25 ], [ 91 ] and built a weight matrix which looks into a window of 1 hour at 1 minute (average power) intervals to predict the power for next 10 minutes (1 minute granularity).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "\"https://medium.com/demagsign/meet-the-humans- of-the-future-holograms-digital-humans-and-deep-fakes-35024b881545\". Meet the Humans of the Future: Holograms, Digital Humans, and Deep Fakes. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "5 , the octree constructed based on the Morton codes is slightly different from the one generated by the sequential algorithm (which is lossless). In fact, in our octree, the  P 0  node now contains geometry information of  [ ‚àí 0 . 43 , 0 , 0 ]  (-0.43=-1+1/7 √ó 4), which is slightly different from the original  [ 0 , 0 , 0 ] , whereas the other two points,  P 1  and  P 2 , are exactly same as the original ones.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "0 \n20 \n40 \n60 \n80 \nV1 V2 V3 V4 V5 Avg. 10: Sensitivity study. PSNR (dB) \n-10 \n-5 \n0 \n5 \n10 \n1 224 447 670 893 1116 1339 1562 1785 2008 2231 2454 2677 2900 3123 3346 3569 3792 \nDistance \nPixel ID \nDelta-y Delta-x \n(a): PSNR (b): Pattern in CubeMap format \nFig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Though reactive policies (used in Clipper and InFaas) can be employed which take into account metrics like CPU utilization [ 83 ], these policies are slow to react when there is dynamism in request rates. Proactive policies with request prediction are know to have superior performance [ 86 ] and can co-exist with reactive policies. In  Cocktail , we use a load prediction model that can accurately forecast the anticipated load for a given time interval.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "GeoInformatica , 20:59‚Äì94, 2016. Haibo Zhang, Prasanna Venkatesh Rengasamy, Shulin Zhao, Nachiappan Chidambaram Nachiappan, Anand Sivasubramaniam, Mahmut T. Kandemir, Ravi Iyer, and Chita R. Das. Race-to-sleep + content caching + display caching: a recipe for energy-efficient video streaming on handhelds.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Storage controllers, typically constrained by I/O bandwidth, are now being complemented by the vast internal bandwidth of solid-state drives (SSDs), making them prime candi- dates for near-data processing. Recent advances in both commercial (Newsroom; AMD, b; Mesnier, 2022; ScaleFlux, a,b; Eideticom & Laboratory; Laboratory) and academic sectors (Torabzadehkashi et al., 2019b; Barbalace & Do, 2021; Lukken & Trivedi, 2021; Torabzadehkashi et al., 2019a; Sala- mat et al., 2021, 2022; Do et al., 2013) advocate the use of computational storage drives (CSDs) across databases, high-performance computing (HPC), and analytics. AMD and Xilinx have intro- duced specialized tools and libraries designed to harness CSDs (AMD, a; AMD & Xilinx), enabling peer-to-peer PCIe transactions that bypass the CPU (AMD & Xilinx).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 264,
    "augmented": false
  },
  {
    "text": "This model balances anticipated energy availability, local data quality, and global benefit to establish stable and cooperative equilibria, opti- mizing the energy-accuracy trade-offs. ‚Ä¢  Federated Learning Integration:  We introduce a fed- erated learning-based framework tailored for intermittent participation and heterogeneous data quality. Unlike con- tinuous on-edge training, we employ periodic or triggered fine-tuning sessions aligned with equilibrium strategies, en- suring robust and progressively improving global models.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "[200] Yazhou Zu, Alireza Ghaffarkhah, Hoang-Vu Dang, Brian Towles, Steven Hand, Safeen Huda, Adekunle Bello, Alexander Kolbasov, Arash Rezaei, Dayou Du, Steve Lacy, Hang Wang, Aaron Wis- ner, Chris Lewis, and Henri Bahini. Association for Computational Linguistics, 2015. In  Proceedings of the 2015 Conference on Em- pirical Methods in Natural Language Processing (EMNLP) , pages 58‚Äì68.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "The former one is a quite heavy model, with 106 layers and 65.86 Bn FLOPS, whereas the latter one is a lighter model, with 38 layers and 6.94 Bn FLOPS. YOLOv3 achieves 55.3 %  mAP on average, whereas YOLOv4-tiny achieves 40.2 %  [45] mAP. C. Results \nWe present and compare the execution latency and energy consumption (via BatteryManager API in Android Studio) when performing inference for each video under the three conÔ¨Ågurations described in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "RaÔ¨Åki [ 80 ] considers small model sets and scales up and down the ensemble size by trading off accuracy to match throughput demands. Although our heterogeneous instance procurement policy has some similarities with MArk, it is signiÔ¨Åcantly different because we consider ensemble models. However,  Cocktail‚Äôs  resource management is more adaptive to changing request loads and does not drop accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Task-2.4: KV Cache Management Key-Value (KV) caches in LLMs store past activations to  accelerate  inference by avoiding redundant com- putations [7, 35, 43, 73, 99, 146, 148, 163, 167, 168, 171, 172, 188, 189, 193]. In large models with billions of parameters, and close to a million context length [27, 124, 149], the KV cache size could grow to hundreds of gigabytes needing careful management. In our EoE , two unique KV cache challenges arise: i) Loading experts and their KV caches onto GPUs for a user can cause high latency and memory consumption due to the initial ‚Äúprefill‚Äù stage, leading to a  cold start  problem.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 189,
    "augmented": false
  },
  {
    "text": "5, pp. 46, no. [42]  M. Liu, ‚ÄúRobotic online path planning on point cloud,‚Äù  IEEE transactions on cybernetics , vol.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "A low output variance of the estimator means the predicted values are tightly concentrated, i.e., different estimators, even after learning different features, give similar answers. The bootstrapping strategy makes each estimator learn different features of the data set and therefore increases the generality of the whole model. In this case, variance of the estimators becomes a good indicator of prediction confidence.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Restrictions apply. approach and are neither conÔ¨Ågured nor capable of operating with an intermittent power source. Deploying sufÔ¨Åcient battery resources to allow intermittency-unaware designs to operate on solar power is neither efÔ¨Åcient nor sustainable.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 11th ACM Symposium on Cloud Computing . 311‚Äì327. [47]  Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R. Das.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "7, pp. 1‚Äì4, 2013. [15]  V. Leonov, T. Torfs, P. Fiorini, and C. Van Hoof, ‚ÄúThermoelectric converters of human warmth for self-powered wireless sensor nodes,‚Äù IEEE Sensors Journal , vol.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Depending on the available energy, the task (vector inner product) can be divided into multiple iterations such that each QuantaTask is guaranteed to finish given the energy availability. Figure 1 illustrates QuantaTask execution with a simple example. A3 B3 \nB2 \nB1 \nX X X \nA2 \nA1 \nX \nFigure 1: An example of variable QuantaTask in a matrix multiplication scenario.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "2.5 Challenges with  serverless functions \nApart from arrival rates, memory allocation to  serverless functions  play a non-trivial role in terms of cost. In our exper- iments we configure the memory allocation to the lambda function such that individual query latency is within the user-specified latency constraint. Observation 4:  It is important to note that, the request arrival pattern plays a key role in determining if mixed procurement can be cost effective.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Directions in deep learning hardware. YouTube, 2024. Available at:  https://youtu.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2404.05567 , 2024. [127] Dongkook Park, Chrysostomos Nicopoulos, Jongman Kim, Narayanan Vijaykrishnan, and Chita R Das. Exploring fault-tolerant network-on-chip architectures.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "2.2.3 What are the Potential Opportunities? Towards addressing this hologram bottleneck, various ap- proaches from both the software [ 33 ,  52 ,  54 ] and hardware [ 32 ,  35 ] sides have been proposed. These prior approaches either incorpo- rate additional memory for maintaining a lookup table for compu- tation reduction, or build an application-specific integrated circuit (ASIC) chip specifically for holographic processing, which is more power-efficient than generic processors.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "The deployment costs differ based on the provisioning times and longevity of the resource pro- cured. Typically, these inference serving systems are hosted using Virtual Machines (VMs), which take a few minutes to start-up. Due to high start-up latencies, using VMs for hosting ML services can lead to over-provisioning, espe- cially during periods of poor workload predictability (flash crowds) [ 10 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Battery-Free Operation:  A key highlight of  Us. ¬¥as  introduces several novel contributions in the domain of  sustainable  continuous learning at edge servers using harvested energy, setting it apart from prior works examining on-edge learning. Our Approach (and its Novelty):  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "¬¥as  uses two kinds of scheduling policies to handle the graceful  powerdown  and work queue rearrangement. Note that the power-up sequence for a tile runs in the exact opposite order of the  powerdown  sequence (a tile becomes computationally active 512 cycles after it gets the power up signal). Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "0 20 40 60 80 100 \nWalking Climbing Cycling Running Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 CAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baselin-2 Baseline-1 \n(b)  Accuracy with PAMAP2 dataset. Fig. Instead of restricting the power constraint to the average power of the entire power trace, the constraint can be relaxed to the average power requirement of the extended round-robin \n0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 AAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baseline-2 Baseline 1 \n(a)  Accuracy with MHEALTH dataset.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 231,
    "augmented": true
  },
  {
    "text": "D.2 Optimal Brain Damage Dropout with QuantaTask Optimization \nOptimal Brain Damage Dropout leverages a simplified version of the Optimal Brain Damage pruning method to adjust dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Mathematical Formulation:  Let  W  be the weight matrix of a layer. The sensitivity of each weight W ij  is calculated using the second-order Taylor expansion of the loss function  L : \n‚àÜ L ‚âà 1 \n2 \nX \ni,j \n‚àÇ 2 L ‚àÇW   2 ij ( W ij ) 2 \nwhere ‚àÇ 2 L ‚àÇW   2 ij   is the second-order derivative (Hessian) of the loss with respect to the weights.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "1. These stalls originate mainly from the inter-block and intra- block synchronizations required by the application, as discussed above when explaining Algo. Second, the four major reasons for instruction stalls in the  Forward-Propagation  step are: Data Request (21%), Execu- tion Dependency (19%), Instruction Fetch (15%), and Sync (10%), whereas in the  Backward-Propagation  step they are Read-only Loads (42%), Sync (24%), Data Request (16%), and Execution Dependency (6%).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "16 MHz MCU with 64KB FRAM, 2KB SRAM, AES, 12-bit ADC, comparator, DMA, \n14 \nUART/SPI/I2C, timer. https://www.ti.com/product/MSP430FR5969. [67]  Rambabu Vatti, Nagarjuna Vatti, K Mahender, Prasanna Lakshmi Vatti, and B Krishnaveni.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Unlike the work presented in this paper, none of the four prior schemes mentioned in Table I performs well in all features listed in the table. While one may hypothesize that a new software-hardware co-design may be a panacea for numerous applications, video analytics at the edge is not necessarily in this category. Edge devices are often equipped with mature and robust video and vision pipelines, including sophisticated hardware like the codecs, which the current video analytics pipeline is yet to fully exploit.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Here, we summarize the research directly related to our proposal under the following areas: Algorithms and Models:  LLMs are known for their vast parameter sizes and training datasets, with a com- \nmon belief that larger LLMs yield better performance [64]. This claim is supported by research showing the positive impact of increasing model and dataset size on accuracy [66,92]. Prior works have contributed towards reducing the parameter count and the compute complexity through model pruning [63, 98, 198], knowledge distillation [55,93,113], quantization [22,46,95] along with mixture of experts (MoE) [69], includ- ing dense MoE [37,117,126,166], sparse MoE [42,74,89,145], soft MoE [111,132,178,194], and composition of experts (CoE) [59, 131, 196, 197].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 205,
    "augmented": false
  },
  {
    "text": "[17] L. Liu, H. Li, and M. Gruteser, ‚ÄúEdge Assisted Real-Time Object Detection for Mobile Augmented Reality,‚Äù in  Proceedings of the An- nual International Conference on Mobile Computing and Networking (MobiCom) , 2019. [18] H. Jiang, A. Sarma, J. Ryoo, J. B. Kotra, M. Arunachalam, C. R. Das, and M. T. Kandemir, ‚ÄúA learning-guided hierarchical approach for biomedical image segmentation,‚Äù in  2018 31st IEEE International System-on-Chip Conference (SOCC) , 2018, pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "IEEE, 2017. Yihua Cheng, Ziyi Zhang, Hanchen Li, Anton Arapin, Yue Zhang, Qizheng Zhang, Yuhan Liu, Kuntai Du, Xu Zhang, Francis Y Yan, et al. { GRACE } : { Loss-Resilient }{ Real-Time }  video through neural codecs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "23 \nShulin Zhao, Haibo Zhang, Cyan Subhra Mishra, Sandeepa Bhuyan, Ziyu Ying, Mahmut Taylan Kandemir, Anand Sivasubramaniam, and Chita Das. Holoar: On-the-fly optimization of 3d holo- graphic processing for augmented reality. In  MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture , MICRO ‚Äô21, pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "[67]  Rambabu Vatti, Nagarjuna Vatti, K Mahender, Prasanna Lakshmi Vatti, and B Krishnaveni. 16 MHz MCU with 64KB FRAM, 2KB SRAM, AES, 12-bit ADC, comparator, DMA, \n14 \nUART/SPI/I2C, timer. https://www.ti.com/product/MSP430FR5969.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. TABLE IV: Comparison against Potluck and MCDNN \nmAP Latency Energy MCDNN 36.9% 33% 35% Potluck 51.6% 63% 61% This Work 50.3% 35% 34% in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "The algorithm operates as follows: \nAlgorithm 1  Distributed Best-Response Participation Algo- rithm \n1:  Input: Current energies  B i ( t ) , predicted harvest ÀÜ E i ( t  + 1) , parameters  Œ≥, Œ¥, Œ∑, Œ≤ , and energy costs e cap ( ¬∑ ) , e inf , e comm . 2:  At each inference event: 3:  Each sensor  s i  receives a solicitation from the lead sensor and forms an estimate of  ‚àÜ A i ( t )  given potential SNR choices and expected actions of others. 4:  For each action candidate  a i ( t )  ‚àà{ P ,  NP } , the sensor computes the expected utility: \nU   a i ( t ) i =  E [ R i ( t )]  ‚àí E [ e i ( t )]  ‚àí Œ≤ E [ V i ( t  + 1)] , \nwhere the expectations are taken over uncertainties in correctness, SNR impact, and future energy.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 261,
    "augmented": false
  },
  {
    "text": "ACM SIGARCH computer architecture news , 38(3):106‚Äì116, 2010. [32] Sarkar Snigdha Sarathi Das, Arzoo Katiyar, Rebecca Passonneau, and Rui Zhang. CONTaiNER: Few- shot named entity recognition via contrastive learning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "During the eight harvested power cycles, the ReRAM can be ON during power cycles  PC3, PC6  and  PC7  and OFF with the other Ô¨Åve power cycles. However, even when the system goes through the three power cycles, only some portion of the harvested power is consumed. As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efÔ¨Åciency under stable, high-power scenarios.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "[33] A. Mazumdar, T. Moreau, S. Kim, M. Cowan, A. Alaghi, L. Ceze, M. Oskin, and V. Sathe, ‚ÄúExploring Computation-communication Trade- offs in Camera Systems,‚Äù in  2017 IEEE International Symposium on Workload Characterization (IISWC) , 2017, pp. 1545‚Äì1553, 2018. 177‚Äì186.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "In  International conference on machine learn- ing , pages 18332‚Äì18346. PMLR, 2022. Deepspeed-moe: Advancing mixture-of-experts inference and training to power next-generation ai scale.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "As training parameters, we provide some statistical parameters (specifically mean and variance) \n7 \nof the signal and random noise to the generator, and the generator generates the lost signals. The discriminator tries to discriminate between the actual data and the synthesized data. Towards this, we designed and trained a generative adversarial network (GAN, see Figure 7b for the structural details) to recover the lost samples of the importance sampling.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Note that most prior works ignore memory and host overheads while reporting the throughput, efÔ¨Åciency and power numbers. Note that the energy inefÔ¨Åciency arises primarily from i) multiple saves and restores, ii) use of NV memories \nand iii) reconÔ¨Åguring the DRAM (along with a commercial ARM based host CPU). Moreover,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "This paper presents the  ResiRCA  architecture that integrates a new, lightweight, and conÔ¨Ågurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node. They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes. ReRAM crossbar-based accelera- tors (RCAs) are an ideal candidate to perform the dominant multiplication-and-accumulation (MAC) operations in CNNs ef- Ô¨Åciently, but conventional, performance-oriented RCAs, while energy-efÔ¨Åcient, are power hungry and ill-optimized for the intermittent and unstable power supply of energy-harvesting IoT nodes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 186,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Quantization:  Finally, these small residual values are quantized to further improve the compression ratio. B. Intra-Frame Geometry Compression \nIn above section, we have discussed our overall proposals for both geometry and attribute compression pipelines. And, as will be shown later in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "When the traversal completes, an  Adder Tree  will be used to merge the partial sums for ReRAM columns and obtain the Ô¨Ånal MAC result. We use parallelism granularity  G  to denote the duplication count as deÔ¨Åned in [ 5 ]. 2) Computation parallelism: Intra-layer parallelism  means overlapping the layer computations on duplicated copies of ReRAMs that store the same weights for one layer.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "517‚Äì531, New York, NY, USA, 2017. Association for Computing Machinery. ISBN 9781450349529. doi: 10.1145/3123939.3123948.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "DynInfer leverages software-compiler-hardware co-design to manage and deploy tasks. With the help of DynFit, DynInfer provides  6% ‚Äì 22%  accuracy improvements with  ‚â§ 5%  additional compute over existing methods. ‚Ä¢  Dataset : A first-of-its-kind machine status monitoring dataset, involving multiple types of EH sensors mounted at various locations on a Bridgeport machine to monitor its activity status, facilitating research in predictive maintenance and Industry 4.0 applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "To implement these three possible decisions (FI, SI, and PI) that can be made by the  Decision Maker , the  Inference Engine  in Fig. 7 takes the corresponding actions: Full Inference:  When the incoming frame contains critical information such as new objects entering, a full inference is needed. In this case, the current frame is processed on the CPU to report the Ô¨Ånal result.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "B. The Case of Privacy Awareness \nHaving a centralized data repository of various systems improves model robustness. However, not all the deployments may want to participate in data sharing because of privacy reasons.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "In order to apply this to proactive container allocation decisions, we can adopt the following procedure. The incoming load to the application at time stamp,  ùë° , is denoted as  ùëÉùêø ùë° and can be predicted using a load estimation model. Assuming each request to a function within the appli- cation spawns one container for that function, the number of containers to be provisioned in advance for functions at depth  ùëë is given by: \nùëÅùê∂ ùëë ùë° =  ‚åà PL  ùë° ¬∑ ( ùëá ùëë ¬∑  ùëÉ 0 )‚åâ \nHere,  ùëÅùê∂ ùëë ùë° is a column vector of ùëõ elements, each correspond- ing to the number of elements required to be provisioned for functions at a depth,  ùëë , from the start function.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 176,
    "augmented": false
  },
  {
    "text": "4) How to Do Partial-Inference? :  Next, we revisit the example scenario discussed in Fig. 3a, and give the details of the proposed partial inference (PI) scheme in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Energy efÔ¨Åciency \nWe evaluate energy efÔ¨Åciency by measuring MAC operations per Joule, as shown in Figure 9. Note that this includes the energy overheads of data movements and other functional units in addition to MACs. Overall, the normalized results of energy efÔ¨Åciency are very similar to those of the throughput evaluation.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Wordcraft: story writing with large language models. In  Proceedings of the 27th International Conference on Intelligent User Interfaces , pages 841‚Äì852, 2022. [178] Ted Zadouri, Ahmet √úst√ºn, Arash Ahmadian, Beyza Ermi¬∏s, Acyr Locatelli, and Sara Hooker.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "The quantized DNNs benefit from lower compute and memory footprints, but need specialized fine-tuning and often suffer from lower ac- curacy. Our analysis, as shown in Figure 2c, shows accuracy as a function of quantization (we took the approach of perform- ing post training quantization and fine-tuned the DNN to work with reduced bit precision instead of training the DNN from scratch with a reduced precision). We observe that the system used in [ 47 ] does not aggressively employ quantization, which is a commonly used technique [ 64 ] to reduce both compute and transmission energy in DNN tasks.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "Better refers to the improvement over iNAS+PT baseline. Datasets Full Power MSP on Thermal AP PT iNAS+PT NExUME Better FMNIST 98.70 80.92 86.32 88.93 95.62 7.53% CIFAR10 89.81 64.78 69.29 71.53 83.78 17.13% MHEALTH 89.62 69.77 73.99 77.70 89.62 15.34% PAMAP 87.30 66.33 71.84 74.47 85.24 14.46% AudioMNIST 88.20 73.84 78.03 81.60 87.64 7.40% Table 5: Accuracy of NExUME on MSP board using thermocouple based thermal harvester. Better refers to the improvement over iNAS+PT baseline.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 204,
    "augmented": false
  },
  {
    "text": "Figure 16:  Latency reduction (%) plotted as bar graph(primary y- axis) and accuracy gains (%) plotted as line graph (secondary y-axis) over InFaaS. Strict Relaxed 0 \n20 \n40 \n60 \n80 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(a)  Wiki Trace. Strict Relaxed 0 \n25 \n50 \n75 \n100 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "5.4. Power Consumption:  Overall, the  Inter-Holo  scheme consumes around 4 . 24 Watts , on average, when running on the edge GPU, which translates to 3 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "[14] F. M. Rueda, R. Grzeszick, G. A. Fink, S. Feldhorst, and M. ten Hompel, ‚ÄúConvolutional neural networks for human activity recognition using body-worn sensors,‚Äù  Informatics , 2018. Springer, 2014. [15] T. Yang, Y. Chen, and V. Sze, ‚ÄúDesigning energy-efÔ¨Åcient convolutional neural networks using energy-aware pruning,‚Äù in  CVPR .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "This ef- fect is highlighted in applications such as  Social Network  and Media Service  which have relatively high MLP misprediction rates (80% and 50%, respectively 2 )) due to the presence of multiple possible paths (Table 2). Media Service  suffers from higher end-to-end response times, further exacerbating this effect. Xanadu  has only a 34% misprediction rate for  Hotel Reservation , due to the lower number of workflows, and is seen to match  Kraken  in terms of SLOs satisfied (99.87%).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "Frameless  2, 1 (2020), 21. [24]  Anton Kaplanyan, Anton Sochenov, Thomas Leimk√ºhler, Mikhail Okunev, T. Goodall, and Gizem Rufo. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "IEEE Transactions on Big Data , 2020. [5] Yang Liu, Yingting Liu, Zhijie Liu, Yuxuan Liang, Chuishi Meng, Junbo Zhang, and Yu Zheng. Federated forest.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "5)Powerandlatencymodels:Theaboveanalysiscaptures thepowerconsumptionandexecutionlatencyofprocessing oneconvolutionlayer .Itisassumedthatallofthesesteps areperformedinsequence.Puttingthemalltogether,for convolutionlayerLk,thepowerandlatencypaircanbemodeled asinEquation2and3. P LK  =(P ld √ó Lat ld Lk   +P comp √ó Lat comp Lk \n+P st √ó Lat st Lk   +P merge  √ó Lat merge Lk )/Lat Lk (2) \nLat LK  = Lat ld Lk   + Lat comp Lk + Lat st Lk   + Lat merge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC ‚â• 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication. Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 328,
    "augmented": true
  },
  {
    "text": "Firecracker: Lightweight Virtualization for Serverless Applications. In  NSDI . 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "And, Ô¨Ånally, we update RoI for the next layer (the region with the purple border in Step  7  ). Thus, the full inference outputs are accordingly padded around the partial inference outputs via memory copy (Step  5  ). For the other regions in the output feature map for this frame, it is safe to simply pad them with zeros (Step  6  ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "45.45 LSTM 28.56 DeepArEst 26.67 \nTable 4:  Prediction models. different load arrival patterns, we design a DeepAR- estimator (DeepARest) based prediction model. Prediction Policy : To effectively capture the \nModel RMSE MWA 77.5 EWMA 88.25 Linear R. 87.5 Logsitic R. 78.34 Simple FF.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "The students models are typically optimized for edge, i.e. with optimizations like quantization, pruning etc. or by developing an application speciÔ¨Åc model from scratch along with the said optimizations.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "32‚Äì40, 2015. [11] S. Ha and S. Choi, ‚ÄúConvolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors,‚Äù in IJCNN , 2016. [10] K. Ma, X. Li, J. Li, Y. Liu, Y. Xie, J. Sampson, M. T. Kandemir, and V. Narayanan, ‚ÄúIncidental computing on iot nonvolatile processors,‚Äù in MICRO , 2017.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "Sun, Y. Xie, S. Zhang, G. Zhang, H. Bao, and X. Zhou, ‚ÄúYou Don‚Äôt Only Look Once: Constructing spatial-temporal memory for integrated 3d object detection and tracking,‚Äù  ICCV , 2021. [79]  M. A. S. Teixeira, H. B. Santos, A. S. d. Oliveira, L. V. Arruda, and F. Neves, ‚ÄúRobots perception through 3d point cloud sensors,‚Äù in  Robot Operating System (ROS) . [78]  J.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "Essentially, the DNN is trained to manage within a static resource budget, ignoring the ‚Äúdynamism‚Äù of the resources . In contrast, our work prioritizes the integration of this dynamism in both the network architecture search (NAS) and the training phases, adapting more effectively to fluctuating energy and compute conditions. 3 NExUME Framework \nTo address the issues with  intermittency-aware  DNN training and inference, we propose NExUME: ( N eural  Ex ecution  U nder Inter M ittent  E nvironments).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "6), that Origin  keeps up with the claimed accuracy (base accuracy), and at times outperforms it. We can attribute this to the conÔ¨Ådence matrix and ensemble learner, since over these 1000 iterations, only the conÔ¨Ådence matrix gets updated. Note that the conÔ¨Ådence matrix reaches the steady state of baseline accuracy within 100 iterations.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "[31]  T. Karras, ‚ÄúMaximizing parallelism in the construction of bvhs, octrees, and k-d trees,‚Äù in  Proceedings of the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics , 2012, p. 33‚Äì37. [32]  J. Kim, J. Im, S. Rhyu, and K. Kim, ‚Äú3d motion estima- tion and compensation method for video-based point cloud compression,‚Äù  IEEE Access , pp. 83 538‚Äì83 547, 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "1. First, to ensure minimal accuracy loss, if we have already skipped inference for frames beyond a certain number ( RD upper bound ), we decide to opt for FI (in Line  17 ). Note that  RD upper bound  can vary across different use cases from parking lot to busy roads and hence, can be set accordingly \n1077 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": ", m n ]  where  m i  ‚àà{ 0 ,  1 } . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Neuron Shapley Value Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ¥ .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "A few techniques we plan to study include: i)  Exploiting Redundancy : Selectively training multiple experts on similar/over- lapping tasks (which are deemed critical to performance/accuracy) provides a fallback mechanism in case one of them fails. Here, the redundant experts should ideally be distributed across multiple nodes; ii) Isolated Training : In the event of changes to experts, our approach enables retraining by accounting for min- imum number of neighboring experts/routers; this will inherently facilitate fault tolerance, thereby allow- ing retraining of the EoE with minimum overhead in the event of expert failures; iii)  Checkpointing/Rollback Recovery : Techniques such as checkpointing weights/gradients periodically with rollback recovery in the event of expert failures can allow training to progress from the latest checkpoint (versus restarting the en- tire training); and finally, iv)  Dynamic Expert Re-routing:  In the event that an expert on one node fails, our system-level framework will communicate with the algorithm-level routers to dynamically decide which experts (on which node) should be used instead. To further minimize the impact of failures, we will investigate known fault-tolerance techniques from the distributed computing domain to support graceful degradation of training.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 296,
    "augmented": true
  },
  {
    "text": "4.48 \n0 2 4 6 8 10 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. latency (ms). Latency (ms) \nHoloCompute Overhead \n876.81 \n430.15 393.07 \n(b) Exec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "He has an extensive research background and publication record in efficient methods for LLMs such as LLM pruning (NAACL 2024), LLM parameter-efficient finetuning (ACL 2022, EMNLP 2023), long-context LLMs (ACL 2022, NeurIPS 2024), data selection for LLM in-context learning (ICLR 2023). In the context of this project, he will lead Thrust-1 and also co-lead Thrust-4 with Kandemir and Das. All the three PIs will work in close coordination on the individual research topics as well as the overall integration of the project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Seeker  provides hardware acceleration support for coreset formation to make them computationally efficient, adaptive, and accuracy-preserving specifically for EH-WSNs. The fol- lowing are the  primary contributions  of our work: ‚Ä¢  Efficient Communication:  We enable low data volume communication by developing extensions to traditional coresets that enhances their applicability to EH-WSN in- ference scenarios. Specifically, we introduce an  activity- aware coreset construction  technique to dynamically adapt to both activity and the available harvested energy, while conserving maximum features of the data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "To maximize the compute reuse between the compute pipeline and the archival pipeline,  Salient Store  uses apart of the neural network of the inference engine to extract features, and then further performs the encoding using the FPGA in the CSD. Neural codecs present a new paradigm video compression technology, leveraging deep learning to surpass traditional codec efficiency (Ma et al., 2019; Chen et al., 2017). Traditional neural codecs, while innovative, typically encode and decode video streams in a monolithic fashion, which often results in suboptimal utilization of computational resources and inflexibility (Ma et al., 2019).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "Calculate the Shapley values  œï i  for each neuron based on their contribution to the network‚Äôs perfor- mance. For each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) If  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \n21 \nUpdate the dropout mask  m  based on the Shapley values: \np i  = Œ¥ œï i  +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Inference with Neuron Shapley Value Dropout and QuantaTask Optimization:  Check the available energy using DynAgent.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 313,
    "augmented": false
  },
  {
    "text": "This example illustrates 3 consecutive frames processing, each of which consists of two projection matrices ( P L and  P R ) for both eyes. Moreover, the reuse between both eyes is further optimized by  AE . The  3 rd frame shares the same head orientation with the  1 st, thus can be optimized by  EA .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Figure  7  shows the computation time and cost for executing 1 million infer- ence queries for three different model types with different memory allocations. We vary the memory allocation, starting from least required memory for the model to the maximum available limit in AWS (3GB) 1 . It can be clearly seen that the computation time reduces with increased memory alloca- tion but also results in higher cost of deployment for every model type.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Arduino. Arduino nano 33 ble sense with headers. https://store-usa.arduino.cc/products/ arduino-nano-33-ble-sense-with-headers , 2024.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "We divide the data into training and testing sets, and to simulate a distributed environment, the training data is further divided into multiple different chunks (starting from 2 to 4, each part representing a household in the same neighbourhood). We ensure data diversity between different partitions to ensure similarities with the real-world. Further, we apply our policies to the distributed data and train random forest models (both for the edge and the cloud).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "72 (with real solar power trace) and minimum of 89 . 14 (with synthetic power trace) accuracy. The micro-proÔ¨Åler, having run multiple sweeps, returns a set of hyper-parameters ( Œ® i ) for each model which is then stored in a history table.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "In EH-WSNs, sensors providing different views of the same scene can en- hance inference accuracy through collaborative processing. Techniques such as co-training, consensus learning, and en- semble methods have been explored to combine information from multiple sensors ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "In the original training phase, these feature vectors are separated using K-means [ 74 ] or other clustering. The cluster centers for each data ( Œº y  for class  y ) are calculated as  Œº y  =   1 \nP y   ‚àë p ‚àà P y   Œ¶ ( p ) , where  P y  is the number of samples belonging to class (or cluster  y ), and  Œ¶  is the feature extraction function working on the data  p . These clusters represent the classes in the high dimensional feature space.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "This results in container provisioning along a single function chain. However, not proportionately allocating containers to all functions in the application can lead to under-provisioning containers for some functions when requests deviate from the predicted path. To address these challenges, we propose  Kraken , a DAG workflow-aware resource management framework specifi- cally catered to dynamic DAGs, that minimizes resource con- sumption, while remaining SLO compliant.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "For example, in this paper, we pick two different thresholds to strike a balance between latency, quality and compression efÔ¨Åciency, as will be discussed in detail later in Sec. On the other hand, for applications that demand very small compressed data sizes to transfer through the network, the threshold condition can be relaxed to favor the  direct reuse  more. VI-C .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "2019. Similarity check (PNSR and SSIM) on the GPU. \"https://docs.opencv.org/2.4/doc/tutorials/gpu/gpu-basics-similarity/gpu- basics-similarity.html\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "10(a), one can observe that, for V1, the energy saving is about  56% with only  0 . From Fig. 10.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Additionally, the students will be encouraged to attend career and professional development workshops offered by Penn State. Training in Paper Writing \nThe PIs will discuss regularly with the PhD students the best paper-writing practices, to ensure that they gain the first-hand experience in best practices. To expedite the process, where it makes sense, the PIs will team up the new students with the older ones in paper writing process.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "[41] A. Rosebrock, ‚ÄúIntersection over Union (IoU) for Object Detection,‚Äù ‚Äùshorturl.at/gszOR‚Äù, 2016. [42] CVLAB in EPFL, ‚ÄúMulti-camera Pedestrians Video,‚Äù ‚Äùshorturl.at/ zDY25‚Äù. [43] Y. Xu, X. Liu, L. Qin, and S.-C. Zhu, ‚ÄúCross-View People Tracking by Scene-Centered Spatio-Temporal Parsing,‚Äù in  Proceedings of the Thirty- First AAAI Conference on ArtiÔ¨Åcial Intelligence , 2017, p. 4299‚Äì4305.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "Const1 Const2 Const3 Const4 Query \n0.0 \n2.5 \n5.0 \n7.5 \n#Models \nClipper Clipper-X Cocktail \n(b)  Sentiment analysis. Figure 15:  Average number of models used in the ensemble. the accuracy, while short latency models need to be ensem- bled to reach the same accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "5%  of the overall inference execution latency for a heavy model, as will be discussed later in detail in Sec. V. \nB. Region-Level Pruning As discussed in Sec. Moreover, the total overhead of this algorithm is only  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Intellectual Merit: This project explores hw-sw support to transform applications into suitable device-agnostic codelets, that serve as the granularity for seamless scheduling and execution across GPUs and FPGAs. Broader Impacts: The research results from this project have been fused into different classes at Penn State, and the project has benefited from the participation of undergraduate honor students. Five PhD students, supported through this project, have graduated and one has joined as a faculty.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "The underlying idea is to use spike counts to represent the data value. An intra-tile pipeline is formed to boost the dot-product throughput. In the PipeLayer design [ 5 ], a spike-based scheme, instead of a voltage-level based scheme, is used for input to eliminate the power overhead of DACs and ADCs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "569‚Äì590, 2024. Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, and Benjamin et al. Caine.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "[49]  Martin Persson, David Engstr√∂m, and Mattias Goks√∂r. Real-time Generation of Fully Optimized Holograms for Optical Trapping Applications. 2011.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "SIGARCH Comput. Archit. News , 39(2):1‚Äì7, August 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "[48]  Abeer Abdel Khaleq and Ilkyeun Ra. Cloud-based disaster manage- ment as a service: A microservice approach for hurricane twitter data analysis. In  GHTC , 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "5%  of the end-to-end execution latency (the baseline YOLOv3 inference). Also, the PI technique consumes  23%  of the execution time in YOLOv3. Similarly, the overhead introduced by Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Sus- tainable Energy Technologies and Assessments  52 (2022), 102093. AI-based modeling and data-driven evaluation for smart farming-oriented big data architecture using IoT with energy harvesting capabilities. [62]  Alanson P Sample, Daniel J Yeager, Pauline S Powledge, Alexander V Mamishev, and Joshua R Smith.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "This  maximizes data and resource reuse , and the pipeline for inference and compression do not diverge from the get going. However, even with data reuse, performing compression using neural codecs would require extra compute resources, energy and latency, hindering the critical path, i.e., inference. However,  this issue could be alleviated by not using the compute resource in the critical path and preferably moving the compute to the storage where the data will eventually be stored .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "While striking a few similarities with  Cocktail , it is practically limited to image-classiÔ¨Åcation applications with very few classes and does not address re- source provisioning challenges. Model-serving in Cloud : The most relevant prior works to Cocktail  are InFaas [ 83 ] and Clipper [ 27 ], which have been extensively discussed and compared to in Section  6 . Recently FrugalML [ 20 ] was proposed to cost-effectively choose from commercial MLaaS APIs.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Each branch node in the octree stores 8 occupy bits, indicating the occupancy of its children/sub-cubes. The attribute compression in the G- PCC depends on the geometry. As a result, the attribute and geometry are compressed separately.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "[28] Y. Leng, C.-C. Chen, Q. 91‚Äì103. Sun, J. Huang, and Y. Zhu, ‚ÄúEnergy-efÔ¨Åcient Video Processing for Virtual Reality,‚Äù in  Proceedings of the International Symposium on Computer Architecture (ISCA) , 2019, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Rapidchiplet: A toolchain for rapid design space exploration of chiplet architectures, 2023. [69] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. Adaptive mixtures of local experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "E VALUATION \nIn this section we explain the strategy for evaluating  Origin . We discuss about the hardware and software framework, and the accuracy of  Origin  compared to two different baselines. A.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "IEEE Access  8 (2020), 93155‚Äì93178. 2020. Bearing fault detection and diagnosis using case western reserve university dataset with deep learning approaches: A review.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "By aligning update events with periods when sensors are most likely to participate meaningfully, we ensure that the global model is refined efficiently without imposing excessive en- ergy demands on the sensors. Training Objective and Regularization: To enhance ro- bustness and efficiency, we incorporate regularizers that pe- nalize undesirable model properties. Specifically, we intro- duce two regularizers:  (1)  ‚Ñ¶ SNR ( Œ∏ ) : Encourages the model to maintain performance across varying SNR levels, pre- venting over-reliance on high-SNR data.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "This represents a particularly challenging tension between energy availability and desired functionality, because the form factor constraints of the WSNs fundamentally limit active power, energy re- serves, compute and communication capabilities. Wireless sensor networks (WSNs), one of the prominent classes of IoT deployments, is currently dominating and expected to be pervasive impacting many application spaces [ 13 ] including, but not limited to, body area network [ 22 ,  47 ], industrial monitoring [ 34 ], predic- tive maintenance [ 70 ], commercial satellites[ 15 ] and smart farming [ 61 ]. Moreover, these WSNs are and further will be participating in producing rapid inferences to support the increasingly complex tasks enabled by machine learning \n(ML) algorithms [ 47 ,  68 ], often tweaked towards edge de- ployments, and applications of such edge-analytics is also ex- ploding with the user and market demands.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 209,
    "augmented": true
  },
  {
    "text": "Kube-Knots: Resource Harvesting through Dynamic Container Orchestration in GPU-based Datacenters. In  CLUSTER , 2019. [76]  Guido Urdaneta, Guillaume Pierre, and Maarten Van Steen.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "When the income falls below the threshold, the system halts the inference and checkpoints the intermediate states (via software or persistent hardware) (Maeng & Lucia, 2018; Qiu et al., 2020), resuming upon energy recovery. Depending on the EH profile, this might lead to significant delays and SLO violations. (II) Computational Approximation : To address (I) and maintain continuous operation, EH-WSNs may skip some compute during energy shortfalls by dropping neurons (zero padding) or by approximating computations (quantization).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Association for Computational Linguistics. [34] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "In  Cocktail , we use a load prediction model that can accurately forecast the anticipated load for a given time interval. Using the predicted load  6a  ,  Cocktail  spawns additional instances, if necessary, for every instance pool. In addition, we sample SLO violations for every 10s interval and reactively spawn additional instances to every pool based on aggregate resource utilization of all instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Our characterization indicates that, on average, around 2.3 GFLOPS is required for this projection transformation (details are discussed in Sec. III). The second input is the decoded  360 ¬∞ frame that contains the pixel values.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "intel.com/content/www/us/en/transportation/urban-mobility.html . Smart city technologies and intelligent transportation systems are helping cities absorb growing populations, overcome congestion, and create sustainable futures. https://www.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Addressing these challenges ne- cessitates a fresh look beyond the current monolithic design for providing a democratic platform for contributing to cost-effective innovations in LLMs. One promis- ing direction that is being recently explored is the development of ‚Äúmodular‚Äù architectures that en- able flexibility, scalability, and efficiency. Mixture of Experts (MoE) [145] and Composition of Experts (CoE) [131, 151] models have been proposed to distribute computational loads across mul- tiple specialized networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "Note, however, that, this step also requires sequential barriers within each plane ( Line#6  synchro- nizes the threads in a warp/block for one depth plane) and across planes ( Line#7  synchronizes the results from all the depth planes, before moving forward to the second step). Hence, as we will show later in this section, such barriers sliced into the massive parallel execution can cause load imbalance and instruction stalls, which slow down the entire execution and impact performance. The sec- ond step,  Backward-Propagate  (denoted  ‚ù∑ in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "Hot experts are those that are more frequently invoked for generating responses because of common or recurring query topics, whereas cold experts are the ones which are less frequently utilized. Note that this categorization is  dynamic , adapting to the temporal nature of the incoming requests which can have \nvariations based on user demand. As shown in Figure 5, one way of utilizing this hot/cold expert separa- tion is to store their respective model parameters at different levels in the memory hierarchy, dictated by the degree of hotness, so as to optimize the response generation pipeline.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "Rather than computing, we \n2 Since CONV layers dominate total computation in DNN inference [8], our partial inference technique is applied only to the CONV layers; the other layers employ full inference. However, it is  not  desirable to execute the infer- ence on the mid- dle part, since, in order to do so, one needs to prepare an input larger than the inner region (due to the various kernel sizes in the convolution, e.g.,  3  √ó  3 ,  5  √ó  5  [38]), which eventually turns out to be the FI. Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "163‚Äì171. HPG ‚Äô16, 2016, pp. [49] C.-H. Tsai, H.-T. Wang, C.-L. Liu, Y. Li, and C.-Y.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "AMD and Xilinx. Xilinx runtime library (xrt). https://www.xilinx.com/products/ design-tools/vitis/xrt.html .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Distributed training frameworks like Horovod [141], Mega- tronLM [149], and DeepSpeed [65] ensure optimized data communication for distributed memory usage along with dynamic batching so that scaling overheads are minimized and resources are maximally uti- lized. Existing literature also examines the impact of software optimizations like kernel fusion [170] and compiler optimizations [25], performance improvements via load balancing [58, 88, 182] and resource al- location [79, 161]. In the direction of fault tolerance, there are works on various checkpointing [102, 162] strategies so that system gracefully comes out of failure with minimum loss of progress.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "This is achieved through the use of a single Digital Signal Processing (DSP) block that operates on signed data representation. The HSPM accelerator‚Äôs architecture, as illustrated in Fig. Consequently, these units are referred to as Signed Double Modular Multiplication (SDMM) units.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "9d, DeepCache can only save  38% and  45%  on execution time for YOLOv3 and YOLOv4-tiny, respectively, which are less than both FI+SI (e.g., 52% for YOLOv3; 53% for YOLOv4-tiny) and FI+SI+PI (e.g., 55% for YOLOv3; 61% for YOLOv4-tiny) schemes. Another hardware-based optimization has been proposed in Euphrates [9], as discussed in Sec. II-B3.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Next, the routers are trained on the new topology, and the leaf nodes are used when the query routes to them. We cluster the experts according to their domain similarity so that each parent node is assigned two most similar leaves. 2.2 Thrust-2: System Support for Expert Scheduling and Data Movements The primary goal of this thrust is to explore novel system support ‚Äì targeting  both  training and inference ‚Äì that complements our algorithmic support for EoE in Thrust 1 and architectural support for EoE in Thrust 3.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "In  Cocktail , we employ a per-class weighted majority voting policy, that makes it scalable and effec- tively breaks ties when compared to traditional weighted averaging, thereby minimizing the accuracy loss. 3. We show that uniformly scaling resources for all models in the ensemble leads to over-provisioning of resources and towards minimizing it, we build a distributed weighted auto-scaling policy that utilizes the  importance sampling technique to proactively allocate resources to every model.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "This software-based viewing window optimization is considered to be the state-of-the-art at an algorithm level, and we refer to it as Baseline  in this study. We evaluate this baseline by profiling its performance and energy consumption from a mobile GPU [36]. ‚Ä¢  Inter-Holo:  We evaluate the  Inter-Holo  design on a mobile GPU [ 36 ] using a framework similar to the state-of-the-art IL- LIXR framework [ 19 ], with one additional eye tracking task (as shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "However, our design objective is to minimize  data movements in the case of compute reconÔ¨Ågura- tion. In an output stationary mapping,  both  input and weights are dynamic and any power failure or reconÔ¨Åguration will need to save and restore a lot of current context (partial sums, indices of weights and inputs etc.) to resume and remap the compute.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "The salient characteristics these videos are given in Tab. 2. To re- place these real objects, we choose six virtual holograms (Sniper, Rock, Tree, Planet, Rabbit, and Dice holograms) from the Open- Holo depthmap database [ 45 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "[5] Yang Liu, Yingting Liu, Zhijie Liu, Yuxuan Liang, Chuishi Meng, Junbo Zhang, and Yu Zheng. [4] Heiner Lasi, Peter Fettke, Hans-Georg Kemper, Thomas Feld, and Michael Hoffmann. Industry 4.0. Business & information systems engineering , 6(4):239‚Äì242, 2014.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "2017. Markov chains: From Theory to Implementation and Experimentation . John Wiley & Sons.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 26,
    "augmented": false
  },
  {
    "text": "The goal of our study was to correctly predict the surface roughness from sensor data. We divided the data into multiple chunks to emulate a multi machine setup (varying from 2 to 5). Since the data size is limited, with increasing numbers of machines, the training data-per-machine decreases, and hence gives us the opportunity to also study the impact of data availability.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "-5 5 15 25 \n1 225 449 673 897 1121 1345 1569 1793 2017 2241 \nDistance \nPixel ID \ndistanceY distanceX \n-10 \n-5 \n0 \n5 \n10 \n0 10 20 \nDistance-x \nDistance-y \n(b) (0.00, 1.57, -0.73) \n-20 0 20 40 60 \n1 202 403 604 805 1006 1207 1408 1609 1810 2011 2212 \nDistance \nPixel ID \ndistanceY distanceX \n-10 -5 0 5 10 \n0 20 40 60 \nDistance-x \nDistance-y \n(c) (0.52, 1.05, -0.73) \nFig. 6: In  AE , distance vector (a) patterns with two different head orientations  ( Y aw, Pitch, Roll )  in (b) and (c). is mapped from position  [( x 360 ) 0 r ,  ( y 360 ) 0 r ]  on the  360 ¬∞ frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 212,
    "augmented": false
  },
  {
    "text": "Clearly, the geometry data has been compressed very well, as opposed to the attribute data. Recall from our intra-frame design discussion in Sec. IV  that, the Morton codes can precisely describe the geometry relations among points (thus, ensuring a good geometry compression), but sometimes they may not work well for the attributes, especially when the spatial locality is not rich for some blocks/frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Furthermore, it can be seen that Xanadu  provisions a relatively high number of containers for a particular group of functions as compared to the rest. However, it does not take workflow activation patterns into consideration while spawning con- tainers, leading to container overprovisioning. The recently proposed scheme,  Xanadu , is based on a workflow-aware container deployment mechanism, but does not employ re- quest batching, leading to extra containers being deployed in comparison to  Kraken .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "The NVSB stores the global/asynchronous work queue and the shufÔ¨Çing conÔ¨Åguration (mini-batch arrangement). Power Failure and Compute Scheduling \nCentral to the  Us. B.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "Varying SLO:  Table 7 shows the SLO guarantees and num- ber of containers spawned for existing policies as well as Comm Only  and  Conn Only , when the SLO is reduced from 1000ms to a value 30% higher than the response time of the slowest workflow in each application. The resultant SLOs are 500ms, 910ms and 809ms for  Social Network ,  Media Ser- vice  and  Hotel Reservation  respectively. Reducing the SLO, in turn, can potentially reduce the batch sizes of functions as well.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "Tourism and Hospitality , 3(1):265‚Äì275, 2022. Philipp M. Grulich and Faisal Nawab. Vr in tourism: A new call for virtual tourism experience amid and after the covid-19 pandemic.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "accuracies (< 75%) because single models can reach those accuracies. Hence, based on the user constraints,  Cocktail chooses between ensemble and single models. 2.3.2 Ensembling Overhead \nWhile ensembling can boost accuracy with low latency, their distinctive resource hungry nature drastically increases the deployment costs when compared to single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "ACM. In  HotOS . A Case for Managed and Model-Less Inference Serv- ing.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "2.2.3 What are the Potential Opportunities? Towards addressing this hologram bottleneck, various ap- proaches from both the software [ 33 ,  52 ,  54 ] and hardware [ 32 ,  35 ] sides have been proposed. These prior approaches either incorpo- rate additional memory for maintaining a lookup table for compu- tation reduction, or build an application-specific integrated circuit (ASIC) chip specifically for holographic processing, which is more power-efficient than generic processors.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "[35] mooovr, ‚ÄúRollerCoaster at Seoul Grand Park.‚Äù ‚Äùhttps://www.youtube. com/watch?v=8lsB-P8nGSM‚Äù, 2019. [36] Nvidia, ‚ÄúJETSON AGX XAVIER AND THE NEW ERA OF AU- TONOMOUS MACHINES.‚Äù ‚Äùhttp://info.nvidia.com/rs/156-OFN-742/ images/Jetson AGX Xavier New Era Autonomous Machines.pdf‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Our proposal introduces an  Ensemble of Experts (EoE)  framework that embodies this co-design philosophy. We envision a network of expert language models, each trained on domain- \nspecific datasets, forming a modular and scalable system. This approach defines a large set of different expert types, routers and composition functions that can be used to build an ‚Äúensemble‚Äù (model) that is customized for the application at hand, and allows for independent training and updating of experts, fa- cilitating continual learning and adaptability.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "In Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture , pp. 204‚Äì218, 2017. Kiwan Maeng and Brandon Lucia.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Training compute- optimal large language models. Journal of Ma- chine Learning Research , 22(241):1‚Äì124, 2021. [64] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Ruther- ford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "Data Management and Sharing Plan \nThis section describes ‚Äúdata‚Äù ‚Äì in its most general definition that includes, compiler, scheduler, and simu- lation source codes and executables, LLM/expert models/algorithms, educational materials, benchmarks, and experimental data ‚Äì that will be produced during the project; how this data will be managed, stored and shared, what standards will be used for different types of data, and how data will be handled and protected during and after the project. In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pages 761‚Äì774, 2024. It also describes our plans for ensuring data integrity and reproducibility.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA ¬© 2021 Association for Computing Machinery. Request permissions from permissions@acm.org.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "The expertise of the management team members are complementary, and col- lectively cover all major aspects of the proposed research, namely, algorithm design, system-level support and architectural support. All the three PIs will work in close coordination on the individual research topics as well as the overall integration of the project. Das and Kandemir have worked together in prior and on-going NSF projects and have a history of successful collaboration, including co-advising underrepresented students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "0 \n10 \n20 \nCost($) \nVM cost \nLambda Cost \ninception          resnet-200 resnext-50 nasnet \n(b)  Cost for ISO-accuracy models. Figure 3. Variation of cost of using VMs vs.  serverless functions  under constant request load.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "2019. [21]  NATIONAL INSTRUMENTS. \"https://www.ifixit.com/Teardown/Magic+Leap+One+Teardown/112245\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "It ensures that active PEs efÔ¨Åciently utilize available power to complete work, preventing potential losses and eliminating the need to restart tasks from the beginning. However, in situations with sporadic energy income, the hardware-assisted scheduling becomes paramount. Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "This calls for revisiting the entire training process; we need to train the DNN in such a way that it is aware of the intermittency and adapts  to it. Motivated by these challenges, we propose  NExUME  ( N eural  Ex ecution  U nder Inter M ittent E nvironments), a novel framework designed specifically for environments with intermittent power and EH-WSNs, with potential applications in any ultra-low-power inference system. NExUME uniquely integrates energy variability awareness directly into both the training ( DynFit ) and inference ( DynInfer ) processes, enabling DNNs to dynamically adapt computations based on real-time energy availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 163,
    "augmented": false
  },
  {
    "text": "GROOT: A Real-time Streaming System of High-fidelity Volumetric Videos. In Proceedings of the ACM/IEEE International Conference on Mobile Computing and Networking (MobiCom) . 1‚Äì14.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "95‚Äì99, 2016. [14]  R. Grezaud and J. Willemin, ‚ÄúA self-starting fully integrated auto-adaptive converter for battery-less thermal energy harvesting,‚Äù in  2013 IEEE 11th International New Circuits and Systems Conference (NEWCAS) , pp. 1‚Äì4, 2013.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "3  b  , and a visual view of how these segments look like in Fig. Temporal Locality in Attributes:  To study the temporal attribute locality across two frames, we plot the CDF of the attribute deltas among two segments in an I-frame and a P-frame in Fig. This again indicates that, within a smaller macro block, the voxels have richer similarity with their neighbors.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "P ROPOSED  S TRATEGIES \nAs discussed in Sec. IV. The rest of this paper presents and experimentally evaluates two novel optimization strategies that exploit this similarity.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "The accelerator encompasses 256 tiles, structured in a 4 √ó 4 conÔ¨Åguration of 16 super-tiles, each harboring 4 √ó 4 tiles. These super-tiles Each tile, individually switchable ON or OFF based on power availability, houses 64 16-bit Ô¨Çoating point MAC units conÔ¨Ågured in an 8  √ó  8 systolic array for convolution operations. 5a  shows the high level design, architecture and different components present in our proposed accelerator.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "In  ACM Symposium on Cloud Computing (SoCC ‚Äô21), November 1‚Äì4, 2021, Seattle, WA, USA. https://doi.org/10.1145/3472883. ACM, New York, NY, USA, 15 pages.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Therefore, there have been several works focusing on compressing the PC, as discussed next. 3) Point Cloud Compression (PCC):  The prior PCC works can be classiÔ¨Åed as follows: G-PCC  utilizes special structures like octree or kd-tree to represent and compress the geometry [ 17 ], [ 23 ], [ 74 ]. For example, with octree-based PCC, considering a PC is con- tained in a  D √ó D √ó D  cube, the cube is recursively divided into 8  D / 2 √ó D / 2 √ó D / 2  sub-cubes until  D = 1 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "Key Observations: 1) If data is shared with (a third party) cloud, the accuracy of the model generated using all data from different machines is significantly higher than the models generated for the edge using their own data. For example, for a typical grinding job that takes about 8.2 seconds [1], this 5% improvement impacts  ‚âà 46 k  parts per year per machine (working 8 hours/day). Although, in case of 5 machines (see Figure 3) we see about a 5% accuracy gain with a 14.71% latency increment to perform the inference at cloud, this 5% increment has significant impact in practise.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "[39]  U. Gupta, S. Hsia, V. Saraph, X. Wang, B. Reagen, G. Wei, H. S. Lee, D. Brooks, and C. Wu. Towards designing a self-managed machine learning inference serving system inpublic cloud, 2020. Deeprecsys: A system for optimiz- ing end-to-end at-scale neural recommendation inference.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "7: The proposed  EA  and  AE  design blocks implementation. E. Design Considerations and Implementation \nWe designed both our schemes as modular and scalable additions to the existing pipeline (refer the  EA  and  AE  blocks shown in Fig. 7).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "to resume and remap the compute. However, our design objective is to minimize  data movements in the case of compute reconÔ¨Ågura- tion. In an output stationary mapping,  both  input and weights are dynamic and any power failure or reconÔ¨Åguration will need to save and restore a lot of current context (partial sums, indices of weights and inputs etc.)",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "‚Ä¢  HORN-8:  While hardware acceleration of hologram is not a goal of this work, to qualitatively compare our GPU-based design with hardware specific accelerators, we also discuss one of the most recent ASIC implementations, HORN-8 [ 35 ]. Due to unavailabil- ity of its hardware implementation or datasheet, we estimate its power efficiency compared to the equivalent GPU SoC based on a published data [ 51 ]. With this estimation, we briefly discuss the performance and computational efficiency variations between this accelerator and our approach, and discuss takeaways that can help one to co-design a hardware accelerator targeting hologram processing.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "As a result, by exploiting the  AE  scheme on the Ô¨Årst frame in Fig. 35%  of that consumed by baseline. 4  b  , its compute energy can be reduced to only  62 .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "This is due to the fact that, to process a denser hologram with more depth planes, additional GPU cores are scheduled to launch the per-plane CUDA kernel (as discussed in Algo. 1) with more holographic data accesses (fetched from the host-side memory). One can observe from this figure that, when the number of depth planes is increased, the power consumptions of  SoC  and  CPU  do not change much, while, in contrast, both the GPU  and  Mem  consume more power.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisÔ¨Åxedas Lat comp = T comp ,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1. E comp =E comp tile /Lat comp \n=(E DAC   +E MAC   +E ADC )/T comp (1) \nThepowerofeachpartistakentobelineartothetiling factorsofm ornortheactualparallelismgranularityaG. TheenergyforoneReRAMrow(e DAC ),oneReRAMcell (e MAC  )andoneReRAMcolumn(e BL ,e SA‚àíRef ,e S+A )are theworst-casevaluesfromthesimulation.Table V-B 2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 233,
    "augmented": false
  },
  {
    "text": "This data set directly fits our use case for two reasons - 1. In the real world, these sensors would be distributed in different homes, and each home will have its own idiosyncrasies. 2.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "E.g., with 32 √ó 32 tiles, only 3% of the tiles are identical. 2). However, as the tile size increases, tiles in successive frames become more dissimilar.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "[21]  M. Zhao, C. Fu, Z. Li, Q. Li, M. Xie, Y. Liu, J. Hu, Z. Jia, and C. J. Xue, ‚ÄúStack-size sensitive on-chip memory backup for self-powered nonvolatile processors,‚Äù  IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) , vol. 36, pp. 37‚Äì46, Dec 2017.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "2019. Cirrus: A Serverless Framework for End-to-End ML Workflows. In  Proceedings of the ACM Symposium on Cloud Computing (Santa Cruz, CA, USA)  (SoCC ‚Äô19) .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "As an example for the  Imagenet  dataset shown in Figure  6 , each constraint is a representative of <latency, accuracy> com- bination offered by single models (shown in Table  1 ). We use one constraint (blue dots) each from Ô¨Åve different regions \n1048    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \n0 \n100 \n200 \n300 \n400 \n70 75 80 85 \nLatency (ms) \nAccuracy (%) \nConst1     Const2       Const3   Const4  Const5 \nFigure 6:  Constraints used in our workloads. (categorized by dotted lines) picked in the increasing order of accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "CSE Department Resources: The Department of Computer Science and Engineering (CSE) at Penn State uses a network of Linux, OS X, and Windows workstations and servers to support academic com- puting needs. Six student teaching labs are equipped to host digital design, FPGA, circuit design, programming, robotics/drone, and related curricula. Instruction is supported by highly virtualized services providing file, application, and li- cense servers for approximately 350 workstations in labs, graduate student offices, and faculty.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Objective:  Maximize  Thr sequ ave Subjected to:  for each layer Lk, P   load Lk   , P  store Lk , P   comp Lk , P   trans Lk , P   merge Lk < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ‚ü® m Lk , n Lk , aG Lk ‚ü© for each layer Lk \nSimilarly, the activation strategy under the pipeline execution mode can be described as below. Objective:  Maximize  Thr pipe ave Subjected to: P  P  load , P  P  store , P  P  comp pipe   , P  P  trans , P  P  merge < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ‚ü® m Lk , n Lk , aG Lk ‚ü© for each layer Lk \nBy solving the above problems, we can obtain activation solution  ‚ü® m, n, aG ‚ü© for each power level under the sequential and pipelining computation modes, referred to as  SOL sequ \nand  SOL pipe   respectively. Then the optimal solution can be selected from among them.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 308,
    "augmented": false
  },
  {
    "text": "Task-3.3: Handling Unforeseen Cases using Reconfiguration Besides having dedicated hardware for experts, there are three possible challenges which require adaption in hardware: the chiplets may incur failures, the work contained in inference is input dependent, and re- \ntraining is needed as part of continuous learning. We plan to have ‚Äúreconfigurable chiplets‚Äù, which can be customized during runtime to become a specific compute engine or memory block. For example, during inference, the system can decide to map an expert onto a chip but the suitable hardware may not be directly present.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "Power Consumption:  Overall, the  Inter-Holo  scheme consumes around 4 . 5.4. 24 Watts , on average, when running on the edge GPU, which translates to 3 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "LiDAR maps spatial relationships and shapes by measuring the time taken by signals to bounce off objects and return to the scanner, while photogrammetry takes many photos from different angles to capture the target‚Äôs geometry [ 9 ]. This process typically takes 10s of milliseconds [ 26 ]. Further, each point in the PC is associated with 3 coordinates (x, y, z) for the geometry and 3 colors (R, G, B) for the attribute.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "8 and Fig. 9. 2. \nto evaluate the accuracy, and plot the experimental results in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "From these results, we can make the following observations. Note that these latency and energy results are  normalized  with respect to the baseline (FI for all frames). 9.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "URL  https://arxiv.org/abs/2001.11737 . M. Bramberger, J. Brunner, B. Rinner, and H. Schwabach. Au-air: A multi-modal unmanned aerial vehicle dataset for low altitude traffic surveillance, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Custom composition functions are anticipated to further speed up the integration of diverse expert outputs, thereby improving overall response times. This unified strategy ensures rapid, accurate query responses and high throughput within the infrastructure‚Äôs memory and computational constraints. Task-2.6: Fault-Tolerant Expert Training Fault-tolerance of monolithic LLM models has been a major concern due to the long-running training jobs on a large number of GPUs [27, 149, 165].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Thelatency modelfordataloadforoneconvolution operationis Lat load = Bits input /BW ld .Theterm Lat load \nrepresentsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.Theterm BW ld denotesthebandwidthof eachloadoperation.Themodelsof P store and Lat store can bederivedinasimilarfashion. Theinputbatchnumber BN in isdeterminedbythepower budgetbecause P load <=P budget shouldalwaysbesatisÔ¨Åed. Therefore, Bit input / BN in meanstheactualloadeddatabits eachbatch.Theterm P ld‚àíbit denotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 192,
    "augmented": true
  },
  {
    "text": "V , only part of the blocks/segments can be directly approximated by the reference block. ‚Ä¢  Intra-Inter-V1 : As mentioned in Sec. IV , and then treat the obtained delta values as new attributes, and Ô¨Ånally feed them again to the encoder to further increase the compression efÔ¨Åciency).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "To address these challenges, we propose Us. Consequently, for edge servers to provide cloud-comparable quality, they must also perform continuous learning to mitigate this drift. However, at expected deployment scales, performing continuous training on every edge server is not sustainable due to their aggregate power demands on grid supply and associated sustainability footprints.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "We explore the impact of privacy-preserving random forest training mechanisms to help protect sensitive data generated by the sensors. (2) Design of a threshold based edge-cloud partitioning policy which intelligently decides when to offload an inference to the cloud while maximizing the prediction accuracy and mini- mizing the communication overheads. (3) Evaluation of these policies on a publicly-available data set and also on data from real industrial grinding machines.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "By loading these selected potentially useful and relevant experts into the main memory, we propose to optimize the response time and computational efficiency. Since this method also reduces the data movements in the system, we can expect a significant reduction in energy consumption. Figure 5 :  Hot and cold experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Platform Freq. (MHz) \nArea (mm 2 ) \nPower \n(W) \nPeak Thpt. (GOps) \nEnergy Eff.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Application mapping for chip multiprocessors. [23] Guangyu Chen and Feihui Li. In  Proceedings of the 45th annual design automation conference , pages 620‚Äì625, 2008.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "2 Proposed Research \nA high-level view of our proposed research consisting of 4 thrusts is depicted in Figure 2. In addition to the individual tasks in each thrust, Figure 2 also shows the inter-task dependencies as well as interactions between them, highlighting our cross-layer co-design aspect. Thus, we believe our proposal is ambitious as its potential to revolutionize the training and deployment of LLMs is profound.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Experimental results using two different HAR data-sets show Origin , while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classiÔ¨Åer continuously operating at the same average power. Index Terms ‚ÄîEnergy Harvesting, Human Activity Recognition, DNN, Wireless Senor Network, Ensemble Learning \nI. I NTRODUCTION \nThe advent of data driven computing, along with advances in low-power computing platforms, has given rise to the new generation of intelligent and connected devices that comprise the internet of things (IoT). These devices have become an integral part of our daily lives and, using techniques such as deep learning, these devices are becoming increasingly capable of performing complex inference tasks including ma- chine translation, human activity recognition (HAR), bio-metric authentication, ECG measurement, fall detection etcetera [1], [2].",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 191,
    "augmented": false
  },
  {
    "text": "36, pp. 1804‚Äì1816, Nov 2017. [22]  A. Colin, E. Ruppel, and B. Lucia, ‚ÄúA reconÔ¨Ågurable energy storage architecture for energy-harvesting devices,‚Äù in  Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018 , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "However, our work focuses on edge-side optimization, which can also be implemented as a comple- mentary add-on in such cloud-assisted systems. These optimizations rely on the powerful cloud with a high bandwidth access, which may not be always available. In comparison, Semantic- Aware-Streaming (SAS) exploits the semantic information inherent in a VR video content to precisely predict users‚Äô next head orientations [28].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "Figure 1: Example PC applications and processing pipelines. immersive telepresence, telemedicine, video streaming etc., needs the attributes to be stored along with the 3D coordinates. Since PC generation requires sophisticated instruments like LiDAR or 3D cameras, it was typically done on server- class computers with high compute and storage capabilities.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "To enhance the performance of EoE , we propose system optimizations that exploit the spatio-temporal locality/affinity of its components ‚Äì data, experts, routers, composition functions, and hardware. Table 2 shows how our proposed framework will exploit these affinities across (training, inference) and (algorithm, systems, architecture) dimensions. Task-2.1: Data Locality and Parallelism‚ÄìAware LLM Training Unlike traditional monolithic LLMs, our EoE -based LLM opens up new opportunities to optimize train- ing for both performance and energy efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "Such invariances are leveraged as reuse opportunities to reduce the compute-heavy projection computation. We formally analyze the potential ‚Äúinput invari- ability‚Äù in the  projection computation  during  360 ¬∞ video streaming, which manifests in the head movement locality (temporal reuse) and the stationarity relationship between two eyes (spatial reuse). The major  contributions of the paper can be summarized as follows: \n‚Ä¢  From an open-source 360¬∞ VR video dataset [3],  we identify both temporal reuse and spatial locality that exists in user behavior .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "https://www.amd.com/content/dam/amd/en/documents/ instinct-tech-docs/data-sheets/amd-instinct-mi300x-platform-data-sheet. pdf \", 2024. [14] Lasse F Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "It can be seen that functions which are common to a larger number of paths are invoked at a higher rate by such a request arrival pattern. Therefore, common functions have a higher chance of experiencing increased load due to be- ing present in multiple paths. Consequently, higher weights have to be assigned to such functions to ensure resilience in the presence of varying application usage patterns.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Compressed Geometry Stream (Output):  The Ô¨Ånal com- pressed geometry output stream is ready to be stored in the memory or streamed over the network. State-of-the-Art Intra-Frame Attribute Compression:  As shown in Fig. 4  b  , to compress the attribute data, similar steps ‚Äì  Raw Frame Input ,  Attribute Transform and Quantize , Entropy Encoding , and  Compressed Attribute Output Stream  ‚Äì are employed.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Additionally, profiling devices to ascertain their energy consumption, computational capabilities, and memory footprint necessitates detailed micro- profiling using embedded programming. This process, while informative, yields only approximate models that are inherently prone to errors. DynFit, with its stochastic dropout features, occasionally leads to overfitting, necessitating meticulous fine-tuning.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Recover(IS#)   Infer(RData) \nRdf4mFRAM(#3) \nret 2 //T=task_next ret -1 //pwr emgncy \nret 1 //Coreset ret 2 //T=task_next \nInt Pred_Pwr(task_next)    ...    ret 2 //T=task_next    ret 1 //save to coreset    ret 0 //backup    ret -1 //pwr emgncy \nPower  Emergency \nHardware Supported Monitoring, Backup and Restore \nP1 P2 L1 \nC1 C2 \nCn \nT1 T2 T3 \nLb \nLr \nL3 \nT4 \nT5 \nL3 \nFigure 2: Software-Compiler-Hardware Driven DynInfer Flow. To support user programs (  P1  ), we implement a moving window-based power predictor (  P2  ) which takes its input from the on-board EH capacitor. Considering the energy available, the predictor makes an informed decision on how to proceed.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 247,
    "augmented": false
  },
  {
    "text": "ing the PCC using a public PC dataset [ 18 ]. The major  contributions  of this work are the following: ‚Ä¢  We identify the spatio-temporal redundancies for optimiz- \n1 In this paper, we use ‚Äúlocality‚Äù and ‚Äúframe similarity‚Äù alternatively. We also demonstrate that, such spatio-temporal localities can be precisely captured by Morton codes [ 30 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "They may alter the shape of  J ( Œ∏ ) , encouraging certain regions of parameter space, but they do not prevent convergence. On the con- trary, they may help by smoothing out undesirable minima or limiting model complexity. Bounding and Selecting Hyperparameters  Œª 1 , Œª 2 \nThe choice of  Œª 1  and  Œª 2  affects the curvature of  J ( Œ∏ )  and can influence convergence speed and the location of  Œ∏ ‚àó .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "dimensions , 30:33. Lorenzo Pichierri, Guido Carnevale, Lorenzo Sforni, Andrea Testa, and Giuseppe Notarstefano. A distributed online optimization strategy for cooperative robotic surveillance.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "A matching circuit, including components like buck or boost converters, adjusts the voltage to the appropriate level, ensuring the device receives the correct current and voltage. Voltage Regulation : After rectification, the power might not be at the right voltage for the device it needs to support. 3.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "1, pp. 6765‚Äì6816, 2017. [49] S. Li, Z. Yang, D. Reddy, A. Srivastava, and B. Jacob, ‚ÄúDramsim3: \na cycle-accurate, thermal-capable dram simulator,‚Äù  IEEE Computer Architecture Letters , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "The main objective of this morphable design is to minimize the resource requirements and training/inference time compared to gigantic monolithic models, while maintaining required accuracy needs. Task- 1.4: Algorithmic Choices Informed by System and Hardware Constraints. Task-1.1: EoE Design Space Exploration In order to address the limitations of the state-of-the-art monolithic LLMs, in this task, we propose to make a paradigm shift by laying the algorithmic foundations for an EoE system, a novel LLM framework consisting of numerous expert models that can be composed into an ecosystem  dynamically  according to the user query.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "[68]  Haibo Zhang, Prasanna Venkatesh Rengasamy, Shulin Zhao, Nachiappan Chi- dambaram Nachiappan, Anand Sivasubramaniam, Mahmut T. Kandemir, Ravi Iyer, and Chita R. Das. 2017. Race-to-Sleep + Content Caching + Display Caching: A Recipe for Energy-Efficient Video Streaming on Handhelds.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "AASR intelligently takes advantage of multiple DNNs (by bringing in activity aware scheduling), leverages the workload (by considering the activity continuity via recall and extended round-robin strategies), and also poses minimal overhead on the host device for running aggregation. However, as we did not want to burden the host device with complex computation, the aggregation task is very na¬®ƒ±ve in that it just performs recall and incorporates no intelligence. Hence, there is an opportunity to also improve the ensemble technique.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "We plan to design and imple- ment a clock/power gating technology to switch off the un-utilized PUs and save power/energy. Third, how do we handle the corner cases, where more computational resources than that provided by the accelerator are required? Towards this, we plan to design a system-level scheduler which can efficiently partition the hologram tasks between the heterogeneous accelerator and original execution engines such as CPUs or GPUs.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "Clearly, having prior knowledge of what functions will be invoked for an application makes container provisioning easier for SDAs. 2.1.2 Dynamic DAGs : Although the application DAG con- sists of multiple functions that may be invoked, there are cases where the functions can themselves invoke other func- tions depending on the inputs they receive. We refer to such functions as Dynamic Branch Points (DBPs), and the chains they are a part of as Dynamic Function Chains.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Next, we analyze the results measured using these platforms. We conclude this section by outlining some research directions for implementing approximation-based accelerators for AR holograms. After that, we show the general applicability of the proposed de- sign, and also present results from a sensitivity study that focuses on the quality-loss vs. energy-savings trade-offs.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "The details are described below. 5.1 Prototype Implementation Kraken  is implemented primarily using Python and Go on top of  OpenFaaS  [ 11 ], an open-source serverless platform. Algorithm 2  Reactive Scaling \n1:  for  Every Monitor_Interval= DR  do 2: Reactive_Resource_Manager ( ‚àÄ ùëìùë¢ùëõùëêùë°ùëñùëúùëõùë† ) 3:  procedure  Reactive_Resource_Manager( func ) 4: cl  ‚Üê ùê∂ùë¢ùëüùëüùëíùëõùë° _ ùêøùëúùëéùëë ( ùëìùë¢ùëõùëê ) 5: func.existing_con  ‚Üê ùê∂ùë¢ùëüùëüùëíùëõùë° _ ùëÖùëíùëùùëôùëñùëêùëéùë† ( ùëìùë¢ùëõùëê ) 6: if l c ùëô f ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m ‚â§ func.existing_con  then  a \n7: reqd_con  ‚Üê l c ùëô f ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m \n8: else 9: #_delayed_requests  ‚Üê Delay_Estimator ( ùëìùë¢ùëõùëê )  b 10: extra_con  ‚Üê l  #_delayed_requests \nf ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m \nc 11: reqd_con  ‚Üê func.existing_con + extra_con 12: Scale_Containers ( ùëìùë¢ùëõùëê,ùëüùëíùëûùëë _ ùëêùëúùëõ ) \nOpenFaaS  is deployed on top of  Kubernetes  [ 9 ], which acts as the chief container orchestrator.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 330,
    "augmented": false
  },
  {
    "text": "[16] Apple. Apple intelligence. \" https : / / machinelearning .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 21,
    "augmented": false
  },
  {
    "text": "We can now transform our previously-assumed Markov Model into a VOMM by splitting up context-dependent states into multiple context-independent states (the number of which is dependent on the DAG structure and the order of the VOMM). by performing a summation of  ùëÅùê∂ ùëë ùë° across all possible depths, ùëë , from the start function. Notation Meaning T Transition Matrix P ùëë Probability Vector for functions at depth,  d n # functions in application or # states in model f  ùëñ ,  f ùëó functions along row,  i  or column,  j  in  T t  ùëóùëñ Transition probability from  f  ùëó ùë°ùëú f ùëñ W ùëù Probability calculation time window t Request arrival time d # time steps for which transitions are done PL ùë° Scalar that represents the anticipated # requests at time,  t NC ùëë ùë° # containers needed for functions at depth  d , at time  t Table 3: Notations used in Equations.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 228,
    "augmented": true
  },
  {
    "text": "[106] R. Zhang, H. Tao, L. Wu, and Y. Guan, ‚ÄúTransfer learning with neural \networks for bearing fault diagnosis in changing working conditions,‚Äù Ieee Access , vol. 5, pp. 14 347‚Äì14 357, 2017.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Detailed guidelines for selecting these hy- perparameters are provided in Appendix  A . Briefly, these parameters should be chosen to ensure that:  (1)  Œ≥  suffi- ciently incentivizes correct participation without leading to excessive energy expenditure. (2)  Œ¥  appropriately penalizes incorrect inferences, discouraging low-quality data contri- butions.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Opt. (2019), A258‚ÄìA266. [63]  Yang Wu, Jun Wang, Chun Chen, Chan-Juan Liu, Feng-Ming Jin, and Ni Chen.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "1 Introduction \nMachine Learning (ML) has revolutionized user experience in various cloud-based application domains such as product recommendations [ 70 ], personalized advertisements [ 44 ], and computer vision [ 13 ,  43 ]. For instance, Facebook [ 44 ,  82 ] serves trillions of inference requests for user-interactive ap- plications like ranking new-feeds, classifying photos, etc. It is imperative for these applications to deliver accurate predic- tions at sub-millisecond latencies [ 27 , 34 , 35 , 39 , 44 , 83 ] as they critically impact the user experience.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "AASR thus bridges the major gaps in the design that we intend to achieve. After receiving or recalling prediction from all sensors, the host performs a majority voting for the Ô¨Ånal classiÔ¨Åcation. The host device remembers the most recent classiÔ¨Åcations by all of the sensors.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "[51]  C. Moreno, Y. Chen, and M. Li, ‚ÄúA dynamic compression technique for streaming kinect-based point cloud data,‚Äù in 2017 International Conference on Computing, Networking and Communications (ICNC) . IEEE, 2017, pp. 550‚Äì555.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "5%  w.r.t. DNN inference for YOLOv3). To implement these three possible decisions (FI, SI, and PI) that can be made by the  Decision Maker , the  Inference Engine  in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "[71]  Richard Socher, Yoshua Bengio, and Chris Manning. US Patent 7,809,601. Deep learning for nlp.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "The overall design of our proposed  HoloAR framework is illustrated in Fig. First,  HoloAR  utilizes the exist- ing viewing-window based technique [52] (denoted \na  ) to skip the hologram computations for the objects which are outside of the current viewing window, in a ‚Äújust-in-time‚Äù fashion. 6a.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "The key compo- nents of  Kraken  are (i)  Kraken  employs a Proactive Weighted Scaler (PWS) which deploys containers for functions in ad- vance by utilizing a request arrival estimation model. The number of containers to be deployed is jointly determined by the estimation model and function weights. To address these challenges, we propose  Kraken , a DAG workflow-aware resource management framework specifi- cally catered to dynamic DAGs, that minimizes resource con- sumption, while remaining SLO compliant.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "[94] Synopsys, ‚ÄúStandard cell libraries,‚Äù  https://www.synopsys.com/dw/ \nipdir.php?ds=dwc standard cell , (Accessed on 04/28/2023). [95] E. Talpes, D. Williams, and D. D. Sarma, ‚ÄúDojo: The microarchitecture \nof tesla‚Äôs exa-scale computer,‚Äù in  2022 IEEE Hot Chips 34 Symposium (HCS) . [93] Synopsys, ‚ÄúDesign compiler,‚Äù https://www.synopsys.com/ implementation-and-signoff/rtl-synthesis-test/dc-ultra.html , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 172,
    "augmented": true
  },
  {
    "text": "199‚Äì208. https: //doi.org/10.1109/CLOUD.2019.00043 [32]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Nachiappan C Nachiappan, Mahmut Taylan Kandemir, and Chita R Das. 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "In this case, the found leaf  L 1 - I , which contains two points ( P 0 and  P 1 ), is a perfect match; however, no match can be found for the  L 2 - P  leaf. Next, for each leaf node/block in the P-MB-Tree, the entire I-MB-Tree needs to be traversed in a top-to-down fashion, and the exactly-matched leaf in the I-MB-Tree is found. 7 ), the macro-block based state-of-the-art approach [ 48 ] Ô¨Årst needs to generate two macro block trees (where the minimum voxel dimension in this tree is of a predeÔ¨Åned size) ‚Äì one for I-Frame and the other for P-Frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 181,
    "augmented": true
  },
  {
    "text": "[75] J. Redmon and A. Farhadi, ‚ÄúYolov3: An incremental improvement,‚Äù \narXiv preprint arXiv:1804.02767 , 2018. [76] G. V. Research, ‚ÄúConsumer iot market size, share and trends \nanalysis report by component (hardware, services), by connectivity technology (wired, wireless), by application (healthcare, wearable devices), and segment forecasts, 2023 - 2030,‚Äù https://www.grandviewresearch.com/industry-analysis/consumer- iot-market-report#: ‚àº :text=The%20global%20consumer%20IoT% 20market,advanced%20devices%20and%20home%20appliances. 2001‚Äì2010.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 189,
    "augmented": true
  },
  {
    "text": "Brandon Haynes, Maureen Daum, Dong He, Amrita Mazumdar, Magdalena Balazinska, Alvin Cheung, and Luis Ceze. Vss: A storage system for video analytics. URL  https://doi.org/10.14778/3229863.3236256 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "3a, and give the details of the proposed partial inference (PI) scheme in Fig. 6. Recall that, Frame-1, as the base frame, has to do the full inference (Step  1  ), and output the feature maps for each layer (Step  2  ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "In the  i th   kernel scheduling iteration, given the power budget and power prediction, the \nmicro-proÔ¨Åler decides the required training conÔ¨Åguration, and the control logic (conservatively) enables suitable number of tiles (say  t i  tiles of the 256 tiles). Those  t i  tiles fetch  t i unique kernels from the 1Byte wide, 256 deep global kernel dispatch queue (GKDQ,  t i  kernels scheduled in parallel ). Note that the power requirement of each tile is known in advance (please refer to ¬ß V , TABLE  I  for details).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Edgepc: Efficient deep learning analytics for point clouds on edge devices. In  Proceedings of the 50th Annual International Symposium on Computer Architecture , ISCA ‚Äô23, New York, NY, USA, 2023. Asso- ciation for Computing Machinery.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "IEEE, 2020. Scale-sim: Systolic cnn accelerator simulator. [138] Ananda Samajdar, Yuhao Zhu, Paul Whatmough, Matthew Mattina, and Tushar Krishna.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "They will not only evaluate whether the individual and intermediate research goals have been achieved or not, but  will also discuss the progress towards achieving the educational and outreach/BPC goals of the project. Collaboration Logistic \nThe PIs will meet regularly to assess the overall progress of the project. Year 3 \nTHRUST-I:Algorithmic  \nSupport for Ensemble  \nof Experts \n2.1 Data Locality and Parallelism-Aware LLM Training \nTHRUST 2: System  \nSupport for Expert  \nScheduling and Data  \nMovements \n3.1 Expert/Hardware Co-Characterization \nTHRUST 3:  Chiplet- \nbased Adaptive and  \nReconfigurable  \nHardware Platform \nCurriculum Development, Undergraduate Research Involvement, Training in Galaxy Community, Industry Outreach, Result  \nDissemination  \nBPC, K-12, Undergraduate Honors, Science-U \n1.1 EoE Design Space Exploration \n1.2 Constructing Morphology of EoE \n2.2 Router Retraining \n2.3 Using Hot and Cold Experts: Caching and Prefetching \n3.2 Chiplet-Based Modular Hardware Platform \n1.3 Continual Adaptation of LLM Experts \n3.3 Handling Unforeseen Cases using Reconfiguration \nTHRUST 4:  \nEvaluation  \nand Fine  \nTuning \n4.1 Evaluation Infrastructure: Experiments + Simulation + Analytical Modeling \n1.4 Algorithmic Choices Informed by System & Hardware Constraints \nYear 2 \nYear 1 \n2.4 KV Cache Management \n2.5 Runtime Support \n2.6 Fault Tolerance \n4.2 Methodology \n3.4 Going beyond with Hardware Software Co-optimization \nFigure 8 :  Project timeline that shows both research and educational/outreach efforts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 365,
    "augmented": true
  },
  {
    "text": "¬¥as to effectively perform more computation with an intermittent power source. As shown in Fig. 11b ,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "the accuracy, while short latency models need to be ensem- bled to reach the same accuracy. For accuracy greater than 80%, the ensemble size drops with higher latencies. This is because the models which offer higher accuracy are typically dense and hence, smaller ensembles are sufÔ¨Åcient.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "E XPERIMENTAL  E VALUATION AND  R ESULTS \nIn this section, we describe our evaluation methodology and evaluate both privacy-preserving and data-sharing partitioning strategies compared with a traditional random-forest approach. Random sampling of decision trees, albeit a na¬®ƒ±ve way, has been empirically shown to work well in preserving model characteristics and providing accurate predictions. III.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "37‚Äì46, Dec 2017. [21]  M. Zhao, C. Fu, Z. Li, Q. Li, M. Xie, Y. Liu, J. Hu, Z. Jia, and C. J. Xue, ‚ÄúStack-size sensitive on-chip memory backup for self-powered nonvolatile processors,‚Äù  IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) , vol. 36, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. [107] S. Zhao, H. Zhang, S. Bhuyan, C. S. Mishra, Z. Ying, M. T. Kandemir, \nA. Sivasubramaniam, and C. R. Das, ‚ÄúD¬¥eja view: Spatio-temporal compute reuse for ‚Äòenergy-efÔ¨Åcient 360 vr video streaming,‚Äù in  2020 ACM/IEEE 47th Annual International Symposium on Computer Archi- tecture (ISCA) . Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "8b, the latencies for GL1 and HC1 only decrease by around  38% , while the energy saving is about  37% , which is lower than the corresponding savings for V1 ( 59% ) and V2 ( 53% ). Thus, compared to V1 and V2 whose latencies can be decreased by  62%  and  55%  respectively with FI+SI as shown in Fig. Additionally, even with our proposed PI technique, the improvements for GL1 and HC1 with YOLOv3 model are not very signiÔ¨Åcant (e.g., the latency reduction is improved by  4% for GL1 as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "Our exploration will focus on various types of router functions to direct user queries to appropriate experts, different expert model architectures, and composition functions to  ag- gregate  expert outputs. A Unified View of EoE Function Choices. We define three building blocks of an EoE system: ‚ÄúRouting‚Äù, ‚ÄúExpert‚Äù, and ‚ÄúComposition‚Äù.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "However, while inferring at the host, if we are able to recover the data or reconstruct it with minimum error, the accuracy can easily be increased. Clustering Coreset Recovery:  Clustering preserves the geometry of the original data by representing them as a set of N-spherical clusters represented with a center and a ra- dius. In the process of coreset construction we only preserve the coordinates of the centers and the radii of the clusters, and hence miss the coordinates of the points inside the clus- ters.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "[8]  Charles Loop, Qin Cai, Sergio Orts Escolano, and Philip A Chou, ‚ÄúJPEG Pleno Database: Microsoft Voxelized Upper Bodies - A Voxelized Point Cloud Dataset,‚Äù  ‚Äùhttp://plenodb. jpeg.org/pc/microsoft‚Äù . [9]  Charles Thomson, ‚ÄúReality capture 101: point clouds, pho- togrammetry and LiDAR,‚Äù  ‚Äùhttps://bit.ly/3xfqvqy‚Äù , 2019.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "5429‚Äì5438. In Proceedings of the IEEE International Conference on Computer Vision . [55]  Rohan Paul, Dan Feldman, Daniela Rus, and Paul Newman.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "ACM , p. 46‚Äì58, 1991. [37]  K. Lee, J. Yi, Y. Lee, S. Choi, and Y. M. Kim,  GROOT: A Real-Time Streaming System of High-Fidelity Volumetric Videos . [36]  D. Le Gall, ‚ÄúMpeg: A video compression standard for multimedia applications,‚Äù  Commun.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "DeepCache [8] has been proposed for trading layer-wise intermediate data memoization/caching for computation savings, but it ignores the frame-wise reuse op- portunities. Different from these two prior works, Potluck [12] caches the feature vectors (FVs) and correspond- ing inference results for key frames, and reuse the results for other frames with similar FVs, with the costs of FV extraction (e.g., down-sampling [16]) penalty and potential accuracy and/or performance drop due to sampling failures. From the hardware side, Euphrates [9] targets the frame-wise reuse, and customizes an accelerator for searching the regions of interest.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "For two instances of the same class, there should be a very high correlation in the sensor data. 3.2.1 Data Memoization:  Given our focus on ultra low power energy harvesting devices, any opportunities to re- duce computation and communication can noticeably aug- ment the performance and efficiency of the entire system. We look into data memoization as one such opportunity.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Bounding and Selecting Hyperparameters  Œª 1 , Œª 2 \nThe choice of  Œª 1  and  Œª 2  affects the curvature of  J ( Œ∏ )  and can influence convergence speed and the location of  Œ∏ ‚àó . Some guidelines include: \n1. Start with small values of  Œª 1  and  Œª 2  to avoid over- whelming the primary loss  L ( Œ∏ ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "In  Social Informatics: 9th International Conference, SocInfo 2017, Oxford, UK, Septem- ber 13-15, 2017, Proceedings, Part II 9 , pages 378‚Äì390. [161] Li Wang, Wei Zhang, and Mei Huang. Springer, 2017.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "2. If participating: capturing data at their cho- sen SNR, performing inference, and computing local gradients  ‚àá ‚Ñì ( f Œ∏ k ( x ) , y )  on their locally available samples drawn from  D . 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "2020. Bearing fault detection and diagnosis using case western reserve university dataset with deep learning approaches: A review. IEEE Access  8 (2020), 93155‚Äì93178.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "As depicted in Figure 4(b), we train E1, E5, and E7 together as they share datasets, followed by E2, E3, and E6, and the remaining experts. This reduces redun- dant data transfers, lowering latency, and reducing energy consumption. This approach can be further refined by, for instance, adjusting the weights taking into account a) availability/proximity of appropriate compute to the nodes (data should ideally be present on nodes which can leverage well-suited accelerators with relative ease), and b) load balancing across nodes to prevent overburdening specific nodes (thus, avoiding performance interference).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors,  Advances in Neural Informa- tion Processing Systems , volume 34, pages 24545‚Äì24555. Curran Associates, Inc., 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Regular re-tuning may be warranted as oper- ating conditions, energy harvesting patterns, or accuracy requirements evolve over the network‚Äôs lifetime. B. Equilibrium Existence and Convergence with Reward-Based Utility \nIn this appendix, we provide a detailed and formal proof that the best-response dynamics, incorporating the newly defined reward-based utility functions, converge to a Nash equilibrium (NE). We first restate the key assumptions and the utility model.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "IV-C), and one edge VR headset cannot afford to memoize them for all  possible head orientations. To address this, we need to study the impact of head orientation on the computation and whether we can establish a relationship between the computation executed for both the eyes to get rid of any existing redundancies. All these are possible avenues for optimization and demand a detailed study of the computa- \ntion pipeline, the workloads, user behavior, etc., to Ô¨Ånd a way to further improve the state-of-the-art.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "2020. CUDA Toolkit Documentation: Nvprof. \"shorturl.at/zEFU5\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "Proc. ACM Meas. Portfolio-driven resource management for transient cloud servers.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 21,
    "augmented": true
  },
  {
    "text": "By integrating adaptive neural architecture and energy-aware training techniques, NExUME significantly enhances the viability of deploying machine learning models in environments with limited and unreliable energy sources. Specifically, improvements ranging from 6.10% to 17.13% over existing methods highlight NExUME‚Äôs capability to adapt dynamically to fluctuating energy conditions, ensuring both operational longevity and computational integrity. The results from our extensive evaluations demonstrate that NExUME can substantially outperform traditional methods in energy-constrained settings, with improvements in accuracy and efficiency that facilitate real-world applications in remote and wearable technology.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "By integrating the game-theoretic approach with federated learning principles, we reduce communication overhead and ensure that contri- butions to model updates come from sensors best positioned to improve accuracy under energy constraints and uncertain availability. These updates occur only when sensors have sufficient energy to participate meaningfully, guided by the game-theoretic equilibrium strategy. Rather than rely- ing on persistent, centralized updates or continuous feder- ated aggregation, we perform  periodic  or  equilibrium-driven fine-tuning rounds.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "13 √ó  data movement reduction, compared to classical systems. This is particularly evident in continuous learning scenarios prevalent in applications such as autonomous driving and urban mobility, where the volume and complexity of data are immense. Looking ahead, the role of storage systems is poised to become even more pivotal as ML applications continue to evolve and generate larger, more complex datasets.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "NExUME has three interrelated compo- nents: (1)  DynNAS : Intermittency- and platform-aware neural architecture search; (2)  DynFit : Intermittency- and platform-aware DNN training with dynamic dropouts and quantization; and (3) DynInfer : Intermittency- and platform-aware task scheduling for inference. While each component can individually optimize DNNs for intermittent environments, their combination yields the best results. 3 NExUME Framework \nTo address the issues with  intermittency-aware  DNN training and inference, we propose NExUME: ( N eural  Ex ecution  U nder Inter M ittent  E nvironments).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 168,
    "augmented": true
  },
  {
    "text": "Lory: Fully Differentiable Mixture-of- Experts for Autoregressive Language Model Pre-training. arXiv preprint arXiv:2405.03133 , 2024. [195] Zeyang Zhong, Urvashi Khandelwal, Omer Levy, and Dan Jurafsky.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "The host writes the latest copy of the completed iteration (in epoch granularity) into the STT- RAMs (STT-RAM-N for the upper 128 SAs, and STT-RAM- S for the lower 128SAs, Fig. We do  not  replace the DRAM buffers with NVM because of limited lifetimes [ 17 ]. The work queue schedule, intermediate result, network and layer information are saved on predicted power failure, and data from the DRAM (the working set of IF/OF/Ô¨Ålter and model state) are moved to an NV-RAM using STT-RAM based buffers in the memory hierarchy (parallel to the IF/OF/Ô¨Ålter).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "Recent works have started exploiting HW-SW co-optimizations, for example, application-specific software prefetching can be used to tolerate the memory access latencies [70, 71], and L2-cache can be precisely populated with most frequency accessed embeddings [70]. In this design space, we plan to expose various ‚Äúknobs‚Äù from hardware via which software can better monitor and control the execution. Further, in some specific cases of unknown constraints, the software can indicate an expert to  migrate  to another chiplet.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "For example,  User1 has similar interest as  User3 , whereas  User2  focuses more on the bottom left corner. Clearly, such temporal similarity for a particular user‚Äôs interests exposes another opportunity for leveraging prior \n497 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \nfoveated rendering in AR holograms, by reducing the amount of computation needed for the objects which are outside the RoF, thus only emphasizing on the processing of the objects which the user is currently focusing on. Driven by these observations, we next want to study the details of hologram with the goal of addressing two critical questions:  What are the problems in the current state-of-the-art hologram software and hardware?",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 190,
    "augmented": false
  },
  {
    "text": "29‚Äì41, 2020. Keith Chapman, Mehdi Nik, Behnam Robatmili, Shahrzad Mirkhani, and Maysam Lavasani. In  18th USENIX conference on file and storage technologies (FAST 20) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "[92] ‚ÄúSurveillance camera statistics: which cities have the most cctv \ncameras?‚Äù https://www.comparitech.com/vpn-privacy/the-worlds- most-surveilled-cities/ , (Accessed on 11/21/2022). com/learning-center/solar-insolation-maps.html/#Map1 , (Accessed on 11/21/2022). [93] Synopsys, ‚ÄúDesign compiler,‚Äù https://www.synopsys.com/ implementation-and-signoff/rtl-synthesis-test/dc-ultra.html , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "For example, PI Kandemir has previously participated in the organization of a workshop targeting high school teachers and gave a talk on ML and high-performance computing. ‚Ä¢  Summer Research Opportunities for High School Students and Science Teachers:  The PIs has been participating in the organization of various summer activities with high school students and teachers. The research team is planning to organize summer activities with high school students and teachers in the context of this project as well.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "2019. https://doi.org/10.1109/ICDCS.2017.262 [48]  Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R. Das. 977‚Äì987.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "H S/C \nM \nH: Harvest\n S/C: Sense & \nCompute\n M: Communicate \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nDecompress + Infer \n+ Ensemble¬† \nSensor state transition sensor \nHost Legend: \nFigure 3: An example of EH Sensor-Host ecosystem - the sensor transitions between multiple states and executes the compute as store and execute fashion [ 47 ]. The host receives the data in compressed form for the unfinished portion, decompresses it, runs inference and finally ensembles the results from multiple sensors to improve accuracy and robustness. 3 DESIGN SPACE EXPLORATION Since data communication in a sensor host ecosystem (Fig- ure 3) consumes substantial power, we rely on coresets as an efficient way to lossily communicate the features with minimal information degradation.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 193,
    "augmented": false
  },
  {
    "text": "5:  Simulation-Refinement Loop: 6:  for  k  = 1 ,  2 , . If participation is overly aggressive, reduce  Œ≥ 0  or increase  Œ¥ 0 . If preliminary tests show insufficient participation, slightly increase  Œ∑ 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Furthermore, when the deployments are geo-distributed and operated by different owners, the privacy concerns on sharing the data with a third party cloud service provider becomes challenging in developing the analytics solutions. A. Data-Shared Edge-Cloud Policy \nFirst, we consider a distributed sensor model, where each device is equipped with a small compute capability to perform analytics using random forests, and each individual device is trained on its own data. Next, we consider a model where multiple devices from multiple deployments participate in cooperative data sharing.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "By doing this,  Us. Consequently, this exemplar set becomes the training data for the continuous learning, which consequently minimizes the drift. Once the student model is trained with the exemplar set, the data is discarded and the feature space for the teacher models is updated.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications . 106‚Äì111. [68]  Haibo Zhang, Prasanna Venkatesh Rengasamy, Shulin Zhao, Nachiappan Chi- dambaram Nachiappan, Anand Sivasubramaniam, Mahmut T. Kandemir, Ravi Iyer, and Chita R. Das.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Combining the  Recall  with AAS (which we term as AASR - Activity Aware Scheduling with Recall) opens possibilities for getting a more accurate classiÔ¨Åcation. To minimize the communication overhead, and to ensure participation of all sensors, we build the  recall  strategy into the host device. The host device remembers the most recent classiÔ¨Åcations by all of the sensors.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "None of  Naive1  and  Naive2  executions can go through power cycle  PC-i  and the power utilization is very low, as there is a signiÔ¨Åcant mismatch between the power producer and consumer. This execution strategy is referred as Naive2 . In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "MITP-Verlags GmbH & Co. KG, 2018. Stratus: Cost-aware container scheduling in the public cloud. [23]  Andrew Chung, Jun Woo Park, and Gregory R. Ganger.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "PI Zhang has participated in the 2024 summer camp, and he will lead this effort for the future years. This summer camp has been very successful, and we plan to extend it to additional school districts. ‚Ä¢  Summer Research Opportunities for High School Students and Science Teachers:  The PIs has been participating in the organization of various summer activities with high school students and teachers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "IEEE, 2012. 3354‚Äì3361. In  2012 IEEE conference on computer vision and pattern recognition , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "What distinguishes these data is their diverse origin, span- ning from IoT devices to wearables, and their acquisition from challenging environments, including autonomous driving and urban mobility scenarios. Consequently, they frequently ex- hibit a phenomenon known as ‚Äúdata drift‚Äù, where the incoming data deviates from the distribution of the originally trained model, leading to degradation in inference accuracy. Mitigating Data Drift:  Dealing with data drift in edge com- pute nodes presents a signiÔ¨Åcant challenge.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "We will explore several directions for estimating  I W i  efficiently such as using a memory-efficient zeroth-order optimizer to estimate gradients using only forward passes [101]. To merge experts into a single one, assuming we have  n  experts each with parameter  Œ∏ i , i  = 1 , . .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "In  2009 IEEE Conference on Computer Vision and Pattern Recognition , June 2009. Imagenet: A large-scale hierarchical image database. [30]  Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Then, the execution process the ‚Äú data loading ‚Üí Mac computing ‚Üí data storing ‚Äù steps in a sequential way to perform convolution operations. The hardware design details will be presented in Section V. \nIV. At runtime, each time when entering a new power cycle, we Ô¨Årst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "In our evaluations and experiments, we used the equirectangular format [52], which is one of the most popular projection formats. The  Projection Mapping  stage (  c  in Fig. The details of these formats are in the purview of cartography and computer graphics domain, and hence we do not evaluate all of the aforementioned formats.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "2020. \"https://github.com/google- research-datasets/Objectron/blob/master/index/cup_annotations\". Objectron Dataset Annotation: cup.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Autoscaling the instances equally for every model based on predicted load, would inherently lead to over-provisioned instances for under-used models. To address this concern, we design a weighted autoscaling policy which intelligently auto-scales instances for every pool based on the weights. As shown in Algorithm  2 , weights are determined by frequency in which a particular model is chosen for requests ( get_popularity ) with respect to other models in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "Classically, neural codecs compress each frame by treating them like images. However, video data often comes with a large amount of inter-frame similarity (Ying et al., 2022b; Zhang et al., 2017; Zhao et al., 2020, 2021; Ying et al., 2022a). One major issue with neural codecs are their lack of utilization of inter-frame similarity.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "¬¥as  delivers 4.96% more accurate classiÔ¨Åcation compared to a na¬®ƒ±ve learner, and the morphable hardware design uses intermittent computing to maintain forward progress even while running on lower power budget. ¬¥as , a sustainable continuous learning platform, which can perform video analytics by using an inter- mittent power source like solar power. The learning algorithm of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Five PhD students, supported through this project, have graduated and one has joined as a faculty. Major Results: The main research results so far from this project appear in [70,71,129,140,150,153,156,174,175,179,190]. Award # 2338418 (CAREER: Trustworthy Human-Centered Summarization); PI: Zhang; duration=09/15/24-08/31/29; amount=$546,000.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "[99] Zichang Liu, Aditya Desai, Fangshuo Liao, Weitao Wang, Victor Xie, Zhaozhuo Xu, Anastasios Kyril- lidis, and Anshumali Shrivastava. arXiv preprint arXiv:1810.05270 , 2018. Rethinking the value of network pruning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Backward pass:  The sensor computes  ‚àá Œ∏ ‚Ñì ( f Œ∏ k ( x ) , y ) via standard backpropagation. To incorporate regu- larizers, the sensor (or the aggregator after collecting updates) adds  Œª 1 ‚àá ‚Ñ¶ SNR ( Œ∏ k )  and  Œª 2 ‚àá ‚Ñ¶ complexity ( Œ∏ k ) . These gradients are computed analytically since the regularizers are explicit, differentiable functions of  Œ∏ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "The execution equivalency can be transferred by Tile count 2   =  Tile count 1   √ó  n 1 /n 2 . The next power cycle‚Äôs level information cannot be known with certainty. Considering a transition \nfor one layer from an activation solution  ‚ü® m 1 , n 1 , aG 1 ‚ü© to ‚ü® m 2 , n 2 , aG 2 ‚ü© , we Ô¨Ånd that, if the expression  Condition trans : ( m 1 =  m 2)&( n 2  |  ( Tile count 1   √ó  n 1))&( aG 1 =  aG 2) is true for each convolution layer, the activation solution ‚ü® m 1 , n 1 , aG 1 ‚ü© with power level PL1 can be transferred to be equivalent to an execution of activation solution  ‚ü® m 2 , n 2 , aG 2 ‚ü© with PL2.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 214,
    "augmented": true
  },
  {
    "text": "ACM Trans. 2019. Foveated AR: Dynamically-Foveated Augmented Reality Display.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 24,
    "augmented": true
  },
  {
    "text": "Define ‚ÄòQuantaTask‚Äò as the minimum iterations that can run. 2. Decomposable loops: Each ‚ÄòQuantaTask‚Äò runs a certain part of the loop.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Both the PWS and RS collect metrics, such as the current container count, load history and request rate for a function for a given time window, from  Prometheus  and the  Kubernetes system log, using the Replica Tracker and Load Monitor mod- ules. The load to each function within each applica- tion is calculated separately using the collected information. Although fetching function metrics incurs a latency in the order of tens of milliseconds, it is performed in the back- ground (during autoscaling) and hence, does not affect the critical path.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "Others have proposed to design efficient and lightweight deep neu- ral networks (DNNs) to achieve high quality scene rendering at the edge device itself, but this requires model retraining/tuning for a particular user [ 33 ,  54 ]. Apart from the above works targeting all areas in a scene,  foveated rendering  techniques have been pro- posed to reduce image resolution in the peripheral area (typically beyond 135 ¬∞  vertically and 160 ¬∞  horizontally in human visual system (HVS)), while maintaining a normal/high quality only for 5 ¬∞  foveal vision [ 2 ,  22 ,  25 ,  47 ,  62 ]. Such differential resolution within an image can reduce computational costs without significantly impacting user experience [ 25 ,  47 ,  62 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 173,
    "augmented": false
  },
  {
    "text": "However, it misses the opportunities of frame-level data reuse, and hence needs to perform inference for each and every frame. Thus, as shown \n1082 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Kraken  is seen to reduce con- tainer overprovisioning when applications have numerous possible workflows and enough slack per function to exploit. Notably,  Kraken  spawns nearly 80% less containers for  Social Network  in comparison to  Arch . Container overprovisioning is inflated 15% more than the corresponding real system re- sult, due to the large-scale traces.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Here‚Äôs a simplified breakdown of the process: \n1. Energy Capture : The setup begins with a harvester, such as a solar panel, piezoelectric sensor, or thermocouple. These devices are designed to collect energy from their surround- ings‚Äîlight, mechanical vibrations, or heat, respectively.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "? presents simulation results and Section  ? concludes with a discussion of limitations and future work.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "LiDAR maps spatial relationships and shapes by measuring the time taken by signals to bounce off objects and return to the scanner, while photogrammetry takes many photos from different angles to capture the target‚Äôs geometry [ 9 ]. This process typically takes 10s of milliseconds [ 26 ]. Further, each point in the PC is associated with 3 coordinates (x, y, z) for the geometry and 3 colors (R, G, B) for the attribute.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Recent works [5], [6] suggest that processing data at the source is more efÔ¨Åcient that sending them to the cloud and getting the results back, owing to the power and latency overhead of data communication. They propose optimizations to efÔ¨Åciently execute the DNNs on low power IoT devices [7], [8]. Other recent works [9], [5], [7], [8] have proposed using energy harvesting (EH) solutions to provide additional energy and increase the battery life in IoT devices.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "This design optimizes the DNN execution in an energy harvesting wireless sensor network by collectively looking into all the involved components. In the earlier case of na¬®ƒ±ve scheduling we tried to build an efÔ¨Åcient DNN by applying energy aware pruning [15]. The DNNs as indi- viduals are optimized before to meet the power budget.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "13, no. 12, p. 123001, 2018. [4] J. Albericio, P. Judd, T. Hetherington, T. Aamodt, N. E. Jerger, and \nA. Moshovos, ‚ÄúCnvlutin: Ineffectual-neuron-free deep neural network computing,‚Äù  ACM SIGARCH Computer Architecture News , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Thus, for a DAG with  ùëõ functions, the transition probabil- ity matrix,  ùëá , is an  ùëõ √ó  ùëõ matrix, where  ùëõ is the total number of states and each entry,  ùë° ùëóùëñ , is the transition probability from the state corresponding to the function along the col- umn j, ( ùëì ùëó ), to that of the function along the row i, ( ùëì ùëñ ). An example of a Transition Matrix for the  Social Network , with 11 functions, is depicted in Figure 5. The weight for each function corresponds to the state transition probability from the start state to the current one (note that this may require possibly transitioning through a number of intermediate states).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": ". . , f n } 2:  Output:  Compressed frames  C  =  { c 1 , c 2 , .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": ", m n ]  where  m i  ‚àà{ 0 ,  1 } . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Optimal Brain Damage Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ≤ .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "However, prior works do not consider other avenues for optimizing the computation. In this context, this paper dives deep to understand the projection computation pipeline for ex- ploring available opportunities and optimizations for speedup as well as power savings. Since  head movement  and  cor- relations between the left and right eye projections  are the two critical components of the projection computation, we analyze and study them to explore possible opportunities to exploit these relations.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "In  MICRO-54: 54th Annual IEEE/ACM International Sympo- sium on Microarchitecture (MICRO ‚Äô21), October 18‚Äì22, 2021, Virtual Event, Greece. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3466752.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Distilling the essence of raw video to reduce memory usage and energy at edge devices. [179] Haibo Zhang, Shulin Zhao, Ashutosh Pattnaik, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. arXiv preprint arXiv:2309.05444 , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Reducing the SLO, in turn, can potentially reduce the batch sizes of functions as well. Moreover, the reduced SLO target results in increased SLO violations across all policies. However,  Kraken  is able to \nmaintain at least 99.5% SLO guarantee and spawns 50%, 34% and 15% less containers compared to  Arch ,  Fifer  and  Xanadu , respectively.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "8a. With the PI scheme, as shown in Fig. 8d and Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout with learnable mask parameters, along with the QuantaTask optimization to handle energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "The power source is denoted in  (Red) (notations used in Figure 1b: COTS: Commercial-off- the-shelf, Bat. The size of the circle representing the solutions de- picts the compute capabilities of the sensor nodes, the shade shows the available power, and their position on the axes approximates the amount of compute done on the node and the amount of reliability on external communication. : Battery, Bonito [ 22 ], Chinchilla [ 43 ], ResiRCA [56], Origin [47]) \ncompute are not energy efficient to run with all modali- ties of harvested energy since all of them do not have the same energy income (see Figure 1b).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "In this case, offloading computations to a resource-rich cluster/cloud system would be a more reasonable design choice (instead of approximating on the edge). Second, for applications, which are motion-sensitive \nsuch as the spaceship simulation [ 34 ], the hologram computation process is required to complete faster, in order to correctly reflect the current user‚Äôs eye movement and head pose in real-time. The proposed  HoloAR  on the edge GPU cannot achieve such strict la- tency requirement, and can cause lagging, e.g., the eye could move to another area, while the hologram is still being computed for the previous focus region.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Kraken  also performs similar to  Fifer , while using 58% reduced containers for  Social Network . From Figures 9 and 10, it can be seen that  Xanadu  has similar (or worse) end- to-end response times than  Kraken  (up to 50 ms more), but \nspawns more containers as well (up to 70% more) and satisfies fewer SLOs on average (0.2% lesser). However,  Arch  uses 4x the number of containers used by  Kraken  (Figure 10a).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "However, when applied to low-dimensional sensor data, classical lossy compression techniques tend to discard or distort some important fea- tures, which significantly degrades the inference accuracy. To mitigate the shortcomings of classical compression tech- niques, recent works [ 7 ,  36 ,  37 ] propose using  coresets , a data representation technique from computational geometry that preserves important, representative features when building a compressed form of the data, and thereby reducing the pay- load size while preserving data integrity for efficient edge communication. Although, with the help of coresets, one can efficiently offload minimal input representations to a more compute-capable device, performing accurate inference on coresets is non-trivial due to their low-dimensional nature.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 172,
    "augmented": true
  },
  {
    "text": "The department operates its own firewall infrastructure using Palo Alto, Cisco, and Sonicwall products. The CSE department at Penn State currently maintains copies of the LLVM compiler toolset, various LLM models, as well as various ML packages and HPC libraries. Other Resources:  Penn State Institute for Computational and Data Sciences (ICDS), of which Mahmut Kandemir is an associate director, provides a variety of compute, storage and network resources, various IT services, including operations, backup, technical consulting, and training material, and is compliant with specific NSF, NIH, and NIST security controls.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "[32]  I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, ‚ÄúQuantized neural networks: Training neural networks with low precision weights and activations,‚Äù  J. Mach. Learn. Res.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "[58]  Nvidia Corporation, ‚ÄúJetson AGX Xavier Developer Kit,‚Äù \n‚Äùhttps://bit.ly/3oWQNtH‚Äù , 2018. 297 \nAuthorized licensed use limited to: Penn State University. [57]  New Farmer Blogger, ‚Äú3D points clouds for immersive real es- tate and telepresence experiences,‚Äù  ‚Äùhttps://bit.ly/3AhWQR5‚Äù , 2015.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "For instance, both  Clipper  and  InFaas  employ variants of a reactive autoscaler as described in Section  4.2.2 . Both  InFaas and  Clipper  share  Cocktail ‚Äôs implementation setup to ensure a fair comparison with respect to our design and execution environment. However, in our setup, both beneÔ¨Åt from the distributed au- toscaling and prediction policies, thus eliminating variability.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Ensemble-spot is explained further in the next section. We run the experiment over a period of 1 hour for 10 requests/second. The cost is calculated as the cost per hour of EC2 c5.xlarge instance use, billed by AWS [ 5 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "In  13th USENIX Symposium on Operating Systems Design and Imple- mentation (OSDI 18) , pages 611‚Äì626, Carlsbad, CA, October 2018. [52]  Yunseong Lee, Alberto Scolari, Byung-Gon Chun, Marco Domenico Santambrogio, Markus Weimer, and Matteo Interlandi. PRETZEL: Opening the black box of machine learning prediction serving systems.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "2. We quantitatively evaluate prior works [ 5 ,  9 ,  10 ] which are geared towards achieving this vision and show that they still suffer from several issues when trying to solve the complex problem of combining model and resource heterogeneity. 3.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, the SOTA geometry compression pipeline includes Ô¨Åve stages which can be summarized as follows: ‚Ä¢  Raw Frame (Input):  The input raw PC frame contains several (usually millions of) points, carrying both geometry and attribute information. Only the geometry data are forwarded to the upper geometry compression pipeline. ‚Ä¢  Octree Construction:  With the input geometry data, the octree construction algorithm is invoked to add the points and update the tree (e.g., the maximum depth required for inclusion of a point, occupancy information for nodes, etc.)",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "To expedite the process, where it makes sense, the PIs will team up the new students with the older ones in paper writing process. Publications and Presentations \nThe PhD students will receive guidance and training in the preparation of manuscripts for scientific journals and presentations at conferences and workshops. They will have access to courses on Effective Communi- cation and Presentation Skills.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "[48]  Abeer Abdel Khaleq and Ilkyeun Ra. Cloud-based disaster manage- ment as a service: A microservice approach for hurricane twitter data analysis. In  GHTC , 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Let  e max total   = e max cap   + e inf   + e comm   represent the maximum energy cost (for a chosen SNR mode). A baseline condition that ensures correct participation can overcome occasional penalties is: \nŒ≥  ¬∑  ‚àÜ A min  > Œ¥  +  e max total   . This inequality implies that even in a worst-case scenario for accuracy gain, the net expected benefit of correct par- ticipation surpasses the sum of potential incorrect penalties and energy costs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Although model sharing, instead of data sharing, solves some of the challenges [5], such approaches are not trivial to deploy in classical learning paradigms, like random forests. In smart manufacturing, multiple machines, even of the identical make and model, can generate different artifacts while encountering the same fault due to different physical interference such as resonant frequency and ambient tem- perature. The ability to capture diverse conditions from the different nodes, with or without sharing data, can lead to more robust models.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "SProb  does worse than  DProb  at the tail because of its lack of adaptive probability estimation. Kraken  makes use of 21% more containers to achieve the improved latencies. Xanadu  experiences a sudden rise in tail latency, with it being 100ms more than that of  Kraken , while using 96% more containers.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Xanadu  experiences a sudden rise in tail latency, with it being 100ms more than that of  Kraken , while using 96% more containers. This is due to  Xanadu ‚Äôs MLP misprediction and the resultant container over-provisioning. Energy Efficiency:  We measure the energy-consumption as total Energy consumed divided over total time.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "[69]  Z. Que, G. Lu, and D. Xu, ‚ÄúVoxelcontext-net: An octree based framework for point cloud compression,‚Äù in  CVPR , 2021, pp. 6042‚Äì6051. [70]  Ricci Rox, ‚ÄúPower-hungry Snapdragon 8 Gen 1 gets trounced by the Apple A15 Bionic in real-world gaming test,‚Äù  ‚Äùhttps: //bit.ly/3P086pp‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "¬¥as  with other possible solutions. Sustainability:  To ensure sustainable and continuous learning at the edge,  Us. ¬¥as 95.3 1.92 7 - 10 years \nTABLE III: Comparing  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Since processing these critical regions is in general much lighter-weight than processing a whole frame due to smaller size and less computation, the proposed partial inference is able to minimize the unnecessary computation (on the background/unimportant regions), thereby further speeding up the inference and reducing the energy consumption. ‚Ä¢  Then, we implement and experimentally evaluate our pro- posal on a representative mobile device ‚Äì the Pixel 3 Phone [20] ‚Äì and collect detailed experimental results, using 6 different video streams. Our proposed frame-level reuse shows  ‚âà 53%  of the frames to be redundant and hence skips the inference, leading to only less than  1%  accuracy loss.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "The faiss library. arXiv preprint arXiv:2401.08281 , 2024. Sourav Dutta and Chinwe Ekenna.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "Keyformer: Kv cache reduction through key tokens selection for efficient gener- ative inference. In P. Gibbons, G. Pekhimenko, and C. De Sa, editors,  Proceedings of Machine Learning and Systems , volume 6, pages 114‚Äì127, 2024. [8] Niket Agarwal, Tushar Krishna, Li-Shiuan Peh, and Niraj K Jha.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Holographic Near- Eye Displays Based on Overlap-Add Stereograms. 2019. ACM Trans.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "[17]  J. Elseberg, D. Borrmann, and A. N ¬® uchter, ‚ÄúOne billion points in the cloud ‚Äì an octree for efÔ¨Åcient processing of 3d laser scans,‚Äù  ISPRS Journal of Photogrammetry and Remote Sensing , pp. 76‚Äì88, 2013. [18]  Eugene d‚ÄôEon, Bob Harrison, Taos Myers and Philip A. Chou, ‚ÄúJPEG Pleno Database: 8i Voxelized Full Bodies (8iVFB v2) - A Dynamic Voxelized Point Cloud Dataset,‚Äù  ‚Äùhttps://bit.ly/ 3cJQ61a‚Äù , 2017.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "Dynamic adjustment of computational tasks based on both energy and task criticality. These innovations enable efficient and reliable DNN inference under intermittent power conditions, differentiating our work from existing energy-aware schedulers. Rationale Behind Method Design:  The overall method design of NExUME is motivated by the need to enable DNNs to function reliably in environments with intermittent and unpredictable energy supply.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Chipper: A low-complexity bufferless deflection router. In  2011 IEEE 17th International Symposium on High Performance Computer Architecture , pages 144‚Äì155. IEEE, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "Salient Store  also provides a hardware accelerated lattice-based quantum safe encryption mechanism. To tightly integrate these solutions to the storage space, while providing data security,  Salient Store uses computational storage devices (CSDs) (AMD, b) which reduce the energy consumption while keeping the compute pipeline unaltered. Our main  contributions  include: \n‚Ä¢  We propose design of a hybrid storage pipeline equipped with computational storage drives (CSDs) where the different drives could communicate with each other in a peer-to-peer fashion.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "append ( model weight ) 7: end for 8: end for 9: if  Predicted_load  ‚â• Current_load  then 10: for  model in  ‚àÄ Models  do 11: I_n  ‚Üê (Predicted_load - Current_load) √ó model weight 12: launch_workers ( est_VMs ) 13: model.workers.append ( est_VMs ) 14: end for 15: end if 16:  end procedure \nof weighted voting in breaking ties is discussed in Section  6 . 4.2 Resource Management \nBesides model selection, it is crucial to design an optimized resource provisioning and management scheme to host the models cost-effectively. We explain in detail the resource procurement and autoscaling policy employed in  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "In networks of energy harvested sensors, the power-hungry nature of commu- nication results in intermittent coordination failures due to one or more of the sensors, or even the fusing node itself, lacking sufÔ¨Åcient energy at the time that inter-node communication is required. This work aims to address this limitation by pursuing answers to the following questions -  1) how do we leverage mul- tiple available energy harvesting wireless sensors collectively, and 2) where should each individual sensor perform its own inference, considering that they collectively perform a single task? Our approach to address these questions relies on decen- tralizing the DNN execution and letting each sensor perform its own inference.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "In  2014 IEEE symposium on computational intelligence in ensemble learning (CIEL) , pages 1‚Äì6. [64]  Xueheng Qiu, Le Zhang, Ye Ren, Ponnuthurai N Suganthan, and Gehan Amaratunga. Ensemble deep learning for regression and time series forecasting.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. This paper presents the  ResiRCA  architecture that integrates a new, lightweight, and conÔ¨Ågurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node. To maximize ResiRCA throughput under different power levels, we develop the  ResiSchedule  approach for dynamic RCA reconÔ¨Åguration.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "II, most existing optimizations focus on accelerating the inference processing/computation only and not fully understand the underlying characteristics of the input data, and thus some input-speciÔ¨Åc optimization opportunities could be easily missed. For example, for the mobile video inference application considered in this paper, the input data \nare continuous video frames, and can potentially contain rich ‚Äúsimilarity‚Äù across different frames. To explore these opportunities, Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Accuracy Met (%) Scheme Strict Relaxed InFaas 21 71 Clipper 47 89 Cocktail 56 96 \nTable 6:  Requests meeting target accuracy averaged for both Trace. Both  Clipper  and  Cock- tail  can meet the ac- curacy for 56% of re- quests, which is 26% and 9% more than  In- Faas  and  Clipper  re- spectively. This is be- cause, intuitively ensembling leads to higher accuracy than single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "2. The home owners may or may not be willing to share the sensor measurements of their home for privacy reasons. We divide the data into training and testing sets, and to simulate a distributed environment, the training data is further divided into multiple different chunks (starting from 2 to 4, each part representing a household in the same neighbourhood).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "¬¥as  can save up to 200lbs of  CO 2  per year compared to a state of the art accelerator running on the grid. VIII. A CKNOWLEDGMENTS \nWe would like to offer our thanks to the anonymous reviewers for their detailed feedback, which has greatly helped to improve and reÔ¨Åne this paper.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "However, all these works focus on the analytics part while overlooking one critical aspect:  what happens to all those video data after the analytics? Recent works try to solve this problem by augmenting these continuous learning edge servers with application-specific hardware targeted for intermittent computing which could run using solar power. Data Archival:  The answer is straightforward, especially for mission-critical public records like urban mobility and surveillance data: these need to be archived in a local storage to avoid under- mining the benefits of edge computation, i.e.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "As the number of storage servers increases, the network contention and data orchestration challenges exponentially increase. Fig. 10 shows the impact of scaling  Salient Store  with respect to a single node system, i.e., a single storage server.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "This changes the to- tal number of states from  ùëõ to  ùëÅ , the number of extended states, resulting in a larger Transition Matrix and Probability Vector. To calculate the required number of containers for a single function that has multiple context-independent states associated with it, we take the sum of the calculated values for all of those states. for the previous equations to hold.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Due to this, one can observe from Fig. 9 that, to execute the same amount of the projection computation, the  PTU  scheme consumes only  62%  of energy w.r.t. the  Baseline , which contributes to  20%  total energy saving.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "[95] E. Talpes, D. Williams, and D. D. Sarma, ‚ÄúDojo: The microarchitecture \nof tesla‚Äôs exa-scale computer,‚Äù in  2022 IEEE Hot Chips 34 Symposium (HCS) . IEEE Computer Society, 2022, pp. 1‚Äì28.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Apart from the above works targeting all areas in a scene,  foveated rendering  techniques have been pro- posed to reduce image resolution in the peripheral area (typically beyond 135 ¬∞  vertically and 160 ¬∞  horizontally in human visual system (HVS)), while maintaining a normal/high quality only for 5 ¬∞  foveal vision [ 2 ,  22 ,  25 ,  47 ,  62 ]. Such differential resolution within an image can reduce computational costs without significantly impacting user experience [ 25 ,  47 ,  62 ]. Others have proposed to design efficient and lightweight deep neu- ral networks (DNNs) to achieve high quality scene rendering at the edge device itself, but this requires model retraining/tuning for a particular user [ 33 ,  54 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 173,
    "augmented": true
  },
  {
    "text": "The load prediction model resides in the master VM which constantly records the arrival rate in adjacent windows. Recall that the details of the pre- diction were described in Section  4.2.2 . The DeepAREst [ 4 ] model was trained using  Keras  [ 22 ] and  Tensorflow , over 100 epochs with 2 layers, 32 neurons and a batch-size of 1.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "For instance, in a train-ticket application [ 40 ], actions like make_reservation  can trigger different paths/workflows (sub- set of functions) within the application. These design chal- lenges, when combined with the scheduling and container provisioning policies of current serverless platforms, result in crucial inefficiencies with respect to application performance and provider-side resource utilization. Two such inefficien- cies are described below: ‚Ä¢  The majority of serverless platforms [ 32 ,  44 ,  46 ,  50 ] assume that DAGs in applications are static, implying that all com- posite functions will be invoked by a single request to the application.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "The list of models used for them are given in the Appendix. We model two different workload mixes by using a combination of these Ô¨Åve query constraint types. Based on the decreasing order of accuracy, we categorize them into  Strict  and  Relaxed  workloads.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Otherwise, as can be seen from Line  6  to Line  8  in Algo. 2, the overlapped area of each MV and BBox is examined to determine whether the object has moved ‚Äútoo far away‚Äù or not; if it has, the ‚ÄúFI‚Äù is triggered. Finally, if the frame falls under the category in which objects have not been signiÔ¨Åcantly displaced, then it is labeled as ‚ÄúPI‚Äù (as shown in Line  9  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "9 \nAlgorithm 2  Training Auto-Encoder with Motion Vectors and Stacked Compression while freezing the inference model. 1:  Input:  Set of training video sequences  V 2:  Initialize:  MobileNet  M ‚ñ∑ Weights frozen 3:  Initialize:  Autoencoder  A ‚ñ∑ Trainable 4:  Initialize:  Motion Vector Extractor  V 5:  procedure  E XTRACT M OTION V ECTORS ( frame current , frame previous ) 6: motion _ vectors  ‚Üê V  ( frame current , frame previous ) 7: return  motion _ vectors 8:  end procedure 9:  procedure  F ORWARD P ASS ( video ) 10: previous _ features  ‚Üê null 11: previous _ compressed  ‚Üê null 12: for  each frame  frame  in  video  do 13: features  ‚Üê M ( frame ) ‚ñ∑ Extract features using frozen MobileNet 14: compressed  ‚Üê A.encode ( features ) ‚ñ∑ Compress features 15: if  previous _ compressed  Ã∏ =  null  then 16: motion _ vectors  ‚Üê E XTRACT M OTION V ECTORS ( frame, previous _ frame ) 17: stacked _ input  ‚Üê concatenate ( compressed, previous _ compressed, motion _ vectors ) 18: compressed  ‚Üê A.reencode ( stacked _ input ) ‚ñ∑ Stacked compression 19: end if 20: reconstructed  ‚Üê A.decode ( compressed ) ‚ñ∑ Decompress to reconstruct 21: Calculate reconstruction loss between  frame  and  reconstructed 22: previous _ frame  ‚Üê frame 23: previous _ compressed  ‚Üê compressed 24: previous _ features  ‚Üê features 25: end for 26: Backpropagate loss and update weights of  A  only 27:  end procedure 28:  while  not converged  do 29: for  each  video  in  V  do  F ORWARD P ASS ( video ) 30: end for 31:  end while \nThe implementation of layered codecs involve the following components. FPGAs are ideal for this application due to their parallel processing capabilities and the ability to handle multiple data streams concurrently.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 468,
    "augmented": true
  },
  {
    "text": "4 PROPOSED STRATEGIES \nAs discussed in Sec. 2.2, holographic processing dominates the la- tency and energy consumption in the AR video pipeline. Further, we also observed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": ";  ii)  What types of chiplet-based architectures are suitable for EoE-based LLMs, and what is the search space for chiplets? ;  iii)  What kind of reconfigurability is needed for chips to accommodate the heterogeneous and morphable aspects of EoEs? ;  iv)  How can inter-chiplet and inter-chip data movements be choreographed to maximize performance and minimize energy consumption for training, inference, and re-training?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "With these depth planes, the first step,  Forward Propagation  (de- noted  ‚ù∂ in Fig. 4a), is to overlay the  i th   plane on the propagation result of the previous 1 st   to  ( i  ‚àí 1 ) th   planes, and then propagate to the next  ( i  +  1 ) th   plane. Note from  Line#3  to  Line#5  in Algo.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "(DASFAA 2003). In  Eighth International Conference on Database Systems for Advanced Applications, 2003. Proceedings.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "This problem reduces in both input stationary and weight stationary, but at the cost of throughput [ 80 ]. Typically, the input feature maps are larger than the (individual) weights, and more importantly large weights can easily be represented \n897 \nAuthorized licensed use limited to: Penn State University. to resume and remap the compute.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "In this signed representation, the Gaussian distribution ranges from  [0 , ks )  to  [ q  ‚àí ks,  0) , where  k  takes integer values  1 ,  2 ,  3 , . . .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Mathematical Formulation:  Let  W  be the weight matrix of a layer. The idea is to use the inverse of the L2 norm to determine the probability: \np i  = Œ± ‚à• W i ‚à• 2  +  œµ \nwhere  Œ±  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. The L2 norm of the weights is calculated as: \n‚à• W ‚à• 2  = sX \ni,j W   2 ij \nDefine the dropout probability  p i  for neuron  i  based on the L2 norm of its corresponding weights.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "[46] Elias Frantar and Dan Alistarh. Qmoe: Practical sub-1-bit compression of trillion-parameter models. arXiv preprint arXiv:2310.16795 , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Second, it utilizes dis- tributed autoscaling poli- cies to reduce the la- tency variability and re- source consumption of hosting ensemble mod- els. Third, it minimizes the cost of deploying ensembles in a public cloud by taking advan- tage of transient VMs, as they can be 70-90% cheaper [ 3 ] than traditional VMs. Cocktail , by coalescing these beneÔ¨Åts, is capable of operating in a region of optimal cost, accuracy and latency (shown in Figure  1 ) that prior works cannot achieve.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level. Throughput model  Achieving the maximal computation progress under the harvested energy has two implications. The Ô¨Årst one is that we expect more energy can be used for program progress.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Thus, prior efforts have proposed using accelerators or cloud for optimiz- ing the hologram computation. In contrast, this paper attempts to exploit available approximation opportunities unique in AR holo- graphic applications, and proposes a two-stage  HoloAR  scheme to speed up the execution and save energy. 7 CONCLUSION The extremely heavy computation in hologram processing hinders the growth of the 3D display applications on AR headsets.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Restrictions apply. (a) Scenario1: moving. (b) Scenario2: capturing a previously missed object.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "cs. Learning multiple layers of features from tiny images. https://www.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 18,
    "augmented": true
  },
  {
    "text": "TABLE III: mAP (%) comparison with the baseline \nV1 V2 V3 V4 YOLOv3 51.8 55.4 42.0 59.5 YOLOv3 w/ FI+SI 51.8 55.4 41.8 59.4 YOLOv3 w/ FI+SI+PI 50.3 54.1 40.6 58.0 YOLOv4-tiny 31.8 49.3 31.3 33.5 YOLOv4-tiny w/ FI+SI 31.6 49.2 31.4 33.3 YOLOv4-tiny w/ FI+SI+PI 31.4 49.1 30.8 33.0 \n3) mAP:  To study the accuracy impact of our proposed SI and PI schemes, we summarize the mAP for our two models (YOLOv3 and YOLOv4-tiny) using four videos from VIRAT dataset [33] in Table III. Restrictions apply. One can observe that the mAP in our FI+SI scheme only drops by  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 250,
    "augmented": true
  },
  {
    "text": "b \n0% 25% 50% 75% 100% \n0 50 100 150 200 Delta(red) \n#blocks=20,best #blocks=20,worst #blocks=1000,best #blocks=1000,worst \n0% 25% 50% 75% 100% \n0 100 200 Range(Delta) \n#blocks=10 #blocks=100 #blocks=10000 #blocks=100000 \na \nc \nFigure 3: a) Spatial locality within one frame. b) Temporal locality among two frames. c) An example of macro blocks segmented using Morton codes in two frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "2.2 Motivation Two specific challenges in the context of DDAs along with potential opportunities to resolve them are described below: Challenge 1: Path Prediction in DDAs. DDAs will only have a subset of their functions invoked for an incoming request to the application due to the presence of conditional paths within their DAGs. Figure 1 depicts the DAGs of three such applications from the  ùê∑ùëíùëéùë°‚ÑéùëÜùë°ùëéùëü benchmark suite [ 29 ], and Table 2 summarizes the various workflows that can be triggered by an incoming request to them.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "This calls for finding further opportunities for optimization. To under- stand the computing requirements in a typical AR pipeline consists of many stages (refer Sec. 2), we profiled a set of applications and found that the  hologram  processing is the primary bottleneck in terms of computation, energy consumption, and execution latency.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "28% of the time the sensors could Ô¨Ånish the inference, while 72% of the time the inference failed as the sensor could not harvest enough energy while not performing any inference. 1:  Fraction of inference completed on harvested energy using na¬®ƒ±ve scheduling. Fig.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "existing policies such as  Arch  and  Fifer  exhibit similar perfor- mance and resource usage when their prediction models and keep-alive times are similarly adjusted. Xanadu , on the other hand, while having 0.74 memory-resident containers per sec- ond, suffers from 55% SLO Violations on average across all applications as a result of MLP mispredictions whose effects are exacerbated in this scenario, due to low request volume. Varying SLO:  Table 7 shows the SLO guarantees and num- ber of containers spawned for existing policies as well as Comm Only  and  Conn Only , when the SLO is reduced from 1000ms to a value 30% higher than the response time of the slowest workflow in each application.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 172,
    "augmented": true
  },
  {
    "text": "Please refer to Figure 5a for more details. The output currents I1 and I2 are then computed as follows: \nI  =  I 1 +  I 2 =  G 1  √ó  V  1 +  G 2  √ó  V  2 \n23 \n(a) Re-RAM Cell \n(b) A Full Re-RAM tile \nFigure 5: DNN computation using ReRAM xBAR. Here, the output currents I1 and I2 are the result of the multiplication of the input voltages V1 and V2 by their respective weight values, which are summed together using the crossbar wires.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "5 √ó  larger than that of TMC13 [ 56 ]. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. C. Intra-Frame Attribute Compression \n289 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "URL  https://www.sciencedirect.com/science/ article/pii/S0016003223007536 . Case Western Reserve University Bearing Data Center. Bearing fault data.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 \n0 0.10.20.30.40.50.60.70.80.9 1 \nPower Utilization \nPower efficiency \nPiezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG \nFig. 10. ResiSchedule power efÔ¨Åciency analysis \nD. Transition efÔ¨Åciency Table  VI-D  shows the ratio of inferences using smooth- transitioned partial results and total inference count number.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": ", and  Can we leverage this proximity to safely skip some computations to save energy? III. 360 ¬∞ V IDEO  P ROJECTION \nTo leverage the opportunities in the  360 ¬∞ video projection, we need to understand the execution of the entire projection processing in a  360 ¬∞ VR system.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Cambridge University Press, 2011, p. 41‚Äì76. [61]  Pix4D SA, ‚ÄúPIX4Dcatch: Turn your mobile device into a professional 3D scanner using the power of photogrammetry,‚Äù ‚Äùhttps://www.pix4d.com/product/pix4dcatch‚Äù , 2021. [62]  Point Cloud Library Contributors, ‚ÄúModule kdtree - Point Cloud Library (PCL),‚Äù  ‚Äùhttps://pointclouds.org/documentation/ group kdtree.html‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "URL  https://doi.org/ 10.1145/3517207.3526973 . Association for Computing Machinery. ISBN 9781450392549. doi: 10.1145/3517207.3526973.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "The backward pass emphasizes gradient computation through backpropaga- tion, which is crucial for weight updates. This gra- dient computation, fundamental for learning, is meticulously mapped across the systolic array, ensuring precise and efÔ¨Åcient backpropagation. The gradient of the loss function concerning the weights is computed through the formula ‚àÇ L ‚àÇ K mi jc   =  ‚àë U ‚àí 1 \nu = 0   ‚àë V ‚àí 1 \nv = 0 \n‚àÇ L ‚àÇ A muv   ¬∑  X ( u + i )( v +  j ) c .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "Rep , 2020. [87] Habana Labs. Habana gaudi ai processor.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. baseline InterHolo IntraHolo InterIntraHolo \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "The trained models can then be used to perform inferences, i.e., the clas- sification task. A typical DNN model has two different phases, namely,  training  and inference . Training a DNN, which is the process of extracting and learning the patterns and the features from millions of sample-data, typically takes a few hours to days.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "InterHolo IntraHolo InterIntraHolo \nPSNR \n(a) PSNR. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "compression ratio (i.e., input size / compressed size). by adjusting the threshold as discussed in Sec. VI-B .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Smart city technologies and intelligent transportation systems are helping cities absorb growing populations, overcome congestion, and create sustainable futures. https://www. intel.com/content/www/us/en/transportation/urban-mobility.html .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "2001‚Äì2010. [75] J. Redmon and A. Farhadi, ‚ÄúYolov3: An incremental improvement,‚Äù \narXiv preprint arXiv:1804.02767 , 2018. [76] G. V. Research, ‚ÄúConsumer iot market size, share and trends \nanalysis report by component (hardware, services), by connectivity technology (wired, wireless), by application (healthcare, wearable devices), and segment forecasts, 2023 - 2030,‚Äù https://www.grandviewresearch.com/industry-analysis/consumer- iot-market-report#: ‚àº :text=The%20global%20consumer%20IoT% 20market,advanced%20devices%20and%20home%20appliances.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 189,
    "augmented": false
  },
  {
    "text": "[186] Yusen Zhang, Ansong Ni, Ziming Mao, Chen Henry Wu, Chenguang Zhu, Budhaditya Deb, Ahmed Awadallah, Dragomir Radev, and Rui Zhang. Studying inter-core data reuse in multi- cores. ACM SIGMETRICS Performance Evaluation Review , 39(1):25‚Äì36, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "[89] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. Gshard: Scaling giant models with conditional computation and automatic sharding. arXiv preprint arXiv:2006.16668 , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "[17]  J. Elseberg, D. Borrmann, and A. N ¬® uchter, ‚ÄúOne billion points in the cloud ‚Äì an octree for efÔ¨Åcient processing of 3d laser scans,‚Äù  ISPRS Journal of Photogrammetry and Remote Sensing , pp. [18]  Eugene d‚ÄôEon, Bob Harrison, Taos Myers and Philip A. Chou, ‚ÄúJPEG Pleno Database: 8i Voxelized Full Bodies (8iVFB v2) - A Dynamic Voxelized Point Cloud Dataset,‚Äù  ‚Äùhttps://bit.ly/ 3cJQ61a‚Äù , 2017. 76‚Äì88, 2013.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "Participation in- volves: \n1. Determining if they have enough energy and incentive (based on the established equilibrium strategy and reward parameters  Œ≥, Œ¥, Œ∑ ). 2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "241‚Äì253. [108] S. Zhao, H. Zhang, C. S. Mishra, S. Bhuyan, Z. Ying, M. T. Kandemir, \nA. Sivasubramaniam, and C. Das, ‚ÄúHoloar: On-the-Ô¨Çy optimization of \n3d holographic processing for augmented reality,‚Äù in  MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture , 2021, pp. 494‚Äì506.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "As discussed in Sec. Opportunities \nExploring and exploiting computation output reuse oppor- tunities is non-trivial in this context. First of all, the projec- tion transformation is multi-staged and is a composition of multiple mathematical operations, e.g., transformation matrix, projection computation, mapping, etc.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "These hardware components are designed to be flex- ible and scalable, allowing customization to specific computational needs. Through this integrated approach, we aim to lower the barriers to entry for AI development. By leveraging reconfigurable chiplet-based architectures, we aim to optimize hardware efficiency, reduce power consumption, and min- imize the environmental footprint of AI operations.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "google.com/project/360-videos‚Äù. [8] Facebook Inc., ‚ÄúFacebook Oculus,‚Äù ‚Äùhttps://www.oculus.com/‚Äù. [9] Google, ‚Äú360¬∞ videos - Google Arts & Culture,‚Äù ‚Äùhttps://artsandculture.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Exploiting Intermittent Computing:  An obvious solution to the power problem is to run the training in a self-sustained way, i.e., without depending on the power grid and by relying on a renewable energy source like solar power; opportunities for harvesting renewables naturally scale alongside a greater number of deployment locations and solar power, even though not always available, is in abundance. Furthermore, solar power has reasonably predictability characteristics. In the United States, a typical 12% efÔ¨Åcient solar panel [ 91 ], can provide an annual average of 50 W / m 2   ‚àí 150 W / m 2   of power [ 64 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "Distributed training frameworks like Horovod [141], Mega- tronLM [149], and DeepSpeed [65] ensure optimized data communication for distributed memory usage along with dynamic batching so that scaling overheads are minimized and resources are maximally uti- lized. Existing literature also examines the impact of software optimizations like kernel fusion [170] and compiler optimizations [25], performance improvements via load balancing [58, 88, 182] and resource al- location [79, 161]. In the direction of fault tolerance, there are works on various checkpointing [102, 162] strategies so that system gracefully comes out of failure with minimum loss of progress.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "(GOps) \nEnergy Eff. (GOps/W) DaDianNao [ 16 ] 606 67.3 16.3 4964 304.54 CNVLUTIN [ 4 ] 606 70.1 17.4 4964 285.29 Activation Sparse [ 80 ] 667 292 19.2 5466 284.69 EyerissV2 [ 15 ] 200MHz N/A N/A 153.6G 8b Ô¨Åxed pt/s 193.7 FlexBlock [ 63 ] 333MHz 160.3 (65nm) 34.4 (when same #PEs) 4504 131.03 \nUs. ¬¥as \n592 168.2 22.7 (17.2 if only train) 4016 159.42 Fully powered, DNN Compute only 287.44 Fully powered, DNN  Œº ‚àí proÔ¨Åler 255.39 EH +  Œº ‚àí proÔ¨Åle + NV-mems + resizing RAM + Host 159.40 \nTABLE II: Comparison with prior accelerator-based platforms.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 238,
    "augmented": false
  },
  {
    "text": "[147] Haizhou Shi, Zihao Xu, Hengyi Wang, Weiyi Qin, Wenyuan Wang, Yibin Wang, and Hao Wang. arXiv preprint arXiv:2404.16789 , 2024. Con- tinual learning of large language models: A comprehensive survey.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "There have also been signiÔ¨Åcant efforts in designing and optimizing specialized DNN training accelerators [ 16 ], [ 27 ], [ 81 ], and many commercial organizations have already devel- oped their own accelerators [ 37 ], [ 95 ] as well. Considering the compute mapping of the DNN training, almost all of these de- signs are based on a ‚Äúsystolic architecture‚Äù, performing chains of multiplication and accumulations (MACs). However, these devices take a ‚Äúthroughput-Ô¨Årst‚Äù approach, to minimize the time consumption and seldom optimize power consumption Ô¨Årst.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Given a power supply level, we can derive the optimal tile size and actual duplication granularity to form the activation solution  ‚ü® m, n, aG ‚ü© for sequential or pipelined computation modes, respectively. Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "2019. In search of a fast and efficient serverless dag engine. In  2019 IEEE/ACM Fourth International Parallel Data Systems Workshop (PDSW) .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes. ReRAM crossbar-based accelera- tors (RCAs) are an ideal candidate to perform the dominant multiplication-and-accumulation (MAC) operations in CNNs ef- Ô¨Åciently, but conventional, performance-oriented RCAs, while energy-efÔ¨Åcient, are power hungry and ill-optimized for the intermittent and unstable power supply of energy-harvesting IoT nodes. This paper presents the  ResiRCA  architecture that integrates a new, lightweight, and conÔ¨Ågurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 186,
    "augmented": false
  },
  {
    "text": "These gradients are computed analytically since the regularizers are explicit, differentiable functions of  Œ∏ . 3. Aggregation:  The aggregator averages the received gradients: b ‚àá J ( Œ∏ k ) =  b ‚àá L ( Œ∏ k )+ Œª 1 ‚àá ‚Ñ¶ SNR ( Œ∏ k )+ Œª 2 ‚àá ‚Ñ¶ complexity ( Œ∏ k ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Keith Chapman, Mehdi Nik, Behnam Robatmili, Shahrzad Mirkhani, and Maysam Lavasani. In  Proceedings of 10th International Workshop on Accelerating Analytics and Data Management Systems (ADMS‚Äô19) , 2019. Com- putational storage for big data analytics.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "6b \na  ) integrated into the existing pipeline to par- tially bypass the computations of holograms that are outside the focus area. ‚Ä¢  Inter-Holo:  We evaluate the  Inter-Holo  design on a mobile GPU [ 36 ] using a framework similar to the state-of-the-art IL- LIXR framework [ 19 ], with one additional eye tracking task (as shown in Fig. Note that, this implementation is purely done in software, without any hardware modification.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "¬¥as  hardware‚Äôs most important feature is its ability to  morph  according to power availability. We also compare our work against two reconÔ¨Ågurable platforms [ 15 ], [ 63 ]. Power Aware Scaling: The  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems , pp. 199‚Äì213, 2019. Transforma Insights.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "To improve the performance, next we want to explore the hidden spatio-temporal locality opportunities (missed by the prior works), and speed up  both  the geometry and attribute compression from  both  the intra- and inter-frame perspectives. 2) Optimizing the Intra-Frame Compression: Driven by the observations above, next we relax the ‚Äúsequential update‚Äù approach that exists in the prior works, and employ the (intermediate) generated  Morton Codes  to reveal the ‚Äúhidden parallelism‚Äù opportunities for compressing a PC frame (shown in Figs. 4  c  and  4  d  for the geometry and attribute compression, respectively).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Recall that, in the AR holographic application discussed above in Fig. 3). 1a and Section 2.1, there are two types of inputs to the holographic pipeline ‚Äì  world sensors  for the physical objects (real cars in this case) in the world, and  user sensors  for the user behavior/state such as pose and eye movements (discussed in details in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "1: A DNN inference pipeline on an edge device with optimizations in the application, system, and hardware levels. B. Prior Work \nPrior work for enabling inferences on edge devices have focused on hardware as well as software optimizations, which can be further classiÔ¨Åed into model compression and pruning, and compiler and runtime support.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Fuse multiple ‚ÄòQuantaTask‚Äòs to minimize load/store operations. 5. Check for power loss after each ‚ÄòQuantaTask‚Äò or fused ‚ÄòQuantaTask‚Äò and checkpoint if necessary.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Accessed: 2024-10-20. [137] Ananda Samajdar, Jan Moritz Joseph, Yuhao Zhu, Paul Whatmough, Matthew Mattina, and Tushar Krishna. A systematic methodology for characterizing scalability of dnn accelerators using scale-sim.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "To achieve this, the PWS  2  first fetches relevant system metrics (using a monitoring tool  3  and orchestrator logs). These metrics, in addition to a developer-provided DAG Descriptor  4  , are then used by the Weight Estimation module  2a  of PWS  2  to assign weights to functions on the basis of their invocation probabil- ities. Commonality  and  Connectivity  (parameters in  2a  ) are additional parameters used in weight estimation to account for critical and common functions.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Our extensive experimental results show that, compared to a state-of-the-art intra-frame PCC technique [ 56 ], our intra- frame proposal can accelerate the PCC by  43 . While with our inter-frame compression design, the compression ratio can be further improved (increasing from 5.95 in intra-frame design to 10.43) with 35 √ó  speedup and 97.4 %  energy savings with respect to a state-of-the-art inter-frame PCC scheme [ 13 ]. 7 √ó  and save 96.6 %  energy.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp. Latency (ms) \n(b)  Wiki-trace:  Relaxed  workload. InFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nLatency \n(c)  Twitter-trace:  Strict  workload.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Motivated by these observations, in the following sections, we explore and address two critical questions:  Can we identify the proximity in the projection computation? The two transformation matrices are very ‚Äúsimilar‚Äù as they inherit a relationship between them as a function of the small pupillary distance. , and  Can we leverage this proximity to safely skip some computations to save energy?",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "; iii)  What types of accelerator-based chiplets and chips perform better for training and inference of EoEs? ; iv)  Should we build separate training and inference chiplets/chips, or would a unified chip/chiplet suffice? ; v)  What is the estimated training time given the size of input data and choice of model architecture?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Post-loading, each SDMM \n11 \n6bit shift  register \nSDMM SDMM \n13bit register \nControl logic \na \nb \nc \nb c \nd \n(a) HSPM micro-architecture. Simultaneously, the first coefficient  a 0  of polynomial  a  is fed in parallel to all 128 SDMM units. During the data loading phase, the 256 coefficients of polynomial  b  are input serially into a 6-bit shift register.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "1, it can be safely bypassed. Additionally, if the frame is in either Scenario-2 or \n1078 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "It can be observed that underprovisioning containers for just one Critical function has a greater im- pact on application performance than doing so for a single Non-Critical function, with the end-to-end response time and SLO guarantees becoming 24ms and 0.25% worse on average. This effect can worsen if the same were to happen with multiple critical functions. The (Critical, Non-Critical) function pairs chosen for this experiment were ( Make_Post ,  Text ), ( ID ,  Rating ) and ( NGINX , Search ) for  Social Network ,  Media Service  and  Hotel Reserva- tion , respectively.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "11 621‚Äì11 631. [15] Y.-H. Chen, T.-J. Yang, J. Emer, and V. Sze, ‚ÄúEyeriss v2: A Ô¨Çexible \naccelerator for emerging deep neural networks on mobile devices,‚Äù IEEE Journal on Emerging and Selected Topics in Circuits and Systems , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "The Primary Y-axis denotes the Av- erage End-to-End Response Time, the Secondary Y-axis represents the percentage of SLOs satisfied and the X-axis indicates the Appli- cation under consideration. Figure 2: Function-wise Breakdown of Container Provisioning across Applications. 98.10% \n98.55% \n99.00% \n99.45% \n99.90% \n0 \n200 \n400 \n600 \n800 \nCritical Non-Critical Critical Non-Critical Critical Non-Critical \nSocial Network Media Service Hotel Reservation \nPercentage \nResponse Time (ms) \nEnd-to-End Response Time SLO Guarantee \nFigure 3: Performance Deterioration resulting from Container De- ficiency at Critical Functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "30 \n35 \n40 \n45 \n50 \n0 0.2 0.4 0.6 0.8 1 \nPSNR (dB) \nBits per Pixel \nH264 H265 Salient Store \nFigure 8: Compression and Recovery efficiency. 0 \n10 \n20 \n30 \n40 \n1 2 3 4 5 6 \nEncoding Latency (s) \nNumber of Layers \nH264 HEVC Salient Store \nFigure 9: Encoding Latency using layered coding. 5.3 Evaluation of Lattice Based Encryption \nOne of the major contribution of  Salient Store  is accelerating the lattice-based encryption with the help of FPGAs on the storage nodes.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "[51]  Mu Editor 2022. Code with Mu a simple Python editor for beginner programmers. https://codewith.mu/en/.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Compared to classical inference, DynInfer introduces additional overhead for scheduling and task fusion, but this is offset by the gains in reliability and efficiency under intermittent power. Handling Extremely Low or Sporadic Energy Levels:  In environments with extremely low or sporadic energy levels where consistent dropout and quantization adjustments may not be feasible, NExUME handles this by: 1. Implementing a minimum viable model configuration that operates at the lowest acceptable energy consumption, achieved by maximizing dropout rates and using the lowest quantization bit-widths.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "1878‚Äì1885, 2019a. doi: 10.1109/HPCC/SmartCity/DSS. 2019.00259.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "In  Advances in Neural Information Process- ing Systems , 2024. [187] Yusen Zhang, Ruoxi Sun, Yanfei Chen, Tomas Pfister, Rui Zhang, and Sercan √ñ Arik. Chain of agents: Large language models collaborating on long-context tasks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 45th annual design automation conference , pages 620‚Äì625, 2008. [24] Guangyu Chen, Feihui Li, and Mahmut Kandemir. Compiler-directed application mapping for noc based chip multiprocessors.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "IEEE, 2017. 1‚Äì4. In  2017 IEEE Visual Communications and Image Processing (VCIP) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 24,
    "augmented": true
  },
  {
    "text": "[13] M. Ham, I. Dae, and C. Choi, ‚ÄúLPD: Low Power Display Mechanism for Mobile and Wearable Devices,‚Äù in  Proceedings of the USENIX Conference on Usenix Annual Technical Conference (ATC) , 2015, pp. 587‚Äì598. [14] K. Han, Z. Fang, P. Diefenbaugh, R. Forand, R. R. Iyer, and D. Newell, ‚ÄúUsing Checksum to Reduce Power Consumption of Display Systems for Low-motion Content,‚Äù in  2009 IEEE International Conference on Computer Design , 2009, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 140,
    "augmented": false
  },
  {
    "text": "D1 \nD2 \nD3 \nD4 \nD5 \nD6 \nD7 \nD8 \nE1 \nE2 \nE3 \nE4 \nE5 \nE6 \nE7 \nE8 \nStep-1: {E1, E5, E7} use {D1, D2, D5} \nStep-2: {E2, E3, E6} use {D3, D6, D7} \nStep-3: {E4, E8} use {D4, D8} \n(a) \n(b) \nFigure 4 :  Bipartite graph to perform data locality- aware expert training. Given memory capacity constraints, we frame the problem as identifying sets of experts to train together such that the data reuse among the selected experts, in a training step, is maximized and the combined data and parameter requirements of the set fit within the available memory. For example, in Figure 4(a), assuming for simplicity that memory can hold at most three experts and three datasets, this locality-aware approach would perform training in three steps.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 213,
    "augmented": true
  },
  {
    "text": "IEEE Embedded Systems Letters , 2022. Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "This would ostensibly allow for the selective transfer of only pertinent exemplar data to compute servers, thereby optimizing data movement costs. However, this approach presents several challenges. Current storage stacks are outfitted with robust CPUs and memory systems, which are heavily tasked with state-of-the-art storage management algorithms, as evidenced by the resource utilization outlined in TABLE 1.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "https://codewith.mu/en/. [52]  Ben Mussay, Margarita Osadchy, Vladimir Braverman, Samson Zhou, and Dan Feldman. 2019.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "), we utilize the octree-based method to compress the geometry data losslessly, while the attributes are compressed by the predictive RAHT lossily. We use this tool to compress every single PC frame, and measure the encoding latency, energy consumption, the compressed stream size, and Ô¨Ånally measure the quality (PSNR) of the decoded frame by  pc error d  tool [ 85 ]. ‚Ä¢  CWIPC  [ 13 ], [ 48 ]: CWIPC is a PCC library that supports the inter-frame compression (encoding the predicted frame via macro block (MB)-based motion estimation).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "However, HORN-8 does not explore the approximation opportuni- ties to speedup the hologram execution. Hence, as shown in Fig. 7c, our  HoloAR  design running on the edge GPU [ 36 ] still saves 25% more energy than the custom HORN-8 accelerator.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Additionally, there are few pixel positions at the frame edges which can only be viewed by one eye (denoted as  exclusive ), which cannot be captured by the above pattern. These pixels amount to only  2 . 7%  of the entire FoV frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "[19] HEADJACK, ‚ÄúThe Best Encoding Settings For Your 4k 360 3D VR Videos + FREE Encoding Tool,‚Äù ‚Äùhttps://headjack.io/blog/best- encoding-settings-resolution-for-4k-360-3d-vr-videos/‚Äù. [21] L. F. Hodges, ‚ÄúTutorial: Time-multiplexed Stereoscopic Computer Graphics,‚Äù  IEEE Computer Graphics and Applications , pp. [20] C. Heather Bellini, W. Chen, M. Sugiyama, M. Shin, S. Alam, and D. Takayama, ‚ÄúVirtual and Augmented Reality.‚Äù ‚Äùhttps://www.goldmansachs.com/insights/pages/technology-driving- innovation-folder/virtual-and-augmented-reality/report.pdf‚Äù, 2016.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 205,
    "augmented": true
  },
  {
    "text": "An ablation study evaluates the contributions of individual components within NExUME. The results, plotted in Figure 3c, indicate that the greatest improvements are derived from the ‚Äúsynergistic operation‚Äù of all components, particularly DynFit and DynInfer. Although iNAS enhances network selection, its lack of intermittency awareness significantly impacts accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "7 shows the comparison of our FPGA-accelerated lattice-based encryption against other state-of-the-art-techniques. However, our proposed solution offers  ‚âà 3 . RSA, the most popular encryption algorithm, when implemented using FPGA, outperforms our proposed hardware solution.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Figure 4 shows a toy example of importance sampling in a 2D data set. Observe that the selected points (in  red ) are approximating the original distribution. 5 \nr2 \nr1 \nr4 \nr3 \nr5 \nOriginal Data Coreset with imp-sampling Coreset with Clustering \nFigure 4: A toy example of the coreset construction techniques in  Seeker .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "678‚Äì683. [6] K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, J. Samp- son, M. T. Kandemir, and V. Narayanan, ‚ÄúResirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent embedded processors,‚Äù in  2020 HPCA , 2020, pp. 315‚Äì327.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Compression EfÔ¨Åciency:  To investigate how the compression efÔ¨Åciency changes with the above schemes, in Fig. Note that, although our schemes employ the GPU with an extra overhead (e.g., the GPU power is about 1065 mW ), the CPU power is reduced (e.g., around  1310 mW , lower than that in TMC13 and CWIPC) since most of the computations are ofÔ¨Çoaded to GPU. Therefore, the overall energy savings brought by our schemes are similar to the corresponding execution latency reductions discussed above.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "A novel accelerated implementation of rsa using parallel processing. Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. Journal of Discrete Mathematical Sciences and Cryptography , 22(2):309‚Äì322, 2019.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "The parallelism in this context is of two types:  intra layer parallelism via layer duplication  and  inter layer parallelism via layer pipelining . 1) Computation tiling:  In this work, we use loop tiling [ 35 ] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one. Further, tiling and parallelization can also be combined to generate Ô¨Åne-grained scales of computations to efÔ¨Åciently Ô¨Åt into the changing harvested power.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Aggregation:  The aggregator averages the received gradients: b ‚àá J ( Œ∏ k ) =  b ‚àá L ( Œ∏ k )+ Œª 1 ‚àá ‚Ñ¶ SNR ( Œ∏ k )+ Œª 2 ‚àá ‚Ñ¶ complexity ( Œ∏ k ) . Since  E [ b ‚àá L ( Œ∏ k )] = ‚àá L ( Œ∏ k ) , we also have E [ b ‚àá J ( Œ∏ k )] =  ‚àá J ( Œ∏ k ) . 4.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "DynFit tends to introduce multiple intermediate states during the training process, resulting in approximately 14% additional wall-time on average. The development of DynInfer requires an in-depth understanding of microcontroller programming and compiler directives. The absence of comprehensive library functions along with the need for computational efficiency frequently necessitates the development of in-line assembly code for certain computational kernels.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "In this example, for compressing the P-Frame, one pointer (for  S 1  which contains  P 0  and  P 1 ) and only one post-intra-encoded compressed delta (for  P 2 ) are required for storage, instead of storing all three. 291 \nAuthorized licensed use limited to: Penn State University. However, the proposed inter-frame compression pipeline has additional steps (PC sorting and block matching), which collectively take about 139 ms  for a typical PC frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "This Load Predictor  2b  can be used in conjunction with the afore- mentioned Weight Estimator  2a  to calculate the fraction of application load each function will receive. Note that  ùë° in the algorithm refers to the current time. We choose this model so as to have a light-weight load prediction mechanism that has min- imal impact on the end-to-end latency ( ‚àº 10 ‚àí 3   ms).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Both  Social Network  and  Me- dia Service  have a high number of workflows, but the former has more functions with higher slack, leading to increased batching, thereby resulting in the most reduction in con- tainers spawned. Hotel Reservation  has the least number of workflows as well as the lowest overall slack for all functions, resulting in the least reduction in the number of containers. On the other hand,  DProb  and  SProb  spawn fewer containers than  Kraken  as a consequence of not using  Commonality  and Connectivity  to augment function weights, while making container allocation decisions.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 136,
    "augmented": false
  },
  {
    "text": "[36] Nvidia, ‚ÄúJETSON AGX XAVIER AND THE NEW ERA OF AU- TONOMOUS MACHINES.‚Äù ‚Äùhttp://info.nvidia.com/rs/156-OFN-742/ images/Jetson AGX Xavier New Era Autonomous Machines.pdf‚Äù, 2019. [37] Oculus, ‚ÄúRendering to the Oculus Rift,‚Äù ‚Äùhttps://developer.oculus.com/ documentation/pcsdk/latest/concepts/dg-render/‚Äù. [38] Oculus, ‚ÄúAsynchronous TimeWarp (ATW).‚Äù ‚Äùhttps://developer.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "The Shown storage pipeline is the preliminary focus of  Salient Store  . analytics and learning tasks related to urban mobility at the edge. This has lead to a significant development in the direction of enabling video analytics and learning with edge servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Secondly, we introduce a novel dataset aimed at advancing research in predictive maintenance and Industry 4.0 (Lasi et al., 2014), and test NExUME on a real manufacturing testbed (¬ß4.3) with COTS hardware. We have developed a first-of-its-kind machine status monitoring dataset, available at  https://hackmd.io/@Galben/rk7YN6jmR , which involves mounting multiple types of sensors at various locations on a Bridgeport machine to monitor its activity status. 4.1 Development and Profiling of NExUME \nNExUME uses a combination of programming languages and technologies to optimize its functional- ity in intermittent and low-power computing environments.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "To estimate the required energy, we ran simple HAR inferences (optimized version of [ 26 ] for edge deployment using [ 68 ]) on an Adafruit ItsyBitsy nRF52840 Express - Bluetooth LE [ 2 ] and found it to be consuming from 550mJ to 1.6J of energy (depending on the quantiza- tion). For example, there has been significant work on enabling solar powered smart farm- ing [ 63 ,  67 ], but the same can not be done for smart manufac- turing due to the lack of solar exposure and the low fidelity of the available EH sources such as vibration and RF (from WiFi or other sources). : Battery, Bonito [ 22 ], Chinchilla [ 43 ], ResiRCA [56], Origin [47]) \ncompute are not energy efficient to run with all modali- ties of harvested energy since all of them do not have the same energy income (see Figure 1b).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 230,
    "augmented": true
  },
  {
    "text": "This may be due to Media Service  having higher path unpredictability than  Hotel Reservation  (Table 2) as well as lower slack per function than Social Network  (Figure 7). This is due to  Kraken ‚Äôs load/path probability miscalculations and the usage of  Commonality and  Connectivity  to cope with this. It is seen that  Kraken spawns 10% more containers for  Media Service  and 6% more for  Hotel Reservation  and  Social Network .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "The left y-axis shows the compute energy consumption normalized to the compute energy consumption in Baseline (the lower, the better). 0 \n20 \n40 \n60 \n80 \nV1 V2 V3 V4 V5 Avg. The right y-axis shows the amount of energy savings compared to the end-to-end total energy consumption in Baseline (the higher, the better).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Current storage stacks are outfitted with robust CPUs and memory systems, which are heavily tasked with state-of-the-art storage management algorithms, as evidenced by the resource utilization outlined in TABLE 1. These algorithms already consume substantial compute and memory resources, often to the extent of fully occupying the storage controller system, with a portion of resources being allocated for essential system stack operations. Furthermore, incorporating more advanced compute hardware, such as FPGAs, GPGPUs and other accelerators, would lead to underutilized I/O slots and memory, consequently escalating the cost of storage systems.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "The fused task executes both convolutions atomically within the energy budget, avoiding the overhead of checkpointing between them. The energy availability constraint over time is expressed as (subject to energy and task constraints): P \ni : s i ‚â§ t<f i   E i  ‚â§ E b ( t )  The objective is to maximize the total weighted priority of scheduled tasks: \nmax { x i ,s i } \nN X \ni =1 \n\u0000 p i  ‚àí Œ±E i  ‚àí Œ≤ ( f i  ‚àí D i ) + \u0001 x i . Scheduling Problem Formulation:  The scheduling problem is formulated with decision variables s i  (task start times) and binary variables  x i  ‚àà{ 0 ,  1 }  (indicating whether a task is scheduled).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 201,
    "augmented": true
  },
  {
    "text": "In addition to working with the GEM/Grad lab, department has developed a partnership with the Black in AI (BAI) group to attract more students from populations underrepresented in computing to our graduate program. Moreover, the CoE (College of Engineering) is a partner with the National GEM Consortium that leads the Grad Lab, which facilitates the participation of populations underrepresented in computing for graduate studies in engineering and science. We also plan develop recruiting relationships with HBCUs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "It is obvious that the most conÔ¨Ådent classiÔ¨Åcation for the same class would be [1 ,  0 ,  0 ,  0] , where the model is 100% conÔ¨Ådent on class  o 1  and the most confused prediction would be  [0 . 25 ,  0 . 25 ,  0 .",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "3),  a  Transformation and  b  Projec- tion Computation remain unchanged. To understand all the contributing factors which affect computations, we further investigate the important inputs of the VR headset. This can help us identify and isolate proper memoization candidates for carefully tweaking our design decisions to maximize the reuse beneÔ¨Åts.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Dean, ‚ÄúCarbon emissions and large neural network training,‚Äù  arXiv preprint arXiv:2104.10350 , 2021. [68] Y. Peng, Y. Bao, Y. Chen, C. Wu, and C. Guo, ‚ÄúOptimus: an efÔ¨Åcient \ndynamic resource scheduler for deep learning clusters,‚Äù in  Proceedings of the Thirteenth EuroSys Conference , 2018, pp. 1‚Äì14.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Conclusion \nThis should finish at 8 pages. Implementation and Evaluation \n6.1. Discussions and Limitations \n7.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "https://azure.microsoft. com/en-us/services/functions/. [11] 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout with learnable mask parameters, along with the QuantaTask optimization to handle energy constraints. Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output Y .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "The breakdown of the average response times in Figure 9 shows that both  Arch  and  Xanadu  do not suffer from queue- ing delays. This is because both policies spawn a container per request, resulting in almost zero queueing. Xanadu  has only a 34% misprediction rate for  Hotel Reservation , due to the lower number of workflows, and is seen to match  Kraken  in terms of SLOs satisfied (99.87%).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Both  Cocktail  and  Clipper  deliver the same overall accuracy (96%, 94.5%, 93.5%, and 92%)). Since sentiment analysis only has 2-3 classes, there are no additional accuracy gains by using the class-based weighted voting. However, the model selection policy effectively switches between differ- ent models based on the structure of input text (equivalent to classes in images).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Theoretical Analysis : The heuristic prioritizes tasks based on effective priority  P   eff i = p i E i   √ó  œï i , where  œï i  accounts for deadline urgency. 2. This balances task importance against energy consumption, leading to efficient utilization of available energy.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Dataset : A first-of-its-kind machine status monitoring dataset, involving multiple types of EH sensors mounted at various locations on a Bridgeport machine to monitor its activity status, facilitating research in predictive maintenance and Industry 4.0 applications. 2 Background and Related Work \nEnergy Harvesting and Intermittent Computing:  The exploding usage of IoTs, connected devices, and wearable electronics project the number of battery operated devices to be 24.1 Billion by 2030 (Insights, 2023). This has a significant economic (users, products and data generating dollar value) as well as environmental (battery and e-waste) impact (Mishra et al., 2024).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "This is because the  Paragon  scheme jointly considers all three parameters and chooses the least costing model. 5 Conclusion \nThere is wide-spread prominence in the adoption of ML- based prediction systems spanning across a wide range of application domains. The critical challenge of deploying ML prediction serving applications in public cloud is to combine both model and resource heterogeneity towards optimizing for application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Next, we solve for the second objective function ( O 2 ) by minimizing  ¬µ C , while maintaining the target accuracy. min ¬µ C  : \b Acc target  ‚â• Acc target  ¬± Acc margin \n( O 2 )  is solved by resizing the model list of size  N  and fur- ther through intelligence resource procurement (described in section  4.2 ), and thus maximizing  P f  and minimizing  k  simul- taneously. For  N  models, where each model has a minimum accuracy ‚Äò a ‚Äô, we model the ensemble as a coin-toss problem, where  N  biased coins (with probability of head being  a ) are tossed together, and we need to Ô¨Ånd the probability of major- ity of them being heads.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 173,
    "augmented": false
  },
  {
    "text": "¬¥as  accelerator design is to ensure proper ‚Äúcompute place- ment‚Äù even under a power emergency or power scaling. Fig. 6 : Accelerator level  provides a high-level overview of the compute scheduling (where the redacted part of the hard- ware is turned off because of the lack of power).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "We induce failures in the in- stances using  chaosmonkey  [ 19 ] tool with a 20% failure proba- bility. Figure  12b  plots the failure analysis results for top three constraints by comparing the ensemble accuracy to the target accuracy. The desired accuracy for all three constraints are plotted as BL1, BL2 and BL3.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "18 \nWei Cao, Yang Liu, Zhushi Cheng, Ning Zheng, Wei Li, Wenjie Wu, Linqiang Ouyang, Peng Wang, Yijing Wang, Ray Kuan, et al. { POLARDB }  meets computational storage: Efficiently support analytical workloads in  { Cloud-Native }  relational database. In  18th USENIX conference on file and storage technologies (FAST 20) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "https://doi.org/10.1145/3357223. 2019. 3362711 [26]  Benjamin Carver, Jingyuan Zhang, Ao Wang, and Yue Cheng.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "This is where the modern and upcoming computational storage devices (CSDs) come to rescue: bringing computation closer to data while providing with maximum energy efficiency and programmability (Newsroom; AMD, b) . However,  this issue could be alleviated by not using the compute resource in the critical path and preferably moving the compute to the storage where the data will eventually be stored . However, storage systems are not typically built to cater towards the ML applications, and now that compression becomes a ML application with the use of stacked neural codecs, building the right storage stack along with computational storage devices becomes an important problem.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "1 on average), and also the ranges/sizes of the bikes are larger, compared to others. Thus, chances for ap- proximating the objects outside the RoF (in  Inter-Holo ) and the objects which are relatively far-away from the user (in  Intra-Holo ) \nare limited. On the other hand, the  shoe  video frames typically contain more objects (2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Similarly, our model selection pol- icy is also changed at runtime based on correct predictions seen during every interval. An important concern in majority voting is tie-breaking. Ties occur when two sets of equal number of models predict a different result.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "For each benchmark, all the numbers are normalized to that of the  G4  setting with the  Naive2  policy. As expected, the throughput increases as  G  grows for every benchmark. Throughput results are plotted in Figure 12 and area costs for  G 1  ‚àº G 5  can be found in Figure 13.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Energy Costs and Future Utility: Participation incurs energy costs, reducing the sensor‚Äôs capacity for future tasks. Additionally, sensors must consider the discounted value of future utility. Let  C i ( t )  represent the cost component: \nC i ( t ) =  e i ( t ) +  Œ≤V i ( t  + 1) , \nwhere  e i ( t )  is the total energy expenditure for participa- tion, encompassing data capture, inference computation, and communication: \ne i ( t ) =  e cap ( SNR i ( t )) +  e inf  +  e comm .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "GeoInformatica , 20:59‚Äì94, 2016. Spatio-temporal traffic video data archiving and retrieval system. Hang Yue, Laurence R Rilett, and Peter Z Revesz.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "In this work we quantitatively characterize the cost, accuracy and latency implications of hosting ML inferences on different public cloud resource of- ferings. Thus, it is strenuous for an infer- ence serving system to choose from this confounding array of resource types and model types to provide low-latency and cost-effective inferences. However, the deployment cost of prediction serving primarily depends on the type of resources being procured, which by them- selves are heterogeneous in terms of provisioning latencies and billing complexity.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "More speciÔ¨Åcally, the rendering process is a projection from the  360 ¬∞ frame pixels‚Äô 3D coordinates to the 2D frame pixels‚Äô 2D coordinates on HMDs. The head orientation is sensed by an inertial measurement unit (IMU) on the HMD as a triple [ Y aw ,  Pitch ,  Roll ] for projection computation 2 . The projection process considers two user-side aspects ‚Äì  head orientation and pupillary dis- tance 1   ‚Äì to render stereoscopic views or Field of View (FoV) frames for both eyes, towards the head direction.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "2008. Hybrid Feature Tracking and User Interaction for Markerless Augmented Reality. In  2008 IEEE Virtual Reality Conference .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "This adaptation is guided by the dropout mask vector and the specific type of sparse matrix operation being performed. This technique effectively reduces the number of load operations by an average of 12%, thereby enhancing the efficiency of computations under energy constraints and contributing to the overall performance improvements in NExUME. 4.2 NExUME on Publicly Available Datasets \nDatasets:  For image data, we consider the Fashion-MNIST (Xiao et al., 2017) and CIFAR10 (Alex, 2009) datasets; for time series sensor data, we focus on popular human activity recognition (HAR) datasets, MHEALTH (Banos et al., 2014) and PAMAP2 (Reiss & Stricker, 2012); and for audio, we use the AudioMNIST (Becker et al., 2023) dataset.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 197,
    "augmented": true
  },
  {
    "text": "296 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "IEEE Transactions on Knowledge and Data Engineering , 2023. 22 \nMahdi Torabzadehkashi, Ali Heydarigorji, Siavash Rezaei, Hosein Bobarshad, Vladimir Alves, and Nader Bagherzadeh. Accelerating hpc applications using computational storage devices.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. baseline InterHolo IntraHolo InterIntraHolo \nExec. Latency (ms) \nHoloCompute Overhead \n876.81 \n430.15 393.07 \n(b) Exec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "[67] Shaomang Huang, Jianfeng Pan, and Hanzhong Zheng. Ccoe: A compact llm with collaboration of experts. arXiv preprint arXiv:2407.11686 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "In this work, we do not want to distort video quality and thus explore the ground-truth only. This is because low precision leads to a mis-projection, which fails to reÔ¨Çect the current head orientation. The Effect of EA:  With this  EA  memoization, once a new head orientation is received, we Ô¨Årst search it in the two head orientation registers.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "ACM SIGARCH Computer Architecture News , 39(3):389‚Äì400, 2011. [111] Mohammed Muqeeth, Haokun Liu, and Colin Raffel. Soft merging of experts with adaptive routing.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "We also propose  Intra-Holo  to further approximate each of the object holograms, by analyzing its cur- rent distance from the user. Our experimental results show that, compared to the baseline,  HoloAR  achieves 2 . 7 √ó  speedup and 73% \nenergy savings.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "https://www. mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai , Febru- ary 2024. [4] The state of ai in early 2024: Gen ai adoption spikes and starts to generate value.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "This inexpensive post-processing step can be applied to all branch nodes in parallel, thus does not bring much overhead. 1 , to obtain the occupy bits for one branch node, we Ô¨Årst calculate which branches its children should be on (e.g.,  C [  j ] %8  in Line #5), and then merge all of its occupied branches via the ‚Äú | ‚Äù operation. 3) What are the BeneÔ¨Åts and Drawbacks?",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "3) What are the BeneÔ¨Åts and Drawbacks? :  To summa- rize, compared to the prior schemes like PCL [ 72 ] and TMC13 [ 56 ], the most obvious beneÔ¨Åt from our proposal is the potential performance improvement in terms of latency \nAlgorithm 1:  Octree Occupy Bits Generation Algo. Input : C : Code Array;  P : Parent Array;  N : Number of Points \n1  Occupy Bits Array:  O  =  {} \n2  L  =  len ( C ) ‚àí N \n3  for  i in L  do \n4 p  =  P [ i ] \n5 O [ p ]  |  = ( C [ j ] %8 ) ,  P [ j ] =  p \nOutput :  O : Occupy Bits Array \nand energy savings, due to embracing more parallelism.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 209,
    "augmented": false
  },
  {
    "text": "2.2.3) ignored in the current implementation of the AR applications, but can be embedded into the existing hardware such as GPUs, to speedup the holographic execution and improve power/energy efficiency with negligible quality loss. 4.1 Exploring the Entire Design Space in AR Hologram Processing \nExploring the entire design space for the AR hologram processing is a non-trivial task. Unlike prior works targeting at optimizing the efficiency of the hologram program- ming itself by proposing alternative hardware [ 32 ,  35 ], we primarily focus on exploring the intrinsic approximation opportunities (dis- cussed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Large language models in healthcare and medical domain: A review. Association for Computing Machinery. [130] Wei Peng.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 26,
    "augmented": true
  },
  {
    "text": "Torr. 2015. SemanticPaint: A Framework for the Interactive Segmentation of 3D Scenes.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "While a completely grid based solution is best in terms of reliability, it is not feasible because of the power demands. Any battery backed system will be limited to the charging cycle of the batteries ( ‚âà 500 cycles for Li-ion batteries) which leads to a typical 18 to 24 months of life for such devices (compared to this, a super capacitor have a life of more than 100 years). Furthermore, we also present a qualitative com- parison on the maintenance cycle needed for these solutions.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Towards this, we propose  Cocktail , a cost effective ensembling-based model serving framework. Cock- tail  comprises of two key components: (i) a dynamic model selection framework, which reduces the number of models in the ensemble, while satisfying the accuracy and latency requirements; (ii) an adaptive resource management (RM) framework that employs a distributed proactive autoscaling policy, to efÔ¨Åciently allocate resources for the models. The RM framework leverages transient virtual machine (VM) in- stances to reduce the deployment cost in a public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "Moreover, the algo- rithmic contributions can be extended into any classiÔ¨Åcation based application or data modality. 10a  shows the contribution of the different components of  Us. ¬¥as  under different power proÔ¨Åles.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "This leaves us with the following important questions: ‚Ä¢  Are continuous inferences essential, or can we leverage the workload itself to skip some inferences without substantial accuracy loss, allowing enough energy to be accumulated for future inferences? Clearly, the completion of the task is power bound: Adopting a wait-compute execution model, such that we have enough energy to complete some results, at a lower duty cycle, instead of always trying and failing would yield beneÔ¨Åts. Therefore, we cannot always expect inference outcomes from all the sensors while doing HAR on EH-WSN.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "[56] B. Worldwide, ‚ÄúNYC 360 Timelapse.‚Äù ‚Äùhttps://www.youtube.com/ watch?v=CIw8R8thnm8‚Äù, 2019. [57] C. Xie, X. Zhang, A. Li, X. Fu, and S. Song, ‚ÄúPIM-VR: Erasing Motion Anomalies In Highly-Interactive Virtual Reality World with Customized Memory Cube,‚Äù in  Proceedings of the International Symposium on High- Performance Computer Architecture (HPCA) , 2019, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "We unify these three types of functions in two steps. First, we decompose EoE networks into three parts, including routing, expert and aggregation functions, constructing a repository of function choices for each type. Next, we evaluate the new combinations by extracting one function from each type.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Case-2:  If the data belongs to a known class, but is signif- icantly different from the training samples, it falls not too far from one of the clusters. This distance of the new data from the cluster center is called the ‚Äúdistillation loss‚Äù [ 74 ]. An encounter of a new example of the existing class is followed by an update to the clustering by minimizing the classiÔ¨Åcation loss of the newly-seen data.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "[64]  Xueheng Qiu, Le Zhang, Ye Ren, Ponnuthurai N Suganthan, and Gehan Amaratunga. Ensemble deep learning for regression and time series forecasting. In  2014 IEEE symposium on computational intelligence in ensemble learning (CIEL) , pages 1‚Äì6.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "The backpropagation is applied only to the layers of the autoencoder, ensuring that the feature extractor‚Äôs parameters remain intact. This approach not only preserves the integrity of the visual features derived from MobileNet but also tailors the compression mechanism to be highly adaptive to the content-specific characteristics captured by these features. 4 Optimizing Lattice-Based Cryptography \nFollowed by the video compression, in this section, we discuss the quantum safe encryption technique.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "This holistic approach addresses the limitations of existing methods that treat training and inference separately or do not account for real-time energy fluctuations. Implementation Details: We design a full software-compiler-hardware co-designed execution framework for commercial devices with non-volatility support (like MSP- EXP430FR5994 with FeRAM). Figure 2 shows a detailed overview of our execution design.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efÔ¨Åciency when active is high. Compared to the cloud for online processing, the preference for local compute over ofÔ¨Çoad can stem from security, con- nectivity and latency concerns as well as power and energy constraints. In our work, local computation across the CNN applications is  ‚àº 50x more efÔ¨Åcient than transmission over Bluetooth with 3Mbps and 2.5mW.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment. It has been shown that the power requirement to fully activate a 128 √ó 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [ 3 ]. Figure 4 shows Ô¨Åve harvested power sources with the maximum, mean and median values and their ratios indicated.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "IEEE, 2012. [159] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "The resultant SLOs are 500ms, 910ms and 809ms for  Social Network ,  Media Ser- vice  and  Hotel Reservation  respectively. Varying SLO:  Table 7 shows the SLO guarantees and num- ber of containers spawned for existing policies as well as Comm Only  and  Conn Only , when the SLO is reduced from 1000ms to a value 30% higher than the response time of the slowest workflow in each application. Reducing the SLO, in turn, can potentially reduce the batch sizes of functions as well.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "computational and memory requirements. NExUME focuses on enabling efficient and reliable deployment of DNNs in intermittent environments, which are often constrained in terms of com- putational resources and energy availability. In many real-world applications, especially in IoT and edge computing, there is a critical need for smaller, energy-efficient models that can operate autonomously without reliance on batteries.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. bounding boxes for the object detection task and the feature maps for each layer during the inference are intermediately stored in memory as a ‚Äúcheckpoint‚Äù.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "2) What are the Pros and Cons? :  As indicated in Fig. 6 , compared to RAHT, our proposal reuses the intermediate Morton codes, which have been computed during the geome- try compression, to precisely identify the points with similar attributes from a set of irregular points.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "[71] Rishabh Jain, Scott Cheng, Vishwas Kalagi, Vrushabh Sanghavi, Samvit Kaul, Meena Arunachalam, Kiwan Maeng, Adwait Jog, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita R. Das. In  To be presented in proceedings of the 57th Annual IEEE/ACM International Symposium on Microarchitecture , pages 62‚Äì76, 2024. Optimizing cpu performance for recommendation systems at-scale.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "This model maps sensor observations to inference outputs. Although parameters  Œ∏  can theoretically be updated through on-edge training, we assume that frequent retraining in situ is prohibitively expensive given energy constraints. Prior to deployment, a global inference model  f Œ∏  is trained offline on representative data and distributed to each sensor.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Furthermore, when the deployments are geo-distributed and operated by different owners, the privacy concerns on sharing the data with a third party cloud service provider becomes challenging in developing the analytics solutions. Since resource constraints can preempt complete execution at the edge, and sending data to the cloud is expensive due to communication energy and latency, it is essential to explore edge-cloud co-design, where we rely on the cloud if and only if it is necessary and \n2 \nbeneficial to achieve a more accurate result. The deployed edge devices perform the same analytics task (for example, monitoring the health of same type of machine at different sites) using a  random forest algorithm  (refer Algorithm-1).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "To address these challenges, we propose Us. ¬¥as, an ap- proach combining algorithmic adjustments, hardware-software co-design, and morphable acceleration hardware to enable the training of workloads on these edge servers to be powered by re- newable, but intermittent, solar power that can sustainably scale alongside data sources. Our evaluation of Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "National Institute of Standards and Technology, 2024. URL  https://csrc.nist.gov/projects/ post-quantum-cryptography . Post-quantum cryptography.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Our Approach (and its Novelty):  Us. ¬¥as  introduces several novel contributions in the domain of  sustainable  continuous learning at edge servers using harvested energy, setting it apart from prior works examining on-edge learning. Battery-Free Operation:  A key highlight of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "This is a standard binomial distribution problem and can be solved by using the following formula: \nP head  = N ‚àë i = ‚åä N \n2   ‚åã + 1 \n\u0012 N i \n\u0013 a i   ( 1 ‚àí a ) ( N ‚àí i ) . To further quantify, let us consider the case where we need to determine if we can reach the accuracy of NasNetLarge (82%) by combining rest of the smaller models which have lesser latency than NasNetLarge. We have 10 (therefore N = 10) such models and among them the least accurate model is MobileNetV1 (accuracy 70%, therefore a = 0.70).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Also, we will identify the most common or frequently accessed experts within and across EoEs. For these metrics, the expert execution may favor different hardware devices. Thus, to cater to the execution diversity in experts, we intend to take advantage of ‚Äúheterogeneous‚Äù chiplets.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "291 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "The output signal is obtained by summing the weighted input signals over a sliding window, which moves across the input signal to compute the convolution. The DACs and ADCs are used to convert the digital input and weight signals into analog signals that can be applied to the rows and columns of the x-bar. At the circuit level, the ReRAM x-bar for multiplication-addition typically includes several com- ponents, such as digital-to-analog converters (DACs), analog-to-digital converters (ADCs), shift registers, and hold capacitors.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "Thus, the latency improvement and energy saving po- tential of DeepCache can be limited. I, DeepCache does not take advantage of frame-wise data reuse opportunities (e.g., reuse the inference result for similar frames). Additionally, as the step- size of full-inference is Ô¨Åxed, it cannot adaptively update its cache based on the video content.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Clipper: A low-latency online pre- diction serving system. In  14th USENIX Symposium on Networked Sys- tems Design and Implementation (NSDI 17) , pages 613‚Äì627, Boston, MA, March 2017. USENIX Association.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "The NVSB stores the global/asynchronous work queue and the shufÔ¨Çing conÔ¨Åguration (mini-batch arrangement). B. Power Failure and Compute Scheduling \nCentral to the  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "0 \n150 \n300 \n450 \n600 \nArch Fifer DProb Kraken SProb Xanadu \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(b) Media Service. 0 \n150 \n300 \n450 \nArch Fifer DProb Kraken SProb Xanadu \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(c) Hotel Reservation. Figure 9: Real System: Breakdown of Average End-to-End Response Times in terms of queueing delay, cold start delay and execution time.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "For example, we have performed demonstration events at the local Science Museum for kids and the regional arts festival based on interaction with individuals who visited our exhibits. The PIs and their students are passionate about the broader outreach and in kindling interest in the K-12 students to pursue STEM careers. It also provides us access to new contacts and additional recruitment opportunities of diverse students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Component Spec Power Area(mm 2 ) \nSRAM Buffers \n1kB*256+ 8kB*256+ 64kB+16*256kB \n10.372W 117.164 \nMAC Unit (8*8) 256 8.46W 32.72 \nAdder Tree and Comparator 16*16bit + 256 2.4W 21.556 \nControl ‚Äì 0.96W 12.2 Host ‚àº Cortex A78 series 11W ‚Äì Design at 592MHz with Synopsys AED 32nm library \nTotal 256 tiles 33.192W 183.64 Table 3: Area and power estimation of our design. A APPENDIX A.1 Reconstructing Importance Sampling Coreset As discussed in Section 3.2.2, we use GANs to recover the data we lost while performing importance sampling. This was motivated from the observation that as we selected more number of points in importance sampling, the accuracy of the inference on the compressed data increased significantly (at times by 2%).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 219,
    "augmented": false
  },
  {
    "text": "Unlike single-model inferences, more sophisticated tech- niques like  ensemble learning  [ 15 ] have been instrumental in allowing model-serving to further improve accuracy with multiple models. For example, by using the ensembling   1 \ntechnique, images can be classiÔ¨Åed using multiple models  in parallel  and results can be combined to give a Ô¨Ånal prediction. This signiÔ¨Åcantly boosts accuracy compared to single-models, and for this obvious advantage, frameworks like Clipper [ 27 ] leverage ensembling techniques.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "3) ,which can be projected to both eyes on the HMD. The  Transformation  stage, shown in Fig. 3  a  for compu- tation of the  Transformation Matrix , is used for projecting the 360 ¬∞ frame pixels onto the  2 D  FoV plane in the subsequent stages.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Better refers to the improvement over iNAS+PT baseline. 14 \nDatasets Full Power Arduino on Thermal AP PT iNAS+PT NExUME Better FMNIST 98.70 77.04 80.44 83.08 89.90 8.20% CIFAR10 89.81 60.38 65.90 66.98 80.70 20.48% MHEALTH 89.62 65.74 69.88 72.41 85.75 18.42% PAMAP 87.30 62.76 65.93 71.46 81.27 13.73% AudioMNIST 88.20 69.12 73.86 77.79 83.54 7.39% Table 7: Accuracy of NExUME on Arduino nano board using thermocouple based thermal harvester. Better refers to the improvement over iNAS+PT baseline.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 201,
    "augmented": false
  },
  {
    "text": "‚Ä¢  T 5 , the last transformation to be applied, performs a view- port transformation 5 , bringing the projected points to the coordinates used to index the pixels on the HMD. As in the case of  T 4 , this transformation is also HMD design- dependent and is known at design-time. Note that, the  product  of these Ô¨Åve transforms gives us the Ô¨Ånal transformation matrices ( T L  and  T R ), which together convert the  3 D  coordinates of the  360 ¬∞ frame to the  2 D  coordinates suitable for HMD.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Based on the above discussion, in this work, we focus on EA  and  AE  opportunities. We are unaware of any existing implementation or research work that focus on compute reuse by leveraging across-frames and across-eyes memoization. In fact, the existing state-of-the-art software stack, such as GoogleVR-SDK [11], simply uses the IMU sensor inputs to calculate the updated transformation matrices, then passes them to the OpenGL [42] engine to process the projection computation, as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "We will also carve up short lecture materials based on the project and preserve them on departmental machines. Note that the lineage data/metadata will be updated as more characteri- zation and experimental results as well as models are collected/generated or the compiler/system software source codes are updated. 6.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Since the regularizers are deterministic, their gradients ‚àá ‚Ñ¶ SNR ( Œ∏ )  and  ‚àá ‚Ñ¶ complexity ( Œ∏ )  do not introduce bias. Averaged over multiple rounds, the collected gradients form an unbiased estimator   b ‚àá L ( Œ∏ )  of  ‚àá L ( Œ∏ ) : \nE [ b ‚àá L ( Œ∏ )] =  ‚àá L ( Œ∏ ) . Although not all sensors participate every time, the equilibrium ensures a stable pattern of participation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "The architectural backbone of neural codecs typically comprises an autoencoder, where the encoder compresses the video into a compact, lower-dimensional representation, and the decoder reconstructs it back into video format. These blocks can be stacked over each other to form layered codecs (like SHVC and SVC). This process benefits significantly from residual learning techniques, where each successive layer in the network aims to correct errors from the previous layers, thereby enhancing the reconstructed video quality incrementally with each additional decoding layer.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "Existing scheduling algorithms typically assume stable energy availability and do not account for the atomicity constraints imposed by intermittent power supply. Our scheduling approach uniquely integrates: 1. Real-time energy availability into scheduling decisions.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "2964‚Äì2968. [16]  C. Dorea and R. L. de Queiroz, ‚ÄúBlock-based motion estima- tion speedup for dynamic voxelized point clouds,‚Äù in  2018 25th IEEE International Conference on Image Processing (ICIP) , 2018, pp. [17]  J. Elseberg, D. Borrmann, and A. N ¬® uchter, ‚ÄúOne billion points in the cloud ‚Äì an octree for efÔ¨Åcient processing of 3d laser scans,‚Äù  ISPRS Journal of Photogrammetry and Remote Sensing , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "The fused task executes both convolutions atomically within the energy budget, avoiding the overhead of checkpointing between them. Scheduling Problem Formulation:  The scheduling problem is formulated with decision variables s i  (task start times) and binary variables  x i  ‚àà{ 0 ,  1 }  (indicating whether a task is scheduled). The energy availability constraint over time is expressed as (subject to energy and task constraints): P \ni : s i ‚â§ t<f i   E i  ‚â§ E b ( t )  The objective is to maximize the total weighted priority of scheduled tasks: \nmax { x i ,s i } \nN X \ni =1 \n\u0000 p i  ‚àí Œ±E i  ‚àí Œ≤ ( f i  ‚àí D i ) + \u0001 x i .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 201,
    "augmented": false
  },
  {
    "text": "time \nFig. 9: Performance and energy improvements for YOLOv4-tiny w.r.t. the baseline; Region Level Reuse Scheme (e.g., FI+SI+PI) has better performance, because this ‚Äúshallow‚Äù model beneÔ¨Åts more from partial inference.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "5. Check for power loss after each ‚ÄòQuantaTask‚Äò or fused ‚ÄòQuantaTask‚Äò and checkpoint if necessary. Fuse multiple ‚ÄòQuantaTask‚Äòs to minimize load/store operations.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "To summarize, among the above discussed features, we identify  head orientation  as the only suitable memoization candidate for boosting the compute reuse scope. Thus, we memoize both head orientation and its corresponding projec- tion matrix (i.e., projection computation results) in a memory buffer, namely,  P buff , and use the head orientation to index the address/pointer of that  P buff  stored in DRAM. Note however that, this meta- information is not on the data-dependence chain, and we do not consider it for memoization.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "append ( addModel ) 17: end if 18:  end procedure 19:  procedure  W EIGHTED _V OTING ( Models ) 20: for  model in  ‚àÄ Models  do 21: class  ‚Üê model . predicted _ class 22: weighted _ vote [ class ]+ =  weights [ model . class ] 23: end for 24: P class  ‚Üê max ( weighted _ vote , key  =  class ) 25: returnP class 26:  end procedure \n4.1.1 Class-based Weighted Majority Voting \nThe model selection policy described above ensures that we only use the necessary models in the majority voting.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "Firstly, the issue of  (non-)supervision  arises, demanding the ability to label data without human interven- tion to preserve privacy during the learning process. The Problem Space:  To address the multi-faceted challenges of sustainable, scalable and privacy-preserving continuous learning at edge servers, several crucial problem spaces must be explored. While recent works [ 12 ], [ 46 ] have attempted to tackle this concern through student-teacher paradigms, efÔ¨Åciently deploying such approaches in complex data modalities (e.g., multi-class video, 3D point cloud) remains a formidable challenge.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "In  CVPR Workshop on the Future of Datasets in Vision , volume 2. sn, 2015. Smart city technologies and intelligent transportation systems are helping cities absorb growing populations, overcome congestion, and create sustainable futures. Intel Corporation.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Both require the assistance of the cloud, and hence, introduce additional costs and privacy issues. To summarize, even though the prior works discussed above have tried the optimized DNN models, the static compiler/run- \n1075 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "[93] Lei Li, Yankai Lin, Shuhuai Ren, Peng Li, Jie Zhou, and Xu Sun. arXiv preprint arXiv:2401.03205 , 2024. The dawn after the dark: An empirical study on factuality hallucination in large language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "All these videos used are captured at 30fps, and voxelized into  1024 √ó 1024 √ó 1024  voxels (3D points), with each point containing three  Ô¨Çoat-pointing  coordinates and three  unsigned char  RGBs. Table I: Six videos in 8iVFB [ 18 ] and MVUB [ 8 ] datasets used in this paper. Video Redandblack Longdress Loot Soldier Andrew10 Phil10 #Frames 300 300 300 300 318 245 #Points/Frame 727070 834315 793821 1075299 1298699 1486648 \nB. PCC Design ConÔ¨Ågurations \nTo demonstrate the effectiveness of our proposal, we evaluate the following Ô¨Åve PCC designs: ‚Ä¢  TMC13  [ 56 ]: We use TMC13 (G-PCC codec from MPEG), as the  state-of-the-art  approach for  intra-frame compression .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 211,
    "augmented": true
  },
  {
    "text": "Another comparison parameter is the  compression ra- tio . This quality degradation comes as a result of the parallel algorithm, and we argue that the PSNR values resulting from our proposal are still very good for most video and AR/VR applications [ 6 ], [ 77 ]. VI , our proposal drops the quality a little bit (PSNR  ‚âà 80 dB in our design).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "2018. KylinX: a dynamic library operating system for simplified and efficient cloud virtualization. In  2018 USENIX Annual Technical Conference .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Another interest- ing observation is that,  Intra-Holo  saves more execution time than Inter-Holo . Recall that the number of depth planes for each hologram object affects the ex- ecution latency dramatically as shown in Fig. 4b; thus, these per- formance benefits come from the speedup brought by the reduced depth planes by approximation in our schemes.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "[41]  H. Liu, H. Yuan, Q. Liu, J. Hou, and J. Liu, ‚ÄúA comprehensive study and comparison of core technologies for mpeg 3-d point cloud compression,‚Äù  IEEE Transactions on Broadcasting , pp. 449‚Äì461. [40]  Y. Lin, Z. Zhang, H. Tang, H. Wang, and S. Han, ‚ÄúPointacc: EfÔ¨Åcient point cloud accelerator,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2021, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "AASR thus bridges the major gaps in the design that we intend to achieve. With the addition of  recall , we have a fully functional ensemble learning system on a EH-WSN. AASR intelligently takes advantage of multiple DNNs (by bringing in activity aware scheduling), leverages the workload (by considering the activity continuity via recall and extended round-robin strategies), and also poses minimal overhead on the host device for running aggregation.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "After Ô¨Åltering out the ‚Äúno change in MV‚Äù cases for SI in Line  19  in Algo.1, we next fuse all of the MVs together and Ô¨Ålter the small ones (i.e., noises) out (shown in Line  21 ). Next, we iterate each MV block for Scenario-1, Scenario-2 and Scenario-3 (shown from Line  22  to Line  31 ). for different cases.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "3 Prelude to Cocktail \nTo speciÔ¨Åcally address the cost of hosting an ensembling- based model-serving framework in public clouds without sacriÔ¨Åcing the accuracy, this section introduces an overview of the two primary design choices employed in  Cocktail . Therefore, it is important to ensemble an ‚Äúoptimal‚Äù number of less compute intensive models to reduce the cost. As shown in Figure  3b , Ensemble-OD is always ex- pensive than single-OD for the all the models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Quantifying generalization complexity for large language models, 2024. [134] Samyam Rajbhandari, Conglong Li, Zhewei Yao, Minjia Zhang, Reza Yazdani Aminabadi, Am- mar Ahmad Awan, Jeff Rasley, and Yuxiong He. Deepspeed-moe: Advancing mixture-of-experts inference and training to power next-generation ai scale.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Even a 10ms reduction in latency is of signiÔ¨Åcant importance to the providers [ 35 ]. We observe a similar trend of higher en- semble accuracy for other four baseline models with a latency reduction of up to 1.3 √ó . Thus, depending on the model sub- set used in the ensemble, it achieves better accuracy than the baseline at lower latencies.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Task Fusion and Scheduling:  DynInfer introduces a novel task scheduling algorithm that dynam- ically adjusts to real-time energy availability. At any given time  t , the available energy is denoted as  E b ( t ) . When the energy required for executing multiple QuantaTasks exceeds the available energy budget, DynInfer employs  task fusion  to combine smaller tasks into larger atomic units that can be executed within the energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Considering the scale of the problem, the execution time on a desktop machine is almost same as a larger cluster that we typically find in a cloud. correlation for 4-home setup). The accuracy improvement in the 4-home setup is significant and the reason for the lower edge accuracy of the 4-home setup is the limitation in number of training samples (2 home setup has twice the amount of data than the 4 home setup to train with).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "IEEE, 2006. [128] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K√∂pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "4 GiB of data per second per imaging source. This pipeline assumes the use of classical data encoding algorithms like H264 4   which requires all the frames to encode a video stream, albeit it only saves the essential information. Therefore, it does not use any of the computations that are used in the inference and learning pipeline.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "However, these compute-intensive algorithms can be optimized further through dedicated hardware acceleration. Designing a learning platform that can adapt to intermittent renewable energy sources (e.g., solar power) and maintain a minimal operational carbon footprint [ 29 ] is paramount. Thirdly, the aspect of  sustainability  poses a critical question of deploying such systems, ideally with minimal reliance on the power grid for learning tasks.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Also, the number of concurrent requests which can be executed in VMs should be accurately determined to meet response latency. Observation 2:  VMs should be used to handle requests during constant arrival rates. Hence, nor- malized by number of requests, bigger VMs would still incur similar costs as smaller VMs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "However, deploying such architectures on ultra-low-power, energy-harvesting devices presents significant challenges due to their substantial \n9 \n200 250 300 350 400 450 500 550 600 \nLatency (ms) \n78 80 82 84 86 88 90 92 94 \nAccuracy (%) \nAccuracy vs. Latency for Different Classes \nR1 R2 R3 SJ SI \n(a) Accuracy vs Latency \n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 Capacitance (F) \n78 \n80 \n82 \n84 \n86 \n88 \n90 \n92 \nAccuracy (%) \nAccuracy vs. Capacitance for Different Classes \nR1 R2 R3 SJ SI \n(b) Accuracy vs Capacitance \nFMNIST CIFAR10 MHEALTH PAMAP AudioMNISTMachine Dataset \n0 \n20 \n40 \n60 \n80 \n100 \nAccuracy (%) \nAbalation Study \nDN DN+DF DN+DF+DI \n(c) Ablation Study Figure 3: Sensitivity and ablation study. computational and memory requirements. DN is DynNAS, DF is DynFit, and DI is DynInfer.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 273,
    "augmented": true
  },
  {
    "text": "11 shows the impact of increasing the number of CSDs in a storage server. Similarly, Fig. With increasing the number of CSDs per SSD (or other storage element) does show significant improvement because of increase in parallelism.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "We performed a study on the VR video dataset [3] to investigate the head orientation traces of 20 users watching 5 widely- variant  360 ¬∞ VR videos (summarized in Tab. To address this, we need to carefully decide how much his- tory is to be memoized for leveraging computation reuse. II).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "1 For squeezenet model, allocating beyond 2GB did not reduce computation time, but resulted in increased cost 2 The smallest standard performance VM (C4 family) comes with 2 vcpus and 3.75GB memory. But serverless functions can be configured starting from 1 vcpu and 0.128GB memory. Implications of Public Cloud Resource Heterogeneity for Inference Serving WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands \n3 How to Design Self-Managed ML Prediction Serving System?",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Lastly, we apply coarse-grain power gating to conÔ¨Ågure the number of duplicated ReRAMs. This reconÔ¨Åguration ability can enable scaled activation of the circuits such that small tile-size computation can be enabled while yielding very low power consumption. V. P OWER - DYNAMIC  RCA  SCHEDULING \nGiven a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Finally, combination of the two schemes ( Inter-Intra-Holo ), results in 28 . This indicates that the optimization scope of the distance- based  Intra-Holo  is larger than that of the RoF-based  Inter-Holo , which provides more sparsity in the hologram computing. 95% power reduction compared to the baseline.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "In Augmented Reality, Virtual Reality, and Computer Graphics: 8th International Conference, AVR 2021, Virtual Event, September 7‚Äì10, 2021, Proceedings 8 , pp. 135‚Äì155. Springer, 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "It also provides us access to new contacts and additional recruitment opportunities of diverse students. We have also participated in the annual Exploration-U Science day events, organized by Penn State. This event helps to create awareness to a much broader audience to our targeted efforts for summer camps and summer internship opportunities.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "We plan to model this problem using a ‚Äúbipartite graph‚Äù (refer to Figure 4) where one set of nodes represent disjoint datasets (D1, D2, etc.) ). Additionally, by clustering and scheduling experts that share training datasets, we propose a ‚Äúlocality-aware‚Äù training strat- egy that minimizes the frequency and volume of data transfers between experts, memory and storage‚Äì a key factor in improving both performance and energy efficiency. and the other represent experts (E1, E2, etc.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "To identify them, we studied two published AR datasets (Objectron [ 1 ] for objects shown in Fig. 3b), and observed the following two properties in the AR holographic applications: Spatio Diversity for Objects:  Intuitively, objects which are far from the user and with small-sized shapes require less informa- tion to generate the virtual hologram than others (more details are provided in Sec. 3a, and MPIIDEye [ 58 ] for users shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Compute express link (cxl): Enabling heterogeneous data-centric computing with heterogeneous memory hierarchy. IEEE Micro , 43(2):99‚Äì109, 2022a. Debendra Das Sharma.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors,  Pro- ceedings of the 40th International Conference on Machine Learning , volume 202 of  Proceedings of Machine Learning Research , pages 38087‚Äì38099. [168] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis. PMLR, 23‚Äì29 Jul 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "They will also be encouraged to affiliate with one or more professional societies in their chosen field. They will also have access to the various Responsible Conduct of Research and DEIB (Diversity, Equity, Inclusion, and Belonging) training courses offered by Penn State. Diverse Collaborations \nFinally, the PhD students in the project will be encouraged to engage in collaborations with researchers from diverse backgrounds and disciplinary areas to enhance their collaboration and communication skills.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Expert Repository. For expert types, as shown in Figure 3, we will cover different do- mains such as scientific, medi- cal, legal, and education, skills such as math reasoning, cod- ing, question answering, and summarization, data modal- ity such as structured data (ta- bles, databases), unstructured data (documents, speech tran- scripts), semi-structured data (XML, JSON), and images, and languages such as En- glish, Chinese, Turkish, and many other low-source lan- guages. Under each type, there can be subtypes of ex- perts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "[4]  2020. Amazon States Language. https://docs.aws.amazon.com/step- functions/latest/dg/concepts-amazon-states-language.html.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Iot & ai market forecasts. Transforma Insights. https://transformainsights.com/research/ tam/market , 2023.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "The proof relies on constructing a potential function  Œ¶  that is strictly increased by unilateral profitable deviations and bounded above. The impossibility of infinite improvement sequences guarantees the existence of an NE, and the assumptions on monotonicity, boundedness, and discounting ensure that the iterative best-response process converges to this equilibrium. ‚ñ° \nC. Proof of Convergence for the Equilibrium-Aware Training Process \nIn this appendix, we provide a comprehensive and detailed proof of the convergence theorem stated in the main text.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "Our experiments suggests variance to be the most suitable metric to decide the threshold. If the user task can tolerate lower accuracy prediction, or the user is more conservative about the cost associated with sending a request to the cloud, they could decide to change the threshold according to their requirements. Consequently, the programmable threshold makes the whole design more flexible: the collaboration ratio can be adjusted based on the needs of different types of machines, and more ro- bust compared with the result dependent model simplification strategy which may perform differently on different datasets.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Recall that the number of depth planes for each hologram object affects the ex- ecution latency dramatically as shown in Fig. 4b; thus, these per- formance benefits come from the speedup brought by the reduced depth planes by approximation in our schemes. Another interest- ing observation is that,  Intra-Holo  saves more execution time than Inter-Holo .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Due to high start-up latencies, using VMs for hosting ML services can lead to over-provisioning, espe- cially during periods of poor workload predictability (flash crowds) [ 10 ]. In stark contrast to VMs, serverless functions have been made available by cloud providers, which can spin-up within a few seconds [ 2 ]. As we will discuss in this paper, the cost of using VMs vs. serverless functions highly depends on the dynamically varying needs of the user query submission rates.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "Restrictions apply. VI. D ISCUSSION \nKey insights:  Compared to other systems, the ratio of energy requirement of task vs the harvested energy is much higher here.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "https://community.intel.com/t5/Blogs/Tech-Innovation/Data-Center/ Intel-Labs-Showcases-Multi-Vendor-Computational-Storage-Platform/post/ 1404651 , August 2022. (Accessed on 11/13/2023). Daniele Micciancio and Oded Regev.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "1 √ó , respectively. This paper pro- vides a comprehensive overview of the potential of CSDs to revolutionize storage, making them not just data repositories but active participants in the computational process. 2 √ó  and  ‚âà 6 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Fig. 10 shows the impact of scaling  Salient Store  with respect to a single node system, i.e., a single storage server. As the number of storage servers increases, the network contention and data orchestration challenges exponentially increase.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Central to the Ring-Learning with Errors (R-LWE) based Public Key Encryption (PKE) is the equation d  =  a  ¬∑  b  +  c . In this context, the operand  a  can represent polynomials such as  p ,  a , or  c 1  from Algorithm 1, while  b  corresponds to  e 1 ,  r 2 , and  c  to  e 2 ,  e 3 ,  c 2 . During the data loading phase, the 256 coefficients of polynomial  b  are input serially into a 6-bit shift register.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "3, is to determine a transformation matrix by com- bining Ô¨Åve different transforms. The second stage,  Projection Computation  (denoted  b  in Fig. 3), uses the transformation matrix and the 2D FoV coordinates for both eyes to obtain \n4 We used an averaged pupillary distance in our evaluations [27], [37].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "This is mainly because TMC13 performs lossless geometry compression and almost-lossless attribute com- pression in our settings. Additionally, the transform and quantization in TMC13 can output (near-)zero coefÔ¨Åcients, which signiÔ¨Åcantly increases the compression ratio. Note however that, this comes at the cost of longer processing latency, as shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Based on the decreasing order of accuracy, we categorize them into  Strict  and  Relaxed  workloads. 5.2.1 Evaluation Metrics \nMost of our evaluations of  Cocktail  for image-classiÔ¨Åcation are performed using the  Imagenet  dataset. To further demon- strate the sensitivity of Cocktail to dataset and applicability to other classiÔ¨Åcation applications, we also evaluate it us- ing  CIFAR-100  and Sentiment-Analysis application.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "828‚Äì842, 2017. [49]  G. Meynet, Y. Nehm ¬¥ e, J. Digne, and G. Lavou ¬¥ e, ‚ÄúPcqm: A full- reference quality metric for colored 3d point clouds,‚Äù in  2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX) , 2020, pp. 1‚Äì6.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": ", 11(12):2046‚Äì2049, aug 2018. ISSN 2150-8097. doi: 10.14778/3229863.3236256. URL  https://doi.org/10.14778/3229863.3236256 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "2.1.1 Static DAGs : In static function chains (or DAGs), the workflows are specified in advance by the developer (using a schema), which is then orchestrated by the provider. This re- sults in a predetermined path being traversed in the event of an application invocation. For example, in  Hotel Reservation (Figure 1c), if only one path (say,  NGINX - Make_Reservation ) is always chosen, it represents a static function chain.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "More importantly, EH can help us build sustainable distributed sensing/monitoring infrastructure at virtually inaccessible places like oil-wells, mines, and even satellite orbits [ 14 ,  49 ]. Specifically, recent works [ 24 ,  43 ] pro- posed EH, along with compiler/runtime optimizations and leveraging non-volatile processors (NVP) [ 40 ,  56 ], to increase local compute at the edge. EH as a solution has been partic- ularly interesting as a means to address the sustainability issue of battery backing trillions of future devices.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "Further, neighboring experts can be mapped to adjacent chiplets for improving physical proximity and reducing data movement costs. For example, smaller experts may be mapped to individual chiplets (or can be colocated in the same chiplet), while a large expert may be mapped to multiple chiplets. Or, multiple low hot experts can be assigned to one chiplet, and high hot experts can be distributed across chiplets.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "For example, the average CPU power for TMC13 is  1687 mW whereas  3622 mW  for CWIPC. 38 J  per PC frame, which represents  96 . On the other hand, our Intra- Only scheme only consumes  0 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "This reduces software overheads and latencies for handling power emergencies and hence can guarantee better QoS for complex and longer tasks even when power is deeply unreliable. Using an NVP and multiple harvested energy sources Qiu et al. [ 56 ] demon- strates the possibility of performing complex DNN inference at the EH-Sensor itself.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "3.2 Communication vs Accuracy We can tune the aforementioned coreset construction tech- niques allow a variable number of features depending on the available energy, i.e. Since clus- tering better preserves the geometry of the distribution, we observe that inferences with coresets constructed using clus- tering are more accurate than using importance sampling, and therefore can be preferred over the former whenever there is enough energy. These are then communicated to the host device for inference.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Note that variability in application usage patterns can lead to changes in function probabilities within each DDA, which the policy will have to account for. Challenge 2: Adaptive Container Provisioning. While probability-based container provisioning can significantly reduce the number of containers, the presence of container cold-starts leads to SLO violations (requests not meeting their expected response latency).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "Although datacenters also try to take leverage of the diversity of heterogeneous computing platforms, they are much slower and very expensive during adop- tion [50,104,105]. To explore the search space, we plan to investigate four design choices: what types of chiplets are needed in a chip, how the EoE can be mapped to our chip, how the memory hierarchy can be tailored for a given EoE mapping, and how the chiplets and chips can be interconnected, as illustrated in Figure 6. We can create a chiplet version of each hardware of interest, and use them as plug-and-play mod- ules, while combining them to create a variety of chips.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "This aids us in the calculation of function invocation probabilities. Wherever appropriate, we draw in- spiration from related works that model user web surfing \n156 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \n0 \n0.25 \n0.5 \n0.75 \n1 \nHit Rate \n(a) Social Network. 0 \n0.25 \n0.5 \n0.75 \n1 \nHit Rate \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "This effect can worsen if the same were to happen with multiple critical functions. In addition to critical functions, it is also crucial to assign higher weights to common functions as well. Common func- tions refer to those which are a part of two or more paths within an application DAG.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "We use two different datasets, MHEALTH [12], [13], and PAMAP2 [16], [17], for our evaluation which follow the similar sensor setup described in Section IV-A. Further, to build an energy efÔ¨Åcient version of the DNNs, we applied the energy-aware DNN optimizations proposed in [3], [15]. However, instead of designing a centralized DNN which processes the combined data from all the sensors, we design three different smaller DNNs that work on their individual data.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "). However, it also introduces complexities in coordinating sensor activities, managing energy resources, and ensuring efficient data collection and processing ( ? 2.2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "The intra-frame approach speeds up the geometry and attribute compression by  37 √ó  and  49 √ó  respectively, while the inter- frame approach further improves the compression ratio by ‚âà 1 . Motivated by these opportunities, we propose and evaluate a two-pronged compression approach, where the  intra-frame approach leverages the opportunities described in 1  and 2  , and the  inter-frame  approach takes advantage of 3  . 75 √ó  by reusing the matched blocks in reference frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "ACM, 2019. [27] Z. Gong, H. Ji, C. W. Fletcher, C. J. Hughes, and J. Torrellas, \n‚ÄúSparsetrain: Leveraging dynamic sparsity in software for training dnns on general-purpose simd processors,‚Äù in  Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques , 2020, pp. [26] G. Gobieski, B. Lucia, and N. Beckmann, ‚ÄúIntelligence beyond the \nedge: Inference on intermittent embedded systems,‚Äù in  ASPLOS .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. 0 20 40 60 80 100 \n0 20 40 60 80 100 \nClass Distribution \nAccuracy (%) \nBaseline Train-Win-1 Train-Win-2 Train-Win-4 Appeared \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "This training framework is intrinsically linked to the game-theoretic participation strategies. Sensors participate \nin training rounds based on their equilibrium-driven de- cisions, ensuring that gradient updates are contributed by those sensors most capable and willing to improve the global model. Our training framework is encapsulated in Algorithm  2 , which outlines the periodic equilibrium-aware training pro- cess.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Since two identical head orientations lead to the same projection matrices, one opportunity to reduce computation is to  memoize  a set of head orientations as well as their corresponding compute results. Vision Proximity:  It is to be emphasized that, even when the head orientation input for two computations are the same, the two eye coordinates can be different. Because of this, in current designs, the projection transformation is invoked  twice as it needs to generate two different transformation matrices for the left eye and the right eye.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "He and F. Zhu, ‚ÄúOnline continual learning for visual food classiÔ¨Å- \ncation,‚Äù in  Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021, pp. 2337‚Äì2346. [32] K. He, X. Zhang, S. Ren, and J.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment. Figure 4 shows Ô¨Åve harvested power sources with the maximum, mean and median values and their ratios indicated. It has been shown that the power requirement to fully activate a 128 √ó 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [ 3 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "29, no. [12]  T. Cosso, I. Ferrando, and A. Orlando, ‚ÄúHigh-precision laser scanning for cave tourism 3d reconstruction of the pollera cave, italy,‚Äù  GIM INTERNATIONAL-THE WORLDWIDE MAG- AZINE FOR GEOMATICS , vol. [11]  A. Corning, ‚ÄúAR/VR in the OR ‚Äì Surgical Applications of Augmented and Virtual Reality,‚Äù  ‚Äùshorturl.at/fqwAJ‚Äù , 2021.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "In Proceedings of the 2017 ACM SIGPLAN International Conference on Compiler Construction , pages 1‚Äì12. Fusing kernels for higher performance deep learning. ACM, 2017.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "ResiRCA supports smooth transi- tions among different activation solutions against computation loss. The experiment results show that the proposed ResiRCA along with the ResiSchedule scheme can achieve much higher speedups and energy efÔ¨Åciency compared to the baselines. ResiRCA for the Ô¨Årst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "[6]  Amazon. Sagemaker. https://aws.amazon.com/sagemaker/, February 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "MITP-Verlags GmbH & Co. KG, 2018. [23]  Andrew Chung, Jun Woo Park, and Gregory R. Ganger. Stratus: Cost-aware container scheduling in the public cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Fur- ther, for those inferences unfinished because of the harvested energy constraints, it leverages task-aware coreset construc- tion to efficiently communicate compact features to the host device. 9 √ó  reduc- tion in communication data volume with 86 . We evaluate  Seeker  for human activity recognition, as well as predictive maintenance and show  ‚âà 8 .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Depending on the available energy, the task (vector inner product) can be divided into multiple iterations such that each QuantaTask is guaranteed to finish given the energy availability. Optimization Variables, Constraints, and Objective Function:  The optimization problem is formulated with variables: the weights  W , dropout rates  d , quantization levels  q , and QuantaTask sizes  ‚Ñì . E  is available energy, and  E b  is the energy required to finish one inner product.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "[38] Junchen Jiang, Ganesh Ananthanarayanan, Peter Bod¬¥ƒ±k, Siddhartha \nSen, Ion Stoica, ‚ÄúChameleon: Scalable adaptation of video analytics,‚Äù in  ACM SIGCOMM , 2018. [39] Junjue Wang, Ziqiang Feng, Shilpa George, Roger Iyengar, Pillai Pad- \nmanabhan, Mahadev Satyanarayanan, ‚ÄúTowards scalable edge-native applications,‚Äù in  ACM/IEEE Symposium on Edge Computing , 2019. 1‚Äì12.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "[51]  Mu Editor 2022. In  IEEE INFOCOM 2020-IEEE Conference on Computer Communications . IEEE, 854‚Äì863.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "However, the intermittent and limited energy income of these deployments demands optimizations for ML applications at the algorithm (Yang et al., 2017; Shen et al., 2022; Mendis et al., 2021), orchestration (Maeng & Lucia, 2018; Mishra et al., 2021), compilation (Gobieski et al., 2018), and hardware development (Qiu et al., 2020; Islam et al., 2022; Mishra et al., 2024) layers. Despite these advancements, achieving consistent and accurate inference‚Äîthereby meeting service level objectives (SLOs)‚Äîin such intermittent environments remains a significant challenge, exacerbated by unpredictable resources, form-factor limitations, and variable computational availability, particularly when employing task-optimized deep neural networks (DNNs). There are two major problems with performing DNN inference under intermittent power.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 220,
    "augmented": false
  },
  {
    "text": "67, pp. 491‚Äì506, 2017. [70] A. Prabhu, C. Dognin, and M. Singh, ‚ÄúSampling bias in deep active \nclassiÔ¨Åcation: An empirical study,‚Äù  arXiv preprint arXiv:1909.09389 , 2019.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "27, p. 28, 2009. [63] S.-H. Noh, J. Koo, S. Lee, J. Park, and J. Kung, ‚ÄúFlexblock: A Ô¨Çexible \ndnn training accelerator with multi-mode block Ô¨Çoating point support,‚Äù IEEE Transactions on Computers , 2023.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "[65]  Atul Rahman, Jongeun Lee, and Kiyoung Choi. EfÔ¨Åcient fpga acceler- ation of convolutional neural networks using logical-3d compute array. In  2016 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pages 1393‚Äì1398.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Peer-Before-Server:  Although sharing data with the cloud helps us build robust models, the communication latency is significantly higher than local computation, prompting several \nworks [6] to push compute to the edge. For latency-sensitive applications, offloading to peers may be more viable than offloading to the cloud. Relying on how different the answers from each estimators are, we can quantify the prediction quality of the random-forest.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Figure 16: Communication data volume with different number of clusters. Component Spec Power Area(mm 2 ) \nSRAM Buffers \n1kB*256+ 8kB*256+ 64kB+16*256kB \n10.372W 117.164 \nMAC Unit (8*8) 256 8.46W 32.72 \nAdder Tree and Comparator 16*16bit + 256 2.4W 21.556 \nControl ‚Äì 0.96W 12.2 Host ‚àº Cortex A78 series 11W ‚Äì Design at 592MHz with Synopsys AED 32nm library \nTotal 256 tiles 33.192W 183.64 Table 3: Area and power estimation of our design. 15 \n0 \n20 \n40 \n60 \n0 \n0.1 \n0.2 \n0.3 \n0.4 \n1 \n4 \n7 \n10 \n13 \n16 \n19 \n22 \n25 \n28 \n31 \n34 \n37 \n40 \n43 \n46 \n49 \n% Reconstruction Error \nFFT Amplitude \nFrequency (Hz) Reconstructed Original % Error \nFigure 14: An example of generator based coreset re- covery \nFigure 15: % completion of the inference at the edge for bearing fault data with different EH source.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 251,
    "augmented": true
  },
  {
    "text": "This signiÔ¨Åcantly boosts accuracy compared to single-models, and for this obvious advantage, frameworks like Clipper [ 27 ] leverage ensembling techniques. Nevertheless, with ensem- bling, the very high resource footprint due to sheer number of models that need to be run for each request [ 27 , 56 ], ex- acerbates the public cloud deployment costs, as well as leads to high variation in latencies. Since cost plays a crucial role in application-provider consideration, it is quintessential to minimize the deployment costs, while maximizing accuracy with low latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "There has been a signiÔ¨Åcant body of work on frame similarity and saliency [ 45 ], [ 84 ], [ 101 ], [ 105 ], [ 107 ], [ 108 ], and those details remain beyond the scope of this work. A. Data Annotation \nPicking the Important Ones:  Typically, edge models are ca- pable of inferring at the frame rate of the camera (at times, 30fps to 60fps) [ 19 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Heiner Lasi, Peter Fettke, Hans-Georg Kemper, Thomas Feld, and Michael Hoffmann. Industry 4.0. Business & information systems engineering , 6(4):239‚Äì242, 2014. 11 \nYongpan Liu, Zewei Li, Hehe Li, Yiqun Wang, Xueqing Li, Kaisheng Ma, Shuangchen Li, Meng-Fan Chang, Sampson John, Yuan Xie, et al.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "[37]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Mahmut Taylan Kandemir, Bhuvan Urgaonkar, George Kesidis, and Chita Das. In  USENIX Middleware Conference , 2020. Fifer: Tackling Resource Underutilization in the Serverless Era.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Swift: Adaptive video streaming with layered neural codecs. In  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , pp. 103‚Äì118, 2022a.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "When power is highly uncertain, the morphable hardware also strongly contributes, however, as the power proÔ¨Åle becomes stable, the algorithmic contributions dominate. Fig. 10a  shows the contribution of the different components of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Besides, most of the NN-PCC only focus on compressing geometry data [ 88 ], thus, is not applicable for this paper‚Äôs target (i.e., mainly for vision applications where the attributes are essential). Considering that NN-PCC can take thousands of seconds to compress one PC frame [ 88 ], such a huge gap between the long execution latency of NN-PCC and the \n2 Although V-PCC and NN-PCC have high compression efÔ¨Åciencies, they are compute-intensive [ 41 ], [ 88 ], and consequently, are not the best option for mobile devices and are not considered in this work. 0 \n500 \n1000 \n1500 \n2000 \nTrans.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "Since this puts a high demand on memory, one edge VR headset cannot afford to memoize for all possible head orientations. Thus, we want to limit the number of  P buff  that we need to store. To address this, we need to carefully decide how much his- tory is to be memoized for leveraging computation reuse.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "BL indicates the baseline models. Moreover, ensemble learning \nActivity Policy Comparision RR12 Origin BL-2 BL-1 vs BL-2 vs BL-1 Walking 81.60896 84.46 91.56 -2.85104 -9.95104 Climbing 83.10679 77.93 83.24 5.176789 -0.13321 Cycling 85.88992 85.81 94.27 0.079918 -8.38008 Running 87.13474 81.29 86.91 5.844736 0.224736 Jogging 81.81809 78.04 83.17 3.778086 -1.35191 Jumping 83.69378 79.42 84.26 4.273776 -0.56622 \nTABLE I:  Comparing RR12 Origin with both the baselines on MHELATH dataset. This makes  Origin  versatile and suitable for systems whose intermittence comes from either or both of power or device reliability limitations, both of which will be key factors in real-world IoT deployments.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 242,
    "augmented": true
  },
  {
    "text": "This work explores policies for partitioning random forest approaches, which are widely used for inference tasks in smart manufacturing, among sets of devices with different resources and data visibility. We demonstrate, using both publicly available datasets and a real-world grinding machine deployment, that our privacy-preserving approach to partitioning and training offers superior latency-accuracy trade- offs to purely on-edge computation while still achieving much of the benefits from data-sharing cloud offload strategies. Index Terms ‚Äîedge computing, random forest, edge-cloud par- titioning, sensor network \nI. I NTRODUCTION R Etrofitting intelligent sensors nodes on legacy manufac- turing systems provides cost-effective smart manufac- turing upgrades.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 170,
    "augmented": false
  },
  {
    "text": "22 \nCalculate the gradients of the loss with respect to the activations: \n‚àÇ L ‚àÇ a i \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the Taylor expansion approximation: \np i  = Œª \f\f\f  ‚àÇ L \n‚àÇ a i   a i \f\f\f  +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Inference with Taylor Expansion Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 340,
    "augmented": true
  },
  {
    "text": "133‚Äì148, 2019. [75]  S. Schwarz, M. Preda, V. Baroncini, M. Budagavi, P. Cesar, P. A. Chou, R. A. Cohen, M. Krivoku ¬¥ ca, S. Lasserre, Z. Li, J. Llach, K. Mammou, R. Mekuria, O. Nakagami, E. Siahaan, A. Tabatabai, A. M. Tourapis, and V. Zakharchenko, ‚ÄúEmerging mpeg standards for point cloud compression,‚Äù  IEEE Journal on Emerging and Selected Topics in Circuits and Systems , pp. [76]  J. Shao, H. Zhang, Y. Mao, and J. Zhang, ‚ÄúBranchy-gnn: A device-edge co-inference framework for efÔ¨Åcient point cloud processing,‚Äù in  ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , 2021, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 241,
    "augmented": true
  },
  {
    "text": "[99] Zichang Liu, Aditya Desai, Fangshuo Liao, Weitao Wang, Victor Xie, Zhaozhuo Xu, Anastasios Kyril- lidis, and Anshumali Shrivastava. Scissorhands: exploiting the persistence of importance hypothesis for llm kv cache compression at test time. In  Proceedings of the 37th International Conference on Neural Information Processing Systems , NIPS ‚Äô23, Red Hook, NY, USA, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "o information. In this case, the side length of the bounding box cube becomes 2 , and now  P 0  is located inside the bounding box. When inserting the Ô¨Årst  P 0  point into the bounding box and the octree, two actions are taken: (1) expanding the bounding box with a step-size of  2 n , where n  =  1 , 2 , 3 , ¬∑¬∑¬∑ , until  P 0  is wrapped inside the bounding box.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "6.1 Latency, Accuracy and Cost Reduction \nLatency Distribution : Figure  7  shows the distribution of to- tal response latency in a standard box-and-whisker plot. The total response latency includes additional 200-300ms incurred for query serialization and data transfer over network. The boundaries of the box-plots depict the 1st quartile (25th per- centile (PCTL)) and 3rd quartile (75th PCTL), the whiskers plot the minimum and maximum (tail) latency and the middle line inside the box depict the median (50 PCTL).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "We detail the design of the hardware accelerated encryption and maximize the resource reuse between the exemplar selection and encryption. ‚Ä¢  Finally we perform an in-depth exploration of this integration, supported by real-world data from domains such as autonomous driving and urban mobility, to illustrate its effectiveness in continuous learning scenarios. The proposed design provides  ‚âà 2 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Such small amount of overhead indicates that our decision-making logic is efÔ¨Åcient and light-weight. 9b. 2) Energy Savings:  As shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "However, these devices take a ‚Äúthroughput-Ô¨Årst‚Äù approach, to minimize the time consumption and seldom optimize power consumption Ô¨Årst. This has lead to a global concern of the energy and consequently carbon-footprint of the DNN training [ 21 ], [ 57 ], [ 67 ], [ 89 ]. Furthermore, these accelerators have been designed to operate under constantly available power.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "(2019). [47]  Anjul Patney, Marco Salvi, Joohwan Kim, Anton Kaplanyan, Chris Wyman, Nir Benty, David Luebke, and Aaron Lefohn. 2016.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "(Accessed on 11/13/2023). Lizhou Fan, Zhanyuan Yin, Huizi Yu, and Anne J Gilliland. Using machine learning to enhance archival processing of social media archives.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "reside in the mas- ter node. Also all VM speciÔ¨Åc metrics such as current_load, CPU utilization, etc. Master-Worker Architecture : The master node handles the major tasks such as (i) concord model selection policy, (ii) request dispatch to workers VMs as asynchronous future tasks using  Python asyncio  library, and (iii) ensembling the pre- diction from the worker VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "It can be seen that,  Cocktail  is up to 1.45 √ó  more cost effective than  InFaas  for  Strict  workload. In addition, Cocktail  reduces cost by 1.35 √ó  and 1.27 √ó  compared to Clipper  and  Clipper-X  policies, owing to its dynamic model selection policy, which minimizes the resource footprint of ensembling. On the other hand,  Clipper  uses all models in ensemble and the  Clipper-X  policy does not right size the models as aggressively as  Clipper , hence they are more expensive.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Mahmut Taylan Kandemir (Co-PI):  Kandemir‚Äôs expertise includes optimizing compilers, storage sys- tems, HPC, and workload characterization. He will lead Thrust-2 and collaborate with Das and Zhang in Thrust-4. He will lead Thrust-3 and also co-lead Thrust-4 with Co-PIs Zhang and Kandemir.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Distance Vector Study:  Let us further look into the detailed mapping of a  360 ¬∞ frame (in equirectangular format) onto a 2 D  FoV frame in the Projection Mapping stage (refer  c  in Fig. 3), at a pixel granularity. The pixel rendered at  [ x 0 l   , y 0 l   ]  on the left VR screen is mapped from position  [( x 360 ) 0 l   ,  ( y 360 ) 0 l   ] on the equirectangular  360 ¬∞ frame, as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "¬¥as  uses non-volatile state buffers (NVSBs, 18 count, 1 per 4x4 tiles, each of 1kB, and 2 of 4kB each) for state saving and data backup. The control logic prioritizes writing data into the local NVSB for the arbiter (each arbiter caters to 2 STiles). If those get full because of continuous power failures, the control directs the data to the global NVSBS (NVSB-NW and NVSB-SE in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "If the model overfits high-SNR data, increase  Œª 1 . 3. Tune  Œª 1 , Œª 2  based on validation performance.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "To summarize, compared to 2D video processing,  360 ¬∞ video processing incurs additional projection computation. However, since the whole computation/rendering process takes place on a battery-backed device [39], one needs to consider the ‚Äúenergy efÔ¨Åciency‚Äù of this computation, i.e., even though we can meet the performance requirements of such video, energy efÔ¨Åciency needs to be improved. From our measurements collected from a smartphone [53] running a  360 ¬∞ VR application [11], even with extra computa- tion, the overall processing for rendering one  360 ¬∞ frame can be completed within 22  ms  on average (translating to 45 fps).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "[2]  Marc Brooker, Andreea Florescu, Diana-Maria Popa, Rolf Neugebauer, Alexandru Agache, Alexandra Iordache, Anthony Liguori, and Phil Piwonka. 2020. Firecracker: Lightweight Virtualization for Serverless Applications.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Kraken  exhibits delay characteristics simi- lar to  Fifer  owing to both policies having batching and a similar container pre-deployment policy. DProb and  SProb  exhibit higher overall end-to-end response times compared to  Kraken , with  SProb  experiencing a dispropor- tionately high queueing delay compared to its cold start delay. However,  Kraken allocates fewer containers (57% lesser, on average across all applications) along each workflow compared to  Fifer .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "One major issue is, most of the works leverage ‚Äúpre-existing‚Äù DNNs, which are typically designed for running on a stable resource environment, while being deployed on an intermittent environment with pseudo notion of stability via check-pointing, and therefore, one direction of works (Mendis et al., 2021) looks for performing network architecture search for intermittent devices. However, this research direction only accounts for fixed lower and upper bounds of energy and compute capacities, overlooking the ‚Äúsporadic‚Äù nature of energy availability and the elasticity of the compute hardware (i.e., the ability to dynamically scale frequency, compute, and memory). Moreover, while the DNN is designed to operate within a specific power window, it is  not  trained to adapt to these fluctuations.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 168,
    "augmented": false
  },
  {
    "text": "In case of abundant energy supply, one can use a round robin policy Ô¨Åt for the given EH source. ‚Ä¢  Table I shows the accuracy comparison between the RR12- Origin  with both the baselines. We observe that, for the MHEALTH dataset, RR12- Origin  is 2.72% more accu- rate than the Baseline-2.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Since majority voting can include ties in votes, we analyzed the number of ties, which were correctly predicted for all the queries. Cocktail  was able to deliver correct predic- tions for 35% of the tied votes, whereas breaking the ties in Clipper  led only to 20% correct predictions. USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1049 \nInFaas Clipper Cocktail Policy \n0 \n500 \n1000 \n1500 \nResp.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "These tailored models enable accurate inference with high throughput and reduced resource footprint, with some compressed models having approximately 50 √ó  fewer parameters [ 30 ], but with a greater susceptibility to data drift [ 42 ], [ 55 ]. However, due to their inherent limitations in resources, such as weak GPUs and smaller memory capacities [ 83 ], these servers often resort to ‚Äúcus- tomized‚Äù analytics services to maximize throughput and meet SLAs, including specialized DNN models tailored for edge deployments [ 51 ], [ 75 ], which are compressed, quantized, and optimized for the targeted hardware [ 30 ], [ 103 ], [ 109 ]. B ACKGROUND AND  M OTIVATION \nEdge servers often leverage the convenience and Ô¨Çexibil- ity of cloud interfaces, granting access to the same APIs, tools, and functionalities [ 60 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 193,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 5th International Workshop on Embedded and Mobile Deep Learning , pp. Battery-free camera occupancy detection system. Ali Saffari, Sin Yong Tan, Mohamad Katanbaf, Homagni Saha, Joshua R Smith, and Soumik Sarkar.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "In  2014 IEEE symposium on computational intelligence in ensemble learning (CIEL) , pages 1‚Äì6. IEEE, 2014. [65]  Atul Rahman, Jongeun Lee, and Kiyoung Choi.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "In  ATC . [19]  Mamoun Awad, Latifur Khan, and Bhavani Thuraisingham. 2008.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Do not distribute. Despite these advantages, large-scale EH Wireless Sensor Networks (EH-WSNs) remain inherently uncertain. Ambi- ent energy availability varies over time and space, leading to fluctuating sensor activity levels and intermittent participa- tion in both training and inference tasks.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Based on  E b , we adjust the dropout rate  d i  for each layer  i  according to: \nd i  =  d max \n\u0012 1  ‚àí E b \nE max \n\u0013 , (1) \nwhere  d max  is the maximum allowable dropout rate, and  E max  is the maximum energy observed in the traces. At each training iteration, the available energy  E b  is sampled from these traces. Specifically, during training, we simulate energy variability by incorporating energy traces into the training loop.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "(b) Scenario2: capturing a previously missed object. (c) Scenario3: entering/existing. Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "The probability of correct prediction is given by \nN ‚àë i = ‚åä N \n2   ‚åã + 1 \n\u0012 N i \n\u0013 a i   ( 1 ‚àí a ) ( N ‚àí i ) \nModel Selection Algorithm:  To minimize  ¬µ C , we design a policy to downscale the number of models, if more than N/2+1 models vote for the same classiÔ¨Åcation result. Algo- rithm  1  describes the overall design of the model selection policy  1a  . For every monitoring interval, we keep track of the accuracy obtained from predicting all input images within the interval.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Observation 1:  Model selection should be focused on meeting the cost requirement of an application without compromising on the accuracy and/or latency constraint. 2.2 Performance under given constraint \nModel selection is not an independent problem because the user-applications also have a cost constraint incurred as a result of procuring resources from the public cloud. We compare the cost of deploying the inference service on a group of virtual machines and  serverless functions .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Fig. Scenario2: An object was not captured by the previous frame, but captured by the current frame. 3: Three scenarios: Scenario1: An existing object is moving.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "DNN training is mas- sively parallel, fairly compute intensive, time consuming, and needs a lot of (albeit structured) data movements [ 16 ], [ 37 ]. Therefore, GP-GPUs have classically been used to train DNN models. However, as mentioned in ¬ß I , the commercial GPUs used for DNN training are typically power hungry ( typically in 100s of Watts TDP; We exprimented with multiple GPUs, server class A6000: 300W TDP, server class A100: 250W ‚Äì 400W TDP, client class TRX3090: 350W TDP, and client class T4: 70W TDP), and are  not  equipped to handle intermittent power emergencies.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "Furthermore, in the retail and business sectors, LLM-powered AI chatbots have been shown to reduce the time taken to process an order by 50% to 70%, demonstrating significant efficiency gains even in industries traditionally reliant on human interaction. 2012  ‚Äô14   ‚Äô16   ‚Äô18   ‚Äô20   ‚Äô22   ‚Äô24  \n10B \n 100M \n     1M \n   10K \n    100 \nTraining Compute (petaFLOPs) \nYear \nInceptionV3 \nResNet \nAlexNet \nXception \nDenseNet201 ELMo \nWav2Vec 2.0 MoCo ResNet50 \nTransformer \nGPT-1 \nBERT Large \nMegatron-NLG \nGPT-2 1.5B \nGPT3-175B \nMT NLG 530B \nBLOOM PaLM \nGPT-MoE-1.8T Transformers=16x/year \nBefore Transformers=3x/year \nFigure 1 :  Trend of increasing compute power requirements for training. Source: [30].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 198,
    "augmented": false
  },
  {
    "text": "The cost metric is the billing cost from AWS, and the accuracy metric is measured as the percentage of requests that meet the target accuracy requirements. We compare these metrics for  Cocktail  against (i)  In- Faas  [ 83 ], which is our baseline that employs single model selection policy; (ii)  Clipper  [ 27 ], which uses static full model selection policy (analogous to AWS AutoGluon); and (iii) Clipper-X  which is an enhancement to  Clipper  with a simple model selection (drop one model at a time) that does not uti- lize the  mode -based policy enforced in  Cocktail . Both  InFaas and  Clipper  share  Cocktail ‚Äôs implementation setup to ensure a fair comparison with respect to our design and execution environment.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 179,
    "augmented": true
  },
  {
    "text": "Restrictions apply. Deploying sufÔ¨Åcient battery resources to allow intermittency-unaware designs to operate on solar power is neither efÔ¨Åcient nor sustainable. approach and are neither conÔ¨Ågured nor capable of operating with an intermittent power source.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Consequently, for edge servers to provide cloud-comparable quality, they must also perform continuous learning to mitigate this drift. However, at expected deployment scales, performing continuous training on every edge server is not sustainable due to their aggregate power demands on grid supply and associated sustainability footprints. To address these challenges, we propose Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "From Fig. 0001 ) to  1  (resolution is  0 . 5c, we can observe that, as the precision decreases from  4  (resolution is  0 .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "In  Advances in neural information processing systems , pages 8026‚Äì8037, 2019. [63]  Heyang Qin, Syed Zawad, Yanqi Zhou, Lei Yang, Dongfang Zhao, and Feng Yan. Swift machine learning model serving scheduling: a region \nbased reinforcement learning approach.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Our experiments reveal that the proposed FL scheme can skip up to  53%  of the frames, with  very less  accuracy loss ( 0 . 075% ). Moreover, the total overhead of this algorithm is only  0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "[32] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúIdentity mappings in deep resid- \nual networks,‚Äù in  European conference on computer vision . Springer, 2016, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "Similarly, Fig. 11 shows the impact of increasing the number of CSDs in a storage server. With increasing the number of CSDs per SSD (or other storage element) does show significant improvement because of increase in parallelism.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "2.2 Related Work \nEnsembling in practice : Ensembling is supported by com- mercial cloud providers like Azure ML-studio [ 11 ] and AWS Autogluon [ 31 ] to boost the accuracy compared to single models. 200 using a hill-climb policy [ 17 ] to meet the target accuracy. Azure initially starts with 5 models and scales up to \nFeatures \nClipper [ 27 ] \nRaÔ¨Åki [ 80 ] \nInfaas [ 83 ] \nMArk [ 86 ] \nSagemaker \nSwayam [ 34 ] \nCocktail \nPredictive Scaling \u0017 \u0017 \u0017 \u0013 \u0017 \u0013 \u0013 SLO Guarantees \u0013 \u0017 \u0013 \u0013 \u0017 \u0013 \u0013 Cost Effective \u0017 \u0017 \u0013 \u0013 \u0017 \u0017 \u0013 Ensembling \u0013 \u0013 \u0017 \u0017 \u0013 \u0017 \u0013 Heterogeneous Instances \u0017 \u0013 \u0013 \u0013 \u0013 \u0017 \u0013 Dynamic ensemble selection \u0017 \u0017 \u0017 \u0017 \u0017 \u0017 \u0013 Model abstraction \u0013 \u0013 \u0013 \u0017 \u0017 \u0017 \u0013 \nTable 2:  Comparing  Cocktail  with other related frameworks.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 170,
    "augmented": true
  },
  {
    "text": "4 Optimizing Lattice-Based Cryptography \nFollowed by the video compression, in this section, we discuss the quantum safe encryption technique. Among quantum safe encryption algorithms, Lattice-based cryptography (LBC) (Micciancio & Regev, 2009; Ajtai, 1996), grounded in hard lattice problems, offers robust resistance against quantum attacks. This quantum resilience is vital for protecting large data-sets on machine learning storage servers, particularly from ‚Äôstore now, decrypt later‚Äô threats.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "This is be- cause, intuitively ensembling leads to higher accuracy than single models. However,  Cocktail  is still 9% better than  Clip- per  because the class-based weighted voting, is efÔ¨Åcient in breaking ties when compared to weighting averaging used in Clipper . Since majority voting can include ties in votes, we analyzed the number of ties, which were correctly predicted for all the queries.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Moreover, the system must accommodate  support for intermittency inherent in sustainable power sources like solar and wind. While incorporating conventional battery storage can mitigate intermittency, it introduces environmental and sustainability challenges associated with resource extraction, production, and replacement [ 3 ], [ 5 ], [ 10 ], [ 13 ], [ 53 ], [ 66 ], [ 69 ]. An ideal solution would entail a battery-free system ( not  energy storage- free, i.e., still with some capacitive storage), circumventing these concerns and aligning with the objectives of sustainable and reliable continuous learning at the edge.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "Continuous Learning: Accuracy \nFig. 7  shows the accuracy improvement over a time window of 8 hours by using the continuous learning algorithm. We compare against a baseline using na¬®ƒ±ve continuous learning algorithm with no representation learning.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "In  13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18) , pp. 129‚Äì144, 2018. Hashan Roshantha Mendis, Chih-Kai Kang, and Pi-cheng Hsiu.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "[160] Bo Wang, Maria Liakata, Arkaitz Zubiaga, and Rob Procter. A hierarchical topic modelling approach for tweet clustering. In  Social Informatics: 9th International Conference, SocInfo 2017, Oxford, UK, Septem- ber 13-15, 2017, Proceedings, Part II 9 , pages 378‚Äì390.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": ": First, RAHT [ 14 ] takes the initial octree (which is deepest now) as input, and invokes  RAHT and Quantization  to perform the linear transformation on the leaves with their siblings along the x, y and z dimensions, and shrinks the tree layer-by-layer. Each transformation emits out one low-coefÔ¨Åcient (LC) and one high-coefÔ¨Åcient (HC) by the following equation: \u0002 LC HC \n\u0003 = 1 ‚àö w 1  + w 2 \n\u0002  ‚àö w 1 ‚àö w 2 ‚àí ‚àö w 2 ‚àö w 1 \n\u0003\u0002 a 1 a 2 , \n\u0003 (1) \nwhere  w 1  and  w 2  are the weights for the two leaves ( # occupied voxels in this leaf), and  a 1  and  a 2  are the attributes. Now, the HC is quantized and entropy encoded, while the LC is further sent to the next  RAHT and Quantization  round and serves as the attribute of the large voxel/leaf in the upper layer.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 241,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 21st International Middleware Conference . 1‚Äì13. [44]  Arjun Singhvi, Kevin Houck, Arjun Balasubramanian, Mo- hammed Danish Shaikh, Shivaram Venkataraman, and Aditya Akella.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "2 √ó  performance improvement on average, and up to  80%  energy savings, while losing less than  2%  accuracy. ‚Ä¢  Finally, We compare our approach against four state-of- the-art works (DeepCache [8], Euphrates [9], Potluck [12], and MCDNN [7]). We outperform the MCDNN [7] and Euphrates [9] in terms of accuracy, and Potluck [12] and DeepCache [8] in terms of performance improvement.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "time support and hardware-based enhancements, performance- and energy-efÔ¨Åcient execution of DNN pipelines for videos on mobile devices are still open problems. Our main goal in this work is to look deeper into the existing pipeline to dynamically identify better opportunities for optimizations, with minimum changes to the existing software-hardware stack. III.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "D√©j√† View: Spatio-Temporal Compute Reuse for Energy-Efficient 360 ¬∞  VR Video Streaming. 241‚Äì253. In  Proceedings of the International Symposium on Computer Architec- ture (ISCA) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Focusing on classiÔ¨Åcation-based inferences, it is important to minimize the bias in predictions resulting from multi- ple models. In  Cocktail , we employ a per-class weighted majority voting policy, that makes it scalable and effec- tively breaks ties when compared to traditional weighted averaging, thereby minimizing the accuracy loss. 2.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "In  Computer Architecture News . PowerChief: Intelligent power allocation for multi-stage applications to improve responsiveness on power con- strained CMP. 2017.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "[45] Giorgio Franceschelli and Mirco Musolesi. On the creativity of large language models. AI Models FYI , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "977‚Äì987. https://doi.org/10.1109/ICDCS.2017.262 [48]  Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R. Das. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "In healthcare for instance, more than 40% of institutions are leveraging LLMs to enhance patient care through improvements in diagnos- tics, patient support, and documentation efficiency [122, 130, 142, 176]. LLMs have also made significant inroads into fields traditionally dominated by human creativity, such as creative writing and AI-generated artworks [3, 45, 85, 125, 177]. Furthermore, in the retail and business sectors, LLM-powered AI chatbots have been shown to reduce the time taken to process an order by 50% to 70%, demonstrating significant efficiency gains even in industries traditionally reliant on human interaction.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "3.1 Salient Store  Storage Architecture: \nSalient Store  edge storage architecture is crafted to optimize data-flow and computational effi- ciency in continuous learning edge servers. Salient Store  employs a ‚Äúhybrid model‚Äù, integrating Computational Storage Drives (CSDs) with Field-Programmable Gate Arrays (FPGAs) (AMD, b) and classical storage drives. This design, depicted in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Collectively, the aforementioned figures demonstrate that the harvested energy budget is insuf- ficient to perform  all  inferences with acceptable accuracy on currently proposed EH-WSN systems. Therefore, to complete all the scheduled computations, and thereby to improve ac- curacy, the system must rely on another device (e.g. a mobile phone), where sufficient resources are available to complete any remaining inference,  if the data can be sent from the sensor .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": ", and if not,  (iii) can we just focus on the RoIs in the current frame and signiÔ¨Åcantly reduce the computational requirements for its inferencing? SpeciÔ¨Åcally, our approach combines inter-frame similarities, motion vectors (MVs), and the concept of regions of interest, to make online video analytics/inferences inherently faster, along with the runtime support for improving the video streaming pipeline. Towards this, we propose and thoroughly evaluate a new approach to answer the aforementioned questions.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "{ GRACE } : { Loss-Resilient }{ Real-Time }  video through neural codecs. In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pp. 509‚Äì531, 2024.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "[80]  Wei Wang, Jinyang Gao, Meihui Zhang, Sheng Wang, Gang Chen, Teck Khim Ng, Beng Chin Ooi, Jie Shao, and Moaz Reyad. Proceedings of the VLDB Endowment , 12(2):128‚Äì140, 2018. RaÔ¨Åki: machine learning as an analytics service system.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Azure Durable Functions. https://docs.microsoft.com/en- us/azure/azure-functions/durable. [7] 2020. hey HTTP Load Testing Tool.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Thresholding the Edge:  The ideal case, for either of the aforementioned models, is when all the compute can be done, accurately, at the edge devices. However, to alleviate the shortcomings of less accurate predictions at the edge, some computations are routed to the cloud, expecting a better result at the expense of a higher latency. In both cases, due to the resource limitation of the edge devices, edge-specific model size may be reduced at the expense of accuracy.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Zero: Memory optimizations toward training trillion parameter models. IEEE, 2020. In  SC20: International Conference for High Performance Com- puting, Networking, Storage and Analysis , pages 1‚Äì16.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "A survey of deep neural network architectures and their applications. Neurocomputing , 234:11‚Äì26, 2017. [55]  Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoy- anov.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Introducing a New Benchmarked Dataset for Activity Monitoring. In  ISWC . IEEE.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 21,
    "augmented": false
  },
  {
    "text": "The naive model selection policy would not choose the models as its oblivious to user requirements and model characteristics. In our experiments, compared to naive selection scheme which does not optimize model selection for cost, the  Paragon  schemes reduces the cost of resource procurement by up to 20% (results are not plotted). This is because the  Paragon  scheme jointly considers all three parameters and chooses the least costing model.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "- \nt << n + - - MR logic \n- \nt << n + - - \nDSP  Unit \na i \nb 0 \nb 1 \nS \nMR logic \nd 0 \nd 1 \n(b) Pipeline SDMM Structure micro-architecture. Post-loading, each SDMM \n11 \n6bit shift  register \nSDMM SDMM \n13bit register \nControl logic \na \nb \nc \nb c \nd \n(a) HSPM micro-architecture. Figure 3: Microarchitectural designs of HSPM and SDMM: Hardware modules for polynomial multiplication in LBC.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Prior studies [ 56 ,  64 ,  68 ] and our empirical analysis on the quantization vs accuracy trade-offs (see Fig. Seeker  lever- ages the concept of NVP, and employs a flexible store and execute method using the state of the art ReRAM crossbar architecture [ 47 ] to perform inference at the edge. It aug- ments the sensor nodes with two different quantized DNNs (16 bit and 12 bit) to increase the number of completed in- ferences at the sensor node itself.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "The bootstrapping strategy makes each estimator learn different features of the data set and therefore increases the generality of the whole model. In this case, variance of the estimators becomes a good indicator of prediction confidence. A low output variance of the estimator means the predicted values are tightly concentrated, i.e., different estimators, even after learning different features, give similar answers.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "2). However, as the tile size increases, tiles in successive frames become more dissimilar. E.g., with 32 √ó 32 tiles, only 3% of the tiles are identical.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "SProb  does worse than  DProb  at the tail because of its lack of adaptive probability estimation. The tail latency (measured at P99) for  DProb almost exceeds the SLO, whereas it does so for  SProb . Kraken manages to avoid high tail latency by assigning augmented weights to key functions, thus, helping it tolerate incorrect load/probability estimations.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "First, these are the most frequently invoked kernels during the block matching stage. Such high energy consumption of these two kernels can be attributed to two reasons. SpeciÔ¨Åcally, to compute the 2-norm attribute distance, two kernel functions are invoked ( Diff Squared  and Squared Sum ), which consume 35 %  and 16 % , respectively of the total energy.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "An empirical comparison of voting classiÔ¨Åcation algorithms: Bagging, boosting, and variants. Machine learning , 36(1-2):105‚Äì139, 1999. [15]  William H Beluch, Tim Genewein, Andreas N√ºrnberger, and Jan M K√∂hler.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "However, HORN-8 does not explore the approximation opportuni- ties to speedup the hologram execution. Hence, as shown in Fig. 7c, our  HoloAR  design running on the edge GPU [ 36 ] still saves 25% more energy than the custom HORN-8 accelerator.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "94 ,  0 . 01 ,  0 . The Ô¨Ånal probability vector from the last layer (soft- max function)  V C 1 = [0 .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "IEEE, 2008. [153] Xulong Tang, Ashutosh Pattnaik, Onur Kayiran, Adwait Jog, Mahmut Taylan Kandemir, and Chita Das. Quantifying data locality in dynamic parallelism in gpus.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "103‚Äì118, 2022a. Swift: Adaptive video streaming with layered neural codecs. Mallesham Dasari, Kumara Kahatapitiya, Samir R. Das, Aruna Balasubramanian, and Dimitris Samaras.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "By integrating adaptive neural architecture and energy-aware training techniques, NExUME significantly enhances the viability of deploying machine learning models in environments with limited and unreliable energy sources. The absence of comprehensive library functions along with the need for computational efficiency frequently necessitates the development of in-line assembly code for certain computational kernels. 5 Conclusions \nThis study presents NExUME, an advanced framework designed to optimize the training and inference phases of deep neural networks within the constraints of intermittently powered, energy-harvesting devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "TOTAL INFERENCES \nPiezo WiFi-h WiFi-o Thermal TV-RF \nLeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 \nE. Power predictor \nWith an accurate power predictor [ 45 ], [ 36 ], we can make more smooth transitions among different power levels. The beneÔ¨Åt is that we can keep more MAC results of the last \nincomplete inference when switching from a higher power level to a lower power level, even if  Condition trans   is not satisÔ¨Åed. However, to be valuable the power predictor must have high accuracy.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 193,
    "augmented": true
  },
  {
    "text": "However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments. When we change to a smaller ReRAM duplication granularity  G , we Ô¨Ånd that the throughput of  Pipelining  is better than that of  Sequential for many power levels. The duplication sensitivity results are presented in Section VI-F. ‚Ä¢  Regarding the throughput absolute values, the results with the power sources of  Thermal  and  TV-RF  are much higher than those with the others, which is constant with the power strength illustrated in Figure 4.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Note that the real-object and the corresponding virtual-hologram are randomly mapped because, theoretically, different mappings have no impact on the perfor- mance speedup and energy saving results (shown in Sec. 5.3). To re- place these real objects, we choose six virtual holograms (Sniper, Rock, Tree, Planet, Rabbit, and Dice holograms) from the Open- Holo depthmap database [ 45 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efÔ¨Åciency under stable, high-power scenarios. Fig. 2.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "IEEE, 2020. 315‚Äì327. Attila Reiss and Didier Stricker.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "We leverage such foveated rendering idea in  Inter-Holo as our  Reference  design in this paper. ‚Ä¢  The above  Viewing-Window  and  Inter-Holo  proposals target at reducing the amount of computation for the holograms from the head orientation ( rotation ) and eye tracking ( up-down ) perspec- tives. As discussed in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "However, it is obvious that this approach, albeit good for streaming and retrieval, are not entirely space-efficient, and at times can increase the data volume by many folds (Douze et al., 2024). In an edge server where we are only worried about storage and not retrieval 3 , the vector database approach is  not  effective. Rather, storing the data in a compressed and encrypted format (with redundancies) is more efficient and therefore is the focus of our work.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "10 766‚Äì10 773. [20]  Y. Feng, B. Tian, T. Xu, P. Whatmough, and Y. Zhu, ‚ÄúMesorasi: Architecture support for point cloud analytics via delayed- aggregation,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2020, pp. 1037‚Äì1050.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "The ifs and buts of less is more: a serverless computing reality check. In  2020 IEEE International Conference on Cloud Engineering (IC2E) . IEEE, 154‚Äì161.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Even with minimal accuracy improvement of 3.5% (see Figure 3, where the 5 machines belong to 5 different owners and not sharing data), one grinding machine can save up to  ‚âà 27 . 4 k  parts per year. 3) The latency difference between the data shared model and privacy preserved model is not so prominent due to the lower data volume.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Training compute- optimal large language models. arXiv preprint arXiv:2203.15556 , 2022. [65] Connor Holmes, Masahiro Tanaka, Michael Wyatt, Ammar Ahmad Awan, Jeff Rasley, Samyam Ra- jbhandari, Reza Yazdani Aminabadi, Heyang Qin, Arash Bakhtiari, Lev Kurilenko, and Yuxiong He.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Modern smart machines come with inte- grated sensors with built-in communication protocols to send data to either an attached computer, a base station or cloud. These features increase the cost of the machines significantly, making it extremely hard for small and medium scale entities to procure them. Moreover, a majority of the machines in operation, comprising much of the modern supply chain, are classical machines without any sensing or intelligence built into them.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "2017. [61]  Oren M Tepper, Hayeem L Rudy, Aaron Lefkowitz, Katie A Weimer, Shelby M Marks, Carrie S Stern, and Evan S Garfein. Mixed Reality with HoloLens: Where Virtual Reality Meets Augmented Reality in the Operating Room.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "As a result, the attribute and geometry are compressed separately. Each branch node in the octree stores 8 occupy bits, indicating the occupancy of its children/sub-cubes. The attribute compression in the G- PCC depends on the geometry.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "The space complexity is  O ( N )  for storing the update frequencies and additional parameters. Compared to classical training, DynFit adds minimal overhead, with a tradeoff of  ‚â§ 5%  additional compute for significant gains in accuracy under intermittent power conditions. 3.2 DynInfer: Intermittency-Aware Inference Scheduling \nDynInfer  optimizes the inference phase of DNNs operating under intermittent power conditions.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "8c, the latency is further decreased by  13%  (V1P) and  19%  (V2P), whereas the energy saving is increased by  12%  and  22% . 8d and Fig. The improvement brought by PI for YOLOv4-tiny model is more signiÔ¨Åcant as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Figure (d) shows the effects of distributed autoscaling with importance sampling. We observe that  Cocktail  can effectively scale up and scale down the mod- els while maintaining the cumulative accuracy well within the threshold. More than 50% of the time the number of models are maintained between 4 to 5, because the dynamic policy is quick in detecting accuracy failures and recovers immediately \n1050    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \n(a)  Clipper \n(b)  Clipper-X \n(c)  Cocktail \nFigure 10:  Figures (a), (b) and (c) shows the number of models used in ensemble with corresponding cumulative accuracy and window accuracy over a 1 hour period for requests under  Const1 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "891‚Äì907. IEEE, 2024. National Cybersecurity Center of Excellence (NCCoE).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "These hardware inefficiencies lead to suboptimal performance and increased energy consumption. Finally, the inherent limitations of monolithic models used in most of the current \nLLM applications [12, 16, 27, 51, 106, 123, 124, 149]‚Äî such as lack of domain specificity and inflexibility in continual learning‚Äîslow down the scientific discovery cycle. These factors collectively restrict innovation, limit accessibility, and contribute to significant environmental impact due to high power consumption and carbon emissions, conflicting with global commitments to achieve carbon neutrality [14,17].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Since Algo. 2 has answered the Ô¨Årst question (i.e., for a speciÔ¨Åc frame, what is the inference choice ‚Äì FI, PI or SI? ), we now turn to the second question raised above ‚Äì how to maintain accuracy?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Com- pared to the state-of-the-art hardware-modiÔ¨Åed PTU, our soft- ware implementation can still provide 16% computation and 8% total energy savings. Our FPGA results can further provide 18% more computation and 9% more total energy savings, compared to the state-of-the-art design. More speciÔ¨Åcally, for each of the Ô¨Åve video inputs (shown in the x-axis in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "[105] Z. Ying, S. Zhao, H. Zhang, C. S. Mishra, S. Bhuyan, M. T. Kandemir, \nA. Sivasubramaniam, and C. R. Das, ‚ÄúExploiting frame similarity for efÔ¨Åcient inference on edge devices,‚Äù in  2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) . 4229‚Äì4240, 2022. IEEE, 2022, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "https://blog.google/ outreach-initiatives/sustainability/google-kairos-power-nuclear-energy- agreement/ , 2024. Google and kairos power nuclear energy agreement. Accessed: 2024-10-20.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "We next discuss the motion vector concept, which is used in our approach. 2) Motion Vectors:  The motion vector (MV), which is built upon pixel differences, can be a good candidate to capture the reusability in video analytics. frame (or skip the current frame).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "3388‚Äì3392. [73]  C. Santos, M. Gon c¬∏ alves, G. Corr ÀÜ ea, and M. Porto, ‚ÄúBlock- based inter-frame prediction for dynamic point cloud com- pression,‚Äù in  2021 IEEE International Conference on Image Processing (ICIP) , 2021, pp. [72]  R. B. Rusu and S. Cousins, ‚Äú3D is here: Point Cloud Library (PCL),‚Äù in  IEEE International Conference on Robotics and Automation (ICRA) , 2011.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "However, our work focuses on edge-side optimization, which can also be implemented as a comple- mentary add-on in such cloud-assisted systems. Energy Optimizations in Conventional Video Processing: In the existing planar video processing pipeline on mobile de- vices, prior works have looked at memory [1], [63], [64], dis- play [13]‚Äì[15], [34] and codec [49], [65], and identiÔ¨Åed ‚Äùmem- ory‚Äù as the major energy bottleneck. For example, AFBC [1] is proposed to efÔ¨Åciently compress video streams between the processing pipeline blocks.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "Continuous Learning at the Edge: Continuous learning, wherein the model continually learns from new samples over time, adapting to seen and previously unseen classes, has \n892 \nAuthorized licensed use limited to: Penn State University. These Ô¨Åndings underscore the critical challenge posed by data drift and the need for continuous learning on edge servers. The similar trends across these results highlight the impact of varying time windows and encounter- ing diverse scene changes, leading to degradation in network accuracy by up to 30%.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "The second component will be based on simulation. To achieve a simulation that aligns closely with actual device implementation and captures detailed system-level interactions, we intend to employ several specialized tools (see Figure 7). Since modularity is the backbone of our proposed framework, we envision a detailed simulation of the in- dividual hardware modules (e.g., chiplets, cache/memory components, on-chip and chip-to-chip networks, \netc), as shown in Figure 7 and stitching the evaluation framework for all such discrete modules together to build an ‚Äúend-to-end‚Äù modeling platform for the proposed system.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "IRV2 \nDNet201 \nNASMob \nDNet121 \nXcep \nMNet \nIncep \nMNetV2 \nRNet50V2 \nRNet50 \nModel \n0 \n50 \n100 \nImportance(%) \n(b)  Distribution of requests served by each individual model. Figure 9:  BeneÔ¨Åts of dynamic model selection policy. Note that, changing the target accuracy to tolerate a 0.5% loss, increases the percentage of requests that meet accuracy to 81% for  Cocktail , when compared to 61% for  InFaas .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "‚Ä¢  In  AA , the input and output mapping are unique, that is, no two input coordinates in  360 ¬∞ frame map to the same coordinates in the 2D FoV frame, thereby eliminating any compute reuse scope. 4, by reconstructing the computation needed for one eye ( P R ) from the other ( P L ). For such scenarios, due to the prevailing relationship between the left and right eye transformation matrices ( T L  and  T R ), we can further avail the spatial compute reuse opportunity shown in b in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "These devices have become an integral part of our daily lives and, using techniques such as deep learning, these devices are becoming increasingly capable of performing complex inference tasks including ma- chine translation, human activity recognition (HAR), bio-metric authentication, ECG measurement, fall detection etcetera [1], [2]. Given the power and compute constraints of the IoT devices performing sensing, it is difÔ¨Åcult to execute these inference tasks on the sensing device itself, excepting a few intermittent tasks such as bio-metric authentication. These inference tasks are typically driven by deep neural networks (DNNs), which are known for being compute heavy and power hungry [3].",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "As a result, the attribute and geometry are compressed separately. There are 3 methods for attribute compression in the G-PCC ‚Äì  RAHT  [ 14 ],  Predicting Transform  [ 52 ], and  Lifting Transform  [ 52 ]. The main idea behind RAHT is to use the attribute values in a lower octree level to predict the values in the upper level.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": ", m n ]  where  m i  ‚àà{ 0 ,  1 } . Each element of the mask is determined by sampling from a Bernoulli distribution with probability  1  ‚àí p i : \nm i  ‚àº Bernoulli (1  ‚àí p i ) \nApply the dropout mask during the forward pass. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with L2 Dynamic Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ± .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "Sensors strategically decide when to ex- pend energy on local model updates and when to engage in inference tasks, ultimately maximizing their long-term contribution to the network‚Äôs performance. ‚Ä¢  Demonstrated Performance Gains:  Through simula- tions  (add simulation details later) , we show that our inte- grated framework outperforms baseline approaches‚Äîsuch as always-on participation or simplistic energy-based selec- tion‚Äîby achieving higher inference accuracy, lower energy consumption, and more sustainable long-term operation in EH-WSNs. By tackling the dual challenges of sensor unreliability and energy scarcity through a rigorous game-theoretic and fed- erated learning lens, our work addresses a critical gap in the design of sustainable, intelligent EH-WSNs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 182,
    "augmented": false
  },
  {
    "text": "Available at:  https://doi.org/10.48550/arXiv.2410.03703 . [86] Mandy La and Andrew Chien. Cerebras systems: Journey to the wafer-scale engine.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "In  Post-quantum cryptography , pp. 147‚Äì191. Springer, 2009.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 22,
    "augmented": false
  },
  {
    "text": "Barry Brown, Mathias Broth, and Erik Vinkhuyzen. The halting problem: Video analysis of self- driving cars in traffic. In  Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems , CHI ‚Äô23, New York, NY, USA, 2023.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "The proposed design provides  ‚âà 2 . 2 √ó  latency and  ‚âà 5 . 6 √ó  data movement benefits compared to the state-of-the-art, on a single storage and  ‚âà 4 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Truthfulqa: Measuring how models mimic human falsehoods. In  Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (CCS) , pages 465‚Äì482. ACM, 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Note that this step is also amenable to parallelism. 2) How to Apply to PCC? : As discussed in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "Spock: Exploiting Serverless Functions for SLO and Cost Aware Resource Procurement in Public Cloud. 2019. [31]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Mahmut Tay- lan Kandemir, Bhuvan Urgaonkar, George Kesidis, and Chita Das.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "[185] Yuanrui Zhang, Mahmut Kandemir, and Taylan Yemliha. IEEE, 2011. Studying inter-core data reuse in multi- cores.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Stratus: Cost-aware container scheduling in the public cloud. In  SoCC , 2018. [24]  Paul Covington, Jay Adams, and Emre Sargin.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "Mathematical Formulation:  Let  W  be the weight matrix of a layer. This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the Shapley values of the neurons, along with the QuantaTask optimization to handle energy constraints. D.6 Taylor Expansion Dropout with QuantaTask Optimization \nTaylor Expansion Dropout uses Taylor expansion (Li et al., 2016) to evaluate the impact of neurons on loss for dropout adjustments, combined with the QuantaTask optimization to handle energy constraints in intermittent systems.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "hologram (in Fig. Compared to the baseline, we then report the averaged PSNR [ 21 ,  44 ] of the recon- structed images from the six videos in Fig. 9c) from different distances.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Edge devices are often equipped with mature and robust video and vision pipelines, including sophisticated hardware like the codecs, which the current video analytics pipeline is yet to fully exploit. Further, the video stream itself has temporal continuity, giving us the opportunities of memoization and reuse. In special cases, like remote surveillance, most frames can even be identical, avoiding the need to process them.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "https://transformainsights.com/research/ tam/market , 2023. Accessed: 05/19/2021. Texas Instruments.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Consequently, they frequently ex- hibit a phenomenon known as ‚Äúdata drift‚Äù, where the incoming data deviates from the distribution of the originally trained model, leading to degradation in inference accuracy. What distinguishes these data is their diverse origin, span- ning from IoT devices to wearables, and their acquisition from challenging environments, including autonomous driving and urban mobility scenarios. Mitigating Data Drift:  Dealing with data drift in edge com- pute nodes presents a signiÔ¨Åcant challenge.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "It includes mechanisms for loop tiling, checkpointing, and resumption to manage computation across power interruptions effectively. The algorithm is designed to operate in environments where energy availability is intermittent, such as in devices powered by energy harvesting. C.1.1 Algorithm Overview \nThe GeMM operation, typically expressed as  C  =  A  √ó  B , where  A ,  B , and  C  are matrices, is imple- mented with considerations for energy limitations.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "We propose a dynamic adjustment of training parameters‚Äîdropout rates and quantization levels‚Äîthat adapt in real-time to the available energy, which varies in energy harvesting scenarios. This study introduces  NExUME , a novel training methodology designed specifically for DNNs operating under such constraints. Abstract \nThe deployment of Deep Neural Networks (DNNs) in energy-constrained envi- ronments, such as Energy Harvesting Wireless Sensor Networks (EH-WSNs), introduces significant challenges due to the intermittent nature of power availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "Abstract ‚Äî There is an increasing demand for performing machine learning tasks, such as human activity recognition (HAR) on emerging ultra-low-power internet of things (IoT) platforms. However, the computation and power demands of deep neural network (DNN) based inference pose signiÔ¨Åcant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN). Recent works show substantial efÔ¨Åciency boosts from performing inference tasks directly on the IoT nodes rather than merely transmitting raw sensor data.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Considering a transition \nfor one layer from an activation solution  ‚ü® m 1 , n 1 , aG 1 ‚ü© to ‚ü® m 2 , n 2 , aG 2 ‚ü© , we Ô¨Ånd that, if the expression  Condition trans : ( m 1 =  m 2)&( n 2  |  ( Tile count 1   √ó  n 1))&( aG 1 =  aG 2) is true for each convolution layer, the activation solution ‚ü® m 1 , n 1 , aG 1 ‚ü© with power level PL1 can be transferred to be equivalent to an execution of activation solution  ‚ü® m 2 , n 2 , aG 2 ‚ü© with PL2. The execution equivalency can be transferred by Tile count 2   =  Tile count 1   √ó  n 1 /n 2 . The next power cycle‚Äôs level information cannot be known with certainty.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 214,
    "augmented": false
  },
  {
    "text": "First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power. Second, the \nvariance of the input power window, i.e., how long the power input stays at a given level, can be large as well. It is known that RCAs achieve their highest efÔ¨Åciency when every cell participates in the MAC computations simul- taneously [ 20 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Figure (d) shows the effects of distributed autoscaling with importance sampling. Strict Relaxed 0 \n25 \n50 \n75 \n#VMs \nInFaas Clipper Clipper-X Cocktail \n(a)  Wiki Trace. Strict Relaxed 0 \n25 \n50 \n75 \n#VMs \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "hologram (in Fig. PSNR (%) \nEnergy Savings (%) \n(b) Trade-offs. Figure 10: Sensitivity studies.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": ". . The chosen action profile is a ( t ) = ( a 1 ( t ) , .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "We refer to this policy that stretches the basic round-robin policy as extended round-robin (ER-r). 3) between one sensor Ô¨Ånishing an inference and the next sensor starting the next one, so that each of the sensors get more time to accumulate more energy prior to attempting an inference. Using ER-r, we can complete more total inferences, \n1 This can also be extended to larger numbers of sensors and modalities \nbut this design is limited by the accuracy of individual sensors.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "RR3 has 3 nodes with no no-ops and RR6 has 3 nodes with 3 no-ops. 3:  Different Ô¨Çavors of (extended) round-robin scheduling and their execution Ô¨Çow. Each policy is named after the num- ber of nodes the cycle has, i.e.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "IV. I NTRA -F RAME  C OMPRESSION  D ESIGN \nAs discussed in Sec. III-A , PCC takes several seconds to execute, which is signiÔ¨Åcantly higher than the ideal/real- time demand ( 100 ms ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "1063‚Äì1075. [42]  Mohammad Shahrad, Rodrigo Fonseca, √ç√±igo Goiri, Gohar Chaudhry, Paul Batum, Jason Cooke, Eduardo Laureano, Colby Tresness, Mark Russinovich, and Ricardo Bianchini. 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "[81]  TopoDOT Blogger, ‚ÄúUsing Point Clouds for Augmented and Virtual Reality,‚Äù  ‚Äùhttps://bit.ly/3OFdA97‚Äù , 2022. [82]  C. Tu, E. Takeuchi, A. Carballo, and K. Takeda, ‚ÄúPoint cloud compression for 3d lidar sensor using recurrent neural network with residual blocks,‚Äù in  2019 International Conference on Robotics and Automation (ICRA) , 2019, pp. 3274‚Äì3280.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "The 2-home setup, albeit more accurate, has a more complex model (#splitting points 10501) at the cloud thanks to the large volume of training samples, leading to more execution time compared to the relatively simpler model for the 4-home setup. The cloud model is trained on a larger data set and has more parameters than the edge models and hence is more accurate. 3) The privacy preserving cloud model, although less accurate than the data shared cloud model, performs significantly better than the edge models, with 5.1% more correlation in case of the 2-home setup and 10.37% more correlation for the 4-home setup.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "Observation 5:  Serverless functions can be used with VMs to avoid over-provisioning resources, but the right configuration needs to be accurately determined for the functions such that it satisfies the application cost and latency constraints. We argue that compared to VMs there is more variability in configurations for  serverless functions  because the resources are billed at a more fine-grained 2   allocation of CPU and memory. 1 For squeezenet model, allocating beyond 2GB did not reduce computation time, but resulted in increased cost 2 The smallest standard performance VM (C4 family) comes with 2 vcpus and 3.75GB memory.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "Therefore, assigning a static weight to the output of each classiÔ¨Åer will not reÔ¨Çect that its accuracy is activity-dependent. For example, the classiÔ¨Åer used in the left ankle sensor tends to be more accurate overall, but for classifying climbing action, it is not better than the chest sensor. 2 it is clear that not all the sensors are equally good at classifying various ac- tivities; in fact, this builds the foundation of AASR.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Spock: Exploiting Server- less Functions for SLO and Cost Aware Resource Procurement in Public Cloud. 2019. [5]  J. R. Gunasekaran, P. Thinakaran, et al .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "In  2022 IEEE Symposium on High-Performance Interconnects (HOTI) , pp. 5‚Äì12. IEEE, 2022b.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "244 \ncoordinates in that frame, thus are evaluated only  once  for that frame, and account for only  4 . 8 MFLOPS  without any optimization. In the  Projection Computation  stage (refer to  b  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "[60] xinreality, ‚ÄúAsynchronous Spacewarp.‚Äù ‚Äùhttps://xinreality.com/wiki/ Asynchronous Spacewarp‚Äù, 2019. [61] YouTube, ‚ÄúGet Started with YouTube VR.‚Äù ‚Äùhttps://support.google.com/ youtube/answer/7205134?hl=en‚Äù, 2019. [62] V. Zakharchenko, K. P. Choi, and J. H. Park, ‚ÄúQuality metric for spherical panoramic video,‚Äù in  Optics and Photonics for Information Processing X , K. M. Iftekharuddin, A.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "A. H. Terriza, M. Damas, H. Pomares, I. R. Ruiz, A. Saez, and C. Villalonga, ‚Äúmhealthdroid: A novel framework for agile development of mobile health applications,‚Äù in  IWAAL . Springer, 2014. [13] O. BaÀúnos, R. Garc¬¥ƒ±a, J.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "3. Access and Sharing Policies \nWe will publish our findings from this research in top ML/AI, systems, HPC, computer architecture and performance evaluation venues, including, but not limited to, ICML, ICLR, NeurIPS, MLSys, ACM SC, ISCA, MICRO, HPCA, ASPLOS and SIGMETRICS, as well as the top relevant ACM and IEEE journals and transactions. When appropriate, the PIs will also try to share their research findings with the broad research community via posts, talks, and seminars.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "2 Characterization and Motivation \n2.1 Variability across model types \nDepending on the accuracy and latency requirements of an end-user application, multiple models (shown in Figure  1 ) might satisfy a given constraint. As shown in Figure  2a , four differ- ent models can satisfy the response latency, but each model comes with a different prediction accuracy. For example, consider a face- recognition application that demands a response latency of under 500ms (ISO-latency).",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "¬¥as implements the major portions using ‚Äúcustom hardware‚Äù (dis- cussed in ¬ß IV-A ). The annotations on the new exemplar set created by the representation learner is compared against the conÔ¨Ådence matrix of the edge model to calculate the ‚Äúdrift‚Äù. Consequently, this exemplar set becomes the training data for the continuous learning, which consequently minimizes the drift.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "(Accessed on 11/13/2023). Abhishek Rawat, Kartik Sehgal, Amartya Tiwari, Abhishek Sharma, and Ashish Joshi. A novel accelerated implementation of rsa using parallel processing.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Towards effective indexing for very large video sequence database. In  Proceedings of the 2005 ACM SIGMOD international conference on Management of data , pp. 730‚Äì741, 2005.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "[181] Nan Zhang, Yanchi Liu, Xujiang Zhao, Wei Cheng, Runxue Bao, Rui Zhang, Prasenjit Mitra, and Haifeng Chen. Pruning as a domain-specific LLM extractor. In Kevin Duh, Helena Gomez, and Steven Bethard, editors,  Findings of the Association for Computational Linguistics: NAACL 2024 , pages 1417‚Äì1428, Mexico City, Mexico, June 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "In this regard, the metric  throughput  measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios. We use the number of convolutional MAC operations to represent the computations. For the sequential computation mode, the throughput for Layer  Lk  can be expressed as below: \nThr sequ Lk =  ( m  √ó  n ) Lk  √ó  aG Lk \nLat Lk (6) \nThe average throughput with a  LC -convolution CNN infer- ence can be expressed as shown below.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "Data driven prediction models of energy use of appliances in a low-energy house. Energy and Buildings , 140:81‚Äì97, 2017. [4] Heiner Lasi, Peter Fettke, Hans-Georg Kemper, Thomas Feld, and Michael Hoffmann.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "In  Advances in Neural Information Process- ing Systems , 2024. [188] Zhenyu Zhang, Shiwei Liu, Runjin Chen, Bhavya Kailkhura, Beidi Chen, and Atlas Wang. Q-hitter: A better token oracle for efficient llm inference via sparse-quantized kv cache.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "15: end if 16: Check feasibility conditions again to ensure no viola- tion of baseline inequalities. 17: If performance metrics (accuracy, sustainability) are satisfactory, terminate. Otherwise, continue refine- ment.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "The projection transformation Ô¨Årst calculates the transformation matrix ( T  ), and then uses the transformation matrix to map each of the pixel coordinates to generate the projection matrices ( P ) for the FoV frames. Then projection mapping stage uses this coordinate mapping ( P ) to move pixels from the original 360 frame  F 360  to the 2D frame  F . following two properties from a published  360 ¬∞ VR dataset [3], as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "However, in the middle of the execution if any new tiles becomes alive (because of an increase in harvested power), the scheduler immediately marks it ready to start working and the tile fetches a kernel (currently not scheduled in any of the tiles) and starts working on it. We face three issues here: 1. How does the new tile get any kernel to work on?",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "We have validated its correctness by correlating various metrics of interest generated from experiments run on the real system with scaled-down versions of the same traces (average ar- rival rate of  ‚àº 100rps). Therefore, the simulator allows us to evaluate our model for a larger setup, where we mimic an 11k core cluster which can handle up to 7000 requests (70 √ó more than the real system). Additionally, it helps compare the resource footprint of  Kraken  against a clairvoyant policy (Oracle) that has 100% load prediction accuracy.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "3) between one sensor Ô¨Ånishing an inference and the next sensor starting the next one, so that each of the sensors get more time to accumulate more energy prior to attempting an inference. We refer to this policy that stretches the basic round-robin policy as extended round-robin (ER-r). Using ER-r, we can complete more total inferences, \n1 This can also be extended to larger numbers of sensors and modalities \nbut this design is limited by the accuracy of individual sensors.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "5) indicates that setting  Œ±  to this specific value brings significant energy savings while maintaining good hologram quality. We also present a sensitivity study on how en- ergy savings and performance vary with different approximation factors in Sec. 5, as our detailed profiling (discussed later in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "We assume the communication cost to be negligible since it infrequently sends a few bytes of data to the host. To replicate the energy harvesting, we use a real power trace harvested from a WiFi source while doing various day to day tasks in an ofÔ¨Åce environment [6]. The speciÔ¨Åcs of the energy-harvesting mechanism producing the power trace are beyond the scope of this work.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "(c) Head movement and pupillary distance as inputs. Fig. 2: Overview of  360 ¬∞  video projection.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "Water Resources Research , 43(1), 2007. [79]  Cheng Wang, Bhuvan Urgaonkar, Neda Nasiriani, and George Kesidis. Using burstable instances in the public cloud: Why, when and how?",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "An intra-tile pipeline is formed to boost the dot-product throughput. In the PipeLayer design [ 5 ], a spike-based scheme, instead of a voltage-level based scheme, is used for input to eliminate the power overhead of DACs and ADCs. The underlying idea is to use spike counts to represent the data value.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "315‚Äì 327. IEEE, 2020, pp. [72] K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, \nJ. Sampson, M. T. Kandemir, and V. Narayanan, ‚ÄúResirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent em- bedded processors,‚Äù in  2020 IEEE International Symposium on High Performance Computer Architecture (HPCA) .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "To address these challenges, this paper proposes and experi- mentally evaluates  ResiRCA , a resilient ReRAM crossbar-based CNN accelerator. ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference. Supported by a reconÔ¨Ågurable lightweight \nhardware design, ResiRCA is able to activate scalable com- putations via a multi-dimension tuning strategy.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "2.2 Performance under given constraint \nModel selection is not an independent problem because the user-applications also have a cost constraint incurred as a result of procuring resources from the public cloud. We compare the cost of deploying the inference service on a group of virtual machines and  serverless functions . Observation 1:  Model selection should be focused on meeting the cost requirement of an application without compromising on the accuracy and/or latency constraint.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Figure 15: Simulator: Comparison of Function-wise Breakdown of Containers spawned by  Kraken  and  Oracle . 0 \n150 \n300 \n450 \n600 \nOracle Kraken Oracle Kraken Oracle Kraken \nSocial Network Media Service Hotel Reservation \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(a) E2E Response Time Break- down. 0 \n2000 \n4000 \n6000 \nOracle Kraken \n# Containers \nNGINX Check_Reservation Get_Profiles Search Make_Reservation \n(c) Hotel Reserva- tion.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "All these DNNs are executed with the state-of-the-art checkpointing and scheduling approach (Maeng & Lucia, 2018). Baseline  Full Power  is a DNN designed by iNAS (Mendis et al., 2021) for running while the system is battery-powered and has to hit a target SLO (latency < 500ms). Baseline  AP  is a DNN compressed to fit the average power of the energy harvesting (EH) environment using iNAS (Mendis et al., 2021) and energy-aware pruning (EAP) (Yang et al., 2017, 2018).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "The  Projection Mapping  stage (  c  in Fig. 3) takes the projection matrices for both the eyes ( P L ,  P R ) of Equation 2 as well as the pixel values of the  360 ¬∞ video frame ( F 360 ), to obtain the  2 D  FoV frames ( F L  and  F R ), which can be further displayed on the HMD. This stage mostly comprises of memory operations, and thus is not a compute bottleneck.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "a  is the region where the convolution kernel only multiplies with the pixels in RoIs. In  b  , the kernel is multiplied with both the RoI pixels and the non-RoI pixels (background region, i.e., BG), and Ô¨Ånally,  c  is where the kernel is only multiplied with the pixels inside BG region. Thus, the inner part of the output is only related to the RoIs of input; the middle part is related to both the RoIs and the BG; and the outer part is only related to the BG.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "It can be clearly seen that the computation time reduces with increased memory alloca- tion but also results in higher cost of deployment for every model type. This is because, inherently, serverless providers allocate a powerful compute core for functions with higher memory allocation. Therefore, depending on the latency re- quirements of the user applications,  serverless functions  need to be allocated the appropriate memory.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "6.2 Simulator Results Since the real-system is limited to a 160-core cluster, we use our in-house simulator, which can simulate an 11k-core cluster, to study the scalability of  Kraken . We mimic a large scale Poisson arrival trace ( ùúá = 1000rps), Wiki ( ùúá = 284 rps) and Twitter ( ùúá = 3332 rps) traces. Figure 14 plots the con- tainers spawned versus the SLO guarantees for each appli- cation for all traces.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "Current head mounted VR devices use a GPU for this heavy computation. Thus, unlike planar videos, in  360 ¬∞ videos, speciÔ¨Åcally the projection computations for capturing the head movements and eye correlations, are sig- niÔ¨Åcantly computation-heavy, amounting to  59%  of the overall VR (headset) power budget. Since the head mounted VR devices are battery-backed, the computations that draw high power from the battery greatly hinder the experience of watching long  360 ¬∞ videos [39].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "https://doi.org/10.1145/3472883. Many of these real-world services often comprise of tens or even hundreds of loosely-coupled microservices [ 42 ] (e.g. 3486992 \n1 Introduction Cloud applications are embracing microservices as a pre- mier application model, owing to their advantages in terms of simplified development and ease of scalability [ 29 ,  40 ].",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Sagemaker. [6]  Amazon. https://aws.amazon.com/sagemaker/, February 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "Inference Deployment Embedded Platforms:  For commercially off-the-shelf micro-controllers, we choose Texas Instruments MSP430FR5994 (Instruments, 2024a), and Arduino Nano 33 BLE Sense (Arduino, 2024) as our deployment platforms with a Pixel-5 phone as the host device. The host device is used for data logging‚Äîcollecting SLOs, violations, power failures, etc., along with running the ‚Äúbaseline‚Äù inferences without intermittency. 4.2 NExUME on Publicly Available Datasets \nDatasets:  For image data, we consider the Fashion-MNIST (Xiao et al., 2017) and CIFAR10 (Alex, 2009) datasets; for time series sensor data, we focus on popular human activity recognition (HAR) datasets, MHEALTH (Banos et al., 2014) and PAMAP2 (Reiss & Stricker, 2012); and for audio, we use the AudioMNIST (Becker et al., 2023) dataset.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 256,
    "augmented": true
  },
  {
    "text": "The missing piece in complex analytics: Low latency, scalable model man- agement and serving with velox. [25]  Daniel Crankshaw, Peter Bailis, Joseph E Gonzalez, Haoyuan Li, Zhao Zhang, Michael J Franklin, Ali Ghodsi, and Michael I Jordan. In  Proceedings of the 10th ACM con- ference on recommender systems , pages 191‚Äì198, 2016.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Only intermittent learn- ing [ 47 ] focuses on performing on-device training, but with very small workloads and models. This gives us a unique platform to think of intermittency beyond embedded systems and energy. Related Works:  Although there has been signiÔ¨Åcant re- search [ 40 ], [ 41 ], [ 47 ], [ 52 ], [ 56 ], [ 61 ], [ 72 ], [ 104 ] on enabling machine learning in intermittently powered devices, a majority of it focuses on performing inference.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output  Y .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Similarly, our model selection pol- icy is also changed at runtime based on correct predictions seen during every interval. Ties occur when two sets of equal number of models predict a different result. An important concern in majority voting is tie-breaking.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "This output is then transmitted serially over  n  clock cycles. The final polynomial product  p  is sequentially read out by the address signal  addr ab , combined with the coefficient of  c , thereby producing the final output  d  as d  =  a  ¬∑  b  +  c . Designing SDMM Hardware on CSD FPGA:  The SDMM hardware is innovatively designed to perform two modular multiplications per DSP Slice.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "R EFERENCES \n[1] Automating the grinding process, 2013. https://www.sme.org/technologies/articles/2013/january/automating-the- grinding-process/. [2] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub KoneÀácn`y, Stefano Mazzocchi, Brendan McMahan, et al. This re- search is supported by NSF grant #1822923 and Clean Energy Smart Manufacturing Innovation Institute award #136067.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "Bert: Pre-training of deep bidirectional transformers for language un- derstanding, 2019. [30]  Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. [31]  Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "When we track the simulation cycles, it is found that the throughput of  Sequential  solution \nResiSchedule \nPiezo WiFi-home WiFi-office Thermal TV-RF \nFig. 8. ‚Ä¢  The results of  ResiSchedule  are very close or equal to that of  Sequential  under most cases.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Inter-layer parallelism  means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion. This pipeline parallelism provides us with another dimension to aggressively exploit the harvested energy. We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Moreover, the experts could differ in their size and thus in their compute and memory requirements. In addition, for supporting morphable network structures that change over time with continual learning, the underlying interconnect should be dynamically reconfigurable. In terms of cost, utilization, power, and area require- ments, we expect several inefficiencies with existing off-the-shelf hardware like CPUs and GPUs when executing our models for training, inference, and re-training purposes, thus exacerbating the gap towards democratization.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "In  2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) , pages 1‚Äì10, 2024. Toward a holistic performance evalua- tion of large language models across diverse ai accelerators. [40] Murali Emani, Sam Foreman, Varuni Sastry, Zhen Xie, Siddhisanket Raskar, William Arnold, Rajeev Thakur, Venkatram Vishwanath, Michael E. Papka, Sanjif Shanmugavelu, Darshan Gandhi, Hengyu Zhao, Dun Ma, Kiran Ranganath, Rick Weisner, Jiunn-yeu Chen, Yuting Yang, Natalia Vassilieva, Bin C. Zhang, Sylvia Howland, and Alexander Tsyplikhin.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 191,
    "augmented": true
  },
  {
    "text": "This has lead to a significant development in the direction of enabling video analytics and learning with edge servers. Although efficient algorithms, compute orchestration and hardware have addressed the analytics part, the scaling of such a system becomes a problem primarily due to high energy consumption. Recent works try to solve this problem by augmenting these continuous learning edge servers with application-specific hardware targeted for intermittent computing which could run using solar power.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "1:  Input:  Set of training video sequences  V 2:  Initialize:  MobileNet  M ‚ñ∑ Weights frozen 3:  Initialize:  Autoencoder  A ‚ñ∑ Trainable 4:  Initialize:  Motion Vector Extractor  V 5:  procedure  E XTRACT M OTION V ECTORS ( frame current , frame previous ) 6: motion _ vectors  ‚Üê V  ( frame current , frame previous ) 7: return  motion _ vectors 8:  end procedure 9:  procedure  F ORWARD P ASS ( video ) 10: previous _ features  ‚Üê null 11: previous _ compressed  ‚Üê null 12: for  each frame  frame  in  video  do 13: features  ‚Üê M ( frame ) ‚ñ∑ Extract features using frozen MobileNet 14: compressed  ‚Üê A.encode ( features ) ‚ñ∑ Compress features 15: if  previous _ compressed  Ã∏ =  null  then 16: motion _ vectors  ‚Üê E XTRACT M OTION V ECTORS ( frame, previous _ frame ) 17: stacked _ input  ‚Üê concatenate ( compressed, previous _ compressed, motion _ vectors ) 18: compressed  ‚Üê A.reencode ( stacked _ input ) ‚ñ∑ Stacked compression 19: end if 20: reconstructed  ‚Üê A.decode ( compressed ) ‚ñ∑ Decompress to reconstruct 21: Calculate reconstruction loss between  frame  and  reconstructed 22: previous _ frame  ‚Üê frame 23: previous _ compressed  ‚Üê compressed 24: previous _ features  ‚Üê features 25: end for 26: Backpropagate loss and update weights of  A  only 27:  end procedure 28:  while  not converged  do 29: for  each  video  in  V  do  F ORWARD P ASS ( video ) 30: end for 31:  end while \nThe implementation of layered codecs involve the following components. 1. Motion Estimation: Utilize dedicated hardware blocks for calculating motion vectors between consecutive frames.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 436,
    "augmented": false
  },
  {
    "text": "This balances task importance against energy consumption, leading to efficient utilization of available energy. 3. Complexity Analysis : The heuristic has a time complexity of O ( N  log  N )  due to sorting tasks based on  P   eff i   , which is acceptable for real-time applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "In  Harvard Brain Science Initiative , Boston, MA, 2024. [125] Will Orwig and Daniel Schacter. Creative writing in humans and large language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "Moreover, the CoE (College of Engineering) is a partner with the National GEM Consortium that leads the Grad Lab, which facilitates the participation of populations underrepresented in computing for graduate studies in engineering and science. In addition to working with the GEM/Grad lab, department has developed a partnership with the Black in AI (BAI) group to attract more students from populations underrepresented in computing to our graduate program. We also plan develop recruiting relationships with HBCUs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "Therefore, we believe that, achiev- ing beneÔ¨Åts by exploiting the  EA  and  AE  opportunities needs an extensive study and a careful design, especially from an architectural perspective, to maximize the beneÔ¨Åts. Driven by the above discussion and the potential optimiza- tion opportunities presented by  EA  and  AE , we propose  D¬¥ej`a View , an energy-efÔ¨Åcient design for  360 ¬∞ video streaming on VRs. As shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "7% of the inferences scheduled on a sensor. Al- though accuracy can increase by further tuning duty-cycle, as shown in Figure 2b, the returns are diminishing, and in- definite increase of duty cycle is also not an option as that might lead to skipping important data to infer. We observe that the system used in [ 47 ] does not aggressively employ quantization, which is a commonly used technique [ 64 ] to reduce both compute and transmission energy in DNN tasks.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "In The Definitive Guide to AWS Application Integration . Step Functions. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 19,
    "augmented": true
  },
  {
    "text": "Lessons Learned from the Chameleon Testbed. In  Proceedings of the 2020 USENIX Annual Technical Conference (USENIX ATC ‚Äô20) . USENIX Association.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Thanks to this, for each segment, we just need to store one medium  value as  Base  and several  residual  values as  Deltas (which are mostly small, due to similarity). And Ô¨Ånally, we quantize these deltas for achieving higher compression ratio. The points within one segment are geometrically close to each other, and hence their attributes are also likely to be similar.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "and starts Ô¨Çushing the results for backup. Buffer Management:  Us. ¬¥as  uses non-volatile state buffers (NVSBs, 18 count, 1 per 4x4 tiles, each of 1kB, and 2 of 4kB each) for state saving and data backup.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Figure 15 shows the breakdown of total number of containers spawned for each application, aver- aged across all realistic large-scale traces using the simulator. It is observed that  Kraken  spawns more containers ( 7%) than  Oracle , on average. This is due to  Kraken ‚Äôs load/path probability miscalculations and the usage of  Commonality and  Connectivity  to cope with this.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "The sec- ond step,  Backward-Propagate  (denoted  ‚ù∑ in Fig. 4a), accumulates the results of each depth plane, backpropagates it to the hologram plane via the  DP2HP  procedure (in  Line#11 ), and generates the final hologram for this depthmap input. Like the first step, this step also involves synchronizations between planes (in  Line#12 ), which can again impact parallelization and slow down the entire execution.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "This additional pre-processing step can draw an overall layout for all the points, which will further help to parallelize the octree construction. ‚Ä¢  Octree Construction 4 :  Using the Morton codes generated in the previous step, now the octree can be constructed in parallel by employing techniques similar to [ 31 ], [ 64 ]. Note that this step is slightly different from the one in the prior pipeline shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Finally, we provide detailed insights on how to tailor the PCC pipeline to cater to various application preferences (Sec. VI-E ). A.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Define a binary dropout mask  m  = [ m 1 , m 2 , . . The idea is to use the reconstruction error to determine the probability: \np i  = Œ≥  RE i max( RE ) +  œµ \n18 \nwhere  Œ≥  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "The DeepARest model is pre-trained using 60% of the arrival trace. All decisions related to VM au- toscaling, bin-packing and load-prediction are reliant on the centralized mongodb database, which can become a potential bottleneck in terms of scalability and consistency. This can be mitigated by using fast distributed solutions like Redis [ 16 ] and Zookeeper [ 46 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "0 \n2000 \n4000 \n6000 \nOracle Kraken \n# Containers \nNGINX Check_Reservation Get_Profiles Search Make_Reservation \n(c) Hotel Reserva- tion. Figure 15: Simulator: Comparison of Function-wise Breakdown of Containers spawned by  Kraken  and  Oracle . 0 \n150 \n300 \n450 \n600 \nOracle Kraken Oracle Kraken Oracle Kraken \nSocial Network Media Service Hotel Reservation \nResponse Time (ms) \nQueueing Cold Start Execution Time \n(a) E2E Response Time Break- down.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Further,  Us. ¬¥as  converges closer to the accuracy of the teacher model. This was possible by restricting the training space and by using the superior exemplar set construction by using representation learning.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "And, as will be shown later in Sec. VI , such optimizations are able to bring around 37 √ó  speedup w.r.t. the state-of-the-art techniques ( 1 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Cold start spillovers (that often occur due to container underprovision- ing), as described in Section 2, can impact the response la- tency of applications harshly. Provisioning critical functions with more containers helps throttle this at the source. To this end,  Kraken  makes use of a parameter called  Connec- tivity , while assigning function weights.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "25 ,  0 . 25 ,  0 . It is obvious that the most conÔ¨Ådent classiÔ¨Åcation for the same class would be [1 ,  0 ,  0 ,  0] , where the model is 100% conÔ¨Ådent on class  o 1  and the most confused prediction would be  [0 .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "However, increased memory allocation leads to faster execution time owing to powerful compute-core allocation, but exacerbates the billing cost. Therefore, these apparent deficiencies of choosing the appropriate resource type and model type for a given user re- quirement motivates the central question of this work:  Does there exist an optimal resource procurement system which can balance the goals of diverse user requirements for accuracy, latency and cost, by efficiently mapping model parameters to heterogeneous resource specifications? This is because, serverless functions are billed based on of number of invocations, compute time and memory requirement of the function.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "Constructing an accurate random forest model, while respecting data privacy of a distributed multi user sensor network is also challenging. Moreover, such a system demands accurately predicting the cases where the edge analytics were insufficient and the cloud must be employed for deeper analysis and accurate results. We propose a novel framework to perform intelligent edge- cloud partitioning for a distributed sensor network running random forest-based analytics.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "[18] Maciej Besta, Syed Minhaj Hassan, Sudhakar Yalamanchili, Rachata Ausavarungnirun, Onur Mutlu, and Torsten Hoefler. Slim noc: A low-diameter on-chip network topology for high energy efficiency and scalability. ACM SIGPLAN Notices , 53(2):43‚Äì55, 2018.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Mouse: Inference in non-volatile memory for energy harvesting applications. Salonik Resch, S Karen Khatamifard, Zamshed I Chowdhury, Masoud Zabihi, Zhengyang Zhao, Husrev Cilasun, Jian-Ping Wang, Sachin S Sapatnekar, and Ulya R Karpuzcu. IEEE, 2012.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "These policies can be collectively used for cost-effective prediction serving with- out compromising on latency and accuracy. Acknowledgement \nThis research was partially supported by NSF grants #1931531, #1955815, #1629129, #1763681, #1629915, #1908793, #1526750 and we thank NSF Chameleon Cloud project CH- 819640 for their generous compute grant. References \n[1]  Omid Alipourfard, Hongqiang Harry Liu, Jianshu Chen, Shivaram Venkataraman, Minlan Yu, and Ming Zhang.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "The above discourse motivates us to rethink the design of serverless RM frameworks to cater to DDAs as well. Hence, rather than simply measuring the weights only in terms of function invocation frequency, we also need to account for DAG specific factors like  Commonality  and  Con- nectivity . One key driver for the design lies in a  Probability Estimation Model  for individual functions, which is explained below.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "training. 0 \n2 \n4 \n6 \n8 \n0 \n10 \n20 \n30 \n40 \n1 2 3 4 5 6 7 8 9 10 \nConvergence Error(%) \nBatch Size \nTranining Iterations Batch Size-Actual Batch Size-Oracle Convergence Error (%)-Actual Convergence Error (%)-Oracle \n(b) Batch-size and convergence. 0 \n5 \n10 \n15 \n0% \n20% \n40% \n60% \n80% \n100% \n1 2 3 4 5 6 7 8 9 10 \n# Exemplar/100 Frames \nExemplar vs Traning  \nTime \nTranining Iterations Exemplar Selection Tranining #Exemplar/100 frames \n(c) Exemplar selection w.r.t.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "In addition, in the cases of heavy data movement within a chiplet, the register file, scratch- pad memory, and cache hierarchy can be configured for more effectiveness. Or, having a fine-grained pro- grammer control via pragmas/annotations can help to efficiently utilize the caches. Since model execution typically demands either a large memory footprint or high bandwidth or both, using both large capacity DDR and fast memory HBM memory blocks in our chip can be explored to effectively meet these memory requirements.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "2022.00031. Ziyu Ying, Shulin Zhao, Haibo Zhang, Cyan Subhra Mishra, Sandeepa Bhuyan, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. Exploiting frame similarity for efficient inference on edge devices.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "4.3 Reactive Scaler (RS) Though the introduction of Request Batching  5  allows Kraken  to reduce the containers provisioned, load mispredic- tions and probability miscalculations can still occur, leading to resource mismanagement, which could potentially affect the SLO compliance. The batch size represents the number of requests that can be served by a function without violating the allotted stage-wise SLO. To deal with this,  Kraken  also employs the RS  7  to scale containers up or down in response to re- quest overloading at containers (due to under-provisioning) and container over-provisioning, respectively.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "Stratus: Cost-aware Container Scheduling in the Public Cloud. In  SoCC . [4]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "In each time slot, the network may perform an inference event, dur- ing which sensors have the opportunity to contribute data that enhances the accuracy of a global inference task, such as object detection or environmental classification. Each sensor  s i  harvests energy from ambient sources, such as solar or vibrational energy, resulting in a stochastically varying energy supply. We denote by  E i ( t )  the energy harvested by sensor  s i  during slot  t .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Skip Inference:  When the current frame is identiÔ¨Åed as ‚Äúclonable‚Äù by the previous frame, the CPU is released without any inference execution request. Instead, the previous results (the bounding boxes [including the classes and scores] in the previous frame), which have been memoized before, are directly loaded as the inference result for the current frame. Partial Inference:  In this case, rather than processing the whole frame, only the RoI blocks are fed into the CPU and, with the memoized feature maps from previous frame, the CPU is able to generate the desired result for the current frame as accurate as performing inference on a full frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "Restrictions apply. bounding boxes for the object detection task and the feature maps for each layer during the inference are intermediately stored in memory as a ‚Äúcheckpoint‚Äù. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "[22] M. Motamedi, D. D. Fong, and S. Ghiasi, ‚ÄúFast and Energy-EfÔ¨Åcient CNN Inference on IoT Devices,‚Äù  CoRR , 2016. [23] C. Wu, D. Brooks, K. Chen, D. Chen, S. Choudhury, M. Dukhan, K. Hazelwood, E. Isaac, Y. Jia, B. Jia, T. Leyvand, H. Lu, Y. Lu, L. Qiao, B. Reagen, J. Spisak, F. Sun, A. Tulloch, P. Vajda, X. Wang, Y. Wang, \nB. Wasti, Y. Wu, R. Xian, S. Yoo, and P. Zhang, ‚ÄúMachine Learning at Facebook: Understanding Inference at the Edge,‚Äù in  Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA) , 2019, pp. 331‚Äì344.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 240,
    "augmented": false
  },
  {
    "text": "Thus, in order to harvest most of the speedup beneÔ¨Åts ( 42 ms  vs  1 . 1 √ó  larger) when exploiting the entropy en- coding. However, this entropy encoding consumes  ‚âà 100 ms , which halves our performance gains.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Abstract \nThe deployment of Deep Neural Networks (DNNs) in energy-constrained envi- ronments, such as Energy Harvesting Wireless Sensor Networks (EH-WSNs), introduces significant challenges due to the intermittent nature of power availability. This study introduces  NExUME , a novel training methodology designed specifically for DNNs operating under such constraints. We propose a dynamic adjustment of training parameters‚Äîdropout rates and quantization levels‚Äîthat adapt in real-time to the available energy, which varies in energy harvesting scenarios.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 4,  D¬¥ej`a View  leverages compute lo- cality to bypass computations and provides signiÔ¨Åcant energy savings, with the following two-step optimization strategy: \na  For each frame, if the head orientation remains the same, we take advantage of the  EA  opportunity. b  If exploiting the  EA  opportunity is not possible, we take advantage of the  AE  opportunity, by performing computation for only one eye (and construct the result for the other eye).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "7: Accuracy boost due to proper exemplar selection over 8 hours of time window. Labels: MN ‚Äì MobileNet-V2, BL ‚Äì Baseline, Teacher ‚Äì the ensemble of teacher models, MN‚Äì#: targeted MobileNet-V2 model for the particular time of day. 0 25 50 75 100 \nMN-BL \nTeacher \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-BL \nTeacher \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nNa√Øve w/Exemplar \nAccuracy in % \nHour-0 Hour-2 Hour-4 Hour-6 Hour-8 \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "In  2012 45th Annual IEEE/ACM International Symposium on Microarchitecture , pages 294‚Äì304. IEEE, 2012. [144] Akbar Sharifi, Shekhar Srikantaiah, Asit K Mishra, Mahmut Kandemir, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "1). We further describe the existing holographic execution inefficiencies in the AR pipeline and potential opportunities for computation reduction. 2.1 AR Holographic Applications and Pipeline \nThe holographic display technique enables a large body of aug- mented applications in real life [ 14 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "When any of the active tiles are marked ready by the scheduler, the tile employees a state machine to decide where to get work from. To address the Ô¨Årst two issues, we developed a work-stealing mechanism for each tile. How do we know when to stop executing?",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Sahand Salamat, Armin Haj Aboutalebi, Behnam Khaleghi, Joo Hwan Lee, Yang Seok Ki, and Tajana Rosing. Nascent: Near-storage acceleration of database sort on smartssd. In  The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "828‚Äì842, 2017. [49]  G. Meynet, Y. Nehm ¬¥ e, J. Digne, and G. Lavou ¬¥ e, ‚ÄúPcqm: A full- reference quality metric for colored 3d point clouds,‚Äù in  2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX) , 2020, pp. 1‚Äì6.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "The evaluation shows that our  EA and  AE  designs consume only  2 mW  and  65 mW , respectively, and are able to deliver around  100  fps, which is more than sufÔ¨Åcient for the current VR application requirements. We prototyped our proposed  EA  and  AE  design blocks using System Verilog in Xilinx Vivado 2019.2 [58], targeting the Xil- \ninx Zynq-7000 SoC ZC706 board running at 100MHz (same as state-of-the-art EVR [28]). V. E VALUATION \nWe compare our proposed  EA  and  AE  designs with six different VR streaming setups, by evaluating the computation and the total energy consumption.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": "[66]  Sara Rosenthal, Noura Farra, and Preslav Nakov. In  2016 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pages 1393‚Äì1398. IEEE, 2016.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "[40] L. Liu and M. T. Zsu,  Encyclopedia of Database Systems , 1st ed. [38] MYO NeuralNet , ‚ÄúCalculating the Output Size of Convolutions and Transpose Convolutions,‚Äù ‚Äùshorturl.at/ioLRV‚Äù, 2020. [39] Qualcomm Technologies Inc., ‚ÄúSnapdragon 845 Mobile Platform,‚Äù ‚Äùshorturl.at/fouyP‚Äù, 2018.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "Guilherme H. Apostolo, Pablo Bauszat, Vinod Nigade, Henri E. Bal, and Lin Wang. Live video analytics as a service. In  Proceedings of the 2nd European Workshop on Machine Learning and Systems , EuroMLSys ‚Äô22, pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Define the dropout probability  p i  for neuron  i  based on the reconstruction error of its corresponding feature map. The reconstruction error of a feature map  F i  is calculated as: \nRE i  =  ‚à• F i  ‚àí ÀÜ F i ‚à• 2 \nwhere   ÀÜ F i  is the reconstructed feature map, and  ‚à•¬∑ ‚à• 2  denotes the L2 norm. The idea is to use the reconstruction error to determine the probability: \np i  = Œ≥  RE i max( RE ) +  œµ \n18 \nwhere  Œ≥  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "Keboola, the platform that automates data lineage. [78] Keboola. In  Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation , pages 74‚Äì85, 2010.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "To explain the high-level idea behind PI, we reconsider Frame-3 in Scenario-1 discussed in Sec. IV-A, and present our Ô¨Åve-step solution in Fig. 4.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "As a result, by exploiting the  EA  scheme on the second frame, its compute energy consumption can be reduced to only  1%  of that consumed by  Baseline . If not, we have to execute the entire computation as in the baseline case. D. IntraFrame-InterEye (AE) Computation Optimization \nIn  EA , the compute can be bypassed by reusing the pre- computed results, if the head orientation matches with any of the two previously memoized head orientations (stored in reg- isters).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Autonomous cars generate more than 300 tb of data per year. https: //www.tuxera.com/blog/autonomous-cars-300-tb-of-data-per-year/ . (Accessed on 11/13/2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "The loss  ‚Ñì ( f Œ∏ ( x ) , y )  is convex in  Œ∏ . 2. Consequently, the expected loss  L ( Œ∏ )  is also convex.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "With this estimation, we briefly discuss the performance and computational efficiency variations between this accelerator and our approach, and discuss takeaways that can help one to co-design a hardware accelerator targeting hologram processing. ‚Ä¢  HORN-8:  While hardware acceleration of hologram is not a goal of this work, to qualitatively compare our GPU-based design with hardware specific accelerators, we also discuss one of the most recent ASIC implementations, HORN-8 [ 35 ]. Due to unavailabil- ity of its hardware implementation or datasheet, we estimate its power efficiency compared to the equivalent GPU SoC based on a published data [ 51 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "0% \n5% \n10% \n15% \n0 2 4 6 8 10 12 14 16 Pixel-level Difference \n95% of the pixels differ within 3 \n(b) Distribution of pixel-level difference across two adjacent frames. Fig. 2: Similarity study.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Tensor cores and matrix multiplication engines will be simulated using ScaleSim v2 [137,138], while the memory hierarchy (both DRAMs and HBMs) will be rep- resented using Ramulator [36]. The custom cache hierarchy will be analyzed through gem5 and Cacti [114], and storage drives will be modeled using MQSim [154] and FlashSim [82]. Additionally, our custom chiplet hardware will be simulated using the publicly-available RapidChiplet [68] simulator.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "1037‚Äì1050. [21]  Geo Week News Staff, ‚ÄúCloud Chamber: Low-cost smartphone app captures point clouds for AEC,‚Äù  ‚Äùhttps://bit.ly/3DP1Qvc‚Äù , 2018. [22]  S. Giancola, J. Zarzar, and B. Ghanem, ‚ÄúLeveraging shape completion for 3d siamese tracking,‚Äù in  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "8b and Fig. 8d, the overheads (due to the decision making module in Algo. 1 and Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "¬¥as offers a 4.96% greater mean accuracy than prior approaches while our morphable accelerator that adapts to solar variance can save up to  { 234.95kWH, 2.63MWH } /year/edge-server compared to a  { DNN accelerator, data center scale GPU } , respectively. I. I NTRODUCTION \nThe rampant growth, and anticipated sustained expansion of data collection and consumption are currently driving data-driven analytics using trained inference models, with signiÔ¨Åcant economic impact. Amidst the myriad of data-driven domains, urban mobility, smart cities, autonomous driving, and the Internet of Things (IoT) emerge as some of the most rapidly expanding Ô¨Åelds contributing to the global economy, amounting to more than 4 trillion US dollars [ 1 ], [ 54 ], [ 76 ], [ 98 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 188,
    "augmented": false
  },
  {
    "text": "0% \n5% \n10% \n15% \n0 2 4 6 8 10 12 14 16 Pixel-level Difference \n95% of the pixels differ within 3 \n(b) Distribution of pixel-level difference across two adjacent frames. Further, if we can  dynamically  exploit this opportunistic similarity (i.e., the inference is invoked based on runtime contents), the solution can encompass most vision applications without affecting the current hardware stack. 0% \n20% \n40% \n60% \n4x4 8x8 16x16 32x32 1080x1920 Tile Size \n<0.1%  \nIdentical Tiles \n(a) Similarity study at different tile size across adjacent frames for a video in VIRAT dataset [33].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "This stability allows us to treat  D  as effectively fixed for the purpose of the asymptotic analy- sis. If  D  were to drift significantly, standard SGD results would not directly apply. The equilibrium prevents such non-stationary behavior in the long run.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)  42, 4 (2012), 1131‚Äì1142. 2004. https://doi.org/10.1109/TSMCB.2012.2187441 [21]  Ron Begleiter, Ran El-Yaniv, and Golan Yona.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "However, if   P \ni   E q i   > E b , we aim to fuse tasks to minimize checkpointing overhead. , q k }  be a set of QuantaTasks with in- dividual energy requirements  E q i . If   P \ni   E q i   ‚â§ E b , the available energy budget, then tasks can be executed sequentially without interruption.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "The GKDQ always points to the next available kernel location. The control fetches the right number of kernels and all of them are synchronously executed in the active tiles. Eager Scheduling:  A weight stationary implementation with a conservative scheduling will always run synchronously.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "In  Eighth International Conference on Database Systems for Advanced Applications, 2003. Manuel J Fonseca and Joaquim A Jorge. Indexing high-dimensional data for content-based retrieval in large databases.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "1027‚Äì1035, 2007. Bahman Bahmani, Benjamin Moseley, Andrea Vattani, Ravi Kumar, and Sergei Vassilvitskii. Scalable k-means++.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "289‚Äì304. 1083 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "C.1.4 Check-pointing Mechanism \nBefore each power interruption, detected through an energy monitoring system, the algorithm saves the current state using the  SAVE_STATE  function. This state includes the loop indices and the current value of the element being processed in  C . This ensures that no computation is lost when the power goes out.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Special-purpose Computer HORN-8 for Phase-type Electro- holography. Opt. Express  (2018), 26722‚Äì26733.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "In  Advances in Neural Information Processing Systems , pages 5204‚Äì5213, 2017. Identifying outlier arms in multi-armed bandit. [88]  Sheikh Ziauddin and Matthew N Dailey.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "It comprises of 100 distinct image classes and we trained 11 different models including the nine that are common from Table  1 . Fig- ure  15a  plots the average number of models used by the three policies for the top four constraints. It can be seen that  Cock- tail  shows similar reduction (as Imagenet) while using only 4.4 models on average.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Our architectural support will result in a search space exploration methodology that can be used to map experts to chiplets for improving execu- tion efficiency. Finally, our evaluation infrastructure can be used for fostering new research directions not only in LLMs, but also broadly in any ‚Äútransformer-based‚Äù applications like recommendation systems and multi-modal Generative AI applications, for efficient training and inferences. Curriculum Development Activities : As we have done in our prior NSF projects, we will integrate our research results from this project with educational activities and graduate and undergraduate student train- ing for nurturing the future workforce in science and engineering.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "The work queue schedule, intermediate result, network and layer information are saved on predicted power failure, and data from the DRAM (the working set of IF/OF/Ô¨Ålter and model state) are moved to an NV-RAM using STT-RAM based buffers in the memory hierarchy (parallel to the IF/OF/Ô¨Ålter). We do  not  replace the DRAM buffers with NVM because of limited lifetimes [ 17 ]. The host writes the latest copy of the completed iteration (in epoch granularity) into the STT- RAMs (STT-RAM-N for the upper 128 SAs, and STT-RAM- S for the lower 128SAs, Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "Pose Estimate \n33  ms Kimera [53] \nEye Track \n33  ms NVGaze [26] \nScene Reconstruct \n100  ms InfiniTAM [50] \nHologram 33  ms GSW [49, 63] \ntasks and interacts with more hardware resources [ 61 ]. Based on our measurements collected from a smartphone [ 60 ] running a sim- ple AR application [ 3 ], the processing performance can be lower than 0 . 5 fps, and the battery life can be as short as just 1 hour.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "This information is used for cal- culating the weights per model for autoscaling decisions. We integrate a  mongodb  [ 21 ] database in the master node to main- tain all information about procured instances, spot-instance price list, and instance utilization. The load prediction model resides in the master VM which constantly records the arrival rate in adjacent windows.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "The probabilities vary by approximately  ¬± 20% of a seed. Note that these probabilities are not visible to  Kraken , but are only used to model function invocation patterns. Transitions between functions are done using function calls on the basis of pre-assigned inter-function transition proba- bilities.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "In this paper, we refer to this combined scheme as  Inter-Intra-Holo . In this scheme, we first identify the objects in- side/outside the RoF ( Inter-Holo ), and then approximate each of them based on its shape and distance ( Intra-Holo ). Note that since the other option ‚Äì first  Intra-Holo , then  Inter-Holo  ‚Äì is theoreti- cally identical to the proposed  Inter-Intra-Holo , we skip its detailed discussion due to space limitation.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "[29] C. Louizos, K. Ullrich, and M. Welling, ‚ÄúBayesian Compression for Deep Learning,‚Äù in  Proceedings of the 31st International Conference on Neural Information Processing Systems , 2017, p. 3290‚Äì3300. [30] H. Yeo, C. J. Chong, Y. Jung, J. Ye, and D. Han, ‚ÄúNEMO: Enabling Neural-Enhanced Video Streaming on Commodity Mobile Devices,‚Äù in  Proceedings of the Annual International Conference on Mobile Computing and Networking (MobiCom) , 2020. [31] K. Simonyan and A. Zisserman, ‚ÄúVery Deep Convolutional Networks for Large-scale Image Recognition,‚Äù  arXiv preprint arXiv:1409.1556 , 2014.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 184,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, we pick four videos from 8iVFB, and two videos from MVUB. The 8iVFB dataset contains the PC data of four persons, captured by 42 RGB cameras placed at different angles, while the MVUB dataset consists of Ô¨Åve subjects captured by four frontal RGBD cameras. All these videos used are captured at 30fps, and voxelized into  1024 √ó 1024 √ó 1024  voxels (3D points), with each point containing three  Ô¨Çoat-pointing  coordinates and three  unsigned char  RGBs.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "V, we perform a detailed comparison of our work against these prior works. As mentioned in Sec. I, DeepCache does not take advantage of frame-wise data reuse opportunities (e.g., reuse the inference result for similar frames).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "The most common algorithms used fod the said operations are High-Speed Schoolbook Polynomial Multiplication (HSPM) and Pipelined Systolic Dimension Modular Multiplier (SDMM), and we propose to accelrate the same using the FPGAs in the CSDs. The data locality due to the SSD and the high throughput due to the FPGA could facilitate swift polynomial processing and refined modular multiplications using DSP slices, thereby accelerating the encryption process. Designing HSPM Accelerator on CSD FPGA:  The HSPM hardware is characterized by its fully parallelized design, incorporating 128 Multiply-Accumulate (MAC) units for handling polynomials of degree  n  = 256 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "4). 2), and the union of the BBoxes and the MVs is reported as the  new  regions of interest (RoIs) (see  2  in Fig. Finally, if the frame falls under the category in which objects have not been signiÔ¨Åcantly displaced, then it is labeled as ‚ÄúPI‚Äù (as shown in Line  9  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "ITU-T Recommendation H.264. ITU-T. High efficiency video coding. International Telecommunication Union, June 2019b.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "[43]  Marek Kowalski, Jacek Naruniec, ‚ÄúLiveScan3D-Hololens,‚Äù \n‚Äùhttps://github.com/MarekKowalski/LiveScan3D-Hololens‚Äù , 2020. [44]  Marek Simonik, ‚ÄúRecord3D-Record your own 3D Videos!‚Äù \n‚Äùhttps://record3d.app/‚Äù , 2021. [45]  S. Martin, M. Stefan, A. Karl  et al.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "In this example, for compressing the P-Frame, one pointer (for  S 1  which contains  P 0  and  P 1 ) and only one post-intra-encoded compressed delta (for  P 2 ) are required for storage, instead of storing all three. However, the proposed inter-frame compression pipeline has additional steps (PC sorting and block matching), which collectively take about 139 ms  for a typical PC frame. 291 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "2020. [43]  Paulo Silva, Daniel Fireman, and Thiago Emmanuel Pereira. 205‚Äì218.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "D.3 Feature Map Reconstruction Error Dropout with QuantaTask Optimization \nFeature Map Reconstruction Error Dropout leverages the reconstruction error of feature maps to adjust dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. Mathematical Formulation:  Let  W  be the weight matrix of a layer and  F  be the feature maps produced by the layer. The reconstruction error of a feature map  F i  is calculated as: \nRE i  =  ‚à• F i  ‚àí ÀÜ F i ‚à• 2 \nwhere   ÀÜ F i  is the reconstructed feature map, and  ‚à•¬∑ ‚à• 2  denotes the L2 norm.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "Fig. 8a  shows the number of layers trained for a DNN, in contrast to the ideal number of layers to achieve maximum accuracy. Over 10 training iterations, we observed the micro-proÔ¨Åler to be con- sistent with the oracle (except for one case of iteration 7).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "The actual parallelism granularity  aG ‚â§ G  for a layer is decided by the harvested power level. That is, if the 50% peak harvested power by proÔ¨Åling is twice ( G =2) of the power consumption with a ReRAM size of Layer 1 of 25x6, the RCA will be designed to offer two sets of ReRAMs sized 25x6 for Layer 1. In this work, the parallelism granularity  G  of a layer is determined by the ratio between 50% of the peak harvested power during proÔ¨Åling and the power consumption of the full- size ReRAM corresponding to this layer.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "While each component can individually optimize DNNs for intermittent environments, their combination yields the best results. Our innovation lies in the integration of energy variability awareness directly into both the training and inference processes, enabling dynamic adaptation to real-time energy conditions, which is not addressed by existing methods (Mendis et al., 2021; Yen et al., 2023, 2022; Montanari et al., 2020; Islam & Nirjon, 2019). To search for the best architecture for the given intermittent environ- ment, DynNAS utilizes the approach proposed by iNAS (Mendis et al., 2021).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "[59] Xilinx, ‚ÄúVivado Design Suite - HLx Editions.‚Äù ‚Äùhttps://www.xilinx.com/ products/design-tools/vivado.html‚Äù, 2019. [60] xinreality, ‚ÄúAsynchronous Spacewarp.‚Äù ‚Äùhttps://xinreality.com/wiki/ Asynchronous Spacewarp‚Äù, 2019. [58] Xilinx, ‚ÄúVivado Design Hub - Installation and Licensing,‚Äù ‚Äùhttps://www.xilinx.com/support/documentation-navigation/design- hubs/dh0013-vivado-installation-and-licensing-hub.html‚Äù.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 169,
    "augmented": true
  },
  {
    "text": "However, the basic principle remains the same, where the input signals are applied to the rows, the weights are applied to the columns, and the output signals are obtained by summing the currents flowing through the ReRAM devices. E.1.2 Extending to Complex Compute: \nIn order to perform multiplication-addition in ReRAM x-bars, two arrays of weights and inputs are used. The inputs are fed to the x-bar, which is a two-dimensional array of ReRAM crossbar arrays.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "[22]  Francois Chollet. O‚ÄôReilly Media, Inc.\", 2013. MongoDB: the deÔ¨Ånitive guide: powerful and scalable data storage . \"",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "‚Ä¢  For the ReRAM circuit concerned works [ 6 ], [ 8 ], although they are lightweight, they  cannot  be dynamically reconÔ¨Ågured to adapt changing power levels. In addition, such works have not presented any software level solution to maximize the utilization of the hardware platform. In order to accommodate the RCA to the changing harvested power supply, we need a ‚Äúlightweight‚Äù and ‚ÄúÔ¨Åne-grain controllable‚Äù design from both the hardware and software angles.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Swift: Adaptive video streaming with layered neural codecs. In  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , pp. 103‚Äì118, Renton, WA, April 2022b.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Torr. SemanticPaint: A Framework for the Interactive Segmentation of 3D Scenes. 2015.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "Since each single ReRAM can be activated at a Ô¨Åner granularity with tiling, the parallelism can be achieved under a Ô¨Çexible range of power consumption to match a variable power supply. Furthermore, the better the high-power supply can be aggressively utilized, the more ambient energy can be continuously extracted without increasing the energy storage capacity for the energy-harvesting power delivery system. Therefore, this weight duplication- based execution style built upon Ô¨Åne-granularity activation can effectively combat  Nonideal scenario 2 .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Rapidchiplet: A toolchain for rapid design space exploration of chiplet architectures, 2023. arXiv preprint arXiv:2407.11686 , 2024. [68] Patrick Iff, Benigna Bruggmann, Maciej Besta, Luca Benini, and Torsten Hoefler.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "The output of each ReRAM device is the product of the input and weight signals, which are added together using the crossbar wires. This results in a single output signal that represents the sum of the weighted inputs. To perform convolution, ReRAM x-bars use a similar approach, but with a more complex circuit.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Thus, a typical PC frame containing  10 6 \npoints [ 49 ] require  120 M  bits of data, which is impossible to transmit in real-time to the end-user‚Äôs display, from both the latency and energy standpoints, considering a \nsteady  30 - 60  f ps  requirement. Therefore, the PC video frame is compressed in the  PC Encoding  stage, before being transmitted over the  network  to the end-user. The received frame is decoded in the  PC Decoding  stage and the decoded PC frame is forwarded to the  Render and Display  stage where it is Ô¨Ånally rendered and displayed on the screen.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "Figure 10: (a) comparison between i: raw PC and our proposals (ii: intra, iii: intra-inter-V1, iv: intra-inter-V2). Original (x) \n% Direct-reuse Blocks \nCompression Ratio PSNR(dB) \n(b) Sensitivity study. 37 39 41 43 45 \n7 8 9 10 11 12 \n31%58%69%79%82% \nPSNR(dB) \nCompressed Size  w.r.t.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "2 . Note that this step is also time-consuming, as shown in Fig. This is because that all the nodes in the tree are traversed sequentially.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "The system needs at least 512 cycles of advanced notice to Ô¨Çush compute and enable a compute migration. ¬¥as is always conservative, and the solar power predictor has a mean accuracy of 92%, limiting false positives and helping the control unit select appropriate tile counts. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Asso- ciation for Computing Machinery. In  Proceedings of the 50th Annual International Symposium on Computer Architecture , ISCA ‚Äô23, New York, NY, USA, 2023. Edgepc: Efficient deep learning analytics for point clouds on edge devices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Accelerating sparse deep neural networks. CoRR , abs/2104.08378, 2021. [110] Asit K Mishra, Narayanan Vijaykrishnan, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "The provisioning latency, instance permanence and packing factor of these resources have a direct impact on the latency and cost of hosting model-serving. We explain instance ‚Äúpack- ing factor‚Äù and its relationship with latency in Section  2.3.2 . In this paper, we focus on improving the accuracy and latency from the model selection perspective and consider instances types from a cost perspective.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "The representative research questions this thrust will strive to answer include: i)  How can an EoE system be trained in a performance- and energy-efficient manner through the maximization of data locality and parallelism? ; ii)  What are the ways of efficiently retraining routers when new experts are added into or removed from the ensemble? 2.2 Thrust-2: System Support for Expert Scheduling and Data Movements The primary goal of this thrust is to explore novel system support ‚Äì targeting  both  training and inference ‚Äì that complements our algorithmic support for EoE in Thrust 1 and architectural support for EoE in Thrust 3.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture , pages 489‚Äì500, 2011. [183] Yuanrui Zhang, Wei Ding, Mahmut Kandemir, Jun Liu, and Ohyoung Jang. A data layout optimiza- tion framework for nuca-based multicores.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Recall that the number of depth planes for each hologram object affects the ex- ecution latency dramatically as shown in Fig. 68 √ó  when employ- ing  Inter-Intra-Holo  (with only 0 . 14% overhead).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "The projection transformation Ô¨Årst calculates the transformation matrix ( T  ), and then uses the transformation matrix to map each of the pixel coordinates to generate the projection matrices ( P ) for the FoV frames. following two properties from a published  360 ¬∞ VR dataset [3], as shown in Fig. Then projection mapping stage uses this coordinate mapping ( P ) to move pixels from the original 360 frame  F 360  to the 2D frame  F .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "2 Cocktail is ascribed to having the perfect blend of models in an ensemble. Applications \nImage  Recognition NLP Recommender  Systems \nModels \nVM \nVM \nVM VM VM \nVM \nFrameworks \nCloud \nResources \nSLO \nAccuracy \nLatency \nUsers \nBurstables Spot CPU GPU \nCost \nLatency \nFigure 2:  The overall framework for model-serving in public cloud. 4.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "IEEE Press, 2019. doi: 10.1109/ICRA.2019.8794073. URL  https://doi.org/10.1109/ICRA.2019.8794073 . 19 \nEideticom and Los Alamos National Laboratory.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Let  Q  represent the set of execution quanta, where each quanta  q  ‚ààQ  is defined by a tuple  ( l, e ) : q  = ( l, e ) Here,  l  is the number of loop iterations and  e  is the estimated energy required for these iterations. The goal is to optimize the loop iteration parameter  l  such that the energy consumption  E q  for each quanta  q  is within the energy budget  E b : \nminimize X \nq ‚ààQ E q subject to E q  ‚â§ E b \nTraining with Learning Sparse Masks Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask parameters  z , and scaling factor  Œ± . Define the energy budget E b  for a single quanta and for the entire inference.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 197,
    "augmented": false
  },
  {
    "text": "The primary innovation lies in leveraging motion vectors to identify and encode only the changes between frames, rather than re-encoding entire frames. Let  F t represent the frame at time  t , and  F t ‚àí 1  be the anchor frame. This technique, combined with the use of anchor frames‚Äîsimilar to keyframes in traditional codecs‚Äîallows the codec to understand and predict frame sequences more effectively, reducing redundancy and enhancing compression.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Designing any sophisticated ensemble learning technique will either consume more resources of the host device, or need more information and computation at the edge, thus making our effort of Ô¨Ånishing the inference at the edge not viable. However, if we can design a simple, light weight and adaptive ensemble technique, then our design will be holistic from both the sensor and the host side. The current scheduler is activity aware, i.e.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Clipper , on the other hand, is static and always uses all the models. This is because our dynamic pol- icy ensures that the number of models are well within  N / 2 most of the time, whereas the  Clipper-X  policy does not ag- gressively scale down models. Here,  Cocktail  reduces the number of models by up to 55% for all four query types.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "They will not only evaluate whether the individual and intermediate research goals have been achieved or not, but  will also discuss the progress towards achieving the educational and outreach/BPC goals of the project. The necessary adjustments will be made if the observed progress is not satisfactory. The PIs will meet with the PhD students as frequently as needed.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Stateful neural networks for intermittent systems. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , 41(11):4229‚Äì4240, 2022. Chih-Hsuan Yen, Hashan Roshantha Mendis, Tei-Wei Kuo, and Pi-Cheng Hsiu.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "To better explain where the power benefits come from, we further breakdown the power consumption for the hologram processing into four parts: CPU (to handle sensor inputs, scheduling, kernel launch, etc. 95% power reduction compared to the baseline. ), GPU (to execute hologram), Mem (for data accesses), and the SoC (the remaining hardware components, e.g., codec, network), with different number of depth planes (ranging from 2 to 16), as shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "2020. Meet the Humans of the Future: Holograms, Digital Humans, and Deep Fakes. \"https://medium.com/demagsign/meet-the-humans- of-the-future-holograms-digital-humans-and-deep-fakes-35024b881545\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "2. Prediction and Residual Calculation:  Implement pipelined architectures for the  predict ( ¬∑ )  function and subsequent residual calculation to minimize latency. 3.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "Our main  contributions  include: \n‚Ä¢  We propose design of a hybrid storage pipeline equipped with computational storage drives (CSDs) where the different drives could communicate with each other in a peer-to-peer fashion. These CSDs synergistically orchestrate the archival related tasks between the storage controller CPU and the computational storage FPGAs. The hybrid storage system is capable of taking the computed \n2 Given a powerful enough computer like quantum computers, RSA encrypted data can be decrypted, and therefore National Institute of Standards and Technology (NIST) called for proposals to develop post quantum cryptography algorithms (National Institute of Standards and Technology (NIST), 2024), and defined a standard for the same.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "Diverse Collaborations \nFinally, the PhD students in the project will be encouraged to engage in collaborations with researchers from diverse backgrounds and disciplinary areas to enhance their collaboration and communication skills. Facilities, Equipment, and Other Resources \nThe participants of the proposed project have access to the facilities and resources described below. Lab Resources:  The PIs collectively have more than 6,000 sq.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "This may be due to Media Service  having higher path unpredictability than  Hotel Reservation  (Table 2) as well as lower slack per function than Social Network  (Figure 7). From Figure 16b, it is observed that  Oracle , being clairvoyant, spawns containers in accor- dance with the peaks and valleys of the request arrival trace. Kraken , while spawning more containers, also is seen to lag behind the trend of the trace due to load prediction errors.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "We use a two-level data annotation mechanism: exemplar identiÔ¨Åcation based on the \n1 Vedic goddess of dawn in Hinduism [ 36 ]; emphasizing the dawn of sustainable continuous learning and signiÔ¨Åcance of solar power in our design. conÔ¨Ådence matrix of the student model, followed by a repre- sentation learning based exemplar selection by ensembling multiple teacher models. Our policy updates  both  the teacher and student models for robust unsupervised learning.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Instead, to perform complex and continuous inference, such as HAR, the data is typically ofÔ¨Çoaded either to the cloud or \nto a nearby host device which in turn executes the inference or further redirects it [4] and, Ô¨Ånally, returns the results to the IoT devices responsible for data display or actuation, dependent on the inference task. Given the power and compute constraints of the IoT devices performing sensing, it is difÔ¨Åcult to execute these inference tasks on the sensing device itself, excepting a few intermittent tasks such as bio-metric authentication. Recent works [5], [6] suggest that processing data at the source is more efÔ¨Åcient that sending them to the cloud and getting the results back, owing to the power and latency overhead of data communication.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 167,
    "augmented": true
  },
  {
    "text": "However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms. Such platforms often already operate at their limits just in order to transmit sensed data at acceptable quality of \nservice (QoS) rates for deployment-viable battery lifetimes, and may not have additional resources available for further computation. For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "IEEE, 2024. In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pp. 891‚Äì907.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Compute the activations a  and apply the dropout mask: a dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output. Calculate the gradients of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \n16 \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the L2 norm of the weights: \np i  = Œ± ‚à• W i ‚à• 2  +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise Perform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 360,
    "augmented": true
  },
  {
    "text": "VI. Putting together, these above observa- tions indicate that, with very little change (to capture the row- dependent information) in our original  AE  design, our idea is able to work with any representation format. This motivates us to target on further improving quality across video formats by capturing the information related to row numbers in future.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Throughput results are plotted in Figure 12 and area costs for  G 1  ‚àº G 5  can be found in Figure 13. For each benchmark, all the numbers are normalized to that of the  G4  setting with the  Naive2  policy. As expected, the throughput increases as  G  grows for every benchmark.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "The overall utility is: \nU i ( t ) =  R i ( t )  ‚àí C i ( t ) . We assume that  ‚àÜ A i ( t )  is non-decreasing in the quality of sensor  s i ‚Äôs data (e.g., higher SNR yields higher  ‚àÜ A i ( t ) ). We also assume that energy resources, accuracy gains, and reward/penalty parameters are finite and bounded, and that sensors have consistent estimation mechanisms for  ‚àÜ A i ( t ) and   ÀÜ E i ( t  + 1) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "We would also like to thank Dr. Jack Sampson and Dr. Dinghao Wu for their feedback on this paper. 2020. REFERENCES \n[1]  Adel Ahmadyan, Liangkai Zhang, Jianing Wei, Artsiom Ablavatski, and Matthias Grundmann.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "[62]  Alanson P Sample, Daniel J Yeager, Pauline S Powledge, Alexander V Mamishev, and Joshua R Smith. 2008. Design of an RFID-based battery- free programmable sensing platform.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Thus, we memoize both head orientation and its corresponding projec- tion matrix (i.e., projection computation results) in a memory buffer, namely,  P buff , and use the head orientation to index the address/pointer of that  P buff  stored in DRAM. How Much to Memoize? The occupied DRAM size is mainly determined by  P buff .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Energy efÔ¨Åciency \nWe evaluate energy efÔ¨Åciency by measuring MAC operations per Joule, as shown in Figure 9. Overall, the normalized results of energy efÔ¨Åciency are very similar to those of the throughput evaluation. Note that this includes the energy overheads of data movements and other functional units in addition to MACs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "First, due to the stateless nature of FaaS, individual mi- croservices have to be designed as functions and explicitly chained together using tools to compose the entire appli- cation, thus forming a Directed Acyclic Graph (DAG) [ 33 ]. Second, the state management between dependent functions has to be explicitly handled using a predefined state ma- chine and made available to the cloud provider [ 6 ,  23 ]. Third, the presence of conditional branches in some DAGs can lead to uncertainties in determining which functions will \n153 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 169,
    "augmented": false
  },
  {
    "text": "147‚Äì191. Springer, 2009. In  Post-quantum cryptography , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "91‚Äì103. [29] Y. Li and W. Gao, ‚ÄúDeltaVR: Achieving High-Performance Mobile VR Dynamics through Pixel Reuse,‚Äù in  2019 18th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN) , 2019, pp. 13‚Äì24.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Figure 7: Slack for various Functions in each Application. The batch size represents the number of requests that can be served by a function without violating the allotted stage-wise SLO. offline profiling and  StageSLO (f)  is allotted in proportion to it.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 1037‚Äì1050. [11]  Yu Feng, Paul Whatmough, and Yuhao Zhu.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "https://mikhail.io/ serverless/coldstarts/azure/. [15]  2021. Expedia Case Study - Amazon AWS.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "4229‚Äì4240, 2022. [105] Z. Ying, S. Zhao, H. Zhang, C. S. Mishra, S. Bhuyan, M. T. Kandemir, \nA. Sivasubramaniam, and C. R. Das, ‚ÄúExploiting frame similarity for efÔ¨Åcient inference on edge devices,‚Äù in  2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) . IEEE, 2022, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "This is because it allocates containers to serve the predicted load along only the Most Likely Path (MLP) of a request. Furthermore, it can be seen that Xanadu  provisions a relatively high number of containers for a particular group of functions as compared to the rest. The rest of the containers are a result of  reactive scaling  that follows from MLP mispredictions, which accounts for 34% of the total number of containers spawned.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "The VLDB Journal  17, 3 (2008), 401‚Äì417. Pre- dicting WWW surfing using multiple evidence combination. 2008.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "Next, we consider a model where multiple devices from multiple deployments participate in cooperative data sharing. In both cases, due to the resource limitation of the edge devices, edge-specific model size may be reduced at the expense of accuracy. The cloud server, to accommodate data drift, periodically (but infrequently) accumulates all the data from different deployments to train a larger model which can generalize better than the local, edge specific, models.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Architectural Constraints/Suitability \nHot Experts \n2.3 Caching/Prefetching  \nHot Experts  \nCold Experts \nStorage \nRAM \nL3 $ \nL2 $ \nMem. Hierarchy \nL1 $ \n2.4 KV Cache  Management \nCompression \nHardware-aware policies \nTailored Token  Eviction \nEnsuring Coherence \nThrust 4:  \nEvaluation &  \nFine Tuning \n2.5 Runtime  \nSupport \nSLO  Guarantee \nAccuracy \n2.6 Fault Tolerant  \nExpert Training \nIsolated  Training Redundancy \nCheckpoint /Recovery \nAlgorithmic Characteristics \nDynamic Re-routing \nCross-Layer Evaluation \n3.1 Expert/Hardware  \nCo-Characterization \nExperts Hardware \nProfile  Expert Execution Attribute Database \n3.2 Chiplet-based Modular  \nHardware Platform \n3.3 Reconfiguration 3.4 Hardware-Software  \nCo-Optimization \n4.1 Evaluation Infrastructure 4.2 Methodology \nExpert,  EoE Chiplet,  Chip Chiplet, Chip Reconfigure Chiplet,  Network \nMonitor & Control \nExposed Hardware Knobs \nPath Frequency \nAccelerator Availabililty \nExperiments on  Testbeds \nAnalytical Model \nSimulation \nTraining  Dataset \nMetrics of  Interest \n‚Ä¢ Latency ‚Ä¢ Power ‚Ä¢ Accuracy ‚Ä¢ Cost \nMemory  Constraints \nGPU \nCPU \nAccel \nAccel \nReconfig \nPlug-n-Play  \nChiplets \nExpert-to-Chiplet  \nMapping Homogeneous and  Heterogeneous Chips \nCustom  Interconnection  \nNetwork \nFigure 2 :  Overview of the proposed project. 1.1 EoE Design Space Exploration 1.2 Constructing Morphology  \nof EoE \n1.3 Continual Adaptation of  \nExperts \nExperts \nExpert Routing  Functions \nComposition  \nfunctions Independent training possible \nExplore \nStore \nExplore Morphologies \nTree EoE Graph EoE \nChain EoE \nSplitting \nMerging \nGrowing Shrinking \nMinimal Retrain Overheads \n1.4 Algorithmic Choices informed  \nby System & Hardware  \nConstraints MORPH (Graph Pruning/ \nGraph  Reconstruction/  \nExpert  Selection) \nBased  \non \n... \nSystem/Resource  Constraints \n2.2 Router  Retraining \nSystems Constraints/Decisions \n?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 466,
    "augmented": true
  },
  {
    "text": "This adaptation is guided by the dropout mask vector and the specific type of sparse matrix operation being performed. This technique effectively reduces the number of load operations by an average of 12%, thereby enhancing the efficiency of computations under energy constraints and contributing to the overall performance improvements in NExUME. 4.2 NExUME on Publicly Available Datasets \nDatasets:  For image data, we consider the Fashion-MNIST (Xiao et al., 2017) and CIFAR10 (Alex, 2009) datasets; for time series sensor data, we focus on popular human activity recognition (HAR) datasets, MHEALTH (Banos et al., 2014) and PAMAP2 (Reiss & Stricker, 2012); and for audio, we use the AudioMNIST (Becker et al., 2023) dataset.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 197,
    "augmented": false
  },
  {
    "text": "Our contributions include: (1) Two different edge-cloud learning and inference policies, in a distributed sensor environment, to efficiently run ran- dom forest based data analytics. We also provide novel learning strategies, especially when the distributed sensors do not want to share the local data with the cloud, saving crucial communication latency and energy. We explore the impact of privacy-preserving random forest training mechanisms to help protect sensitive data generated by the sensors.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "19 \nEideticom and Los Alamos National Laboratory. Line-rate compression on lustre/zfs-based par- allel filesystems using noload computational storage processor. https://www.eideticom.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "For example, in Figure 1a, the Commonality  of the function  ùê∂ùëúùëöùëùùëúùë†ùëí _ ùëÉùëúùë†ùë° in the  Social Network  application is given by the fraction   4 \n7   as it is present in four out of the seven possible paths in the DAG. To cope with this, we introduce a parameter called  Commonality , which is defined as the fraction of number of unique paths that the function can be a part of with respect to the total number of unique paths. This is how the procedure  ùê∂ùëúùëöùëö calculates Commonality  in Algorithm 1.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "This paper proposes ResiRCA, a resilient energy harvesting accelerator. We propose a lightweight and Ô¨Çexibly tuning RCA architecture and a ResiSchedule scheme to dynamically activate various scaled MAC operations so as to fully translate the ‚Äúharvested energy‚Äù into ‚Äúcomputation progress‚Äù. ResiRCA supports smooth transi- tions among different activation solutions against computation loss.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "[17] A. Reiss and D. Stricker, ‚ÄúCreating and benchmarking a new dataset for physical activity monitoring,‚Äù in  PETRA , F. Makedon, Ed. ACM, 2012. [18] F. Chollet  et al.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Next, we use one of the popular SLAM techniques, Kimera-VIO [ 53 ], to estimate the user‚Äôs pose and understand the relative positions of the objects and the user. As shown in Fig. To lever- age this opportunity, we need to know where the user is located in the world and what the objects in the world look like [ 13 ,  19 ,  53 ,  59 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Attila Reiss and Didier Stricker. Introducing a new benchmarked dataset for activity monitoring. In 2012 16th international symposium on wearable computers , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Three demo examples of reconstructed images by OpenHolo are shown in Fig. 9: viewing a whole-hologram from different pupil positions in Fig. 9a; viewing an entire hologram (in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "[2] K. Boos, D. Chu, and E. Cuervo, ‚ÄúFlashBack: Immersive Virtual Reality on Mobile Devices via Rendering Memoization,‚Äù in  Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services , ser. MobiSys ‚Äô16, 2016, pp. 291‚Äì304.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "How do we know when to stop executing? To address the Ô¨Årst two issues, we developed a work-stealing mechanism for each tile. When any of the active tiles are marked ready by the scheduler, the tile employees a state machine to decide where to get work from.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Conf. on Robotics and Automation (ICRA) . [54]  Liang Shi, Beichen Li, Changil Kim, Petr Kellnhofer, and Wojciech Matusik.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Us.¬¥as, unlike prior edge-focused analytics approaches (e.g., Ekya [ 12 ]), detaches the inference and train- ing hardware, as the training task is the major source of the compute, power, and time consumption. Us.¬¥as introduces an al- gorithmic framework for data labeling using a teacher-student model, designing the exemplar selection using representation learning and determining the right set of hyperparameters using micro proÔ¨Åling to energy-efÔ¨Åciently continuously train the DNNs with the selected exemplar sets. Us.¬¥as also employs a dynamically morphable systolic array for enabling energy- efÔ¨Åcient computing within the harvested power envelope.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 165,
    "augmented": false
  },
  {
    "text": "IEEE, 2012. [16] A. Reiss and D. Stricker, ‚ÄúIntroducing a new benchmarked dataset for activity monitoring,‚Äù in  ISWC . [17] A. Reiss and D. Stricker, ‚ÄúCreating and benchmarking a new dataset for physical activity monitoring,‚Äù in  PETRA , F. Makedon, Ed.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a \n3-bit resolution, which is a high performance but also a high power consuming design. Although the above designs provide different approaches to achieve high throughput, high energy efÔ¨Åciency and low power, they cannot be directly applied or combined to be applied in the energy harvested edge devices due to the following reasons. ‚Ä¢  The architecture-centric works [ 3 ], [ 4 ], [ 5 ] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "The trend we observe is that traces with higher variability, such as the Twitter trace, af- fect the tail latencies of policies more harshly than the other, more predictable, traces. Nevertheless,  Kraken  is resilient to \nPolicy Poisson Wiki Twitter Med Tail Med Tail Med Tail Arch 336 568 336 568 336 599 Fifer 362 612 360 611 373 833 DProb 371 746 368 753 381 1549 Kraken 366 634 358 633 371 974 SProb 395 1101 382 1073 395 1610 Xanadu 343 723 340 774 340 1244 Table 6: Simulator: Median and tail latencies (in ms) averaged across all applications for the three traces \nunpredictable loads as well, with tail latencies always remain- ing within the SLO (1000 ms). However, the tail latencies of  DProb  and  SProb  sometimes exceeds the SLO, since they don‚Äôt use  Commonality  and  Connectivity .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 240,
    "augmented": false
  },
  {
    "text": "Our system support will provide a framework using which re- searchers can conduct scalable training and inference experiments. Specifically, our algorithmic layer will ad- vance state-of-the-art in LLM models and algorithms and generate an extensible framework in which more futuristic EoE networks can be explored. Our architectural support will result in a search space exploration methodology that can be used to map experts to chiplets for improving execu- tion efficiency.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Therefore, we adapt a ‚Äústudent-teacher paradigm‚Äù [ 46 ], where a more \nClassify \nLow Conf \nFrame? Discard \nFrame No \nExemplar Yes \nYes \nEdge Model \nConfidence Matrix \nMajority Voting Labeling \nM1 \nM2 \nM3 \nFig. 2: Auto-labeling in  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Pyramidinfer: Pyramid kv cache compression for high-throughput llm inference, 2024. [172] June Yong Yang, Byeongwook Kim, Jeongin Bae, Beomseok Kwon, Gunho Park, Eunho Yang, Se Jung Kwon, and Dongsoo Lee. No token left behind: Reliable kv cache compression via importance-aware mixed precision quantization, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "6 \nThe meta information of these VR videos are listed in Tab. II. C. Experimental Results \nWe present and compare the energy consumption of the pro- jection computation and the cor- responding video quality impact, when running the Ô¨Åve VR videos described in Tab.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "PI Kandemir is an adviser/co-adviser of 5 female students, and PI Zhang has been advising 1 female PhD student, 4 female undergraduate stu- dents for their honors thesis projects, and serving on PhD dissertation committee for 9 female PhD students including 1 African American student. We plan to share our BPC effort outcomes in our NSF project reports and at different forums such as the annual Big Ten Department Heads meeting as well as in Tapia and CRA-W conferences. Mentoring Plan \nThis project will accommodate a total of 4 PhD students, as discussed in our Management and Coordi- nation Plan.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Figure  5  depicts the high-level design of  Cocktail . Users submit requests to a master VM, which runs a model selection algorithm, 1a to decide the models to participate in the ensemble. The participating models are made available in a model cache  1b for faster access and avoid re-computation for requests having similar constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "[91] Feihui Li, Chrysostomos Nicopoulos, Thomas Richardson, Yuan Xie, Vijaykrishnan Narayanan, and Mahmut Kandemir. Design and management of 3d chip multiprocessors using network-in-memory. ACM SIGARCH Computer Architecture News , 34(2):130‚Äì141, 2006.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Our analysis (see Figure 2a) shows that the state-of-the-art system still only finishes  ‚âà 58 . 7% of the inferences scheduled on a sensor. Complex Compute on EH-WSNs:  To quantify the scope performing complex compute using EH-WSNs, we took hu- man activity recognition (HAR) as a workload 1 , and per- formed experiments on the MHEALTH data-set [9, 10] (see Section 5 for data-set details) using the DNNs proposed in [ 26 ,  60 ], an energy harvesting friendly DNN hardware accelerator [ 56 ] (to ensure that we are using the state of the art EH-WSN hardware) and recently proposed HAR- specific optimizations for EH systems [ 47 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 179,
    "augmented": true
  },
  {
    "text": "[161] Li Wang, Wei Zhang, and Mei Huang. Dynamic resource allocation for large-scale distributed training of deep learning models. In  Proceedings of the ACM Symposium on Cloud Computing , pages 789‚Äì800.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "3a) affect the amount of computations actually required to provide just enough yet necessary virtual holo- grams. 3a), as well as the size of how the object seems/appears to the user ( ObjSize shown in red color in Fig. Hence, the distance between the user and the objects ( Cam2ObjDist  shown in black color in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "[44] Konstantin Shmelkov, Cordelia Schmid, Karteek Alahari , ‚ÄúIncremental \nlearning of object detectors without catastrophic forgetting,‚Äù in  ICCV , 2017. [45] G. Kordopatis-Zilos, S. Papadopoulos, I. Patras, and I. Kompatsiaris, \n‚ÄúVisil: Fine-grained spatio-temporal video similarity learning,‚Äù in  Pro- ceedings of the IEEE/CVF international conference on computer vision , 2019, pp. 6351‚Äì6360.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Yang, A. Howard, B. Chen, X. Zhang, A. [103] T.-J. Go, M. Sandler, V. Sze, \nand H. Adam, ‚ÄúNetadapt: Platform-aware neural network adaptation for mobile applications,‚Äù in  Proceedings of the European Conference on Computer Vision (ECCV) , 2018, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Note from  Line#3  to  Line#5  in Algo. 1 that, such forward propagation is massively parallel at the depth plane level (across planes) as well as at the pixel level (within one plane). Each depth plane processes the forward-propagation from the hologram plane independently, and each pixel on a particular depth plane goes through the exact processing sequence ( HP2DP in  Line#5 ; more details can be found in [ 4 ,  18 ]).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "[167] Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han. SmoothQuant: Ac- curate and efficient post-training quantization for large language models. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors,  Pro- ceedings of the 40th International Conference on Machine Learning , volume 202 of  Proceedings of Machine Learning Research , pages 38087‚Äì38099.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "IEEE. [59]  Mohammad Rostami, Jeremy Gummeson, Ali Kiaghadi, and Deepak Ganesan. 2018.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "15 √ó  speedup compared to the baseline. Further, a 2 . 42 √ó  speedup is achieved when employing Intra-Holo  (with only 0 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "In order to determine the weight of every class, we use a per-class dictionary that keeps track of the correct predic- tions of every model per class. Hence, classes that did not get the highest votes can still be the Ô¨Ånal output if the models associated with that class has a higher weight, than the combined weights of highest voted class. Unlike commonly used voting policies which assign weights based on overall correct predictions, our policy incor- porates class-wise information to the weights, thus making it more adaptable to different images classes.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": ", m n ]  where  m i  ‚àà{ 0 ,  1 } . In Learning Sparse Masks Dropout, the dropout masks are treated as learnable parameters. The mask values are determined using a sigmoid function to ensure they lie between 0 and 1: m i  =  œÉ ( z i ) where  z i  are learnable parameters and  œÉ ( ¬∑ )  is the sigmoid function.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Our experimental evaluations using six different videos reveal that the proposed schemes are up to  80%  ( 56%  on average) energy efÔ¨Åcient and  2 . 2 √ó  performance efÔ¨Åcient compared to the conventional scheme, which performs full inference, while losing less than  2%  accuracy. Additionally, the experimental analysis indicates that our approach outperforms the state-of-the-art work with respect to accuracy and/or performance/energy savings.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "This research is supported in part by NSF grants #1629915, #1763681, #1931531, #2008398, #2116962, #2122155, #2028929 and #2211018. A CKNOWLEDGMENT \nWe thank the anonymous reviewers for their helpful feedback and suggestions towards improving the paper content. R EFERENCES \n[1]  E. E. Aksoy, S. Baci, and S. Cavdar, ‚ÄúSalsanet: Fast road and vehicle segmentation in lidar point clouds for autonomous driving,‚Äù in  2020 IEEE intelligent vehicles symposium (IV) .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "by scaling up models. Figure 12:  Sensitivity analysis of VMs. However,  Clipper-X  does not scale down models as frequently as  Cocktail , while ensuring similar accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "315‚Äì327. [7] G. Gobieski, B. Lucia, and N. Beckmann, ‚ÄúIntelligence beyond the edge: Inference on intermittent embedded systems,‚Äù in  ASPLOS . ACM, 2019.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "In  2019 IEEE/ACM Fourth International Parallel Data Systems Workshop (PDSW) . IEEE, \n1‚Äì10. [27]  Nilanjan Daw, Umesh Bellur, and Purushottam Kulkarni.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "1b). Therefore, we induce a delay (no-op cycles in Fig. 3) between one sensor Ô¨Ånishing an inference and the next sensor starting the next one, so that each of the sensors get more time to accumulate more energy prior to attempting an inference.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "As shown in Figure 5, one way of utilizing this hot/cold expert separa- tion is to store their respective model parameters at different levels in the memory hierarchy, dictated by the degree of hotness, so as to optimize the response generation pipeline. This dynamic allocation allows for a flexible working set of experts hosted in the main memory, tailored to the specific needs of the batch of requests currently being processed. Specifically, the various experts are typically stored on SSDs or HDDs, and are on-demand loaded into the main memory as required by incoming queries.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Second, its execution latency when running on our edge GPU prototype [ 36 ] is within 4 . First, it provides sufficient accuracy for the AR applications ‚Äì as high as 2 . 06 ¬∞  accuracy for gaze shape/direction estimation across a wide field of view [ 26 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "B. Proper Exemplar Selection \nTo tackle the sampling bias [ 70 ], we adapt a representation learning [ 74 ] framework for designing the proper exemplar selection. The fundamental issue with the previous approach is the inability to select correct numbers of IID data for training.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Typically, these online service ap- plications are user-facing and hence, are administered under strict Service Level Objectives (SLOs) [ 47 ,  48 ] and response latency requirements. Therefore, choosing the underlying resources (virtual machines or containers) from a plethora of public cloud resource offerings [ 31 ,  33 ,  37 ,  41 ,  45 ,  50 ] becomes crucial due to their characteristics (such as provisioning la- tency) that determine the response latency. Serverless com- puting (FaaS) has recently emerged as a first-class platform to deploy latency-critical user facing applications as it miti- gates resource management overheads for developers while simultaneously offering instantaneous scalability.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 173,
    "augmented": false
  },
  {
    "text": "Yoonsung Kim, Changhun Oh, Jinwoo Hwang, Wonung Kim, Seongryong Oh, Yubin Lee, Hardik Sharma, Amir Yazdanbakhsh, and Jongse Park. Dacapo: Accelerating continuous learning in autonomous systems for video analytics. arXiv preprint arXiv:2403.14353 , 2024.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "More importantly, EH can help us build sustainable distributed sensing/monitoring infrastructure at virtually inaccessible places like oil-wells, mines, and even satellite orbits [ 14 ,  49 ]. However, harvested energy is fickle in nature, and typically \narXiv:2408.14379v1  [cs.AR]  26 Aug 2024 \nharvested sources only deliver scant microwatts of power (see Figure 1b for an overview). The sporadic nature of har- vested energy and the lossy nature of EH based storage and charging circuits calls for using the harvested energy di- rectly to perform intermittent compute rather than storing energy for some distant future use.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "By loading these selected potentially useful and relevant experts into the main memory, we propose to optimize the response time and computational efficiency. Figure 5 :  Hot and cold experts. Since this method also reduces the data movements in the system, we can expect a significant reduction in energy consumption.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "gaming, autonomous driving, etc. Moreover, with the recent pandemic, as telepresence is becoming a norm, people are virtually attending meetings, visiting arts, heritage sites and tourist places across the globe, and even living in a virtual universe. All these applications rely on high quality PC capturing, processing and displaying for a more realistic experience.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "A CKNOWLEDGMENTS \nWe would like to offer our thanks to the anonymous reviewers for their detailed feedback, which has greatly helped to improve and reÔ¨Åne this paper. This work was supported in part by Semiconductor Research Corporation (SRC), Cen- ter for Brain-inspired Computing (C-BRIC) and NSF Grant #1822923 (SPX: SOPHIA). We acknowledge that all product names used are for identiÔ¨Åcation purposes only and may be trademarks of their respective companies.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "This may be due to change in user behavior manifesting itself as variable function input patterns. Such errors can lead to sub- optimal container allocation to DAG stages in proportion to the wrongly-calculated function weights. To cope with this, we introduce a parameter called  Commonality , which is defined as the fraction of number of unique paths that the function can be a part of with respect to the total number of unique paths.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Section  V-C will further present quantitative analysis and solution on how \ntoÔ¨Ågureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA. B.Powermodelandlatencymodel PowersupplyisasigniÔ¨ÅcantconstraintforResiSchedule. Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solution m,n,aG  wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,P load ,P comp andP store ,andtheyareperformed insequence.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 196,
    "augmented": true
  },
  {
    "text": "Thus, to further improve the attribute compression efÔ¨Åciency, in the next section, we investigate the inter-frame similarity opportunity. V. I NTER -F RAME  A TTRIBUTE  C OMPRESSION  D ESIGN \nMotivated by the above discussion, in an attempt to further improve the compression efÔ¨Åciency from an inter- frame perspective, in this section we explore the ‚Äùattribute similarity‚Äù that exists across consequent frames in a PC video, and explain the design details of our proposed inter- frame attribute compression scheme. Similar to the intra- frame proposals discussed in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "IEEE, 2012. [159] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "A CKNOWLEDGEMENTS \nThis work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants #1822923 \n(SPX: SOPHIA), #1763681, #1629915, #1629129, #1317560, #1526750, National Natural Science Foundation of China [NSFC Project No. 61872251] and Beijing Advanced Innova- tion Center for Imaging Technology. This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "Continuous Learning at the Edge: Continuous learning, wherein the model continually learns from new samples over time, adapting to seen and previously unseen classes, has \n892 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Quip: 2-bit quantization of large language models with guarantees. IEEE, 2024. [22] Jerry Chee, Yaohui Cai, Volodymyr Kuleshov, and Christopher M De Sa.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "TensorÔ¨Çow-serving: Flexible, high-performance ml serving. arXiv preprint arXiv:1712.06139 , 2017. [61]  Nikunj C Oza.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "There is lesser difference in containers spawned by  Comm Only ,  Conn Only  and  Kraken  for  Media Service  because we have implemented  Kraken  with a cap on the additional con- tainers spawned due to  Commonality  and  Connectivity  when the sum of their values exceeds a threshold. Following this, we observe that the variation in the number of containers in  Social Network  is mainly due to the significant difference in the  Commonality  and  Connectivity of the  Compose Post  function whose batch size is only one. This threshold is exceeded in  Media Service  for the majority of functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Aggregator \nMaster VM \nUser Requests \n‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ \nQueries Cost aware Procurement \nImportance Sampling \nModel-1  Model-2  Model-3  Model-4  Model-n  \noutput \nHeterogeneity \nPrediction Policy \nAutoscaler \nResource Controller \nLoad Balancer \nÔÅ± argmax O 1  (latency) ÔÅ± argmin O 2  (accuracy) \nCPU GPU CPU GPU \nObjectives \n1a \n3 \n4b \n1b \n2 4 \n4a \n4b \n1 \n6 \n6b \n6a \nw1 w2 w3 wk w4 \n3 \n5  Bin-Packing \nWeight Matrix \nL \nN \nFigure 5:  High-level overview of  Cocktail  design. 4 Overall Design of Cocktail \nMotivated by our observations, we design a novel model- serving framework,  Cocktail , that can deliver high-accuracy and low-latency predictions at reduced cost. Figure  5  depicts the high-level design of  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 204,
    "augmented": false
  },
  {
    "text": "To perform convolution, ReRAM x-bars use a similar approach, but with a more complex circuit. The input signal is applied to the x-bar in the same way, but the weights are now applied in a more structured way. Specifically, the weights are arranged in a way that mimics the convolution operation, such that each weight corresponds to a specific location in the input signal.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "These works are broadly categorized into: (i) multiplexing the different instance types (e.g., Spot, On- Demand) [ 12 ,  23 ,  34 ,  41 ,  42 ,  68 ,  79 ], (ii) proactive resource provisioning based on prediction policies [ 34 , 36 , 40 , 41 , 69 , 86 ]. Cocktail  uses similar load prediction models and auto-scales VMs in a distributed fashion with respect to model ensem- bling. Swayam [ 34 ] is relatively similar to our work as it han- \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1043 \nBaseline(BL) NASLarge IRV2 Xception DNet121 NASMob #Models 10 8 7 5 2 BL_Latency 311(ms) 152(ms) 120(ms) 100(ms) 98(ms) E_Latency 152(ms) 120(ms) 103(ms) 89(ms) 44(ms) \nTable 3:  Comparing latency of Ensembling (E_Latency) with single (baseline) models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 286,
    "augmented": false
  },
  {
    "text": "[27]  Nilanjan Daw, Umesh Bellur, and Purushottam Kulkarni. 2020. Xanadu: Mitigating cascading cold starts in serverless function chain deploy- ments.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "2019. MArk: Exploiting Cloud Services for Cost-Effective, SLO-Aware Machine Learning Inference Serving. In  ATC .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "7. Note that, this implementation is purely done in software, without any hardware modiÔ¨Åcation. ‚Ä¢  EA  (SW) : We evaluate the  InterFrame, IntraEye ( EA ) design on a GPU, as shown in the  EA  block in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "30 35 40 45 50 55 60 65 70 75 80 \nBaseline \nWin-1 \nWin-2 \nWin-3 \nWin-4 \nWin-5 \nBaseline \nWin-1 \nWin-2 \nWin-3 \nWin-4 \nWin-5 \nBaseline \nWin-1 \nWin-2 \nWin-3 \nWin-4 \nWin-5 \nVideo Audio 3DPC \nAccuracy (%) \nSM SMR LM \nFig. Restrictions apply. 1: Data drift on different data modalities.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor net- works. In  2021 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pages 1414‚Äì1419. IEEE, 2021.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2303.14177 , 2023. [61] Linley Gwennap. Groq rocks neural networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "It can be seen that for higher accuracies, Cocktail  tries to ensemble more models to reach the accuracy, while for lower accuracy it resorts to using single models. This is because the models which offer higher accuracy are typically dense and hence, smaller ensembles are sufÔ¨Åcient. In Fig- ure  14b , we vary the accuracy under six different constant latency categories.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "This section addresses the Ô¨Årst of these challenges, and Section V discusses our approach to the second. Challenge 1:  Achieving low-power, reconÔ¨Ågurable RCA Although recent works have presented systems [ 4 ], [ 3 ], [ 5 ] and circuits [ 24 ], [ 6 ] for inference-oriented RCAs, they are not directly suitable for adoption in our target scenario because of either their high power consumption or their stringent execution parameters (e.g., computation granularity). In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "To minimize the data communication overhead between the sensor-node and the host device,  Seeker  utilizes coresets to build representative, yet compressed, forms of the data. To cater towards the fickle EH budget, we use the two dif- ferent coreset construction techniques, described in Section 3: a cheaper, less accurate formation (importance sampling) and a more expensive, yet accurate formation (K-means). Trans- mitting coresets rather than raw data greatly improves the \nenergy efficiency of communication to the host, when re- quired, and effectively increases the number of completed inferences, thereby increasing overall accuracy.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "In this case, the current sensor chooses the next best sensor for the job and signals it. To incorporate the ER-r, we induce delays between sending the external signal and starting the inference on the same sensor. The other sensor receives this as an external signal and activates itself to classify the activity.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "[10] M. Riera, J.-M. Arnau, and A. Gonz¬¥alez, ‚ÄúComputation Reuse in DNNs by Exploiting Input Similarity,‚Äù in  Proceedings of the International Symposium on Computer Architecture , 2018, p. 57‚Äì68. [11] L. N. Huynh, Y. Lee, and R. K. Balan, ‚ÄúDeepMon: Mobile GPU- Based Deep Learning Framework for Continuous Vision Applications,‚Äù in  Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services , 2017, p. 82‚Äì95. [12] P. Guo and W. Hu, ‚ÄúPotluck: Cross-application approximate deduplica- tion for computation-intensive mobile applications,‚Äù p. 271‚Äì284, 2018.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 181,
    "augmented": false
  },
  {
    "text": "2020. NASA at Home ‚Äì Virtual Tours and Apps. [34]  NASA.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 20,
    "augmented": true
  },
  {
    "text": ",  Q m  such that, for each subset  Q j ,   P q i ‚ààQ j   E q i   ‚â§ E b , and  m  is minimized. For example, Consider two convolution operations  C 1  and  C 2  with energy requirements  E C 1  and  E C 2 , respectively. This reduces the number of checkpoints and the overhead associated with task switching.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Cost of using  mixed  compared to  util_aware  and  exascale , normalized to a baseline  reactive  scheme for four traces. Percentage of SLO violations for each scheme are shown in the line graph (the corresponding color in the bar-graph is used for all the schemes.) 0 \n200 \n400 \n600 \n0 \n0.6 \n1.2 \n1.8 \n2.4 \n3 \nCost ($) \nModel Type \nexec_time(ms) \nMemory(GB) Cost($) \nFigure 7.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "3) How to Maintain Accuracy? ‚Äì and study the layers in DNN to explore how to identify which parts are important and which are not. ), we now turn to the second question raised above ‚Äì how to maintain accuracy?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "This resilient activation approach can effectively combat  Nonideal scenario 1 . The underlying reason of encountering so many power failures in the case of conventional working mode is that the power threshold of the system to remain alive is set too high. With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Hence, greedily assigning requests enables early scale down of lightly loaded instances. 4.2.2 Autoscaler \nAlong with resource procurement, we need to autoscale instances to satisfy the incoming query load. Though reactive policies (used in Clipper and InFaas) can be employed which take into account metrics like CPU utilization [ 83 ], these policies are slow to react when there is dynamism in request rates.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "1‚Äì28. IEEE Computer Society, 2022, pp. [95] E. Talpes, D. Williams, and D. D. Sarma, ‚ÄúDojo: The microarchitecture \nof tesla‚Äôs exa-scale computer,‚Äù in  2022 IEEE Hot Chips 34 Symposium (HCS) .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Gemino: Practical and robust neural compression for video conferencing. In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pp. 569‚Äì590, 2024.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "2) We leverage temporal continuity of human activity, and persist the last successful classiÔ¨Åcation result of a sensor. The paper makes the following key contributions: 1) We design a scheduling policy that chooses the salient sensor for performing the inference depending on the an- ticipated activity, i.e. the scheduler is  activity aware .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "This can be further asserted from Fig. 9, that only 28%  of the compute energy is consumed w.r.t. As a result, they can also be deployed on top of the PTU-based SoC.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Figure 4 shows a toy example of importance sampling in a 2D data set. The caveat is to have a model trained on the sub-sampled data, which can be done as an one-time step. Although the sub-sampling might lead to poor inference accuracy, in our experiments, with iso-compression ratio, importance sampling based coresets still outperforms classical compression techniques.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Microsoft Azure Serverless Functions. https://azure.microsoft. [10]  2020.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 21,
    "augmented": true
  },
  {
    "text": "a mobile phone), where sufficient resources are available to complete any remaining inference,  if the data can be sent from the sensor . Therefore, to complete all the scheduled computations, and thereby to improve ac- curacy, the system must rely on another device (e.g. Collectively, the aforementioned figures demonstrate that the harvested energy budget is insuf- ficient to perform  all  inferences with acceptable accuracy on currently proposed EH-WSN systems.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "Cambridge University Press, 2011, p. 41‚Äì76. [62]  Point Cloud Library Contributors, ‚ÄúModule kdtree - Point Cloud Library (PCL),‚Äù  ‚Äùhttps://pointclouds.org/documentation/ group kdtree.html‚Äù , 2022. [61]  Pix4D SA, ‚ÄúPIX4Dcatch: Turn your mobile device into a professional 3D scanner using the power of photogrammetry,‚Äù ‚Äùhttps://www.pix4d.com/product/pix4dcatch‚Äù , 2021.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Transient in- stances [ 69 ] are similar to traditional VMs but can be revoked at any time by the cloud provider with an interruption notice. These re- sources are available in different types including CPU/GPU instances, burstables and transient instances. The provisioning latency, instance permanence and packing factor of these resources have a direct impact on the latency and cost of hosting model-serving.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "[74] S.-A. RebufÔ¨Å, A. Kolesnikov, G. Sperl, and C. H. Lampert, ‚Äúicarl: \nIncremental classiÔ¨Åer and representation learning,‚Äù in  Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , 2017, pp. 2001‚Äì2010.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Since both regularizers are convex and smooth, their in- clusion ensures that the overall objective  J ( Œ∏ )  maintains desirable convexity and smoothness properties, facilitating the convergence of stochastic gradient descent (SGD). Additionally, the gradients of the regularizers,  ‚àá ‚Ñ¶ SNR ( Œ∏ )  and  ‚àá ‚Ñ¶ complexity ( Œ∏ ) , are analyt- ically derived and added to the local gradient estimates. During back- propagation, each sensor computes the gradient of the loss function  ‚àá ‚Ñì ( f Œ∏ ( x ) , y )  with respect to  Œ∏  based on locally available samples from  D .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "[75]  P. Thinakaran, J. R. Gunasekaran, B. Sharma, M. T. Kandemir, and C. R. Das. Kube-Knots: Resource Harvesting through Dynamic Container Orchestration in GPU-based Datacenters. In  2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS) , June 2017.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "In  GHTC , 2018. [49]  J Zico Kolter and Marcus A Maloof. Dynamic weighted majority: An ensemble method for drifting concepts.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "[44]  K. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, D. Dzhulgakov, M. Fawzy, B. Jia, Y. Jia, A. Kalro, J. In  ASPLOS , 2015. Law, K. Lee, J. Lu, P. Noordhuis, M. Smelyanskiy, L. Xiong, and X. Wang.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "[31] Reetuparna Das, Onur Mutlu, Thomas Moscibroda, and Chita R Das. Aergia: Exploiting packet latency slack in on-chip networks. ACM SIGARCH computer architecture news , 38(3):106‚Äì116, 2010.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "[2]  L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, ‚ÄúSwitched by input: Power efÔ¨Åcient structure for RRAM-based convolutional neural network,‚Äù in  2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC) , pp. 82‚Äì83, 2018. R EFERENCES \n[1]  C. Xia, J. Zhao, H. Cui, and X. Feng, ‚ÄúCharacterizing DNN models for edge-cloud computing,‚Äù in  2018 IEEE International Symposium on Workload Characterization (IISWC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint arXiv:1701.06538 , 2017. [146] Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Beidi Chen, Percy Liang, Christopher R√©, Ion Stoica, and Ce Zhang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "With increasing the number of CSDs per SSD (or other storage element) does show significant improvement because of increase in parallelism. Integrating more number of CSDs into the standard storage server will significantly increase the cost of the server. However, a typical CSD is  ‚âà 15 √ó  expensive than a standard SSD and  ‚âà 25 √ó  expensive than a classical HDD.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Serverless com- puting (FaaS) has recently emerged as a first-class platform to deploy latency-critical user facing applications as it miti- gates resource management overheads for developers while simultaneously offering instantaneous scalability. However, deploying complex microservice-based applications on FaaS has unique challenges owing to its design limitations. First, due to the stateless nature of FaaS, individual mi- croservices have to be designed as functions and explicitly chained together using tools to compose the entire appli- cation, thus forming a Directed Acyclic Graph (DAG) [ 33 ].",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "For example, the recent iPhone 12/13 Pro features LiDAR camera for PC recording, and similarly, Samsung Galaxy S20+/S20 Ultra contains ToF (Time of Flight) camera for the same. This makes PC-based media recording a common commodity, rather than a sophisticated pipedream. Moreover, applications like Record3D [ 44 ] enable seamless PC media streaming from phone to a wearable, encouraging a perpetually increasing PC content generation and consumption.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "In practice, ReRAM crossbar arrays can have many more cells, and can be used to perform more complex multiplication-addition and convolution operations. The output currents I1 and I2 are the result of the multiplication-addition operation, and are obtained by summing the currents flowing through the ReRAM devices. However, the basic principle remains the same, where the input signals are applied to the rows, the weights are applied to the columns, and the output signals are obtained by summing the currents flowing through the ReRAM devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "[24]  X. Sun, S. Yin, X. Peng, R. Liu, J. Seo, and S. Yu, ‚ÄúXNOR-RRAM: A scalable and parallel resistive synaptic architecture for binary neural networks,‚Äù in  2018 Design, Automation Test in Europe Conference Exhibition (DATE) , pp. 1423‚Äì1428, 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Data locality should benefit from prefetching and caching critical data, which would lower transfer delays and potentially speed up training and inference. Intelligent routing algorithms are proposed to efficiently distribute queries based on real-time performance data and expert availability. Custom composition functions are anticipated to further speed up the integration of diverse expert outputs, thereby improving overall response times.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Us.¬¥as also employs a dynamically morphable systolic array for enabling energy- efÔ¨Åcient computing within the harvested power envelope. Key contributions  of the work include: ‚Ä¢  We propose algorithmic enhancements of  continuous learn- \ning  for mitigating data drift and design a  student-teacher based automated data labelling algorithm , to prepare train- ing exemplars from input data. We use a two-level data annotation mechanism: exemplar identiÔ¨Åcation based on the \n1 Vedic goddess of dawn in Hinduism [ 36 ]; emphasizing the dawn of sustainable continuous learning and signiÔ¨Åcance of solar power in our design.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Note that such maps are not necessarily required to be generated for each frame (typically computed once per two or three frames [ 28 ,  50 ], thus 67 ‚àí 100 ms  in Table 1); hence, we argue that the state-of-the-art InfiniTAM technique, which implements a framework for real-time depth fusion and learning of 3D scenes [ 50 ], is already close to the ideal case. However,  Hologram , which takes depthmap, point-cloud, or light field as its input [ 18 ] 2   to create arbitrary 3D configurations of optical traps useful for capturing, moving and transforming mesoscopic objects freely in the world [ 4 ], takes as long as 341 . 7 ms on an edge GPU 3 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "inferences w/ smooth transition vs. # all inferences vs. # addi. inferences w/ smooth transition \nPiezo Thermal \nLeNet FR HG PV \nFig. 11.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Towards this, for each EoE dataflow over varieties of off-the-shelf hardware platforms including general purpose cores, GPUs, and hardware accel- erators like TPU [50] and SN40L [131] among others, we will investigate the performance, compute and memory utilization, accuracy contribution, and power metrics for every single expert to list the key bot- tleneck kernels. With the target of achieving an efficient execution, we first want to understand the execution behavior. Also, we will identify the most common or frequently accessed experts within and across EoEs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "We implement our designs on an NVIDIA Jetson AGX Xavier edge GPU board. To further improve the compression efÔ¨Åciency, our second scheme, inter-frame compression, considers the temporal similarity among the video frames and reuses the attribute data from the previous frame for the current frame. Experimental results with six videos show that the combined compression schemes provide 34.0 √ó  speedup compared to a state-of-the-art scheme, with minimal impact on quality and compression ratio.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Chest \nNo  Op \nRight  Wrist \nNo  Op \nLeft  Ankle \nNo  Op \nChest \nNo  Op \nNo  Op \nRight  Wrist \nNo  Op No  Op \nLeft  Ankle \nNo  Op \nNo  Op \nChest \nNo  Op \nNo  Op \nNo  Op \nRight  Wrist \nNo  Op No  Op \nNo  Op \nLeft  Ankle \nNo  Op \nNo  Op \nNo  Op Chest \nRight  Wrist Left  Ankle \nRR3 \nRR6 RR9 \nRR12 \nFig. This can be extended further adopting a round-robin activation schedule to both increase harvesting periods per initiated in- ference on each node while increasing the odds that at least some node is attempting an inference at any given time. 3:  Different Ô¨Çavors of (extended) round-robin scheduling and their execution Ô¨Çow.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "Task-1.2: Constructing Morphology of Ensemble of Experts In this task, we propose innovative, flexible, and diverse ways of connecting individual experts to cre- ate diverse LLM expert network morphologies, tailored to various usage scenarios by applying different combinations of expert types, routers, models, and composition functions. It delivers the promise of scaling LLMs through many smaller, specialized, independently trained expert language models. Our LLM expert repository, together with our cross-layer approach among algorithm, system, and architecture, will lay the foundation for the democra- tization of LLM development under friendly compute budgets for a wide range of community groups.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Latency Distribution:  The end-to-end latency distribution for all policies for the  Social Network  application with the Twitter trace is plotted in Figure 12. Consequently, they exhibit up to 0.24% more SLO Violations compared to  Kraken , for this workload mix. In particular,  Arch ,  Fifer and  Kraken  show comparable latencies, with P99 values re- maining well within the SLO of 1000ms.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Vidur: A large-scale simulation framework for llm inference. Proceedings of Machine Learning and Systems , 6:351‚Äì366, 2024. [9] Amey Agrawal, Nitin Kedia, Jayashree Mohan, Ashish Panwar, Nipun Kwatra, Bhargav Gulavani, Ramachandran Ramjee, and Alexey Tumanov.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. Experimental results show that ResiRCA and ResiSchedule achieve average speedups and energy efÔ¨Åciency improvements of 8 √ó  and 14 √ó  respectively compared to a baseline RCA with intermittency-unaware scheduling. Keywords -Energy harvesting, ReRAM crossbar, CNN, Recon- Ô¨Ågurable hardware, Loop tiling, Computation scheduling \nI. I NTRODUCTION \nIn recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [ 1 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 189,
    "augmented": false
  },
  {
    "text": "Shiju Li, Kevin Tang, Jin Lim, Chul-Ho Lee, and Jongryool Kim. Computational storage for an energy-efficient deep neural network training system. In  European Conference on Parallel Processing , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Serving dnns like clockwork: Perfor- mance predictability from the bottom up. In  14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20) , Banff, Alberta, November 2020. USENIX Association.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Figure 2. Comparison of different models under ISO-latency and ISO-accuracy setup. heterogeneous resource availability from the public cloud.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl: Incremental classifier and representation learning. In  Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Note that, both the  Inter-Holo  and the  Intra-Holo  schemes are complementary to each other, when both the eye tracking and pose estimation inputs are available at the same time. Therefore, we also investigate a combined  Inter-Intra-Holo  scheme which com- bines both the schemes to further reduce the amount of hologram computations. We would like to emphasize that the proposed  HoloAR  framework can, in principle, work with any hardware platform.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "1‚Äì6, 2009. [42]  S. A. Dawwd and B. S. Mahmood, ‚ÄúA reconÔ¨Ågurable interconnected Ô¨Ålter for face recognition based on convolution neural network,‚Äù in  2009 4th International Design and Test Workshop (IDT) , pp. [43]  Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, ‚ÄúGradient-based learning applied to document recognition,‚Äù  Proceedings of the IEEE , vol.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "[70]  Steven A Shaya, Neal Matheson, John Anthony Singarayar, Nikiforos Kollias, and Jeffrey Adam Bloom. Intelligent performance-based prod- uct recommendation system, October 5 2010. US Patent 7,809,601.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Acknowledgments \nWe are indebted to our shepherd Manya Ghobadi, the anony- mous reviewers and Anup Sarma for their insightful com- ments to improve the clarity of the presentation. More speciÔ¨Åcally, we (i) develop a novel dynamic model selection, (ii) design a prudent resource management scheme that utilizes weighted autoscaling for efÔ¨Åcient resource allocation, and (iii) lever- age transient VM instances to reduce the deployment costs. Our results from extensive evaluations using both CPU and GPU instances on AWS EC2 cloud platform demonstrate that Cocktail  can reduce deployment cost by 1.4 √ó , while reducing latency by 2 √ó  and satisfying accuracy for 96% of requests, compared to the state-of-the-art model-serving systems.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 183,
    "augmented": true
  },
  {
    "text": "[73]  Mingxing Tan and Quoc V Le. In Proceedings of the 2013 conference on empirical methods in natural language processing , pages 1631‚Äì1642, 2013. EfÔ¨Åcientnet: Rethinking model scaling for convolutional neural networks.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "As discussed in Sec. 2: Similarity study. II, most existing optimizations focus on accelerating the inference processing/computation only and not fully understand the underlying characteristics of the input data, and thus some input-speciÔ¨Åc optimization opportunities could be easily missed.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "[35] Z. Jackson, ‚ÄúFree spoken digit dataset (fsdd),‚Äù https://github. com/Jakobovski/free-spoken-digit-dataset , July 2022, (Accessed on 07/08/2023). [36] C. Jones and J. D. Ryan,  Encyclopedia of hinduism .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Each layer of the neural network encodes progressively finer details of  R t . Algorithm 1 shows the details of the layered neural codec. If  L k ( R t )  represents the  k -th layer‚Äôs encoding of the residual frame, the overall encoding of the frame can be expressed as: \nE t  = \nK X \nk =1 L k ( R t ) \nwhere  K  is the total number of layers, and each  L k  encodes different levels of detail or different regions of the frame, based on the motion information and the prediction error.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 135,
    "augmented": true
  },
  {
    "text": "URL https://arxiv.org/abs/2303.05760 . ITU-T. Advanced video coding for generic audiovisual services. International Telecommunication Union, June 2019a.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "The main objective of this morphable design is to minimize the resource requirements and training/inference time compared to gigantic monolithic models, while maintaining required accuracy needs. Each expert model is a smaller language model with several orders of magnitude fewer parameters versus monolithic LLMs such as GPT-4 [124]. Here, each expert is specialized to solve tasks in specific domains, languages, or skills.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Preparation for Activities:  The two senior PIs have extensive prior experience in supervising female un- dergraduate and graduate students. In the context of this project, we plan to participate in Exploration-U Science Day and organize a booth on Generative AI. The PIs and their students are passionate about the broader outreach and in kindling interest in the K-12 students to pursue STEM careers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Algorithm 2  Periodic Equilibrium-Aware Training Algo- rithm \n1:  Initialization:  Initialize  Œ∏ 0 . Broadcast  Œ∏ 0  to all sensors. Set a diminishing step-size schedule  { Œ± k } k ‚â• 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "[36] Nvidia, ‚ÄúJETSON AGX XAVIER AND THE NEW ERA OF AU- TONOMOUS MACHINES.‚Äù ‚Äùhttp://info.nvidia.com/rs/156-OFN-742/ images/Jetson AGX Xavier New Era Autonomous Machines.pdf‚Äù, 2019. com/watch?v=8lsB-P8nGSM‚Äù, 2019. [35] mooovr, ‚ÄúRollerCoaster at Seoul Grand Park.‚Äù ‚Äùhttps://www.youtube.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "[64] H. Zhang, S. Zhao, A. Pattnaik, M. T. Kandemir, A. Sivasubramaniam, and C. R. Das, ‚ÄúDistilling the Essence of Raw Video to Reduce Memory Usage and Energy at Edge Devices,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2019, pp. 657‚Äì669. [65] D. Zhou, S. Wang, H. Sun, J. Zhou, J. Zhu, Y. Zhao, J. Zhou, S. Zhang, S. Kimura, T. Yoshimura, and S. Goto, ‚Äú14.7 a 4gpixel/s 8/10b h.265/hevc video decoder chip for 8k ultra hd applications,‚Äù in 2016 IEEE International Solid-State Circuits Conference (ISSCC) , 2016, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 208,
    "augmented": false
  },
  {
    "text": "The two transformation matrices are very ‚Äúsimilar‚Äù as they inherit a relationship between them as a function of the small pupillary distance. Motivated by these observations, in the following sections, we explore and address two critical questions:  Can we identify the proximity in the projection computation? , and  Can we leverage this proximity to safely skip some computations to save energy?",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "3b. A single DSP unit includes a multiplier, with the lowest 18 bits of the \n12 \nDSP output representing the first product  d 0  and the highest 18 bits indicating the second product  d 1 , corresponding to  b 0  and  b 1  respectively, as depicted in Fig. 3b.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Considering the cheap commodity use storage devices are often plug and play, they are often vulnerable for data leak, especially if they are deployed in public, like urban mobility setting. The second challenge comes from  privacy and security of sensitive data . Furthermore, it needs to take advantage of the  data similarity between frames  to further minimize the storage footprint, and thereby reducing the form factor and need of frequent disk swapping/ maintenance.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "0 \n10 \n20 \nCost($) \nVM cost \nLambda Cost \ninception          resnet-200 resnext-50 nasnet \n(b)  Cost for ISO-accuracy models. Variation of cost of using VMs vs.  serverless functions  under constant request load. Figure 3.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "[ 56 ] demon- strates the possibility of performing complex DNN inference at the EH-Sensor itself. While an NVP ensures safe check- pointing for a given computation, current edge scenarios may require a device to be simultaneously performing multi- ple functionalities [ 3 ‚Äì 5 ,  25 ] and might be at energy scarcity. As a result, it is difficult to reliably run these complex tasks standalone on the edge device.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "6b and Fig. 6c, we plot the distance pattern between both eyes of a  360 ¬∞ frame using the CubeMap format [41] in Fig. 10  b  .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "This leads to an exponential growth in latency with the increase in the number of storage servers used per application. It is recommended to contain most of the data belonging to the same application in the same storage server to minimize remove disk accesses over network. 16 \n0 \n2 \n4 \n6 \n8 \n10 \n12 \n14 \nKittiVision nuScenes CHIME Cityscapes Waymo \nRelative Latecny \n2 Nodes 3 Nodes 4 Nodes 5 Nodes 6 Nodes \nFigure 10: Change of data movement latency with respect to the number of storage servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "[14]  R. L. de Queiroz and P. A. Chou, ‚ÄúCompression of 3d point clouds using a region-adaptive hierarchical transform,‚Äù  IEEE Transactions on Image Processing , pp. 3947‚Äì3956, 2016. [15]  R. L. de Queiroz and P. A. Chou, ‚ÄúMotion-compensated compression of dynamic voxelized point clouds,‚Äù  IEEE Transactions on Image Processing , vol.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "Although dynamic model selection poli- cies can signiÔ¨Åcantly reduce the resource footprint as shown in Figure  3b , the cost is still 20-30% higher when compared to a single model inference. Most cloud providers offer tran- sient VMs such as Amazon Spot instances [ 69 ], Google Pre- emptible VMs [ 9 ], and Azure Low-priority VMs [ 7 ], that can reduce cloud computing costs by as much as 10 √ó  [ 3 ]. In  Cock- tail , we leverage these transient VMs such as spot instances to drastically reduce the cost of deploying ensembling model framework.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "This process is constant time, requiring only a single subtraction of  q . A Modular Reduction (MR) circuitry based on approximation (Kundi et al., 2020). Our MR unit achieves consumes  ‚âà 82%  less hardware compared to classical implementation.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "BL indicates the baseline models. D. Adaptive Ensemble Learner \nAs discussed earlier in Section III-D, origin uses a lightweight and adaptive ensemble learner that performs weighted majority voting based on a conÔ¨Ådence matrix. techniques combined with efÔ¨Åcient scheduling occasionally gives more accuracy than a larger and unpruned centralized DNN that is more failure-prone and power hungry.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "(2) \nThis ensures that when energy is low, higher dropout rates and lower quantization bit-widths are used to reduce computational load, and vice versa. Similarly, the quantization levels  q j  are adjusted: \nq j  =  q min  + ( q max  ‚àí q min )   E b \nE max . Based on  E b , we adjust the dropout rate  d i  for each layer  i  according to: \nd i  =  d max \n\u0012 1  ‚àí E b \nE max \n\u0013 , (1) \nwhere  d max  is the maximum allowable dropout rate, and  E max  is the maximum energy observed in the traces.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "[14] K. Han, Z. Fang, P. Diefenbaugh, R. Forand, R. R. Iyer, and D. Newell, ‚ÄúUsing Checksum to Reduce Power Consumption of Display Systems for Low-motion Content,‚Äù in  2009 IEEE International Conference on Computer Design , 2009, pp. 47‚Äì53. [15] K. Han, A. W. Min, N. S. Jeganathan, and P. S. Diefenbaugh, ‚ÄúA Hybrid Display Frame Buffer Architecture for Energy EfÔ¨Åcient Display Subsystems,‚Äù in  International Symposium on Low Power Electronics and Design (ISLPED) , 2013, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Expert models are also ‚Äúcomposable‚Äù, so that they can be chosen dynamically according to inputs and then grouped together to solve difficult tasks, which require a combination of skills and knowledge sources. Towards this, we aim to explore a vast design space of model architecture choices and expert model types. A Unified View of EoE Function Choices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "III. M OTIVATION \nA. Reasons for InefÔ¨Åciency \nTo better understand the performance of the PCC pipeline, we characterize the ‚Äúlatency breakdown‚Äù of two state-of- the-art G-PCC techniques, i.e., PCL [ 72 ] and TMC13 [ 56 ], on a typical edge SoC platform (NVIDIA AGX Xavier) in Figs.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "3.2 Resource selection \n3.2.1 Static Load  From  Observation 2 , it is clear that, be- sides model selection, it is crucial to select and configure the right resource to satisfy the application constraints. For applications where the request load is fairly constant over time, only VM-based resources can be procured to serve the requests. To determine the number of requests each VM can handle in parallel, we can conduct offline profiling for different model types.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "This load will have to be predicted in order to make timely container provisioning decisions. These containers have to be provisioned in advance to service fu- ture load to shield the end user from the effects of cold starts \nand thereby meet the SLO. Algorithm 1  Proactive Scaling with weight estimation \n1:  for  Every Monitor_Interval= PW  do 2: Proactive_Weighted_Scaler ( ‚àÄ ùëìùë¢ùëõùëêùë°ùëñùëúùëõùë† ) 3:  procedure  Proactive_Weighted_Scaler( func ) 4: cl  ‚Üê ùê∂ùë¢ùëüùëüùëíùëõùë° _ ùêøùëúùëéùëë ( ùëìùë¢ùëõùëê ) 5: ùëùùëô ùë° + ùëÉùëä ‚Üê Load_Predictor ( ùëêùëô, ùëùùëô ùë° )  a 6: batches  ‚Üê l p ùëôùë° + ùëÉùëä f ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m \nb 7: total_con  ‚Üê Estimate_Containers ( ùëèùëéùë°ùëê‚Ñéùëíùë†, ùëìùë¢ùëõùëê ) 8: reqd_con  ‚Üê ùëöùëéùë• ( ùëöùëñùëõ _ ùëêùëúùëõ,ùë°ùëúùë°ùëéùëô _ ùëêùëúùëõ ) 9: Scale_Containers ( ùëìùë¢ùëõùëê,ùëüùëíùëûùëë _ ùëêùëúùëõ ) 10:  procedure  estimate_containers( load, func ) ‚ä≤ Output:  ùëüùëíùëûùëë _ ùëêùëúùëõ 11: func.prob  ‚Üê Compute_Prob (func) 12: reqd_con  ‚Üê‚åà ùëôùëúùëéùëë ‚àó ùëìùë¢ùëõùëê.ùëùùëüùëúùëè ‚åâ 13: extra  ‚Üê‚åà( Comm ( ùëìùë¢ùëõùëê ) +  Conn ( ùëìùë¢ùëõùëê )) ‚àó ùëüùëíùëûùëë _ ùëêùëúùëõ ‚åâ 14: reqd_con  ‚Üê reqd_con + extra \nKraken  makes use of a Load Predictor  2b  (Algorithm 1  a ) which uses the EWMA model to predict the incoming load at the end of a fixed time window,  ùëÉùëä .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 427,
    "augmented": true
  },
  {
    "text": "[17]  K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúArchitecture exploration for ambient energy harvesting nonvolatile processors,‚Äù in  2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , pp. 526‚Äì537, 2015. [18]  K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, ‚ÄúNEOFog: Nonvolatility-exploiting optimizations for fog computing,‚Äù in  Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 215,
    "augmented": true
  },
  {
    "text": "Data compression becomes even more critical as PC processing is pushed to edge devices with limited compute and power budgets. Unlike existing techniques that use sequential algorithms, our Ô¨Årst design, intra-frame compression, exploits parallelism for boosting the performance of both geometry and attribute compression. In this paper, we propose and evaluate two complementary schemes, intra-frame compression and inter-frame compression, to speed up the PC compression, without losing much quality or compression efÔ¨Åciency.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Now, the HC is quantized and entropy encoded, while the LC is further sent to the next  RAHT and Quantization  round and serves as the attribute of the large voxel/leaf in the upper layer. This procedure is repeated until we reach the root node. In this example, eventually the coeffs vector contains  [ 2 , 0 , 89 ] , which can be further compressed by entropy encoding.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Workload-2 consists of different cost, accuracy and latency requirements for all queries. The  Paragon scheme does not offload to lambdas for relaxed latency queries. We compare the  Paragon model selection scheme against a naive constraints-unaware model selection scheme.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "In  2016 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pages 1393‚Äì1398. IEEE, 2016. [66]  Sara Rosenthal, Noura Farra, and Preslav Nakov.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "8: Evaluation proto- type ‚Äì Nvidia Jetson TX2 GPU board [36] (PMU: Power Management Unit). 6 \nThe meta information of these VR videos are listed in Tab. 360 ¬∞  VR Video Dataset:  We use the published 360¬∞ Head Movements Dataset [3], which includes head movement traces from 59 users viewing seven widely-variant 360¬∞ VR videos.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Why Coresets? The aforementioned requirements moti- vate us to consider  coresets  for forming representations of the original data. Coresets, primarily used in computational geometry [ 7 ], have been recently used [ 36 ,  37 ] for machine learning and sensor networks.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "For every monitoring interval, we keep track of the accuracy obtained from predicting all input images within the interval. The probability of correct prediction is given by \nN ‚àë i = ‚åä N \n2   ‚åã + 1 \n\u0012 N i \n\u0013 a i   ( 1 ‚àí a ) ( N ‚àí i ) \nModel Selection Algorithm:  To minimize  ¬µ C , we design a policy to downscale the number of models, if more than N/2+1 models vote for the same classiÔ¨Åcation result. Algo- rithm  1  describes the overall design of the model selection policy  1a  .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "4,  D¬¥ej`a View  leverages compute lo- cality to bypass computations and provides signiÔ¨Åcant energy savings, with the following two-step optimization strategy: \na  For each frame, if the head orientation remains the same, we take advantage of the  EA  opportunity. b  If exploiting the  EA  opportunity is not possible, we take advantage of the  AE  opportunity, by performing computation for only one eye (and construct the result for the other eye). As shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "The 8 √ó 8 systolic array in each tile executes multiply-accumulate operations in a pipelined and parallel fashion, abiding by the Weight Stationary approach, thereby optimizing the throughput and efÔ¨Åciency of the train- ing operations within this hardware architecture. Power Control Logic:  Power emergency prediction in  Us. ¬¥as is always conservative, and the solar power predictor has a mean accuracy of 92%, limiting false positives and helping the control unit select appropriate tile counts.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "We have also verified that  Kraken (as well as the other schemes) yield similar results (within 2%) when multiple applications are run concurrently. 6.1 Real System Results 6.1.1 Containers Spawned : Figure 8 depicts the function- wise breakdown of the number of containers provisioned across all policies for individual applications. This repre- sents  ùëÅùê∂ ùëë ùë° (Section 3) for all possible depths,  ùëë .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "[63]  Himanshu Sharma, Ahteshamul Haque, and Zainul Abdin Jaffery. 2019. Maximization of wireless sensor network lifetime using solar energy harvesting for smart agriculture monitoring.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "251 \nOur proposed  EA  and  AE  designs focus on these intensive projection computations, and as such are orthogonal to these prior efforts. In our future work, we would like to further explore the beneÔ¨Åts by incorporating them into our design. Head Orientation Prediction for  360 ¬∞  Video Streaming: To optimize both performance and energy, researchers have leveraged the powerful remote rendering engines on cloud to predict the next head orientation for the VR clients [2], [6], [18], [23], [30]‚Äì[32].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "The systolic array structure of the DNN accelerators is well suited for this as we can change the com- pute size, as well as the number of memory channels feeding to those compute units as per the power availability. However, we need to be innovative in terms of designing and placing the compute hierarchy to ensure minimum data movement and re-computations when compute scaling. The hardware design of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "The architectural backbone of neural codecs typically comprises an autoencoder, where the encoder compresses the video into a compact, lower-dimensional representation, and the decoder reconstructs it back into video format. These blocks can be stacked over each other to form layered codecs (like SHVC and SVC). This process benefits significantly from residual learning techniques, where each successive layer in the network aims to correct errors from the previous layers, thereby enhancing the reconstructed video quality incrementally with each additional decoding layer.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "However, these compute-intensive algorithms can be optimized further through dedicated hardware acceleration. Thirdly, the aspect of  sustainability  poses a critical question of deploying such systems, ideally with minimal reliance on the power grid for learning tasks. Designing a learning platform that can adapt to intermittent renewable energy sources (e.g., solar power) and maintain a minimal operational carbon footprint [ 29 ] is paramount.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "[74] S.-A. RebufÔ¨Å, A. Kolesnikov, G. Sperl, and C. H. Lampert, ‚Äúicarl: \nIncremental classiÔ¨Åer and representation learning,‚Äù in  Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , 2017, pp. 2001‚Äì2010.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "2 it is clear that not all the sensors are equally good at classifying various ac- tivities; in fact, this builds the foundation of AASR. Therefore, assigning a static weight to the output of each classiÔ¨Åer will not reÔ¨Çect that its accuracy is activity-dependent. For example, the classiÔ¨Åer used in the left ankle sensor tends to be more accurate overall, but for classifying climbing action, it is not better than the chest sensor.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Au-air: A multi-modal unmanned aerial vehicle dataset for low altitude traffic surveillance, 2020. URL  https://arxiv.org/abs/2001.11737 . M. Bramberger, J. Brunner, B. Rinner, and H. Schwabach.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "From Table 5, it can be seen that  Comm Only  spawns 8% more containers than  Conn Only  for  Social Network . schemes that exclude  Commonality  and  Connectivity  com- ponents from  Kraken , respectively. Application Kraken Comm Only Conn Only Social Network (99.94%, 284) (99.91%, 276) (99.89%, 256) Media Service (99.73%, 572) (99.66%, 561) (99.64%, 552) Hotel Reservation (99.87%, 316) (99.77%, 290) (99.74%, 282) Table 5: Real System: Comparing (SLO Guarantees,#Containers Spawned) against  Comm Only  and  Conn Only .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "In order to determine the weight of every class, we use a per-class dictionary that keeps track of the correct predic- tions of every model per class. Similarly, our model selection pol- icy is also changed at runtime based on correct predictions seen during every interval. We populate the dictionary at runtime to avoid any inherent bias that could result from varying images over time.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "[33] IBM, ‚ÄúData labeling,‚Äù  https://www.ibm.com/cloud/learn/data-labeling , \n(Accessed on 11/21/2022). 630‚Äì645. Springer, 2016, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "In  2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) , pp. 1‚Äì5. IEEE, 2015.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Each request in the trace is associated with an ML inference query, which is randomly picked from our model pool. Figure  4 shows the ratio of over-provisioned VMs compared to a baseline  reactive  autoscaling mechanism. It can be seen that although both  util_aware  and  exascale  can reduce SLO vi- olations (shown in Figure  5 ), they still suffer from 20% to 30% over-provisioned VMs across all four traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Salient Store  also provides a hardware accelerated lattice-based quantum safe encryption mechanism. Salient Store  utilizes the state-of- the-art neural compression which partially uses the inference/ exemplar selection pipeline along with layered neural codecs to compress the video data. It also uses the motion vectors as a latent space to effectively use the inter-frame similarity, thereby further increasing the compression ratio.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "A typical DNN model has two different phases, namely,  training  and inference . Training a DNN, which is the process of extracting and learning the patterns and the features from millions of sample-data, typically takes a few hours to days. The trained models can then be used to perform inferences, i.e., the clas- sification task.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Das and Kandemir have worked together in prior and on-going NSF projects and have a history of successful collaboration, including co-advising underrepresented students. Zhang, Kandemir and Das have recently started to work together. Zhang and Kandemir have recently co-authored a paper in MICRO (2024) and all three PIs have co-authored a paper in NeurIPS (2021).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "4  even with DVFS, commercial off the shelf GPUs could only Ô¨Ånish  <  50% of the scheduled training task. However, hardware is not the only limitation, as even with custom hardware [ 16 ] enabled with the state-of-the-art continuous learning algorithm [ 12 ] could only Ô¨Ånish  ‚âà 75% \n2 NVIDIA provides the list of supported clocks through the API ‚Äú nvidia--smi --q --d SUPPORTED_CLOCKS ‚Äù; We did not creport the results from A100 for this, as it does not offer multiple memory clocks, signiÔ¨Åcantly impacting its DVFS capabilities. T4, thanks to its limited compute capabilities, could not Ô¨Ånish training tasks on time.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "V. \nB. Region-Level Pruning As discussed in Sec. IV-A, while our proposed frame level scheme (coarse granularity) enjoys FI skipping opportunities in some cases, we need to perform FI for the remaining cases, to maintain the accuracy. This leads us to our next question ‚Äì  Can we do better?",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "They will be made available to the broad research community and other interested parties via a GitHub license. The educational materials, characterization and experimental data, and the representative LLM/expert models will also be maintained in machines at Penn State, and will be shared with the user community via a website dedicated to the project (as discussed earlier). 2.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "abs/1612.08350, 2016. [6] T. El-Ganainy and M. Hefeeda, ‚ÄúStreaming Virtual Reality Content,‚Äù CoRR , vol. [Online].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "In  13th USENIX Symposium on Operating Systems Design and Imple- mentation (OSDI 18) , pages 611‚Äì626, Carlsbad, CA, October 2018. USENIX Association. [53]  Romain Lerallut, Diane Gasselin, and Nicolas Le Roux.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "HC1 on the other hand is a garden video, with people walking around, riding \nbike, etc. These two videos are much more active (dynamic) than V1/V2, meaning that they contain less reuse opportunities than V1/V2. Thus, compared to V1 and V2 whose latencies can be decreased by  62%  and  55%  respectively with FI+SI as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Further, in this paper, we have gone beyond foveated rendering ( Inter-Holo ), by proposing an optimiza- tion/approximation called  Intra-Holo , that complements the former in boosting performance/energy efficiency. This enhancement is ideally suited for holographic processing at the edge, without re- quiring additional hardware, cloud assistance, or machine learning framework. Holographic Displays on AR:  Another large body of prior works focus on optimizing the holographic displays for the next- generation AR headsets [ 6 ,  17 ,  23 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "A cycle would imply an infinite sequence of im- provements or a return to a previously visited state without improvement, which cannot occur since profitable devia- tions strictly increase  Œ¶( a ( t )) . Under the assumptions that ‚àÜ A i ( t )  is non-decreasing and that sensors have consistent energy and accuracy estimates, no cyclical behavior can persist. The presence of the discount factor  Œ≤  further stabilizes the process.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "In  Pro- ceedings of the 46th International Symposium on Computer Architecture , ISCA ‚Äô19, page 210‚Äì223, New York, NY, USA, 2019. Opportunistic computing in gpu architectures. Association for Computing Machinery.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Users submit requests in the form of invocation triggers to applications  1  hosted on a Serverless platform. In  Kraken , containers are provisioned in advance by the Proactive Weighted Scaler (PWS)  2  to serve these incoming requests by avoiding cold starts. To achieve this, the PWS  2  first fetches relevant system metrics (using a monitoring tool  3  and orchestrator logs).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Since the simulation of generative AI (especially training monolithic LLMs) can take extremely long running times and may not even be feasible in some cases, we will also build, as the third component of our evaluation framework, using data from our actual machine experiments and simulations, ‚Äúanalytical models‚Äù that provide fast evaluation of EoE systems and LLMs with reasonable accuracy, such as [40, 169]. Our approach will em- body the best of both the worlds ‚Äì taking the deeper system level insights from real hardware/simulators and extending it to large scale by analytically modeling their behavior as a complex system. Additionally, our custom chiplet hardware will be simulated using the publicly-available RapidChiplet [68] simulator.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 166,
    "augmented": true
  },
  {
    "text": "Our proposal is fundamentally different from prior optimizations targeting various architectures or execution environments, such as customized hardware accelerators [ 35 ], cloud assistance [ 16 ,  27 ,  67 ], or neural network training/inferencing [ 33 ,  54 ]. Note that, each of these prior efforts has its own limitations, e.g., expensive in-house implementation and fixed functionality without proper power gat- ing in accelerators [ 35 ]; requiring reliable network connections and expensive round-trip latency in cloud offloading [ 16 ,  27 ,  67 ]; and re-training of a new model for each application scenario and poten- tially for each user in neural networks [ 33 ,  54 ]. Thus, our proposal does not rely on any assistance from hardware accelerators, cloud platforms, or neural networks.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 187,
    "augmented": false
  },
  {
    "text": "Figure 14 plots the con- tainers spawned versus the SLO guarantees for each appli- cation for all traces. The simulator results closely correlate to those of the real system. Kraken  is seen to reduce con- tainer overprovisioning when applications have numerous possible workflows and enough slack per function to exploit.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "As a result, the 120s interval has the highest number of models. This is because, increasing the interval leads to lower number of scale down operations, thus resulting in a bigger ensemble. USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1051 \n10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n82.25 \n82.50 \n82.75 \nAccuracy \n(a)  Queries under Constraint-1.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Collaboration Plan \nProject Team \nThe proposed project spans design and analysis of LLM and expert models, characterization and evaluation of such models, development of compiler and runtime system support for efficient LLM/expert training and inference as well as chiplet selection for LLM/expert execution. The project will be managed by the three PIs from Penn State. The specific responsibilities of the PIs and their complementary expertise are explained below: Chitaranjan Das (PI):  Das is the PI of the project and will be responsible for the overall coordination and progress as planned in the project schedule.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "5 Implementation and Evaluation We have implemented a prototype of  Kraken  using open- source tools for evaluation with synthetic and real-world traces. Thus, the RS  7  , in combination with the PWS  2  and re- quest batching  5  , helps  Kraken  remain SLO compliant while using minimum resources. The details are described below.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Thus, if sensor  s i  participates with SNR SNR i ( t ) , its total energy expenditure is \ne i ( t ) =  e cap ( SNR i ( t )) +  e inf  +  e comm \n3 \n165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 \nThe improvement in global inference accuracy due to sen- sor  s i  is denoted by  ‚àÜ A i ( t ) . In addition to capture costs, partici- pation incurs inference computation cost  e inf  and communi- cation cost  e comm . This quantity depends on SNR i ( t )  and on the data contributed by other participating sensors, as their combined perspectives shape the overall result.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 279,
    "augmented": true
  },
  {
    "text": "Us. In contrast, cloud-based solutions ex- hibited poor sustainability, relying on high-power-consuming GP-GPUs, and edge servers without power availability strug- gled to perform any compute. It completed more training tasks while consuming less power and minimizing wastage.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "For example, a per- formance counter exposing data movement traffic in NoC can be used by runtime support to shuffle the expert to chiplet mappings. Thus, by investigating all the HW-SW co-optimizer pairs, we envision boosting the overall performance. In addition, the plug-and-play nature of chiplet provides better ‚Äúfault isolation‚Äù, as only the faulty chiplet can be changed as opposed to throwing away an entire chip.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "‚Ä¢  The architecture-centric works [ 3 ], [ 4 ], [ 5 ] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption. Furthermore, the hierarchy they adopt with multiple ReRAMs targets primarily high throughput, leading to high power consumption on the whole RCA. For example, the total 168  Tiles  and one  IMA  element of the ISAAC architecture [ 3 ] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "2019. Comparing Energy Efficiency of CPU, GPU and FPGA Implementations for Vision Kernels. In  15th IEEE International Conference on Embedded Software and Systems .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "T p  is set to 10 minutes because it is sufÔ¨Åcient time to capture the variations in long-term future. Using the global arrival rate from all windows, the model predicts ( L p ) for  T p  time units from  T . All these parameters are tunable based on the system needs.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "VI. R ELATED  W ORK \nOptimizations in Planar Video Streaming:  Pixel-similarity based optimizations [38], [57] have been exploited to improve \nperformance in 2D rendering. For example, ATW [38] is a post-render technique, which sits between rendering (our focus) and display.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "In fact, in our octree, the  P 0  node now contains geometry information of  [ ‚àí 0 . 5 , the octree constructed based on the Morton codes is slightly different from the one generated by the sequential algorithm (which is lossless). 43 , 0 , 0 ]  (-0.43=-1+1/7 √ó 4), which is slightly different from the original  [ 0 , 0 , 0 ] , whereas the other two points,  P 1  and  P 2 , are exactly same as the original ones.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "storage stack archi- tects often abstract the computational processes, neglecting considerations such as data movement cost, compute cost, and power requirements. Conversely, architects of storage drives, including CSDs, tend to overlook the broader application requirements, such as data prioritization, potential offloading of computational tasks to storage, and application-specific data compression and encryption strategies. Our research aims to  bridge  this gap, focusing specifically on the exigencies of continuous learning applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "¬¥as . 5: Overall architecture with the components and the power failure handle sequence of  Us. stationary; 2. input stationary; and 3. weight stationary [ 79 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "Introduction \nThe rapid proliferation of the Internet of Things (IoT) has sparked a tremendous growth in the scale and diversity of sensor deployments, from smart homes to expansive in- dustrial and environmental monitoring systems. As these networks continue to expand, sustaining continuous opera- tion in the face of finite power sources becomes a paramount concern. To address this, energy harvesting (EH) technolo- gies have emerged as a viable solution, enabling sensors to convert ambient energy (e.g., solar, thermal, or vibration) into electrical power.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "For example, if  ùëÉùêø ùë° is estimated to be 25 requests, then from Figure 5, we obtain the number of containers needed for functions at depth,  ùëë =  1, by multiplying 25 with  ùëÉ 1  (which is  ùëá 1 ¬∑ P 0 ). Consequently, the total number of containers re- quired for each function in the application can be computed \n157 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. Notation Meaning T Transition Matrix P ùëë Probability Vector for functions at depth,  d n # functions in application or # states in model f  ùëñ ,  f ùëó functions along row,  i  or column,  j  in  T t  ùëóùëñ Transition probability from  f  ùëó ùë°ùëú f ùëñ W ùëù Probability calculation time window t Request arrival time d # time steps for which transitions are done PL ùë° Scalar that represents the anticipated # requests at time,  t NC ùëë ùë° # containers needed for functions at depth  d , at time  t Table 3: Notations used in Equations.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 263,
    "augmented": true
  },
  {
    "text": "We want to emphasize however that, such static (pre-deÔ¨Åned) window-size works well only when there are few movements in the videos. On the other hand, when the video has more dynamic behavior, this static skipping jeopardizes the quality of applications which demand high accuracy. To give an example, we selected a segment of frames (i.e.,  Frame#6750  to  Frame#6850 ) from V1 [33], in which the objects move more aggressively than other segments.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "3a, one of the most common cases in videos is that the object(s) (which have been identiÔ¨Åed in previous frames, i.e., Frame-1) move around in the current frame (i.e., Frame-2 , Frame-3). 3) Three Scenarios of Frame-Level Reuse: i Moving Object(s) : As shown in Fig. We next illustrate 3 common scenarios of leveraging the MVs to capture the reuse opportunities in a DNN-based object detection application.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "Career Counseling/Advising \nThe PIs will provide ‚Äì on a regular basis ‚Äì career counseling and advising to the PhD students in the project as part of the mentorship. After the initial meetings with the PhD students, the students will be asked to complete a worksheet to ensure alignment on objectives. Regular annual review meetings will be conducted to assess progress and make necessary adjustments.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "AMD. Vitis unified software platform. https://www.xilinx.com/products/design-tools/ vitis/vitis-platform.html , a.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Also, we estimate the right configuration of lambda functions by conduction offline experiments. By offline profiling, we estimate the number of model instances each VM can execute in par- allel without violating the model latency. The types of instance used in our evaluation include all the c5 and m5 instances for EC2.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Trans- mitting coresets rather than raw data greatly improves the \nenergy efficiency of communication to the host, when re- quired, and effectively increases the number of completed inferences, thereby increasing overall accuracy. To cater towards the fickle EH budget, we use the two dif- ferent coreset construction techniques, described in Section 3: a cheaper, less accurate formation (importance sampling) and a more expensive, yet accurate formation (K-means). To minimize the data communication overhead between the sensor-node and the host device,  Seeker  utilizes coresets to build representative, yet compressed, forms of the data.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "[22]  Francois Chollet. Deep Learning mit Python und Keras: Das Praxis- Handbuch vom Entwickler der Keras-Bibliothek . MITP-Verlags GmbH & Co. KG, 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "A. We Ô¨Årst describe the design conÔ¨Ågurations, experi- mental platform, datasets, and measurement tools used in this work, and then analyze the collected results. Design conÔ¨Ågurations \nBaseline:  We evaluate the baseline video object detection on an edge CPU 1 , where every frame is fully inferenced.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "[19]  Michael Alan Chang, Bredan Tschaen, Theophilus Benson, and Lau- rent Vanbever. Springer, 2005. Chaos monkey: Increasing sdn reliability through systematic network destruction.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Accessed: 2023-10-20. Making ai less ‚Äúthirsty‚Äù: Uncovering and addressing the secret water footprint of ai models. arXiv preprint arXiv:2304.03271 , April 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "2020. Real-Time Spatio-Temporal LiDAR Point Cloud Compression. 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)  (2020), 10766‚Äì10773.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "On top of the ILLIXR codebase, we implemented three new components ‚Äì eye tracking, pose estimation, and hologram processing. Further, we mapped these AR software components to an edge GPU prototype [ 36 ], from which the power breakdown across different components such as SoC, memory, CPU, and GPU are measured through the on-board Texas Instruments INA 3221 voltage monitor IC hard- ware, and the performance of execution status is sampled by the Nvidia NVPROF [ 37 ] profiling tool, which enables the collection of a timeline of CUDA-related activities on both the CPU and GPU, including kernel execution, memory transfer, CUDA API calls and events/metrics for CUDA kernels. 5 EVALUATION We evaluate our proposed  HoloAR  design by comparing the execu- tion latency and total energy consumption with four different AR hologram setups.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 204,
    "augmented": false
  },
  {
    "text": "Each sensor has a data buffer that collects the data points for classification (implemented using a 60  √ó 3 FIFO structure of 4Byte cells to store the floating point data. The √ó 3 caters towards the multiple channels of the sensor. The moving window is designed using a counter to shift the streaming data.)",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "In the remainder of this paper, this execution strategy is referred to as  Naive1 . We assume that  Naive1  is also designed with the proposed lightweight circuits. In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "[25] Z. Song, B. Fu, F. Wu, Z. Jiang, L. Jiang, N. Jing, and X. Liang, ‚ÄúDRQ: Dynamic Region-Based Quantization for Deep Neural Network Accel- eration,‚Äù in  Proceedings of the International Symposium on Computer Architecture , 2020, p. 1010‚Äì1021. [26] H. Sharma, J.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "More speciÔ¨Åcally, the  < accuracy-loss, energy- savings >  pairs are plotted in Fig. We used Pytorch [46] to proÔ¨Åle the accuracy behavior of two videos picked from VIRAT [33] dataset, and show that our proposal can adaptively support such alternate design choices. 10.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "The latency numbers for the baseline models and the corresponding ensemble models along with the size of the ensemble are shown in Table  3 . In majority voting, every model votes for a prediction for each input, and the Ô¨Ånal output prediction is the one that receives more than half of the votes. Figure  3a , shows the accuracy comparison of the baseline (single) and static ensemble (ex- plained in Section  3 ) compared to the full-ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Iterating this process for  ùëë time steps would yield the proba- bilities of functions at a depth of  ùëë from the start function, given by  ùëÉ ùëë =  ùëá ùëë ¬∑  ùëÉ 0 . Thus, we can compute the probability of any function in the DAG by varying the depth,  ùëë , using this equation. In order to apply this to proactive container allocation decisions, we can adopt the following procedure.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "First, it maintains dedicated instance pools to serve indi- vidual models which simpliÔ¨Åes the management and load balancing overheads for every model. The results from the workers are  ensembled  using an weighted majority voting aggregator  3  to agree upon a correct prediction. To efÔ¨Åciently address the resource management and scalability challenges,  Cocktail  applies multiple strategies.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Our proposal is fundamentally different from prior optimizations targeting various architectures or execution environments, such as customized hardware accelerators [ 35 ], cloud assistance [ 16 ,  27 ,  67 ], or neural network training/inferencing [ 33 ,  54 ]. Thus, our proposal does not rely on any assistance from hardware accelerators, cloud platforms, or neural networks. Note that, each of these prior efforts has its own limitations, e.g., expensive in-house implementation and fixed functionality without proper power gat- ing in accelerators [ 35 ]; requiring reliable network connections and expensive round-trip latency in cloud offloading [ 16 ,  27 ,  67 ]; and re-training of a new model for each application scenario and poten- tially for each user in neural networks [ 33 ,  54 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 187,
    "augmented": true
  },
  {
    "text": "We compare the  Paragon model selection scheme against a naive constraints-unaware model selection scheme. Results:  Figure  8  plots the SLO and cost for workload-1 across Berkley and WITS trace. It can be seen that mixed scheme has similar cost to reactive but it reduces SLO vi- olations by up to 60%.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Both  Cocktail  and  Clipper  deliver the same overall accuracy (96%, 94.5%, 93.5%, and 92%)). Figure  16b  plots the latency reduction and accuracy gain, compared to  InFaaS  (baseline). While being able to reduce 50% of the models used in the ensemble,  Cocktail  also re- duces latency by up to 50% and improves accuracy by up to 1.3%.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "ACM Meas. Quantifying data locality in dynamic parallelism in gpus. Proc.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "We would like to emphasize that the proposed  HoloAR  framework can, in principle, work with any hardware platform. As discussed later in Sec. 5, in this paper, we evaluate the performance and energy benefits of  HoloAR  by using an embedded GPU prototype for the edge AR headsets [ 36 ], and leave the hardware-software co- design based on FPGA-based acceleration for future work.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Since the model participation for ensembling can vary based on the class of input images being classiÔ¨Åed, there is a scope to develop a dy- namic model selection policy that can leverage this class-wise variability to intelligently determine the number of models required for a given input. Key Takeaway:  Full ensemble model-selection is an overkill, while static-ensemble leads to accuracy loss. This calls for a dynamic model selection policy which can accurately de- termine the number of models required, contingent upon the accuracy and scalability of the model selection policy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the ACM SIGMETRICS joint international conference on Measurement and modeling of computer systems , pages 13‚Äì24, 2011. [145] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "At the same time, the quality further drops by  2 . 9 dB. Still, we argue that, even with the Intra-Inter-V2 option (see one demo in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "This enables flexible, diverse ways of expert adaptation and localized training to keep pace with rapidly changing knowledge and user needs, while also facilitating cross-layer optimization for system and architecture design. Systems for LLMs:  Since training giant monolithic models entail huge compute infrastructure, prior works have explored developing parallelization techniques like model parallelism [90, 149], data paral- lelism [118,128], and hybrid parallelism [135]. Distributed training frameworks like Horovod [141], Mega- tronLM [149], and DeepSpeed [65] ensure optimized data communication for distributed memory usage along with dynamic batching so that scaling overheads are minimized and resources are maximally uti- lized.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, our approach combines inter-frame similarities, motion vectors (MVs), and the concept of regions of interest, to make online video analytics/inferences inherently faster, along with the runtime support for improving the video streaming pipeline. Our main  contributions  in this work include the following: ‚Ä¢  First, we study the similarities between successive frames in videos at various levels. We identify  online-pruning opportunities for inferences, which can also be exploited at  frame-level ,  region-level , and  pixel-level.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University. The authors also greatly appreciate Dr. Yongpan Liu, Dr. Kaisheng Ma, Dr. Xulong Tang and Mr. Challapalle Nagadastagiri Reddy‚Äôs useful discussion. R EFERENCES \n[1]  C. Xia, J. Zhao, H. Cui, and X. Feng, ‚ÄúCharacterizing DNN models for edge-cloud computing,‚Äù in  2018 IEEE International Symposium on Workload Characterization (IISWC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "3  a  for compu- tation of the  Transformation Matrix , is used for projecting the 360 ¬∞ frame pixels onto the  2 D  FoV plane in the subsequent stages. This matrix is calculated by applying Ô¨Åve different transforms ‚Äì  T 1 ,  T 2 ,  T 3 ,  T 4 , and  T 5  ‚Äì in a serial fashion. ‚Ä¢  T 1  serves as a  rigid body transformation  matrix which ap- plies 3D rotation ( Y aw, Pitch, Roll ) and translation so that, the objects do not get distorted.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "The energy availability constraint over time is expressed as (subject to energy and task constraints): P \ni : s i ‚â§ t<f i   E i  ‚â§ E b ( t )  The objective is to maximize the total weighted priority of scheduled tasks: \nmax { x i ,s i } \nN X \ni =1 \n\u0000 p i  ‚àí Œ±E i  ‚àí Œ≤ ( f i  ‚àí D i ) + \u0001 x i . (5) \nScheduling Performance Assurance:  Our scheduling heuristic,  Energy-Aware Priority Scheduling , while sub-optimal in the theoretical sense, is designed to perform near-optimally in practice for real- time systems. We ensure its performance by: 1.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 184,
    "augmented": false
  },
  {
    "text": "Association for Computing Machinery. [116] Chrysostomos A Nicopoulos, Dongkook Park, Jongman Kim, Mazin S Yousif, and Chita R Das. Vichar: A dynamic virtual channel regulator for network-on-chip routers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "3947‚Äì3956, 2016. [14]  R. L. de Queiroz and P. A. Chou, ‚ÄúCompression of 3d point clouds using a region-adaptive hierarchical transform,‚Äù  IEEE Transactions on Image Processing , pp. [15]  R. L. de Queiroz and P. A. Chou, ‚ÄúMotion-compensated compression of dynamic voxelized point clouds,‚Äù  IEEE Transactions on Image Processing , vol.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode. In this example, the full size of ReRAM (or loop nest) is M  √ó  N  =  A  √ó  B  √ó  C  √ó  N , and the tile size of ReRAM (or loop nest) is  m  √ó  n  = 1  √ó  tb  √ó  C  √ó  tn . Since each single ReRAM can be activated at a Ô¨Åner granularity with tiling, the parallelism can be achieved under a Ô¨Çexible range of power consumption to match a variable power supply.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "Typically denser models are designed with more parameters (ex. classes of images. NASLarge ) to classify complex \n1042    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nModel (Acronym) Params (10k) \nTop-1 Accuracy(%) \nLatency (ms) P f \nMobileNetV1 (MNet) 4,253 70.40 43.45 10 MobileNetV2 (MNetV2) 4,253 71.30 41.5 10 NASNetMobile (NASMob) 5,326 74.40 78.18 3 DenseNet121 (DNet121) 8,062 75.00 102.35 3 DenseNet201 (DNet201) 20,242 77.30 152.21 2 Xception (Xcep) 22,910 79.00 119.2 4 Inception V3 (Incep) 23,851 77.90 89 5 ResNet50-V2 (RNet50) 25,613 76.00 89.5 6 Resnet50 (RNet50) 25,636 74.90 98.22 5 IncepResnetV2 (IRV2) 55,873 80.30 151.96 1 NasNetLarge (NasLarge) 343,000 82.00 311 1 \nTable 1:  Collection of pretrained models used for image classiÔ¨Åcation.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 317,
    "augmented": true
  },
  {
    "text": "Over multiple iterations of such asynchronous scheduling, the kernel queue for each tile will be of different size creating a load imbalance; how to tackle this? 3. How do we know when to stop executing?",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "0 500 1000 1500 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers \nNGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network. The rest of the containers are a result of  reactive scaling  that follows from MLP mispredictions, which accounts for 34% of the total number of containers spawned. 161 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Since both regularizers are convex and smooth, their in- clusion ensures that the overall objective  J ( Œ∏ )  maintains desirable convexity and smoothness properties, facilitating the convergence of stochastic gradient descent (SGD). Partici- pation during training follows the same equilibrium model: sensors decide whether to compute and send gradients based on their current energy states, predicted future utilities, and the established reward structure. Periodic Equilibrium-Aware Training: Model updates are performed periodically at an aggregator node that col- lects gradient estimates from participating sensors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "2020 IEEE International Conference on Robotics and Automation (ICRA)  (2020), 4666‚Äì4672. [14]  Giorgia Lombardo. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "Towards this, Han et al. proposed the viewpoint-dependent PCC scheme (termed as ‚ÄúViVo‚Äù) which only sends the 3D tiles within user‚Äôs Ô¨Åeld of view [ 24 ], thereby reducing the data volume. Such optimizations [ 37 ], [ 59 ], [ 68 ] are extremely important for applications like virtual tourism, video streaming etc.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "In terms of cost, utilization, power, and area require- ments, we expect several inefficiencies with existing off-the-shelf hardware like CPUs and GPUs when executing our models for training, inference, and re-training purposes, thus exacerbating the gap towards democratization. Towards this, in this thrust, we propose to explore a novel ‚Äúchiplet-based‚Äù custom hard- ware platform. Chiplet-based designs have shown great promise for integrating a variety of modular chips, both homogeneous and heterogeneous, on a silicon interposer [72,152] and is a great fit for our envisioned modular and fault-tolerant design.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "IEEE, 2011. [185] Yuanrui Zhang, Mahmut Kandemir, and Taylan Yemliha. Studying inter-core data reuse in multi- cores.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.‚Äù \nThe above statement can be used verbatim in such cases, but we encourage authors to think about whether there is content which does warrant further discussion, as this statement will be apparent if the paper is later flagged for ethics review. References \nA. Guidelines for Hyperparameter Selection and Bounds on Reward Parameters \nThe parameters  Œ≥ ,  Œ¥,  and  Œ∑  govern the reward structure of the proposed framework, influencing whether sensors participate consistently, over-participate and waste energy, or abstain altogether.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "2 F super-capacitors connected in parallel to a voltage regulator \ncircuit. 5 V ,  2 . To properly model the energy harvesting, losses during conversion, and leakage, we built a rectiÔ¨Åcation circuit with 4  √ó  5 .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "(2019). [26]  Joohwan Kim, Michael Stengel, Alexander Majercik, Shalini De Mello, David Dunn, Samuli Laine, Morgan McGuire, and David Luebke. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Daniele Micciancio and Oded Regev. Lattice-based cryptography. In  Post-quantum cryptography , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "We dis- cuss how the proposed hardware techniques can be adapted by many of the current DNN training accelerators to add similar dynamism in sustainability-sensitive environments. ‚Ä¢  Finally, we evaluate Us.¬¥as in depth on a  real-world trafÔ¨Åc \ndata set  [ 97 ] and perform sensitivity studies on other classes (audio, IMU) of data. ‚Ä¢  We design a  morphable hardware accelerator  that efÔ¨Å- \nciently maps training tasks, is suitable for intermittent computing, and can adapt its capabilities to reduce power emergencies without devolving to grid operation.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "[77] M. S. rutgers.edu, ‚ÄúSupport for trafÔ¨Åc cameras increases if used as a tool to limit interactions with police,‚Äù https://www.rutgers.edu/news/support-trafÔ¨Åc-cameras-increases-if- used-tool-limit-interactions-police , (Accessed on 04/28/2023). [78] J. Salamon, C. Jacoby, and J. P. Bello, ‚ÄúA dataset and taxonomy \nfor urban sound research,‚Äù in  22nd ACM International Conference on Multimedia (ACM-MM‚Äô14) , Orlando, FL, USA, Nov. 2014, pp. 1041‚Äì 1044.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "Task-3.3: Handling Unforeseen Cases using Reconfiguration Besides having dedicated hardware for experts, there are three possible challenges which require adaption in hardware: the chiplets may incur failures, the work contained in inference is input dependent, and re- \ntraining is needed as part of continuous learning. We plan to have ‚Äúreconfigurable chiplets‚Äù, which can be customized during runtime to become a specific compute engine or memory block. For example, during inference, the system can decide to map an expert onto a chip but the suitable hardware may not be directly present.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "These frames are then buffered in a memory buffer, waiting for the next stage ‚Äì NN Inference. NN Inference:  In this stage, the neural network (NN) pipeline takes the decoded video data to perform the inference tasks with the available compute engines (e.g., CPU, GPU, NPU, or any dedicated ASICs). Numerous prior studies (e.g., see [21]‚Äì [23] and the references therein) have clearly shown that, regardless of the type of the compute hardware employed, the NN inferences are both compute and memory intensive.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "1‚Äì14. [69] J. F. Peters, M. Baumann, B. Zimmermann, J. Braun, and M. Weil, ‚ÄúThe \nenvironmental impact of li-ion batteries and the role of key parameters‚Äì a review,‚Äù  Renewable and Sustainable Energy Reviews , vol. 67, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Restrictions apply. compression ratio) takes  121 ms  ( 43 ms  for geometry and 78 ms  for attribute compression), which represents about 35 √ó  speedup w.r.t. CWIPC.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "In  Advances in Neural Information Processing Systems (NeurIPS) , 2020. [21]  Kristina Chodorow. MongoDB: the deÔ¨Ånitive guide: powerful and scalable data storage . \"",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "To collect performance metrics such as the streaming multiprocessor (SM) utilization, memory traffic, and CUDA kernel execution latency, we utilized the open-source Nvidia NVPROF tool [37] on the GPU platform. We use the published short object-centric Objectron [ 1 ] video dataset, which is accompanied by AR session metadata such as camera poses, as well as the object annotations such as position, orientation and dimension for nine categories of object videos 4 . The salient characteristics these videos are given in Tab.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "In contrast, both Cocktail  and  Clipper  can reach the accuracy at lower latency due to ensembling, thus minimizing SLO violations to 1%. Also, the tail latency is higher for Twitter trace (Figure  7c , 7d ) owing to its bursty nature. Note that the tail latency of  Clipper  is still higher than  Cocktail  because  Clipper ensembles more models than  Cocktail , thereby resulting in straggler tasks in the VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "However, to alleviate the shortcomings of less accurate predictions at the edge, some computations are routed to the cloud, expecting a better result at the expense of a higher latency. Therefore, it is essential to know if and when to route the compute to the cloud to balance accuracy and latency. We solve this issue by a adopting a thresholding mechanism based on model confidence, and accordingly decide to consult the cloud for better accuracy on less-confident local predictions.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "By characterizing production appli- cation traces from Azure, Shahrad et.al [ 42 ] have elucidated that 46% of applications have 2-10 functions. Excluding the most general (and rare) cases where applications can have loops/cycles within a function chain [ 27 ], applications can be modeled as a  Directed Acyclic Graph  (DAG) where each ver- tex/stage is a function [ 26 ] Henceforth, we will use the terms ‚Äòfunction‚Äô and ‚Äòstage‚Äô interchangeably. Function chains are supported in commercial serverless platforms such as AWS Step Functions [4, 23], IBM Cloud Functions [8], and Azure Durable functions [ 6 ].",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "Mixture of lora experts. arXiv preprint arXiv:2404.13628 , 2024. [167] Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "In case of a complete power failure, the compute in Ô¨Çight are rejected and, once the system starts working, the work queues get invalidated and the host starts the compute again from the last checkpoint. Along with that, the most common intermittent software libraries and software designs [ 26 ], [ 52 ] (and most DNN training libraries like PyTorch, TensorFlow) also offer periodic checkpoints. Note that the power-up sequence for a tile runs in the exact opposite order of the  powerdown  sequence (a tile becomes computationally active 512 cycles after it gets the power up signal).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "The  t i + 1  tiles fetch the next  t i + 1  kernels from the GKDQ and the process continues. The GKDQ always points to the next available kernel location. This conservative compute and power estimation ensures that none of the kernel computes (the lowest decomposed level of compute unit for the hardware) ever fails and hence there is no need for any partial data movement.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "The GAN modeled the lost signals with a very high correlation ( ‚â• 0 . The generator is tuned repeatedly until the discriminator could not distinguish the original and the generated signal. 9 in most cases and 0 .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Therefore, it does not use any of the computations that are used in the inference and learning pipeline. 4 GiB of data per second per imaging source. This pipeline assumes the use of classical data encoding algorithms like H264 4   which requires all the frames to encode a video stream, albeit it only saves the essential information.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "[30]  Z. Cai, X. He, J. Sun, and N. Vasconcelos, ‚ÄúDeep learning with low precision by half-wave gaussian quantization,‚Äù  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Note that the power-up sequence for a tile runs in the exact opposite order of the  powerdown  sequence (a tile becomes computationally active 512 cycles after it gets the power up signal). Us. ¬¥as  uses two kinds of scheduling policies to handle the graceful  powerdown  and work queue rearrangement.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Architectural implications of function-as-a-service computing. In  Pro- ceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture . 1063‚Äì1075.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "In many cases, where the ethical impacts and expected societal implications are those that are well established when advancing the field of Machine Learning, substantial discussion is not required, and a simple statement such as the following will suffice: \n‚ÄúThis paper presents work whose goal is to advance the field of Machine Learning. This statement should be in an unnumbered section at the end of the paper (co- located with Acknowledgments ‚Äì the two may appear in either order, but both must be before References), and does not count toward the paper page limit. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.‚Äù \nThe above statement can be used verbatim in such cases, but we encourage authors to think about whether there is content which does warrant further discussion, as this statement will be apparent if the paper is later flagged for ethics review.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 187,
    "augmented": true
  },
  {
    "text": "200 using a hill-climb policy [ 17 ] to meet the target accuracy. AWS combines about 6-12 models to give the best possible accuracy. Users also have the option to manually mention the ensemble size.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "In this context, our project takes an ambitious step to  democratize  LLM models by exploring the design space of morphable EoEs. In this direction, we plan to use/augment these models by investigating microarchitectural, architectural and system level impacts on training and inference processes. 4 Broader Impacts Research Ramifications : While LLMs have recently gained significant attention specifically in paving the way for Generative AI, the monolithic design of such models have made training and inference pro- hibitively expensive.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Even today, more than 10 million users enjoy  360 ¬∞ videos \nusing Google Cardboard [10], Samsung Gear VR [44], and Oculus VR [8], to experience  360 ¬∞ video [7], art museum [9], live stadium [46], etc. The  360 ¬∞ videos are created by capturing scenes in all directions typically using omnidirectional cameras or a set of cameras. They are further encoded by the conventional video encoders, as if they are planar videos, for transmission efÔ¨Åciency.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "E. Sensitivity Study \nOur proposed intra-frame PCC utilizes the Morton code to capture the spatial locality, and signiÔ¨Åcantly speeds up the compression ( 44 √ó ), with high compressed quality (48.5 dB PSNR). This motivates us to further look into architecture-level optimizations in future work, including 1) replacing GPU with ASIC to improve the power efÔ¨Åciency for  Diff Squared  computation kernel; 2) customizing the accelerator (e.g., number of layers of the tree-structured adder) for the  Squared Sum  kernel; and 3) minimizing data movements such as inter-SoC (e.g., between GPU and CPU) or intra-SoC (e.g., across L2/L3 caches in a GPU) memory copies. More interestingly, software-level optimizations for this step have been fully exploited (e.g., the kernel functions are invoked in a fully-parallelized manner), yet it still dominates the latency and energy.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 221,
    "augmented": true
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply. -18.87 \n-9.14 \n-10.2 -11.35 \n-20 \n-15 \n-10 \n-5 \n0 \n0% 20% 40% 60% 80% 100% \nRapidly Varrying \nModerately \nstable \nRelatively \nStable \nFully Powered \nLoss in accuracy in % \nContribution of Policy \nExemplar Profiler Morphable No Optimization \n(a) Contribution of components on video data \n0 \n0.1 \n0.2 \n0.3 \n0.4 \n0.5 \n0.6 \nBest Average Best Average \nUsas iCARL Usas Optimus \n# Relative Exemplars # Relative Epoch \nRelative Error wrt Oracle  \n(Lower  is better) \n(Audio) Audio MNIST (Audio) CHiME Home (3D PC) KITTI Vision \n(3D PC) nuScenes (IMU) Bearing Fault (IMU) MHEALTH \n(b)  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 225,
    "augmented": false
  },
  {
    "text": "We propose to plug-in intelligent peak-to-median prediction policies (in accordance to  Observation 4 ) , which can aid the load-monitor to estimate the duration of static load. To handle dynamic load variations, a load-monitor can be designed such that it constantly moni- tors different periods of static load and peak load. Furthermore, it can measure the peak-to-median ratio in sampling windows, which can be used to decide if  serverless functions  are re- quired to balance the load.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "URL https://doi.org/10.1145/3466752.3480056 . Jingjie Zhu, Mingming Cheng, and Ying Wang. Viewer in-consumption engagement in pro- environmental tourism videos: A video analytics approach.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "1192‚Äì1205, 2018. [18] J. He, M. A. Qureshi, L. Qiu, J. Li, F. Li, and L. Han, ‚ÄúRubiks: Practical 360-Degree Streaming for Smartphones,‚Äù in  Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services , 2018, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "[34]  Ram Srivatsa Kannan, Lavanya Subramanian, Ashwin Raju, Jeongseob Ahn, Jason Mars, and Lingjia Tang. 2019. GrandSLAm: Guaranteeing SLAs for Jobs in Microservices Execution Frameworks.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "We leverage data memoization to skip unnecessary compute saving inference execution time and energy. ‚Ä¢  Efficient Hardware:  We propose simple, low power, and low latency hardware to efficiently build coresets, further increasing the number of samples that can be inferred or transmitted under EH budget, and thereby significantly improving the accuracy over the state-of-the-art ( ‚âà 5%). We develop a non-volatile hardware accelerator, with mul- tiple quantization support, for efficient DNN inference.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Additionally, the  nuScenes  data-set (Caesar et al., 2020) by Aptiv, with its comprehensive sensor data and annotations covering diverse driving scenes, is instrumental in evaluating  Salient Store  ‚Äôs efficiency in multi-modal data processing typical in urban mobility scenarios. Beyond the vision- based data, we also incorporated the  Chime Audio  data-set (Foster et al., 2015) into our evaluation. This data-set, consisting of audio recordings, offers a different modality to test the versatility of Salient Store  in handling various types of continuous learning data beyond visual inputs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "Note that, as discussed above, 2 . Due to this inherent nature of compute, the pattern between left eye and right eye can be easily  captured  by proÔ¨Åling the distance vector for only the Ô¨Årst row on the screens:  Œî = \u0002 ‚Éóx 0 r   ‚àí ‚Éóx 0 l   , ‚Éóy 0 r   ‚àí ‚Éóy 0 l \u0003 , as shown in line number  2  in Algorithm 1. With the learned pattern, the remaining  i th rows for the right- eye ( i  ‚àà [1 , n  ‚àí 1] , where  n  is the  height  of the VR screen) can be  reconstructed  by using the projection computation results of the left-eye ( [ ‚Éóx i l , ‚Éóy i l ] ) and the pattern  Œî , as shown in line  6  in Algorithm 1.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 198,
    "augmented": true
  },
  {
    "text": "C/S is the ratio of  C ompleted over the  S cheduled training tasks over multiple time windows of 4hours. Our custom HW runs with intermittent support both by hardware and software. There have also been signiÔ¨Åcant efforts in designing and optimizing specialized DNN training accelerators [ 16 ], [ 27 ], [ 81 ], and many commercial organizations have already devel- oped their own accelerators [ 37 ], [ 95 ] as well.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Key Observations: 1) If data is shared with (a third party) cloud, the accuracy of the model generated using all data from different machines is significantly higher than the models generated for the edge using their own data. Although, in case of 5 machines (see Figure 3) we see about a 5% accuracy gain with a 14.71% latency increment to perform the inference at cloud, this 5% increment has significant impact in practise. For example, for a typical grinding job that takes about 8.2 seconds [1], this 5% improvement impacts  ‚âà 46 k  parts per year per machine (working 8 hours/day).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "3 HOLOGRAPHIC PROCESSING STUDY \nTo leverage the opportunities in the holographic processing from a RGB-D (i.e., RGB and depth) image, we need to first understand the detailed execution of the entire hologram processing from both the algorithm and hardware perspectives. We illustrate the details of depthmap hologram processing in Fig. 4a and Algo.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Impact on Quality : The proposed  AE  scheme captures the pattern between both the eyes with only the  1 st  row of the frame, and then uses the same pattern to  bypass  the projection computation for the remaining rows of the right eye. 9, that only 28%  of the compute energy is consumed w.r.t. the  Baseline ( 22%  for the left-eye,  6%  for the right-eye), translating to a  37%  total energy saving.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "However, it is evident that any compute offloaded to any of the CSDs in these scenarios offers benefits in terms of data processing latency. To underscore the impact of  Salient Store  at a much larger scale, where one can assume a consolidated edge server catering towards multiple streams as depicted in Ekya (Bhardwaj et al., 2022), we utilized an AWS EC2 F1 instance with Alveo FPGAs, along with EC2 P4 instance with A100 GPUs to implement the continuous learning end-to-end. As shown in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "Oresti Banos, Rafael Garcia, Juan A Holgado-Terriza, Miguel Damas, Hector Pomares, Ignacio Rojas, Alejandro Saez, and Claudia Villalonga. Accessed on 05/19/2024. https://store-usa.arduino.cc/products/ arduino-nano-33-ble-sense-with-headers , 2024.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "These optimizations have been attempted at different levels, including model compression (pruning [2], [3], quantization [4]), compiler support [2], [5]‚Äì [7], runtime systems [7]‚Äì[13], and hardware enhancements [9], [14], [15]. There has been recent research in optimizing video analytics on edge devices, targeting smartphones, autonomous driving cars, and VR/AR headsets. Furthermore, running inference for videos on edge devices is even more expensive than images due to the data volume and the power/energy constraints.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Having an ensemble provides robust exemplar selection and improves accuracy over a single teacher. The X-Axis has different DNNs , R: ResNeXt101, T: YOLO-V3, V: VGG- 16, IL: Intermittent Learning, RR: Round Robin. C. Hardware Implementation and Evaluation \nThe proposed morphable hardware was simulated using an in-house simulator based on ScaleSim [ 79 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "To further mimic realwold scenarios of multiple cameras sending multiple streams with various stream rate, we  distributed  video data into across two CSDs in different ratio, as shown in TABLE 2. Trivially, a load-balanced scenario outperforms any of the biased data distribution scenario. However, it is evident that any compute offloaded to any of the CSDs in these scenarios offers benefits in terms of data processing latency.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "[53] Wikipedia, ‚ÄúPixel 2,‚Äù ‚Äùhttps://en.wikipedia.org/wiki/Pixel 2‚Äù. [54] Wikipedia, ‚ÄúActive-Matrix Organic Light-Emitting Diode,‚Äù ‚Äùhttps://en. wikipedia.org/wiki/AMOLED‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Therefore, we need to Ô¨Ånd the classiÔ¨Åcation result for all the sensors without activating them. Extending our assumption from AAS, we hypothesize that the most recent classiÔ¨Åcation result of a sensor must be a good \nrepresentation of what its inference would be for the current activity. Hence, by memorizing or  recalling  the most recent classiÔ¨Åcation result, we can get the inference result of a sensor even without activating it.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Both require the assistance of the cloud, and hence, introduce additional costs and privacy issues. To summarize, even though the prior works discussed above have tried the optimized DNN models, the static compiler/run- \n1075 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "heterogeneous resource availability from the public cloud. Comparison of different models under ISO-latency and ISO-accuracy setup. Figure 2.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Lab Resources:  The PIs collectively have more than 6,000 sq. ft. of laboratory space including three conference rooms and more than 60 desks with PCs, peripherals, and virtual meeting equipment. The prototyping efforts in the proposed research will be carried out primarily in the research labs at Penn State, directed by Das, Kandemir, and Zhang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "¬¥as  plays a crucial role in efÔ¨Åciently handling varying energy income and workloads. As the energy income becomes more sporadic, hardware- assisted scheduling seamlessly transfers work to active pro- cessing elements (PEs), maximizing the completion of tasks that could have otherwise been lost. This hardware-driven adaptive scheduling signiÔ¨Åcantly impacts different data modal- ities, from large-scale to small-scale, and various magnitudes of energy income, as depicted in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Openwebtext corpus: Extracting web- content using reddit links. arXiv preprint arXiv:2001.08023 , 2020. [49] Mohammad Gokaslan, Girish Mishra, and Andrea Madotto.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "5b  shows the power-down sequence and signal states. The network works at a super-tile (STile) granularity and each arbiter node uses an 8x8 priority- mux. The network only gets activated when it gets a  w-pdown warning signal from the predictor.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "One key driver for the design lies in a  Probability Estimation Model  for individual functions, which is explained below. 3 Function Probability Estimation Model As elucidated in  Opportunity-1 , to specifically address the container over-provisioning problem for DDAs, we need to estimate the weights to be assigned to their composite func- tions, a key component of which is the function invocation probability. In this section, we model the function probability estimation problem using a Variable Order Markov Model (VOMM) [ 21 ].",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Furthermore, the AASR poses negligible overhead both in terms of compute and memory. Our goal is to develop an activity aware ensemble technique which can further improve accuracy, when compared to AASR. The idea of making the ensemble task activity aware has similarities to weighted majority voting, where we assign weights to the individual learners participating in the ensemble, such that a higher accuracy classiÔ¨Åer contributes more weight towards the Ô¨Ånal result.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "891‚Äì907. Usas: A sustainable continuous-learning¬¥ framework for edge servers. In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "[54]  MPEG, ‚ÄúPoint Cloud Video: Loot,‚Äù  ‚Äùhttps://bit.ly/3QXDsPf‚Äù , 2022. [55]  MPEG, ‚ÄúPoint Cloud Video: Redandblack,‚Äù  ‚Äùhttps://bit.ly/ 3NyQq2R‚Äù , 2022. [53]  MPEG, ‚ÄúMPEG Point Cloud Compression,‚Äù  ‚Äùhttps://mpeg- pcc.org‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "This difference, in terms of percent of SLO violations, changes from being at most 0.1% to being between 0.1 to 0.35%. However,  Kraken  is able to \nmaintain at least 99.5% SLO guarantee and spawns 50%, 34% and 15% less containers compared to  Arch ,  Fifer  and  Xanadu , respectively. It can be seen that the difference in SLO compli- ance between  Kraken ,  Comm Only , and  Conn Only  increases due to the reduced target SLO.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "We will then perform ‚Äúunlearning‚Äù by parameter-efficient fine-tuning to update the most relevant parameters. On the other hand, for knowledge integrity and resource efficiency, we will also explore innovative directions for expert shrinking by unlearning outdated knowledge that is no longer required. To maximize the unlearning effectiveness, given a seed forget dataset, we will perform deductive reasoning based on our previous work [62] to generate a larger forget dataset to account for the ripple effect of knowledge update [28].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "However, even after preserving important fea- tures, the constructed corests are lossy representation of the original data. Therefore, when performing inference on the compressed coresets representation, the inference ac- curacy goes down, albeit not significant compared to other lossy compression methods (we can again refer to Table 1 for the relevant comparisons). This leaves an optimization space in trading between communication cost vs. accuracy, i.e.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "1: Data drift on different data modalities. Sampling window size: 4hours for video, 20 minutes for audio for urban trafÔ¨Åc video and audio data. 1hour for 3D Point Cloud simulated data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "The codec‚Äôs autoencoder component, which is trainable, is then tasked with compressing these enriched features. The extraction of motion vectors between frames further enriches the feature space by incorporating temporal dynamics essential for effective compression. This strategy capitalizes on the robust, pre-trained features of MobileNet, which are frozen during training to ensure their integrity and to leverage their proven capability in capturing essential visual features.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Proper Exemplar Selection \nTo tackle the sampling bias [ 70 ], we adapt a representation learning [ 74 ] framework for designing the proper exemplar selection. B. The fundamental issue with the previous approach is the inability to select correct numbers of IID data for training.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Addi- tionally, we discuss bounds on the newly introduced hyper- parameters and provide guidelines for selecting them. Problem Setting and Notation \nWe consider a global inference model  f Œ∏  :  X ‚ÜíY  parame- terized by  Œ∏  ‚àà R d . The model‚Äôs performance is measured by a loss function  ‚Ñì :  Y √ó Y ‚Üí R ‚â• 0  that is convex in  Œ∏  for any fixed input-label pair  ( x, y ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Scalable k-means++. arXiv preprint arXiv:1203.6402 , 2012. Antonio Barbalace and Jaeyoung Do.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "https: //www.tuxera.com/blog/autonomous-cars-300-tb-of-data-per-year/ . (Accessed on 11/13/2023). Autonomous cars generate more than 300 tb of data per year.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Our results show a 6% to 22% improvement in accuracy over current methods, with an increase of less than 5% in computational overhead. This paper details the development of the adaptive training framework, describes the integration of energy profiles with dropout and quantization adjustments, and presents a comprehensive evaluation using real- world data. Additionally, we introduce a novel dataset aimed at furthering the application of energy harvesting in computational settings.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Algorithm 1  Proactive Scaling with weight estimation \n1:  for  Every Monitor_Interval= PW  do 2: Proactive_Weighted_Scaler ( ‚àÄ ùëìùë¢ùëõùëêùë°ùëñùëúùëõùë† ) 3:  procedure  Proactive_Weighted_Scaler( func ) 4: cl  ‚Üê ùê∂ùë¢ùëüùëüùëíùëõùë° _ ùêøùëúùëéùëë ( ùëìùë¢ùëõùëê ) 5: ùëùùëô ùë° + ùëÉùëä ‚Üê Load_Predictor ( ùëêùëô, ùëùùëô ùë° )  a 6: batches  ‚Üê l p ùëôùë° + ùëÉùëä f ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m \nb 7: total_con  ‚Üê Estimate_Containers ( ùëèùëéùë°ùëê‚Ñéùëíùë†, ùëìùë¢ùëõùëê ) 8: reqd_con  ‚Üê ùëöùëéùë• ( ùëöùëñùëõ _ ùëêùëúùëõ,ùë°ùëúùë°ùëéùëô _ ùëêùëúùëõ ) 9: Scale_Containers ( ùëìùë¢ùëõùëê,ùëüùëíùëûùëë _ ùëêùëúùëõ ) 10:  procedure  estimate_containers( load, func ) ‚ä≤ Output:  ùëüùëíùëûùëë _ ùëêùëúùëõ 11: func.prob  ‚Üê Compute_Prob (func) 12: reqd_con  ‚Üê‚åà ùëôùëúùëéùëë ‚àó ùëìùë¢ùëõùëê.ùëùùëüùëúùëè ‚åâ 13: extra  ‚Üê‚åà( Comm ( ùëìùë¢ùëõùëê ) +  Conn ( ùëìùë¢ùëõùëê )) ‚àó ùëüùëíùëûùëë _ ùëêùëúùëõ ‚åâ 14: reqd_con  ‚Üê reqd_con + extra \nKraken  makes use of a Load Predictor  2b  (Algorithm 1  a ) which uses the EWMA model to predict the incoming load at the end of a fixed time window,  ùëÉùëä . This time window is chosen according to the time taken to scale all functions in the respective application. Note that  ùë° in the algorithm refers to the current time.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 407,
    "augmented": false
  },
  {
    "text": "[33] Kitware, Inc., ‚ÄúThe VIRAT Video Dataset,‚Äù ‚Äùhttps://viratdata.org‚Äù, 2011. [34] A. Tamhankar and K. R. Rao, ‚ÄúAn overview of H.264/MPEG-4 Part 10,‚Äù in  Proceedings EC-VIP-MC 2003. 4th EURASIP Conference focused on Video/Image Processing and Multimedia Communications (IEEE Cat.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "), GPU (to execute hologram), Mem (for data accesses), and the SoC (the remaining hardware components, e.g., codec, network), with different number of depth planes (ranging from 2 to 16), as shown in Fig. One can observe from this figure that, when the number of depth planes is increased, the power consumptions of  SoC  and  CPU  do not change much, while, in contrast, both the GPU  and  Mem  consume more power. 8a.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "2. Comparisons on loop code and ReRAM activation with tile- size activation over full-size activation. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation \nIf we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve ‚Äúcontinuous progress‚Äù under lower power supply.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "power Input \nPV [41] \nInput 1@50 √ó 50 Conv1 8@6 √ó 6 √ó 1 36 √ó 8 752.2 ¬µ W 8@45 √ó 45 Conv2 12@3 √ó 3 √ó 8 72 √ó 12 1125.6 ¬µ W 12@20 √ó 20 Conv3 16@3 √ó 3 √ó 12 108 √ó 16 1526 ¬µ W 16@8 √ó 8 Conv4 10@3 √ó 3 √ó 16 144 √ó 10 1114 ¬µ W 10@6 √ó 6 Conv5 6@3 √ó 3 √ó 10 90 √ó 6 676.2 ¬µ W 6@4 √ó 4 \nFR [42] \nInput 1@32 √ó 32 Conv1 4@5 √ó 5 √ó 1 25 √ó 4 377.4 ¬µ W 4@28 √ó 28 Conv2 16@4 √ó 4 √ó 4 64 √ó 16 1433.6 ¬µ W 16@10 √ó 10 \nLeNet [43] \nInput 1@32 √ó 32 Conv1 6@5 √ó 5 √ó 1 25 √ó 6 539.7 ¬µ W 6@28 √ó 28 Conv2 16@5 √ó 5 √ó 6 150 √ó 16 1614.2 ¬µ W 16@10 √ó 10 \nHG [44] \nInput 1@28 √ó 28 Conv1 6@5 √ó 5 √ó 1 25 √ó 6 539.7 ¬µ W 6@24 √ó 24 Conv2 12@4 √ó 4 √ó 6 96 √ó 12 1176 ¬µ W 12@8 √ó 8 \nFor each application on each power trace, we report the throughput and energy efÔ¨Åciency under the Ô¨Åve different execution strategies. We also study the sensitivity of our proposed approach to available ReRAM hardware resources. We then demonstrate the beneÔ¨Åts from the proposed smooth transition strategy and power prediction.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 420,
    "augmented": true
  },
  {
    "text": "We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers. Previous work [ 3 ] has noted vulnerabilities to pipeline bubbles and execution stalls in CNNs because of the large variance in weight and feature map scales across different layers. In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very Ô¨Åne-grain fashion.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. InterHolo IntraHolo InterIntraHolo \nPSNR \n(a) PSNR.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "1221‚Äì1230, 2013. Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazar√©, Maria Lomeli, Lucas Hosseini, and Herv√© J√©gou. The faiss library.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "9 \n495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 \nBecause the best-response process eliminates profitable de- viations step by step and cannot cycle indefinitely, the action profile sequence generated by iterative best responses con- verges to the NE. As a result, sensors do not continually defer improvements, preventing complex long-term cycles. This discounting ensures diminish- ing returns for postponing beneficial participation or indefi- nitely waiting for ideal conditions.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 209,
    "augmented": true
  },
  {
    "text": "3a, the bike  object is closer to the user, and also has a larger range/size ( size=farmost-nearest ); thus, more information is required to create the hologram for the  bike  for maintaining fairly good QoS than the  chair . Therefore, one opportunity to reduce the amount of computation is to  approximate  the hologram processing based on the objects‚Äô distances and sizes. Temporal Locality for the User Interests:  As also established by prior foveated rendering proposals, the foveal vision (or Region of Focus, RoF) is only a small region in the current scene and can be traced by eye tracking techniques [ 26 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "Google Preemptible VMs., February 2018. https://cloud.google.com/preemptible-vms . [10]  Azure. Machine Learning as a Service., February 2018. https://azure.microsoft.com/en-us/pricing/details/machine-learning- service/ .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "If preliminary tests show insufficient participation, slightly increase  Œ∑ 0 . If participation is overly aggressive, reduce  Œ≥ 0  or increase  Œ¥ 0 . 5:  Simulation-Refinement Loop: 6:  for  k  = 1 ,  2 , .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Using Scene Viewer to Display Interactive 3D Models in AR from an Android App or Browser. \"https://developers.google.com/ar/develop/java/ scene-viewer\". [4]  Stephen A Benton and V Michael Bove Jr. 2008.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "4. Stationary distribution  D . The equilibrium participa- tion strategies induce a stationary effective distribution D .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 24,
    "augmented": true
  },
  {
    "text": "5.2.1 Evaluation Metrics \nMost of our evaluations of  Cocktail  for image-classiÔ¨Åcation are performed using the  Imagenet  dataset. Based on the decreasing order of accuracy, we categorize them into  Strict  and  Relaxed  workloads. To further demon- strate the sensitivity of Cocktail to dataset and applicability to other classiÔ¨Åcation applications, we also evaluate it us- ing  CIFAR-100  and Sentiment-Analysis application.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "(a) Power breakdown consuming 3.4 Watts; (b) Projection pipeline taking head orientation and pupillary distance to compute projection matrices for both the eyes, which map  360 ¬∞  coordinates to 2D coordinates for generating stereoscopic frames. (c) Reusing projection matrices by exploiting relation between both eyes and fusing it with head orientation. 2: Overview of  360 ¬∞  video projection.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "To address this, we also utilize coreset construction using k-means clustering [ 8 ,  36 ,  37 ], which separates the data points into a set of k (or fewer) N-spherical clusters and represents the geometric shape of the data by using the cluster centers and cluster radii (Fig. In each case, the points/values in  red  are communicated to the host. Coreset Construction Using Clustering:  Although im- portance sapling based coreset construction is computation- ally inexpensive, it suffers from accuracy loss because it doesn‚Äôt explicitly preserve the intricate structure of the data points.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "Available at:  https://doi.org/10.48550/arXiv.2410.03703 . [86] Mandy La and Andrew Chien. Cerebras systems: Journey to the wafer-scale engine.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "locality opportunities (i.e., the smaller area, the better). ‚Ä¢  Moreover, a vertical line can be drawn in this gap range, i.e.,  x  =  Œ± , and the macro blocks on the left side have ‚Äúenough‚Äù temporal similarities and thus can be compressed with the I-frame (e.g., simply discard the deltas and represent/compress these blocks by the pointers to the matched I-blocks), whereas those on the right have to employ an extra intra-compression step to further compress the deltas. Note that  Œ±  can be adjusted based on the application preference, e.g., shifting the  x  =  Œ±  line to the right results in more macro blocks in the I-frame being directly reused for compressing the P-frame, i.e., higher compression ratio, with a cost of quality drop (more details in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 202,
    "augmented": false
  },
  {
    "text": "To address these challenges, this paper proposes and experi- mentally evaluates  ResiRCA , a resilient ReRAM crossbar-based CNN accelerator. However, neither of them is a good Ô¨Åt for energy-harvesting scenarios. The approaches in the Ô¨Årst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [ 3 ], [ 4 ], [ 5 ], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [ 6 ], [ 8 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "[16]  Bo Han, Yu Liu, and Feng Qian. 2020. ViVo: Visibility-aware Mobile Volumetric Video Streaming.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, with our current ‚Äúsub-optimal‚Äù implementation (e.g., the codes are not fully optimized), the de-compression stage (including both geometry and attribute de-compression) for Redandblack video [ 55 ] only takes ‚âà 70 ms  per PC frame, which is less then the PC compression latency as we will discuss later in Sec. Such signiÔ¨Åcant speedup comes with a reduction in quality. VI-C .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "These annotations will provide a kind of ‚Äúdata lineage‚Äù, i.e., they will document a trail that accounts for the origin of a piece of data as well as the stages it went through to reach its final form. In a sense, our annotations will make the data originating from this project more actionable and easily repro- ducible. In addition to the data de- scribed above, they will also generate and maintain ‚Äúannotations‚Äù attached to i) the libraries used in com- piler and runtime system source codes, and ii) the characterization and experimental data generated by the project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "Restrictions apply. [27]  L. Huang, S. Wang, K. Wong, J. Liu, and R. Urtasun, ‚ÄúOctsqueeze: Octree-structured entropy model for lidar com- pression,‚Äù in  CVPR , 2020. [28]  T. Huang and Y. Liu, ‚Äú3d point cloud geometry compression on deep learning,‚Äù in  Proceedings of the 27th ACM International Conference on Multimedia , 2019, p. 890‚Äì898.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Restrictions apply. A. Video Inference on Mobile Platforms \nThe key difference between a video-based DNN application and other popular DNN inferencing applications like natural language processing (NLP) or speech-to-text is that, the former interacts with video frames which are either captured from the camera or downloaded/streamed from internet and hence, has a strict latency requirement for performing inferencing within the frame deadline.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Similarly, for performing convolution, the ReRAM x-bar typically includes additional components, such as delay lines and adders. The delay lines are used to implement the sliding window for the convolution operation, while the adders are used to sum the weighted input signals over the sliding window. 24 \nF Pseudo Codes \nF.1 Depth-wise Separable Convolution 2D Using TI LEA \nDepth-wise separable convolution is an efficient form of convolution that reduces the computational cost compared to standard convolution.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "25 and  RD upper bound  = 10  in Algo. 1;  T moving 2  = 0 . 3  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "1 and Algo. 2) introduced by our proposal amount to only  0 . 5%  of the end-to-end execution latency (the baseline YOLOv3 inference).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "8097. International Society for Optics and Photonics, 80971H. [50]  Victor Adrian Prisacariu, Olaf K√§hler, Stuart Golodetz, Michael Sapienza, Tom- maso Cavallari, Philip H. S. Torr, and David William Murray. 2017.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Compared to the baseline, we then report the averaged PSNR [ 21 ,  44 ] of the recon- structed images from the six videos in Fig. 10a. It can be observed from this figure that, even with the most aggressive approximation introduced by  Inter-Intra-Holo , the video quality is still sufficient for most of the AR applications (30 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "This data set directly fits our use case for two reasons - 1. such as temperature and humidity of different regions of the home as well as the locality (from weather station data [3] with 14803 training samples and 4932 testing samples). The data set is divided into 2 chunks creating a two home set up and the similar is done for a 4 home setup.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "As can be observed from three users‚Äô eye tracking shown in Fig. 3b, all focus only on a portion of the entire viewing window within a short period of time (10 seconds in this case). Temporal Locality for the User Interests:  As also established by prior foveated rendering proposals, the foveal vision (or Region of Focus, RoF) is only a small region in the current scene and can be traced by eye tracking techniques [ 26 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "We integrate a  mongodb  [ 21 ] database in the master node to main- tain all information about procured instances, spot-instance price list, and instance utilization. This information is used for cal- culating the weights per model for autoscaling decisions. The load prediction model resides in the master VM which constantly records the arrival rate in adjacent windows.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "To solve this issue, we propose to re-construct the expert graph automatically to balance the workload. The EoE graph pruning process, involving removing and merging experts, can sometimes result in imbalanced branches, where one branch contains significantly more experts than another. This imbalance can lead to inefficiency in workload distribution among different parts of computing resources.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Furthermore, it needs to take advantage of the  data similarity between frames  to further minimize the storage footprint, and thereby reducing the form factor and need of frequent disk swapping/ maintenance. The second challenge comes from  privacy and security of sensitive data . Considering the cheap commodity use storage devices are often plug and play, they are often vulnerable for data leak, especially if they are deployed in public, like urban mobility setting.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "[39] Junjue Wang, Ziqiang Feng, Shilpa George, Roger Iyengar, Pillai Pad- \nmanabhan, Mahadev Satyanarayanan, ‚ÄúTowards scalable edge-native applications,‚Äù in  ACM/IEEE Symposium on Edge Computing , 2019. [40] C.-K. Kang, H. R. Mendis, C.-H. Lin, M.-S. Chen, and P.-C. Hsiu, \n‚ÄúEverything leaves footprints: Hardware accelerated intermittent deep inference,‚Äù  IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , vol. 39, no.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "We also observe a similar trend over other modalities, making the importance of continuous learning clear for multiple domains. However, in a continuous learning paradigm, training be- comes an essential, repeatedly scheduled task whose computa- tional and time costs cannot be considered a one-time overhead freely delegated to the cloud. However, with a proper retraining, the smaller model could keep up with the original accuracy.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "13 \nA More Results on Other Platforms and EH Sources \nFigure 4: Hardware setup of NExUME using MSP-EXP430FR5994 as the edge compute, Adafruit ItsyBitsy nRF52840 Express for communicating, Energy Harvester Breakout - LTC3588 with super- capacitors as energy rectification and storage and a Pixel-5 phone as the host. ACM Transactions on Embedded Computing Systems , 22(5s):1‚Äì25, 2023. Keep in balance: Runtime-reconfigurable intermittent deep inference.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Training in Paper Writing \nThe PIs will discuss regularly with the PhD students the best paper-writing practices, to ensure that they gain the first-hand experience in best practices. Additionally, the students will be encouraged to attend career and professional development workshops offered by Penn State. To expedite the process, where it makes sense, the PIs will team up the new students with the older ones in paper writing process.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Abstract \nWe are witnessing an increasing trend towards using Ma- chine Learning (ML) based prediction systems, spanning across different application domains, including product rec- ommendation systems, personal assistant devices, facial recognition, etc. These applications typically have diverse requirements in terms of accuracy and response latency, that can be satisfied by a myriad of ML models. However, the deployment cost of prediction serving primarily depends on the type of resources being procured, which by them- selves are heterogeneous in terms of provisioning latencies and billing complexity.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "Note that the latency is the raw model execution latency, and does not include the addi- tional network-transfer overheads incurred. (categorized by dotted lines) picked in the increasing order of accuracy. Each of these picked constraints (named const1 - const5 in the Figure) represents a single baseline model, whose corresponding ensemble size ranges from small (2) to large (10), as shown in Table  3 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, Vijaykrishnan Narayanan, and Chita R Das. Usas: A sustainable continuous-learning¬¥ framework for edge servers. In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "0001 ) to  1  (resolution is  0 . 1 ), the reuse ratio increases from  18%  to  92% ; however, the PSNR drops from  85%  to only  19% . This is because low precision leads to a mis-projection, which fails to reÔ¨Çect the current head orientation.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "2021. Exploring Extended Reality with ILLIXR: A new Playground for Architecture Research. [19]  Muhammad Huzaifa, Rishi Desai, Samuel Grayson, Xutao Jiang, Ying Jing, Jae Lee, Fang Lu, Yihan Pang, Joseph Ravichandran, Finn Sinclair, Boyuan Tian, Hengzhi Yuan, Jeffrey Zhang, and Sarita V. Adve.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Let  e op  denote the energy consumed per computational operation, which varies with operation type and data precision. Modeling Energy Consumption:  The energy consumption of DNN operations is modeled based on empirical profiling data from the hardware platform. (2) \nThis ensures that when energy is low, higher dropout rates and lower quantization bit-widths are used to reduce computational load, and vice versa.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "2.2. Traditional approaches often assume con- tinuous participation of all sensors, which is impractical in energy-constrained environments ( ? Participation Strategies in EH-WSNs \nEfficient participation strategies are critical in EH-WSNs to optimize network performance while conserving limited energy resources.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "In  2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS) , June 2017. [75]  P. Thinakaran, J. R. Gunasekaran, B. Sharma, M. T. Kandemir, and C. R. Das. Kube-Knots: Resource Harvesting through Dynamic Container Orchestration in GPU-based Datacenters.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "We propose a dynamic adjustment of training parameters‚Äîdropout rates and quantization levels‚Äîthat adapt in real-time to the available energy, which varies in energy harvesting scenarios. This approach utilizes a model that integrates the characteristics of the network architecture and the specific energy harvesting profile. It dynamically adjusts training strategies, such as the intensity and timing of dropout and quantization, based on predictions of energy availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Feature Map Reconstruction Error Dropout and QuantaTask Optimization: Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ≥ . Define the energy budget E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "To summarize, compared to 2D video processing,  360 ¬∞ video processing incurs additional projection computation. From our measurements collected from a smartphone [53] running a  360 ¬∞ VR application [11], even with extra computa- tion, the overall processing for rendering one  360 ¬∞ frame can be completed within 22  ms  on average (translating to 45 fps). However, since the whole computation/rendering process takes place on a battery-backed device [39], one needs to consider the ‚Äúenergy efÔ¨Åciency‚Äù of this computation, i.e., even though we can meet the performance requirements of such video, energy efÔ¨Åciency needs to be improved.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "Custom Accelerator  \nChip \nSystolic  \nArray \nCache Hierarchy \nDRAM/ \nHBM \nChiplet \nInterconnect  \network \nCacti/gem5 \nScaleSimv2 \nRamulator \nRapid  Chiplet \nMQSim/ FlashSim \ngem5 \nGARNET \nGPGPU  \nSim \nHardware  \nstats \nTraining  dataset Analytical  \nmodels \nEstimation for: ‚Ä¢ Time ‚Ä¢ H/W choice ‚Ä¢ Power ‚Ä¢ Cost ‚Ä¢ Accuracy \nLatency  \nstats \nAccuracy \nstats \nUser Input \nEoE \nSoftware  \nRuntime  \nHARDWARE SIMULATION ENVIRONMENT \nINFERENCE \nTRAINING \nFigure 7 :  An end-to-end evaluation environment \nTask-4.2: Methodology We plan to compare our proposed optimizations against state-of-the-art MoEs [38, 42, 57, 74, 83, 89], CoEs [60, 67, 131, 151] and monolithic LLMs [107, 192] on state-of-the-art GPUs, CPUs, and custom acceler- ators (e.g., Groq, Cerebras, SambaNova, Habana Gaudi, and GraphCore). In our evaluation, we will employ both architecture-level and LLM/application-level met- rics. Our approach will em- body the best of both the worlds ‚Äì taking the deeper system level insights from real hardware/simulators and extending it to large scale by analytically modeling their behavior as a complex system.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 337,
    "augmented": true
  },
  {
    "text": "One promis- ing direction that is being recently explored is the development of ‚Äúmodular‚Äù architectures that en- able flexibility, scalability, and efficiency. Mixture of Experts (MoE) [145] and Composition of Experts (CoE) [131, 151] models have been proposed to distribute computational loads across mul- tiple specialized networks. Addressing these challenges ne- cessitates a fresh look beyond the current monolithic design for providing a democratic platform for contributing to cost-effective innovations in LLMs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "For example, for a typical grinding job that takes about 8.2 seconds [1], this 5% improvement impacts  ‚âà 46 k  parts per year per machine (working 8 hours/day). 2) For the most part, the accuracy of the privacy preserving model remains same (if not less) compared to the data sharing model (this reflects the fact that these machines might belong to different industries who were not willing to participate in the the data sharing process). Even with minimal accuracy improvement of 3.5% (see Figure 3, where the 5 machines belong to 5 different owners and not sharing data), one grinding machine can save up to  ‚âà 27 .",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "4.1.1 Estimating function weights : Since workflows in SDAs are pre-determined, pre-deploying resources for them is straightforward in comparison to DDAs, whose workflow activation patterns are not known a priori. To address this, we design a Weight Estimator  2a  to assign weights to all functions so as to allocate resources in propor- tion to them. For DDAs, de- ploying containers for each function in proportion to the application load will inevitably lead to resource wastage.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "[27]  Kyungjin Lee, Juheon Yi, Youngki Lee, Sunghyun Choi, and Young Min Kim. 2020. GROOT: A Real-time Streaming System of High-fidelity Volumetric Videos.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "The w-pdown  triggers the  backup  signal and the system goes into pwr-warning  state (other states being on, off, invalid and X). In the  pwr-warning  phase the system Ô¨Ånishes the remaining compute of the systolic arrays (which can take up to 64 cycles), \n898 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Prior works, trying to tackle this conflict between computa- tion, communication, power-requirement and quality of ser- vice (QoS), have pursued three major approaches: inference effort partitioning optimizations [ 22 ,  30 ,  31 ,  50 ], mitigation of energy provisioning limitations [ 24 ,  40 ,  43 ,  47 ,  56 ], and minimizing communication overheads [32, 33, 36, 37, 45]. One of the most emerging line of work aims to solve the energy provisioning problem at the edge by integrating en- ergy harvesting (EH) to the sensor nodes while making them more capable performing complex compute intermittently, which has given rise to energy harvesting wireless sensor networks (EH-WSNs). Specifically, recent works [ 24 ,  43 ] pro- posed EH, along with compiler/runtime optimizations and leveraging non-volatile processors (NVP) [ 40 ,  56 ], to increase local compute at the edge.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 230,
    "augmented": false
  },
  {
    "text": "In fact, our proÔ¨Åling indicates that only tens of  Œºs  are needed to generate the MVs for one frame (negligible compared to milliseconds or even seconds that DNN inference takes). As opposed to the software-based ‚Äúoptical Ô¨Çow‚Äù solution widely used in the computer vision domain [36], collecting the MV from the  codec hardware  is quite light-weight. We next illustrate 3 common scenarios of leveraging the MVs to capture the reuse opportunities in a DNN-based object detection application.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "6 , compared to RAHT, our proposal reuses the intermediate Morton codes, which have been computed during the geome- try compression, to precisely identify the points with similar attributes from a set of irregular points. :  As indicated in Fig. 2) What are the Pros and Cons?",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "C ONCLUSION \nMAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs. Considering the application sce- narios where the accelerator is supported by harvested energy, we Ô¨Ånd that the previous designs cannot well accommodate the RCA to the changing power sources. This paper proposes ResiRCA, a resilient energy harvesting accelerator.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Furthermore, the PIs will leverage additional connections through their former students working in these companies. The feedback from industry will help us fine tune our proposed EoE models. K12 and Outreach : Our outreach plans include involvement of underrepresented groups in computer science and engineering and various K-12 related activities.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "https : / / machinelearning . apple . com / research / introducing-apple-foundation-models \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "C. Design and Implementation \nWe designed our both schemes (frame-level reuse in Sec. And, Ô¨Ånally, we update RoI for the next layer (the region with the purple border in Step  7  ). The execution time of the PI for Frame-3 is only 54% of the FI, due to a large amount of computation reduction (achieved by omitting the unimportant regions).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Objective:  Maximize  Thr sequ ave Subjected to:  for each layer Lk, P   load Lk   , P  store Lk , P   comp Lk , P   trans Lk , P   merge Lk < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ‚ü® m Lk , n Lk , aG Lk ‚ü© for each layer Lk \nSimilarly, the activation strategy under the pipeline execution mode can be described as below. Then the optimal solution can be selected from among them. Objective:  Maximize  Thr pipe ave Subjected to: P  P  load , P  P  store , P  P  comp pipe   , P  P  trans , P  P  merge < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ‚ü® m Lk , n Lk , aG Lk ‚ü© for each layer Lk \nBy solving the above problems, we can obtain activation solution  ‚ü® m, n, aG ‚ü© for each power level under the sequential and pipelining computation modes, referred to as  SOL sequ \nand  SOL pipe   respectively.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 308,
    "augmented": true
  },
  {
    "text": "An application DAG can map neatly onto a Markov model wherein the functions within the application DAG are mod- eled as states of the VOMM. The process of one function invoking another function corresponds to a transition from the caller function state to the callee function state. The weight for each function corresponds to the state transition probability from the start state to the current one (note that this may require possibly transitioning through a number of intermediate states).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Since both regularizers are convex and smooth, their in- clusion ensures that the overall objective  J ( Œ∏ )  maintains desirable convexity and smoothness properties, facilitating the convergence of stochastic gradient descent (SGD). Periodic Equilibrium-Aware Training: Model updates are performed periodically at an aggregator node that col- lects gradient estimates from participating sensors. Partici- pation during training follows the same equilibrium model: sensors decide whether to compute and send gradients based on their current energy states, predicted future utilities, and the established reward structure.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "The DeepARest model is pre-trained using 60% of the arrival trace. For varying load patterns, the model parameters can be updated by re-training in the background with new arrival rates. 5.2 Evaluation Methodology \nWe evaluate our prototype implementation on AWS EC2 [ 8 ] platforms.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "These are functions within a DAG that have a high number of descendant functions that are linked to it and we use the \n155 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. SEARCH \nNGINX \nMAKE_POST \nREAD_TIMELINE \nFOLLOW \nTEXT \nMEDIA \nUSER_TAG \nURL_SHORTENER \nCOMPOSE_POST \nPOST_STORAGE \n(a) Social Network. NGINX ID \nMOVIE_ID \nTEXT_SERVICE \nUSER_SERVICE \nRATING \nCOMPOSE_REVIEW \nMOVIE_REVIEW \nUSER_REVIEW \nREVIEW_STORAGE \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "Tree Structure \nGraph¬† Structure \nChain Structure \nExpert¬† Function \nForward¬† \nPass \nType/ Subtype \nRouter 1 Router 2 \nRouter 1 \nRouter 2 \nCompo- \nsition \nTask-1.1 to Task-1.2 \nTask-1.2 to Task-1.4 \nTask-1.2 to Task-1.3 \nExpert Splitting \nData \nData \nData \nExpert Merging \nAn Expert from¬† Trained¬† EoE  Model¬†¬† \nTrain ¬†on Domain Datasets \nReinforced  EoE  Expert \nwith New Knowledge \nRemove ¬†Components of Expert¬† Add  Components of Expert \nContinual Learning \nAvaliable¬† Accelerators \nRemove Uncommon¬† \nPathes \nUser¬† Preferences Remove Unwanted \nExperts & Reform \nUser Logs \nRemove Unavaliable \nExperts & Reform \n¬† Experts \nUser Selected/ Unavaliable¬†Experts \nCommonly Routed¬† \nPath \nEoE  Network \nMemory Constraint \nAccelerator \nConstraint \nDomain Experts Skill Experts \nLanguage Experts Data Experts \nMedical Science Law Finance Math Code Retrieval \nDocument Table Image \nGraph \nEN CN TR HI \nSumma- \nrization \nFigure 3 :  An overview of four tasks in Thrust-1. Task-1.1: EoE Design Space Exploration. Task-1.2: Constructing Morphology of Ensemble of Experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 256,
    "augmented": false
  },
  {
    "text": "To tackle this, a significant amount of work has been done on check-pointing, and compiler level tweaks, which help maximize the forward progress on such devices [ 39 ,  43 ,  44 ]. These solutions operate on augmented commercial off the shelf micro-controllers [ 66 ], or specialized products with traditional architecture [ 62 ], and rely on their efficient prediction of power failure. While these software optimizations and judicious use of persistent storage works for smaller workloads like keyword spotting (e.g  \"Ok Google\" detection), they are inefficient for complex workloads (e.g.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "[2]  Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang. ACM, 2016. In  Acm Sigplan Notices .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Figure 5 shows the proposed peripheral circuit design for one ReRAM crossbar. Lightweight ReRAM circuit design \npower ReRAM cells. This design is more concise even than the SINWP [ 6 ], because we target low power as the primary goal.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "We use the Ô¨Årst 1 hour sample of both the traces and they are scaled to have an average request rate of 50 req/sec. Workload:  As shown in Table  5  we use image-classiÔ¨Åcation and Sentiment Analysis (text) applications with two datasets each for our evaluation. The second trace is production twitter [ 48 ] trace which is bursty with unexpected load spikes.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Moreover, these AR infotainment applications have helped many of us through the recent global pandemic by bringing us the liveliness of the virtual outdoors, while we were confined to our homes, and more AR capa- ble mobile devices penetrating the market with cheaper price tags have made AR applications pervasive and made the virtual world easily accessible for users on the tip of their fingers. For ex- ample, one of the earliest AR games, Pok√©mon GO (launched in July 2016), had a cumulative download of over 1 Billion, and gener- ated about $900 Million in revenue by late 2019 1 . These technologies have become an important part of our daily life, in the form of creative photography, content creation, gaming, online shopping, virtual touring, and educational and non-educational training, etc.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 182,
    "augmented": true
  },
  {
    "text": "The sensor computes the correlation (  1a  ) between the stored ground truth and the current data. If the correlation coefficient is  ‚â• ùë°‚Ñéùëüùëíùë†‚Ñéùëúùëôùëë (  1b  ) the sensor skips all computation and sends the result to the host. Oth- erwise, the sensor prioritizes local computation and, with the help of a moving average power predictor [ 47 ], predicts whether it can finish the quantized DNN inference with the combination of stored energy and expected income (  2a  and \n2b  ).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "6) using clustering based techniques. Empirically, we observe that ac- curately preserving the features for each class requires  20 data points  using importance sampling or  12 clusters  (see Fig. We perform an analysis on the MHELATH [ 9 ,  10 ] data set (we take a overlapping moving window of 60 data points sampled at 50Hz from 3 different IMUs, overlap size: 30 data points) to find a trade-off between the coreset size (directly related to the communication cost) and the inference accuracy.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "However, our proposed solution offers  ‚âà 3 . 2 √ó  speedup compared to its software counterpart and a  ‚âà 2 . 5 √ó speedup compared to the software based RSA algorithm.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "4), with only  1%  overhead w.r.t. baseline. If not, we have to execute the entire computation as in the baseline case.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Typically, there is an inverse correlation of the convergence of the stochastic gradient descent (SGD) algorithm, the most popular training algorithm for DNNs, over the number of iterations ( n i ) [ 68 ]: l  ‚àù O ( 1 / n i )  and  l  = 1 Œ≤ 0 . n i + Œ≤ 1   +  Œ≤ 2 , where  l  is the loss of the SGD and  Œ≤ i  is an non-negative real number. Therefore, by running a few iterations of the SGD algorithms with various other hyperparameters, we can easily  predict  the con- vergence of the models.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "Targeting on ATW, PIMVR [57] proposed a 3D-stacked HMC to re- duce Motion-to-Photon latency and off-chip memory accesses. Motivated by the observation that the ATW transform matrix generated by rotation on a 2D image is shared by both eyes, PIMVR [57] calculated the transform matrix only once, and scheduled two tiles (one for left-eye one for right-eye) with the same coordinate to the same vault in HMC. Note that, this computation still happens in planar-format, and remains the same between two-eyes for one frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, Origin targets inherent features of sensor data from distributed body area networks in human activity recognition (HAR) tasks and leverages non- volatile processing, intelligent scheduling for energy-harvesting sensor nodes, and ensemble leaning to classify human activity with minimum accuracy loss compared to a state-of-the-art battery powered system. To the best of our knowledge, this is the Ô¨Årst work that tries to enable DNN inference for human activity recognition in a distributed energy harvesting wireless sensor network by leveraging ensemble learning. The paper makes the following key contributions: 1) We design a scheduling policy that chooses the salient sensor for performing the inference depending on the an- ticipated activity, i.e.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 159,
    "augmented": false
  },
  {
    "text": "Moreover,  Us. ¬¥as  needs more I/O operations to store the streaming data to compute the exemplars. We believe it will not be fair to compare the energy efÔ¨Åciency and throughput of a system like ours, which in- herently has more memory, I/O and reconÔ¨Åguration operation with a pure compute based systems mentioned in the hardware baseline.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "If sensors over-exert themselves, reduce  Œ≥  or increase  Œ¥, Œ∑ . If sensors rarely par- ticipate, increase  Œ≥  or decrease  Œ∑ . 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Therefore,  designing a training platform to perform continuous learning with the intermittent solar power and within the typical harvested budget  would be the best solution. The power sustainability consequently reduces the cost of deployment as the publicly available edge server, like AWS outpost offering (one of the cheaper and lower power consuming ones) for performing edge inference costs $5,134.92/month [ 83 ]. Our Approach (and its Novelty):  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "https://docs.aws.amazon.com/ sagemaker/latest/dg/deepar.html,February2020 . Deepar estimator. [4]  Amazon.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "Introduce a discount factor Œ≤  ‚àà [0 ,  1) , and let  V i ( t  + 1)  represent the expected future utility of sensor  s i  given its current decisions and predicted energy availability. The cost is: \nC i ( t ) =  e i ( t ) +  Œ≤V i ( t  + 1) . The overall utility is: \nU i ( t ) =  R i ( t )  ‚àí C i ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "[25] N. Global Monitoring Laboratory, ‚ÄúSolrad network,‚Äù  https://gml.noaa. gov/grad/solrad/index.html , (Accessed on 11/21/2022). [26] G. Gobieski, B. Lucia, and N. Beckmann, ‚ÄúIntelligence beyond the \nedge: Inference on intermittent embedded systems,‚Äù in  ASPLOS .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Thus, in this paper, we want to go beyond the prior foveated rendering for further optimizations, by investigating the potential opportunities which are unique to the AR use cases and may have been missed out before. 2.2.3 What are the Potential Opportunities? However, such performance gain from foveated rendering is still insufficient to close the 10 √ó  gap discussed above.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Only  DProb  and SProb  consume lesser energy than  Kraken  (4% lesser), due to their more aggressive container reduction approach. 6.1.4 Ablation Study : This subsection conducts a brick-by- brick evaluation of  Kraken  using  Conn Only  and  Comm Only , \n163 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. Application Kraken Comm Only Conn Only Social Network (99.94%, 284) (99.91%, 276) (99.89%, 256) Media Service (99.73%, 572) (99.66%, 561) (99.64%, 552) Hotel Reservation (99.87%, 316) (99.77%, 290) (99.74%, 282) Table 5: Real System: Comparing (SLO Guarantees,#Containers Spawned) against  Comm Only  and  Conn Only .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 226,
    "augmented": false
  },
  {
    "text": "We compare the  Paragon model selection scheme against a naive constraints-unaware model selection scheme. It can be seen that mixed scheme has similar cost to reactive but it reduces SLO vi- olations by up to 60%. Results:  Figure  8  plots the SLO and cost for workload-1 across Berkley and WITS trace.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "The throughput can be expressed as follows: \nThr pipe ave   = P Lk = LC Lk =1 ( m  √ó  n ) Lk  √ó  aG Lk \nLat pipe (8) \n2) Activation strategy formulation :  The activation strategy for the sequential mode can be described as shown below. Thr sequ ave   = P Lk = LC Lk =1 ( m  √ó  n ) Lk  √ó  aG Lk P Lk = C Lk =1   Lat Lk (7) \nFor the pipelining computation mode, all the  LC  layers are executed in parallel. For the sequential computation mode, the throughput for Layer  Lk  can be expressed as below: \nThr sequ Lk =  ( m  √ó  n ) Lk  √ó  aG Lk \nLat Lk (6) \nThe average throughput with a  LC -convolution CNN infer- ence can be expressed as shown below.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 217,
    "augmented": true
  },
  {
    "text": "Similarity check (PNSR and SSIM) on the GPU. \"https://docs.opencv.org/2.4/doc/tutorials/gpu/gpu-basics-similarity/gpu- basics-similarity.html\". 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Implementing a minimum viable model configuration that operates at the lowest acceptable energy consumption, achieved by maximizing dropout rates and using the lowest quantization bit-widths. 2. Prioritizing essential tasks and deferring non-critical computations.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "They will also be encouraged to affiliate with one or more professional societies in their chosen field. They will also have access to the various Responsible Conduct of Research and DEIB (Diversity, Equity, Inclusion, and Belonging) training courses offered by Penn State. Diverse Collaborations \nFinally, the PhD students in the project will be encouraged to engage in collaborations with researchers from diverse backgrounds and disciplinary areas to enhance their collaboration and communication skills.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Association for Computing Machinery. [130] Wei Peng. Large language models in healthcare and medical domain: A review.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 26,
    "augmented": false
  },
  {
    "text": "We refer to this effect as  Cold Start Spillover . Fig- ure 3 compares the performance degradation resulting from underprovisioning both Critical and Non-Critical functions. The (Critical, Non-Critical) function pairs chosen for this experiment were ( Make_Post ,  Text ), ( ID ,  Rating ) and ( NGINX , Search ) for  Social Network ,  Media Service  and  Hotel Reserva- tion , respectively.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "The answer is  neural codecs  (Ma et al., 2019; Chen et al., 2017). Neural Codecs ‚Äì DNNs for Compression:  Neural codecs represent a paradigm shift in video com- pression technology, leveraging the capabilities of deep learning to optimize both encoding and decoding processes. Unlike traditional codecs that rely on predefined algorithms to compress video data, neural codecs utilize an end-to-end trainable system based on neural networks.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Fpga acceleration of zstd compression algorithm. In  2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) , pp. 188‚Äì191.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "For example, for a typical grinding job that takes about 8.2 seconds [1], this 5% improvement impacts  ‚âà 46 k  parts per year per machine (working 8 hours/day). Even with minimal accuracy improvement of 3.5% (see Figure 3, where the 5 machines belong to 5 different owners and not sharing data), one grinding machine can save up to  ‚âà 27 . 2) For the most part, the accuracy of the privacy preserving model remains same (if not less) compared to the data sharing model (this reflects the fact that these machines might belong to different industries who were not willing to participate in the the data sharing process).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "Since utilities are bounded (due to finite en- ergy and limited accuracy gains) and returns diminish over time, no infinite sequence of profitable deviations is possi- ble. A complete formal proof, including all technical conditions, is provided in Appendix  B . Hence, the best-response dynamics must terminate at a profile where no sensor can improve its utility alone, i.e., a Nash equilibrium.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "11: else if  participation is too high, leading to frequent energy depletion  then 12: Decrease  Œ≥ k  ‚Üê Œ≥ k ‚àí ‚àÜ Œ≥  or increase  Œ¥ k  ‚Üê Œ¥ k +‚àÜ Œ¥ to discourage high-risk attempts. 13: else if  incorrect inferences are prevalent  then 14: Increase  Œ¥ k  ‚Üê Œ¥ k  + ‚àÜ Œ¥  to penalize low-quality submissions more strongly. 15: end if 16: Check feasibility conditions again to ensure no viola- tion of baseline inequalities.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Typically, the sensor data are low dimensional, and hence even with a good quality of coreset construction, it is difficult to preserve all the features. 3.2.2 Recoverable Coreset Construction:  The primary reason the accuracy of inferring on coreset data is lower than that of the original model is the loss of features. However, while inferring at the host, if we are able to recover the data or reconstruct it with minimum error, the accuracy can easily be increased.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Our approach con- siders the mentioned state-of-the-art optimizations and on top of that exploits the natural affinities among experts, routers, composition functions, data, and hardware to synergistically boost training/inference. In the direction of fault tolerance, there are works on various checkpointing [102, 162] strategies so that system gracefully comes out of failure with minimum loss of progress. LLM Hardware and Accelerators:  These sophisticated system level strategies require the use of equally high-performing hardware to complement for faster, efficient and economic implementation for both train- ing and inferring from these models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "https://cloud.google.com/ functions/docs/. Google Cloud Functions. [17]  February 2018.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "ZED Software Development Kit. [60]  techradar. \"https://www.stereolabs.com/developers/release/\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "Ties occur when two sets of equal number of models predict a different result. The effectiveness \n1046    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nAlgorithm 2  Predictive Weighted Instance Auto Scaling \n1:  procedure  W EIGHTED _A UTOSCALING ( Stages ) 2: Predicted_load  ‚Üê DeepARN_Predict (load) 3: for  every Interval  do 4: for  model in  ‚àÄ Models  do 5: model weight  ‚Üê get _ popularity ( model ) 6: Weight . append ( model weight ) 7: end for 8: end for 9: if  Predicted_load  ‚â• Current_load  then 10: for  model in  ‚àÄ Models  do 11: I_n  ‚Üê (Predicted_load - Current_load) √ó model weight 12: launch_workers ( est_VMs ) 13: model.workers.append ( est_VMs ) 14: end for 15: end if 16:  end procedure \nof weighted voting in breaking ties is discussed in Section  6 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 253,
    "augmented": false
  },
  {
    "text": "Deploying sufÔ¨Åcient battery resources to allow intermittency-unaware designs to operate on solar power is neither efÔ¨Åcient nor sustainable. C. Hyperparameters: The Right Way to Learn \nAfter Ô¨Ånalizing the training set for continuous learning, the next challenge is to learn within the power and time budget. Given enough time even na¬®ƒ±ve low power hardware can Ô¨Ånish training, but will have longer periods where the drift is exposed.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "In fact, our proÔ¨Åling shows that RAHT takes around 2 seconds to process a typical frame with around 1M points, on a typical edge device. III-B , which indicates that the locality revealed by \nthe Morton codes does not only exists among the geometry data, but it can also help with the attribute compression. Towards addressing this signiÔ¨Åcant performance inefÔ¨Å- ciency, we investigate the insight from the above discussion in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Neural Network Models:  We examine two DNN models in our experiments: YOLOv3 [44] and YOLOv4-tiny [37]. The input shape for both of them is  1 √ó 416 √ó 416 √ó 3 . The former one is a quite heavy model, with 106 layers and 65.86 Bn FLOPS, whereas the latter one is a lighter model, with 38 layers and 6.94 Bn FLOPS.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:1905.03854 , 2019. Sahidul Islam, Jieren Deng, Shanglin Zhou, Chen Pan, Caiwen Ding, and Mimi Xie. Enabling fast deep learning on tiny energy-harvesting iot devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Or, in training, new memory blocks can be spawned to support the higher KV-caching needs. During the occurrence of a fault, prior known works can be used to checkpoint and migrate the execution to a newly spawned chiplet. Further, based on our profiling of the communication behavior across chiplets and chips, we will consider performant and adaptive interconnect designs [80, 81, 110, 116, 127] to co-optimize for latency, bandwidth, and fault tolerance.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "[62]  Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Brad- bury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Ieee, 2005. In  2005 IEEE interna- tional conference on systems, man and cybernetics , volume 3, pages 2340‚Äì2345.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "If it detects requests whose wait times exceed the cost of spawning a new container (the cold start of the function), overloading is said to have occurred at the stage. This is because requests that have to wait longer than the cold start would be served faster at a newly created container than by waiting at an overloaded container. In such a scenario,  Kraken batches these requests (# _ ùëëùëíùëôùëéùë¶ùëíùëë _ ùëüùëíùëûùë¢ùëíùë†ùë°ùë† in Algorithm 2) onto a newly-spawned container(s) (Algorithm 2  c  ).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Second Version of HoloLens HPU will Incorporate AI Coprocessor for Implementing DNNs. 2020. [32]  Microsoft Research Blog.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "They do not seem to leverage the fact that the transformation matrices are unique for each head orientation and memoizing them will save re-calculating the transformation matrix ( T  ) as well as the projection matrix ( P ). ‚Ä¢  Even if they do realize such opportunities, the projection matrix ( P ) is very big ( ‚âà 8 MB , details in Sec. IV-C), and one edge VR headset cannot afford to memoize them for all  possible head orientations.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Our proposal introduces an  Ensemble of Experts (EoE)  framework that embodies this co-design philosophy. How do we get there? These observations call for a holistic hardware-software ‚Äúco-design‚Äù that integrates efficient expert models with custom system support and reconfigurable hardware architectures, to optimize performance, while minimizing resource consumption.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Predicting future energy intake is challenging, so each sensor employs an estimator   ÀÜ E i ( t  + 1)  to anticipate its upcoming energy resources. Prior to deployment, a global inference model  f Œ∏  is trained offline on representative data and distributed to each sensor. Incorporating uncertainty-aware models or robust estimation techniques is beyond the scope of this paper.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Previous studies have observed that the computation in  360 ¬∞ video processing is, mainly, the  projection transformation  [28]. These observations motivate us to explore the potential opportunities for reducing the power/energy consumption in the  projection  stage. We illustrate the  360 ¬∞ video projection/projection transfor- mation 3   computation in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "[78] J. Salamon, C. Jacoby, and J. P. Bello, ‚ÄúA dataset and taxonomy \nfor urban sound research,‚Äù in  22nd ACM International Conference on Multimedia (ACM-MM‚Äô14) , Orlando, FL, USA, Nov. 2014, pp. [77] M. S. rutgers.edu, ‚ÄúSupport for trafÔ¨Åc cameras increases if used as a tool to limit interactions with police,‚Äù https://www.rutgers.edu/news/support-trafÔ¨Åc-cameras-increases-if- used-tool-limit-interactions-police , (Accessed on 04/28/2023). 1041‚Äì 1044.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "In fact, there may still be another level of opportunity for approximating the objects in long distance ( Intra-Holo , shown in Fig. 5c). To lever- age this opportunity, we need to know where the user is located in the world and what the objects in the world look like [ 13 ,  19 ,  53 ,  59 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "4 DESIGN IMPLEMENTATION OF  SEEKER \nBy leveraging the coreset construction techniques discussed in Section 3, we design  Seeker: A synergistic sensor host ecosys- tem . Although, the training of the GAN is complex and involves multiple networks as well as hyper-parameters tun- ing, the generator network itself is very small ( few hundred thousands  of parameters depending on the sensor data). The recovery policy can be implemented as a simple generator network in the host.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Azure Functions Cold Starts. https://mikhail.io/serverless/ coldstarts/aws/. [14]  2021.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "Azure Low priority batch VMs., February 2018. https://docs.microsoft.com/en-us/azure/batch/batch-low-pri-vms . [8]  Amazon. EC2 C5 Instances., February 2018. https://aws.amazon.com/ec2/instance-types/c5/ .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "This is because the models which offer higher accuracy are typically dense and hence, smaller ensembles are sufÔ¨Åcient. In Fig- ure  14b , we vary the accuracy under six different constant latency categories. It can be seen that for higher accuracies, Cocktail  tries to ensemble more models to reach the accuracy, while for lower accuracy it resorts to using single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "ISBN 9781450394215. doi: 10.1145/3544548.3581045. 3581045 . URL  https://doi.org/10.1145/3544548.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "71  on average) for VR video applications [26], [62]. General Applicability of D¬¥ej`a View : The above discussion assumes that the Equirectangular format [52] is used to represent the  360 ¬∞ videos. We want to emphasize that our underlying ideas behind the proposed  EA  and  AE  (designed for the Equirectangular format) can work irrespective of the representation formats used [48].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Especially, many levels of dependencies (i.e, various regularities of locks) exist in their pipelines ‚Äì e.g., the entire octree needs to acquire a ‚Äúmacro lock‚Äù before inserting a point and updating the tree (as shown in Fig. 5 ), during the intra-frame geometry compression; similarly, in the attribute compression shown in Fig. 6 , the points at one layer in the octree have dependencies with those at other layers, thus their processing requires acquiring locks at a ‚Äúlayer granularity‚Äù.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "Such an- alytics are critical for virtual/augmented reality, object recog- nition/detection for surveillance, commercial advertisement insertion/deletion, synopsis extraction, and video querying. To enable such analytics, current devices rely heavily on deep \n* Work was done while at Penn State. eural networks (DNNs).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "We implement each ap- plication as a workflow of chained functions in  OpenFaaS . To model the characteristics of the original functions, we invoke sleep timers within our functions to emulate their execution times (including the time for state recovery, if any). Transitions between functions are done using function calls on the basis of pre-assigned inter-function transition proba- bilities.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "0 200 400 600 800 1000 1200 \n1 2 4 8 16 32 64 \nExec. Latency (ms) \n# Depth Planes \nForward Backward \n(b) Latency w/ num of depth planes. Figure 4: Depthmap hologram algorithm details.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "In comparison,  Comm Only  and  Conn Only  fail to spawn enough containers for each important function as they do not consider both these parameters, resulting in increased tail latency and exacerbates the SLO violations. This difference, in terms of percent of SLO violations, changes from being at most 0.1% to being between 0.1 to 0.35%. This is a result of  Kraken  being more resilient at the tail of the response time distribution as it uses both  Commonality  and  Connectivity  while spawning containers.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "The superior performance of NExUME can be attributed to its unique integration of energy variability awareness directly into both the training (DynFit) and inference (DynInfer) processes. Unlike other methods that either focus on modifying the DNN architecture or optimizing inference configurations, NExUME adapts the DNN‚Äôs computational complexity in real-time based on instantaneous energy availability, leading to more efficient use of scarce energy resources and improved accuracy. Dataset Platform Energy Source Stateful ePerceptive DynBal NExUME \nFMNIST MSP430FR5994 Piezoelectric 20.1 20.8 21.5 23.4 CIFAR10 Arduino Nano Thermal 16.0 16.5 17.0 18.5 MHEALTH ESP32 S3 Eye Piezoelectric 18.5 19.0 19.6 21.0 PAMAP STM32H7 Thermal 16.5 17.0 17.5 19.0 AudioMNIST Raspberry Pi Pico Piezoelectric 20.5 21.0 21.7 23.2 Table 2: Energy efficiency comparison on different hardware platforms.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 232,
    "augmented": false
  },
  {
    "text": "https://www.xilinx.com/applications/ data-center/computational-storage/smartssd.html , b. (Accessed on 07/13/2023). AMD and Xilinx.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "USENIX Association. [155] The New York Times. Amazon, google, microsoft turn to nuclear energy.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 26,
    "augmented": false
  },
  {
    "text": "Kraken  is seen to reduce con- tainer overprovisioning when applications have numerous possible workflows and enough slack per function to exploit. Figure 14 plots the con- tainers spawned versus the SLO guarantees for each appli- cation for all traces. The simulator results closely correlate to those of the real system.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "For the remaining frames however, we invoke Algo. 1 to make the frame-level decision (i.e., either do the full inference or skip) 3 . When skipping, we can simply bypass the inference task by reusing  the inference result from the last frame; otherwise (i.e., if cannot skip), the full inference has to be performed for the current frame, in the same fashion as in the baseline.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "\"https://www.gazept.com/\". [13]  Patrick Geneva, Kevin Eckenhoff, Woosik Lee, Y. Yang, and Guoquan Huang. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "We will maintain a repository of LLM experts that are independently trained, from which we can select and modify to form an ecosystem of LLM experts for complex tasks in continually evolving usage scenarios. Under each type, there can be subtypes of ex- perts. For example, there can be different subtypes of sci- ence experts for different sci- entific disciplines.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "However, these schemes do not address the holis- tic problem by taking into account model selection, resource selection, and resource scaling to cope up with user-specified constraints. We name this scheme as  mixed  pro- curement. Prior works  [ 5 ,  10 ] try to hide the pro- visioning latency of VMs by using  server- less functions  as a handover mechanism when starting new VMs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pages 745‚Äì760, 2024. { MegaScale } : Scaling large language model training to more than 10,000  { GPUs } . [76] Norm Jouppi, George Kurian, Sheng Li, Peter Ma, Rahul Nagarajan, Lifeng Nai, Nishant Patil, Suvinay Subramanian, Andy Swing, Brian Towles, Clifford Young, Xiang Zhou, Zongwei Zhou, and David A Patterson.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "https://mikhail.io/serverless/ coldstarts/aws/. [13]  2021. AWS Lambda Cold Starts.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "[121] Julius Odede and Ingo Frommholz. In  Proceedings of the 2024 Conference on Human Information Interaction and Retrieval , pages 391‚Äì395, 2024. Jaybot‚Äìaiding university students and admission with an llm- based chatbot.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "14 347‚Äì14 357, 2017. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. 906 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "7 √ó  less in comparison to the original 240 Bytes needed to communicate the raw data in our setup. However, since clustering based coreset construction is more expensive than the importance sampling based coreset construction, it is not always possible to build a recoverable coreset at the edge, unless we figure out a to recover the lost points while we perform importance sampling. The addition of the recovery parameter (number of points per cluster) needs  4 more bits (in our experiments, we never observe any clusters having more than 16 data points) of data per cluster, bringing the total data communication volume to  42 Bytes , which is still a significant 5 .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "Notation Meaning T Transition Matrix P ùëë Probability Vector for functions at depth,  d n # functions in application or # states in model f  ùëñ ,  f ùëó functions along row,  i  or column,  j  in  T t  ùëóùëñ Transition probability from  f  ùëó ùë°ùëú f ùëñ W ùëù Probability calculation time window t Request arrival time d # time steps for which transitions are done PL ùë° Scalar that represents the anticipated # requests at time,  t NC ùëë ùë° # containers needed for functions at depth  d , at time  t Table 3: Notations used in Equations. by performing a summation of  ùëÅùê∂ ùëë ùë° across all possible depths, ùëë , from the start function. We can now transform our previously-assumed Markov Model into a VOMM by splitting up context-dependent states into multiple context-independent states (the number of which is dependent on the DAG structure and the order of the VOMM).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 228,
    "augmented": false
  },
  {
    "text": "The second input is the decoded  360 ¬∞ frame that contains the pixel values. The decoded  360 ¬∞ frame is fed to the Projection Mapping stage, which uses the projection matrix, locates the coordinates in the decoded  360 ¬∞ frame, and moves their pixel values to the transformed 2D coordinates in the FoV frames. It is to be noted that, when a user‚Äôs head orientation is changed, the Projection Computation stage needs to  recompute the transformations to reÔ¨Çect the user‚Äôs head movement.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "However, there has been signiÔ¨Åcant recent development in portable wind turbines [ 96 ], which can be deployed on rooftops, can work with  ‚â• 5 mph  wind speed, and can provide power equivalent of 15 solar cells. Deployment Training Completed \nMean Power Consumed (W) \nMean Power \nWasted (W) \nCarbon Footprint (lbs/yr) Us. Therefore, similar technologies can be used to augment the harvesting mechanism.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Proceedings of Machine Learning and Systems , 1:374‚Äì 388, 2019. [3] Luis M. Candanedo, V¬¥eronique Feldheim, and Dominique Deramaix. Data driven prediction models of energy use of appliances in a low-energy house.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Compute time (seconds) and Memory allocated (GB) is shown on left Y-axis. Cost ($) is shown in right Y-axis. Observation 3:  Only-VM based resource procurement should not be used during dynamic load as it leads to over-provisioned resources and increased cost.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "We assume the output to be correct if majority of them, i.e. ‚åä N / 2 ‚åã + 1  of them give the same result. Then, the Ô¨Ånal ac- curacy of this ensemble would be the probability of at least ‚åä N / 2 ‚åã + 1 of them giving a correct result.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "The configuration of the server with Xilinx CSD has a 12-core Xeon bronze CPU with 128GB memory,  2 √ó 3.84TB CSDs, and  2 √ó 2TB SSDs. Similarly, the AWS server has 24 cores, with 192GB memory, one Alveo FPGA and 2TB SSDs. 0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \nKitti Vision nuScenes Chime Cityscapes Waymo \nNormalized Latency \nCompute Server CSD Alveo FPGA \nFigure 4: Latency analysis of  Salient Store  on the commercial Xilinx CSD on a workstation class machine (lower is better).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "[19]  M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, ‚ÄúRedesigning software and systems for non-volatile processors on self-powered devices,‚Äù in  2016 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC) , pp. 1‚Äì6, Sep. 2016. [20]  L. Ni, Z. Liu, H. Yu, and R. V. Joshi, ‚ÄúAn energy-efÔ¨Åcient digital ReRAM-crossbar-based cnn with bitwise parallelism,‚Äù  IEEE Journal on Exploratory Solid-State Computational Devices and Circuits , vol.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": "Power Failure and Compute Scheduling \nCentral to the  Us. ¬¥as  accelerator‚Äôs operational efÔ¨Åciency is the work queue‚Äîan intricately designed, hierarchical structure that meticulously catalogues pending computational tasks. Each task, represented in the queue, corresponds to the execu- tion of speciÔ¨Åc CNN kernels, feature tiles and operations.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "2020. Pok√©mon GO Revenue and Usage Statistics. \"https: //www.businessofapps.com/data/pokemon-go-statistics/\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "A variety of other grid computing resources are also freely available to their re- search groups. For example, Kandemir‚Äôs lab has CAPI-capable FPGA resources integrated into IBM Power servers for modeling of emerging accelerator and chiplet resources and software licenses for the HLS and EDA flows needed to generate new accelerator and chiplet models and deploy them on this platform. CSE Department Resources: The Department of Computer Science and Engineering (CSE) at Penn State uses a network of Linux, OS X, and Windows workstations and servers to support academic com- puting needs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Definitions of different affinities:  Expert‚ÄìExpert:  the tendency of certain experts to be used more frequently together to serve a request;  Expert‚ÄìData:  the tendency of similar experts to use a common subset of training data;  Expert‚ÄìRouter:  the tendency of given experts and routers to be used together frequently to serve different requests and to share a subset of training data. When two \nAffinity Optimization Stage Tasks \nTraining Inference Algorithm System Architecture \nExpert‚ÄìExpert ‚úì ‚úì Task 1.2, 1.3, 1.4 Task 2.1, 2.3, 2.5 Task 3.2 Expert‚ÄìData ‚úì Task 1.1, 1.3 Task 2.1, 2.5 Expert‚ÄìRouter ‚úì Task 1.2, 1.3 Task 2.2, 2.5 Task 3.3 Expert‚ÄìComposition Function ‚úì ‚úì Task 1.2, 1.3 Task 2.3, 2.5 Expert‚ÄìAccelerator ‚úì ‚úì Task 1.4 Task 3.2 \nTable 2 :  Overview of affinities in the proposal. As a user query can be possibly answered by different sets of experts, we will choose experts based on the combination of two factors: (1) The relevance of expert to the user query, and (2) the availability of accelerator (developed in Thrust 3) for the expert.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 270,
    "augmented": true
  },
  {
    "text": "However, they may not fully exploit the potential for collaboration among sensors or account for the strategic interactions inherent in decen- tralized networks. These strategies aim to balance energy expenditure with the need for timely and accurate data, often using heuristic or optimization-based approaches. 2 \n110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 \n2.3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 167,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2310.16795 , 2023. [47] Gerasimos Gerogiannis, Sriram Aananthakrishnan, Josep Torrellas, and Ibrahim Hur. Hottiles: Ac- celerating spmm with heterogeneous accelerator architectures.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Increasing Geometry Compression Parallelism Using Morton Code:  As mentioned earlier, the reason why the ‚Äúsequential update‚Äù is necessary is that, during the interme- diate stages, the  global  Octree (the Ô¨Ånal tree constructed at the last step) is unknown until the last point is inserted in the tree. As a result, these points can processed in  parallel . To relax this constraint, if the PCs can be  sorted based on a geometrical order, then the topographic structure of the global tree can be known at the beginning, thus Ô¨Åxing the tree structure and not requiring to be updated in a point-by-point fashion.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "Unlike simple heuristic meth- ods that ignore future resource allocation or complex ap- proaches like reinforcement learning that may be too costly to implement, game theory provides equilibrium guaran- tees. By modeling each sensor as a rational player aiming to optimize its own long-term utility, we achieve stable, coop- erative equilibria where no sensor can improve its outcome through unilateral deviation. This strategic equilibrium un- derpins both training and inference participation decisions, ensuring that the sensors most likely to improve the global \n1 \n055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071 072 073 074 075 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109 \nmodel‚Äîgiven their energy, data quality, and network condi- tions‚Äîare the ones that engage.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 269,
    "augmented": true
  },
  {
    "text": "However, in a continuous learning paradigm, training be- comes an essential, repeatedly scheduled task whose computa- tional and time costs cannot be considered a one-time overhead freely delegated to the cloud. A recent work, Ekya [ 12 ], has demonstrated that edge servers equipped with GPUs are capable of performing the necessary tasks for continuous learning within their form-factor-imposed resource constraints, provided that those resources are intelligently managed. Sustainable  Continuous Learning at the Edge:  Even given such advancements in continuous learning on edge servers, provisioning training resources at the edge for every sensing- to-analytics application entails sustainability questions.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "Let  e op  denote the energy consumed per computational operation, which varies with operation type and data precision. The total energy consumption of a QuantaTask  q  is modeled as  E q  =  e op  √ó  ‚Ñì q , where  ‚Ñì q  is the number of operations in the task. By integrating the energy model into the training process, DynFit ensures the adjustments to dropout and quantization directly correspond to actual energy savings on the target hardware.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "[168] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis. Efficient streaming lan- guage models with attention sinks. arXiv , 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "[8] Niket Agarwal, Tushar Krishna, Li-Shiuan Peh, and Niraj K Jha. Garnet: A detailed on-chip network model inside a full-system simulator. In  2009 IEEE international symposium on performance analysis of systems and software , pages 33‚Äì42.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "In \n246 \nTABLE II: Video workloads. 2a). Potentially, content-based optimizations (e.g., content cache [63]) can beneÔ¨Åt the data transfer; however, they are not attractive candidates to leverage compute reuse, which is the major power-hungry stage (as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "A. Preamble to Origin \nHuman activity has temporal continuity, i.e. Therefore, there is an opportunity to skip some intermediate inferences over the period of an activity in order to increase harvesting duration and the prob- ability that an initiated inference will complete. most activ- ities last for some duration (in the range of hundreds of milliseconds to seconds).",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "2 Yaw: vertical; Pitch: side-to-side; Roll: front-to-back. Previous studies have observed that the computation in  360 ¬∞ video processing is, mainly, the  projection transformation  [28]. power consumption, constituting  59% .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "[26]  J. Hu, A. Shaikh, A. Bahremand, and R. LiKamWa, ‚ÄúCharac- terizing real-time dense point cloud capture and streaming on mobile devices,‚Äù in  Proceedings of the 3rd ACM Workshop on Hot Topics in Video Analytics and Intelligent Edges , 2021, pp. 1‚Äì6. 296 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "We have had continuous partnership with the CSATS faculty for over 5 years and have hosted \nday-long seminars for middle school and high school teachers as part of our prior NSF funded outreach efforts. In particular, we plan to visit along with a couple of our trained undergraduate and graduate stu- dents to local middle and high schools and talk to students about the exciting opportunities in computing discipline. A selected group of undergraduate students and volunteers from CRA-W, ACM, and Girls Who Code programs will be trained to go to these schools and talk to students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Kraken achieves one of the lowest energy consumption rates among all the policies considered, with it bettering existing policies, namely,  Arch ,  Fifer  and  Xanadu  by 26%, 14% and 3% respec- tively (for the workload mix of  Media Service  application with Wiki trace) as depicted in Figure 13a. These savings can go up to 48% compared to  Arch  for applications like  Social Network . Energy Efficiency:  We measure the energy-consumption as total Energy consumed divided over total time.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "[39] Oculus, ‚ÄúOculus Rift and Rift S Minimum Requirements and Sys- tem SpeciÔ¨Åcations.‚Äù ‚Äùhttps://www.tomshardware.com/news/magic-leap- tegra-specs-release,37443.html‚Äù, 2019. [40] OpenCV, ‚ÄúSimilarity check (PNSR and SSIM) on the GPU.‚Äù ‚Äùhttps://docs.opencv.org/2.4/doc/tutorials/gpu/gpu-basics- similarity/gpu-basics-similarity.html‚Äù, 2019. [41] OpenGL, ‚ÄúCubemaps - Learn OpenGL.‚Äù ‚Äùhttps://learnopengl.com/ Advanced-OpenGL/Cubemaps‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 191,
    "augmented": true
  },
  {
    "text": "5 and carefully consider our design decisions. Here, we partition the output FM regions into three categories ‚Äì  a  inner part,  b  middle part, and \nc  outer part. a  is the region where the convolution kernel only multiplies with the pixels in RoIs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:1909.11942 , 2019. Albert: A lite bert for self-supervised learning of language representations. [52]  Yunseong Lee, Alberto Scolari, Byung-Gon Chun, Marco Domenico Santambrogio, Markus Weimer, and Matteo Interlandi.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Power Failure and Compute Scheduling \nCentral to the  Us. ¬¥as  accelerator‚Äôs operational efÔ¨Åciency is the work queue‚Äîan intricately designed, hierarchical structure that meticulously catalogues pending computational tasks. Each task, represented in the queue, corresponds to the execu- tion of speciÔ¨Åc CNN kernels, feature tiles and operations.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "We plan to provide hands-on computer architecture experience to students and show them how modern computer systems can address important societal challenges, specifically how LLMs can be used in many such domains. PI Zhang has offered an NSF REU seminar and mentored an NSF REU student on a project investigating the intersection of LLMs and code generation. The PIs will leverage their complementary experience in developing appropriate research thrust areas within the scope of LLM to attract and engage a new cohort set of minority undergraduate students in research.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "3) Our proposed policy,  Origin , combines an adaptive conÔ¨Å- dence matrix and the activity aware scheduler to perform efÔ¨Åcient and accurate classiÔ¨Åcation. 4) Finally, we provide a detailed evaluation of  Origin , and show that, even when powered by an unreliable EH source, the efÔ¨Åciency achieved by the this system results in better accuracy than that of a fully powered system running state of the art classiÔ¨Åers optimized for energy efÔ¨Åciency. The adaptive conÔ¨Ådence matrix, which weights the output of each sensor depending upon the classiÔ¨Åcation result, is updated on each successful classiÔ¨Åcation.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Redis in action . Manning Publications Co., 2013. [17]  Rich Caruana, Alexandru Niculescu-Mizil, Geoff Crew, and Alex Ksikes.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "10b , with fewer ‚Äúdirect-reuse‚Äù blocks (e.g., only  31%  of the I-blocks are directly reused in the left-most bar), the PSNR drops slightly when compared to the intra- frame compression, while the compression ratio is also the worst. On the other side, by increasing the percentage of the ‚Äúdirect-reuse‚Äù blocks, the compression efÔ¨Åciency also increases, at the cost of a PSNR degradation (e.g., the PSNR reduces to  38 dB with 83 %  ‚Äúdirect-reuse‚Äù blocks). Hence, to enhance the Ô¨Çexibility of our proposed design for trading off the compression efÔ¨Åciency with the quality, we can use the  percentage of ‚Äúdirect-reuse‚Äù blocks  as a  tunable design knob , for which, users can choose the appropriate value based on their preferences (i.e., fewer ‚Äúdirect-reuse‚Äù blocks with higher PSNR vs. more ‚Äúdirect-reuse‚Äù blocks with higher compression efÔ¨Åciency).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 222,
    "augmented": false
  },
  {
    "text": "While the previous research has suggested the idea of integrating analytics into storage systems, these discussions usually revolve around system architecture, scheduling, and data management, without delving into the requisite compute capabilities (Haynes et al., 2021; Daum et al., 2021; Tsai et al., 2020; Xu et al., 2019). 2.4 More Compute in Storage? Why Not?",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "DynFit, with its stochastic dropout features, occasionally leads to overfitting, necessitating meticulous fine-tuning. While effective in smaller networks, our studies involving larger datasets (such as ImageNet) and more complex network architectures (like MobileNetV2 and ResNet) reveal challenges in achieving convergence without precise fine-tuning. DynFit tends to introduce multiple intermediate states during the training process, resulting in approximately 14% additional wall-time on average.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "‚Ä¢  We go beyond the compute and look into future-proofing the storage server by equipping it with quantum safe lattice-based encryption technique. We maximize the hardware utilization by reusing compute kernels from the compression pipeline. We detail the design of the hardware accelerated encryption and maximize the resource reuse between the exemplar selection and encryption.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Unlike con- tinuous on-edge training, we employ periodic or triggered fine-tuning sessions aligned with equilibrium strategies, en- suring robust and progressively improving global models. ‚Ä¢  Joint Optimization of Training and Inference:  Our unified solution aligns training participation decisions with inference needs. Sensors strategically decide when to ex- pend energy on local model updates and when to engage in inference tasks, ultimately maximizing their long-term contribution to the network‚Äôs performance.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution. For each computation mode, we can derive the optimal activation solutions under each power level directed by the  power model  and  throughput model  ofÔ¨Çine. These knobs can be integrated to form sequential or pipelined computation modes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "In  Acm Sigplan Notices . ACM, 2016. [2]  Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "However, for other functional units, we assign a Ô¨Åxed latency. For the ReRAM circuit simulation, we quantify power and performance of our design in HSPice [ 38 ] using 20nm \nFinFET ReRAM parameters from [ 39 ]. Load/store parameters of the ReRAM memory are from NVSim [ 40 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Figure 5: Performance of  Salient Store  on larger compute and storage nodes. This experiment to mimics a consolidated edge server catering to many video streams. Compute server indicates a software only classical storage solution without CSDs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. 907 \nAuthorized licensed use limited to: Penn State University. 8697‚Äì8710.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "First, it maintains dedicated instance pools to serve indi- vidual models which simpliÔ¨Åes the management and load balancing overheads for every model. Next, the resource con- troller  4  handles instance procurement, by exploiting both CPU and GPU instances  4a  in a cost-aware  4b  fashion, while the load balancer  5  ensures all procured instances are bin- packed by assigning queries to appropriate instances. We also design an autoscaler  6  , which utilizes a prediction pol- icy  6a  to forecast the request load and scale instances for every model pool, thereby minimizing over-provisioning of resources.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "[14]  Giorgia Lombardo. 2020 IEEE International Conference on Robotics and Automation (ICRA)  (2020), 4666‚Äì4672. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "Efficient Scheduling:  DynInfer‚Äôs energy-aware task scheduling and task fusion mechanisms reduce overhead from checkpointing and optimize the execution of tasks within \n8 \nthe available energy budget. 4. Holistic Approach:  Unlike other methods that focus on either training or inference optimizations, NExUME provides a comprehensive solution that addresses both phases, leading to superior overall performance.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "B ¬¥ edorf, E. Gaburov, and S. P. Zwart, ‚ÄúA sparse octree gravitational n-body code that runs entirely on the GPU processor,‚Äù  Journal of Computational Physics , pp. 2825‚Äì2839, 2012. [6]  M. Beg, Y. C. Chang, and T. F. Tang, ‚ÄúPerformance evaluation of error resilient tools for mpeg-4 video transmission over a mobile channel,‚Äù in  2002 IEEE International Conference on Personal Wireless Communications , 2002, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Imagenet: A large-scale hierarchical image database. In  2009 IEEE Conference on Computer Vision and Pattern Recognition , June 2009. [30]  Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "By prioritizing energy efficiency and system adaptability, NExUME contributes to the sustainability and accessibility of machine learning solutions, enabling their deployment in regions where power infrastructure is absent or unreliable. This is particularly crucial in developing regions where such technology can drive innovation in healthcare, agriculture, and education. Furthermore, the development of energy-efficient, adaptive systems like NExUME is aligned with the growing need for sustainable computing practices across all disciplines of technology.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Through offline profiling or initial runs, we can de- termine the right memory allocation for a given response latency. From our observations in  AWS Lambda , three types of cores are allocated in the increasing order of the memory allocation ( 0.5GB, 1.5GB, and  > 2GB ). Also, these policies can be changed over time by Amazon, and they can also be dif- ferent for other cloud providers [ 8 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "[54]  Liang Shi, Beichen Li, Changil Kim, Petr Kellnhofer, and Wojciech Matusik. 2021. Towards Real-time Photorealistic 3D Holography with Deep Neural Networks.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "The main reason for this is that the  ResiSchedule  policy can efÔ¨Åciently organize more hardware resources than the  Sequential  policy when hardware resources are limited. 0.00 0.20 0.40 0.60 0.80 1.00 1.20 1.40 1.60 \nG1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 \nPV HG LeNet FR \nNaive2 Sequential Pipelining ResiSchedule \nFig. 12.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "The tail latency of  Kraken , in comparison, grows slower and remains within the target SLO. Comm Only  and  Conn Only  are seen to exceed the target SLO at the 99th percentile. 6.2 Simulator Results Since the real-system is limited to a 160-core cluster, we use our in-house simulator, which can simulate an 11k-core cluster, to study the scalability of  Kraken .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture , pp. 224‚Äì238, 2019. Michael Mesnier.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "6 , the points at one layer in the octree have dependencies with those at other layers, thus their processing requires acquiring locks at a ‚Äúlayer granularity‚Äù. Even with the optimizations in [ 33 ], where the octree construction stage can be performed in parallel, there are still several synchronization points, resulting to limited parallelism. To summarize, the performance inefÔ¨Åciencies in prior works can be primarily attributed to the lack of parallelism of these algorithms.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "99‚Äì108, 1996. AMD. In  Proceedings of the twenty-eighth annual ACM symposium on Theory of computing , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "In  USENIX annual technical conference , 2010. [47]  Minoru Kawashima, Charles E Dorgan, and John W Mitchell. Hourly thermal load prediction for the next 24 hours by arima, ewma, lr and \n1054    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nan artiÔ¨Åcial neural network.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "07] . The accuracy of both system might be identical (over a large number of test sets), yet for the current test case, both the models are not equally conÔ¨Ådent about the classiÔ¨Åcation. Both the models have classiÔ¨Åed the input to be of class  o 1 .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Forward pass:  Each participating sensor collects data ( x, y )  and evaluates  ‚Ñì ( f Œ∏ k ( x ) , y ) . 10 \n550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 \n2. Backward pass:  The sensor computes  ‚àá Œ∏ ‚Ñì ( f Œ∏ k ( x ) , y ) via standard backpropagation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 193,
    "augmented": true
  },
  {
    "text": "Task-1.2: Constructing Morphology of Ensemble of Experts. Task-1.3: Continual Adaptation of EoE through Morphable LLM Experts. Task- 1.4: Algorithmic Choices Informed by System and Hardware Constraints.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "In an effort to optimize video compression beyond traditional and current neural codec capabilities, we introduce an enhanced layered neural codec that utilizes both intra-frame and inter-frame redundancies. 8 \nAlgorithm 1  Neural Encoding and Compression using the video data inference pipeline. Our approach extends the layered neural codecs by incorporating motion vectors as a latent space, akin to the macroblock techniques used in H.264, to maximize inter-frame compression efficiency.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Efficient dnn execution on intermittently-powered iot devices with depth-first inference. Mingsong Lv and Enyu Xu. IEEE Access , 10:101999‚Äì102008, 2022.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "AMD and Xilinx have intro- duced specialized tools and libraries designed to harness CSDs (AMD, a; AMD & Xilinx), enabling peer-to-peer PCIe transactions that bypass the CPU (AMD & Xilinx). Decoupling compute tasks needed for storing the data from the host CPU and embedding them directly within storage devices, particularly through CSDs, has demonstrated significant performance and energy benefits. The emergence of Compute Express Link (CXL) technology (Sharma, 2022a,b; Jung, 2022) further amplifies the potential of disaggregated storage and memory systems.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "We used  5 √ó AWS EC2 F1 instances with Alveo FPGAs as storage nodes, along with one EC2 P4 instance with A100 GPUs as the compute server. Since majority of the storage systems are not limited to one storage server, but are spread across multiple servers, we scaled  Salient Store  by deploying it in a distributed fashion. We do not observe much change in the data volume.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "3 DESIGN SPACE EXPLORATION Since data communication in a sensor host ecosystem (Fig- ure 3) consumes substantial power, we rely on coresets as an efficient way to lossily communicate the features with minimal information degradation. The coreset construction techniques need to be extremely lightweight while preserv- ing key features to justify the computation-communication trade-offs in energy and latency. To this end, we explore two different kinds of coreset construction techniques.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "103‚Äì118, Renton, WA, April 2022b. USENIX Association. ISBN 978-1-939133-27-4.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Fig. 5a  shows the block diagram of the mesh interconnect, and Fig. 5b  shows the power-down sequence and signal states.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Simi- larly, the pixel value rendered at  [ x 0 r , y 0 r ]  on the right VR screen \n247 \n0 \n2 \n4 \n6 \n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \nAvg. The pixel rendered at  [ x 0 l   , y 0 l   ]  on the left VR screen is mapped from position  [( x 360 ) 0 l   ,  ( y 360 ) 0 l   ] on the equirectangular  360 ¬∞ frame, as shown in Fig. 6a.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "Thus, the inner part of the output is only related to the RoIs of input; the middle part is related to both the RoIs and the BG; and the outer part is only related to the BG. In  b  , the kernel is multiplied with both the RoI pixels and the non-RoI pixels (background region, i.e., BG), and Ô¨Ånally,  c  is where the kernel is only multiplied with the pixels inside BG region. a  is the region where the convolution kernel only multiplies with the pixels in RoIs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "Park, and J. Kung, ‚ÄúFlexblock: A Ô¨Çexible \ndnn training accelerator with multi-mode block Ô¨Çoating point support,‚Äù IEEE Transactions on Computers , 2023. [64] T. N. R. E. L. (NREL), ‚ÄúSolar resource maps and data,‚Äù  https://www. rel.gov/gis/solar-resource-maps.html , (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "8a  shows the number of layers trained for a DNN, in contrast to the ideal number of layers to achieve maximum accuracy. Fig. Over 10 training iterations, we observed the micro-proÔ¨Åler to be con- sistent with the oracle (except for one case of iteration 7).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "45‚Äì51, 2022. Hwajung Kim, Heon Y Yeom, and Hanul Sung. Understanding the performance characteristics of computational storage drives: A case study with smartssd.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "3) ,which can be projected to both eyes on the HMD. T 1 Rigid body No Compile-time Left = Right T 2 An eye‚Äôs view Yes Runtime Left = Right T 3 Eye adjusting No Compile-time Left  Ã∏ =  Right T 4 Perspective No Design-time Left = Right T 5 Viewport No Design-time Left = Right \ntheir corresponding  360 ¬∞ video frame coordinates. Finally, the third stage, i.e.,  Projection Mapping , uses the mapping results from the second stage and the  360 ¬∞ video frame to deduce the pixel values for 2D FoV frames (shown in  c  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "2017. Race-to-Sleep + Content Caching + Display Caching: A Recipe for Energy-Efficient Video Streaming on Handhelds. [68]  Haibo Zhang, Prasanna Venkatesh Rengasamy, Shulin Zhao, Nachiappan Chi- dambaram Nachiappan, Anand Sivasubramaniam, Mahmut T. Kandemir, Ravi Iyer, and Chita R. Das.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Let  e max total   = e max cap   + e inf   + e comm   represent the maximum energy cost (for a chosen SNR mode). Accuracy Gains and Costs: Let  ‚àÜ A min  and  ‚àÜ A max  de- note the minimum and maximum expected accuracy im- provements from any sensor‚Äôs participation. Formal Bounds and Conditions \nTo ensure balanced behavior, it is helpful to relate  Œ≥, Œ¥,  and Œ∑  to typical values of accuracy improvement and energy costs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Towards this, we plan to design a system-level scheduler which can efficiently partition the hologram tasks between the heterogeneous accelerator and original execution engines such as CPUs or GPUs. 6 RELATED WORK \nIn this section, we summarize prior work related to different aspects of holographic processing. Optimizations in Holographic Processing:  Holographic pro- cessing has been optimized in various domains [ 33 ,  35 ,  52 ,  54 ], to improve power efficiency or execution performance.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "7, when processing the six videos listed in Tab. 5.3 Experimental Results We present the power and energy consumption, as well as the execution latency of the hologram computation in Fig. 5.3).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Holdings, ‚ÄúWhite Paper: 360-Degree Video Rendering.‚Äù ‚Äùhttps://community.arm.com/developer/tools-software/graphics/b/ blog/posts/white-paper-360-degree-video-rendering‚Äù, 2019. 252 \n[22] A. [23] J. Huang, Z. Chen, D. Ceylan, and H. Jin, ‚Äú6-DOF VR Videos with a Single 360-camera,‚Äù  2017 IEEE Virtual Reality (VR) , pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 49th Annual International Symposium on Computer Architecture , pages 567‚Äì580, 2022. [6] Eleni Adamopoulou and Lefteris Moussiades. An overview of chatbot technology.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Moreover, these AR infotainment applications have helped many of us through the recent global pandemic by bringing us the liveliness of the virtual outdoors, while we were confined to our homes, and more AR capa- ble mobile devices penetrating the market with cheaper price tags have made AR applications pervasive and made the virtual world easily accessible for users on the tip of their fingers. However, even the state-of-the-art mobile devices with high bandwidth cannot meet the heavy compute and real-time demands of the AR applications, leading to very low quality of service (QoS) ‚Äì in some cases as low as 1 frame per second (fps) [ 19 ,  54 ]. Further, \n1 To give a quantitative estimation of the popularity of the game, a Pok√©mon GO event at Safari Zone New Taipei City, Taiwan in October 2019 had a total of 327,000 attendees and they walked around 4.5 million kilometers to catch 50 Million Pok√©mons [5].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 217,
    "augmented": true
  },
  {
    "text": "[33]  M. Courbariaux, Y. Bengio, and J.-P. David, ‚ÄúBinaryconnect: Training deep neural networks with binary weights during propagations,‚Äù in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 , NIPS‚Äô15, pp. 3123‚Äì3131, 2015. [34]  M. Alwani, H. Chen, M. Ferdman, and P. Milder, ‚ÄúFused-layer cnn accelerators,‚Äù in  2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "95% power reduction compared to the baseline. To better explain where the power benefits come from, we further breakdown the power consumption for the hologram processing into four parts: CPU (to handle sensor inputs, scheduling, kernel launch, etc. ), GPU (to execute hologram), Mem (for data accesses), and the SoC (the remaining hardware components, e.g., codec, network), with different number of depth planes (ranging from 2 to 16), as shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "4%  for YOLOv4-tiny. These results clearly show that our proposal is able to maintain high accuracy. 4) Model-SpeciÔ¨Åc Analysis:  To study how the inference behavior changes across different DNN models, we next compare the performance and the energy consumption of two DNN models used in this work (YOLOv3 and YOLOv4-tiny), and plot the results in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "22 \nCalculate the gradients of the loss with respect to the activations: \n‚àÇ L ‚àÇ a i \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the Taylor expansion approximation: \np i  = Œª \f\f\f  ‚àÇ L \n‚àÇ a i   a i \f\f\f  +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Compute the activations  a  and apply the dropout mask: \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 364,
    "augmented": true
  },
  {
    "text": "Algorithmic Advancements:  Us. By demonstrating the viability of a battery-less edge server for video analytics, Us.¬¥as spearheads the adoption of similarly sustainable systems for other do- mains. While the initial scope is limited to urban mobility applications, the concept‚Äôs adaptability extends to various domains, including autonomous driving, smart industries, and remote sensing: Section  V-D  performs an initial exploration of how techniques from Us.¬¥as will apply to other domains.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "2019. Nvgaze: An Anatomically-informed Dataset for Low-latency, Near-eye Gaze Estimation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Typically, the input feature maps are larger than the (individual) weights, and more importantly large weights can easily be represented \n897 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Here, the redundant experts should ideally be distributed across multiple nodes; ii) Isolated Training : In the event of changes to experts, our approach enables retraining by accounting for min- imum number of neighboring experts/routers; this will inherently facilitate fault tolerance, thereby allow- ing retraining of the EoE with minimum overhead in the event of expert failures; iii)  Checkpointing/Rollback Recovery : Techniques such as checkpointing weights/gradients periodically with rollback recovery in the event of expert failures can allow training to progress from the latest checkpoint (versus restarting the en- tire training); and finally, iv)  Dynamic Expert Re-routing:  In the event that an expert on one node fails, our system-level framework will communicate with the algorithm-level routers to dynamically decide which experts (on which node) should be used instead. Note that such system level fault-tolerant techniques will be augmented with hardware (chiplet)-level fault-tolerant techniques, described later in Task 3.4. 2.3 Thrust-3: A Chiplet-based Adaptive and Reconfigurable Hardware Platform Our proposed EoE-based LLM algorithm consists of a diverse set of building blocks with routers, experts, and composition functions, entailing heterogeneity in different stages of the application execution.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 305,
    "augmented": false
  },
  {
    "text": "[17] B. Haynes, A. Mazumdar, A. Alaghi, M. Balazinska, L. Ceze, and A. Cheung, ‚ÄúLightDB: A DBMS for Virtual Reality Video,‚Äù  Proc. [16] T. HARDWARE, ‚ÄúMagic Leap One Powered by Nvidia Tegra TX2, Available Summer.‚Äù ‚Äùhttps://support.oculus.com/248749509016567/‚Äù, 2019. VLDB Endow.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "494‚Äì496, 2018. [8]  F. Su, W. Chen, L. Xia, C. Lo, T. Tang, Z. Wang, K. Hsu, M. Cheng, J. Li, Y. Xie, Y. Wang, M. Chang, H. Yang, and Y. Liu, ‚ÄúA 462gops/j RRAM-based nonvolatile intelligent processor for energy harvesting ioe system featuring nonvolatile logics and processing-in-memory,‚Äù in  2017 Symposium on VLSI Technology , pp. T260‚ÄìT261, 2017.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Ali Saffari, Sin Yong Tan, Mohamad Katanbaf, Homagni Saha, Joshua R Smith, and Soumik Sarkar. Battery-free camera occupancy detection system. In  Proceedings of the 5th International Workshop on Embedded and Mobile Deep Learning , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "V-PCC 2   targets compressing PC videos. SpeciÔ¨Åcally, given a PC video stream, V-PCC Ô¨Årst performs 3D to 2D projection on each frame [ 29 ], [ 32 ], [ 39 ], [ 75 ], and then encodes these 2D projections via traditional 2D image codec. Both G-PCC and V-PCC are widely adopted in MPEG standard [ 53 ], and since our proposals begin with G-PCC, thus, is also compliant with the MPEG PCC standard.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "Following the multiplication, the two 18-bit products undergo separate modular reductions. 3b. A Modular Reduction (MR) circuitry based on approximation (Kundi et al., 2020).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Apart from these methods that compress a static PC, there also exist several attempts at optimizing the compression for dynamic PCs by exploring the ‚Äútemporal redundancy‚Äù across the PC video frames. For example, a macro block (a  S √ó S √ó S  cube) based motion estimation and compensation is proposed in [ 15 ], [ 16 ], [ 48 ], [ 73 ], to further improve the compression efÔ¨Åciency. V-PCC 2   targets compressing PC videos.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "As depicted in Figure 4(b), we train E1, E5, and E7 together as they share datasets, followed by E2, E3, and E6, and the remaining experts. This reduces redun- dant data transfers, lowering latency, and reducing energy consumption. This approach can be further refined by, for instance, adjusting the weights taking into account a) availability/proximity of appropriate compute to the nodes (data should ideally be present on nodes which can leverage well-suited accelerators with relative ease), and b) load balancing across nodes to prevent overburdening specific nodes (thus, avoiding performance interference).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "the  Baseline , with only  10%  for the right-eye, translating to  28%  total energy saving. ‚Ä¢  EA+AE:  With both  EA  and  AE  optimizations deployed, as shown in Fig. 9, on average, the left-eye compute consumes only  36%  energy w.r.t.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "IV-C 1 and Sec. V ). SpeciÔ¨Åcally, with our current ‚Äúsub-optimal‚Äù implementation (e.g., the codes are not fully optimized), the de-compression stage (including both geometry and attribute de-compression) for Redandblack video [ 55 ] only takes ‚âà 70 ms  per PC frame, which is less then the PC compression latency as we will discuss later in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "As has been highlighted in Table 2, we plan to exploit the expert-router affinity to reduce the training com- plexity of the router at initial training time and even while fine-tuning as the ensemble of experts evolve. This would ensure that these routers can be fine-tuned in isolation, causing minimum to none ripple effects on to other expert branches, lowering the computational complexity and cost. We intend to co-locate the expert and routers physically in the system during both training and inference time to leverage this affinity and reduce expensive data movement cost.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Bar graphs (latency) plotted using primary y-axis and line graph (#models) plotted using secondary y-axis. Const1 Const2 Const3 Const4 Query \n0.0 \n2.5 \n5.0 \n7.5 \n#Models \nClipper Clipper-X Cocktail \n(b)  Sentiment analysis. Const1 Const2 Const3 Const4 Query \n0 \n5 \n10 \n#Models \nClipper Clipper-X Cocktail \n(a)  Image ClassiÔ¨Åcation-Cifar-100.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "It can be concluded from these results that, memoizing the last  two  frames is sufÔ¨Åcient for most of the cases. 5a. From the dataset, we report the average reuse distance, i.e., the average number of preceding frames with same head orientation to be memoized, and show it in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "[78]  J. Springer, 2014. [77]  R. Shumaker and L. Stephanie,  Virtual, Augmented and Mixed Reality: Designing and Developing Augmented and Virtual Environments: 6th International Conference, VAMR 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014, Proceedings, Part I .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "[76]  Guido Urdaneta, Guillaume Pierre, and Maarten Van Steen. Wikipedia workload analysis for decentralized hosting. Computer Networks , 2009.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "However, it results in almost twice the latency and energy consumption with respect to our approach. 6% , which is slightly better than  50 . 3%  provided by our approach.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "23.6 \n19.8 \n7.1 6.7 \n0 10 20 30 40 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. 0 \n2000 \n4000 \n6000 \n2 4 6 8 10 12 14 16 \nPower (mW) \n# Depth-planes \nCPU SoC GPU Mem \n(a) Power breakdown. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "3  in Algo. 2 4 The ground-truth annotations for the EPFL and CAMPUS datasets were not available to us; so, in this work, we primarily focused on the VIRAT dataset to evaluate the accuracy. 1080 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "4, pp. [48] L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, \n‚ÄúHyperband: A novel bandit-based approach to hyperparameter opti- mization,‚Äù  The Journal of Machine Learning Research , vol. 1‚Äì30, 2019.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "D Instance conÔ¨Åguration and Pricing \nInstance vCPUs Memory Price C5a.xlarge 4 8 GiB $0.154 C5a.2xlarge 8 16 GiB $0.308 C5a.4xlarge 16 32 GiB $0.616 C5a.8xlarge 32 64 GiB $1.232 \nTable 7:  ConÔ¨Åguration and Pricing for EC2 C5 instances. E CIFAR-100 and BERT Models \nTable  8  shows the different models available for image predic- tion, that are pretrained on Keras using  CIFAR-100  dataset. The end-to-end response time to send the image to a worker VM and get the prediction back, was dominated by about 300ms (at maximum) of payload transfer time.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 169,
    "augmented": true
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. TABLE I: Qualitative summary of DNN vision optimiza- tion work in terms of accuracy, saving, adaptivity, hardware support, and decision making mechanism (DM).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "[70]  Tiago Zonta, Cristiano Andr√© da Costa, Rodrigo da Rosa Righi, Miro- mar Jose de Lima, Eduardo Silveira da Trindade, and Guann Pyng Li. 2020. Predictive maintenance in the Industry 4.0: A systematic litera- ture review.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "A novel accelerated implementation of rsa using parallel processing. Journal of Discrete Mathematical Sciences and Cryptography , 22(2):309‚Äì322, 2019. Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Instead of simulating the CPU, we tested the K-means clustering and cluster optimization on a mobile SoC with 8 √ó  ARM Cortex A78 series CPU. Table  II gives the key attributes of the implemented hardware against some of the prior accelerators. Note that  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Second, the state management between dependent functions has to be explicitly handled using a predefined state ma- chine and made available to the cloud provider [ 6 ,  23 ]. First, due to the stateless nature of FaaS, individual mi- croservices have to be designed as functions and explicitly chained together using tools to compose the entire appli- cation, thus forming a Directed Acyclic Graph (DAG) [ 33 ]. Third, the presence of conditional branches in some DAGs can lead to uncertainties in determining which functions will \n153 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 169,
    "augmented": true
  },
  {
    "text": "[2]  2019. Airbnb AWS Case Study. https://aws.amazon.com/solutions/ case-studies/airbnb/.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "2012. Prediction of User‚Äôs Web-Browsing Behavior: Application of Markov Model. IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)  42, 4 (2012), 1131‚Äì1142.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "It leverages the PCIe interface for efficient ‚Äúpeer-to-peer communication‚Äù, substantially reducing communication latency and energy requirements. This setup alleviates the host CPU from handling frequent data movement interruptions. A storage platform entirely designed with CSDs is not pragmatic at the current time because of their exorbitant cost and power consumption (AMD, b; Cao et al., 2020) .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Users also have the option to manually mention the ensemble size. 200 using a hill-climb policy [ 17 ] to meet the target accuracy. AWS combines about 6-12 models to give the best possible accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "For example, the average CPU power for TMC13 is  1687 mW whereas  3622 mW  for CWIPC. On the other hand, our Intra- Only scheme only consumes  0 . 38 J  per PC frame, which represents  96 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Our Approach (and its Novelty):  Us. The power sustainability consequently reduces the cost of deployment as the publicly available edge server, like AWS outpost offering (one of the cheaper and lower power consuming ones) for performing edge inference costs $5,134.92/month [ 83 ]. Therefore,  designing a training platform to perform continuous learning with the intermittent solar power and within the typical harvested budget  would be the best solution.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Conversely, simplistic policies‚Äîsuch as se- lecting only the highest-energy sensors‚Äîignore factors like data relevance, sensor quality, and the strategic implications of current participation on future network states. This challenge motivates the need for intelligent, context- aware participation strategies that dynamically determine which sensors should engage during both the  training phase‚Äîwhere global model parameters are periodically fine-tuned or updated‚Äîand the  inference  phase‚Äîwhere newly observed data are aggregated to produce predictions. Sensors must carefully balance immediate accuracy gains against conserving energy for future tasks, while also antici- pating the behavior of other sensors that may be collaborat- ing or competing.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "[37]  N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A. Wood, ‚ÄúThe Gem5 Simulator,‚Äù SIGARCH Comput. Archit.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Figure  9b  shows the most used models in decreasing order of importance. How- ever, since  Cocktail  exploits importance sampling by keeping track of the frequency in which models are selected, the num- \nber of VMs spawned for model1, model2 and model-3 is upto 3 √ó  times lesser than uniform scaling. Not adopting an importance sampling based weighted policy would result in equivalent number of VMs as the Bline for all models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Furthermore, each teacher model has its private conÔ¨Ådence matrix on different object classes. This conÔ¨Ådence matrix serves as a weight for performing the ensemble of multiple teachers, and helps exploiting the expertise of each of the teacher models for each of the individual classes, signiÔ¨Åcantly boosting the accuracy and robustness of the data annotation. This maximizes the accuracy of the teacher, and consequently minimizes the chance of the student model learning wrong labels.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "[29]  Magic Leap. 2020. Magic Leap 1 is a Wearable Computer for Enterprise Produc- tivity.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "This stability is critical for maintaining consistent network performance and energy sustainability over time. Distributed Best-Response Algorithm: To realize the NE, we propose a distributed best-response algorithm where each sensor iteratively adjusts its action based on the current state and the expected actions of others. The algorithm operates as follows: \nAlgorithm 1  Distributed Best-Response Participation Algo- rithm \n1:  Input: Current energies  B i ( t ) , predicted harvest ÀÜ E i ( t  + 1) , parameters  Œ≥, Œ¥, Œ∑, Œ≤ , and energy costs e cap ( ¬∑ ) , e inf , e comm .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 173,
    "augmented": false
  },
  {
    "text": "Proposed Intra-Frame Geometry Compression:  As can be seen from Fig. 4  c  , the modiÔ¨Åed components in our pipeline compared to the previously-proposed geometry compression approach (depicted in Fig. 4  c  and  4  d  for the geometry and attribute compression, respectively).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "The  PTU+EA+AE  implementation combines the  PTU  and our  EA+AE  optimizations together. B. Experimental Platforms and Datasets \nEvaluation Platforms:  The  Baseline  GPU platform described in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "The data lineage information will also help the project to reduce its ‚Äústorage footprint‚Äù. More specifically, instead of storing all versions of each and every dataset and model we generate, we can only store the most important ones and, for the remaining ones, the data lineage information (a kind ‚Äúmetadata‚Äù) can be used to re-generate them, if/when needed. Collaboration Plan \nProject Team \nThe proposed project spans design and analysis of LLM and expert models, characterization and evaluation of such models, development of compiler and runtime system support for efficient LLM/expert training and inference as well as chiplet selection for LLM/expert execution.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "[22]  S. Giancola, J. Zarzar, and B. Ghanem, ‚ÄúLeveraging shape completion for 3d siamese tracking,‚Äù in  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. [24]  B. Han, Y. Liu, and F. Qian,  ViVo: Visibility-Aware Mobile Volumetric Video Streaming . [23] Google, ‚ÄúDraco,‚Äù  ‚Äùhttps://github.com/google/draco‚Äù , 2021.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "8a. Also, V1 can save  7%  more execution time and 6%  more energy than V2 when using the FI+SI+PI scheme. GL1 and HC1 are other two videos from the CAMPUS [43] dataset.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "class ] 23: end for 24: P class  ‚Üê max ( weighted _ vote , key  =  class ) 25: returnP class 26:  end procedure \n4.1.1 Class-based Weighted Majority Voting \nThe model selection policy described above ensures that we only use the necessary models in the majority voting. predicted _ class 22: weighted _ vote [ class ]+ =  weights [ model . append ( addModel ) 17: end if 18:  end procedure 19:  procedure  W EIGHTED _V OTING ( Models ) 20: for  model in  ‚àÄ Models  do 21: class  ‚Üê model .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "However, certain jobs could be too big to execute atomically on harvested en- ergy. Therefore, we profile the tasks using the compute platform (in this case using the MSP-EXP430FR5994 and the LEA in it) to further divide the jobs into Power Atomic Tasks (QuantaTasks). These QuantaTasks are carefully coded with optimized assembly language to maximize their efficiency.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Load/store parameters of the ReRAM memory are from NVSim [ 40 ]. The main parameters of our simulations are given in Table VI. Four practical CNNs listed in Table VI are evaluated on the Ô¨Åve power traces illustrated in Figure 4 for each of the Ô¨Åve execution strategies from Section  V-A 3:  Naive1 ;  Naive2 ;  Sequential ; Pipelining ; and  ResiSchedule .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "3. Access and Sharing Policies \nWe will publish our findings from this research in top ML/AI, systems, HPC, computer architecture and performance evaluation venues, including, but not limited to, ICML, ICLR, NeurIPS, MLSys, ACM SC, ISCA, MICRO, HPCA, ASPLOS and SIGMETRICS, as well as the top relevant ACM and IEEE journals and transactions. When appropriate, the PIs will also try to share their research findings with the broad research community via posts, talks, and seminars.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "Centimani: Enabling fast AI accelerator selection for DNN training with a novel performance predictor. In  2024 USENIX Annual Technical Conference (USENIX ATC 24) , pages 1203‚Äì 1221, Santa Clara, CA, July 2024. USENIX Association.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "When appropriate, the PIs will also try to share their research findings with the broad research community via posts, talks, and seminars. No ethical and privacy issues will be associated with the data, and the data will not contain any personal information and will not be copyrighted. All data mentioned above will be accessible via our website dedicated to the project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Based on Table  1 , if we had statically taken the top  N / 2 most accurate models, NasNetmobile would not have been included in the ensemble. However, based on the input im- ages sent in each query, our model selection policy has been able to identify NasNetMobile to be a signiÔ¨Åcantly contribut- ing model in the ensemble. Further, the other 5 models are used by up to 25% of the images.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "On the other hand,  Scene Reconstruct captures comprehensive consistent maps of environments from an RGB-D image, and consumes 120 ms  in the practical setting. Thus, both of these two tasks are able to meet the performance re- quirements shown in Table 1. Note that such maps are not necessarily required to be generated for each frame (typically computed once per two or three frames [ 28 ,  50 ], thus 67 ‚àí 100 ms  in Table 1); hence, we argue that the state-of-the-art InfiniTAM technique, which implements a framework for real-time depth fusion and learning of 3D scenes [ 50 ], is already close to the ideal case.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "Broadening Participation in Computing (BPC) Plan: Connected \nSince this is a connected BPC plan, we only discuss the planned activities for the PIs, as specified in the submission guidelines. The approved departmental BPC plan is also included. Plan of Activities:  Aligned with the departmental BPC plan, we plan to pursue several activities related to this proposed research as summarized below: ‚Ä¢  Customized Graduate Student Recruiting and Training:  We will recruit graduate women and students from populations underrepresented in computing to work on this project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "However, it does not take workflow activation patterns into consideration while spawning con- tainers, leading to container overprovisioning. The recently proposed scheme,  Xanadu , is based on a workflow-aware container deployment mechanism, but does not employ re- quest batching, leading to extra containers being deployed in comparison to  Kraken . Furthermore, it can be seen that Xanadu  provisions a relatively high number of containers for a particular group of functions as compared to the rest.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "6.2.2 BeneÔ¨Åts from Autoscaling \nFigure  11  plots the reduction in the number of VMs used by all four schemes. Cocktail  spawns 29% lesser VMs on top of Clipper-X , because it is not aggressive enough like  Cocktail to downscale more models at every interval. It can be seen that both  Cocktail  and  Clipper-X spawn 49% and 20% fewer VMs than  Clipper  for workload-1 on Twitter trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "IRV2 \nDNet201 \nNASMob \nDNet121 \nXcep \nMNet \nIncep \nMNetV2 \nRNet50V2 \nRNet50 \nModel \n0 \n50 \n100 \nImportance(%) \n(b)  Distribution of requests served by each individual model. Const1 Const2 Const3 Const4 Query \n0 \n5 \n10 \n#Models \nClipper Clipper-X Cocktail \n(a)  Average number of models used in the ensemble. Figure 8:  Cost savings of  Cocktail  compared to three schemes.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "[35]  Kate Keahey, Jason Anderson, Zhuo Zhen, Pierre Riteau, Paul Ruth, Dan Stanzione, Mert Cevik, Jacob Colleran, Haryadi S. Gunawi, Cody Hammock, Joe Mambretti, Alexander Barnes, Fran√ßois Halbach, Alex Rocha, and Joe Stubbs. 2020. Lessons Learned from the Chameleon Testbed.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Evolution of Computational Storage:  The advent of CSDs represents a paradigm shift, bringing computation closer to storage. However, storage systems are not typically built to cater towards the ML applications, and now that compression becomes a ML application with the use of stacked neural codecs, building the right storage stack along with computational storage devices becomes an important problem. These devices, by integrating CPUs or FPGAs into the storage \n4 We do  not  consider H265 here as currently in commercial systems H264 is the standard and typically enjoys hardware support.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "(b) The  Inter-Holo  and  Intra-Holo . Figure 6: The proposed  HoloAR  which includes  Inter-Holo leveraging foveated rendering, and  Intr-Holo  further ap- proximating holograms for far objects. (a) HoloAR overview.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "heterogeneous resource availability from the public cloud. Towards this, we make the following  key contributions . 1.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 26,
    "augmented": false
  },
  {
    "text": "[4] J. Albericio, P. Judd, T. Hetherington, T. Aamodt, N. E. Jerger, and \nA. Moshovos, ‚ÄúCnvlutin: Ineffectual-neuron-free deep neural network computing,‚Äù  ACM SIGARCH Computer Architecture News , vol. 44, no. 3, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Spock: Exploiting serverless functions for slo and cost aware resource procure- ment in public cloud. [37]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Mahmut Taylan Kandemir, Bhuvan Urgaonkar, George Kesidis, and Chita Das. In  IEEE CLOUD , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "While previous works have de- signed energy-efÔ¨Åcient training hardware with support for variable precision training, none have adapted to variable energy income. Us. ¬¥as  optimizes the entire solution space, maximizing hardware reuse for exemplar selection and micro- proÔ¨Åling while addressing the training task.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Caine. Scalability in perception for autonomous driving: Waymo open dataset. In  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "¬¥as  uses non-volatile state buffers (NVSBs, 18 count, 1 per 4x4 tiles, each of 1kB, and 2 of 4kB each) for state saving and data backup. The control logic prioritizes writing data into the local NVSB for the arbiter (each arbiter caters to 2 STiles). If those get full because of continuous power failures, the control directs the data to the global NVSBS (NVSB-NW and NVSB-SE in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "The overall utility is: \nU i ( t ) =  R i ( t )  ‚àí C i ( t ) . We assume that  ‚àÜ A i ( t )  is non-decreasing in the quality of sensor  s i ‚Äôs data (e.g., higher SNR yields higher  ‚àÜ A i ( t ) ). We also assume that energy resources, accuracy gains, and reward/penalty parameters are finite and bounded, and that sensors have consistent estimation mechanisms for  ‚àÜ A i ( t ) and   ÀÜ E i ( t  + 1) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "1080 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Specifically, we intro- duce two regularizers:  (1)  ‚Ñ¶ SNR ( Œ∏ ) : Encourages the model to maintain performance across varying SNR levels, pre- venting over-reliance on high-SNR data. (2)  ‚Ñ¶ complexity ( Œ∏ ) : Controls model complexity, reducing computational and communication overheads by discouraging overly intricate models. The full training objective is formulated as: \nJ ( Œ∏ ) =  L ( Œ∏ ) +  Œª 1 ‚Ñ¶ SNR ( Œ∏ ) +  Œª 2 ‚Ñ¶ complexity ( Œ∏ ) , \nwhere L ( Œ∏ ) =  E ( x,y ) ‚àºD [ ‚Ñì ( f Œ∏ ( x ) , y )] , \nand  Œª 1 , Œª 2  ‚â• 0  are hyperparameters that balance accuracy, robustness, and efficiency.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 203,
    "augmented": false
  },
  {
    "text": "During back- propagation, each sensor computes the gradient of the loss function  ‚àá ‚Ñì ( f Œ∏ ( x ) , y )  with respect to  Œ∏  based on locally available samples from  D . Additionally, the gradients of the regularizers,  ‚àá ‚Ñ¶ SNR ( Œ∏ )  and  ‚àá ‚Ñ¶ complexity ( Œ∏ ) , are analyt- ically derived and added to the local gradient estimates. Since both regularizers are convex and smooth, their in- clusion ensures that the overall objective  J ( Œ∏ )  maintains desirable convexity and smoothness properties, facilitating the convergence of stochastic gradient descent (SGD).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "The lecture slides/videos are expected to be stored until their useful lifetime, and they will also be made available via YouTube. The main documentation that will accom- \npany the data are project reports and research publications. Since all data will be maintained in electronic format, archiving and version control will be achieved automatically via SVN software [15].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Cost Comparison:  Figure  8  plots the cost savings of Cocktail  when compared to  InFaas ,  Clipper  and  Clipper-X policies. We do not plot the results for Clipper-X , which achieves similar accuracy to  Cocktail , but uses more models as explained in Section  6.2.1 . It can be seen that,  Cocktail  is up to 1.45 √ó  more cost effective than  InFaas  for  Strict  workload.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "This stability allows us to treat  D  as effectively fixed for the purpose of the asymptotic analy- sis. If  D  were to drift significantly, standard SGD results would not directly apply. The equilibrium prevents such non-stationary behavior in the long run.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "https://docs.aws.amazon.com/step- functions/latest/dg/concepts-amazon-states-language.html. [5]  2020. AWS Lambda.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Both G-PCC and V-PCC are widely adopted in MPEG standard [ 53 ], and since our proposals begin with G-PCC, thus, is also compliant with the MPEG PCC standard. NN-PCC 2   takes the raw PC as input, and feeds it into a pretrained 3D CNN, which outputs the compressed PC stream [ 28 ], [ 82 ]. Several recent efforts have been put into optimizing the 3D CNN to increase the compression ratio and/or decrease the number of parameters in the neural network model [ 27 ], [ 69 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "Section  V-C will further present quantitative analysis and solution on how \ntoÔ¨Ågureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA. At runtime, ResiSchecule dynamically selects activation solutions from either  Sequential  or  Pipelining  in each power cycle, depending on which can provide a better throughput. With  ResiSchedule , we can cover a large tuning range commensurate with power supply variation.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "Abstract ‚ÄîThe emergence of virtual reality (VR) and aug- mented reality (AR) has revolutionized our lives by enabling a  360 ¬∞  artiÔ¨Åcial sensory stimulation across diverse domains, including, but not limited to, sports, media, healthcare, and gaming. Unlike the conventional planar video processing, where memory access is the main bottleneck, in  360 ¬∞  VR videos the compute is the primary bottleneck and contributes to more than 50%  energy consumption in battery-operated VR headsets. Thus, improving the computational efÔ¨Åciency of the video processing pipeline in a VR is critical.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "[47] Tom‚Äôs HARDWARE, ‚ÄúNvidia‚Äôs Jetson TX2 Powers GameFace Labs‚Äô Standalone VR Headset.‚Äù ‚Äùhttps://www.tomshardware.com/news/ gameface-labs-standalone-steamvr-headset,37112.html‚Äù, 2019. [48] R. Toth, J. Nilsson, and T. Akenine-M¬®oller, ‚ÄúComparison of Projection Methods for Rendering Virtual Reality,‚Äù in  Proceedings of High Perfor- mance Graphics , ser. HPG ‚Äô16, 2016, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "10: Sensitivity study. (a): Video quality metric (PSNR [25], [40]) across video inputs. (b): The pattern between left-eye and right-eye in the  front  face in Cube Mapping [41].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "4 Œ≤  =  approxFactors (cam2ObjDists[obj]) \n5 Holograms[obj] = Algorithm1( 16  √ó  Œ≤ , obj) \n6 return  { Holo–¥rams } \nIn the  Inter-Holo  design, the hologram computation can be ap- proximated by identifying the region of focus from eye tracking. However, the scope of this approximation opportunity might be limited due to the strict 16 depth planes requirement for all objects inside the RoF, regardless of their distance from the user. In fact, there may still be another level of opportunity for approximating the objects in long distance ( Intra-Holo , shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "https://github.com/edge-video-services/ekya#urban-traffic-dataset. Shaohua Wan, Zonghua Gu, and Qiang Ni. Cognitive computing and wireless communications on the edge for healthcare service robots.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "pdf \", 2024. [14] Lasse F Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan. https://www.amd.com/content/dam/amd/en/documents/ instinct-tech-docs/data-sheets/amd-instinct-mi300x-platform-data-sheet.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Although our heterogeneous instance procurement policy has some similarities with MArk, it is signiÔ¨Åcantly different because we consider ensemble models. RaÔ¨Åki [ 80 ] considers small model sets and scales up and down the ensemble size by trading off accuracy to match throughput demands. However,  Cocktail‚Äôs  resource management is more adaptive to changing request loads and does not drop accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "[93] Lei Li, Yankai Lin, Shuhuai Ren, Peng Li, Jie Zhou, and Xu Sun. Dynamic knowledge distillation for pre-trained language models. arXiv preprint arXiv:2109.11295 , 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Keni Qiu, Nicholas Jao, Mengying Zhao, Cyan Subhra Mishra, Gulsum Gudukbay, Sethu Jose, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Resirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent embedded processors. 382‚Äì394, 2020.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "7 √ó  speedup and 73% \nenergy savings. We believe that the lessons learned from this work will help in designing next-generation hologram accelerators that can combine approximation as well as other optimizations such as tuning PU counts, frequency, and power gating for achieving the target performance and energy efficiency for edge devices. ACKNOWLEDGMENTS \nThis research is supported in part by NSF grants #1763681, #1629915, #1629129, #1317560, #1526750, #1714389, #1912495, and #1909004.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "This behaviour is expected and can be attributed to the increasing number of completed inferences. 5b shows the results for the PAMAP2 dataset. Following are our observations: ‚Ä¢  The overall accuracy tends to improve with increasing round-robin delay time.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Combination of ER-r and AAS, results in more than 70% accuracy for most of the activities (Fig. This delay depends of the extended round- robin policy. To incorporate the ER-r, we induce delays between sending the external signal and starting the inference on the same sensor.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 9368‚Äì9377, 2018. [16] Josiah L Carlson. Redis in action .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "¬¥as  converges closer to the accuracy of the teacher model. Further,  Us. This was possible by restricting the training space and by using the superior exemplar set construction by using representation learning.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Let  D  denote the effective data distribution induced by the equilibrium strategies of the sensors. The model operates in an energy-harvesting wireless sensor network (EH-WSN) envi- ronment where sensors participate strategically in inference tasks based on a game-theoretic equilibrium. The model‚Äôs performance is measured by a loss function  ‚Ñì :  Y √ó Y ‚Üí R ‚â• 0  that is convex in  Œ∏  for any fixed input-label pair  ( x, y ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Smartssd computational storage drive. AMD. https://www.xilinx.com/applications/ data-center/computational-storage/smartssd.html , b.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "This again validates the quality impact discussed earlier. Note that the pattern behavior also depends on the row numbers. Putting together, these above observa- tions indicate that, with very little change (to capture the row- dependent information) in our original  AE  design, our idea is able to work with any representation format.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Input : C : Code Array;  P : Parent Array;  N : Number of Points \n1  Occupy Bits Array:  O  =  {} \n2  L  =  len ( C ) ‚àí N \n3  for  i in L  do \n4 p  =  P [ i ] \n5 O [ p ]  |  = ( C [ j ] %8 ) ,  P [ j ] =  p \nOutput :  O : Occupy Bits Array \nand energy savings, due to embracing more parallelism. In fact, the CPU-based PCC pipeline in PCL [ 72 ] requires O ( N  √ó  D )  time complexity to process  N  points, with a  D - layer tree. In comparison, given a GPU-based system with  k parallel cores, our design requires only  O ( ‚àë D i = 1   N i / k )  time ( N i is #nodes in layer ‚àí i ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 228,
    "augmented": false
  },
  {
    "text": "In the  pwr-warning  phase the system Ô¨Ånishes the remaining compute of the systolic arrays (which can take up to 64 cycles), \n898 \nAuthorized licensed use limited to: Penn State University. The w-pdown  triggers the  backup  signal and the system goes into pwr-warning  state (other states being on, off, invalid and X). Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "23 \nShulin Zhao, Haibo Zhang, Cyan Subhra Mishra, Sandeepa Bhuyan, Ziyu Ying, Mahmut Taylan Kandemir, Anand Sivasubramaniam, and Chita Das. In  MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture , MICRO ‚Äô21, pp. Holoar: On-the-fly optimization of 3d holo- graphic processing for augmented reality.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "https://discover.lanl. gov/news/0728-storage-device/ . Los alamos national laboratory and sk hynix to demonstrate first-of-a-kind ordered key-value store computational storage device.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "[63] H. Zhang, P. V. Rengasamy, S. Zhao, N. C. Nachiappan, A. Sivasub- ramaniam, M. T. Kandemir, R. Iyer, and C. R. Das, ‚ÄúRace-to-sleep + Content Caching + Display Caching: A Recipe for Energy-efÔ¨Åcient Video Streaming on Handhelds,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2017, pp. 517‚Äì531. [64] H. Zhang, S. Zhao, A. Pattnaik, M. T. Kandemir, A. Sivasubramaniam, and C. R. Das, ‚ÄúDistilling the Essence of Raw Video to Reduce Memory Usage and Energy at Edge Devices,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2019, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 205,
    "augmented": true
  },
  {
    "text": "IEEE, 2006. Pytorch: An imperative style, high-performance deep learning library. [128] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K√∂pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "[28] Y.-D. Kim, E. Park, S. Yoo, T. Choi, L. Yang, and D. Shin, ‚ÄúCompression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications,‚Äù  arXiv preprint arXiv:1511.06530 , 2015. [29] C. Louizos, K. Ullrich, and M. Welling, ‚ÄúBayesian Compression for Deep Learning,‚Äù in  Proceedings of the 31st International Conference on Neural Information Processing Systems , 2017, p. 3290‚Äì3300. [27] S. Han, H. Mao, and W. J. Dally, ‚ÄúDeep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding,‚Äù  arXiv preprint arXiv:1510.00149 , 2015.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 201,
    "augmented": true
  },
  {
    "text": "Gpt-4 tech- nical report. arXiv preprint arXiv:2303.08774 , 2023. [125] Will Orwig and Daniel Schacter.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "[41]  H. Liu, H. Yuan, Q. Liu, J. Hou, and J. Liu, ‚ÄúA comprehensive study and comparison of core technologies for mpeg 3-d point cloud compression,‚Äù  IEEE Transactions on Broadcasting , pp. 701‚Äì717, 2020. [42]  M. Liu, ‚ÄúRobotic online path planning on point cloud,‚Äù  IEEE transactions on cybernetics , vol.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "The loss  ‚Ñì ( f Œ∏ ( x ) , y )  is convex in  Œ∏ . Consequently, the expected loss  L ( Œ∏ )  is also convex. 2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Restrictions apply. [59]  Park, Jounsup and Chou, Philip A. and Hwang, Jenq-Neng, ‚ÄúRate-utility optimized streaming of volumetric media for augmented reality,‚Äù 2018. [60]  W. A. Pearlman and A.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Previous studies have observed that the computation in  360 ¬∞ video processing is, mainly, the  projection transformation  [28]. These observations motivate us to explore the potential opportunities for reducing the power/energy consumption in the  projection  stage. We illustrate the  360 ¬∞ video projection/projection transfor- mation 3   computation in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "Memory-efficient nllb-200: Language-specific expert pruning of a massively multilingual machine translation model. In  2009 First International Conference on Advances in System Simu- lation , pages 125‚Äì131, 2009. [83] Yeskendir Koishekenov, Alexandre Berard, and Vassilina Nikoulina.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "2. We leverage this in  Cocktail , to design a novel dynamic model selection policy, which ensures accuracy with signiÔ¨Åcantly reduced number of models. By characterizing accuracy  vs.  latency of ensemble models, we identify that prudently selecting a subset of available models under a given latency can achieve the target ac- curacy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "To improve the conÔ¨Ådence of the teacher models, we employ an ensemble learning based weighted majority voting policy [ 28 ]. Furthermore, each teacher model has its private conÔ¨Ådence matrix on different object classes. Each of the teacher models infers on the exemplar frame.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. Experimental results show that ResiRCA and ResiSchedule achieve average speedups and energy efÔ¨Åciency improvements of 8 √ó  and 14 √ó  respectively compared to a baseline RCA with intermittency-unaware scheduling. Keywords -Energy harvesting, ReRAM crossbar, CNN, Recon- Ô¨Ågurable hardware, Loop tiling, Computation scheduling \nI. I NTRODUCTION \nIn recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [ 1 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 189,
    "augmented": true
  },
  {
    "text": "Task-1.2: Constructing Morphology of Ensemble of Experts In this task, we propose innovative, flexible, and diverse ways of connecting individual experts to cre- ate diverse LLM expert network morphologies, tailored to various usage scenarios by applying different combinations of expert types, routers, models, and composition functions. In Figure 3, we illustrate three specific morphologies:  chain ,  tree , and  graph , among other potential configurations. The chain structure connects experts in a sequential manner, ideal for tasks requiring a series of expert skills; the tree struc- ture models a type-subtype hierarchy; and the graph structure enables complex expert communication and collaboration.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Although modern encryption algorithms like RSA are secure, there is still a threat of  store now decrypt later 2   kind of attack (National Cybersecurity Center of Excellence (NCCoE), 2023). To mitigate this,  quantum safe encryption algorithms needs to be used without hindering the throughput . Furthermore, the design  needs to be programmable  to ensure encryption keys to be changed regularly for additional security.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "[5] Discovery, ‚ÄúElephants on the Brink.‚Äù ‚Äùhttps://www.youtube.com/watch? [6] T. El-Ganainy and M. Hefeeda, ‚ÄúStreaming Virtual Reality Content,‚Äù CoRR , vol. v=2bpICIClAIg‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "This eye tracking step takes the current IR sensor im- ages as its input, and analyzes the user‚Äôs current gaze area as well as \nAlgorithm 2:  Inter-Holo algorithm. Input : IRs : eye tracking sensors Input : Objs : set of virtual objects Input : Œ± : inter-holo approximation factor,  Œ±  ‚àà( 0 ,  1 ] Output: Holo–¥rams : Generated holograms \n1  procedure  Inter _ Holo ( IRs ,  Objs ,  Œ± ) // main \n2 RoF =  EyeT rackin–¥ ( IRs ) \n3 for  obj  in  Objs  do // View-Window only \n4 if  obj  in  RoF  then // inside of RoF \n5 Holograms[obj] = Algorithm1( 16 , obj) \n6 else // outside of RoF, thus approximate \n7 Holograms[obj] = Algorithm1( 16  √ó  Œ± , obj) \n8 return  { Holo–¥rams } \nthe viewing direction. Note that this additional eye tracking proce- dure needs to be invoked for each frame, in order to capture/reflect the current eye movements without causing nausea for the user.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 304,
    "augmented": false
  },
  {
    "text": "[61]  Rachid Saadane, Abdellah Chehri, Seunggil Jeon, et al . Convolutional Neural Networks for Human Activity Recognition Using Body-Worn Sensors. Informat- ics  (2018).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 29th Symposium on Operating Systems Principles , SOSP ‚Äô23, page 364‚Äì381, New York, NY, USA, 2023. Association for Computing Machinery. [163] Zihao Wang, Bin Cui, and Shaoduo Gan.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "https://doi.org/10.1145/3466752. ACM, New York, NY, USA, 13 pages. In  MICRO-54: 54th Annual IEEE/ACM International Sympo- sium on Microarchitecture (MICRO ‚Äô21), October 18‚Äì22, 2021, Virtual Event, Greece.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "This can help us identify and isolate proper memoization candidates for carefully tweaking our design decisions to maximize the reuse beneÔ¨Åts. Further, we also study the overheads introduced by our design modiÔ¨Åcations to perform a fair comparison with the state-of-the-art. What (features) to Memoize?",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "more intuitive opportunities could exist in the AR application do- main, from  both  the object and user perspectives. Figure 4: Depthmap hologram algorithm details. To identify them, we studied two published AR datasets (Objectron [ 1 ] for objects shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Graham Gobieski, Nathan Beckmann, and Brandon Lucia. Intermittent deep neural network inference. In  SysML Conference , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Additionally, we introduce a novel dataset aimed at furthering the application of energy harvesting in computational settings. 1 Introduction \nThe increasing demand for ubiquitous, sustainable, and energy-efficient computing, combined with advancements in energy harvesting systems, has spurred significant research into battery-less devices (Gobieski et al., 2019; Resch et al., 2020; Mishra et al., 2021; Saffari et al., 2021; Afzal et al., 2022). Such platforms represent the future of the Internet of Things (IoT) and energy harvesting wireless sensor networks (EH-WSNs).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "In contrast, this paper attempts to exploit available ‚Äúre- dundancies‚Äù in computation by analyzing the VR projection computation pipeline. However, unlike planar videos, the 360¬∞ VR video streaming demands signiÔ¨Åcantly more compute power from a battery-operated headset. Thus, prior research has proposed using accelerators for optimizing the computations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Figure 16: Simulator: Comparison of End-to-End (E2E) Response Times and Containers Spawned Over Time (60 minutes) of  Kraken and  Oracle . Trace Arch Fifer Kraken Xanadu Comm Only Conn Only Wiki (99.91%, 2737) (99.90%, 2092) (99.86%, 1396) (99.66%, 1737) (99.78%, ) (99.75%, ) Twitter (99.72%, 45,107) (99.63%, 34,210) (99.50%, 22,377) (99.10%, 25,132) (99.22%, ) (99.15%, ) Table 7: Simulator: Comparing (% SLO met,# Containers Spawned) against Existing Policies after Varying the Target SLOs. existing policies such as  Arch  and  Fifer  exhibit similar perfor- mance and resource usage when their prediction models and keep-alive times are similarly adjusted.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 239,
    "augmented": false
  },
  {
    "text": "Therefore, retrofitting such classical machines with smart sensors will help in preventing such failures and will allow taking predictive measures to increase production efficiency. To understand the implications and benefits of retrofitting sensing into these classical machines, we conducted a case study on the data collected from a grinding machine which had three types of sensors ‚Äì one power sensor and two accelerom- eters. It also incorporated the tool parameters like speed, feed \n4 \n0 0.5 1 1.5 2 2.5 3 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nInference Time (ms) \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(a) Inference time vs threshold \n0 1 2 3 4 5 6 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nAverage # Devices Encountered \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(b) Communication through (aver- age) number of devices vs Threshold \n0.78 0.8 0.82 0.84 0.86 0.88 0.9 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nCorrelation \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(c) Correlation vs threshold \n0 0.2 0.4 0.6 0.8 1 1.2 1.4 \n0.86 \n0.861 \n0.862 \n0.863 \n0.864 \n0.865 \n100 200 300 400 500 600 700 800 \nInference Time (ms) \nCorrelation \n# Cloud Estimators Correlation Inference Time \n(d) Accuracy (correlation) and infer- ence time vs # cloud estimators \nFig.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 430,
    "augmented": false
  },
  {
    "text": "We denote by  E i ( t )  the energy harvested by sensor  s i  during slot  t . Predicting future energy intake is challenging, so each sensor employs an estimator   ÀÜ E i ( t  + 1)  to anticipate its upcoming energy resources. The sensor maintains an energy buffer whose state evolves as \nB i ( t  + 1) =  B i ( t ) +  E i ( t )  ‚àí e i ( t ) , \nwhere  B i ( t )  is the energy available at the beginning of slot  t , and  e i ( t )  is the energy expended during that slot.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "18 √ó  speedup compared to the classical storage server. Furthermore, as depicted in Fig. 5c, SLAT reduces the data communication volume up to  ‚âà 5 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "2020. Objectron Dataset Annotation: shoe. \"https://github.com/google- research-datasets/Objectron/blob/master/index/shoe_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "com/science/article/pii/S0140366419307960 . \"Simon Wright\". Autonomous cars generate more than 300 tb of data per year.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "19 \nD.4 Learning Sparse Masks Dropout with QuantaTask Optimization \nLearning Sparse Masks Dropout adapts dropout masks as learnable parameters within the network, inspired by Wen et al. This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the reconstruction error of the feature maps, along with the QuantaTask optimization to handle energy constraints. Perform the forward pass with the updated dropout mask to obtain the output  Y .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "[45] B.-G. Han, J.-G. Lee, K.-T. Lim, and D.-H. Choi, ‚ÄúDesign of a Scalable and Fast YOLO for Edge-Computing Devices,‚Äù  Sensors , 2020. [46] PyTorch Development Team, ‚ÄúPyTorch,‚Äù ‚Äùhttps://github.com/pytorch/ pytorch‚Äù, 2016. [47] H. Bay, T. Tuytelaars, and L. Van Gool, ‚ÄúSurf: Speeded up robust features,‚Äù in  European conference on computer vision , 2006, pp.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "The  mongodb  database is a centralized server, which resides on the head-node. We measure the overall average latency incurred due to all reads/writes in the database, which is well within 1.5ms. The DeepARest prediction model which is not in the critical decision-making path runs as a background process incurring 2.2 ms latency on average.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "However, the computation and power de- mands of Deep Neural Network (DNN)-based inference pose significant challenges in an energy-harvesting wireless sen- sor network (EH-WSN). Recent works have shown substantial efficiency boosts by execut- ing inferences directly on the IoT device (node) rather than transmitting data. Abstract There is an increasing demand for intelligent processing on ultra-low-power internet of things (IoT) device.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Latency Requirements for Foveated Rendering in Virtual Reality. ACM Trans. 2017.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "8c-8d and Fig. Additional energy and latency can be saved by the FI+SI+PI scheme, as Fig. Note that, the reason why the overhead in YOLOv4-tiny is higher is because, YOLOv4-tiny is already a very light-weight model, and consequently, the time spent on decision making is not negligible compared to the extremely fast inference it performs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "0 \n300 \n600 \n900 \n1200 \n0.25 0.5 0.75 0.98 0.99 \nResponse Time (ms) \nCDF Archipelago Fifer DProb Kraken SProb SLO Xanadu \nFigure 12: Real System: Response Time Distribution. 0 \n300 \n600 \n900 \n1200 \n1500 \nArch Fifer DProb Kraken SProb Xanadu \nJobs per Container \nFigure 11: Real System: Comparison of Container Utilization (a.k.a. average #jobs executed per Container).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "We further describe the existing holographic execution inefficiencies in the AR pipeline and potential opportunities for computation reduction. 2.1 AR Holographic Applications and Pipeline \nThe holographic display technique enables a large body of aug- mented applications in real life [ 14 ]. 1).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "It can be seen that  Cock- tail  shows similar reduction (as Imagenet) while using only 4.4 models on average. As expected,  Clipper  and  Clipper-X use more models than  Cocktail  (11 and 5.4, respectively) due to non-aggressive scaling down of the models used. Figure  16a  plots the latency reduction and accuracy boost when compared to  InFaaS  (baseline).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "2020. Prebaking Functions to Warm the Serverless Cold Start. In  Proceedings of the 21st International Middleware Conference .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "However, note that the ‚ÄúPacking factor‚Äù ( P f  ) for each model also impacts the deployment costs. P f  in this context is deÔ¨Åned as the number of inferences that can be executed concurrently in a single instance without violating the inference latency (on average). Table  1  provides the  P f  for 11 different models when executed on a  C5.xlarge  instance.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "7%  exclusive  pixel coordinates for the right-eye cannot be reconstructed by this algorithm. Note that, as discussed above, 2 . Therefore, only for this small number of pixel coordinates, the entire coordinate projection computations need to be processed.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "They may alter the shape of  J ( Œ∏ ) , encouraging certain regions of parameter space, but they do not prevent convergence. The equilibrium prevents such non-stationary behavior in the long run. Furthermore, since the regularizers are deterministic and have bounded gradients, they do not add pathological con- ditions to the optimization landscape.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "The second input is the decoded  360 ¬∞ frame that contains the pixel values. It is to be noted that, when a user‚Äôs head orientation is changed, the Projection Computation stage needs to  recompute the transformations to reÔ¨Çect the user‚Äôs head movement. The decoded  360 ¬∞ frame is fed to the Projection Mapping stage, which uses the projection matrix, locates the coordinates in the decoded  360 ¬∞ frame, and moves their pixel values to the transformed 2D coordinates in the FoV frames.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "The results will be disseminated through timely scientific publications in respected conferences and journals throughout the project period. Year 3 \nTHRUST-I:Algorithmic  \nSupport for Ensemble  \nof Experts \n2.1 Data Locality and Parallelism-Aware LLM Training \nTHRUST 2: System  \nSupport for Expert  \nScheduling and Data  \nMovements \n3.1 Expert/Hardware Co-Characterization \nTHRUST 3:  Chiplet- \nbased Adaptive and  \nReconfigurable  \nHardware Platform \nCurriculum Development, Undergraduate Research Involvement, Training in Galaxy Community, Industry Outreach, Result  \nDissemination  \nBPC, K-12, Undergraduate Honors, Science-U \n1.1 EoE Design Space Exploration \n1.2 Constructing Morphology of EoE \n2.2 Router Retraining \n2.3 Using Hot and Cold Experts: Caching and Prefetching \n3.2 Chiplet-Based Modular Hardware Platform \n1.3 Continual Adaptation of LLM Experts \n3.3 Handling Unforeseen Cases using Reconfiguration \nTHRUST 4:  \nEvaluation  \nand Fine  \nTuning \n4.1 Evaluation Infrastructure: Experiments + Simulation + Analytical Modeling \n1.4 Algorithmic Choices Informed by System & Hardware Constraints \nYear 2 \nYear 1 \n2.4 KV Cache Management \n2.5 Runtime Support \n2.6 Fault Tolerance \n4.2 Methodology \n3.4 Going beyond with Hardware Software Co-optimization \nFigure 8 :  Project timeline that shows both research and educational/outreach efforts. Note that the education activities, undergraduate involvement efforts, outreach and BPC activities, and industry collaboration efforts (discussed earlier in the broader impact section of the proposal) will continue throughout the entire project duration.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 373,
    "augmented": true
  },
  {
    "text": "3  a  , and observe that: ‚Ä¢  Overall, with more segments/macro blocks whose size is smaller (compared to a frame), more similarity exists in a block (delta is small). Spatial Locality in Attributes:  Towards exploring the attribute similarity within one frame, we partition a frame (whose points are Ô¨Årst sorted in Morton-code order) from the 8iVFB dataset [ 18 ] into  10 ,  10 2 ,  10 4   and  10 5   macro blocks , plot the CDF of the range for attribute delta ( Max red  ‚àí Min red ) within one segment/macro block in Fig. SpeciÔ¨Åcally, compared to the black line (only 10 blocks), the attribute in yellow line ( 10 4 \nblocks, each of them is  1000 √ó  smaller) exhibits a better similarity (i.e., left-shift towards the y-axis).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 203,
    "augmented": true
  },
  {
    "text": "The hardware design of  Us. ¬¥as  (Fig. 5a ) incorporates all the aforementioned points.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "Note that the power requirement of each tile is known in advance (please refer to ¬ß V , TABLE  I  for details). Once the scheduled ( t i ) tiles are completed, the micro-proÔ¨Åler again Ô¨Ånds the right conÔ¨Åguration for the  i  +  1 th   iteration and the scheduler again conservatively enables  t i + 1  number of tiles suitable for the power budget. The  t i + 1  tiles fetch the next  t i + 1  kernels from the GKDQ and the process continues.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "This transformation depends only on the HMD characteristics, including, but not limited to, the display size and resolution, and hence, is known apriori (at design-time). ‚Ä¢  T 5 , the last transformation to be applied, performs a view- port transformation 5 , bringing the projected points to the coordinates used to index the pixels on the HMD. ‚Ä¢  T 4 , also known as the  perspective transformation  ma- trix, maps all  360 ¬∞ coordinates onto 2D coordinates.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "A low output variance of the estimator means the predicted values are tightly concentrated, i.e., different estimators, even after learning different features, give similar answers. Simi- larly, a high variance indicates that the predicted values are discrete and there is no consensus. Relying on how different the answers from each estimators are, we can quantify the prediction quality of the random-forest.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Note that the conÔ¨Ådence matrix reaches the steady state of baseline accuracy within 100 iterations. V. C ONCLUSION \nEnabling DNN inference on edge devices has been gaining recent traction, especially for tasks like HAR. This, in turn, will lead to better and more stable classiÔ¨Åcation for every individual without extensive need for retraining and updating the DNN, which might be impractical for EH-WSNs due to the high communication cost while updating the parameters.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "NetAdapt: Platform- Aware Neural Network Adaptation for Mobile Applications. In  ECCV . [69]  Zhuoran Zhao, Kamyar Mirzazad Barijough, and Andreas Gerstlauer.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "[66] Y. Zhu, A. Samajdar, M. Mattina, and P. Whatmough, ‚ÄúEuphrates: Algorithm-SoC Co-design for Low-power Mobile Continuous Vision,‚Äù in  Proceedings of the International Symposium on Computer Architec- ture (ISCA) , 2018, pp. 547‚Äì560. 253",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "This means that only a portion of computation results from   ‚àó Tile count 1   to  Tile count 1   will be discarded. The discussion on this transition without power prediction is applied for transitions 1  and 2  in the Figure 7. We call this smooth transition strategy as  Transition Keep .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "This strategy is particularly useful when we need a single model to handle diverse knowledge sources or when we aim to reduce training costs by first training smaller models and then combining them. The importance of each weight at index  i , denoted as  I W i , can be approximated by: I W i  =  |L ( D )  ‚àíL W i =0 ( D ) | , where  L W i =0 ( D )  is the loss, by setting parameter  W i  to zero. To create a smaller model for a domain- specific dataset  D , we will identify parameters that have the least influence on loss  L ( D )  and remove them from the large expert.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "Moreover, the experts could differ in their size and thus in their compute and memory requirements. 2.3 Thrust-3: A Chiplet-based Adaptive and Reconfigurable Hardware Platform Our proposed EoE-based LLM algorithm consists of a diverse set of building blocks with routers, experts, and composition functions, entailing heterogeneity in different stages of the application execution. For ex- ample, the experts in the input layer processing the input prompt are expected to require a larger KV-cache against experts in the middle or output layers processing intermediate and refined embeddings.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "EfÔ¨Åcientnet: Rethinking model scaling for convolutional neural networks. arXiv preprint arXiv:1905.11946 , 2019. [74]  P. Thinakaran, J. R. Gunasekaran, B. Sharma, M. T. Kandemir, and C. R. Das.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "We solve this issue by a adopting a thresholding mechanism based on model confidence, and accordingly decide to consult the cloud for better accuracy on less-confident local predictions. Deciding a proper threshold is application and quality of service dependent and remains a user tunable parameter. If the user task can tolerate lower accuracy prediction, or the user is more conservative about the cost associated with sending a request to the cloud, they could decide to change the threshold according to their requirements.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "[4] Heiner Lasi, Peter Fettke, Hans-Georg Kemper, Thomas Feld, and Michael Hoffmann. Industry 4.0. Business & information systems engineering , 6(4):239‚Äì242, 2014. [5] Yang Liu, Yingting Liu, Zhijie Liu, Yuxuan Liang, Chuishi Meng, Junbo Zhang, and Yu Zheng.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "[86]  Chengliang Zhang, Minchen Yu, Wei Wang, and Feng Yan. Mark: Exploiting cloud services for cost-effective, slo-aware machine learning inference serving. In  ATC , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "1  depicts our experimental investigations on data drift, encompassing training and testing multiple DNNs on diverse datasets such as Urban TrafÔ¨Åc [ 12 ], [ 97 ], 3D Point Cloud [ 14 ], [ 24 ], and audio [ 78 ]. The similar trends across these results highlight the impact of varying time windows and encounter- ing diverse scene changes, leading to degradation in network accuracy by up to 30%. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "nuscenes: A multimodal dataset for autonomous driving. In  Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 11621‚Äì11631, 2020.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:1905.03854 , 2019. Enabling fast deep learning on tiny energy-harvesting iot devices. Sahidul Islam, Jieren Deng, Shanglin Zhou, Chen Pan, Caiwen Ding, and Mimi Xie.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "[14] Lasse F Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan. Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. arXiv preprint arXiv:2007.03051 , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "[112] Sai Prashanth Muralidhara, Lavanya Subramanian, Onur Mutlu, Mahmut Kandemir, and Thomas Moscibroda. In  Proceedings of the 44th annual IEEE/ACM international symposium on microar- chitecture , pages 374‚Äì385, 2011. Reducing memory interference in multicore systems via application-aware memory channel partitioning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Us.¬¥as also employs a dynamically morphable systolic array for enabling energy- efÔ¨Åcient computing within the harvested power envelope. Us.¬¥as, unlike prior edge-focused analytics approaches (e.g., Ekya [ 12 ]), detaches the inference and train- ing hardware, as the training task is the major source of the compute, power, and time consumption. Us.¬¥as introduces an al- gorithmic framework for data labeling using a teacher-student model, designing the exemplar selection using representation learning and determining the right set of hyperparameters using micro proÔ¨Åling to energy-efÔ¨Åciently continuously train the DNNs with the selected exemplar sets.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 165,
    "augmented": true
  },
  {
    "text": "Accuracy Met (%) Scheme Strict Relaxed InFaas 21 71 Clipper 47 89 Cocktail 56 96 \nTable 6:  Requests meeting target accuracy averaged for both Trace. Both  Clipper  and  Cock- tail  can meet the ac- curacy for 56% of re- quests, which is 26% and 9% more than  In- Faas  and  Clipper  re- spectively. This is be- cause, intuitively ensembling leads to higher accuracy than single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Task fusion to minimize checkpointing overhead, which is critical in intermittent environments. Real-time energy availability into scheduling decisions. 2.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "2019. Foveated AR: Dynamically-Foveated Augmented Reality Display. ACM Trans.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 24,
    "augmented": false
  },
  {
    "text": "Nevertheless,  Cocktail  is able to deliver the accuracy at 2x lower latency than  InFaaS  and 1.35x lower cost than Clipper. 6.4 General Applicability of Cocktail \nTo demonstrate the general applicability of  Cocktail  to other classiÔ¨Åcation tasks, we evaluated  Cocktail  using a Sentiment Analysis application for two datasets. The results reported are averaged across both the datasets.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "URL  https://www.sciencedirect. com/science/article/pii/S0140366419307960 . ISSN 0140- 3664. doi: https://doi.org/10.1016/j.comcom.2019.10.012.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "[33] Kitware, Inc., ‚ÄúThe VIRAT Video Dataset,‚Äù ‚Äùhttps://viratdata.org‚Äù, 2011. [31] K. Simonyan and A. Zisserman, ‚ÄúVery Deep Convolutional Networks for Large-scale Image Recognition,‚Äù  arXiv preprint arXiv:1409.1556 , 2014. [32] Klaus Hinum, ‚ÄúQualcomm Adreno 640,‚Äù ‚Äùshorturl.at/btCH3‚Äù, 2018.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "V). Moreover,  EA  and  AE  can further be integrated into  PTU  to save even more energy. Pixel Content Reuse on VRs:  Pixel value reuse has been well-studied in VRs [17], [22], [23], [29], [33], [50], [60], [66] to improve throughput and performance.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "These stages include the data loading phase, the modular polynomial multiplication via the SDMM unit, and the final accumulation registers. Data is input into the HSPM in a serial-to-parallel conversion process, while the outputs, after undergoing addition operations, are retrieved serially through an address signal. Central to the Ring-Learning with Errors (R-LWE) based Public Key Encryption (PKE) is the equation d  =  a  ¬∑  b  +  c .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "The time taken to spawn new VM takes about 60s to 100s de- pending on the size of the VM instance. The DeepARest prediction model which is not in the critical decision-making path runs as a background process incurring 2.2 ms latency on average. The weighted majority voting takes 0.5ms and the model selection policy takes 0.7ms.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "[58]  Attila Reiss and Didier Stricker. 2012. Introducing a New Benchmarked Dataset for Activity Monitoring.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Nevertheless,  Cocktail  is able to deliver the accuracy at 2x lower latency than  InFaaS  and 1.35x lower cost than Clipper. 6.4 General Applicability of Cocktail \nTo demonstrate the general applicability of  Cocktail  to other classiÔ¨Åcation tasks, we evaluated  Cocktail  using a Sentiment Analysis application for two datasets. The results reported are averaged across both the datasets.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Autonomous driving and urban mobility applications, generating over 400TB of data annually (Wright\"; \"premioinc\"; Bhardwaj et al., 2022), predominantly comprise video and 3D point cloud data, making them ideal for our evaluation. This data-set is particularly suited for evaluating the performance of  Salient Store  in dense, urban environments. The  Cityscapes data-set (Cordts et al., 2015) is a comprehensive collection of urban street scenes from 50 different cities, providing a rich source of annotated video data for semantic urban scene understanding.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "The layers are scheduled in a sequential fashion. In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks. This execution style is called  Sequential .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "How- ever, traditional monolithic LLMs are not well-suited for frequent updates, because training monolithic LLMs often involves wholesale replacement which is prohibitively expensive and challenging. By contrast, our proposed EoE paradigm is inherently modular , requiring updates of only a small subset of experts to accom- modate new usage scenarios. This allows us to perform flexible and efficient ‚Äúneighborhood training‚Äù by localizing  the training parameters and  freezing  the rest of the parameters as much as possible to save cost.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "It delivers the promise of scaling LLMs through many smaller, specialized, independently trained expert language models. Our LLM expert repository, together with our cross-layer approach among algorithm, system, and architecture, will lay the foundation for the democra- tization of LLM development under friendly compute budgets for a wide range of community groups. Task-1.2: Constructing Morphology of Ensemble of Experts In this task, we propose innovative, flexible, and diverse ways of connecting individual experts to cre- ate diverse LLM expert network morphologies, tailored to various usage scenarios by applying different combinations of expert types, routers, models, and composition functions.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "For example, while cycling, the data sensed by the ankle, chest and wrist sensors would be en- tirely different because of the nature of the motion. Thus, the DNN architectures to infer these data are also different. It is obvious that the raw data sensed by each sensor would be different, even for the same activity, because of the difference in move- ment and dynamics.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "Based on the above discussion, in this work, we focus on EA  and  AE  opportunities. We are unaware of any existing implementation or research work that focus on compute reuse by leveraging across-frames and across-eyes memoization. In fact, the existing state-of-the-art software stack, such as GoogleVR-SDK [11], simply uses the IMU sensor inputs to calculate the updated transformation matrices, then passes them to the OpenGL [42] engine to process the projection computation, as shown in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "¬¥as  uses two kinds of scheduling policies to handle the graceful  powerdown  and work queue rearrangement. Conservative Scheduling:  The most important part of the Us. ¬¥as  accelerator design is to ensure proper ‚Äúcompute place- ment‚Äù even under a power emergency or power scaling.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "These devices, by integrating CPUs or FPGAs into the storage \n4 We do  not  consider H265 here as currently in commercial systems H264 is the standard and typically enjoys hardware support. Moreover, H265 is an extension of H264 with additional features like coding tree units and intra-prediction directions which demand significantly more computation. 5 \nmedium, facilitate computation at the storage level.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "To lever- age this opportunity, we need to know where the user is located in the world and what the objects in the world look like [ 13 ,  19 ,  53 ,  59 ]. Next, we use one of the popular SLAM techniques, Kimera-VIO [ 53 ], to estimate the user‚Äôs pose and understand the relative positions of the objects and the user. As shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": ": To identify such similarity/reuse opportunities across frames (shown in Fig. 7 ), the macro-block based state-of-the-art approach [ 48 ] Ô¨Årst needs to generate two macro block trees (where the minimum voxel dimension in this tree is of a predeÔ¨Åned size) ‚Äì one for I-Frame and the other for P-Frame. 2) How to Capture the Temporal Opportunity?",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "0 \n300 \n600 \n900 \n1200 \n0.25 0.5 0.75 0.98 0.99 \nResponse Time (ms) \nCDF Archipelago Fifer DProb Kraken SProb SLO Xanadu \nFigure 12: Real System: Response Time Distribution. across all functions in  Social Network  for the Poisson trace. An ideal scheme would focus on packing more number of requests per container to improve utilization without caus- ing SLO violations.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "The only difference that can be observed is that, regarding LeNet  and  PV  with the power source of  Thermal , relatively speaking, the results of energy efÔ¨Åciency with  Pipelining strategy are higher than that appearing in the throughput evaluation. One possible reason for this is that  Pipelining \nrequires loading several inputs from ReRAM memory to perform the parallel operations, which is power-expensive. This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efÔ¨Åciency when active is high.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "This amounts to about  2.3 GFLOPS , which represents a substantial amount of computation, given the limited compute capabilities and power in such edge devices. Note that, even though theoretically one represents the  360 ¬∞ frame coordinates as quaternions, in practice, they are typically represented using speciÔ¨Åc projection formats, e.g., equirectangular, cube map, equi-angular cubemap, pyramid format, etc. The details of these formats are in the purview of cartography and computer graphics domain, and hence we do not evaluate all of the aforementioned formats.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "Figure  9b  shows the breakdown of the percentage of re- quests ( Const1 ) served by the each model. Thus, the beneÔ¨Åts of  Cocktail  are substantial for large ensembles while reducing the number of models for medium-sized ensembles. Still, the savings in terms of cost will be signiÔ¨Åcant because even removing one model from the ensemble amounts to  ‚àº 20% cost savings in the long run ( Clipper  vs  Clipper-X  ensemble in Figure  8 ).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "To procure  A n  instances, we greedily calculate the least cost instance as  min ‚àÄ i ‚àà instances Cost i  √ó A n / P f i . Depend- ing on the cost-effectiveness ratio of  A n / P f i , GPUs will be preferred over CPU instances. Load Balancer : Apart from procuring instances, it is quintessential to design a load balancing and bin-packing  5 strategy to fully utilize all the provisioned instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "In this case, we choose the activation solution with larger tiling size by taking into account the transition cost. It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode. If the tiling sizes of output solutions are the same, we choose larger  m because larger  m  implies fewer partial sum adds.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Despite using multiple models for a single inference, importance sampling combined with aggressive model pruning, greatly reduces the resource foot- print which directly translates to the cost savings in  Cocktail . 6.2.3 BeneÔ¨Åts of Transient VMs \nThe cost-reductions in  Cocktail  are akin to cost-savings of transient VMs compared to On-Demand (OD) VMs. We pro- Ô¨Åle the spot price of 4 types of  C5  EC2 VMs over a 2-week period in August 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "Fine-grained reconÔ¨Åguration:  The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes. Similarly, total model size, including any granularity overheads (e.g., from the partitioning used to store both positive and negative weights by having the kernels of one layer mapped to two crossbars, one each for positive and negative weights, which share the same input port) must Ô¨Åt within the allocated RCAs of a particular ResiRCA design. This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "Prior works on PCC acceleration [ 19 ], [ 33 ] only consider the PC with geometry data and/or have limited parallelism, and thus, could neither leverage GPU nor beneÔ¨Åt from other types of accelerators. In this context, this paper explores the following three  opportunities : \n1  The points can be processed  in parallel  by using Morton codes [ 30 ] (which mathematically represent the geometry relationship among points) to identify the spatial-locality 1 \nwithin one frame for geometry compression. 2  Further, this locality also exists in attributes (RGB pixels), i.e., spatial locality leads to attribute similarities, and hence opening opportunities for fast attribute compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "[62]  Alanson P Sample, Daniel J Yeager, Pauline S Powledge, Alexander V Mamishev, and Joshua R Smith. 2008. Design of an RFID-based battery- free programmable sensing platform.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Several works [ 37 , 38 ] like MArk [ 86 ] proposed SLO and cost aware resource procure- ment policies for model-serving. While striking a few similarities with  Cocktail , it is practically limited to image-classiÔ¨Åcation applications with very few classes and does not address re- source provisioning challenges. Although our heterogeneous instance procurement policy has some similarities with MArk, it is signiÔ¨Åcantly different because we consider ensemble models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": ". Mathematical Formulation:  Let  W  be the weight matrix of a layer. Define a binary dropout mask m  = [ m 1 , m 2 , .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Sustainability:  To ensure sustainable and continuous learning at the edge,  Us. ¬¥as  operates independently of the power grid or cloud dependency. We evaluated  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Race-to-Sleep + Content Caching + Display Caching: A Recipe for Energy-Efficient Video Streaming on Handhelds. In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 517‚Äì531.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Consequently, for edge servers to provide cloud-comparable quality, they must also perform continuous learning to mitigate this drift. However, due to their resource constraints, these servers often employ compressed models, which are typically prone to data drift. Abstract ‚ÄîEdge servers have recently become very popular for performing localized analytics, especially on video, as they reduce data trafÔ¨Åc and protect privacy.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Moreover, the algo- rithmic contributions can be extended into any classiÔ¨Åcation based application or data modality. If the learning has to be unsupervised, one needs to experiment with known clustering techniques to decide the right classiÔ¨Åcation approach. We demonstrate this by testing the exemplar selection and the Œº ‚àí proÔ¨Åler with different modalities of data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "In  15th IEEE International Conference on Embedded Software and Systems . 1‚Äì8. [52]  Stephan Reichelt, Ralf Haussler, Norbert Leister, Gerald Futterer, Hagen Stolle, and Armin Schwerdtner.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 517‚Äì531. Race-to-Sleep + Content Caching + Display Caching: A Recipe for Energy-Efficient Video Streaming on Handhelds.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "However, in situations with sporadic energy income, the hardware-assisted scheduling becomes paramount. For scenarios with larger and predictable energy income, software-based backup and restore mechanisms can offer signiÔ¨Åcant beneÔ¨Åts, as the energy consumed for such operations is typically a small fraction of the overall energy income. Predictive actions for saving the system state can be easily taken.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "[17]  February 2018. Google Cloud Functions. https://cloud.google.com/ functions/docs/.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "[8]  2020. IBM-Composer. https://cloud.ibm.com/docs/openwhisk?topic= cloud-functions-pkg_composer.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Yang, A. Howard, B. Chen, X. Zhang, A. Go, M. Sandler, V. Sze, and H. Adam, ‚ÄúNetadapt: Platform-aware neural network adaptation for mobile applications,‚Äù in  ECCV , September 2018. [4] ‚ÄúGoogle assistant for wearables,‚Äù 2020, https://assistant.google.com/platforms/wearables/.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "NExUME is especially advantageous in intermittent environments, and its utility extends to ultra- low-power or energy scavenging systems. However, the efficacy of DynFit and iNAS is contingent upon the breadth and depth of the available dataset. Additionally, profiling devices to ascertain their energy consumption, computational capabilities, and memory footprint necessitates detailed micro- profiling using embedded programming.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "This is because, increasing the interval leads to lower number of scale down operations, thus resulting in a bigger ensemble. As a result, the 120s interval has the highest number of models. USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1051 \n10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n82.25 \n82.50 \n82.75 \nAccuracy \n(a)  Queries under Constraint-1.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Kite: A family of hetero- geneous interposer topologies enabled via accurate interconnect modeling. In  2020 57th ACM/IEEE Design Automation Conference (DAC) , pages 1‚Äì6. IEEE, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 52nd Annual Design Automation Conference , pp. 1‚Äì6, 2015. Mingsong Lv and Enyu Xu.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Although efficient algorithms, compute orchestration and hardware have addressed the analytics part, the scaling of such a system becomes a problem primarily due to high energy consumption. This has lead to a significant development in the direction of enabling video analytics and learning with edge servers. Recent works try to solve this problem by augmenting these continuous learning edge servers with application-specific hardware targeted for intermittent computing which could run using solar power.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "By referring this, it can potentially beneÔ¨Åt an inference to be performed later by either completely skipping it (SI) or reducing the computation (PI). bounding boxes for the object detection task and the feature maps for each layer during the inference are intermediately stored in memory as a ‚Äúcheckpoint‚Äù. Skip Inference:  When the current frame is identiÔ¨Åed as ‚Äúclonable‚Äù by the previous frame, the CPU is released without any inference execution request.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "IEEE, 2018. Shaoheng Fang, Zi Wang, Yiqi Zhong, Junhao Ge, Siheng Chen, and Yanfeng Wang. Tbp-former: Learning temporal bird‚Äôs-eye-view pyramid for joint perception and prediction in vision-centric autonomous driving, 2023.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "In this case, the found leaf  L 1 - I , which contains two points ( P 0 and  P 1 ), is a perfect match; however, no match can be found for the  L 2 - P  leaf. This process is repeated for  O ( N )  times, where  N  is the number of macro-blocks in the P-Frame. This processing can be quite time-consuming, and our proÔ¨Åling shows that it usually takes  ‚âà 5 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "By leveraging the parallel processing capabilities of FPGAs and the high internal bandwidth of SSDs,  Salient Store  reduces the communication latency and data volume by  ‚âà 6 . We present a detailed analysis of data movement challenges within the archival workflows and demonstrate how the strategic integration of CSDs can significantly optimize data compression, encryption, as well as other data management tasks, to improve overall system performance. 2 √ó  and  ‚âà 6 .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Consequently, the mere presence of numerous EH sensors does not guaran- tee robust and reliable performance for complex tasks such as image recognition, acoustic surveillance, or precision agriculture monitoring. Achieving accurate inference in these complex scenarios de- pends on effective coordination. Multiple sensors observing the same phenomenon from different angles can collectively provide more comprehensive and reliable insights than any single sensor could.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "In  European Conference on Parallel Processing , pp. 304‚Äì319. Springer, 2023.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "Since modularity is the backbone of our proposed framework, we envision a detailed simulation of the in- dividual hardware modules (e.g., chiplets, cache/memory components, on-chip and chip-to-chip networks, \netc), as shown in Figure 7 and stitching the evaluation framework for all such discrete modules together to build an ‚Äúend-to-end‚Äù modeling platform for the proposed system. The interconnects within the System on Chip (SoC) connecting different chiplets as well as within a chiplet will be modeled using gem5‚Äôs [20] on-chip network implementation, GARNET [158]. Tensor cores and matrix multiplication engines will be simulated using ScaleSim v2 [137,138], while the memory hierarchy (both DRAMs and HBMs) will be rep- resented using Ramulator [36].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 198,
    "augmented": false
  },
  {
    "text": "Note that  ùë° in the algorithm refers to the current time. We choose this model so as to have a light-weight load prediction mechanism that has min- imal impact on the end-to-end latency ( ‚àº 10 ‚àí 3   ms). This Load Predictor  2b  can be used in conjunction with the afore- mentioned Weight Estimator  2a  to calculate the fraction of application load each function will receive.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "[26] H. Sharma, J. Song, B. Fu, F. Wu, Z. Jiang, L. Jiang, N. Jing, and X. Liang, ‚ÄúDRQ: Dynamic Region-Based Quantization for Deep Neural Network Accel- eration,‚Äù in  Proceedings of the International Symposium on Computer Architecture , 2020, p. 1010‚Äì1021. [25] Z.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "289‚Äì304. 1083 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "However, it is noteworthy that at higher bitrates,  Salient Store  consistently achieves high quality recovery with PSNR reaching  ‚âà 47 dB. With complex and high dimensional video data, HEVC computation complexity increases exponentially, and is more pronounced because of lack of hardware support. Furthermore, as we can see in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "However, in a continuous learning paradigm, training be- comes an essential, repeatedly scheduled task whose computa- tional and time costs cannot be considered a one-time overhead freely delegated to the cloud. A recent work, Ekya [ 12 ], has demonstrated that edge servers equipped with GPUs are capable of performing the necessary tasks for continuous learning within their form-factor-imposed resource constraints, provided that those resources are intelligently managed. Sustainable  Continuous Learning at the Edge:  Even given such advancements in continuous learning on edge servers, provisioning training resources at the edge for every sensing- to-analytics application entails sustainability questions.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "The primary innovation lies in leveraging motion vectors to identify and encode only the changes between frames, rather than re-encoding entire frames. This technique, combined with the use of anchor frames‚Äîsimilar to keyframes in traditional codecs‚Äîallows the codec to understand and predict frame sequences more effectively, reducing redundancy and enhancing compression. Let  F t represent the frame at time  t , and  F t ‚àí 1  be the anchor frame.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "2021. A LiDAR-Guided Framework for Video Enhancement. ArXiv  (2021).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "In comparison, given a GPU-based system with  k parallel cores, our design requires only  O ( ‚àë D i = 1   N i / k )  time ( N i is #nodes in layer ‚àí i ). Input : C : Code Array;  P : Parent Array;  N : Number of Points \n1  Occupy Bits Array:  O  =  {} \n2  L  =  len ( C ) ‚àí N \n3  for  i in L  do \n4 p  =  P [ i ] \n5 O [ p ]  |  = ( C [ j ] %8 ) ,  P [ j ] =  p \nOutput :  O : Occupy Bits Array \nand energy savings, due to embracing more parallelism. In fact, the CPU-based PCC pipeline in PCL [ 72 ] requires O ( N  √ó  D )  time complexity to process  N  points, with a  D - layer tree.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 228,
    "augmented": true
  },
  {
    "text": "Note that, even with DVFS, most scheduled compute could not be Ô¨Ånished. 0 0.2 0.4 0.6 0.8 \n1 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nA6000 w/DVFS RTX3090 w/DVFS Non-intermittent Custom HW w/Ekya \nOur Custom HW \nCompleted/Scheduled \nC/S Win-1 C/S Win-2 C/S Win-3 C/S Win-4 C/S Win-5 C/S mean \nFig. 4: Impact of DVFS on completion (average power budget 70W).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 179,
    "augmented": true
  },
  {
    "text": "MQSim: A framework for enabling realistic studies of modern Multi-Queue SSD devices. In  16th USENIX Conference on File and Storage Technologies (FAST 18) , pages 49‚Äì66, Oakland, CA, February 2018. USENIX Association.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "4.3) and found to reduce around 23% execution latency (in Sec. 5) for AR holograms. However, such performance gain from foveated rendering is still insufficient to close the 10 √ó  gap discussed above.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "However, for Frame-3, the motion vectors generated by codec (  6  ) drift away from the bounding box in Frame- 1 (with an overlap ratio of 0.6 in the right case), indicating that the object has moved/shifted a signiÔ¨Åcant distance. Thus,we can safely  skip  the inference for Frame-2, and simply reuse the result from Frame-1, as shown in  5  . With such knowledge, for Frame-2, we can observe that the bounding box and the MVs mostly overlap (with an overlap ratio of 0.71 in the left case), which indicates that the objects have barely moved.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "[108] Asit K Mishra, Xiangyu Dong, Guangyu Sun, Yuan Xie, Narayanan Vijaykrishnan, and Chita R Das. Architecting on-chip interconnects for stacked 3d stt-ram caches in cmps. ACM SIGARCH Computer Architecture News , 39(3):69‚Äì80, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "We solve this issue by a adopting a thresholding mechanism based on model confidence, and accordingly decide to consult the cloud for better accuracy on less-confident local predictions. However, to alleviate the shortcomings of less accurate predictions at the edge, some computations are routed to the cloud, expecting a better result at the expense of a higher latency. Therefore, it is essential to know if and when to route the compute to the cloud to balance accuracy and latency.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "3.2 Communication vs Accuracy We can tune the aforementioned coreset construction tech- niques allow a variable number of features depending on the available energy, i.e. for importance sampling, we can limit the number of points to choose, and similarly, for clustering we can limit both the number of clusters and the number of iterations. However, even after preserving important fea- tures, the constructed corests are lossy representation of the original data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "In case of a complete power failure, the compute in Ô¨Çight are rejected and, once the system starts working, the work queues get invalidated and the host starts the compute again from the last checkpoint. Along with that, the most common intermittent software libraries and software designs [ 26 ], [ 52 ] (and most DNN training libraries like PyTorch, TensorFlow) also offer periodic checkpoints. Note that the power-up sequence for a tile runs in the exact opposite order of the  powerdown  sequence (a tile becomes computationally active 512 cycles after it gets the power up signal).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "In  14th  { USENIX }  Symposium on Operating Systems Design and Imple- mentation ( { OSDI }  20) . 805‚Äì825. 166 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \n[41]  Mohammad Shahrad, Jonathan Balkind, and David Wentzlaff.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "5 dB (only  6 . 5 dB drop compared to TMC13). Clearly, the geometry data has been compressed very well, as opposed to the attribute data.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "). Non-cooperative game models allow sensors to make au- tonomous decisions while considering the potential ac- tions of others, leading to equilibria that balance individ- ual utility with collective goals ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "1, the neural network video inference software pipeline can be summarized as follows: Input:  The raw video data is Ô¨Årst stored in memory (usually in the H.264/MPEG format). These frames are then buffered in a memory buffer, waiting for the next stage ‚Äì NN Inference. A hardware-based H.264/MPEG decoder decodes the compressed video bitstreams to obtain the original video frames.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Moreover, as stated in the proposal, we will collaborate with Argonne National Lab specifically for the experimental evaluation thrust of the project. A letter of collaboration is included as a supplementary document (our partnership with ANL already generated a SIGMETRICS paper [26], and we will also be submitting a joint paper to MLSys by the end of October 2024). These partnerships will also provide external insights to the project, and in particular, our collaboration with ANL enable us to access a large number and variety of compute platforms (including those with accelerators).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "6, we observe a significant change in the latency compared to a single storage node. Although, a multi-node setup provides more parallelism, the speedup is sub-linear, and we observe  ‚âà 3 √ó  and  ‚âà 4 . 77 √ó  speedup against VSS and a classical storage server, respectively.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "6.3.4 Sensitivity to Dataset \nTo demonstrate the applicability of  Cocktail  to multiple datasets, we conducted similar experiments as elucidated in Section  5.2.1  using the  CIFAR-100  dataset [ 50 ]. It can be seen that for higher accuracies, Cocktail  tries to ensemble more models to reach the accuracy, while for lower accuracy it resorts to using single models. It comprises of 100 distinct image classes and we trained 11 different models including the nine that are common from Table  1 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "The bars are all normalized to  ResiSchedule . The included table gives the absolute values of throughput by ResiSchedule. The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 √ó  compared to a baseline RCA with intermittency-unaware scheduling.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Initialize the loop iteration parameters  l . 17 \nCompute the activations  a  and apply the dropout mask: \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output. Calculate the gradients and Hessians of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij , ‚àÇ 2 L ‚àÇW   2 ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) If  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the sensitivities: \np i  = Œ≤   P j ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \nmax \u0010P j ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \u0011 +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 412,
    "augmented": false
  },
  {
    "text": "All product names used here are for identification purposes only and may be trademarks of their respective companies. 165 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. References \n[1]  [n.d.].",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "In fact, our proÔ¨Åling shows that RAHT takes around 2 seconds to process a typical frame with around 1M points, on a typical edge device. Towards addressing this signiÔ¨Åcant performance inefÔ¨Å- ciency, we investigate the insight from the above discussion in Sec. III-B , which indicates that the locality revealed by \nthe Morton codes does not only exists among the geometry data, but it can also help with the attribute compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "[80]  TheAILearner Blogger, ‚ÄúImage Processing ‚Äì Nearest Neigh- bour Interpolation,‚Äù  ‚Äùhttps://bit.ly/3l4iY95‚Äù , 2018. 525‚Äì561. [81]  TopoDOT Blogger, ‚ÄúUsing Point Clouds for Augmented and Virtual Reality,‚Äù  ‚Äùhttps://bit.ly/3OFdA97‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Moreover, some static objects (trafÔ¨Åc light, stop sign, etc.) This creates a sampling ‚Äúbias‚Äù [ 70 ] while performing the training, and often leads to catastrophic forgetting. might be present in all frames.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "3b, all focus only on a portion of the entire viewing window within a short period of time (10 seconds in this case). On the other hand, even when viewing the exact same scene, the RoF varies across users. For example,  User1 has similar interest as  User3 , whereas  User2  focuses more on the bottom left corner.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Fig. 1: A DNN inference pipeline on an edge device with optimizations in the application, system, and hardware levels. Output:  Following the inference stage, the resulting Feature- Maps (FMs) are used to generate the Ô¨Ånal tags/bounding-boxes and Ô¨Ånally report to the application (e.g., a cow has been identiÔ¨Åed in the image with 95% conÔ¨Ådence).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Furthermore, it then applies innovative coreset techniques to efficiently and intelligently offload unfinished compute tasks to a more capable host to further increase the inferences that can be performed. Particularly,  Seeker  aug- ments its coreset formation with  application-awareness  to form an energy aware, dynamically configured, and feature \npreserving payload with minimal communication footprint. Seeker  provides hardware acceleration support for coreset formation to make them computationally efficient, adaptive, and accuracy-preserving specifically for EH-WSNs.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "3. Decomposable loops: Each ‚ÄòQuantaTask‚Äò runs a certain part of the loop. Check for sufficient energy before launching a ‚ÄòQuantaTask‚Äò.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "Although model sharing, instead of data sharing, solves some of the challenges [5], such approaches are not trivial to deploy in classical learning paradigms, like random forests. However, sharing data with as server makes data privacy a key constraint, especially when the server is an external service provider. techniques that bal- ance communication and computation costs while partitioning the compute between the edge and a resource-rich server have been deployed.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "[63]  Yang Wu, Jun Wang, Chun Chen, Chan-Juan Liu, Feng-Ming Jin, and Ni Chen. 2021. Adaptive Weighted Gerchberg-Saxton Algorithm for Generation of Phase- only Hologram with Artifacts Suppression.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "As discussed above in Sec. 3, both the user‚Äôs pose and the gaze position, as well as the targeted objects (intended to be re- placed by the virtual holograms) shape the hologram computation. Further, in many cases, these inputs are dynamically changing at the same frequency (e.g., the image sensors) as the frame-rate, which needs to be captured and updated at runtime, or even at a faster rate (e.g., the IMU and IR sensors).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "Also, where possible, the research material from this project will be integrated into the ML, architecture, and systems courses the PIs are regularly teaching at Penn State. Undergraduate Involvement : We will engage undergraduates, especially those from the Penn State‚Äôs Schreyer Honors College, in the planned research activities. Considering that a lot of motivated undergrad- uate students at Penn State are interested in ML and AI, we plan to assign well-defined projects from this research as ‚Äúhonors theses‚Äù.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "WoSC‚Äô20, December 7≈õ11, 2020, Delft, Netherlands ¬© 2020 Association for Computing Machinery. ACM ISBN 978-1-4503-8204-5/20/12...$15.00 https://doi.org/10.1145/3429880.3430093 \nACM Reference Format: Jashwant Raj Gunasekaran, Cyan Subhra Mishra, Prashanth Thi- nakaran, Mahmut Taylan Kandemir, and Chita R. Das. 2020.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "Each transformation emits out one low-coefÔ¨Åcient (LC) and one high-coefÔ¨Åcient (HC) by the following equation: \u0002 LC HC \n\u0003 = 1 ‚àö w 1  + w 2 \n\u0002  ‚àö w 1 ‚àö w 2 ‚àí ‚àö w 2 ‚àö w 1 \n\u0003\u0002 a 1 a 2 , \n\u0003 (1) \nwhere  w 1  and  w 2  are the weights for the two leaves ( # occupied voxels in this leaf), and  a 1  and  a 2  are the attributes. : First, RAHT [ 14 ] takes the initial octree (which is deepest now) as input, and invokes  RAHT and Quantization  to perform the linear transformation on the leaves with their siblings along the x, y and z dimensions, and shrinks the tree layer-by-layer. Now, the HC is quantized and entropy encoded, while the LC is further sent to the next  RAHT and Quantization  round and serves as the attribute of the large voxel/leaf in the upper layer.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 241,
    "augmented": true
  },
  {
    "text": "5.1. We discuss the impact of our proposal on output/result quality, compared to the baseline design, later in Sec. 5.4.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Introduce a discount factor Œ≤  ‚àà [0 ,  1) , and let  V i ( t  + 1)  represent the expected future utility of sensor  s i  given its current decisions and predicted energy availability. The cost is: \nC i ( t ) =  e i ( t ) +  Œ≤V i ( t  + 1) . The overall utility is: \nU i ( t ) =  R i ( t )  ‚àí C i ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Kraken  exhibits delay characteristics simi- lar to  Fifer  owing to both policies having batching and a similar container pre-deployment policy. However,  Kraken allocates fewer containers (57% lesser, on average across all applications) along each workflow compared to  Fifer . DProb and  SProb  exhibit higher overall end-to-end response times compared to  Kraken , with  SProb  experiencing a dispropor- tionately high queueing delay compared to its cold start delay.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with  Transition keep   for all the workloads with these power sources. 0.0% \n0.3% \n0.0% \n0.3% \n0.0% \n0.9% \n1.9% \n2.0% \n0.0% \n0.5% \n0.0% \n20.0% \n40.0% \n60.0% \nvs. # all inferences vs. # addi. inferences w/ smooth transition vs. # all inferences vs. # addi.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. frame (or skip the current frame).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "A 128kB SRAM serves as a scratchpad for storing activations, transposes, and intermediate differentials during the backward pass. The convolution map transforms  [ X  √ó Y  √ó  Z ]   M √ó C √ó W √ó H ‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí [ M  √ó U  √ó V ]  to yield an output tensor of dimensions  [ M  √ó  U  √ó  V ] , supported by a 256 banked double buffered output feature map SRAM, each bank of size 8kB (4kB/buffer). Input data broadcast to all tiles is managed by a 64kB double- buffered input feature map SRAM (32kB each), requiring ‚åà [ X  √ó Y  √ó Z ] / 1024 ‚åâ iterations for full input loading, with each buffer loaded  [ X  √ó Y  √ó  Z ] / 2048 times.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 213,
    "augmented": true
  },
  {
    "text": "). Challenges include aligning hetero- geneous data, managing communication costs, and dealing with unreliable or missing inputs. Existing methods may not account for the energy constraints and participation vari- ability inherent in EH-WSNs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "When introduced to a new set of constraints (change of power availability, accuracy etc. ), the micro-proÔ¨Åler Ô¨Årst looks in the history table to Ô¨Ånd a conÔ¨Åguration and runs proÔ¨Åling if and only if it could not Ô¨Ånd one. IV.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "The equilibrium prevents such non-stationary behavior in the long run. Furthermore, since the regularizers are deterministic and have bounded gradients, they do not add pathological con- ditions to the optimization landscape. They may alter the shape of  J ( Œ∏ ) , encouraging certain regions of parameter space, but they do not prevent convergence.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Considering the cheap commodity use storage devices are often plug and play, they are often vulnerable for data leak, especially if they are deployed in public, like urban mobility setting. Although modern encryption algorithms like RSA are secure, there is still a threat of  store now decrypt later 2   kind of attack (National Cybersecurity Center of Excellence (NCCoE), 2023). Unlike secure data centers, these federated, distributed and public deployment could be susceptible to direct physical attacks for data breach.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "give more importance in choosing the data which are unique and, in our case, contribute significant to the inference (i.e. To this end, we explore two different kinds of coreset construction techniques. 3.1 Coreset Construction Techniques \nCoreset Construction Using Importance Sampling:  An easy way to build a representation from a data distribution is to perform importance sampling [ 7 ,  8 ], i.e.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "the  Baseline , with only  10%  for the right-eye, translating to  28%  total energy saving. ‚Ä¢  PTU:  In the current state-of-the-art scheme, which is the hardware-based PTU [28], they explored the energy- efÔ¨Åcient hardware accelerator (namely, PTU) to replace power-hungry GPU. Due to this, one can observe from Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Keep the cost down: A review on methods to optimize llm‚Äô s kv-cache consumption, 2024. [149] Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catan- zaro. Megatron-lm: Training multi-billion parameter language models using model parallelism, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Award # 2338418 (CAREER: Trustworthy Human-Centered Summarization); PI: Zhang; duration=09/15/24-08/31/29; amount=$546,000. Intellectual Merit: This research advances trustwor- thy summarization by centering design, development, and deployment on humans in terms of user preferences for controllability, social perspectives for fairness, and human knowledge for factuality. Broader Impacts: This project initiates several aspiring education and outreach activities supported by project research outcomes to involve, mentor, and empower female, underrepresented, disabled, and interdisciplinary students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Glue: A multi-task benchmark and analysis platform for natural language understanding. In  Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP , pages 353‚Äì355, 2018. [160] Bo Wang, Maria Liakata, Arkaitz Zubiaga, and Rob Procter.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "Variation of cost of using VMs vs.  serverless functions  under constant request load. same application requires accuracy to be at-least 80% (ISO- accuracy), as shown in Figure  2b , four different models with different response latencies can satisfy the accuracy. Each of the four bars under any model type corresponds to request arrival rates of 10, 50, 100, and 200 requests/second.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "The inputs are fed to the x-bar, which is a two-dimensional array of ReRAM crossbar arrays. The crossbar arrays are composed of a set of row and column wires that intersect at a set of ReRAM devices (refer Figure 5b). The ReRAM devices are programmed to have different resistance values, which are used to store the weights.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Zookeeper: Wait-free coordination for internet-scale systems. [46]  Patrick Hunt, Mahadev Konar, Flavio Paiva Junqueira, and Benjamin Reed. In  USENIX annual technical conference , 2010.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "2020. Zynq UltraScale+ MPSoC ZCU102 Evaluation Kit. \"https://www.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 27,
    "augmented": false
  },
  {
    "text": "The pixel rendered at  [ x 0 l   , y 0 l   ]  on the left VR screen is mapped from position  [( x 360 ) 0 l   ,  ( y 360 ) 0 l   ] on the equirectangular  360 ¬∞ frame, as shown in Fig. 6a. Simi- larly, the pixel value rendered at  [ x 0 r , y 0 r ]  on the right VR screen \n247 \n0 \n2 \n4 \n6 \n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \nAvg.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Following are the key observations from our experiments. 1) The data sharing with the cloud increases the accuracy of the power prediction significantly (11.94% increase in correlation for a 2-home setup and about 25.62% increase in \n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 \n0.8 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.9 \nEdge \nCloud (Shared) \nCloud (Privacy) \nEdge \nCloud (Shared) \nCloud (Privacy) \nEdge \nCloud (Shared) \nCloud (Privacy) \nEdge \nCloud (Shared) \nCloud (Privacy) \n#Devices=2 #Devices=3 #Devices=4 #Devices=5 \nLatency (ms) \nPearson Correlation \nPearson Correlation Latency (ms) \nFig. 3: Accuracy-latency comparison of different policies with differ- ent distributed setup.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 206,
    "augmented": true
  },
  {
    "text": "Scenario-3, it indicates that the object(s) in the current frame are different from the last inference outputs (i.e., ‚Äúmissed‚Äù in Scenario-2, or ‚Äúentering/exiting‚Äù in Scenario-3) and hence, requires full inference (refer to Line  5  in Algo. 2). Otherwise, as can be seen from Line  6  to Line  8  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "[20] Lingjiao Chen, Matei Zaharia, and James Zou. Frugalml: How to use ml prediction apis more accurately and cheaply. In  Advances in Neural Information Processing Systems (NeurIPS) , 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "We can now transform our previously-assumed Markov Model into a VOMM by splitting up context-dependent states into multiple context-independent states (the number of which is dependent on the DAG structure and the order of the VOMM). For example, in Figure 5, if the transition from  Com- pose_Post  to  Post_Storage  depended on the immediate prede- cessors of  Compose_Post , the  Compose_Post  state would be context-dependent and would therefore, be split into context- independent states, namely,  ùê∂ùëúùëöùëùùëúùë†ùëí _ ùëÉùëúùë†ùë° | ùëáùëíùë•ùë° ( Compose Post  given ùëáùëíùë•ùë° was already invoked), ùê∂ùëúùëöùëùùëúùë†ùëí _ ùëÉùëúùë†ùë° | ùëÄùëíùëëùëñùëé etc. for the previous equations to hold.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 165,
    "augmented": false
  },
  {
    "text": "The PIs will leverage their complementary experience in developing appropriate research thrust areas within the scope of LLM to attract and engage a new cohort set of minority undergraduate students in research. ‚Ä¢  Broad Reach to K-12 students:  We will partner with CSATS (Center for Science and the Schools) in the College of Education at Penn State to leverage their ongoing Penn State STEM-oriented outreach pro- grams. We have had continuous partnership with the CSATS faculty for over 5 years and have hosted \nday-long seminars for middle school and high school teachers as part of our prior NSF funded outreach efforts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "0 \n50 \n100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nChest Left Ankle Right Wrist Majority Voting \nFig. 2:  Accuracy of the individual DNNs and with a majority voting ensemble for different activities. Thus, the DNN architectures to infer these data are also different.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "This processing can be quite time-consuming, and our proÔ¨Åling shows that it usually takes  ‚âà 5 . 9 s  to compress one predicted PC frame even when running on 4 CPU threads. Instead, our proposal takes advantage of the Morton code generated in the geometry compression, which is a good indicator for attribute similarity (as discussed earlier in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efÔ¨Åciency under stable, high-power scenarios. During the eight harvested power cycles, the ReRAM can be ON during power cycles  PC3, PC6  and  PC7  and OFF with the other Ô¨Åve power cycles. However, even when the system goes through the three power cycles, only some portion of the harvested power is consumed.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Therefore, instead of recording the exact attribute values for all the points within a segment, we only need to Ô¨Ånd the ‚Äú median value ‚Äù of these attributes (as base) and then compute and compress the  residual values (as deltas) for these points. Fortunately, these computations are light-weight, and can be performed in parallel. ‚Ä¢  Quantization:  Finally, these small residual values are quantized to further improve the compression ratio.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "This strategic compute-reuse could help in optimizing the efficiency and efficacy of computational operations, especially in large scale data intensive and data driven applications. 2.3 Why Not More Compute at Storage Stacks? Integrating additional compute capabilities within storage stacks to offload certain computational tasks may seem an intuitive solution to the problem at hand.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "GROOT: A Real-time Streaming System of High-fidelity Volumetric Videos. 2020. [27]  Kyungjin Lee, Juheon Yi, Youngki Lee, Sunghyun Choi, and Young Min Kim.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "4.3). We leverage such foveated rendering idea in  Inter-Holo as our  Reference  design in this paper. 2 and Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "Representation learning solves both these issues. The learner (here the teacher models) need to properly classify the data, learn if the data is a new type of one of the older classes, and identify if it encounters a new class. We achieve this by clustering the feature vector of the Large DNN model.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "https://doi.org/10.1145/3472883. 3486992 \n1 Introduction Cloud applications are embracing microservices as a pre- mier application model, owing to their advantages in terms of simplified development and ease of scalability [ 29 ,  40 ]. Many of these real-world services often comprise of tens or even hundreds of loosely-coupled microservices [ 42 ] (e.g.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Furthermore, as we can see in Fig. 9, HEVC takes significantly more latency compared to  Salient Store  and therefore not entirely suitable for high frame-rate applications with resource constraints. 30 \n35 \n40 \n45 \n50 \n0 0.2 0.4 0.6 0.8 1 \nPSNR (dB) \nBits per Pixel \nH264 H265 Salient Store \nFigure 8: Compression and Recovery efficiency.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, it is equipped with a 512-core Volta GPU, a 8-core ARMv8 64-bit CPU, and 32GB 256- Bit LPDDR4x Memory. In our implementation, we start the application from CPU (reading the PC data), and then ofÔ¨Çoad the computations to GPU (octree construction, block matching, etc. ), and the compute mode of Jetson AGX Xavier board is set to be 15W.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "[55] Wikipedia, ‚ÄúVirtual Reality.‚Äù ‚Äùhttps://en.wikipedia.org/wiki/Peak signal-to-noise ratio#: ‚àº :targetText=Typical \\ %20values%20for% 20the%20PSNR,20 \\ %20dB%20to%2025%20dB.‚Äù, 2019. wikipedia.org/wiki/AMOLED‚Äù, 2019. [56] B.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "III. In fact, the inference of VGG-16 [31], which is a popular DNN model, takes 240  ms  to execute on an embedded Adreno 640 [32] GPU, which is far from  real-time . S IMILARITY IN  V IDEO  A PPLICATIONS \nDue to the limited computing resources and the strict power/energy budget constraints [2], enabling high-quality fast inference on mobile devices is very challenging for DNN applications (e.g., object detection for videos).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "(c) Reusing projection matrices by exploiting relation between both eyes and fusing it with head orientation. the video buffer to present the  decoded  frames, the  360 ¬∞ video frames require ‚Äúadditional rendering effort‚Äù to get displayed. More speciÔ¨Åcally, the rendering process is a projection from the  360 ¬∞ frame pixels‚Äô 3D coordinates to the 2D frame pixels‚Äô 2D coordinates on HMDs.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "IEEE, 2021. 1775‚Äì1786. In  2021 IEEE 37th International Conference on Data Engineering (ICDE) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "[30]  Xiaoxu Meng, Ruofei Du, and Amitabh Varshney. Magic Leap 1 is a Wearable Computer for Enterprise Produc- tivity. \"https://www.magicleap.com/en-us/magic-leap-1\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "[2] K. Boos, D. Chu, and E. Cuervo, ‚ÄúFlashBack: Immersive Virtual Reality on Mobile Devices via Rendering Memoization,‚Äù in  Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services , ser. MobiSys ‚Äô16, 2016, pp. 291‚Äì304.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "From our observations in  AWS Lambda , three types of cores are allocated in the increasing order of the memory allocation ( 0.5GB, 1.5GB, and  > 2GB ). Through offline profiling or initial runs, we can de- termine the right memory allocation for a given response latency. Also, these policies can be changed over time by Amazon, and they can also be dif- ferent for other cloud providers [ 8 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Thus, a typical PC frame containing  10 6 \npoints [ 49 ] require  120 M  bits of data, which is impossible to transmit in real-time to the end-user‚Äôs display, from both the latency and energy standpoints, considering a \nsteady  30 - 60  f ps  requirement. Thus, to represent one point,  4 byte √ó 3  +  1 byte √ó 3 = 15 bytes  are needed ( 4 byte s per coordinate and  1 byte  per color component). Further, each point in the PC is associated with 3 coordinates (x, y, z) for the geometry and 3 colors (R, G, B) for the attribute.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Although we can arrange more hardware resources with the pipelined computation mode, it does not mean this mode will always yield greater computation progress than the sequential mode due to the constraints of tile size and parallelism granularity. P   pipe   = \nLC X \nLk =1 P Lk (4) \nLat pipe   =  max ( Lat L 1 , Lat L 2 ...Lat LC ) (5) \nC. Dynamic activation strategy \n1) Problem formulation:  In this section, we focus on Ô¨Åguring out the ResiSchedule solution to achieve the maximal throughput.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "USENIX Association. Fusing kernels for higher performance deep learning. [170] Wei Xu, E-Sheng Peh, and Edward Wong.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "Targeting them, prior efforts have proposed to optimize their compression ratio, processing performance, and energy efficiency [ 8 ‚Äì 10 ,  16 ,  27 ,  67 ‚Äì 70 ]. For example, ASV lever- ages characteristics unique to stereo vision and proposes algorith- mic and computational optimizations to improve performance and energy-efficiency of ‚Äúdepth from stereo‚Äù [ 11 ]. Tigris proposes an algorithm-architecture co-design system specialized for point cloud registration, to improve real-time performance and energy effi- ciency for 3D perception applications [ 65 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "3274‚Äì3280. [83]  D. Valenzuela-Urrutia, R. Mu Àú noz-Riffo, and J. Ruiz-del Solar, ‚ÄúVirtual reality-based time-delayed haptic teleoperation using point cloud data,‚Äù  Journal of Intelligent & Robotic Systems , vol. 96, no.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "To better understand where the beneÔ¨Åt comes from, next we go over a simple example, given in Fig. 5 , and answer the following three critical questions:  i) how to increase parallelism for the bottleneck steps? ,  ii) how to integrate such optimizations into the entire geometry compression pipeline?",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Yen, H. R. Mendis, T.-W. Kuo, and P.-C. Hsiu, ‚ÄúStateful neural \networks for intermittent systems,‚Äù  IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems , vol. [104] C.-H. 41, no.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "To achieve this, the PWS  2  first fetches relevant system metrics (using a monitoring tool  3  and orchestrator logs). These metrics, in addition to a developer-provided DAG Descriptor  4  , are then used by the Weight Estimation module  2a  of PWS  2  to assign weights to functions on the basis of their invocation probabil- ities. Commonality  and  Connectivity  (parameters in  2a  ) are additional parameters used in weight estimation to account for critical and common functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Inference with L2 Dynamic Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. Calculate the gradients of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \n16 \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the L2 norm of the weights: \np i  = Œ± ‚à• W i ‚à• 2  +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise Perform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 336,
    "augmented": true
  },
  {
    "text": "177‚Äì186. HotMobile ‚Äô16, 2016, pp. [34] H. Miao and F. X. Lin, ‚ÄúTell Your Graphics Stack That the Display Is Circular,‚Äù in  Proceedings of the 17th International Workshop on Mobile Computing Systems and Applications , ser.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Therefore, to classify the next possible activity, we activate the sensor which is most accurate for classifying the anticipated activity. This motivates us to develop an  activity-aware scheduling  (AAS) policy which aims to activate the best suited sensor for the anticipated activity. B.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "In order to determine the weight of every class, we use a per-class dictionary that keeps track of the correct predic- tions of every model per class. We populate the dictionary at runtime to avoid any inherent bias that could result from varying images over time. Similarly, our model selection pol- icy is also changed at runtime based on correct predictions seen during every interval.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "[45]  S. Martin, M. Stefan, A. Karl  et al. , ‚ÄúComplex-yolo: real-time 3d objectdetection on point clouds,‚Äù in  Computer vision and pattern recognition , 2018. [46]  Mayank Raj, ‚ÄúPoint Clouds and its signiÔ¨Åcance in AR,‚Äù  ‚Äùhttps: //bit.ly/3uknBjT‚Äù , 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "A hierarchical K-means+ (or DBSCAN) clustering approach learns representations for exemplar se- lection. ¬¥as  employs an ensembled teacher-student method, wherein multiple teachers annotate student data. To overcome these limitations,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Ensemble pruning via individual contribution ordering. In  Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ‚Äô10, page 871‚Äì880, New York, NY, USA, 2010. Association for Computing Machinery.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Restrictions apply. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. compression (PCC) pipeline which is  fast  (within or close to real-time),  accurate  (with good quality), and  efÔ¨Åcient (with high compression ratio).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference. Still, with Condition trans   satisÔ¨Åed, the smooth transition can be achieved in a similar way. Otherwise, if the expression  Condition trans \nis not satisÔ¨Åed, with power prediction, we can still speculatively attempt to perform a smooth transition.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "Association for Computing Machinery. [13]  Marian Stewart Bartlett, Gwen Littlewort, Mark Frank, Claudia Lain- scsek, Ian Fasel, and Javier Movellan. Recognizing facial expression: machine learning and application to spontaneous behavior.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "25 ,  0 . 25] , where the classiÔ¨Åer is equally confused between all the classes. 25 ,  0 .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Moreover, our proposal not only accelerates the PC encoding stage, but also can improve the performance of the decoding stage which involves inverse encoding operations (e.g., reduces decoding latency to  ‚âà 70 ms ), thus enabling the end-to-end PC processing in near real-time (i.e., 10FPS). While with our inter-frame compression design, the compression ratio can be further improved (increasing from 5.95 in intra-frame design to 10.43) with 35 √ó  speedup and 97.4 %  energy savings with respect to a state-of-the-art inter-frame PCC scheme [ 13 ]. II.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "In  16th USENIX Symposium on Networked Systems Design and Implementa- tion (NSDI 19) , pages 699‚Äì718, Boston, MA, February 2019. [59]  Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gregory R Ganger, Phillip B Gibbons, and Matei Zaharia. USENIX Association.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Available: http://arxiv.org/ abs/1612.08350 [7] Facebook, ‚ÄúFacebook 360,‚Äù ‚Äùhttps://facebook360.fb.com/‚Äù, 2019. [8] Facebook Inc., ‚ÄúFacebook Oculus,‚Äù ‚Äùhttps://www.oculus.com/‚Äù. [Online].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "when some of the tiles are half way through the compute, some other tiles can just start execution). However, in the middle of an kernel execution iteration, if the hardware gains access to more power which in turn can enable more tiles, it cannot do so without breaking synchrony (i.e. Eager Scheduling:  A weight stationary implementation with a conservative scheduling will always run synchronously.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "The exemplar set signiÔ¨Åcantly impacts the accuracy in two ways: 1. missing valid exemplars will result in the student model missing out in learning vital information, increasing its drift, and 2. a wrong annotation by the teacher can also result in the student learning wrong labels, resulting in increased mis-predictions. To avoid this, in  Us. ¬¥as , the teacher models perform majority voting to decide the right exemplar, which signiÔ¨Åcantly reduces false positives and true negatives (refer to the top bar in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. 4413.87 4243.51 3190.25 3135.99 \n0 1000 2000 3000 4000 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Human creativity in the age of llms: Randomized experiments on divergent and convergent thinking. arXiv , arXiv:2410.03703, 2024. Available at:  https://doi.org/10.48550/arXiv.2410.03703 .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Note that the power predictors used in prior works are meant for Ô¨Åckle energy harvesting scenarios like piezoelectric (movement), or RF (WiFi). 2 F super-capacitors connected in parallel to a voltage regulator \ncircuit. The harvested power is given as an input to a mov- ing average power predictor [ 61 ], [ 72 ] to predict the future available power.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Although efÔ¨Åcient hardware accelerators [ 16 ], [ 27 ], [ 80 ] have been developed to do the same, these ac- celerators are typically designed with a ‚Äúthroughput-Ô¨Årst‚Äù \n895 \nAuthorized licensed use limited to: Penn State University. By doing this,  Us. ¬¥as  keeps  both  the student and the teacher models ‚Äúupdated.‚Äù Since the feature space of the teacher model is updated using K-means+, the major computation is the training of the student model using the exemplar data.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "The distribution of the absolute differences (deltas) between the pixel values in successive frames plotted in Fig. Instead, one may want to consider alternate similarity metrics that can lead to richer reuse opportunities. As a result, any approach trying to exploit frame reuse (e.g., skip inferences for similar frames) based on this speciÔ¨Åc similarity metric (exact pixel match) will not have much scope for optimization.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Struc- tured in space, randomized in time: Leveraging dropout in rnns for efficient training. [140] Anup Sarma, Sonali Singh, Huaipan Jiang, Rui Zhang, Mahmut Kandemir, and Chita Das. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "The heavy compute demand of the hologram (re)construction has made this a promising candidate for acceleration, and prior works have tried to offload it to cloud [ 16 ,  27 ,  67 ] and specialized accelerators [35] to achieve high throughput, but doing so has led the communication with the edge device to be a major bottleneck. 2), we profiled a set of applications and found that the  hologram  processing is the primary bottleneck in terms of computation, energy consumption, and execution latency. Others have proposed to design efficient and lightweight deep neu- ral networks (DNNs) to achieve high quality scene rendering at the edge device itself, but this requires model retraining/tuning for a particular user [ 33 ,  54 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 169,
    "augmented": true
  },
  {
    "text": "Our LLM expert repository offers a rich set of diverse skills and domains to serve a user query. As a user query can be possibly answered by different sets of experts, we will choose experts based on the combination of two factors: (1) The relevance of expert to the user query, and (2) the availability of accelerator (developed in Thrust 3) for the expert. We will conduct the following research to incorporate the availability of expert accelerators, memory constraints, and workload balance to inform our algorithmic choices: Selecting Experts based on Available Expert Accelerators.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Also, we will identify the most common or frequently accessed experts within and across EoEs. Thus, to cater to the execution diversity in experts, we intend to take advantage of ‚Äúheterogeneous‚Äù chiplets. For these metrics, the expert execution may favor different hardware devices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "285 \nAuthorized licensed use limited to: Penn State University. IV-C 1 ), and macro block-based motion compensation pipeline for inter-frame compression \n3 We use PCL [ 72 ] and TMC13 [ 56 ] library for our proÔ¨Åling, where the geometry is compressed by the octree structure in PCL, and the attributes (RGB colors) are compressed through RAHT in TMC13. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "[51] M Sandler, A Howard, Menglong Zhu, Andrey Zhmoginov, Liang- \nChieh Chen , ‚ÄúMobilenetv2: Inverted residuals and linear bottlenecks,‚Äù in  CVPR , 2018. USENIX Association, 2018. [52] K. Maeng and B. Lucia, ‚ÄúAdaptive dynamic checkpointing for safe \nefÔ¨Åcient intermittent computing,‚Äù in  OSDI .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "We have 10 (therefore N = 10) such models and among them the least accurate model is MobileNetV1 (accuracy 70%, therefore a = 0.70). We need to Ô¨Ånd the probability of at least 6 of them being correct. Using the equation above we Ô¨Ånd the probability to be \nP head  = 10 ‚àë i = ‚åä 10 \n2   ‚åã + 1 = 6 \n\u0012 10 i \n\u0013 0 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "[76]  J. Shao, H. Zhang, Y. Mao, and J. Zhang, ‚ÄúBranchy-gnn: A device-edge co-inference framework for efÔ¨Åcient point cloud processing,‚Äù in  ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , 2021, pp. 8488‚Äì8492. [77]  R. Shumaker and L. Stephanie,  Virtual, Augmented and Mixed Reality: Designing and Developing Augmented and Virtual Environments: 6th International Conference, VAMR 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014, Proceedings, Part I .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "The necessary adjustments will be made if the observed progress is not satisfactory. The PIs will meet with the PhD students as frequently as needed. They will not only evaluate whether the individual and intermediate research goals have been achieved or not, but  will also discuss the progress towards achieving the educational and outreach/BPC goals of the project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Performance-Power Trade-offs:  As Table  II  suggest,  Us. ¬¥as does not deliver the highest throughput and also consumes more power compared to the other accelerators. Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Motivated by this, we propose a novel framework  T ree  E nsemble- o f- E xperts (TEoE). Since knowledge domains often exhibit a hierarchical structure, it is natural to model an EoE using a hierarchical approach to save training and inference costs further. Specifically, given a knowledge domain of  k  layers, we assign the structure to  k  adjacent FFNN expert layers in an EoE model, where the  i th layer indicates the  i th level of the knowledge.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "It can be seen that functions which are common to a larger number of paths are invoked at a higher rate by such a request arrival pattern. Common func- tions refer to those which are a part of two or more paths within an application DAG. Figure 4 shows the ‚Äòhit rate‚Äô of \nfunctions within an application that is subject to a constant load where any path in the application is equally likely to be picked.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Although the prior works do add value to video analytics, each comes with its own problems and costs. SpeciÔ¨Åcally, with limited energy budget or available models, MCDNN suffers from accuracy drops. In comparing these prior approaches with ours, we consider Ô¨Åve critical features of DNN-based video optimization, shown in Table I: high accuracy, high performance improvement and energy sav- ings, the hardware enhancement needed, generality of decision making logic for proper approximation and correspondingly, the adaptation to various runtime conditions.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "However, a very small fraction is observed with the other, stronger power sources. For Piezo , saving the intermediate results of one incomplete inference is meaningful. However, one power cycle of the other power sources can usually process thousands or hundreds of inferences.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "166 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \n[41]  Mohammad Shahrad, Jonathan Balkind, and David Wentzlaff. 2019. Architectural implications of function-as-a-service computing.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "With these sensors and compute resources in place, an AR head- set executes a set of software tasks, either entirely or selectively based on the applications‚Äô requirements [ 19 ]. Hence, the power/energy efficiency is critical metrics in many AR use cases so that the battery lifetime can be sufficiently long. This is for enabling users to freely move around in a large area without the need of connecting with a power cable constantly.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Challenges with Data Compression: Using standard compression algorithms, like discrete cosine transform, dis- crete wavelet transform, and Fourier decomposition etc., to minimize the communication overhead is not a viable solu- tion [ 45 ]. The obvious solution is to reduce the communication data volume by compress- ing the data before transmitting. This also reduces energy footprint and the probability of data packet loss.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "The hardware design details will be presented in Section V. \nIV. A  HARVESTING - COMPATIBLE ,  LOW - \nPOWER  R ESI RCA \nSupporting the necessary features for adapting RCAs to a harvested power supply will require optimizations in both RCA circuit design and the development of variable-power-optimized loop-tiling strategies. First, feasible implementations of Ô¨Çexible activation options require a low power and reconÔ¨Ågurable RCA.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. SpeciÔ¨Åcally, with limited energy budget or available models, MCDNN suffers from accuracy drops. Also, if the approximation opportunity incurs high overhead and/or the decision is made based on high-level features, the scope for performance/energy savings \n1073 \n2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) \n2575-8411/22/$31.00 ¬©2022 IEEE DOI 10.1109/ICDCS54860.2022.00107 \n2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) | 978-1-6654-7177-0/22/$31.00 ¬©2022 IEEE | DOI: 10.1109/ICDCS54860.2022.00107 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 196,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Finally, we evaluate Us.¬¥as in depth on a  real-world trafÔ¨Åc \ndata set  [ 97 ] and perform sensitivity studies on other classes (audio, IMU) of data. Power estimations of our hardware design, modeled by Design Compiler [ 93 ], indicate that the proposed morphable accelerator approach can save up to 234.95kWH/year/edge-server, compared to running continuous learning on a state of the art DNN accelerator and 2.63MWH/year/edge-server, compared to utilizing a datacenter-scale GPU for learning on the edge. Our algorithmic framework for performing continuous learning has a 4.96% greater mean accuracy than a na¬®ƒ±ve continuous learner.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 166,
    "augmented": true
  },
  {
    "text": "Hashan Roshantha Mendis, Chih-Kai Kang, and Pi-cheng Hsiu. Intermittent-aware neural architecture search. ACM Transactions on Embedded Computing Systems (TECS) , 20(5s):1‚Äì27, 2021.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "As also mentioned in Sec. 2.1, the 16 depth planes required by most of the AR applications (typically 10 to 100 depth planes are sufficient) [ 19 ,  49 ] consume more than 300 ms , which is 10 √ó  larger than the real-time (QoS) requirement. Thus, it can be concluded that, without any optimization, a state- of-the-art edge GPU is only able to compute for  <  4 depth planes in real-time [ 36 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "In our evaluation, we will employ both architecture-level and LLM/application-level met- rics. The former includes execution cycles, energy consumption and carbon footprint (by extending GA4HPC [11]). In addition to these, we will also use LLM/application-level metrics such as LLMOps (an extension of MLOps [84] tailored for LLMs).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 5a  Salient Store \n14 \n0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nNormalized Latecy \nCompute Server \nVSS \nStorage Server \nFigure 6: Impact of scaling to multiple storage nodes. keeps up with the accuracy of the traditional compression system thanks to the robust layered coding algorithm.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Results collected over 200 experiment cycles. Class Full Power AP PT iNAS+PT Stateful ePerceptive DynBal NExUME \nR1 84.93 74.46 77.02 79.62 80.85 81.50 82.15 83.60 R2 85.85 76.21 79.18 80.36 81.95 82.60 83.25 84.50 R3 81.09 72.43 75.38 78.18 79.05 79.70 80.35 80.85 SJ 90.95 82.33 85.00 87.58 88.60 89.15 89.80 90.50 SI 94.76 85.31 88.05 89.90 91.00 91.65 92.30 93.00 Table 3: Accuracy of NExUME and other methods for industry status monitoring dataset using TI MSP board and piezoelectric energy source. NExUME demonstrates superior performance across all operating classes, achieving the highest accuracy in each case.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 245,
    "augmented": true
  },
  {
    "text": "The results from the workers are  ensembled  using an weighted majority voting aggregator  3  to agree upon a correct prediction. To efÔ¨Åciently address the resource management and scalability challenges,  Cocktail  applies multiple strategies. First, it maintains dedicated instance pools to serve indi- vidual models which simpliÔ¨Åes the management and load balancing overheads for every model.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "[49]  Martin Persson, David Engstr√∂m, and Mattias Goks√∂r. 2011. Real-time Generation of Fully Optimized Holograms for Optical Trapping Applications.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Moreover, applications like Record3D [ 44 ] enable seamless PC media streaming from phone to a wearable, encouraging a perpetually increasing PC content generation and consumption. However, the sheer volume of the data captured in these PC applications coupled with the limited compute and storage capabilities of these handheld devices pose a challenge in high quality PC media capture, storage and consumption [ 26 ]. To understand these challenges, we analyze an end-to-end PC pipeline.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Moreover, as stated in the proposal, we will collaborate with Argonne National Lab specifically for the experimental evaluation thrust of the project. These partnerships will also provide external insights to the project, and in particular, our collaboration with ANL enable us to access a large number and variety of compute platforms (including those with accelerators). A letter of collaboration is included as a supplementary document (our partnership with ANL already generated a SIGMETRICS paper [26], and we will also be submitting a joint paper to MLSys by the end of October 2024).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "[52] Google. Google notebooklm. \" https://notebooklm.google/ \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "To implement these three possible decisions (FI, SI, and PI) that can be made by the  Decision Maker , the  Inference Engine  in Fig. 7 takes the corresponding actions: Full Inference:  When the incoming frame contains critical information such as new objects entering, a full inference is needed. In this case, the current frame is processed on the CPU to report the Ô¨Ånal result.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "The idea is to use the inverse of the L2 norm to determine the probability: \np i  = Œ± ‚à• W i ‚à• 2  +  œµ \nwhere  Œ±  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. Define a binary dropout mask  m  = [ m 1 , m 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Figure 10: Real System: Comparison of Total Number of Containers spawned VS SLOs satisfied by each policy. 0 \n300 \n600 \n900 \n1200 \n1500 \nArch Fifer DProb Kraken SProb Xanadu \nJobs per Container \nFigure 11: Real System: Comparison of Container Utilization (a.k.a. The Primary Y-Axis denotes the number of containers spawned, The secondary Y-axis indicates the percentage of SLOs met and the X-axis represents each policy.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "This is the primary motivation of this paper, where we explore trade-offs between hologram quality and processing costs. Despite providing significant performance and energy-efficiency benefits, these prior works still miss out on even more selective rendering of viewed hologram images - beyond just the FoV and/or regions of the user‚Äôs focus. These trade-offs are not very straightforward due to the following  challenges : First,  among all of the inputs to the AR headset (shown later in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "926‚Äì932. [2]  Andrei Frumusanu, ‚ÄúThe Snapdragon 888 vs The Exynos 2100: Cortex-X1 & 5nm, Who Does It Better?‚Äù  ‚Äùhttps://bit. ly/3OF66Tw‚Äù , 2021.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Design of an RFID-based battery- free programmable sensing platform. IEEE transactions on instrumen- tation and measurement  57, 11 (2008), 2608‚Äì2615. [63]  Himanshu Sharma, Ahteshamul Haque, and Zainul Abdin Jaffery.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "An encounter of a new example of the existing class is followed by an update to the clustering by minimizing the classiÔ¨Åcation loss of the newly-seen data. Case-3:  Finally, if the classiÔ¨Åer sees an example of a new class then the feature vector of the data sits far from all the cluster centers indicating an unknown class. The distance of this feature vector from the other cluster center is called ‚ÄúclassiÔ¨Åcation loss‚Äù [ 74 ], and this re-triggers clustering with an updated number of clusters.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "(c): Compression efÔ¨Åciency. (b) Energy consumption. in parallel with the help of Morton codes, which speeds up the geometry compression by  37 √ó ; 2).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "Figure 3: Microarchitectural designs of HSPM and SDMM: Hardware modules for polynomial multiplication in LBC. unit commences the modular multiplication of each coefficient  a i  with the entirety of  b ‚Äôs coefficients in parallel. This process repeats for all coefficients  a i .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [ 8 ] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets. It includes four ReRAMs, each 32x32. The inputs and weights are binary and the output is adaptive between 1-3 bits.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Conventionally, training is much more compute intensive (compared to an inference), takes many iterations and hence has been given considerable attention for better accuracy and convergence time. The trained models can then be used to perform inferences, i.e., the clas- sification task. Since typical large scale DNNs have millions of parameters and perform billions of multiplications and accumulations for executing a single inference, they are typ- ically hosted as web-services, which are often queried for predictions.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "Calculate the gradients and Hessians of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij , ‚àÇ 2 L ‚àÇW   2 ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) If  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the sensitivities: \np i  = Œ≤   P j ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \nmax \u0010P j ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \u0011 +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Inference with Optimal Brain Damage Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 388,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, as shown in Fig. III-B , which indicates that the locality revealed by \nthe Morton codes does not only exists among the geometry data, but it can also help with the attribute compression. Note that, the Morton codes have already been generated as intermediate results during the geometry compression, thus, can be (re)used to identify the spatio-locality for the attribute compression without any extra cost.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Fig. The typical  archival process  involves three key phases: compression, encryption, and redundancy. Furthermore, given the plug-and-play nature of storage media like HDDs and SSDs, securing this data becomes even more critical.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "IEEE, 2018. [11] Green Algorithms. Green Algorithms 4 HPC, August 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "2 s , respectively, to compress one PC frame on an edge platform, which are signiÔ¨Åcantly higher than the real-time requirement ( ‚âà 100 ms  [ 19 ]), making them even more challenging to employ in emerging edge devices. To address this, we study the SOTA compression pipelines and observe that the main reason behind their performance inefÔ¨Åciencies is their  sequential updates  to the global result with each intermediate local runtime state  in a  point-by-point fashion. 1 s  and  4 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "The critical challenge of deploying ML prediction serving applications in public cloud is to combine both model and resource heterogeneity towards optimizing for application constraints. In this paper, we propose to build a self-managed ML prediction system, which can optimize the diverse application requirements based on characteristics of heterogeneous public cloud resource offerings. Towards this, we discuss the trade-offs of intermixing resources like serverless functions along with VMs and identify the key challenges associated with configuring these resources.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "[57] Meta, ‚ÄúSharing our progress on combating climate change = https://about.fb.com/news/2022/11/metas-progress-on-combating- climate-change/ ,‚Äù (Accessed on 11/21/2022). [58] Meta, ‚ÄúSustainability: Data centers,‚Äù  https://sustainability.fb.com/data- \ncenters/ , (Accessed on 04/28/2023). [59] Microsoft, ‚ÄúBuilding world-class sustainable datacenters and investing \nin solar power in arizona,‚Äù https://blogs.microsoft.com/on-the- issues/2019/07/30/building-world-class-sustainable-datacenters-and- investing-in-solar-power-in-arizona/ , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 186,
    "augmented": false
  },
  {
    "text": "Additionally, by clustering and scheduling experts that share training datasets, we propose a ‚Äúlocality-aware‚Äù training strat- egy that minimizes the frequency and volume of data transfers between experts, memory and storage‚Äì a key factor in improving both performance and energy efficiency. We plan to model this problem using a ‚Äúbipartite graph‚Äù (refer to Figure 4) where one set of nodes represent disjoint datasets (D1, D2, etc.) and the other represent experts (E1, E2, etc.).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "To these ends, we propose Us.¬¥as,   1   a HW-SW co-design approach to building sustainable, scalable, drift-mitigating edge analytics platforms using harvested power to support continuous learning. Us.¬¥as, unlike prior edge-focused analytics approaches (e.g., Ekya [ 12 ]), detaches the inference and train- ing hardware, as the training task is the major source of the compute, power, and time consumption. An ideal solution would entail a battery-free system ( not  energy storage- free, i.e., still with some capacitive storage), circumventing these concerns and aligning with the objectives of sustainable and reliable continuous learning at the edge.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "To prevent myopic strategies, one can limit  Œ≥  such that continuously investing in high-SNR captures does not dominate long-term considerations. For example: \nŒ≥  ¬∑  ‚àÜ A max  < Œ∑  +  margin , \nwhere  margin  accounts for future opportunities and energy savings. 7 \n385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 \nEnergy Preservation: If  Œ≥  is too large, sensors might not value future energy at all.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 191,
    "augmented": true
  },
  {
    "text": "The modular nature of our system allows experts to be trained separately and then combined in multiple configurations. ; and iv)  How do compute and memory resource constraints and runtime environments influence our algorithmic decisions? This thrust aims to advance the state-of-the-art by proposing an innovative framework built on a network of specialized LLM experts that can operate both independently and in collaboration.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "9b. Such small amount of overhead indicates that our decision-making logic is efÔ¨Åcient and light-weight. 2) Energy Savings:  As shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "5, pp. 1217‚Äì1228, 2015. [43]  Marek Kowalski, Jacek Naruniec, ‚ÄúLiveScan3D-Hololens,‚Äù \n‚Äùhttps://github.com/MarekKowalski/LiveScan3D-Hololens‚Äù , 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Hence, classes that did not get the highest votes can still be the Ô¨Ånal output if the models associated with that class has a higher weight, than the combined weights of highest voted class. Unlike commonly used voting policies which assign weights based on overall correct predictions, our policy incor- porates class-wise information to the weights, thus making it more adaptable to different images classes. In order to determine the weight of every class, we use a per-class dictionary that keeps track of the correct predic- tions of every model per class.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "[19] Coral.ai, ‚ÄúEdge tpu performance benchmarks =  https://coral.ai/docs/ \nedgetpu/benchmarks/ ,‚Äù (Accessed on 11/21/2022). [20] D Maltoni, V Lomonaco, ‚ÄúContinuous learning in single-incremental- \ntask scenarios,‚Äù in  Neural Networks , 2019. [18] A. F. CNBC, ‚ÄúHow trafÔ¨Åc sensors and cameras are trans- forming city streets,‚Äù  https://www.cnbc.com/2021/02/22/how-trafÔ¨Åc- sensors-and-cameras-are-transforming-city-streets.html , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 161,
    "augmented": true
  },
  {
    "text": "2) Motion Vectors:  The motion vector (MV), which is built upon pixel differences, can be a good candidate to capture the reusability in video analytics. A MV is a 2-D vector that provides an offset from the coordinates in the decoded frame to the coordinates in a reference frame [34], which can be directly obtained from the codec [35] without any post-processing. As opposed to the software-based ‚Äúoptical Ô¨Çow‚Äù solution widely used in the computer vision domain [36], collecting the MV from the  codec hardware  is quite light-weight.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Portfolio-driven resource management for transient cloud servers. Proc. ACM Meas.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 21,
    "augmented": false
  },
  {
    "text": "We ensure its performance by: 1. 2. Empirical Validation : We compare the heuristic‚Äôs \n5 \nperformance with the optimal solution on smaller problem instances using exhaustive search and find that the heuristic achieves within 95% of the optimal task completion rate.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Association for Computing Machinery. [103] Eitan Medina and Eran Dagan. In  Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing , HPDC ‚Äô24, page 227‚Äì239, New York, NY, USA, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "3c). In this case, although the MV is smaller than the bounding boxes, its position is on the edge, indicating that a new object is entering the frame. iii  Entering/Exiting Object(s) : Another scenario is where one or more objects are moving into or out from a frame (refer Frame-2 in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Our probability-based policy, on the other hand, provisions containers for func- tions along  every possible path in proportion to their assigned weights . Note that variability in application usage patterns can lead to changes in function probabilities within each DDA, which the policy will have to account for. Consequently,  Xanadu , when subject to moderate/heavy load, over-provisions containers by 32% compared to the Probability-based policy (from Figure 2) as a result of being locked into provisioning containers for the MLP until it is able to recalculate it.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "V ), given the points sorted in the Morton code order, the search space for block matching in our proposal is minimized (in the I-frame, now, we only need to search the neighboring regions for the current P-block); 2). for the matched macro block, instead of executing the complex iterative closest point (ICP) [ 7 ] algorithm for the translation and rotation matrix, we only need to record a pointer to the matched block in I-frame, without any extra computation overhead. ‚Ä¢  Our Intra-Inter-V2 (Compression efÔ¨Åciency-oriented):  Sim- ilarly, our Intra-Inter-V2 scheme (oriented towards high \n293 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "In DNN training, meticulous compute mapping, mem- ory access strategies, and operational formulas are instru- mental for the forward and backward passes. The for- ward pass computes activations via the formula  A muv  = ‚àë C ‚àí 1 \nc = 0   ‚àë H ‚àí 1 \ni = 0   ‚àë W ‚àí 1 \nj = 0   X ( u + i )( v +  j ) c   ¬∑ K mijc , with results stored in the double-buffered output feature map SRAM. The backward pass emphasizes gradient computation through backpropaga- tion, which is crucial for weight updates.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "To address this, we study the SOTA compression pipelines and observe that the main reason behind their performance inefÔ¨Åciencies is their  sequential updates  to the global result with each intermediate local runtime state  in a  point-by-point fashion. Moreover, there has been little effort in parallelizing them on the state-of-the-art commercial systems, let alone on any edge/mobile devices. Prior works on PCC acceleration [ 19 ], [ 33 ] only consider the PC with geometry data and/or have limited parallelism, and thus, could neither leverage GPU nor beneÔ¨Åt from other types of accelerators.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "[5] Dennis Abts, Garrin Kimmell, Andrew Ling, John Kim, Matt Boyd, Andrew Bitar, Sahil Parmar, Ibrahim Ahmed, Roberto DiCecco, David Han, John Thompson, Michael Bye, Jennifer Hwang, Jeremy Fowers, Peter Lillian, Ashwin Murthy, Elyas Mehtabuddin, Chetan Tekur, Thomas Sohmers, Kris Kang, Stephen Maresh, and Jonathan Ross. In  Proceedings of the 49th Annual International Symposium on Computer Architecture , pages 567‚Äì580, 2022. A software-defined tensor streaming multiprocessor for large-scale machine learning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "C.1.2 Function Definitions \n‚Ä¢  SAVE_STATE : Saves the current indices and the partial result of the output matrix  C  to non-volatile memory to allow recovery after a power interruption. C.1.1 Algorithm Overview \nThe GeMM operation, typically expressed as  C  =  A  √ó  B , where  A ,  B , and  C  are matrices, is imple- mented with considerations for energy limitations. The algorithm breaks the matrix multiplication into smaller chunks (tiles), periodically saves the state before potential power losses, and resumes computation from the last saved state upon power restoration.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "TABLE I A N EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT - CYCLE POWER TRACE . Power cycle \nHarv. Power ( ¬µ W) \nPower consumption with full-size acti.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "On the other hand, quantization, which has recently gained a lot of traction, trying to quantize the parameters to lower precision [25]. While some of the weights contribute more towards accuracy, some contribute less; and the ones contributing less are dropped to reduce the parameter size as well as compute and memory footprints. Combined with specialized hardware support, quantization can reduce the amount of computation, memory footprint, and energy consumption.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "37 39 41 43 45 \n7 8 9 10 11 12 \n31%58%69%79%82% \nPSNR(dB) \nCompressed Size  w.r.t. Original (x) \n% Direct-reuse Blocks \nCompression Ratio PSNR(dB) \n(b) Sensitivity study. Figure 10: (a) comparison between i: raw PC and our proposals (ii: intra, iii: intra-inter-V1, iv: intra-inter-V2).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "27‚Äì39, 2016. [5]  L. Song, X. Qian, H. Li, and Y. Chen, ‚ÄúPipelayer: A pipelined ReRAM- Based accelerator for deep learning,‚Äù in  2017 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pp. 541‚Äì552, 2017.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Due to the trafÔ¨Åc distribution (e.g., more cars than buses), the camera typically sees a varied distribution of different classes, which might reÔ¨Çect in the exemplar set. Moreover, some static objects (trafÔ¨Åc light, stop sign, etc.) Consider a trafÔ¨Åc camera looking at a busy street with a trafÔ¨Åc signal.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "It also shows the number of exemplar frames per 100 frame, i.e., of any 100 frame encountered, how many of those will contain a relatively new data. Over 10 iterations of retraining, \n901 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "[41]  R. Wang and Z. Xu, ‚ÄúA pedestrian and vehicle rapid identiÔ¨Åcation model based on convolutional neural network,‚Äù in  Proceedings of the 7th International Conference on Internet Multimedia Computing and Service , ICIMCS ‚Äô15, pp. 32:1‚Äì32:4, 2015. [42]  S. A. Dawwd and B. S. Mahmood, ‚ÄúA reconÔ¨Ågurable interconnected Ô¨Ålter for face recognition based on convolution neural network,‚Äù in  2009 4th International Design and Test Workshop (IDT) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "Including redundancy, this requires an additional  33% to  100%  more storage capacity. 32  TiB of raw video data, which compresses to approximately 60  GiB to  400  GiB of encoded data per day. Furthermore, given the plug-and-play nature of storage media like HDDs and SSDs, securing this data becomes even more critical.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "3b, all focus only on a portion of the entire viewing window within a short period of time (10 seconds in this case). On the other hand, even when viewing the exact same scene, the RoF varies across users. For example,  User1 has similar interest as  User3 , whereas  User2  focuses more on the bottom left corner.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "The answer is  neural codecs  (Ma et al., 2019; Chen et al., 2017). Therefore, it does not use any of the computations that are used in the inference and learning pipeline. Then, the question is:  is there a way we can reuse the computations used for the inference to help us in encoding the data?",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "ArXiv  (2021). 2021. A LiDAR-Guided Framework for Video Enhancement.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "a mobile phone), where sufficient resources are available to complete any remaining inference,  if the data can be sent from the sensor . Said coordinating device completes the rest of the computations and finally, aggregates them with the ones completed in the sensor nodes. The challenge here is to  send \n1 Throughout the paper we evaluate many of our motivation results using HAR as a workload as it is one such application, where the (EH-)WSN, used as body area network, fits perfectly with RF or body movement as the har- vesting source.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "power (mW). baseline InterHolo IntraHolo InterIntraHolo \nAvg. Power (mW) \n(a) Avg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "[13]  CWI-DIS Group, ‚Äúcwipc-CWI Point Clouds software suite,‚Äù \n‚Äùhttps://github.com/cwi-dis/cwipc‚Äù , 2021. 23‚Äì25, 2015. [14]  R. L. de Queiroz and P. A. Chou, ‚ÄúCompression of 3d point clouds using a region-adaptive hierarchical transform,‚Äù  IEEE Transactions on Image Processing , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "3. This ensures that  L ( Œ∏ )  is Lipschitz-smooth. There exists a constant  L >  0 such that for all  Œ∏, Œ∏ ‚Ä≤ , \n‚à•‚àá L ( Œ∏ )  ‚àí‚àá L ( Œ∏ ‚Ä≤ ) ‚à•‚â§ L ‚à• Œ∏  ‚àí Œ∏ ‚Ä≤ ‚à• .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "In this regard, the metric  throughput  measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios. We use the number of convolutional MAC operations to represent the computations. For the sequential computation mode, the throughput for Layer  Lk  can be expressed as below: \nThr sequ Lk =  ( m  √ó  n ) Lk  √ó  aG Lk \nLat Lk (6) \nThe average throughput with a  LC -convolution CNN infer- ence can be expressed as shown below.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "Experts can be classified via a set of diverse criteria  a , such as domain, skills, and languages. The chain structure connects experts in a sequential manner, ideal for tasks requiring a series of expert skills; the tree struc- ture models a type-subtype hierarchy; and the graph structure enables complex expert communication and collaboration. Each morphology is described in detail below: Modeling Diverse Expert Types with Chain Ensemble-of-Experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "IEEE, 2022b. Heng Tao Shen, Beng Chin Ooi, and Xiaofang Zhou. Towards effective indexing for very large video sequence database.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Energy Variability Awareness:  By integrating energy profiles directly into the training process, NExUME ensures that the model learns to handle fluctuations in energy supply, leading to more robust performance compared to methods that do not consider energy variability during training. 3. Efficient Scheduling:  DynInfer‚Äôs energy-aware task scheduling and task fusion mechanisms reduce overhead from checkpointing and optimize the execution of tasks within \n8 \nthe available energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Efficient healthcare with large language models: optimizing clinical workflow and enhancing patient care. Oxford Academic , 2024. [123] OpenAI.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "We induce failures in the in- stances using  chaosmonkey  [ 19 ] tool with a 20% failure proba- bility. It can be seen that queries in all three constraints suffer an intermittent loss in accuracy of 0.6% between the time period 240 s  and 800 s . Beyond 800 s , they quickly recover back to the required accuracy because additional instances are spawned in place of failed instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "This eye tracking step takes the current IR sensor im- ages as its input, and analyzes the user‚Äôs current gaze area as well as \nAlgorithm 2:  Inter-Holo algorithm. Note that this additional eye tracking proce- dure needs to be invoked for each frame, in order to capture/reflect the current eye movements without causing nausea for the user. Input : IRs : eye tracking sensors Input : Objs : set of virtual objects Input : Œ± : inter-holo approximation factor,  Œ±  ‚àà( 0 ,  1 ] Output: Holo–¥rams : Generated holograms \n1  procedure  Inter _ Holo ( IRs ,  Objs ,  Œ± ) // main \n2 RoF =  EyeT rackin–¥ ( IRs ) \n3 for  obj  in  Objs  do // View-Window only \n4 if  obj  in  RoF  then // inside of RoF \n5 Holograms[obj] = Algorithm1( 16 , obj) \n6 else // outside of RoF, thus approximate \n7 Holograms[obj] = Algorithm1( 16  √ó  Œ± , obj) \n8 return  { Holo–¥rams } \nthe viewing direction.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 304,
    "augmented": true
  },
  {
    "text": "[7]  P. J. Besl and N. D. McKay, ‚ÄúMethod for registration of 3-d shapes,‚Äù in  Sensor fusion IV: control paradigms and data structures , 1992, pp. 586‚Äì606. [8]  Charles Loop, Qin Cai, Sergio Orts Escolano, and Philip A Chou, ‚ÄúJPEG Pleno Database: Microsoft Voxelized Upper Bodies - A Voxelized Point Cloud Dataset,‚Äù  ‚Äùhttp://plenodb.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "The PIs will meet with the PhD students as frequently as needed. The existing industrial partnerships of the PIs (e.g., with Intel, AMD, NVIDIA, Microsoft, and Amazon) will be leveraged to provide opportunities for student internships and placements. Moreover, as stated in the proposal, we will collaborate with Argonne National Lab specifically for the experimental evaluation thrust of the project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "The host writes the latest copy of the completed iteration (in epoch granularity) into the STT- RAMs (STT-RAM-N for the upper 128 SAs, and STT-RAM- S for the lower 128SAs, Fig. 5a ). In case of a complete power failure, the compute in Ô¨Çight are rejected and, once the system starts working, the work queues get invalidated and the host starts the compute again from the last checkpoint.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "[58]  Julian Steil, Inken Hagestedt, Michael Xuelin Huang, and Andreas Bulling. Privacy-Aware Eye Tracking Using Differential Privacy. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "These are functions within a DAG that have a high number of descendant functions that are linked to it and we use the \n155 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. We identify two interlinked factors, in the context of DDAs, that need to be accounted for when making container scaling decisions. The first, is what we call  critical functions .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "[12] Google, ‚ÄúGVR Android SDK Samples - Video360.‚Äù ‚Äùhttps://github.com/ googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/ java/com/google/vr/sdk/samples/video360/VrVideoActivity.java#L257‚Äù, 2019. [13] M. Ham, I. Dae, and C. Choi, ‚ÄúLPD: Low Power Display Mechanism for Mobile and Wearable Devices,‚Äù in  Proceedings of the USENIX Conference on Usenix Annual Technical Conference (ATC) , 2015, pp. [11] Google, ‚ÄúBuild Virtual Worlds.‚Äù ‚Äùhttps://developers.google.com/vr‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 194,
    "augmented": true
  },
  {
    "text": "If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output Y .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "8697‚Äì8710. [109] B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, ‚ÄúLearning transferable \narchitectures for scalable image recognition,‚Äù in  Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 494‚Äì506.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Therefore the prob- ability of any model giving a correct classiÔ¨Åcation is ‚Äôa‚Äô. We assume the output to be correct if majority of them, i.e. We perform an inference by ensembling ‚ÄôN‚Äô models, and each of these models have accuracy ‚Äôa‚Äô.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "behavior [ 19 ,  20 ]. VOMMs are an extension of Markov Mod- els [ 28 ], where the transition probability from the current state to the next state depends not only on the current state, but possibly on its predecessors (which we refer to as the ‚Äòcontext‚Äô of the state). Such behavior is seen in some of our workloads such as  ùëÄùëíùëëùëñùëéùëÜùëíùëüùë£ùëñùëêùëí .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "2018. Polymorphic radios: A new design paradigm for ultra- low power communication. In  Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "4.Data Flow Management:  Design efficient data paths to handle the high throughput of video data and intermediate results between the FPGA blocks, ensuring that bandwidth and memory access bottlenecks are minimized. By optimizing each component for FPGA execution and taking advantage of the hardware‚Äôs ability to execute multiple operations in parallel, the proposed codec can achieve real-time performance even for high-resolution video streams. The use of FPGA not only accelerates the processing speed but also provides flexibility to adapt to various codec configurations.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "1‚Äì12. [27]  Kyungjin Lee, Juheon Yi, Youngki Lee, Sunghyun Choi, and Young Min Kim. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "This slack is leveraged by  Kraken  by batching multiple requests to the functions by queueing requests at their con- tainers. Figure 7 depicts this slack for all functions in the applications considered. Allotting stage-wise SLOs to each function in a chain in proportion to their execution times reveals that there are cases where there is significant difference (slack) between the function‚Äôs expected SLO and its run-time.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "The importance of each weight at index  i , denoted as  I W i , can be approximated by: I W i  =  |L ( D )  ‚àíL W i =0 ( D ) | , where  L W i =0 ( D )  is the loss, by setting parameter  W i  to zero. Our solution will leverage our previous work on LLM structured pruning [140], unstructured pruning [181], and parameter- efficient fine-tuning [32,33]. We will explore several directions for estimating  I W i  efficiently such as using a memory-efficient zeroth-order optimizer to estimate gradients using only forward passes [101].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "Later, we show quality results compared to the baseline design. In addition, we also discuss the  our design‚Äôs versatility  on other 360 ¬∞ video representation formats. the  Baseline  method.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "3). 3b), and observed the following two properties in the AR holographic applications: Spatio Diversity for Objects:  Intuitively, objects which are far from the user and with small-sized shapes require less informa- tion to generate the virtual hologram than others (more details are provided in Sec. Hence, the distance between the user and the objects ( Cam2ObjDist  shown in black color in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "IV-B4), and Ô¨Ånally, we report the output result to the application, as shown in the blue BBoxes in Step  5  . Next, the new inputs are fed into Step  4  to perform the PI (details are in Sec. Since Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Background and Related Work \nVery basic, just the outline, compact and make robust \n2.1. ). Energy Harvesting Wireless Sensor Networks \nEnergy harvesting wireless sensor networks (EH-WSNs) have emerged as a sustainable solution for long-term envi- ronmental monitoring, infrastructure surveillance, and IoT applications ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "118‚Äì123, 2019. [29]  E. S. Jang, M. Preda, K. Mammou, A. M. Tourapis, J. Kim, D. B. Graziosi, S. Rhyu, and M. Budagavi, ‚ÄúVideo-based point-cloud-compression standard in mpeg: From evidence collection to committee draft [standards in a nutshell],‚Äù  IEEE Signal Processing Magazine , pp. [28]  T. Huang and Y. Liu, ‚Äú3d point cloud geometry compression on deep learning,‚Äù in  Proceedings of the 27th ACM International Conference on Multimedia , 2019, p. 890‚Äì898.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "If this deviation is profitable for sensor s j , we have: \nU j ( a ‚Ä≤ j ( t ) ,  a ‚àí j ( t ))  > U j ( a j ( t ) ,  a ‚àí j ( t )) . Such a deviation affects only  U j ( t ) , not the utilities of other sensors directly in a one-step change. Monotonicity of the Potential Function \nConsider a unilateral deviation by a single sensor  s j  from an action  a j ( t )  to a different action  a ‚Ä≤ j ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "Algorithm 1  Model Selection and Weighted Majority Voting \n1:  procedure  F ULL _E NSEMBLE (M ODEL L IST , SLO) 2: for  model  ‚àà ModelList  do 3: if  model.latency  ‚â§ SLO.latency  then 4: Model.add(model) 5: end if 6: end for O 1 7:  end procedure 8:  procedure  D YNAMIC _M ODEL _S CALING ( Models ) 9: if  curr_accuracy  ‚â• accuracy_threshold  then \n10: if  max vote  >   N \n2   + 1  then  O 2 \n11: to _ be _ dropped  ‚Üê max vote  ‚àí N \n2   + 1 12: Models . It can so happen that dropping models can lead to drop in accuracy for certain intervals, because the class of images being predicted are different. In such cases, we up-size the models (one at a time) by adding most accurate model from the remaining unused models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 230,
    "augmented": true
  },
  {
    "text": "To evaluate our design implementation in hardware, we use an FPGA platform, which is the same as the state-of-the-art PTU [28], with a 100MHz system clock, onboard conÔ¨Åguration circuitry, 2x16MB Quad SPI Flash, 1GB DDR2 Component Memory, and also a hardware PMU. A full seat Vivado design suite [58], [59] is utilized to synthesize the design and report the power and timing numbers. We collect the display traces from a 5-inch (130 mm) 16:9 1080p (1920 √ó 1080) AMOLED display [54], which is similar to the Samsung Gear VR display [45].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "Computer Networks  (2009). 2009. Wikipedia workload analysis for decentralized hosting.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 16,
    "augmented": true
  },
  {
    "text": "5 √ó  larger than that of TMC13 [ 56 ]. Thus, in order to harvest most of the speedup beneÔ¨Åts ( 42 ms  vs  1 . 55 s ), in our design, we discard the entropy encoding and still achieve reasonable compressed size, which is  ‚âà 0 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "It is noteworthy that, the process of neural compression as well as inference/representation learning use the feature extraction method. In this work, our goal is to use this to our advantage and maximize the compute and data reuse. The critical insight to be gleaned here is reusing data and compute pipeline prior to its transfer to storage could markedly diminish the costs associated with data movement.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "This demonstrates that NExUME not only improves accuracy but also enhances energy utilization, making it highly suitable for deployment in energy-constrained intermittent environments. NExUME achieves the highest energy efficiency across all platforms and datasets. The improvements in energy efficiency are due to NExUME‚Äôs ability to adjust computational workload dynamically, minimizing energy wastage and ensuring that computa- tions are matched to the available energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "IV-B) as plugable modules to the existing compute engines (e.g., CPU, GPU, etc. ), as shown in Fig. 7.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "For varying load patterns, the model parameters can be updated by re-training in the background with new arrival rates. The DeepARest model is pre-trained using 60% of the arrival trace. 5.2 Evaluation Methodology \nWe evaluate our prototype implementation on AWS EC2 [ 8 ] platforms.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "T 1 Rigid body No Compile-time Left = Right T 2 An eye‚Äôs view Yes Runtime Left = Right T 3 Eye adjusting No Compile-time Left  Ã∏ =  Right T 4 Perspective No Design-time Left = Right T 5 Viewport No Design-time Left = Right \ntheir corresponding  360 ¬∞ video frame coordinates. Finally, the third stage, i.e.,  Projection Mapping , uses the mapping results from the second stage and the  360 ¬∞ video frame to deduce the pixel values for 2D FoV frames (shown in  c  in Fig. 3) ,which can be projected to both eyes on the HMD.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "‚Ä¢  CWIPC  [ 13 ], [ 48 ]: CWIPC is a PCC library that supports the inter-frame compression (encoding the predicted frame via macro block (MB)-based motion estimation). We use CWIPC as the  state-of-the-art  approach for  inter-frame compression  and build it with multi-thread option. In our setup, one I-frame(intra-compressed frame) is followed by two P-frames(predicted frames), and the number of threads for MB matching is set to 4.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "To further prove this, we also change the compute mode of Jetson AGX Xavier board to 10W, and measure the execution latency for loot video [ 54 ]. For other high-demanding applications like AR-based surgery [ 11 ], our proposals may jeopardize the video quality, and consequently, we may need further software and/or hardware optimizations for improved user experience. Correlation with the evaluations on smartphones:  Based on our proÔ¨Åling, the power consumption of our proposal is ‚âà 4 W , which is below the peak discharge power of modern smartphones (10W [ 2 ], [ 70 ]), meaning that our proposal will work Ô¨Åne on smartphones as well.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "1‚Äì3, 2018. In  SysML Conference , pp. Graham Gobieski, Brandon Lucia, and Nathan Beckmann.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "HC1 on the other hand is a garden video, with people walking around, riding \nbike, etc. These two videos are much more active (dynamic) than V1/V2, meaning that they contain less reuse opportunities than V1/V2. Thus, compared to V1 and V2 whose latencies can be decreased by  62%  and  55%  respectively with FI+SI as shown in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "https://aws.amazon.com/sagemaker/, February 2018. [7]  Amazon. Azure Low priority batch VMs., February 2018. https://docs.microsoft.com/en-us/azure/batch/batch-low-pri-vms .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Feature Map Reconstruction Error Dropout and QuantaTask Optimization: Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ≥ . Define the energy budget E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "In order to maintain high accuracy, we also propose an adaptive technique to dynamically adjust the reuse window size based on the runtime statistics by comparing the MVs in consequent frames. ‚Ä¢  Next, we propose a tile-level inference scheme to enable the region/tile reuse by identifying the critical regions. Since processing these critical regions is in general much lighter-weight than processing a whole frame due to smaller size and less computation, the proposed partial inference is able to minimize the unnecessary computation (on the background/unimportant regions), thereby further speeding up the inference and reducing the energy consumption.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "2 Background and Related Work \nEnergy Harvesting and Intermittent Computing:  The exploding usage of IoTs, connected devices, and wearable electronics project the number of battery operated devices to be 24.1 Billion by 2030 (Insights, 2023). ‚Ä¢  Dataset : A first-of-its-kind machine status monitoring dataset, involving multiple types of EH sensors mounted at various locations on a Bridgeport machine to monitor its activity status, facilitating research in predictive maintenance and Industry 4.0 applications. This has a significant economic (users, products and data generating dollar value) as well as environmental (battery and e-waste) impact (Mishra et al., 2024).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "Unified low-resource sequence labeling by sample-aware dynamic sparse finetuning. In Houda Bouamor, Juan Pino, and Kalika Bali, editors,  Proceedings of the 2023 Conference on Empirical Methods in Natu- ral Language Processing , pages 6998‚Äì7010, Singapore, December 2023. Association for Computational Linguistics.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "In special cases, like remote surveillance, most frames can even be identical, avoiding the need to process them. Consequently, the only regions of interest (RoIs) should be the change between successive frames. Furthermore, these changes between consecutive frames need not be explicitly calculated as they can be extracted from the hardware codecs directly, giving us a chance to capitalize on an existing funda- mental component, instead of adding new hardware blindly.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "On the other hand,  DProb  and  SProb  spawn fewer containers than  Kraken  as a consequence of not using  Commonality  and Connectivity  to augment function weights, while making container allocation decisions. Note that, these additional containers are necessary to reduce SLO violations. As a result,  Kraken  provisions up to 21% more containers than both  DProb  and  SProb  for the three applications.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "B. Case Study: Edge Cloud Partitioning in Smart Industries \nThe evolution of industry 4.0 [4] standard is bringing intelligent sensing and analytics into the industrial and man- ufacturing segment. Modern smart machines come with inte- grated sensors with built-in communication protocols to send data to either an attached computer, a base station or cloud.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "[6] Alibaba, ‚ÄúMNN: Mobile Neural Network,‚Äù ‚Äùhttps://github.com/alibaba/ MNN‚Äù, 2019. [5] Tencent, ‚ÄúNCNN,‚Äù ‚Äùhttps://github.com/Tencent/ncnn‚Äù, 2017. 4820‚Äì4828.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "(c): View- ing the S-CGH from different focal distances. (b) Viewing the W-CGH from different focal distances. (a): Viewing the W-CGH from different eye-center positions.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Let us now consider the example in Fig. 6 with three points ‚Äì  P 0  with geometry data of  [ 0 , 0 , 0 ]  and one attribute value of  50  (in this example, we set the attribute as a scalar for simplicity; normally, the attribute should be a vector, e.g., RGBs),  P 1  with a  [ ‚àí 1 , 0 , 0 ]  geometry and  52  as the attribute, and  P 2  with a  [ 3 , 3 , 3 ]  geometry and  54  as the attribute. Here, we assume that the octree for these points has already been established using the geometry pipeline, and we next go through our proposed attribute pipeline step by step and explain where the envisioned beneÔ¨Åts will come from.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 176,
    "augmented": false
  },
  {
    "text": "The recovery policy can be implemented as a simple generator network in the host. Although, the training of the GAN is complex and involves multiple networks as well as hyper-parameters tun- ing, the generator network itself is very small ( few hundred thousands  of parameters depending on the sensor data). 4 DESIGN IMPLEMENTATION OF  SEEKER \nBy leveraging the coreset construction techniques discussed in Section 3, we design  Seeker: A synergistic sensor host ecosys- tem .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems , CHI ‚Äô23, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9781450394215. doi: 10.1145/3544548.3581045.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "[57]  New Farmer Blogger, ‚Äú3D points clouds for immersive real es- tate and telepresence experiences,‚Äù  ‚Äùhttps://bit.ly/3AhWQR5‚Äù , 2015. [58]  Nvidia Corporation, ‚ÄúJetson AGX Xavier Developer Kit,‚Äù \n‚Äùhttps://bit.ly/3oWQNtH‚Äù , 2018. 297 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Initialize the loop iteration parameters  l . Compute the activations  a  and apply the dropout mask: \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output. 22 \nCalculate the gradients of the loss with respect to the activations: \n‚àÇ L ‚àÇ a i \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the Taylor expansion approximation: \np i  = Œª \f\f\f  ‚àÇ L \n‚àÇ a i   a i \f\f\f  +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 364,
    "augmented": false
  },
  {
    "text": "[13] O. BaÀúnos, R. Garc¬¥ƒ±a, J. A. H. Terriza, M. Damas, H. Pomares, I. R. Ruiz, A. Saez, and C. Villalonga, ‚Äúmhealthdroid: A novel framework for agile development of mobile health applications,‚Äù in  IWAAL . Springer, 2014.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Over sufficiently large timescales, the system does not drift away from this equilibrium, and samples  ( x, y ) can be considered drawn i.i.d. The equilibrium participa- tion strategies induce a stationary effective distribution D . from  D .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "In Figure 3, we illustrate three specific morphologies:  chain ,  tree , and  graph , among other potential configurations. The chain structure connects experts in a sequential manner, ideal for tasks requiring a series of expert skills; the tree struc- ture models a type-subtype hierarchy; and the graph structure enables complex expert communication and collaboration. Task-1.2: Constructing Morphology of Ensemble of Experts In this task, we propose innovative, flexible, and diverse ways of connecting individual experts to cre- ate diverse LLM expert network morphologies, tailored to various usage scenarios by applying different combinations of expert types, routers, models, and composition functions.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "By integrating the energy model into the training process, DynFit ensures the adjustments to dropout and quantization directly correspond to actual energy savings on the target hardware. The total energy consumption of a QuantaTask  q  is modeled as  E q  =  e op  √ó  ‚Ñì q , where  ‚Ñì q  is the number of operations in the task. Let  e op  denote the energy consumed per computational operation, which varies with operation type and data precision.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "VI-E . VI. E XPERIMENTAL  R ESULTS \nIn this section, we compare our proposed intra-frame and inter-frame designs against two different PCC techniques, by evaluating four metrics critical for the PC-based applications ‚Äì execution latency, energy consumption, video quality, and compression ratio.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Pushing point cloud compression to the edge. In  2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp. 282‚Äì299, 2022a.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "9. ‚Ä¢  AE:  For those head orientations not memoized, we further exploited the  spatial compute reuse  across eyes within a frame. In the proposed  AE  scheme, one can observe that for the left-eye computation, the energy consumption is the same as in the  Baseline .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "2021. Towards Real-time Photorealistic 3D Holography with Deep Neural Networks. [54]  Liang Shi, Beichen Li, Changil Kim, Petr Kellnhofer, and Wojciech Matusik.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Recognizing facial expression: machine learning and application to spontaneous behavior. [13]  Marian Stewart Bartlett, Gwen Littlewort, Mark Frank, Claudia Lain- scsek, Ian Fasel, and Javier Movellan. Association for Computing Machinery.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "DynFit, with its stochastic dropout features, occasionally leads to overfitting, necessitating meticulous fine-tuning. While effective in smaller networks, our studies involving larger datasets (such as ImageNet) and more complex network architectures (like MobileNetV2 and ResNet) reveal challenges in achieving convergence without precise fine-tuning. DynFit tends to introduce multiple intermediate states during the training process, resulting in approximately 14% additional wall-time on average.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "9 \n495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 \nBecause the best-response process eliminates profitable de- viations step by step and cannot cycle indefinitely, the action profile sequence generated by iterative best responses con- verges to the NE. We have shown that, with the reward-based utility function that includes correct participation rewards ( Œ≥  ¬∑  ‚àÜ A i ( t ) ), penalties for incorrect inferences ( Œ¥ ), and penalties for non- participation ( Œ∑ ), the best-response dynamics lead to a Nash equilibrium. The proof relies on constructing a potential function  Œ¶  that is strictly increased by unilateral profitable deviations and bounded above.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 259,
    "augmented": false
  },
  {
    "text": "Our main  contributions  include: \n‚Ä¢  We propose design of a hybrid storage pipeline equipped with computational storage drives (CSDs) where the different drives could communicate with each other in a peer-to-peer fashion. These CSDs synergistically orchestrate the archival related tasks between the storage controller CPU and the computational storage FPGAs. The hybrid storage system is capable of taking the computed \n2 Given a powerful enough computer like quantum computers, RSA encrypted data can be decrypted, and therefore National Institute of Standards and Technology (NIST) called for proposals to develop post quantum cryptography algorithms (National Institute of Standards and Technology (NIST), 2024), and defined a standard for the same.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "IV. Motivated by this observation, we next propose schemes that can utilize Morton codes for both  geometry and attribute compression in point clouds. Takeaway : The Morton codes generated as an intermediate result during geometry compression not only improve the geometry compression by increasing pipeline parallelism, but also help to capture/identify the attribute similarities within a frame as well as across frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the Fourteenth EuroSys Conference 2019 , pp. 1‚Äì17, 2019. Yang Yang, Zhi Guan, Huiping Sun, and Zhong Chen.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "0 \n0.25 \n0.5 \n0.75 \n1 \nHit Rate \n(b) Media Service. 0 \n0.25 \n0.5 \n0.75 \n1 \nHit Rate \n(c) Hotel Reservation. Figure 4: Function Hit Rate for an Evenly Distributed Load across all Paths in each Application.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "https://www.nvidia.com/en-us/data-center/nvlink/ \", 2024. Octopai: Automated data lineage, data catalog and discovery. [120] Octopai.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "6), that Origin  keeps up with the claimed accuracy (base accuracy), and at times outperforms it. We can attribute this to the conÔ¨Ådence matrix and ensemble learner, since over these 1000 iterations, only the conÔ¨Ådence matrix gets updated. Note that the conÔ¨Ådence matrix reaches the steady state of baseline accuracy within 100 iterations.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "In each time slot, the network may perform an inference event, dur- ing which sensors have the opportunity to contribute data that enhances the accuracy of a global inference task, such as object detection or environmental classification. Each sensor  s i  harvests energy from ambient sources, such as solar or vibrational energy, resulting in a stochastically varying energy supply. We denote by  E i ( t )  the energy harvested by sensor  s i  during slot  t .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Finally, we prove that the equilibrium is reached under the given assumptions. We first restate the key assumptions and the utility model. We then show that the iterative best- response updates cannot lead to infinite improvement cycles, implying the existence of an NE.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Kraken , while spawning more containers, also is seen to lag behind the trend of the trace due to load prediction errors. Moreover, more than 40% of requests show significant variability in inter- arrival times. Performance under Sparse Load:  Analysis of logs col- lected from the Azure cloud platform [ 42 ] shows request volumes that are much lighter (average of 2 requests/hour) than those of the traces we have considered.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "com/media/attachments/2020/06/03/noload-compression-zfs.pdf . https://www.eideticom. (Accessed on 11/13/2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "[3]  ARCore. 2020. Using Scene Viewer to Display Interactive 3D Models in AR from an Android App or Browser.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "By integrating the energy model into the training process, DynFit ensures the adjustments to dropout and quantization directly correspond to actual energy savings on the target hardware. Each QuantaTask ensures that execution proceeds without partial computation, which would otherwise lead to overhead from checkpointing and potential data corruption. A  QuantaTask  is defined as the smallest atomic unit of computation that can be executed entirely without interruption under the current energy and hardware constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Baseline  AP  is a DNN compressed to fit the average power of the energy harvesting (EH) environment using iNAS (Mendis et al., 2021) and energy-aware pruning (EAP) (Yang et al., 2017, 2018). Baseline  PT  takes the  Full Power  DNN and uses techniques proposed by (Yang et al., 2018) and (Yang et al., 2017) to prune, quantize, and compress the model. Baseline  iNAS+PT designs the network from the ground up while combining the work of iNAS (Mendis et al., 2021) and EAP (Yang et al., 2018, 2017).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 165,
    "augmented": false
  },
  {
    "text": "Execution Latency:  Clearly, the reduction in the number of depth planes when using our approximation schemes can reduce the hologram execution latency as well. The above observations from these two figures explain the power benefits of our proposed designs. As shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "CoRR , abs/1804.03230, 2018. [84]  Tien-Ju Yang, Andrew G. Howard, Bo Chen, Xiao Zhang, Alec Go, Vivienne Sze, and Hartwig Adam. Netadapt: Platform-aware neural network adaptation for mobile applications.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "2  shows the different components of the student-teacher data annotation model adapted in  Us. ¬¥as , where the edge model is the ‚Äústudent‚Äù (continuously retrained), and larger models are the ‚Äúteachers‚Äù (the ones teaching the student about what-is-what). The students models are typically optimized for edge, i.e.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "The naive model selection policy would not choose the models as its oblivious to user requirements and model characteristics. In our experiments, compared to naive selection scheme which does not optimize model selection for cost, the  Paragon  schemes reduces the cost of resource procurement by up to 20% (results are not plotted). This is because the  Paragon  scheme jointly considers all three parameters and chooses the least costing model.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "8 \nAlgorithm 1  Neural Encoding and Compression using the video data inference pipeline. 1:  Input:  Video frames sequence  F  =  { f 1 , f 2 , . .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "[37]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Mahmut Taylan Kandemir, Bhuvan Urgaonkar, George Kesidis, and Chita Das. Spock: Exploiting serverless functions for slo and cost aware resource procure- ment in public cloud. In  IEEE CLOUD , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Incidental computing on iot nonvolatile processors. Kaisheng Ma, Xueqing Li, Jinyang Li, Yongpan Liu, Yuan Xie, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. In Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "As a user query can be possibly answered by different sets of experts, we will choose experts based on the combination of two factors: (1) The relevance of expert to the user query, and (2) the availability of accelerator (developed in Thrust 3) for the expert. When two \nAffinity Optimization Stage Tasks \nTraining Inference Algorithm System Architecture \nExpert‚ÄìExpert ‚úì ‚úì Task 1.2, 1.3, 1.4 Task 2.1, 2.3, 2.5 Task 3.2 Expert‚ÄìData ‚úì Task 1.1, 1.3 Task 2.1, 2.5 Expert‚ÄìRouter ‚úì Task 1.2, 1.3 Task 2.2, 2.5 Task 3.3 Expert‚ÄìComposition Function ‚úì ‚úì Task 1.2, 1.3 Task 2.3, 2.5 Expert‚ÄìAccelerator ‚úì ‚úì Task 1.4 Task 3.2 \nTable 2 :  Overview of affinities in the proposal. Definitions of different affinities:  Expert‚ÄìExpert:  the tendency of certain experts to be used more frequently together to serve a request;  Expert‚ÄìData:  the tendency of similar experts to use a common subset of training data;  Expert‚ÄìRouter:  the tendency of given experts and routers to be used together frequently to serve different requests and to share a subset of training data.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 270,
    "augmented": false
  },
  {
    "text": "To summarize the overall results, Cocktail providing 2 √ó  reduction in latency, while meeting the accuracy for up-to 96% of the requests under reduced deployment cost by 1.4 √ó , when compared to  InFaaS and  Clipper . 6.1 Latency, Accuracy and Cost Reduction \nLatency Distribution : Figure  7  shows the distribution of to- tal response latency in a standard box-and-whisker plot. 6 Analysis of Results \nThis section discusses the experimental results of  Cocktail using the Wiki and Twitter traces.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Employing predictive energy harvesting models to anticipate energy availability and adjust computations proactively. Prioritizing essential tasks and deferring non-critical computations. 3.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "2021. [8]  Yu Feng, Patrick Hansen, P. Whatmough, Guoyu Lu, and Yuhao Zhu. Optica  (2021), 143‚Äì146.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "From the myriad of ML Ô¨Çavours, Deep Neural Networks \n(DNNs) [ 54 ] due to their multi-faceted nature, and highly gen- eralized and accurate learning patterns [ 45 , 73 ] are dominating the landscape by making these model-serving frameworks accessible to developers. These ML models are typically trained and hosted on cloud platforms as service end- points, also known as  model-serving  framework [ 6 ,  28 ,  60 ]. However, their high variance due to the Ô¨Çuctuations in training data along with compute and mem- ory intensiveness [ 59 , 65 , 84 ] has been a major impediment in designing models with high accuracy and low latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": "Algorithm 2  Periodic Equilibrium-Aware Training Algo- rithm \n1:  Initialization:  Initialize  Œ∏ 0 . Set a diminishing step-size schedule  { Œ± k } k ‚â• 0 . Broadcast  Œ∏ 0  to all sensors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "2020. Magic Leap One Teardown. \"https://www.ifixit.com/Teardown/Magic+Leap+One+Teardown/112245\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "E.1.2 Extending to Complex Compute: \nIn order to perform multiplication-addition in ReRAM x-bars, two arrays of weights and inputs are used. However, the basic principle remains the same, where the input signals are applied to the rows, the weights are applied to the columns, and the output signals are obtained by summing the currents flowing through the ReRAM devices. The inputs are fed to the x-bar, which is a two-dimensional array of ReRAM crossbar arrays.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "We use iNAS (Mendis et al., 2021) to find the DNNs meeting the energy income and train them using our proposed DynFit. Table 3 shows the accuracy of classification tasks against the different baselines and state-of-the-art methods. Class Full Power AP PT iNAS+PT Stateful ePerceptive DynBal NExUME \nR1 84.93 74.46 77.02 79.62 80.85 81.50 82.15 83.60 R2 85.85 76.21 79.18 80.36 81.95 82.60 83.25 84.50 R3 81.09 72.43 75.38 78.18 79.05 79.70 80.35 80.85 SJ 90.95 82.33 85.00 87.58 88.60 89.15 89.80 90.50 SI 94.76 85.31 88.05 89.90 91.00 91.65 92.30 93.00 Table 3: Accuracy of NExUME and other methods for industry status monitoring dataset using TI MSP board and piezoelectric energy source.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 278,
    "augmented": false
  },
  {
    "text": "Furthermore, no restriction on the reuse or redistribution of any artifact developed in this project will be placed for non-commercial use. Policies and Provisions for Reuse and Redistribution \nNo permission restrictions will be placed on the data. Academic researchers, industrial researchers as well as scientists working on AI/ML (especially generative AI and LLMs), systems, computer architecture, carbon-efficient cyberinfrastructure, compilers and performance evaluation areas would likely be interested in our data.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "However,  Cocktail‚Äôs  resource management is more adaptive to changing request loads and does not drop accuracy. Pretzel [ 52 ] and Inferline [ 26 ] are built on top of Clipper to optimize the prediction pipeline and cost due to load variations, respectively. Many prior works [ 2 , 25 , 35 , 63 , 74 , 75 ] have extensively tried to reduce model latency by reducing overheads due to shared resources and hardware interference.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "IV-A. The Ô¨Årst frame is considered as the ‚Äúbase‚Äù, which is always fully inferenced. For the remaining frames however, we invoke Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "43 , 0 , 0 ]  (-0.43=-1+1/7 √ó 4), which is slightly different from the original  [ 0 , 0 , 0 ] , whereas the other two points,  P 1  and  P 2 , are exactly same as the original ones. Thus, as we discuss later in Sec. VI , our proposal drops the quality a little bit (PSNR  ‚âà 80 dB in our design).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation , pages 74‚Äì85, 2010. [78] Keboola. Keboola, the platform that automates data lineage.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "4. The interplay of multiple sensors making similar decisions un- der uncertainty and energy constraints naturally suggests a game-theoretic framework for modeling their interactions. Game-Theoretic Modeling \n4.1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "We will also collaborate with the Penn State College of Education‚Äôs CSATS (Center for Science and the Schools) to participate in the university‚Äôs continuing outreach initiatives focused on STEM subjects. The PIs have supervised several women PhD students, and are currently advising a total of 6 female PhD students in their groups. The PIs plan to recruit new women and minorities for this project as well.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "With this estimation, we briefly discuss the performance and computational efficiency variations between this accelerator and our approach, and discuss takeaways that can help one to co-design a hardware accelerator targeting hologram processing. 5.2 Experimental Platform and Datasets \nThe edge GPU platform used in this work consists of a 512- core Volta GPU, a 4Kp60 HEVC codec, 16GB LPDDR4x memory, 32GB eMMC storage, and a power management unit (PMU) that exposes the real-time power traces to users [ 36 ]. To ensemble the \nAR pipeline with generic state-of-the-art components shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 149,
    "augmented": false
  },
  {
    "text": "0 1000 2000 3000 Time interval (10s) \n0 \n50 \n100 \n#VMs \nBline model1 model2 model3 \n(a)  Cumulative #VMs. 0 25 50 75 Time interval (10s) \n79 \n80 \n81 \n82 \nAccuracy \nBL1 BL2 \nBL3 const1 \nconst2 const3 \n(b)  Failure Analysis. Figure 12:  Sensitivity analysis of VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "The trend we observe is that traces with higher variability, such as the Twitter trace, af- fect the tail latencies of policies more harshly than the other, more predictable, traces. However, the tail latencies of  DProb  and  SProb  sometimes exceeds the SLO, since they don‚Äôt use  Commonality  and  Connectivity . Nevertheless,  Kraken  is resilient to \nPolicy Poisson Wiki Twitter Med Tail Med Tail Med Tail Arch 336 568 336 568 336 599 Fifer 362 612 360 611 373 833 DProb 371 746 368 753 381 1549 Kraken 366 634 358 633 371 974 SProb 395 1101 382 1073 395 1610 Xanadu 343 723 340 774 340 1244 Table 6: Simulator: Median and tail latencies (in ms) averaged across all applications for the three traces \nunpredictable loads as well, with tail latencies always remain- ing within the SLO (1000 ms).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 240,
    "augmented": true
  },
  {
    "text": "However, when applied to low-dimensional sensor data, classical lossy compression techniques tend to discard or distort some important fea- tures, which significantly degrades the inference accuracy. These wireless sensing (EH or otherwise) devices have long relied on compression techniques to mitigate data com- munication overheads [ 32 ,  33 ,  45 ]. How- ever, to unleash the remote deployment, and sustainable, yet pervasive, computing capabilities WSNs, development of ef- ficient  energy harvesting WSNs  (EH-WSNs), both for sensing and edge-analytics, plays an essential role.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "4  c  and  4  d  for the geometry and attribute compression, respectively). Proposed Intra-Frame Geometry Compression:  As can be seen from Fig. 4  c  , the modiÔ¨Åed components in our pipeline compared to the previously-proposed geometry compression approach (depicted in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "hologram (in Fig. 9c) from different distances. Compared to the baseline, we then report the averaged PSNR [ 21 ,  44 ] of the recon- structed images from the six videos in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "baseline InterHolo IntraHolo InterIntraHolo \nEnergy (J) \nHoloCompute Overhead \n3.68 \n1.40 1.28 \n(c) Energy consumption (J). bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "By integrating energy variability into both training and inference, we allow the DNN to adapt its computational load dynamically, ensuring that critical tasks are completed within energy constraints. This holistic approach addresses the limitations of existing methods that treat training and inference separately or do not account for real-time energy fluctuations. Rationale Behind Method Design:  The overall method design of NExUME is motivated by the need to enable DNNs to function reliably in environments with intermittent and unpredictable energy supply.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Springer. In The Definitive Guide to AWS Application Integration . [24]  James Cadden, Thomas Unger, Yara Awad, Han Dong, Orran Krieger, and Jonathan Appavoo.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Non-Participation and Equilibrium: Since  Œ∑ > Œ¥ , we ensure that sensors prefer risking occasional incorrect infer- ences over consistently abstaining. A suitable gap might be chosen so that: Œ¥ < Œ∑  ‚â§ Œ¥  +  c, \nfor some small  c >  0 . Choosing  c  relative to typical gains, say  c  ‚âà 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "If Œ≥  is too high, sensors may waste energy attempting difficult inferences. The parameter  Œ¥ >  0  penalizes incorrect in- ferences, discouraging reckless submissions of low-quality data. The parameter  Œ∑ >  0  penalizes non-participation, ensuring that sensors do not remain idle indefinitely.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "To address these chal- lenges, we propose  Seeker , a hardware-software co-design approach for increasing on-sensor computation, reducing communication volume, and maximizing inference comple- tion, without violating the quality of service, in EH-WSNs co- ordinated by a mobile device. Seeker  uses a  store-and-execute approach to complete a subset of inferences on the EH sensor node, reducing communication with the mobile host. Fur- ther, for those inferences unfinished because of the harvested energy constraints, it leverages task-aware coreset construc- tion to efficiently communicate compact features to the host device.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "Quantifying data locality in dynamic parallelism in gpus. Proc. ACM Meas.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 25,
    "augmented": false
  },
  {
    "text": "‚Ä¢  T 1  serves as a  rigid body transformation  matrix which ap- plies 3D rotation ( Y aw, Pitch, Roll ) and translation so that, the objects do not get distorted. ‚Ä¢  T 2  gives us  eyes‚Äô view ; i.e., this changes the virtual world‚Äôs coordinate frame to match the frame of the eye. Since this transformation does not depend on any of the sensor inputs, it can be pre- calculated at compile-time.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "These re- sources are available in different types including CPU/GPU instances, burstables and transient instances. Transient in- stances [ 69 ] are similar to traditional VMs but can be revoked at any time by the cloud provider with an interruption notice. The provisioning latency, instance permanence and packing factor of these resources have a direct impact on the latency and cost of hosting model-serving.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "emerged as a preferred approach to mitigate data drift [ 20 ], [ 44 ], [ 50 ], [ 74 ]. The temporal locality of (video like) data has shown models to effectively learn from recent data. Although, multiple task-dedicated models are typically deployed to enhance accuracy and reduce sampling bias [ 70 ], particularly in scenarios like trafÔ¨Åc monitoring, where different time periods exhibit distinct trafÔ¨Åc patterns, they are not immune to data drift.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "Shulin Zhao, Haibo Zhang, Sandeepa Bhuyan, Cyan Subhra Mishra, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. D√©j√† view: Spatio-temporal compute reuse for‚Äò energy- efficient 360¬∞ vr video streaming. In  2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "Wireless Personal Communications 101, 2 (2018), 1019‚Äì1055. 2020. [50]  Thaha Mohammed, Carlee Joe-Wong, Rohit Babbar, and Mario Di Francesco.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Better refers to the improvement over iNAS+PT baseline. 14 \nDatasets Full Power Arduino on Thermal AP PT iNAS+PT NExUME Better FMNIST 98.70 77.04 80.44 83.08 89.90 8.20% CIFAR10 89.81 60.38 65.90 66.98 80.70 20.48% MHEALTH 89.62 65.74 69.88 72.41 85.75 18.42% PAMAP 87.30 62.76 65.93 71.46 81.27 13.73% AudioMNIST 88.20 69.12 73.86 77.79 83.54 7.39% Table 7: Accuracy of NExUME on Arduino nano board using thermocouple based thermal harvester. Better refers to the improvement over iNAS+PT baseline.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 201,
    "augmented": true
  },
  {
    "text": "1 to YOLOv4- tiny is not too much ‚Äì  5%  of the baseline execution latency, as shown in Fig. 9b. Similarly, the overhead introduced by Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "As one can observe from the  Intra- Holo  scenario shown in Fig. 5c, the  football  is larger than the soccer ball , and is located much closer to the user. Hence, even though both of them are located inside the RoF (and, of course, inside the viewing window), intuitively, the  soccer ball hologram does not need as much information as the  football hologram to compute.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "(c) SW pipeline [19, 50]. Figure 1: Main hardware components and software pipeline on a typical AR device. and improve its energy efficiency, with ‚Äúapproximation‚Äù as the core idea.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "This leaves an optimization space in trading between communication cost vs. accuracy, i.e. We perform an analysis on the MHELATH [ 9 ,  10 ] data set (we take a overlapping moving window of 60 data points sampled at 50Hz from 3 different IMUs, overlap size: 30 data points) to find a trade-off between the coreset size (directly related to the communication cost) and the inference accuracy. whether to construct strict and low-volume coresets and lose accuracy or to preserve maximum data points and pay for the communication cost .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "The received frame is decoded in the  PC Decoding  stage and the decoded PC frame is forwarded to the  Render and Display  stage where it is Ô¨Ånally rendered and displayed on the screen. Note that although the same method is followed and has been well established for streaming  2 D  or  360 ¬∞ videos, given that the PC data is much denser, compression becomes essential as well as the primary bottleneck, often taking several seconds to compress one PC frame [ 26 ](see Fig. 1  a  ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "The  Paragon scheme does not offload to lambdas for relaxed latency queries. Workload-2 consists of different cost, accuracy and latency requirements for all queries. We compare the  Paragon model selection scheme against a naive constraints-unaware model selection scheme.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "[45]  Davide Taibi, Nabil El Ioini, Claus Pahl, and Jan Raphael Schmid Niederkofler. 2020. Patterns for Serverless Functions (Function-as- a-Service): A Multivocal Literature Review..",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "The improvements in energy efficiency are due to NExUME‚Äôs ability to adjust computational workload dynamically, minimizing energy wastage and ensuring that computa- tions are matched to the available energy budget. NExUME, thanks to its inherent learnt adaptability, significantly reduces saves, restores, reconfigurations and READ/WRITE from/to nonvolatile memory or to the flash memory in the cases and devices where NVMs are not present which gives it edge over the baselines across multiple devices. Discussion of Results:  1.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Note from  Line#3  to  Line#5  in Algo. 4a), is to overlay the  i th   plane on the propagation result of the previous 1 st   to  ( i  ‚àí 1 ) th   planes, and then propagate to the next  ( i  +  1 ) th   plane. With these depth planes, the first step,  Forward Propagation  (de- noted  ‚ù∂ in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "6c, we plot the distance pattern between both eyes of a  360 ¬∞ frame using the CubeMap format [41] in Fig. 10  b  . 6b and Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Distilling the Essence of Raw Video to Reduce Memory Usage and Energy at Edge Devices. In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "The speciÔ¨Åcs of the energy-harvesting mechanism producing the power trace are beyond the scope of this work. B. DNN ClassiÔ¨Åer and the Dataset \nOur DNN design choices are inspired from the works in [11], [14]. However, instead of designing a centralized DNN which processes the combined data from all the sensors, we design three different smaller DNNs that work on their individual data.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "Small-size tiles share signiÔ¨Åcant similarities across consecutive frames. E.g., nearly 50% of the tiles are identical in successive frames with a tile size of 8 √ó 8. 2).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "2.3 Thrust-3: A Chiplet-based Adaptive and Reconfigurable Hardware Platform Our proposed EoE-based LLM algorithm consists of a diverse set of building blocks with routers, experts, and composition functions, entailing heterogeneity in different stages of the application execution. For ex- ample, the experts in the input layer processing the input prompt are expected to require a larger KV-cache against experts in the middle or output layers processing intermediate and refined embeddings. Moreover, the experts could differ in their size and thus in their compute and memory requirements.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "Ensembling in Azure ML Studio., February 2020. https://docs.microsoft.com/en-us/azure/machine-learning/studio- module-reference/multiclass-decision-forest . [11]  Azure. Machine Learning as a Service., February 2018. https://azure.microsoft.com/en-us/pricing/details/machine-learning- service/ .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Such  Intra-Holo enhancement is ideally suited for holographic processing at the edge, without requiring additional hardware, cloud assistance, or machine learning. ‚Ä¢  We implement both the designs on an edge GPU platform [ 36 ], without the need for any hardware modification. In this paper, we have gone be- yond foveated rendering ( Inter-Holo ), by proposing an optimiza- tion/approximation called  Intra-Holo , that complements the for- mer in boosting performance/energy efficiency.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "However, in situations with sporadic energy income, the hardware-assisted scheduling becomes paramount. It ensures that active PEs efÔ¨Åciently utilize available power to complete work, preventing potential losses and eliminating the need to restart tasks from the beginning. Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "[40]  Rui Han, Moustafa M. Ghanem, Li Guo, Yike Guo, and Michelle Osmond. Enabling cost-aware and adaptive elasticity of multi-tier cloud applications. Future Gener.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "[32]  Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural languages. arXiv preprint arXiv:2002.08155 , 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "These strategies aim to balance energy expenditure with the need for timely and accurate data, often using heuristic or optimization-based approaches. However, they may not fully exploit the potential for collaboration among sensors or account for the strategic interactions inherent in decen- tralized networks. 2 \n110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 \n2.3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 167,
    "augmented": false
  },
  {
    "text": "By integrating the energy model into the training process, DynFit ensures the adjustments to dropout and quantization directly correspond to actual energy savings on the target hardware. A  QuantaTask  is defined as the smallest atomic unit of computation that can be executed entirely without interruption under the current energy and hardware constraints. Each QuantaTask ensures that execution proceeds without partial computation, which would otherwise lead to overhead from checkpointing and potential data corruption.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "3) Our proposed policy,  Origin , combines an adaptive conÔ¨Å- dence matrix and the activity aware scheduler to perform efÔ¨Åcient and accurate classiÔ¨Åcation. 2) We leverage temporal continuity of human activity, and persist the last successful classiÔ¨Åcation result of a sensor. We use aggressive recall which reduces the number of total inferences performed and mitigates the requirement that all of the sensors be involved in the ensemble process during each inference.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "31, pp. 994‚Äì1007, July 2012. [41]  R. Wang and Z. Xu, ‚ÄúA pedestrian and vehicle rapid identiÔ¨Åcation model based on convolutional neural network,‚Äù in  Proceedings of the 7th International Conference on Internet Multimedia Computing and Service , ICIMCS ‚Äô15, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "7 \n385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 \nEnergy Preservation: If  Œ≥  is too large, sensors might not value future energy at all. To prevent myopic strategies, one can limit  Œ≥  such that continuously investing in high-SNR captures does not dominate long-term considerations. For example: \nŒ≥  ¬∑  ‚àÜ A max  < Œ∑  +  margin , \nwhere  margin  accounts for future opportunities and energy savings.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 191,
    "augmented": false
  },
  {
    "text": "In  Social Informatics: 9th International Conference, SocInfo 2017, Oxford, UK, Septem- ber 13-15, 2017, Proceedings, Part II 9 , pages 378‚Äì390. Springer, 2017. [161] Li Wang, Wei Zhang, and Mei Huang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "the limited battery capacity prevents users from enjoying their AR devices for extended periods of time. To meet the heavy compute demands of these applications, most of AR applications are run using high-end desktop/server-class GPUs [ 18 ,  55 ], or specialized hardware accelerators [ 35 ] on cloud platforms [ 16 ,  27 ]. However, since most of these applications are now running on low-power mobile devices, and frequent communi- cation of data to and from cloud via wireless medium is inefficient, optimization of an AR pipeline to maximize the compute and en- ergy efficiency, while providing adequate QoS, at an edge device is an architectural challenge.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Note that, although our schemes employ the GPU with an extra overhead (e.g., the GPU power is about 1065 mW ), the CPU power is reduced (e.g., around  1310 mW , lower than that in TMC13 and CWIPC) since most of the computations are ofÔ¨Çoaded to GPU. Therefore, the overall energy savings brought by our schemes are similar to the corresponding execution latency reductions discussed above. Compression EfÔ¨Åciency:  To investigate how the compression efÔ¨Åciency changes with the above schemes, in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "The modular multiplication utilizing these signed numbers is formulated as follows: b  ‚äó a mod  q  =  q  ‚àí [( b  ‚àí a ) mod  q ] (1) \nHere, the most significant bit (MSB) signed-bit dictates the subtraction of the result from the modulus q , as illustrated in Fig. 3b. Consequently, there is no data in the range  [0 , q  ‚àí 1) , allowing the maximum value of the 13-bit samples to be represented efficiently by a 6-bit signed number.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "SemanticPaint: A Framework for the Interactive Segmentation of 3D Scenes. arXiv  (2015). [16]  Bo Han, Yu Liu, and Feng Qian.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "IEEE, 2020. [136] Reuters. Meta strikes geothermal energy deal with sage geosystems to power data centers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, our proposed new pipeline includes the following three steps: \nFigure 5: Intra-Frame geometry compression example. 4  d  . Motivated by this, we further optimize the attribute compression pipeline for a given frame, as shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Two such inefficien- cies are described below: ‚Ä¢  The majority of serverless platforms [ 32 ,  44 ,  46 ,  50 ] assume that DAGs in applications are static, implying that all com- posite functions will be invoked by a single request to the application. This assumption leads to the spawning of equal number of containers for all functions in proportion to the application load, resulting in container over-provisioning. ‚Ä¢  Dynamic DAGs, where only a subset of functions within each DAG are invoked per request type, necessitate the ap- portioning of containers to each function.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Exploring fault-tolerant network-on-chip architectures. IEEE, 2006. In  International Conference on Dependable Systems and Networks (DSN‚Äô06) , pages 93‚Äì104.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "As shown in Fig. Finally, the energy saving achieved by the  Inter-Intra-Holo  scheme is about 73%, meaning that it only consumes 27% of the baseline energy. 7c, on average, the  Inter- Holo  scheme saves 18% energy compared to the baseline, and the Intra-Holo  scheme saves 70% energy.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "It also incorporated the tool parameters like speed, feed \n4 \n0 0.5 1 1.5 2 2.5 3 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nInference Time (ms) \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(a) Inference time vs threshold \n0 1 2 3 4 5 6 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nAverage # Devices Encountered \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(b) Communication through (aver- age) number of devices vs Threshold \n0.78 0.8 0.82 0.84 0.86 0.88 0.9 \n0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 \nCorrelation \nVariance Threshold Edge-Cloud devices=2 Edge-Cloud devices=4 \nEdge-Peer devices=2 Edge-Peer devices=4 \n(c) Correlation vs threshold \n0 0.2 0.4 0.6 0.8 1 1.2 1.4 \n0.86 \n0.861 \n0.862 \n0.863 \n0.864 \n0.865 \n100 200 300 400 500 600 700 800 \nInference Time (ms) \nCorrelation \n# Cloud Estimators Correlation Inference Time \n(d) Accuracy (correlation) and infer- ence time vs # cloud estimators \nFig. 4: Sensitivity study and depth-of-cut, and measured the surface roughness of the grinding surface. The goal of our study was to correctly predict the surface roughness from sensor data.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 389,
    "augmented": false
  },
  {
    "text": "Association for Computing Machinery. In  Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture , MICRO ‚Äô52, page 657‚Äì669, New York, NY, USA, 2019. Distilling the essence of raw video to reduce memory usage and energy at edge devices.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "[84] K. Seyerlehner, G. Widmer, and P. Knees, ‚ÄúFrame level audio \nsimilarity-a codebook approach,‚Äù in  Proc. of the 11th Int. Conf.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the Twenty-Fourth International Conference on Archi- tectural Support for Programming Languages and Operating Systems . 2019. An open-source benchmark suite for microservices and their hardware-software implications for cloud & edge systems.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "OpenVINS: A Research Platform for Visual-Inertial Estimation. 2020. 2020 IEEE International Conference on Robotics and Automation (ICRA)  (2020), 4666‚Äì4672.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Hence, greedily assigning requests enables early scale down of lightly loaded instances. Though reactive policies (used in Clipper and InFaas) can be employed which take into account metrics like CPU utilization [ 83 ], these policies are slow to react when there is dynamism in request rates. 4.2.2 Autoscaler \nAlong with resource procurement, we need to autoscale instances to satisfy the incoming query load.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "All decisions related to VM au- toscaling, bin-packing and load-prediction are reliant on the centralized mongodb database, which can become a potential bottleneck in terms of scalability and consistency. Note that changing the models or/and framework would lead to minor deviations. While providing latency and top-1% ac- curacy of the pretrained models is an ofÔ¨Çine step in  Cocktail , we can calculate these values through one-time proÔ¨Åling and use them in the framework.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "The answer is  neural codecs  (Ma et al., 2019; Chen et al., 2017). Unlike traditional codecs that rely on predefined algorithms to compress video data, neural codecs utilize an end-to-end trainable system based on neural networks. Neural Codecs ‚Äì DNNs for Compression:  Neural codecs represent a paradigm shift in video com- pression technology, leveraging the capabilities of deep learning to optimize both encoding and decoding processes.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "Designing any sophisticated ensemble learning technique will either consume more resources of the host device, or need more information and computation at the edge, thus making our effort of Ô¨Ånishing the inference at the edge not viable. The current scheduler is activity aware, i.e. However, if we can design a simple, light weight and adaptive ensemble technique, then our design will be holistic from both the sensor and the host side.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Yang, A. Howard, B. Chen, X. Zhang, A. [2] ‚ÄúUse fall detection with apple watch,‚Äù 2020, https://support.apple.com/en- us/HT208944. [3] T.-J.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "The ideal parallelism granularity determination for a particular deployment should consider the balance between throughput and area. 0 20000 40000 60000 80000 100000 120000 140000 160000 \nPV HG LeNet FR G1 G2 G3 G4 (default) G5 \nArea in ¬≠ m 2 \n<2, 2, 2, 2, 2> <4, 3, 2, 3, 5> <6, 4, 3, 4, 7> <8, 5, 4, 5, 9> \n<12, 7, 6, 7, 13> \n<2, 2> <6, 2> <9, 3> <11, 5> <16, 7> \n<2, 2> <5, 2> <8, 3> <11, 4> <16, 6> \n<2, 2> <7, 2> <13, 3> <17, 4> <22, 6> \nFig. It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed ‚Äúsmart dust‚Äù solutions [ 8 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 228,
    "augmented": true
  },
  {
    "text": "Ac- cessed: 2024-04-27. [88] Minho Lee, Sooyeon Park, and Hyunsoo Choi. Load balancing techniques for efficient training of large-scale neural networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "com/science/article/pii/S0140366419307960 . \"Simon Wright\". Autonomous cars generate more than 300 tb of data per year.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "The robust exemplar selection and micro-proÔ¨Åling mechanisms are discussed and evaluated in ¬ß III-B  and ¬ß III-C , respectively. Hardware Innovation:  Us.¬¥as embraces the intermittency en- tailed by harvesting and advocates for hardware adaptation (resizing) to efÔ¨Åciently manage variable power income and avoid power emergencies. While previous works have de- signed energy-efÔ¨Åcient training hardware with support for variable precision training, none have adapted to variable energy income.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "This solves majority of the bottlenecks in a performance-driven classical cloud server platform. However, video analytics for many applications (Corporation; Custom On-Device ML Models with Learn2Compress; Wright\"; \"premioinc\") are moving towards the edge. Therefore, managing and storing the hefty volume of video data brings more challenge due to the energy, compute and form-factor limitations.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "0 \n2 \n4 \n6 \n8 \n60 \n70 \n80 \n90 \n60 70 100 120 150 350 \nAverage #Models \nAccuracy (%) \nLatency (ms) \naccuracy Average #Model \n(b)  Fixed Latency. Intuitively, singe large models with higher latency can satisfy \n0 2 4 6 8 10 \n0 \n100 \n200 \n300 \n400 \n72 78 80 81.5 83.5 85 \nAvegae #Models \nLatency (ms) \nAccuracy (%) \nLatency Average #Models \n(a)  Fixed Accuracy. It can be seen that for Ô¨Åxed accuracy of 72%, 78% and 80%, the average number of models increase with increase in latency, but drops to 1 for the highest latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "2.1 AR Holographic Applications and Pipeline \nThe holographic display technique enables a large body of aug- mented applications in real life [ 14 ]. 1a, where a physical car being driven on a highway is replaced by the corresponding virtual/augmented holographic car in a real-time fashion such that, instead of viewing the real cars, the AR user views the virtual ones. One such application is illus- trated in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "2. Ensure  Œª 1  ‚â§ c 1 G 1   and  Œª 2  ‚â§ c 2 G 2   for some constants c 1 , c 2  >  0 , to prevent excessively large gradients due to the regularizers. 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Figure  5  depicts the high-level design of  Cocktail . The participating models are made available in a model cache  1b for faster access and avoid re-computation for requests having similar constraints. Users submit requests to a master VM, which runs a model selection algorithm, 1a to decide the models to participate in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Career Counseling/Advising \nThe PIs will provide ‚Äì on a regular basis ‚Äì career counseling and advising to the PhD students in the project as part of the mentorship. The students will also have access to individual career counseling appointments with Penn State, who specialize in career and professional development. Additionally, the students will be encouraged to attend career and professional development workshops offered by Penn State.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "Class Full Power AP PT iNAS+PT Stateful ePerceptive DynBal NExUME \nR1 84.93 74.46 77.02 79.62 80.85 81.50 82.15 83.60 R2 85.85 76.21 79.18 80.36 81.95 82.60 83.25 84.50 R3 81.09 72.43 75.38 78.18 79.05 79.70 80.35 80.85 SJ 90.95 82.33 85.00 87.58 88.60 89.15 89.80 90.50 SI 94.76 85.31 88.05 89.90 91.00 91.65 92.30 93.00 Table 3: Accuracy of NExUME and other methods for industry status monitoring dataset using TI MSP board and piezoelectric energy source. Results collected over 200 experiment cycles. NExUME demonstrates superior performance across all operating classes, achieving the highest accuracy in each case.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 245,
    "augmented": false
  },
  {
    "text": "Note that we do not delve into the details of the computa- tional primitives involved in training the DNN as several prior works [ 15 ], [ 16 ], [ 80 ] provide a very detailed accounting of it (for both forward and backward pass) along with the hardware and control requirements. Whenever all the local work queue counter hits zero along with the layer kernel counter, the control moves to schedule the next layer (or previous layer in backward propagation) for computation. We treat the convolution scheduling (using input stationary and at a kernel level) in a morphable systolic hardware to be the main challenge and explain it.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "doi: 10.1109/HPCC/SmartCity/DSS. 2019.00259. 1878‚Äì1885, 2019a.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "Our extensive experimental results show that, compared to a state-of-the-art intra-frame PCC technique [ 56 ], our intra- frame proposal can accelerate the PCC by  43 . ‚Ä¢  We implement and evaluate our proposals on an edge device ‚Äì NVIDIA Jetson AGX Xavier board [ 58 ]. Also, to utilize temporal locality, we propose an inter-frame compression scheme which further increases the compression efÔ¨Åciency.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "This is for enabling users to freely move around in a large area without the need of connecting with a power cable constantly. Hence, the power/energy efficiency is critical metrics in many AR use cases so that the battery lifetime can be sufficiently long. With these sensors and compute resources in place, an AR head- set executes a set of software tasks, either entirely or selectively based on the applications‚Äô requirements [ 19 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "[89] E. Strubell, A. Ganesh, and A. McCallum, ‚ÄúEnergy and policy con- \nsiderations for deep learning in nlp,‚Äù  arXiv preprint arXiv:1906.02243 , 2019. [90] J. S.-M. studyÔ¨Ånds.org, ‚ÄúTrafÔ¨Åc cameras become more popular when \nthey cut down on interactions with police,‚Äù  https://studyÔ¨Ånds.org/ trafÔ¨Åc-cameras-interactions-police/ , (Accessed on 04/28/2023). [91] N. A. W. .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "There are three cases: Case-1:  If the data is close to one of the cluster centers and belongs to its cluster boundary, then it falls into the bucket of that particular class. This typically happens if the data are very similar to the training samples. Case-2:  If the data belongs to a known class, but is signif- icantly different from the training samples, it falls not too far from one of the clusters.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "Our research tasks in Thrust 1 are illustrated in Figure 3. They will address the following research questions: i)  What is the search space for EoE systems, in terms of expert types, expert routing, expert model architecture, and expert composition? ; ii)  How can we dynamically shape the morphology of EoE systems by identifying the best design points in the search space?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "8: Performance and energy improvements for YOLOv3 w.r.t. the baseline;  XX:our  are the results achieved by our proposed FI+PI+SI scheme;  XX:dc  are the results for DeepCache [8];  V1P  and  V2P  are part of V1 and V2, respectively; and  AVG  is the weighted average (weight is the # of frames in each video). 0% \n20% \n40% \n60% \n80% \n(a) FI+SI energy saving \n0% 20% 40% 60% 80% 100% \nFull Overhead \n(b) FI+SI exec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "Furthermore, these accelerators have been designed to operate under constantly available power. Although our pro- posed representation learning (¬ß III ) and micro-proÔ¨Åler (¬ß III-C ) help us Ô¨Ånd a better training conÔ¨Åguration that can minimize the compute if deployed in the aforementioned accelerators, it does not solve sustainability: That is, with variable solar power, can we scale compute alongside power to continue to make ‚Äúforward progress‚Äù, even when minimum amount of power is available. The systolic array structure of the DNN accelerators is well suited for this as we can change the com- pute size, as well as the number of memory channels feeding to those compute units as per the power availability.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "[29]  J. Deng, W. Dong, R. Socher, L. Li, and and. Imagenet: A large-scale hierarchical image database. Deep Learning Dtudio, February 2020. https://docs.deepcognition.ai/ .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "[80] Jongman Kim, Chrysostomos Nicopoulos, Dongkook Park, Vijaykrishnan Narayanan, Mazin S Yousif, and Chita R Das. Optimizing resource allocation in gpu clusters for deep learning training. IEEE Transactions on Parallel and Distributed Systems , 32(8):1987‚Äì2000, 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "As shown for  Const1 ,  Cocktail  shows similar reduction (as image-classiÔ¨Åcation) with only using 4.8 models on average, which is 40% and 26% lower than Clipper  and  Clipper-X , respectively. Cocktail  is also able to reduce the number of models by 30% and 50% for medium ensembles ( Const2  &  Const3 ) as well. Figure  16b  plots the latency reduction and accuracy gain, compared to  InFaaS  (baseline).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "As discussed in Sec. III, the projection computation varies across  eyes  even for the same head orientation. Moreover, in many cases, computations are also sensor input-dependent such as the IMU data for determining the head orientation, which is updated across frames , at runtime.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "The accuracy of both system might be identical (over a large number of test sets), yet for the current test case, both the models are not equally conÔ¨Ådent about the classiÔ¨Åcation. The question is, how do we measure the conÔ¨Ådence of the given classiÔ¨Åcation? It is obvious that the most conÔ¨Ådent classiÔ¨Åcation for the same class would be [1 ,  0 ,  0 ,  0] , where the model is 100% conÔ¨Ådent on class  o 1  and the most confused prediction would be  [0 .",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "828‚Äì842, 2017. [48]  R. Mekuria, K. Blom, and P. Cesar, ‚ÄúDesign, implementation, and evaluation of a point cloud codec for tele-immersive video,‚Äù  IEEE Transactions on Circuits and Systems for Video Technology , pp. 129‚Äì147, 1982.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Besides accuracy again, ensembling can also achieve lower latency. The latency of the ensemble is calculated as the time between start and end of the longest running model.As shown in Table  3 , in the case of  NASLarge , the ensemble latency is 2 √ó  lower (151ms) than the baseline latency (311ms). Even a 10ms reduction in latency is of signiÔ¨Åcant importance to the providers [ 35 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "[63] H. Zhang, P. V. Rengasamy, S. Zhao, N. C. Nachiappan, A. Sivasub- ramaniam, M. T. Kandemir, R. Iyer, and C. R. Das, ‚ÄúRace-to-sleep + Content Caching + Display Caching: A Recipe for Energy-efÔ¨Åcient Video Streaming on Handhelds,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2017, pp. 57 ‚Äì 65. SPIE, 2016, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Although the intra-cluster data distribution will be different from the original, it will still preserve the overall geometry with a certain degree of approximation which the DNN could learn to accommodate. Experimentally, on the MHELATH dataset, we observe that inferring on the synthesized reconstructions of cluster \n0 \n20 \n40 \n60 \n80 \n100 \nWalking Climbing Cycling Running Jogging Jumping \n% Accuracy \nk= 12 (Baseline) K= 15 k =10 k = 8 k=6 \nFigure 6: Accuracy with different #clusters (k). Clustering Recovery \nOriginal Data Coreset Recovered Data \n(a) Recovering a cluster with uniform random re-distribution.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "Only intermittent learn- ing [ 47 ] focuses on performing on-device training, but with very small workloads and models. Similarly, Ekya [ 12 ] only focuses on co-location of computation, and it‚Äôs efÔ¨Åciency on Ô¨Ånishing compute even on a custom hardware is shown in Fig. Considering the scale, scope and workload of our problem, limits direct comparisons, ex- cept for comparing their exemplar selection method.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "6042‚Äì6051. [69]  Z. Que, G. Lu, and D. Xu, ‚ÄúVoxelcontext-net: An octree based framework for point cloud compression,‚Äù in  CVPR , 2021, pp. [70]  Ricci Rox, ‚ÄúPower-hungry Snapdragon 8 Gen 1 gets trounced by the Apple A15 Bionic in real-world gaming test,‚Äù  ‚Äùhttps: //bit.ly/3P086pp‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "For instance, Figure 8 indicates that the Social Network ,  Media Service  and  Hotel Reservation  applica- tions show the highest (73%, 53% and 36%), moderate (40%, 28% and 7%) and least (at most 33%) reductions in the number of containers spawned with respect to existing policies,  Arch , Fifer  and  Xanadu , respectively. Both  Social Network  and  Me- dia Service  have a high number of workflows, but the former has more functions with higher slack, leading to increased batching, thereby resulting in the most reduction in con- tainers spawned. The reduction in the number of containers spawned by Kraken  in comparison to other policies is roughly propor- tional to the total number of application workflows and the slack available for each function within a workflow (see Ta- ble 2 and Figure 7).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 202,
    "augmented": true
  },
  {
    "text": "In this case, the training is completed in 3 steps. As depicted in Figure 4(b), we train E1, E5, and E7 together as they share datasets, followed by E2, E3, and E6, and the remaining experts. D1 \nD2 \nD3 \nD4 \nD5 \nD6 \nD7 \nD8 \nE1 \nE2 \nE3 \nE4 \nE5 \nE6 \nE7 \nE8 \nStep-1: {E1, E5, E7} use {D1, D2, D5} \nStep-2: {E2, E3, E6} use {D3, D6, D7} \nStep-3: {E4, E8} use {D4, D8} \n(a) \n(b) \nFigure 4 :  Bipartite graph to perform data locality- aware expert training.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 172,
    "augmented": true
  },
  {
    "text": "To ensemble the \nAR pipeline with generic state-of-the-art components shown in Fig. 5.2 Experimental Platform and Datasets \nThe edge GPU platform used in this work consists of a 512- core Volta GPU, a 4Kp60 HEVC codec, 16GB LPDDR4x memory, 32GB eMMC storage, and a power management unit (PMU) that exposes the real-time power traces to users [ 36 ]. With this estimation, we briefly discuss the performance and computational efficiency variations between this accelerator and our approach, and discuss takeaways that can help one to co-design a hardware accelerator targeting hologram processing.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "In Proceedings of the IEEE International Conference on Computer Vision . 5429‚Äì5438. [55]  Rohan Paul, Dan Feldman, Daniela Rus, and Paul Newman.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "However, not all the deployments may want to participate in data sharing because of privacy reasons. Using the example of modern industrial machine state monitoring, the sensor attached to the machines for monitoring their health can also give away critical information like run time, operating conditions, materials etc., which might cause major privacy concerns. This problem has been addressed in federated learning by combining the models using weight averaging [2].",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Figure  1  shows the candidate models which can be used for a given latency and accuracy. This re-instantiates our claim that the resource procurement scheme needs to be aware of request constraints. Therefore, this results in reduced cost and at the same time does not violate SLOs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": ", and  iii) what are the resulting beneÔ¨Åts and overheads? ,  ii) how to integrate such optimizations into the entire geometry compression pipeline? 1) How to Increase Parallelism?",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "With these inputs, the  Transform  step \n5 We consider the octree-based technique [ 56 ], [ 72 ] and RAHT [ 14 ], [ 56 ] as SOTAs for geometry and attribute compression respectively. 287 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": ", and if not,  (iii) can we just focus on the RoIs in the current frame and signiÔ¨Åcantly reduce the computational requirements for its inferencing? Towards this, we propose and thoroughly evaluate a new approach to answer the aforementioned questions. SpeciÔ¨Åcally, our approach combines inter-frame similarities, motion vectors (MVs), and the concept of regions of interest, to make online video analytics/inferences inherently faster, along with the runtime support for improving the video streaming pipeline.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "This proÔ¨Åling collects data used to determine the best activation solution for each power level. As part of compiling a CNN to ResiRCA, we build a proÔ¨Åling table relating each potential tiling and pipeline conÔ¨Åguration \nthat might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw. At runtime, each time when entering a new power cycle, we Ô¨Årst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "A Unified View of EoE Function Choices. Towards this, we aim to explore a vast design space of model architecture choices and expert model types. Expert models are also ‚Äúcomposable‚Äù, so that they can be chosen dynamically according to inputs and then grouped together to solve difficult tasks, which require a combination of skills and knowledge sources.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "The Probability Vector after  ùëë number of time steps can be represented as  ùëÉ ùëë . Then, the Probability Vector for the next time step,  ùëë +  1, is given by the  transition equation ,  ùëÉ ùë° + 1  =  ùëá ¬∑  ùëÉ ùë° . This equation infers that the Proba- bility Vector at the next time step is obtained by performing a transition operation across all possible current states.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "[70] Rishabh Jain, Vivek M Bhasi, Adwait Jog, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita R Das. Adaptive mixtures of local experts. Neural computation , 3(1):79‚Äì87, 1991.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Furthermore, the better the high-power supply can be aggressively utilized, the more ambient energy can be continuously extracted without increasing the energy storage capacity for the energy-harvesting power delivery system. Since each single ReRAM can be activated at a Ô¨Åner granularity with tiling, the parallelism can be achieved under a Ô¨Çexible range of power consumption to match a variable power supply. Therefore, this weight duplication- based execution style built upon Ô¨Åne-granularity activation can effectively combat  Nonideal scenario 2 .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "We propose a novel and efficient approach for continual learning of EoE. We split a large expert into smaller, domain-specific experts, train them on focused domain- specific datasets, and then merge them back into a reinforced model. This strategy is particularly useful when we need a single model to handle diverse knowledge sources or when we aim to reduce training costs by first training smaller models and then combining them.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "Moreover, we also implement the memoization option so that it does not have to repeat infer- ences if it encounters similar data, thereby saving substantial energy as well as delivering results with extremely low la- tency. However, even with all these optimizations, due to the fickle nature of EH,  Seeker  cannot finish all the inferences at the edge and must communicate with a host device. To minimize the data communication overhead between the sensor-node and the host device,  Seeker  utilizes coresets to build representative, yet compressed, forms of the data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 130,
    "augmented": false
  },
  {
    "text": "[16] Josiah L Carlson. In  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 9368‚Äì9377, 2018. Redis in action .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "For example, AFBC [1] is proposed to efÔ¨Åciently compress video streams between the processing pipeline blocks. MACH [63] integrates a display cache to reduce the amount of memory bandwidth. Although, these techniques can potentially save memory usage/energy for  360 ¬∞ VR videos, as discussed in earlier sections, due to inherent nature of  360 ¬∞ video processing, which introduces additional overheads for projection computation, we identify compute  to be the major energy bottleneck.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "IEEE Access  8 (2020), 93155‚Äì93178. [54]  Kyle Olszewski, Zimo Li, Chao Yang, Yi Zhou, Ronald Yu, Zeng Huang, Sitao Xiang, Shunsuke Saito, Pushmeet Kohli, and Hao Li. 2017.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Cocktail takes the accuracy of each model as a probability of cor- rectness and then iteratively constructs a model list, where the joint probability of them performing the classiÔ¨Åcation is within the accuracy target. max ¬µ AL  : \u001a Acc target  ‚â• Acc target  ¬± Acc margin Lat target  ‚â§ Lat target  ¬± Lat margin \nTo solve  O 1 , we determine an initial model list by choosing the individual models satisfying  Lat target  and then create a probabilistic ensemble that satisÔ¨Åes the  Acc target . Our Ô¨Årst objective function ( O 1 ) is to the maximize  ¬µ AL  such that target accuracy ( Acc target ) is reached within the target latency ( Lat target ).",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "To answer this, we plan to characterize the number of depth planes needed in various AR applications, and guide the optimal design choices (i.e., number of PUs, frequency, input and output buffer size, etc.) based on application require- ments, and evaluate both PSNR and user-experience metrics such as satisfaction and dizziness [ 66 ]. Second, How do we maintain high power efficiency of PUs during runtime?",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "accuracies (< 75%) because single models can reach those accuracies. Hence, based on the user constraints,  Cocktail chooses between ensemble and single models. 2.3.2 Ensembling Overhead \nWhile ensembling can boost accuracy with low latency, their distinctive resource hungry nature drastically increases the deployment costs when compared to single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "In  2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA) , pp. 23 \nShulin Zhao, Haibo Zhang, Cyan Subhra Mishra, Sandeepa Bhuyan, Ziyu Ying, Mahmut Taylan Kandemir, Anand Sivasubramaniam, and Chita Das. 241‚Äì253, 2020. doi: 10.1109/ISCA45697.2020.00030.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "4. Diminishing Step-Size and Convergence Results \nClassical convex optimization theory (see Bottou et al. Update step:  With a chosen step size  Œ± k , \nŒ∏ k +1  =  Œ∏ k  ‚àí Œ± k   b ‚àá J ( Œ∏ k ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "2% accuracy of the state-of-the-art. 8% accuracy, surpassing the 81 . 9 √ó  reduc- tion in communication data volume with 86 .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "Commonality  and  Connectivity  (parameters in  2a  ) are additional parameters used in weight estimation to account for critical and common functions. Additionally, a Load Pre- dictor module  2b  makes use of the system metrics to predict \n1 Kraken is a legendary sea monster with tentacles akin to multiple paths/chains in a Serverless DAG. Containers \nRequest  \nQueue \nFunction 1 \nFunction 2 \nFunction n \n.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Over 10 training iterations, we observed the micro-proÔ¨Åler to be con- sistent with the oracle (except for one case of iteration 7). Note that the hyperparameter selected in iteration 7 by the micro- proÔ¨Åler performs as good as the the oracle model in terms of achieving accuracy, albeit by performing more computation. A deep dive into 7 th   iteration reveals that the micro-proÔ¨Åler chose a higher learning rate (compared to the oracle), which biased the convergence curve Ô¨Åtting and extrapolation (as discussed in ¬ß III-C ) and hence suggested a larger number of layers to be trained to achieve the required convergence.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "USENIX Association, 2018. [8] K. Maeng and B. Lucia, ‚ÄúAdaptive dynamic checkpointing for safe efÔ¨Åcient intermittent computing,‚Äù in  OSDI . ACM, 2019.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "1941‚Äì1953, 2017. [17] L. Liu, H. Li, and M. Gruteser, ‚ÄúEdge Assisted Real-Time Object Detection for Mobile Augmented Reality,‚Äù in  Proceedings of the An- nual International Conference on Mobile Computing and Networking (MobiCom) , 2019. [16] Aashish Chaubey, ‚ÄúDownsampling and Upsampling of Images - Demys- tifying the Theory,‚Äù ‚Äùshorturl.at/rCMPU‚Äù, 2020.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "Dynamic weighted majority: An ensemble method for drifting concepts. Journal of Machine Learning Research , 8(Dec):2755‚Äì2790, 2007. [50]  Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "To achieve a simulation that aligns closely with actual device implementation and captures detailed system-level interactions, we intend to employ several specialized tools (see Figure 7). Since modularity is the backbone of our proposed framework, we envision a detailed simulation of the in- dividual hardware modules (e.g., chiplets, cache/memory components, on-chip and chip-to-chip networks, \netc), as shown in Figure 7 and stitching the evaluation framework for all such discrete modules together to build an ‚Äúend-to-end‚Äù modeling platform for the proposed system. The second component will be based on simulation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "However, instead of designing a centralized DNN which processes the combined data from all the sensors, we design three different smaller DNNs that work on their individual data. B. DNN ClassiÔ¨Åer and the Dataset \nOur DNN design choices are inspired from the works in [11], [14]. The speciÔ¨Åcs of the energy-harvesting mechanism producing the power trace are beyond the scope of this work.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "[37] Shihan Dou, Enyu Zhou, Yan Liu, Songyang Gao, Jun Zhao, Wei Shen, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, and Xuanjing Huang. ACM, 2014. In Proceedings of the 22nd ACM International Symposium on High-Performance Parallel and Distributed Com- puting , pages 151‚Äì160.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "Game-Theoretic Modeling \n4.1. Motivation for Game Theory over Simpler Methods \nWhile heuristic methods‚Äîsuch as always selecting the top- k  sensors based on current energy levels‚Äîor greedy algo- rithms that maximize immediate utility might offer straight- forward solutions, they fall short in addressing the strate- gic and long-term dynamics inherent in EH-WSNs. These simplistic approaches ignore the interdependencies among sensor decisions and fail to account for future resource allo- cation, potentially leading to suboptimal performance over time.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "[5] Dennis Abts, Garrin Kimmell, Andrew Ling, John Kim, Matt Boyd, Andrew Bitar, Sahil Parmar, Ibrahim Ahmed, Roberto DiCecco, David Han, John Thompson, Michael Bye, Jennifer Hwang, Jeremy Fowers, Peter Lillian, Ashwin Murthy, Elyas Mehtabuddin, Chetan Tekur, Thomas Sohmers, Kris Kang, Stephen Maresh, and Jonathan Ross. A software-defined tensor streaming multiprocessor for large-scale machine learning. In  Proceedings of the 49th Annual International Symposium on Computer Architecture , pages 567‚Äì580, 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "Subsequently, it triggers container scaling  6  by calculating the additional containers needed to mitigate the delay. Second, a Function Idler component  7b  evicts containers from memory  6  when an excess is detected. Thus,  Kraken  makes use of PWS and RS to scale containers to meet the target SLOs while simul- taneously minimizing the number of containers by making use of function invocation probabilities, function batching, and container eviction, where appropriate.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Hence, the over- all cost incurred by  mixed  procurement can be higher or lower than VM-only autoscaling policies. However, this might result in increased cost when using  serverless functions  along with VMs for varying latency requirements. Therefore, depending on the latency re- quirements of the user applications,  serverless functions  need to be allocated the appropriate memory.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Our evaluations indicate 2.2 √ó speedup and 56 %  energy saving over the baseline setting. Further, relaxing the accuracy loss tolerance to 2 % , we can save up to  80%  energy. Additionally, the experimental analysis indicates that our approach outperforms the state-of-the-art work with respect to accuracy and/or performance/energy savings.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Set a diminishing step-size schedule  { Œ± k } k ‚â• 0 . 2:  for  each training round  k  = 0 ,  1 ,  2 , . .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "[101] J. Xu and X. Wang, ‚ÄúRethinking self-supervised correspondence learn- \ning: A video frame-level similarity perspective,‚Äù in  Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021, pp. [100] www.dlapiperdataprotection.com, ‚ÄúSweden data collection & process- \ning,‚Äù  https://www.dlapiperdataprotection.com/index.html?t=collection- and-processing&c=SE , (Accessed on 11/21/2022). 10 075‚Äì10 085.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "A. Design Description of the DNN Hardware Augmentations \nCompute Mapping:  Fig. 5a  shows the high level design, architecture and different components present in our proposed accelerator.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Such platforms represent the future of the Internet of Things (IoT) and energy harvesting wireless sensor networks (EH-WSNs). Equipped with modern machine learning (ML) techniques, these devices can revolutionize computing, monitoring, and analytics in remote, risky, and critical environments such as oil wells, mines, deep forests, oceans, remote industries, and smart cities. However, the intermittent and limited energy income of these deployments demands optimizations for ML applications at the algorithm (Yang et al., 2017; Shen et al., 2022; Mendis et al., 2021), orchestration (Maeng & Lucia, 2018; Mishra et al., 2021), compilation (Gobieski et al., 2018), and hardware development (Qiu et al., 2020; Islam et al., 2022; Mishra et al., 2024) layers.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 219,
    "augmented": false
  },
  {
    "text": "This behaviour is expected and can be attributed to the increasing number of completed inferences. The nature of the workload itself gives us an opportunity to not perform inference at a rapid rate. Further evaluations suggest Origin  with RR-12 to be the best Ô¨Åt for HAR.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "However, the number of skipped inferences there is  static . As a sample work, Euphrates [9] employs MVs to detect small changes between frames and skips unnecessary inferences. However, in the speciÔ¨Åc context of video applications, the ‚Äútemporal continuity nature‚Äù of the video data presents itself as an opportunity that is yet to be fully exploited.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "Thus, the full inference outputs are accordingly padded around the partial inference outputs via memory copy (Step  5  ). For the other regions in the output feature map for this frame, it is safe to simply pad them with zeros (Step  6  ). And, Ô¨Ånally, we update RoI for the next layer (the region with the purple border in Step  7  ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Our Intra-only:  The performance of above two tech- niques has two orders of gap with the  ‚âà 100 ms  real- time requirement [ 19 ]. On the other hand, our intra- only scheme takes only  95 ms  ( 42 ms  for geometry and 53 ms  for attribute compression), which is  43 √ó  faster w.r.t. TMC13.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "4820‚Äì4828. [5] Tencent, ‚ÄúNCNN,‚Äù ‚Äùhttps://github.com/Tencent/ncnn‚Äù, 2017. [6] Alibaba, ‚ÄúMNN: Mobile Neural Network,‚Äù ‚Äùhttps://github.com/alibaba/ MNN‚Äù, 2019.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Moreover, the two  P 1  points are located closely (i.e.,  [ 12 , 8 , 13 ]  vs  [ 12 , 8 , 12 ] ), and contain very similar attribute values ( 52  vs  51 ). Thus, the P-Frame can also be further compressed by reusing the P 1  data in the previous I-Frame, without losing too much quality. On the other hand, the two  P 2  points are relatively far away from each other and their attribute inputs are quite different, offering little reuse opportunity.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "Kube-knots: Resource harvesting through dynamic container orchestration in gpu- based datacenters. In  2019 IEEE International Conference on Cluster Computing (CLUSTER) , pages 1‚Äì13, 2019. [157] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "To study how the inter-compressed frames/blocks would affect the compression efÔ¨Åciency (the compressed size w.r.t. the raw PC frame) and the quality (PSNR), we  reconÔ¨Ågured  the number of ‚Äúdirect-reuse‚Äù blocks \ni iii iv ii \n(a) Original vs. decoded PCs with our proposals. 37 39 41 43 45 \n7 8 9 10 11 12 \n31%58%69%79%82% \nPSNR(dB) \nCompressed Size  w.r.t.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "[82] scale.com, ‚ÄúData labeling: The authoritative guide,‚Äù https://scale.com/guides/data-labeling-annotation-guide#data-labeling- for-computer-vision , (Accessed on 11/21/2022). [83] A. W. Services, ‚ÄúAws outposts rack pricing,‚Äù  https://aws.amazon.com/ \noutposts/rack/pricing/ , (Accessed on 11/21/2022). [84] K. Seyerlehner, G. Widmer, and P. Knees, ‚ÄúFrame level audio \nsimilarity-a codebook approach,‚Äù in  Proc.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 153,
    "augmented": true
  },
  {
    "text": "While many of the prior works have designed their systems around inference using intermittent systems, we are one of the few works which focuses on learning, and the only work which does it on a large scale of data. The proposed system is not only energy intermittent, but also memory intermittent, interconnect intermittent and most importantly data intermittent (we don‚Äôt know how much data and what data). This gives us a unique platform to think of intermittency beyond embedded systems and energy.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "[131] Raghu Prabhakar, Ram Sivaramakrishnan, Darshan Gandhi, Yun Du, Mingran Wang, Xiangyu Song, Kejie Zhang, Tianren Gao, Angela Wang, Karen Li, Yongning Sheng, Joshua Brot, Denis Sokolov, Apurv Vivek, Calvin Leung, Arjun Sabnis, Jiayu Bai, Tuowen Zhao, Mark Gottscho, David Jackson, Mark Luttrell, Manish K. Shah, Edison Chen, Kaizhao Liang, Swayambhoo Jain, Urmish Thakker, Dawei Huang, Sumti Jairath, Kevin J. Brown, and Kunle Olukotun. Sambanova sn40l: Scaling the ai memory wall with dataflow and composition of experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 206,
    "augmented": false
  },
  {
    "text": "A standard offering with 2 √ó g4dn.12xlarge instances need 4kW power [ 7 ] (the compute units have a TDP of  ‚âà 1 kW  [ 65 ], [ 71 ]) for \nperforming analytics. Sustainable  Continuous Learning at the Edge:  Even given such advancements in continuous learning on edge servers, provisioning training resources at the edge for every sensing- to-analytics application entails sustainability questions. For ex- ample, a popular AWS outpost, a g4dn.12xlarge instance [ 83 ], consists of a 24 core Intel Xeon CPU (150W TDP) [ 71 ] with 192GB of memory and 4 NVIDIA T4 (with tensor cores, 70W TDP) [ 65 ] with 64GB GPU memory.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 191,
    "augmented": true
  },
  {
    "text": "3 NExUME Framework \nTo address the issues with  intermittency-aware  DNN training and inference, we propose NExUME: ( N eural  Ex ecution  U nder Inter M ittent  E nvironments). NExUME has three interrelated compo- nents: (1)  DynNAS : Intermittency- and platform-aware neural architecture search; (2)  DynFit : Intermittency- and platform-aware DNN training with dynamic dropouts and quantization; and (3) DynInfer : Intermittency- and platform-aware task scheduling for inference. While each component can individually optimize DNNs for intermittent environments, their combination yields the best results.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 168,
    "augmented": false
  },
  {
    "text": "heavily loaded tiles. We implemented a counter (local kernel counter) to keep track of the size of the remaining local work queue of each of the tile. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "(b) Energy consumption. (c): Compression efÔ¨Åciency. in parallel with the help of Morton codes, which speeds up the geometry compression by  37 √ó ; 2).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "We also model the pipelined computation mode shown in Equations 4 and 5. Note that the pipelined computation mode means that all the  LC convolution layers are executed fully parallel. P   pipe   = \nLC X \nLk =1 P Lk (4) \nLat pipe   =  max ( Lat L 1 , Lat L 2 ...Lat LC ) (5) \nC. Dynamic activation strategy \n1) Problem formulation:  In this section, we focus on Ô¨Åguring out the ResiSchedule solution to achieve the maximal throughput.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Battery-Free Operation:  A key highlight of  Us. ¬¥as  lies in its battery-free operation, which aligns with the current global push for sustainable computing. The scaling up via mil- \n893 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "https://www.xilinx.com/products/design-tools/ vitis/vitis-platform.html , a. (Accessed on 11/13/2023). AMD.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "1‚Äì15. [25]  Joao Carreira, Pedro Fonseca, Alexey Tumanov, Andrew Zhang, and Randy Katz. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "C ONCLUDING  R EMARKS \nPC processing has become the trend for many video applications spanning scientiÔ¨Åc computing, education, health- care and entertainment, and is recently being ofÔ¨Çoaded to the edge. PC compression is an essential component of PC processing (and a critical performance bottleneck), which affects video quality, user experience, and energy efÔ¨Åciency. Unfortunately, prior works mainly focused on compression ratio, but did not consider the performance and energy implications, particularly for edge devices.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": ". . 5:  Simulation-Refinement Loop: 6:  for  k  = 1 ,  2 , .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "[96] Sean Lie. Cerebras architecture deep dive: First look inside the hardware/software co-design for deep learning. IEEE Micro , 43(3):18‚Äì30, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": ". . , q k }  be a set of QuantaTasks with in- dividual energy requirements  E q i .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "In our  EA  design, the last two head orientations are  cached  in local SRAM ( Comp 1  and  Comp 2  in the  EA block) and their corresponding projection computation results are stored in DRAM ( P i ‚àí 2 buff   and  P i ‚àí 1 buff ). Once the current head orientation is received, the  EA  block Ô¨Årst compares it with the memoized  Comp 1  and  Comp 2 . If a match is detected, then the corresponding  P i ‚àí 2 buff   or  P i ‚àí 2 buff   buffer address pointer is directly returned.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "There are mainstream commercial systems which automate single model-serving like TF-Serving [ 60 ], SageMaker [ 6 ], AzureML [ 10 ], Deep-Studio [ 28 ] etc. Autoscaling in Public Cloud : There are several research works that optimize the resource provisioning cost in pub- lic cloud. These works are broadly categorized into: (i) multiplexing the different instance types (e.g., Spot, On- Demand) [ 12 ,  23 ,  34 ,  41 ,  42 ,  68 ,  79 ], (ii) proactive resource provisioning based on prediction policies [ 34 , 36 , 40 , 41 , 69 , 86 ].",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 166,
    "augmented": false
  },
  {
    "text": "Therefore, in principle, \n0 1 2 3 \nbike \nbook \nbottle \ncamera \ncerealBox \nchair \ncup \nlaptop \nshoe \nDistance/Size (m) \nCam2ObjDist. ObjSize \n(a) Object study. 3).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "[36] Xiaobin Dong, Kurt Keutzer, and Cong Zhang. Ramulator: A cycle accurate dram simulator. In Proceedings of the 22nd ACM International Symposium on High-Performance Parallel and Distributed Com- puting , pages 151‚Äì160.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Spock: Exploiting Server- less Functions for SLO and Cost Aware Resource Procurement in Public Cloud. In  CLOUD . [6] Aaron Harlap, Andrew Chung, Alexey Tumanov, Gregory R. Ganger, and Phillip B. Gibbons.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "A large portion of our test and development will be performed on these machines. The PIs and their students also have access to grid and supercomputing resources through the College of Engi- neering at University Park. A variety of other grid computing resources are also freely available to their re- search groups.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "IEEE Access , 10:101999‚Äì102008, 2022. Kaisheng Ma, Xueqing Li, Karthik Swaminathan, Yang Zheng, Shuangchen Li, Yongpan Liu, Yuan Xie, John Jack Sampson, and Vijaykrishnan Narayanan. Nonvolatile processor architectures: Efficient, reliable progress with unstable power.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "2009. https://doi.org/10.1109/CLUSTER.2019. 8891040 [49]  Guido Urdaneta, Guillaume Pierre, and Maarten Van Steen.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "A standard offering with 2 √ó g4dn.12xlarge instances need 4kW power [ 7 ] (the compute units have a TDP of  ‚âà 1 kW  [ 65 ], [ 71 ]) for \nperforming analytics. Scaling this to crowded cities with 30- 50+kilo-cameras like Beverly Hills ( >  35 k  [ 11 ]), Los Angeles ( ‚âà 35 k  [ 92 ]), New York ( ‚âà 56k [ 92 ]), or Chicago ( ‚âà 30k) will need a lot of power. With state-of-the-art learning APIs [ 60 ] and intelligent co-location and scheduling of inference and continuous learning [ 12 ], these edge servers can support about 8 videos streams [ 12 ], resulting in  ‚âà 120 W  (just for compute) per video stream.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 190,
    "augmented": true
  },
  {
    "text": "2018. IEEE. [59]  Mohammad Rostami, Jeremy Gummeson, Ali Kiaghadi, and Deepak Ganesan.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "3  shows a typical trafÔ¨Åc distribution from Urban TrafÔ¨Åc data [ 97 ]) and the impact of sampling bias on class distribution. Note that, as some of the classes (e.g., bicycles) are barely present in the exemplar, the model tend to lose accuracy (because of catastrophic forgetting) on them, whereas the model rapidly over-Ô¨Åts for the classes with more examples (e.g., trafÔ¨Åc light). B.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Also, the number of concurrent requests which can be executed in VMs should be accurately determined to meet response latency. 0 \n0.4 \n0.8 \n1.2 \n1.6 \nBerkley WITS Twitter Wiki \nNormalized VMs \nreactive util_aware exascale \nFigure 4. Over-provisioning of  util_aware  and  exascale , nor- malized to a baseline  reactive  scheme for four traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "[155] The New York Times. USENIX Association. Amazon, google, microsoft turn to nuclear energy.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 26,
    "augmented": true
  },
  {
    "text": "The ideal latencies and our collected latencies are given in Table 1 and Fig. 2, respectively, for an ILLIXR playground scenario [15, 19]. 1c) on a typical edge prototype [ 36 ] running a set of state-of-the-art AR-related tasks [ 19 ,  26 ,  49 ,  50 , 53 ], and compared the collected results against ideal execution latencies for the same set of tasks (i.e., the maximum latency within which the task needs to finish before its next invocation).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "3. 5: A subset of sensors, determined by the equilibrium, send their gradient estimates to the aggregator. Adding regularizer gradients  Œª 1 ‚àá ‚Ñ¶ SNR ( Œ∏ k )  and Œª 2 ‚àá ‚Ñ¶ complexity ( Œ∏ k ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Heng Tao Shen, Beng Chin Ooi, and Xiaofang Zhou. IEEE, 2022b. Towards effective indexing for very large video sequence database.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Tong Chen, Haojie Liu, Qiu Shen, Tao Yue, Xun Cao, and Zhan Ma. Deepcoder: A deep neural network based video compression. In  2017 IEEE Visual Communications and Image Processing (VCIP) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Further, we apply our policies to the distributed data and train random forest models (both for the edge and the cloud). Figure 2 shows the accuracy of various policies on 2-home and 4-home setups. Following are the key observations from our experiments.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "11 \nYongpan Liu, Zewei Li, Hehe Li, Yiqun Wang, Xueqing Li, Kaisheng Ma, Shuangchen Li, Meng-Fan Chang, Sampson John, Yuan Xie, et al. Heiner Lasi, Peter Fettke, Hans-Georg Kemper, Thomas Feld, and Michael Hoffmann. Industry 4.0. Business & information systems engineering , 6(4):239‚Äì242, 2014.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "In  2005 IEEE interna- tional conference on systems, man and cybernetics , volume 3, pages 2340‚Äì2345. Ieee, 2005. [62]  Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Brad- bury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "2.3.2 Ensembling Overhead \nWhile ensembling can boost accuracy with low latency, their distinctive resource hungry nature drastically increases the deployment costs when compared to single models. This is because more VMs or containers have to be procured to match the resource demands. However, note that the ‚ÄúPacking factor‚Äù ( P f  ) for each model also impacts the deployment costs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows. We modify the column multiplexers to enable variable active columns and turn off the ADCs of inactive channels. Lastly, we apply coarse-grain power gating to conÔ¨Ågure the number of duplicated ReRAMs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Calculate the gradients of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the reconstruction error of the feature maps: \np i  = Œ≥  RE i max( RE ) +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Inference with Feature Map Reconstruction Error Dropout and QuantaTask Optimization: Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 338,
    "augmented": true
  },
  {
    "text": "2020. [70]  Tiago Zonta, Cristiano Andr√© da Costa, Rodrigo da Rosa Righi, Miro- mar Jose de Lima, Eduardo Silveira da Trindade, and Guann Pyng Li. Predictive maintenance in the Industry 4.0: A systematic litera- ture review.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "0 \n5 \n10 \n0 \n0.5 \n1 \n1.5 \nutil_aware exascale mixed paragon \nSLO Violations \nNormalized Cost \nCost SLO violations \n(b)  Workload-1: WITS Trace. Figure 8. 0 \n1 \n2 \n3 \n4 \n0 \n0.5 \n1 \n1.5 \nutil_aware exascale mixed paragon \nSLO Violations \nNormalized Cost \nCost SLO violations \n(a)  Workload-1: Berkeley Trace.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Demix layers: Disentangling domains for modular language modeling. arXiv preprint arXiv:2108.05036 , 2021. [60] Suchin Gururangan, Margaret Li, Mike Lewis, Weijia Shi, Tim Althoff, Noah A Smith, and Luke Zettlemoyer.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "We propose a novel framework to perform intelligent edge- cloud partitioning for a distributed sensor network running random forest-based analytics. We propose novel inference \nstrategies to maximize the number of predictions performed at the edge, while consulting the cloud only when the local results are not satisfactory. We also provide novel learning strategies, especially when the distributed sensors do not want to share the local data with the cloud, saving crucial communication latency and energy.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Apple intelligence. \" [16] Apple. https : / / machinelearning .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 21,
    "augmented": true
  },
  {
    "text": "While the works relying on loop-decomposition or task partition (e.g., see (Qiu et al., 2020; Gobieski et al., 2019) and the references therein) ensure ‚Äúforward progress‚Äù, they do not guarantee an inference completion while meeting SLOs. Optimizing DNNs for the energy constraints (Yang et al., 2018, 2017), or performing early exit and depth-first slicing (Lv & Xu, 2022; Islam & Nirjon, 2019) does ensure more forward progress, but such approaches compromise accuracy while often imposing scheduling overheads and higher memory footprint. One major issue is, most of the works leverage ‚Äúpre-existing‚Äù DNNs, which are typically designed for running on a stable resource environment, while being deployed on an intermittent environment with pseudo notion of stability via check-pointing, and therefore, one direction of works (Mendis et al., 2021) looks for performing network architecture search for intermittent devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 228,
    "augmented": false
  },
  {
    "text": "In addition, the plug-and-play nature of chiplet provides better ‚Äúfault isolation‚Äù, as only the faulty chiplet can be changed as opposed to throwing away an entire chip. Since fault-tolerance has become a major concern for long-running training jobs [39,75,200], our proposed chiplet-based design should be able to handle hardware and software faults in a gracefully-degraded manner. In this project, we will investigate the fault-tolerance behavior of the chiplet architecture by injecting different types of faults.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Our profiling on the edge GPU prototype [ 36 ] shows that Kimera-VIO takes, on av- erage, 13 . 75 ms  latency to execute, which is less than 1% of the total hologram processing time. Therefore, the overhead introduced due to the additional pose estimation step is negligible compared to the baseline latency, thereby opening up opportunities for significant energy savings and performance speedup as demonstrated later in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Clearly, the current solution is  not  sustainable, neither in terms of the load on the power grid, nor in terms of the  CO 2  footprint (1.1 √ó 10 9 lbs); reducing the power budget for continuous learning is essential, as the carbon footprint of DNN training has emerged as a prominent concern [ 21 ], [ 57 ], [ 67 ], [ 89 ], demanding careful consideration as a primary design metric. In fact, it will take  ‚â• 3Million cameras (assuming  ‚âà 9 cameras/1000 people, similar to LA, and scaled to US population) to just enable autonomous urban mobility in the USA, which may consume 360 MW  power (1296 GWh  energy, 0.03% of US power) for video analytics alone. Scaling this to crowded cities with 30- 50+kilo-cameras like Beverly Hills ( >  35 k  [ 11 ]), Los Angeles ( ‚âà 35 k  [ 92 ]), New York ( ‚âà 56k [ 92 ]), or Chicago ( ‚âà 30k) will need a lot of power.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 238,
    "augmented": true
  },
  {
    "text": "(c) Intra-Holo scenario. Figure 5: Three opportunities for reducing hologram computation in an AR application. (a) HoloAR overview.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Netadapt: Platform-aware neural network adaptation for mobile applications. In Proceedings of the European conference on computer vision (ECCV) , pp. Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, and Hartwig Adam.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Additionally, our custom chiplet hardware will be simulated using the publicly-available RapidChiplet [68] simulator. Since the simulation of generative AI (especially training monolithic LLMs) can take extremely long running times and may not even be feasible in some cases, we will also build, as the third component of our evaluation framework, using data from our actual machine experiments and simulations, ‚Äúanalytical models‚Äù that provide fast evaluation of EoE systems and LLMs with reasonable accuracy, such as [40, 169]. Our approach will em- body the best of both the worlds ‚Äì taking the deeper system level insights from real hardware/simulators and extending it to large scale by analytically modeling their behavior as a complex system.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 166,
    "augmented": false
  },
  {
    "text": "Figure 13:  Sensitivity analysis of model selection with respect to sampling interval. The average number of models is in primary axis and cumulative accuracy in secondary axis. 10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n79.0 \n79.2 \n79.4 \nAccuracy \n(c)  Queries under Constraint-3.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "This calls for a dynamic model selection policy which can accurately de- termine the number of models required, contingent upon the accuracy and scalability of the model selection policy. Since the model participation for ensembling can vary based on the class of input images being classiÔ¨Åed, there is a scope to develop a dy- namic model selection policy that can leverage this class-wise variability to intelligently determine the number of models required for a given input. Key Takeaway:  Full ensemble model-selection is an overkill, while static-ensemble leads to accuracy loss.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "VI. E XPERIMENTS \nTo evaluate ResiRCA, we have extended the Gem5 [ 37 ] simulator with RCA modeling. The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": ", 8(1), February 2024. [27] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Brad- bury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, San- jay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexan- der Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 422,
    "augmented": false
  },
  {
    "text": "This enables flexible, diverse ways of expert adaptation and localized training to keep pace with rapidly changing knowledge and user needs, while also facilitating cross-layer optimization for system and architecture design. Systems for LLMs:  Since training giant monolithic models entail huge compute infrastructure, prior works have explored developing parallelization techniques like model parallelism [90, 149], data paral- lelism [118,128], and hybrid parallelism [135]. Distributed training frameworks like Horovod [141], Mega- tronLM [149], and DeepSpeed [65] ensure optimized data communication for distributed memory usage along with dynamic batching so that scaling overheads are minimized and resources are maximally uti- lized.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "Prebaking Functions to Warm the Serverless Cold Start. 2020. In  Proceedings of the 21st International Middleware Conference .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "Therefore, we adapt a ‚Äústudent-teacher paradigm‚Äù [ 46 ], where a more \nClassify \nLow Conf \nFrame? Discard \nFrame No \nExemplar Yes \nYes \nEdge Model \nConfidence Matrix \nMajority Voting Labeling \nM1 \nM2 \nM3 \nFig. 2: Auto-labeling in  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "As a result, ‚Äúon-premise‚Äù edge servers  [ 7 ], [ 8 ] have become prime choices for local inference and prediction [ 6 ], [ 39 ], [ 85 ], [ 86 ], necessitating the handling of both learning and inference tasks to meet application needs, including privacy preservation, reduced data communication, and disaggregated computing. Finally, although recent studies have suggested co-locating training and inference [ 12 ] to tackle privacy concerns without signiÔ¨Åcantly affecting the inference service, the power demand associated with equipping multiple commercial edge servers [ 7 ], [ 8 ] for both tasks hinders sustainable scaling. The Problem Space:  To address the multi-faceted challenges of sustainable, scalable and privacy-preserving continuous learning at edge servers, several crucial problem spaces must be explored.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "Observe that the selected points (in  red ) are approximating the original distribution. 5 \nr2 \nr1 \nr4 \nr3 \nr5 \nOriginal Data Coreset with imp-sampling Coreset with Clustering \nFigure 4: A toy example of the coreset construction techniques in  Seeker . Figure 4 shows a toy example of importance sampling in a 2D data set.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "[77]  R. Shumaker and L. Stephanie,  Virtual, Augmented and Mixed Reality: Designing and Developing Augmented and Virtual Environments: 6th International Conference, VAMR 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014, Proceedings, Part I . Springer, 2014. [78]  J.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "arXiv , arXiv:2410.03703, 2024. Available at:  https://doi.org/10.48550/arXiv.2410.03703 . Human creativity in the age of llms: Randomized experiments on divergent and convergent thinking.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "real-time refresh requirement of vision applications is yet to close and prevents the deployment of NN-PCC on edge devices. Moreover, NN-PCC mainly focuses on compressing the geometry data and hence is not very useful for the PC with attributes [ 88 ]. To the best of our knowledge, most of these works focusing on PCC with attributes target the compression ratio, and overlook the latency or energy consumption.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Dynamic adjustment of computational tasks based on both energy and task criticality. These innovations enable efficient and reliable DNN inference under intermittent power conditions, differentiating our work from existing energy-aware schedulers. Rationale Behind Method Design:  The overall method design of NExUME is motivated by the need to enable DNNs to function reliably in environments with intermittent and unpredictable energy supply.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "994‚Äì1007, July 2012. [41]  R. Wang and Z. Xu, ‚ÄúA pedestrian and vehicle rapid identiÔ¨Åcation model based on convolutional neural network,‚Äù in  Proceedings of the 7th International Conference on Internet Multimedia Computing and Service , ICIMCS ‚Äô15, pp. 31, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "5c, the  football  is larger than the soccer ball , and is located much closer to the user. As one can observe from the  Intra- Holo  scenario shown in Fig. Hence, even though both of them are located inside the RoF (and, of course, inside the viewing window), intuitively, the  soccer ball hologram does not need as much information as the  football hologram to compute.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Autoscaling the instances equally for every model based on predicted load, would inherently lead to over-provisioned instances for under-used models. To address this concern, we design a weighted autoscaling policy which intelligently auto-scales instances for every pool based on the weights. As shown in Algorithm  2 , weights are determined by frequency in which a particular model is chosen for requests ( get_popularity ) with respect to other models in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "[34] I. Ilievski, T. Akhtar, J. Feng, and C. Shoemaker, ‚ÄúEfÔ¨Åcient hyperpa- \nrameter optimization for deep learning algorithms using deterministic rbf surrogates,‚Äù in  Proceedings of the AAAI Conference on ArtiÔ¨Åcial Intelligence , vol. 31, no. [33] IBM, ‚ÄúData labeling,‚Äù  https://www.ibm.com/cloud/learn/data-labeling , \n(Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "This is because the single model inference have up to 2x higher latency to achieve higher accuracy. In contrast, both Cocktail  and  Clipper  can reach the accuracy at lower latency due to ensembling, thus minimizing SLO violations to 1%. Consequently, this leads to 35% SLO violations for  InFaas  in the case of Strict workload.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "2020. Sequoia: Enabling quality-of-service in serverless com- puting. In  Proceedings of the 11th ACM Symposium on Cloud Computing .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "Moreover, the total overhead of this algorithm is only  0 . 5%  of the overall inference execution latency for a heavy model, as will be discussed later in detail in Sec. V. \nB. Region-Level Pruning As discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Towards Real-time Photorealistic 3D Holography with Deep Neural Networks. Nature  592 (2021). [55]  Tomoyoshi Shimobaba, Jiantong Weng, Takahiro Sakurai, Naohisa Okada, Takashi Nishitsuji, Naoki Takada, Atsushi Shiraki, Nobuyuki Masuda, and To- moyoshi Ito.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Task- 1.4: Algorithmic Choices Informed by System and Hardware Constraints. Task-1.3: Continual Adaptation of EoE through Morphable LLM Experts. Task-1.2: Constructing Morphology of Ensemble of Experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Our experimental results show 34% computation reduction and 17% energy savings, compared to the state-of-the-art [28]. In the future, we would also like to explore other opportunities to improve energy efÔ¨Åciency and tune the computation pipelines to cater more towards VR applications. We believe, given that the current VR devices are battery-backed, these kinds of energy savings and performance improvements will not only enable the users to experience longer videos, but also encourage both industry \nand academia to work further on improving the pipeline to make VR more pervasive and versatile.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Communicate elsewhere \n0-50 50-500 500-1k 1k-10k > 10k Harvested/available power in the sensor node (¬µW) \nCompute at the edge \nCOTS high-end wearables  (bat.) Seeker  (RF) \nAll compute at edge Partial compute at edge \nDesign space of  ‚ÄúSeeker‚Äù \n(b) Current state-of-the-art of EH-WSN. Bonito  (multiple) \nOrigin  (RF) ResiRCA  (RF/Piezo/Solar) Chinchilla  (RF) Ideal Solution  (Any) \nCOTS cheap wearables  (bat.)",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)  42, 4 (2012), 1131‚Äì1142. https://doi.org/10.1109/TSMCB.2012.2187441 [21]  Ron Begleiter, Ran El-Yaniv, and Golan Yona. 2004.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "A typical EH setup consists of 5 components, namely, energy capture (solar panel, thermocouple, etc), power conditioning, voltage regulation (buck or boost converter), energy storage (super capacitor) and compute unit (refer ¬ßAppendix B for details about each of them). In fact, advances in EH has lead to a staggering development in intermittently powered battery-free devices (Maeng & Lucia, 2018; Gobieski et al., 2019; Qiu et al., 2020; Saffari et al., 2021; Afzal et al., 2022). This has a significant economic (users, products and data generating dollar value) as well as environmental (battery and e-waste) impact (Mishra et al., 2024).",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 192,
    "augmented": true
  },
  {
    "text": "We also investigate how different thresholds/preferences shape the behavior of our approach in a sensitivity study in Sec. VI-C . VI-E .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "This effect is more obvious in the edge-peer structure since it will send the data to its nearest peer and check the prediction quality until it reaches the cloud. Figure 4b also shows how network structure amplifies the effect of changing threshold value. Therefore, it is important to choose a threshold that optimizes the trade off between efficiency and accuracy.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "In  CLOUD . [6] Aaron Harlap, Andrew Chung, Alexey Tumanov, Gregory R. Ganger, and Phillip B. Gibbons. Spock: Exploiting Server- less Functions for SLO and Cost Aware Resource Procurement in Public Cloud.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Dodge, T. Prewitt, R. Tachet des Combes, E. Odmark, R. Schwartz, \nE. Strubell, A. S. Luccioni, N. A. Smith, N. DeCario, and W. Buchanan, ‚ÄúMeasuring the carbon intensity of ai in cloud instances,‚Äù in  2022 ACM Conference on Fairness, Accountability, and Transparency , 2022, pp. [21] J. [20] D Maltoni, V Lomonaco, ‚ÄúContinuous learning in single-incremental- \ntask scenarios,‚Äù in  Neural Networks , 2019.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "[37] Nvidia. 2020. \"http://info.nvidia.com/rs/156-OFN-742/images/Jetson_AGX_ Xavier_New_Era_Autonomous_Machines.pdf\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Our experiments show that PCC is the most expensive computation in a PC processing pipeline that takes  ‚âà 4 seconds , especially when deployed in mobile/edge devices, and hence, is a major contributor to the performance, video quality, and transmission energy, for the entire PC pipeline. Considering the dense features, 3D geometry and the visual attributes captured in PC, especially for the media applications like telepresence and virtual visits, pre-processing [ 21 ], [ 44 ], [ 61 ], [ 84 ], compressing and storing [ 14 ], [ 16 ], [ 19 ], [ 47 ], [ 48 ], [ 74 ], post-processing and streaming [ 25 ], [ 40 ], [ 66 ], [ 76 ], [ 90 ] PC using a mobile device, while maintaining a reasonable quality of service (QoS), are fast becoming challenging tasks. SpeciÔ¨Åcally,  PC compression  ( PCC , or PC encoding ) consists of both geometry (e.g., x, y, z coordinates in the 3D space) and attribute (e.g., RGB colors) compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 254,
    "augmented": true
  },
  {
    "text": "(a) Depthmap hologram algorithm. 0 200 400 600 800 1000 1200 \n1 2 4 8 16 32 64 \nExec. Figure 3: Dataset study.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "He, H. L. Cao, and B. Zhu, ‚ÄúAdvectivenet: An eulerian- lagrangian Ô¨Çuidic reservoir for point cloud processing,‚Äù  arXiv preprint arXiv:2002.00118 , 2020. [25]  X. [26]  J. Hu, A. Shaikh, A. Bahremand, and R. LiKamWa, ‚ÄúCharac- terizing real-time dense point cloud capture and streaming on mobile devices,‚Äù in  Proceedings of the 3rd ACM Workshop on Hot Topics in Video Analytics and Intelligent Edges , 2021, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "There exists a constant  L >  0 such that for all  Œ∏, Œ∏ ‚Ä≤ , \n‚à•‚àá L ( Œ∏ )  ‚àí‚àá L ( Œ∏ ‚Ä≤ ) ‚à•‚â§ L ‚à• Œ∏  ‚àí Œ∏ ‚Ä≤ ‚à• . 2. L -smoothness of  ‚Ñì .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "V. P OWER - DYNAMIC  RCA  SCHEDULING \nGiven a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture. Challenge 2:  Software controlled dynamic RCA activation and scheduling The idea of loop tiling has been widely leveraged in RCA design to either increase system throughput by smoothing the pipelining or reduce memory accesses by improving data locality [ 34 ], [ 3 ]. In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM \naccelerated MACs.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "The coreset construction techniques need to be extremely lightweight while preserv- ing key features to justify the computation-communication trade-offs in energy and latency. 3 DESIGN SPACE EXPLORATION Since data communication in a sensor host ecosystem (Fig- ure 3) consumes substantial power, we rely on coresets as an efficient way to lossily communicate the features with minimal information degradation. To this end, we explore two different kinds of coreset construction techniques.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "[65]  Tiancheng Xu, Boyuan Tian, and Yuhao Zhu. 2019. Tigris: Architecture and Algorithms for 3D Perception in Point Clouds.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "As shown in Fig. 4a, the depthmap input is first sliced into several planes ( M  depth planes in this case). With these depth planes, the first step,  Forward Propagation  (de- noted  ‚ù∂ in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Nonvolatile processor architectures: Efficient, reliable progress with unstable power. IEEE Micro , 36(3):72‚Äì83, 2016. Kaisheng Ma, Xueqing Li, Jinyang Li, Yongpan Liu, Yuan Xie, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "\"https://www.ifixit.com/Teardown/Magic+Leap+One+Teardown/112245\". [21]  NATIONAL INSTRUMENTS. 2019.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "[36]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Nachiappan C.Nachiappan, Mahmut Taylan Kandemir, and Chita R. Das. Fifer: Tackling Resource Underutilization in the Serverless Era. USENIX Association.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Further,  Us. 62%) more accurate than the na¬®ƒ±ve learner. 03%, and minimum  ‚âà 2 .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "For latency-sensitive applications, offloading to peers may be more viable than offloading to the cloud. That is, if the model at the edge node is unavailable (because of resource constraints) or has produced a low-confidence result, instead of directing the prediction query to the cloud, the edge could direct it to the peers (or other deployments) on the same local network. Since, all the deployments are working on the same task, and have trained on similar data, we will be able to perform the analytics task within a reasonable accuracy bound.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "Rather than rely- ing on persistent, centralized updates or continuous feder- ated aggregation, we perform  periodic  or  equilibrium-driven fine-tuning rounds. These updates occur only when sensors have sufficient energy to participate meaningfully, guided by the game-theoretic equilibrium strategy. By integrating the game-theoretic approach with federated learning principles, we reduce communication overhead and ensure that contri- butions to model updates come from sensors best positioned to improve accuracy under energy constraints and uncertain availability.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "9 √ó  reduc- tion in communication data volume with 86 . 8% accuracy, surpassing the 81 . 2% accuracy of the state-of-the-art.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "Calculate the Shapley values  œï i  for each neuron based on their contribution to the network‚Äôs perfor- mance. Inference with Neuron Shapley Value Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. For each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) If  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \n21 \nUpdate the dropout mask  m  based on the Shapley values: \np i  = Œ¥ œï i  +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 313,
    "augmented": true
  },
  {
    "text": "Springer, 2005. Robust bayesian linear classiÔ¨Åer ensembles. In  European Conference on Machine Learning , pages 72‚Äì83.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "This represents a particularly challenging tension between energy availability and desired functionality, because the form factor constraints of the WSNs fundamentally limit active power, energy re- serves, compute and communication capabilities. For many WSNs, their participation in inference tasks has traditionally been limited to data collection and transmission, sometimes with modest preprocessing. While several studies have shown the benefits of performing more inference closer to the point of data collection [ 23 ,  30 ,  31 ,  40 ,  56 ] and have ap- plied these techniques to more powerful edge devices, their form-factor-imposed limited energy storage, low-power op- eration points, and deployment scenarios have been a major impediment in executing compute-intensive inference tasks directly on such platforms.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "500 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 5.4. We also present a sensitivity study on how en- ergy savings and performance vary with different approximation factors in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "8b and Fig. V1 has fewer objects and less movements, and thus, compared to V2, the savings on execution time and energy consumption for V1 are slightly higher, as shown in Fig. 8a.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Task-3.1: Expert/Hardware Co-Characterization To efficiently serve various application needs, the question we ask is  what are the intelligent ways to execute EoEs? As discussed in Thrust-1, our expert repository allows us to plug-and-play experts to create diverse EoEs, thereby many types of experts exist within and across EoEs. With the target of achieving an efficient execution, we first want to understand the execution behavior.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "K12 and Outreach : Our outreach plans include involvement of underrepresented groups in computer science and engineering and various K-12 related activities. A detailed description of our  BPC plan  is in- cluded as a supplementary document. One example is the Science-U camp at Penn State, which is designed to take K-12 students through a one-week journey that investigates an area of STEM in an exciting way.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Note that each func- tion triggers only one other function in the application at a time. ‚ÄòTotal fan-out‚Äô and ‚ÄòMax Depth‚Äô denotes the total number of outgoing branches and maximum distance between the start function and any other function in a DAG, respectively. Figure 1 depicts the DAGs of three such applications from the  ùê∑ùëíùëéùë°‚ÑéùëÜùë°ùëéùëü benchmark suite [ 29 ], and Table 2 summarizes the various workflows that can be triggered by an incoming request to them.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "How does the new tile get any kernel to work on? Over multiple iterations of such asynchronous scheduling, the kernel queue for each tile will be of different size creating a load imbalance; how to tackle this? 2.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "D. IntraFrame-InterEye (AE) Computation Optimization \nIn  EA , the compute can be bypassed by reusing the pre- computed results, if the head orientation matches with any of the two previously memoized head orientations (stored in reg- isters). However, we also note that these opportunities might be limited owing to the ‚Äúnon-repetitive‚Äù user behavior. De- spite this variation, there may still be matches/recomputations within a frame between two eyes, i.e., IntraFrame-InterEye as shown in  b  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Kiwan Maeng and Brandon Lucia. Adaptive dynamic checkpointing for safe efficient intermittent computing. In  13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18) , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Porting ai/ml models to intelligence processing units (ipus). Association for Computing Machinery. In  Practice and Experience in Advanced Research Computing 2023: Computing for the Common Good , PEARC ‚Äô23, page 231‚Äì236, New York, NY, USA, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Thus, any unilateral profitable deviation increases  Œ¶( a ( t )) . Boundedness and Impossibility of Infinite Improvement Sequences \nSince all utilities are bounded (due to finite  Œ≥, Œ¥, Œ∑,  bounded ‚àÜ A i ( t ) , and bounded energy resources), there exists a finite upper bound  Œ¶ max  such that: \nŒ¶( a ( t ))  ‚â§ Œ¶ max ‚àÄ a ( t ) . Suppose, for contradiction, that there exists an infinite se- quence of unilateral profitable deviations.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "Especially,  interactive volumetric video streaming  is starting to become mainstream, as edge devices (e.g., iPhones) facilitate recording and streaming the PC video which provide end-users with real-time 6-degrees of freedom (6-DoF) experiences. On the other hand, for applications such as autonomous driving [ 1 ], [ 4 ], robotics [ 79 ], motion planning [ 34 ] or path planning [ 42 ], attributes like RGB info, at most times, are not necessary as the PC is used in the compute pipeline (by the machine) to extract features and make decisions. Almost all of these applications can be categorized as interactive volumetric video streaming.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "However, the architectural insights on how to co-design a next-generation accelerator that can accommodate our proposed  HoloAR  framework are discussed later in Sec. 5.5. 5, in this paper, we evaluate the performance and energy benefits of  HoloAR  by using an embedded GPU prototype for the edge AR headsets [ 36 ], and leave the hardware-software co- design based on FPGA-based acceleration for future work.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "Lightweight ReRAM circuit design \npower ReRAM cells. Figure 5 shows the proposed peripheral circuit design for one ReRAM crossbar. This design is more concise even than the SINWP [ 6 ], because we target low power as the primary goal.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": ". , s N }  deployed to monitor a common scene. Each sensor observes the environment from a distinct van- tage point.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "In  Cock- tail , we leverage these transient VMs such as spot instances to drastically reduce the cost of deploying ensembling model framework. As an example, we host full-ensembling on AWS spot instances. Figure  3b  shows that ensemble-spot can re- duce the cost by up to 3.3 √ó  when compared to ensemble-OD.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "While the margins may appear small, in industrial settings, even minor improvements in classification accuracy can have significant implications for predictive maintenance and operational efficiency. For example, for the spindle idle (SI) class, NExUME attains an accuracy of 93.00%, outperforming DynBal by 0.70%. NExUME demonstrates superior performance across all operating classes, achieving the highest accuracy in each case.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "In stark contrast to VMs, serverless functions have been made available by cloud providers, which can spin-up within a few seconds [ 2 ]. Due to high start-up latencies, using VMs for hosting ML services can lead to over-provisioning, espe- cially during periods of poor workload predictability (flash crowds) [ 10 ]. As we will discuss in this paper, the cost of using VMs vs. serverless functions highly depends on the dynamically varying needs of the user query submission rates.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "2020. Objectron Dataset Annotation: book. \"https://github.com/ google-research-datasets/Objectron/blob/master/index/book_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Figure 7:  Latency Distribution of  InFaas ,  Clipper  and  Cocktail  for two workload mixes using both Wiki and Twitter traces. Latency (ms) \n(d)  Twitter-trace:  Relaxed  workload. Strict Relaxed 0 \n20 \n40 \n60 \n80 \nCost($) \nInFaas Clipper Clipper-X Cocktail \n(a)  Wiki Trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "PC compression is an essential component of PC processing (and a critical performance bottleneck), which affects video quality, user experience, and energy efÔ¨Åciency. C ONCLUDING  R EMARKS \nPC processing has become the trend for many video applications spanning scientiÔ¨Åc computing, education, health- care and entertainment, and is recently being ofÔ¨Çoaded to the edge. Unfortunately, prior works mainly focused on compression ratio, but did not consider the performance and energy implications, particularly for edge devices.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "They have also advised a couple of female undergraduate students. PI Das has worked with several high school students and teachers in summer for the completed NSF Expeditions project. In addition, he had co-organized a summer workshop for visually-impaired students as a part of their Expeditions project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "4: Main idea in our partial inference scheme. whether one frame should process the PI, and if so, reuse the cached computation results for ‚Äúunimportant‚Äù regions and only do computation for the ‚Äúregions of interest‚Äù (bounding boxes and MVs), to save computations without much accuracy loss. To explain the high-level idea behind PI, we reconsider Frame-3 in Scenario-1 discussed in Sec.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "based coresets can achieve an accuracy of  ‚âà 85%. Figure 7: Recovering data from the coresets. Finetune \n(b) Recovering a sub-sampling with GAN.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pp. Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, Vijaykrishnan Narayanan, and Chita R Das. Usas: A sustainable continuous-learning¬¥ framework for edge servers.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "To address these challenges, this paper proposes and experi- mentally evaluates  ResiRCA , a resilient ReRAM crossbar-based CNN accelerator. Supported by a reconÔ¨Ågurable lightweight \nhardware design, ResiRCA is able to activate scalable com- putations via a multi-dimension tuning strategy. ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "This process, while informative, yields only approximate models that are inherently prone to errors. Additionally, profiling devices to ascertain their energy consumption, computational capabilities, and memory footprint necessitates detailed micro- profiling using embedded programming. DynFit, with its stochastic dropout features, occasionally leads to overfitting, necessitating meticulous fine-tuning.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "The inference process is represented as a set of tasks  T  =  { T 1 , T 2 , . . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "when some of the tiles are half way through the compute, some other tiles can just start execution). Facilitating such schedul- ing will provide us less idle time, more forward progress and more efÔ¨Åcient use of the incoming power but at the expense of more control overheads. We call this  Eager Scheduling .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Although the spike-based scheme [ 5 ] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input/output data. It is known that the energy harvesting system often suffers from power failures and works in an intermittent mode; so, the spike-based data injection scheme is not favorable. ‚Ä¢  For the ReRAM circuit concerned works [ 6 ], [ 8 ], although they are lightweight, they  cannot  be dynamically reconÔ¨Ågured to adapt changing power levels.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "There are diverse applications that are typically developed, trained and hosted as web services. These services allow end-users to submit queries via web server interface. Since these inference requests are often user-facing, it is imperative to administer them under a strict service level ob- jective (SLO).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "[121] Julius Odede and Ingo Frommholz. Jaybot‚Äìaiding university students and admission with an llm- based chatbot. In  Proceedings of the 2024 Conference on Human Information Interaction and Retrieval , pages 391‚Äì395, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Octree Construction:  With the input geometry data, the octree construction algorithm is invoked to add the points and update the tree (e.g., the maximum depth required for inclusion of a point, occupancy information for nodes, etc.) SpeciÔ¨Åcally, the SOTA geometry compression pipeline includes Ô¨Åve stages which can be summarized as follows: ‚Ä¢  Raw Frame (Input):  The input raw PC frame contains several (usually millions of) points, carrying both geometry and attribute information. Only the geometry data are forwarded to the upper geometry compression pipeline.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Figure 9: Real System: Breakdown of Average End-to-End Response Times in terms of queueing delay, cold start delay and execution time. 99.40% \n99.55% \n99.70% \n99.85% \n100.00% \n0 \n300 \n600 \n900 \n1200 \nArch Fifer Dprob Kraken Sprob Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(a) Social Network. 99.00% \n99.25% \n99.50% \n99.75% \n100.00% \n0 \n300 \n600 \n900 \n1200 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "The model‚Äôs performance is measured by a loss function  ‚Ñì :  Y √ó Y ‚Üí R ‚â• 0  that is convex in  Œ∏  for any fixed input-label pair  ( x, y ) . The model operates in an energy-harvesting wireless sensor network (EH-WSN) envi- ronment where sensors participate strategically in inference tasks based on a game-theoretic equilibrium. Let  D  denote the effective data distribution induced by the equilibrium strategies of the sensors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "[7] Muhammad Adnan, Akhil Arunkumar, Gaurav Jain, Prashant Nair, Ilya Soloveychik, and Pu- rushotham Kamath. Springer, 2020. Keyformer: Kv cache reduction through key tokens selection for efficient gener- ative inference.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "The throughput can be expressed as follows: \nThr pipe ave   = P Lk = LC Lk =1 ( m  √ó  n ) Lk  √ó  aG Lk \nLat pipe (8) \n2) Activation strategy formulation :  The activation strategy for the sequential mode can be described as shown below. In order to formulate the problem in a concise way, the tiling factors,  m  and  n , are constrained to be divisors of the ReRAM weight matrix M √ó  N using the annotations of  m  |  M ;  n  |  N . Objective:  Maximize  Thr sequ ave Subjected to:  for each layer Lk, P   load Lk   , P  store Lk , P   comp Lk , P   trans Lk , P   merge Lk < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ‚ü® m Lk , n Lk , aG Lk ‚ü© for each layer Lk \nSimilarly, the activation strategy under the pipeline execution mode can be described as below.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 270,
    "augmented": false
  },
  {
    "text": "However, there has been a significant push towards enabling more complex workloads, including query processing on CSDs. Efforts to adapt CSDs for machine learning applications, albeit limited in scope to classical learning and data management, mark a crucial step forward. Yet, the expansion of these technologies to encompass large-scale storage stacks and the integration of CSDs into conventional storage systems, particularly for ML applications, remains a significant challenge and an open area of research.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "25 and  RD upper bound  = 10  in Algo. 1;  T moving 2  = 0 . 3  in Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "8: Algorithmic performance of  Us. Component Spec Power Area(mm 2 ) SRAM Buffers 1kB*256+8kB*256+64kB+16*256kB 10.372W 117.164 MAC Unit (8*8)*256 8.46W 32.72 Adder Tree and Comparator 16*16bit + 256 2.4W 21.556 Control ‚Äì 0.96W 12.2 Host ‚àº Cortex A78 series 11W ‚Äì Design at 592MHz with Synopsys AED 32nm library Total 256 tiles 33.192W 183.64 \nTABLE I: Area and power estimation of our design. ¬¥as : the beniÔ¨Åts of the exemplar selection and  Œº -proÔ¨Åler.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "Intelligent virtual assistants with llm-based process automation, 2023. [57] Nikhil Gupta and Jason Yip. [56] Yanchu Guan, Dong Wang, Zhixuan Chu, Shiyu Wang, Feiyue Ni, Ruihua Song, Longfei Li, Jinjie Gu, and Chenyi Zhuang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Alessandro Montanari, Manuja Sharma, Dainius Jenkus, Mohammed Alloulah, Lorena Qendro, and Fahim Kawsar. eperceptive: energy reactive embedded intelligence for batteryless sensors. IEEE, 2024.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the ACM Symposium on Cloud Computing , pages 789‚Äì800. ACM, 2020. [162] Zhuang Wang, Zhen Jia, Shuai Zheng, Zhen Zhang, Xinwei Fu, T. S. Eugene Ng, and Yida Wang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Applied machine learning at facebook: A datacenter infrastructure perspective. In  2018 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 620‚Äì629, Feb 2018. Law, K. Lee, J. Lu, P. Noordhuis, M. Smelyanskiy, L. Xiong, and X. Wang.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Based on  E b , we adjust the dropout rate  d i  for each layer  i  according to: \nd i  =  d max \n\u0012 1  ‚àí E b \nE max \n\u0013 , (1) \nwhere  d max  is the maximum allowable dropout rate, and  E max  is the maximum energy observed in the traces. Similarly, the quantization levels  q j  are adjusted: \nq j  =  q min  + ( q max  ‚àí q min )   E b \nE max . (2) \nThis ensures that when energy is low, higher dropout rates and lower quantization bit-widths are used to reduce computational load, and vice versa.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "Additionally, the  nuScenes  data-set (Caesar et al., 2020) by Aptiv, with its comprehensive sensor data and annotations covering diverse driving scenes, is instrumental in evaluating  Salient Store  ‚Äôs efficiency in multi-modal data processing typical in urban mobility scenarios. Beyond the vision- based data, we also incorporated the  Chime Audio  data-set (Foster et al., 2015) into our evaluation. This data-set, consisting of audio recordings, offers a different modality to test the versatility of Salient Store  in handling various types of continuous learning data beyond visual inputs.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "‚Ä¢  PTU  (HW):  A recent optimized solution [28] utilizes a more energy-efÔ¨Åcient hardware accelerator, i.e., Projec- tive Transformation Unit ( PTU ), to process the compute- intensive projection operations. This GPU is commonly used in contemporary VR devices (Oculus [39], Magic Leap [16], and GameFace [47], etc.). Note that, with this setup, the projection computation is triggered for each frame, and also per projection computation invocation includes computation of two projection matrices for the two eyes.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Initialize the loop iteration parameters  l . Calculate the Shapley values  œï i  for each neuron based on their contribution to the network‚Äôs perfor- mance. Compute the activations  a  and apply the dropout mask: \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "7, when processing the six videos listed in Tab. 5.1. 2, with the first four config- urations described earlier in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Ensuring adherence to Service Level Agreements (SLAs), where in- ference typically utilizes a lower-resource model [ 51 ], [ 75 ] and labeling is performed using a larger teacher model [ 44 ], \n891 \n2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) \n2378-203X/24/$31.00 ¬©2024 IEEE DOI 10.1109/HPCA57654.2024.00073 \n2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) | 979-8-3503-9313-2/24/$31.00 ¬©2024 IEEE | DOI: 10.1109/HPCA57654.2024.00073 \nAuthorized licensed use limited to: Penn State University. While recent works [ 12 ], [ 46 ] have attempted to tackle this concern through student-teacher paradigms, efÔ¨Åciently deploying such approaches in complex data modalities (e.g., multi-class video, 3D point cloud) remains a formidable challenge.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 249,
    "augmented": true
  },
  {
    "text": "[62]  Lingjie Wei and Yuji Sakamoto. 2019. Fast Calculation Method with Foveated Rendering for Computer-generated Holograms Using an Angle-changeable Ray- tracing Method.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Algorithm 1  Proactive Scaling with weight estimation \n1:  for  Every Monitor_Interval= PW  do 2: Proactive_Weighted_Scaler ( ‚àÄ ùëìùë¢ùëõùëêùë°ùëñùëúùëõùë† ) 3:  procedure  Proactive_Weighted_Scaler( func ) 4: cl  ‚Üê ùê∂ùë¢ùëüùëüùëíùëõùë° _ ùêøùëúùëéùëë ( ùëìùë¢ùëõùëê ) 5: ùëùùëô ùë° + ùëÉùëä ‚Üê Load_Predictor ( ùëêùëô, ùëùùëô ùë° )  a 6: batches  ‚Üê l p ùëôùë° + ùëÉùëä f ùë¢ùëõùëê.ùëèùëéùë°ùëê‚Ñé _ ùë†ùëñùëßùëí m \nb 7: total_con  ‚Üê Estimate_Containers ( ùëèùëéùë°ùëê‚Ñéùëíùë†, ùëìùë¢ùëõùëê ) 8: reqd_con  ‚Üê ùëöùëéùë• ( ùëöùëñùëõ _ ùëêùëúùëõ,ùë°ùëúùë°ùëéùëô _ ùëêùëúùëõ ) 9: Scale_Containers ( ùëìùë¢ùëõùëê,ùëüùëíùëûùëë _ ùëêùëúùëõ ) 10:  procedure  estimate_containers( load, func ) ‚ä≤ Output:  ùëüùëíùëûùëë _ ùëêùëúùëõ 11: func.prob  ‚Üê Compute_Prob (func) 12: reqd_con  ‚Üê‚åà ùëôùëúùëéùëë ‚àó ùëìùë¢ùëõùëê.ùëùùëüùëúùëè ‚åâ 13: extra  ‚Üê‚åà( Comm ( ùëìùë¢ùëõùëê ) +  Conn ( ùëìùë¢ùëõùëê )) ‚àó ùëüùëíùëûùëë _ ùëêùëúùëõ ‚åâ 14: reqd_con  ‚Üê reqd_con + extra \nKraken  makes use of a Load Predictor  2b  (Algorithm 1  a ) which uses the EWMA model to predict the incoming load at the end of a fixed time window,  ùëÉùëä . This time window is chosen according to the time taken to scale all functions in the respective application. Note that  ùë° in the algorithm refers to the current time.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 407,
    "augmented": true
  },
  {
    "text": "2019. DeepFovea: Neural Reconstruction for Foveated Rendering and Video Compression using Learned Statistics of Natural Videos. ACM Trans.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "7%  of the entire FoV frame. How to capture the pattern and utilize the pattern? Due to this inherent nature of compute, the pattern between left eye and right eye can be easily  captured  by proÔ¨Åling the distance vector for only the Ô¨Årst row on the screens:  Œî = \u0002 ‚Éóx 0 r   ‚àí ‚Éóx 0 l   , ‚Éóy 0 r   ‚àí ‚Éóy 0 l \u0003 , as shown in line number  2  in Algorithm 1.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Iris recognition performance enhancement using weighted majority voting. In  2008 15th IEEE International Conference on Image Processing , pages 277‚Äì280. [88]  Sheikh Ziauddin and Matthew N Dailey.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "315‚Äì327. ResiRCA: A Resilient Energy Harvesting ReRAM Crossbar-Based Accelerator for Intelligent Embedded Processors. In  2020 HPCA .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "If those get full because of continuous power failures, the control directs the data to the global NVSBS (NVSB-NW and NVSB-SE in Fig. 5a ). The NVSB stores the global/asynchronous work queue and the shufÔ¨Çing conÔ¨Åguration (mini-batch arrangement).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "As the coreset for- mation algorithms are fairly simple [ 7 ,  8 ,  36 ,  37 ], it does not take much latency or energy to convert the raw sensor data into the coreset form even while using a commercial-off- the-shelf micro-controller (like TI MSP430FR5969 [ 66 ]). This further motivates us to look for opportunities in the data distribution to improve the compression ratio. As the DNN models were designed to infer on the full data, we retrain the DNN models to recognize the compressed rep- resentation of the data and infer directly from that (both from the importance sampling and clustering).",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "After sensing, the input samples are then buffered in the video buffer, waiting to be processed timely at the frame-rate. Processing Engines:  To efficiently handle the above two types of inputs, various computational resources have been integrated into AR SoCs, as shown in Fig. 1b, e.g., CPUs for generic processing, GPUs for graphics computing, vision processing units (VPUs) for rendering, and tensor processing units (TPUs) for learning infer- ences.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Typically denser models are designed with more parameters (ex. Table  1  shows the different models available for image predic- tion, that are pretrained on Keras using  ImageNet  [ 29 ] dataset. Each model has unique accuracy and latencies depending on the model architecture.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "We have advised several Penn State honors students (including women and minorities) through our prior NSF projects. We will also target students from the Integrated Undergraduate/Graduate (IUG) program at Penn State (which allows students to earn both a bachelor‚Äôs and master‚Äôs degree in five years), to get involved in Generative AI research for possible graduate studies. Industry Collaboration: We have several ongoing collaborations with industries like NVIDIA, AMD, Google and Meta, who are major players in advancing deep learning technology/systems.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "[73] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L√©lio Re- nard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Tim- oth√©e Lacroix, and William El Sayed. Mistral 7b, 2023. [74] Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bam- ford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 199,
    "augmented": false
  },
  {
    "text": "525‚Äì561. [80]  TheAILearner Blogger, ‚ÄúImage Processing ‚Äì Nearest Neigh- bour Interpolation,‚Äù  ‚Äùhttps://bit.ly/3l4iY95‚Äù , 2018. [81]  TopoDOT Blogger, ‚ÄúUsing Point Clouds for Augmented and Virtual Reality,‚Äù  ‚Äùhttps://bit.ly/3OFdA97‚Äù , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "In this paper, we focus on improving the accuracy and latency from the model selection perspective and consider instances types from a cost perspective. A majority of the model serving systems [ 6 , 83 , 86 ] in public cloud support individual model selection from available models. For instance, InFaas [ 83 ] can choose variants among a same model to maintain accu- racy and latency requirements.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "), we utilize the octree-based method to compress the geometry data losslessly, while the attributes are compressed by the predictive RAHT lossily. ‚Ä¢  CWIPC  [ 13 ], [ 48 ]: CWIPC is a PCC library that supports the inter-frame compression (encoding the predicted frame via macro block (MB)-based motion estimation). We use this tool to compress every single PC frame, and measure the encoding latency, energy consumption, the compressed stream size, and Ô¨Ånally measure the quality (PSNR) of the decoded frame by  pc error d  tool [ 85 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "Initialize the loop iteration parameters  l . Compute the activations  a  and apply the dropout mask: \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y )  where  Y  is the output of the network and   ÀÜ Y  is the target output. Calculate the gradients of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the reconstruction error of the feature maps: \np i  = Œ≥  RE i max( RE ) +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 358,
    "augmented": true
  },
  {
    "text": "Next,  HoloAR employs the  Inter-Holo  scheme (denoted  b  ), to take advantage of the region of focus from analyzing the current eye tracking inputs and sparsely compute the objects outside the RoF. First,  HoloAR  utilizes the exist- ing viewing-window based technique [52] (denoted \na  ) to skip the hologram computations for the objects which are outside of the current viewing window, in a ‚Äújust-in-time‚Äù fashion. Finally,  HoloAR \n499 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece \n(a) Viewing-Window scenario [52].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "1038‚Äì1043, 2014. [45]  K. Ma, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúDynamic machine learning based matching of nonvolatile processor microarchi- tecture to harvested energy proÔ¨Åle,‚Äù in  2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD) , pp. 670‚Äì675, 2015.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "We demonstrate this by testing the exemplar selection and the Œº ‚àí proÔ¨Åler with different modalities of data. Our workloads included Audio [ 23 ], [ 35 ](speech classiÔ¨Åcation), 3D Point Clouds [ 14 ], [ 24 ](object classiÔ¨Åcation) and Inertial Measure- ment Unit sensor data [ 9 ], [ 106 ](fault and activity detection). Observe that, as  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "When skipping, we can simply bypass the inference task by reusing  the inference result from the last frame; otherwise (i.e., if cannot skip), the full inference has to be performed for the current frame, in the same fashion as in the baseline. FI+SI+PI:  Different from the above FI+SI scheme, in this scheme, the region level decision-making Algo. 2 is invoked to decide among the execution choices for the incoming frames ‚Äì including Skipping, Full-Inference, and Partial-Inference.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "IEEE, 2012. Salonik Resch, S Karen Khatamifard, Zamshed I Chowdhury, Masoud Zabihi, Zhengyang Zhao, Husrev Cilasun, Jian-Ping Wang, Sachin S Sapatnekar, and Ulya R Karpuzcu. Mouse: Inference in non-volatile memory for energy harvesting applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "91‚Äì98. Springer, 2014. S√∂ren Becker, Johanna Vielhaben, Marcel Ackermann, Klaus-Robert M√ºller, Sebastian Lapuschkin, and Wojciech Samek.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , 41(11):4229‚Äì4240, 2022. Chih-Hsuan Yen, Hashan Roshantha Mendis, Tei-Wei Kuo, and Pi-Cheng Hsiu. Keep in balance: Runtime-reconfigurable intermittent deep inference.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "At any instance, a user is only concerned about the FoV pixels in the entire  360 ¬∞ frame. So, instead of evaluating the mapping for all coordinates in the  360 ¬∞ frame, we only generate the mapping for those pixels which are within the user‚Äôs view. As the target  2 D  FoV coordinates are already known (VR screen dimensions), these mappings can be performed by multiplying the inverse of the transformation matrix ( T   ‚àí 1 ) with the  2 D  FoV coordinates ( V 2 D ), thus generating the corresponding  360 ¬∞ pixel coordinates ( P ), as shown in Equation 2.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "Exploration Algorithm \nAlgorithm  3  outlines a systematic approach to exploring suit- able hyperparameter values. It combines theoretical bounds with empirical evaluation, guiding the search toward stable and efficient equilibria. The above guidelines and the explo- ration algorithm provide a structured approach to selecting and refining  Œ≥, Œ¥,  and  Œ∑ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Formal Bounds and Conditions \nTo ensure balanced behavior, it is helpful to relate  Œ≥, Œ¥,  and Œ∑  to typical values of accuracy improvement and energy costs. Accuracy Gains and Costs: Let  ‚àÜ A min  and  ‚àÜ A max  de- note the minimum and maximum expected accuracy im- provements from any sensor‚Äôs participation. Let  e max total   = e max cap   + e inf   + e comm   represent the maximum energy cost (for a chosen SNR mode).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Additionally, we implement a partial inference scheme to enable region/tile-level reuse. SpeciÔ¨Åcally, considering the similarities between successive video frames, we propose a frame-level compute reuse algorithm based on the motion vectors of each frame. With frame-level reuse, we are able to skip  53%  of frames in inference with negli- gible overhead and remain within less than  1%  mAP (accuracy) drop for the object detection task.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "For instance, from \n154 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nFeatures \nArchipelago [44] \nPower-chief [51] \nFifer [32] \nXanadu [27] \nGrandSLAm [34] \nSequoia [46] \nHybrid Histogram [42] \nCirrus [25] \nKraken \nSLO Guarantees ‚úì ‚úó ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì Dynamic DAG Applications ‚úó ‚úó ‚úó ‚úì ‚úó ‚úó ‚úó ‚úó ‚úì Slack-aware batching ‚úó ‚úó ‚úì ‚úó ‚úì ‚úó ‚úó ‚úó ‚úì Cold Start Spillover Prevention ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úì Function Weight Apportioning ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úì Energy Efficieny ‚úó ‚úì ‚úì ‚úì ‚úó ‚úó ‚úì ‚úì ‚úì Request Arrival Prediction ‚úì ‚úó ‚úì ‚úì ‚úì ‚úó ‚úì ‚úó ‚úì Satisfactory Tail Latency ‚úì ‚úó ‚úì ‚úó ‚úì ‚úì ‚úì ‚úì ‚úì \nTable 1: Comparing the features of  Kraken  with other state-of-the- art resource management frameworks. Figure 1 shows the DAGs for three Dynamic Function Chains. Social Net- work  (Figure 1a), for example, is one such chain that has 11 functions in total, with each subset of functions contribut- ing to multiple paths (7 paths in total).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 377,
    "augmented": true
  },
  {
    "text": "We also spawn con- tainers much more in advance than the predicted arrival time and also keep them alive for at least a minute before evicting them from memory, to account for arrival unpredictability. Other \n3 These results are not shown in any graph. It is seen that  Kraken  meets the SLOs for all requests from the lightly-loaded trace over 18 hours while averaging 0.85 memory-resident containers at any given second 3 .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "The trained models can then be used to perform inferences, i.e., the clas- sification task. Since typical large scale DNNs have millions of parameters and perform billions of multiplications and accumulations for executing a single inference, they are typ- ically hosted as web-services, which are often queried for predictions. Conventionally, training is much more compute intensive (compared to an inference), takes many iterations and hence has been given considerable attention for better accuracy and convergence time.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "After the initial meetings with the PhD students, the students will be asked to complete a worksheet to ensure alignment on objectives. Regular annual review meetings will be conducted to assess progress and make necessary adjustments. Career Counseling/Advising \nThe PIs will provide ‚Äì on a regular basis ‚Äì career counseling and advising to the PhD students in the project as part of the mentorship.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "This can also explain why the portions with the power source of  Thermal  are very small. However, for both  Piezo  and  Thermal , the portions for  PV  are very small. The underlying reason is that the smooth  Transition keep   strategy can already handle the smooth transitions with no need of power prediction support for this workload.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Assuming each request to a function within the appli- cation spawns one container for that function, the number of containers to be provisioned in advance for functions at depth  ùëë is given by: \nùëÅùê∂ ùëë ùë° =  ‚åà PL  ùë° ¬∑ ( ùëá ùëë ¬∑  ùëÉ 0 )‚åâ \nHere,  ùëÅùê∂ ùëë ùë° is a column vector of ùëõ elements, each correspond- ing to the number of elements required to be provisioned for functions at a depth,  ùëë , from the start function. Provisioning these containers at a fixed time window in advance from  ùë° prevents cold starts from affecting the end-user experience. For example, if  ùëÉùêø ùë° is estimated to be 25 requests, then from Figure 5, we obtain the number of containers needed for functions at depth,  ùëë =  1, by multiplying 25 with  ùëÉ 1  (which is  ùëá 1 ¬∑ P 0 ).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 206,
    "augmented": false
  },
  {
    "text": "reside in the mas- ter node. It runs on a  C5.16x  [ 8 ] large instance to handle these large volume of diverse tasks. Each worker VMs runs a client process to serve its corresponding model.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Alexa. \" https://developer.amazon.com/en-US/alexa/alexa-ai \", 2024. [13] AMD.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "Green Data Centers:  As sustainability gains traction, industry has worked towards building green data centers [ 58 ], [ 59 ]. Although using these data centers for computation can be an alternative, it will not solve the bandwidth and the privacy issues mentioned in ¬ß I . Moreover, communicating and storing such high volume data will also require energy.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Moreover, as stated in the proposal, we will collaborate with Argonne National Lab specifically for the experimental evaluation thrust of the project. The existing industrial partnerships of the PIs (e.g., with Intel, AMD, NVIDIA, Microsoft, and Amazon) will be leveraged to provide opportunities for student internships and placements. The PIs will meet with the PhD students as frequently as needed.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Deep- Holo: Recognizing 3D Objects Using a Binary-Weighted Computer-Generated Hologram. In  SIGGRAPH Asia 2017 Posters . [34]  NASA.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "[84] Dominik Kreuzberger, Niklas K√ºhl, and Sebastian Hirschl. Memory-efficient nllb-200: Language-specific expert pruning of a massively multilingual machine translation model. arXiv preprint arXiv:2212.09811 , 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Strategies in- clude adaptive aggregation methods, energy-aware training schedules, and robustness to device dropouts ( ? ). However, these approaches often assume some level of reliability or do not fully integrate energy harvesting dynamics into the learning process.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "5. Archiving and Preservation Policies \nData will be archived on our departmental machines at Penn State as long as necessary for possible aca- demic publications and at least until the end of the project. The main documentation that will accom- \npany the data are project reports and research publications.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Megatron-lm: Training multi-billion parameter language models using model parallelism, 2020. [150] Sonali Singh, Anup Sarma, Sen Lu, Abhronil Sengupta, Mahmut T. Kandemir, Emre Neftci, Vijaykr- ishnan Narayanan, and Chita R. Das. Skipper: Enabling efficient snn training through activation- checkpointing and time-skipping.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "The beneÔ¨Åts of  P f  is contingent upon the models chosen by the model selection policy. It can be seen that smaller models  (MNet, NASMob ) can be packed 2-5 √ó  more when compared to larger models  (IRV2, NASLarge) . Thus, the ensembles with models of higher  P f have signiÔ¨Åcantly lower cost.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "These works are broadly categorized into: (i) multiplexing the different instance types (e.g., Spot, On- Demand) [ 12 ,  23 ,  34 ,  41 ,  42 ,  68 ,  79 ], (ii) proactive resource provisioning based on prediction policies [ 34 , 36 , 40 , 41 , 69 , 86 ]. There are mainstream commercial systems which automate single model-serving like TF-Serving [ 60 ], SageMaker [ 6 ], AzureML [ 10 ], Deep-Studio [ 28 ] etc. Autoscaling in Public Cloud : There are several research works that optimize the resource provisioning cost in pub- lic cloud.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 166,
    "augmented": true
  },
  {
    "text": "Keywords -Energy harvesting, ReRAM crossbar, CNN, Recon- Ô¨Ågurable hardware, Loop tiling, Computation scheduling \nI. I NTRODUCTION \nIn recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [ 1 ]. Such integration grants IoT devices an important degree of independence from remote servers, which can be critical in deployments with challenging communication environments. However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 162,
    "augmented": false
  },
  {
    "text": "do 3: The aggregator signals that a training update round is imminent. 4: Sensors decide on participation. Participation in- volves: \n1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "We believe, given that the current VR devices are battery-backed, these kinds of energy savings and performance improvements will not only enable the users to experience longer videos, but also encourage both industry \nand academia to work further on improving the pipeline to make VR more pervasive and versatile. A CKNOWLEDGMENT \nThis research is supported in part by NSF grants #1763681, #1629915, #1629129, #1317560, #1526750, #1714389, #1912495, and a DARPA/SRC JUMP grant. We would also like to thank Dr. Jack Sampson, Dr. Aasheesh Kolli and Dr. Timothy Zhu for their feedback on this paper.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "In  IEEE INFOCOM 2020-IEEE Conference on Computer Communications . IEEE, 854‚Äì863. [51]  Mu Editor 2022.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "To support faster inter-chip communication, which is essential for training, the chips can be interconnected using a fast fabric like NVLink [119], Infinity Fabric [13], or any newer technologies, and to cater inter-chiplet communication, which is essential for both training and inference, the chips can benefit from high-performance on-chip interconnect designs [10, 18, 31, 41, 108, 110, 116, 143]. For example, in cases of large working footprint or streaming accesses, the caches can be instructed to bypass low reuse data and store only the high reuse data. Or, having a fine-grained pro- grammer control via pragmas/annotations can help to efficiently utilize the caches.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": "1) Partial Inference:  To further explore the computation reuse opportunities, we revisit the Ô¨Årst scenario illustrated in Fig. This leads us to our next question ‚Äì  Can we do better? To explore the reuse opportunities at a Ô¨Åner granularity, we now dive into a tile/region-level study.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "A. Intra-frame Compression \nIn this subsection, we Ô¨Årst present the state-of-the-art intra- frame geometry and attribute compression techniques and discuss their inefÔ¨Åciencies. We then introduce our proposed intra-frame geometry and attribute compression schemes which are discussed in detail in Sec. IV-B  and Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Thus, the existence of a Nash equilibrium follows directly from the finiteness of utilities, the monotonicity of  Œ¶ , and the impossibility of infinite improvement sequences. Since each sensor‚Äôs best-response update seeks to maximize its own utility, sensors will continue to deviate as long as prof- itable deviations exist. Convergence to the Nash Equilibrium \nThe final step is to show that the iterative best-response dy- namics indeed converge to the NE identified above.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "The algorithm operates as follows: \nAlgorithm 1  Distributed Best-Response Participation Algo- rithm \n1:  Input: Current energies  B i ( t ) , predicted harvest ÀÜ E i ( t  + 1) , parameters  Œ≥, Œ¥, Œ∑, Œ≤ , and energy costs e cap ( ¬∑ ) , e inf , e comm . 4:  For each action candidate  a i ( t )  ‚àà{ P ,  NP } , the sensor computes the expected utility: \nU   a i ( t ) i =  E [ R i ( t )]  ‚àí E [ e i ( t )]  ‚àí Œ≤ E [ V i ( t  + 1)] , \nwhere the expectations are taken over uncertainties in correctness, SNR impact, and future energy. 2:  At each inference event: 3:  Each sensor  s i  receives a solicitation from the lead sensor and forms an estimate of  ‚àÜ A i ( t )  given potential SNR choices and expected actions of others.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 261,
    "augmented": true
  },
  {
    "text": "Im- plications of Public Cloud Resource Heterogeneity for Inference Serving. In  Workshop on Serverless Computing (WoSC‚Äô20), December 7≈õ11, 2020, Delft, Netherlands. 2020.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "( T s ) is set to 1 minute as it is the typical instance provisioning time for EC2 VMs. As shown in Algorithm  2 , for every model under a periodic scheduling interval of 1 minute ( T s ), we use the  Predicted _load ( L p ) at time  T  +  T p  and compare it with the  current_load  to determine the number of instances ( I n ). T p  is deÔ¨Åned as the average launch time for new instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "Figure 7: Inter-Frame attribute compression example. example using a state-of-the-art inter-frame compression technique [ 13 ] and our proposal, and study the following important questions: i)  what  is the opportunity?, ii) how do we  capture  and  exploit  such opportunity?, and iii) what are the potential  beneÔ¨Åts ? A. Inter-Frame Attribute Compression \n1) What is the Temporal Opportunity?",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "One approach to achieve lower RCA power is to limit precision. In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power. Therefore, the the RCA should be built on the basis of a low power hardware design that is upwardly reconÔ¨Ågurable to higher power scenarios rather than the reverse.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "It includes a variety of data types and tasks, providing a real-world urban driving context that is essential for testing  Salient Store  ‚Äôs performance in processing and managing 3D spatial data. Additionally, the  nuScenes  data-set (Caesar et al., 2020) by Aptiv, with its comprehensive sensor data and annotations covering diverse driving scenes, is instrumental in evaluating  Salient Store  ‚Äôs efficiency in multi-modal data processing typical in urban mobility scenarios. For 3D point cloud data, we selected the  KITTI Vision Benchmark Suite  (Geiger et al., 2012), a fundamental data-set in autonomous driving research.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "77 √ó  speedup against VSS and a classical storage server, respectively. Although, a multi-node setup provides more parallelism, the speedup is sub-linear, and we observe  ‚âà 3 √ó  and  ‚âà 4 . 6, we observe a significant change in the latency compared to a single storage node.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "This holistic approach addresses the limitations of existing methods that treat training and inference separately or do not account for real-time energy fluctuations. Implementation Details: We design a full software-compiler-hardware co-designed execution framework for commercial devices with non-volatility support (like MSP- EXP430FR5994 with FeRAM). Figure 2 shows a detailed overview of our execution design.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "4) Model-SpeciÔ¨Åc Analysis:  To study how the inference behavior changes across different DNN models, we next compare the performance and the energy consumption of two DNN models used in this work (YOLOv3 and YOLOv4-tiny), and plot the results in Fig. 8 and Fig. 9.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Dur E Shahwar Kundi, Song Bian, Ayesha Khalid, Chenghua Wang, M√°ire O‚ÄôNeill, and Weiqiang Liu. In 2020 IEEE International Symposium on Circuits and Systems (ISCAS) , pp. Axmm: Area and power efficient approximate modular multiplier for r-lwe cryptosystem.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "1074 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "However, this initial model may not be optimally adapted to the complex operational reality of the network, where sensors strategically choose SNR levels, participate inter- mittently according to equilibrium strategies, and generate data distributions that deviate from the original training set. The goal of the training process is to adjust  Œ∏  to these condi- tions, effectively  fine-tuning  the model to the nonstationary data distribution  D  induced by the sensors‚Äô equilibrium be- haviors. At equilibrium, sensors strike a balance between accurate data contribution and energy conservation, result- ing in a stable pattern of participation and SNR choices.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "In  MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture , MICRO ‚Äô21, pp. 494‚Äì506, New York, NY, USA, 2021. Associa- tion for Computing Machinery.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "5c, SLAT reduces the data communication volume up to  ‚âà 5 . 18 √ó  speedup compared to the classical storage server. Furthermore, as depicted in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "or by developing an application speciÔ¨Åc model from scratch along with the said optimizations. with optimizations like quantization, pruning etc. The students models are typically optimized for edge, i.e.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "First, these are the most frequently invoked kernels during the block matching stage. Second, processing a typical PC with  1 M points in a fully-parallelized fashion poses very high demands on the GPU resources (e.g., the number of available threads or the memory budget), which are quite limited, especially in edge devices. More interestingly, software-level optimizations for this step have been fully exploited (e.g., the kernel functions are invoked in a fully-parallelized manner), yet it still dominates the latency and energy.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "Since majority voting can include ties in votes, we analyzed the number of ties, which were correctly predicted for all the queries. However,  Cocktail  is still 9% better than  Clip- per  because the class-based weighted voting, is efÔ¨Åcient in breaking ties when compared to weighting averaging used in Clipper . This is be- cause, intuitively ensembling leads to higher accuracy than single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Also, where possible, the research material from this project will be integrated into the ML, architecture, and systems courses the PIs are regularly teaching at Penn State. Considering that a lot of motivated undergrad- uate students at Penn State are interested in ML and AI, we plan to assign well-defined projects from this research as ‚Äúhonors theses‚Äù. Undergraduate Involvement : We will engage undergraduates, especially those from the Penn State‚Äôs Schreyer Honors College, in the planned research activities.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Inter-Holo:  We evaluate the  Inter-Holo  design on a mobile GPU [ 36 ] using a framework similar to the state-of-the-art IL- LIXR framework [ 19 ], with one additional eye tracking task (as shown in Fig. 6b \na  ) integrated into the existing pipeline to par- tially bypass the computations of holograms that are outside the focus area. Note that, this implementation is purely done in software, without any hardware modification.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "1. Note that  RD upper bound  can vary across different use cases from parking lot to busy roads and hence, can be set accordingly \n1077 \nAuthorized licensed use limited to: Penn State University. First, to ensure minimal accuracy loss, if we have already skipped inference for frames beyond a certain number ( RD upper bound ), we decide to opt for FI (in Line  17 ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "1‚Äì15. [25]  Joao Carreira, Pedro Fonseca, Alexey Tumanov, Andrew Zhang, and Randy Katz. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "Modeling Expert Collaboration with Graph Ensemble-of-Experts. By integrating multiple Chain and Tree EoE structures, we can create complex Graph Ensemble-of-Experts (GEoE), facilitating communication and collaboration among experts. For example, each expert in chains and trees can produce intermediate results, and they can be aggregated into the final manager expert to produce the ultimate result.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "There have also been signiÔ¨Åcant efforts in designing and optimizing specialized DNN training accelerators [ 16 ], [ 27 ], [ 81 ], and many commercial organizations have already devel- oped their own accelerators [ 37 ], [ 95 ] as well. C/S is the ratio of  C ompleted over the  S cheduled training tasks over multiple time windows of 4hours. Our custom HW runs with intermittent support both by hardware and software.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Forward pass:  Each participating sensor collects data ( x, y )  and evaluates  ‚Ñì ( f Œ∏ k ( x ) , y ) . 10 \n550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 \n2. Backward pass:  The sensor computes  ‚àá Œ∏ ‚Ñì ( f Œ∏ k ( x ) , y ) via standard backpropagation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 193,
    "augmented": false
  },
  {
    "text": "In USENIX ATC . [40]  Haoran Qiu, Subho S Banerjee, Saurabh Jha, Zbigniew T Kalbarczyk, and Ravishankar K Iyer. 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Moreover, when adopting the FI+SI+PI, compared with the FI+SI, around  12%  more energy can be saved, as shown in Fig. 9a. 9c.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "DeepCache [8] has been proposed for trading layer-wise intermediate data memoization/caching for computation savings, but it ignores the frame-wise reuse op- portunities. These optimizations have been attempted at different levels, including model compression (pruning [2], [3], quantization [4]), compiler support [2], [5]‚Äì [7], runtime systems [7]‚Äì[13], and hardware enhancements [9], [14], [15]. Let us now summarize the pros and cons of four representative state-of-the-art works which include var- ious levels of optimizations as aforementioned, and compare them with our work.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "Lorenzo Pichierri, Guido Carnevale, Lorenzo Sforni, Andrea Testa, and Giuseppe Notarstefano. A distributed online optimization strategy for cooperative robotic surveillance. dimensions , 30:33.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "0.00 0.20 0.40 0.60 0.80 1.00 1.20 1.40 1.60 \nG1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 \nPV HG LeNet FR \nNaive2 Sequential Pipelining ResiSchedule \nFig. 12. The main reason for this is that the  ResiSchedule  policy can efÔ¨Åciently organize more hardware resources than the  Sequential  policy when hardware resources are limited.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "2001‚Äì2010, 2017. Sahand Salamat, Armin Haj Aboutalebi, Behnam Khaleghi, Joo Hwan Lee, Yang Seok Ki, and Tajana Rosing. In  Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "[93] Synopsys, ‚ÄúDesign compiler,‚Äù https://www.synopsys.com/ implementation-and-signoff/rtl-synthesis-test/dc-ultra.html , (Accessed on 04/28/2023). [94] Synopsys, ‚ÄúStandard cell libraries,‚Äù  https://www.synopsys.com/dw/ \nipdir.php?ds=dwc standard cell , (Accessed on 04/28/2023). [95] E. Talpes, D. Williams, and D. D. Sarma, ‚ÄúDojo: The microarchitecture \nof tesla‚Äôs exa-scale computer,‚Äù in  2022 IEEE Hot Chips 34 Symposium (HCS) .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 172,
    "augmented": false
  },
  {
    "text": "One major issue with neural codecs are their lack of utilization of inter-frame similarity. Classically, neural codecs compress each frame by treating them like images. However, video data often comes with a large amount of inter-frame similarity (Ying et al., 2022b; Zhang et al., 2017; Zhao et al., 2020, 2021; Ying et al., 2022a).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Seeker  provides hardware acceleration support for coreset formation to make them computationally efficient, adaptive, and accuracy-preserving specifically for EH-WSNs. Particularly,  Seeker  aug- ments its coreset formation with  application-awareness  to form an energy aware, dynamically configured, and feature \npreserving payload with minimal communication footprint. Furthermore, it then applies innovative coreset techniques to efficiently and intelligently offload unfinished compute tasks to a more capable host to further increase the inferences that can be performed.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "3b), and observed the following two properties in the AR holographic applications: Spatio Diversity for Objects:  Intuitively, objects which are far from the user and with small-sized shapes require less informa- tion to generate the virtual hologram than others (more details are provided in Sec. 3). Hence, the distance between the user and the objects ( Cam2ObjDist  shown in black color in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Due to the limited number of segments, one can observe that some highlighted blocks are not well matched. This again conÔ¨Årms that a Ô¨Åner segment can yield a better temporal locality, as also discussed above. Takeaway : The Morton codes generated as an intermediate result during geometry compression not only improve the geometry compression by increasing pipeline parallelism, but also help to capture/identify the attribute similarities within a frame as well as across frames.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "The chosen action profile is a ( t ) = ( a 1 ( t ) , . . .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "In  ATC . [51]  Hailong Yang, Quan Chen, Moeiz Riaz, Zhongzhi Luan, Lingjia Tang, and Jason Mars. 2017.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "‚Ä¢  We can search for an intermediate power level, where we Ô¨Årst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level ‚Äì this strategy is called  Multi-step Transition . ‚Ä¢  If the power predictor reports a power transition from a high level to a low level, we can move to the new activation solution before performing the last incomplete inference ‚Äì this strategy is referred to as  Eager Transition . The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , 41(11):4229‚Äì4240, 2022. Keep in balance: Runtime-reconfigurable intermittent deep inference. Chih-Hsuan Yen, Hashan Roshantha Mendis, Tei-Wei Kuo, and Pi-Cheng Hsiu.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "[36] S. S. Beauchemin and J. L. Barron, ‚ÄúThe Computation of Optical Flow,‚Äù ACM Comput. 1‚Äì51 vol.1. [35] Google Developers, ‚ÄúMediaCodec,‚Äù ‚Äùshorturl.at/mCHV4‚Äù, 2021.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "2.1) ‚Ä¢  From two open-source AR datasets [ 1 ,  58 ], we identify two prop- erties in AR hologram applications:  spatio diversity for objects , and  temporal locality for the user (viewer) interests (i.e., user typ- ically focuses on one region within a short period of time) . Such properties are leveraged as approximation opportunities to skip the ‚Äúunimportant‚Äù portions of the hologram computation, based on user‚Äôs region of focus (known as foveated rendering), and object‚Äôs distance/size from the user. (Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "3a) affect the amount of computations actually required to provide just enough yet necessary virtual holo- grams. For example, compared to the  chair  object in Fig. 3a, the bike  object is closer to the user, and also has a larger range/size ( size=farmost-nearest ); thus, more information is required to create the hologram for the  bike  for maintaining fairly good QoS than the  chair .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "However, it also introduces complexities in coordinating sensor activities, managing energy resources, and ensuring efficient data collection and processing ( ? ). 2.2.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "51% \n32% \n17% \n2-Norm Attri. Distance \nCount P-Block \nOther \nFigure 9: Energy consumption breakdown for inter-frame attribute compression for Loot video [ 54 ]. consuming one among the proposed geometry, intra- and inter- frame attribute compression techniques).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "‚Ä¢  In  AA , the input and output mapping are unique, that is, no two input coordinates in  360 ¬∞ frame map to the same coordinates in the 2D FoV frame, thereby eliminating any compute reuse scope. Although, in principle, for computing the transformation for consecutive pixels, one can leverage data value similarity to reduce the computation, in this work we are not focusing on leveraging any such opportunity. ‚Ä¢  EE  offers little chance of reuse, and can only be leveraged in rare occasions, where we have oracular knowledge of head movements.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "12, pp. 40, no. [50] Z. Li and D. Hoiem, ‚ÄúLearning without forgetting,‚Äù  IEEE transactions \non pattern analysis and machine intelligence , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "In this work, the parallelism granularity  G  of a layer is determined by the ratio between 50% of the peak harvested power during proÔ¨Åling and the power consumption of the full- size ReRAM corresponding to this layer. G  can be determined considering the tradeoff between energy efÔ¨Åciency and chip area during the design phase. We use parallelism granularity  G  to denote the duplication count as deÔ¨Åned in [ 5 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Figure 14: Simulator: Comparison of Total Number of Containers spawned VS SLOs satisfied by each policy. The Primary Y-Axis denotes the number of containers spawned, The secondary Y-axis indicates the percentage of SLOs met and the X-axis represents each policy. 0 \n2000 \n4000 \n6000 \nOracle Kraken \n# Containers \nNGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "C ONCLUDING  R EMARKS \nPC processing has become the trend for many video applications spanning scientiÔ¨Åc computing, education, health- care and entertainment, and is recently being ofÔ¨Çoaded to the edge. Hence, to enhance the Ô¨Çexibility of our proposed design for trading off the compression efÔ¨Åciency with the quality, we can use the  percentage of ‚Äúdirect-reuse‚Äù blocks  as a  tunable design knob , for which, users can choose the appropriate value based on their preferences (i.e., fewer ‚Äúdirect-reuse‚Äù blocks with higher PSNR vs. more ‚Äúdirect-reuse‚Äù blocks with higher compression efÔ¨Åciency). VII.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "arXiv  (2015). SemanticPaint: A Framework for the Interactive Segmentation of 3D Scenes. [16]  Bo Han, Yu Liu, and Feng Qian.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "244 \ncoordinates in that frame, thus are evaluated only  once  for that frame, and account for only  4 . 8 MFLOPS  without any optimization. In the  Projection Computation  stage (refer to  b  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Each branch node in the octree stores 8 occupy bits, indicating the occupancy of its children/sub-cubes. For example, with octree-based PCC, considering a PC is con- tained in a  D √ó D √ó D  cube, the cube is recursively divided into 8  D / 2 √ó D / 2 √ó D / 2  sub-cubes until  D = 1 . The occupied/non- empty voxels in level n  can be indicated by the  occupy  bits of its ‚Äúparent voxel‚Äù (voxel in level n ‚àí 1 ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "Note from  Line#3  to  Line#5  in Algo. Each depth plane processes the forward-propagation from the hologram plane independently, and each pixel on a particular depth plane goes through the exact processing sequence ( HP2DP in  Line#5 ; more details can be found in [ 4 ,  18 ]). 1 that, such forward propagation is massively parallel at the depth plane level (across planes) as well as at the pixel level (within one plane).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Lightweight hardware implementation of r-lwe lattice-based cryptography. In  2018 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS) , pp. Sailong Fan, Weiqiang Liu, James Howe, Ayesha Khalid, and Maire O‚ÄôNeill.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Serverless functions, hav- ing short resource provisioning times and instant scalability, are suitable candidates for developing such latency-critical applications. However, existing serverless providers are un- aware of the workflow characteristics of application DAGs, leading to container over-provisioning in many cases. This is further exacerbated in the case of dynamic DAGs, where the function chain for an application is not known a pri- ori.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Towards this, we designed and trained a generative adversarial network (GAN, see Figure 7b for the structural details) to recover the lost samples of the importance sampling. And these artifact must have some pattern, if modeled correctly, could represent the lost data. We hypothesize that the dropped sample should con- tain, although not important, sensor specific artifacts.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "To procure  A n  instances, we greedily calculate the least cost instance as  min ‚àÄ i ‚àà instances Cost i  √ó A n / P f i . Depend- ing on the cost-effectiveness ratio of  A n / P f i , GPUs will be preferred over CPU instances. Load Balancer : Apart from procuring instances, it is quintessential to design a load balancing and bin-packing  5 strategy to fully utilize all the provisioned instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "5.2 Evaluation Methodology \nWe evaluate our prototype implementation on AWS EC2 [ 8 ] platforms. SpeciÔ¨Åcally, we use  C5.xlarge, 2xlarge, 4xlarge, 8xlarge  for CPU instances and  p2.xlarge  for GPU instances. Load Generator:  We use different traces which are given as input to the load generator.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "We assume the communication cost to be negligible since it infrequently sends a few bytes of data to the host. First sensor at the chest, second on the right wrist and last sensor on the left ankle. Each sensor consists of four major components, namely, the sensing component, an IMU, which collects acceleration and attitude data, an energy harvester which harvest the surrounding RF (WiFi) energy, a compute component same as [6] and a wireless communication module (BLE or WiFi) to connect to a host device (battery backed mobile phone).",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "Our goal is to maximize storage at edge so that the frequency of maintenance decreases. This can be done by periodically transporting the data by swapping out storage bays. 4 \nThe main reason these algorithms consume significant resources is because of the amount of data they handle.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM. This resilient activation approach can effectively combat  Nonideal scenario 1 . The underlying reason of encountering so many power failures in the case of conventional working mode is that the power threshold of the system to remain alive is set too high.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "[144] Akbar Sharifi, Shekhar Srikantaiah, Asit K Mishra, Mahmut Kandemir, and Chita R Das. Mete: meet- ing end-to-end qos in multicores through system-wide resource management. In  Proceedings of the ACM SIGMETRICS joint international conference on Measurement and modeling of computer systems , pages 13‚Äì24, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "We want to emphasize however that, such static (pre-deÔ¨Åned) window-size works well only when there are few movements in the videos. We acknowledge that, compared to our proposal, Euphrates yields around  10% additional energy savings when the window size is set to be as large as  8  (i.e., always skipping  7  frames). II-B3.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)  42, 4 (2012), 1131‚Äì1142. 2012. Prediction of User‚Äôs Web-Browsing Behavior: Application of Markov Model.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "As we will discuss in this paper, the cost of using VMs vs. serverless functions highly depends on the dynamically varying needs of the user query submission rates. Besides workload arrival rates, there is fur- ther variability in terms of configuring serverless functions to meet the end-user demands of latency and cost require- ments. This is because, serverless functions are billed based on of number of invocations, compute time and memory requirement of the function.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Advances in Neural Information Processing Systems , 36, 2024. Quip: 2-bit quantization of large language models with guarantees. [23] Guangyu Chen and Feihui Li.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "[31] J. He and F. Zhu, ‚ÄúOnline continual learning for visual food classiÔ¨Å- \ncation,‚Äù in  Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021, pp. [30] S. Han, H. Mao, and W. J. Dally, ‚ÄúDeep compression: Compressing \ndeep neural networks with pruning, trained quantization and huffman coding,‚Äù  arXiv preprint arXiv:1510.00149 , 2015.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Octree Construction:  With the input geometry data, the octree construction algorithm is invoked to add the points and update the tree (e.g., the maximum depth required for inclusion of a point, occupancy information for nodes, etc.) in a point-by-point fashion. This point-by-point ‚Äúupdate‚Äù makes this stage difÔ¨Åcult to parallelize.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "ACM SIGARCH Computer Architecture News , 34(2):4‚Äì15, 2006. [80] Jongman Kim, Chrysostomos Nicopoulos, Dongkook Park, Vijaykrishnan Narayanan, Mazin S Yousif, and Chita R Das. A gracefully degrading and energy-efficient modular router architecture for on-chip networks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "From this Ô¨Ågure, we can Ô¨Ånd that:  1). Here, we vary the tile size (an N √ó N tile is a N √ó N pixel block) from 4 √ó 4 to the entire frame (1080 √ó 1920) on the x-axis, and the y-axis gives the fraction of ‚Äúidentical tiles‚Äù (when compared pixel-by- pixel) in  two successive frames . Small-size tiles share signiÔ¨Åcant similarities across consecutive frames.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Third, the presence of conditional branches in some DAGs can lead to uncertainties in determining which functions will \n153 \nSoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. be invoked by different requests to the same application. For instance, in a train-ticket application [ 40 ], actions like make_reservation  can trigger different paths/workflows (sub- set of functions) within the application.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Peak-to-median ratio. Prior works  [ 5 ,  10 ] try to hide the pro- visioning latency of VMs by using  server- less functions  as a handover mechanism when starting new VMs. 0 \n500 \n1000 \n1500 \nwiki WITS berkley Twitter \nRequest Rate \nAvg Req \nMax Req \nFigure 6.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": ", q k }  be a set of QuantaTasks with in- dividual energy requirements  E q i . If   P \ni   E q i   ‚â§ E b , the available energy budget, then tasks can be executed sequentially without interruption. However, if   P \ni   E q i   > E b , we aim to fuse tasks to minimize checkpointing overhead.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "https://doi.org/10.1145/3429880.3430093 \n1 Introduction \nSustained advances in ML has fueled the proliferation of emerging applications such as product recommendation sys- tems, facial recognition systems, and intelligent personal assistants [ 7 ]. Among many ML paradigms, Deep Neural Net- works (DNNs), owing to their generalization and massively- parallel nature, has been predominant in making all these applications pervasive and accessible to developers. A typical DNN model has two different phases, namely,  training  and inference .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Thus, to cater to the execution diversity in experts, we intend to take advantage of ‚Äúheterogeneous‚Äù chiplets. Using the above profiling, for each expert in each EoE when run over a variety of hardware platforms, we can systemati- \nSilicon Interposer \nIntra-Chip Network Fabric \nHomogeneous Chip \nHeterogeneous Chip \nIntra-Chip Network Fabric \nSilicon Interposer \nFigure 6 :  Our proposed chip infrastructure. Each chip can potentially contain a set of homogeneous or heterogeneous chiplets including accelerator engines, reconfigurable engines, CPUs, GPUs, and various types of memory modules.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "Microprocessor Report, Tech. Groq rocks neural networks. Rep., jan , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 23,
    "augmented": true
  },
  {
    "text": "Restrictions apply. 1074 \nAuthorized licensed use limited to: Penn State University. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "P f  in this context is deÔ¨Åned as the number of inferences that can be executed concurrently in a single instance without violating the inference latency (on average). However, note that the ‚ÄúPacking factor‚Äù ( P f  ) for each model also impacts the deployment costs. Table  1  provides the  P f  for 11 different models when executed on a  C5.xlarge  instance.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Therefore, reducing the number of estimators while keeping the prediction quality over a certain boundary will optimize fine tuning the model. IV. Figure 4d shows that inference time will increase linearly with the number of estimators whereas it has a very small impact on correlation.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "shorturl.at/jmnpD [53]  Antoni Rosinol, Marcus Abate, Yun Chang, and Luca Carlone. 2020. Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "GPU instances are cost-effective when packed with a large batch of requests for execution. We explain the details below. Resource Types : We use both CPU and GPU instances  4a depending on the request arrival load.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "To tackle this, recent works [9], [6] use a non-volatile processor (NVP) to ensure sufÔ¨Åcient forward progress in the face of frequent power emergencies. The combination of EH, NVPs and other architectural and compiler optimizations have enabled the use of sensors as smart inference engines. However, these node-level optimizations are not entirely sufÔ¨Åcient for sensor networks with multiple sensors collectively working together to achieve a goal, which are very common.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Re- alistic dynamic facial textures from a single image using gans. 2017. In Proceedings of the IEEE International Conference on Computer Vision .",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "It is recommended to contain most of the data belonging to the same application in the same storage server to minimize remove disk accesses over network. 16 \n0 \n2 \n4 \n6 \n8 \n10 \n12 \n14 \nKittiVision nuScenes CHIME Cityscapes Waymo \nRelative Latecny \n2 Nodes 3 Nodes 4 Nodes 5 Nodes 6 Nodes \nFigure 10: Change of data movement latency with respect to the number of storage servers. This leads to an exponential growth in latency with the increase in the number of storage servers used per application.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "These components form the foundation for constructing a ‚Äúmorphable ecosystem of experts‚Äù through dynamic routing and composition. The different methods for each component are summarized in Table 1. Our exploration will focus on various types of router functions to direct user queries to appropriate experts, different expert model architectures, and composition functions to  ag- gregate  expert outputs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Zero: Memory optimizations toward training trillion parameter models. In  SC20: International Conference for High Performance Com- puting, Networking, Storage and Analysis , pages 1‚Äì16. IEEE, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "31, no. 1, 2017. [35] Z. Jackson, ‚ÄúFree spoken digit dataset (fsdd),‚Äù https://github.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "t . The micro-proÔ¨Åler optimizes the weighted accuracy ( A w  = \nW i \nA i   / ‚àë W i ; ‚àÄ i  ‚â§ # models ; W i  =  f ( time , dri ft , compute )  with a user-deÔ¨Åned slack value of  Œ¥ ), with respect to available power ( P av ): max A w ;  s . changes.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "In comparison,  Comm Only  and  Conn Only  fail to spawn enough containers for each important function as they do not consider both these parameters, resulting in increased tail latency and exacerbates the SLO violations. 7 Concluding Remarks Adopting serverless functions for executing microservice- based applications introduces critical inefficiencies in terms of scheduling and resource management for the cloud provider, especially when deploying Dynamic DAG Applications. To- wards addressing these challenges, we design and evalu- ate  Kraken , a DAG workflow-aware resource management framework, for efficiently running such applications by uti- lizing minimum resources, while remaining SLO-compliant.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "Learning Approach: Our approach diverges from classi- cal Learning paradigms. We adopt a hybrid strategy where periodic or event-triggered updates refine the model parame- ters based on equilibrium-driven data collection. This hybrid \n5 \n275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 \napproach mitigates the high communication overhead and energy consumption, making it more suitable for resource- constrained EH-WSNs.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 187,
    "augmented": true
  },
  {
    "text": "We consider this design as the  state-of-the-art . In contrast, as explained earlier in Sec. However, PTU  only optimizes the energy per compute through accel- eration, with exactly the ‚Äúsame amount of computations‚Äù as in the baseline design.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "It simulates the working of DDAs running on a serverless framework that are subjected to both real-world (Twitter and Wiki) and synthetic (Poisson-based) traces. We have validated its correctness by correlating various metrics of interest generated from experiments run on the real system with scaled-down versions of the same traces (average ar- rival rate of  ‚àº 100rps). 5.3 Large Scale Simulation To evaluate the effectiveness of  Kraken  in large-scale sys- tems, we built a high fidelity, multi-threaded simulator in Python using container cold start latencies and function execution times profiled from our real-system counterpart.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "In  18th USENIX conference on file and storage technologies (FAST 20) , pp. 29‚Äì41, 2020. Keith Chapman, Mehdi Nik, Behnam Robatmili, Shahrzad Mirkhani, and Maysam Lavasani.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Probability:  As alluded to in Section 2, one of the factors used in function weight estimation is its invocation probabil- ity. The procedure in Section 3 describes how the transition probabilities of the states associated with functions are com- puted through repeated matrix multiplications of the Transi- tion Matrix, ùëá with the Probability Vector,  ùëÉ . ùê∂ùëúùëöùëùùë¢ùë°ùëí _ ùëÉùëüùëúùëè , \n158 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nin Algorithm 1, first estimates the invocation probabilities of a function‚Äôs immediate predecessors and uses it along with system log information and load measurements of the function to calculate its invocation probability.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 176,
    "augmented": false
  },
  {
    "text": "Chipper: A low-complexity bufferless deflection router. In  2011 IEEE 17th International Symposium on High Performance Computer Architecture , pages 144‚Äì155. IEEE, 2011.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "However, these schemes do not address the holis- tic problem by taking into account model selection, resource selection, and resource scaling to cope up with user-specified constraints. We conduct similar experiments to mimic the mixed  procurement scheme. As shown in Figure  5 ,  mixed procurement reduces the over-provisioning cost of VMs.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "¬¥as . When power is highly uncertain, the morphable hardware also strongly contributes, however, as the power proÔ¨Åle becomes stable, the algorithmic contributions dominate. Along with morphable hardware, the exemplar selection and the micro-proÔ¨Åler play an important role for the success of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "The insights gained from these simulations and modeling efforts will be instrumental in refining run- time performance and providing informed estimates regarding the system and hardware demands of emerging applications. Furthermore, we plan to make this comprehensive full-stack development envi- ronment open-sourced, enabling the community to leverage it for informed design decision-making. 3 Related Work \nLLMs have gained significant momentum in recent years and are being used in domains like virtual as- sistants [12,16,56], website chatbots [121], tools [48,123], notetaking/summarization [52], etc.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "However,  Clipper-X  does not scale down models as frequently as  Cocktail , while ensuring similar accuracy. 6.2.2 BeneÔ¨Åts from Autoscaling \nFigure  11  plots the reduction in the number of VMs used by all four schemes. Clipper  is less accurate than  Cocktail  and further it uses all 10 models throughout.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "The head orientation is sensed by an inertial measurement unit (IMU) on the HMD as a triple [ Y aw ,  Pitch ,  Roll ] for projection computation 2 . For each frame, this computation is processed twice ‚Äì one for left eye and the other for right eye ‚Äì to reinforce users‚Äô sense of depth. Display:  After the projection, the two generated FoV frames are stored in 2D format in the video buffer.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "These inference queries are typically administered with strict response laten- cies of under one second [ 4 ]. Based on the application needs, prediction queries require different compute resources, and have different accuracy, latency, and cost requirements. To ensure a required accuracy with given latency, applications have to choose from a confounding array of different types of models (shown in Figure  1 ).",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "All these activities may require  retraining  the routers. Task-2.2: Router Retraining As stated earlier, our morphable LLMs will function in a plug-and-play fashion in which we will introduce new experts into the current ensemble incrementally, drop unneeded experts from an ensemble, or replace existing experts with others. This approach can be further refined by, for instance, adjusting the weights taking into account a) availability/proximity of appropriate compute to the nodes (data should ideally be present on nodes which can leverage well-suited accelerators with relative ease), and b) load balancing across nodes to prevent overburdening specific nodes (thus, avoiding performance interference).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "At any instance, a user is only concerned about the FoV pixels in the entire  360 ¬∞ frame. So, instead of evaluating the mapping for all coordinates in the  360 ¬∞ frame, we only generate the mapping for those pixels which are within the user‚Äôs view. As the target  2 D  FoV coordinates are already known (VR screen dimensions), these mappings can be performed by multiplying the inverse of the transformation matrix ( T   ‚àí 1 ) with the  2 D  FoV coordinates ( V 2 D ), thus generating the corresponding  360 ¬∞ pixel coordinates ( P ), as shown in Equation 2.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "the ratio of number of scheduled training to the number of completed training, loss of accuracy compared to the baseline. We quantitatively compare the effective training, i.e. It is clear that even with intermittent power availability  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "The cloud model is trained on a larger data set and has more parameters than the edge models and hence is more accurate. The 2-home setup, albeit more accurate, has a more complex model (#splitting points 10501) at the cloud thanks to the large volume of training samples, leading to more execution time compared to the relatively simpler model for the 4-home setup. 3) The privacy preserving cloud model, although less accurate than the data shared cloud model, performs significantly better than the edge models, with 5.1% more correlation in case of the 2-home setup and 10.37% more correlation for the 4-home setup.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Figure 1: DAGs of Dynamic Function Chains. 0 100 200 300 \nStatic Provisioning \nProbability-based \nXanadu \n# Containers NGINX Search Make_Post Text Media User_Tag URL_Shortener Compose_Post Post_Storage Read_Timeline Follow \n(a) Social Network. 0 100 200 300 \nStatic Provisioning \nProbability-based \nXanadu \n# Containers NGINX ID Movie_ID Text User_Service Rating Compose_Review Movie_Review User_Review Review_Storage \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "315‚Äì 327. [73] Ravi Teja Mullapudi, Steven Chen, Keyi Zhang, Deva Ramanan, \nKayvon Fatahalian, ‚ÄúOnline model distillation for efÔ¨Åcient video in- ference,‚Äù in  ICCV , 2019. [74] S.-A.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Edge devices are often equipped with mature and robust video and vision pipelines, including sophisticated hardware like the codecs, which the current video analytics pipeline is yet to fully exploit. Further, the video stream itself has temporal continuity, giving us the opportunities of memoization and reuse. In special cases, like remote surveillance, most frames can even be identical, avoiding the need to process them.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Despite using multiple models for a single inference, importance sampling combined with aggressive model pruning, greatly reduces the resource foot- print which directly translates to the cost savings in  Cocktail . The au- toscaling policy effectively utilizes this importance factor in regular intervals of 5 minutes. Figure  9b  shows the most used models in decreasing order of importance.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "2. Focusing on classiÔ¨Åcation-based inferences, it is important to minimize the bias in predictions resulting from multi- ple models. In  Cocktail , we employ a per-class weighted majority voting policy, that makes it scalable and effec- tively breaks ties when compared to traditional weighted averaging, thereby minimizing the accuracy loss.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "733‚Äì747, 2019. [10]  K. Qiu, W. Chen, Y. Xu, L. Xia, Y. Wang, and Z. Shao, ‚ÄúA peripheral circuit reuse structure integrated with a retimed data Ô¨Çow for low power rram crossbar-based cnn,‚Äù in  2018 Design, Automation Test in Europe Conference Exhibition (DATE) , pp. 1057‚Äì1062, March 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Appl. Fast Calculation Method with Foveated Rendering for Computer-generated Holograms Using an Angle-changeable Ray- tracing Method. Opt.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "3) The privacy preserving cloud model, although less accurate than the data shared cloud model, performs significantly better than the edge models, with 5.1% more correlation in case of the 2-home setup and 10.37% more correlation for the 4-home setup. Thanks to a simpler model (which is a random sample of the edge models), the latency does not increase significantly. B.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "real-time refresh requirement of vision applications is yet to close and prevents the deployment of NN-PCC on edge devices. Entropy Other Geo. Compression Pipeline:  PCL \nb c a \nFigure 2: Prior PC compression technique categories and latency breakdown for prior techniques on compressing one PC frame from [ 55 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "Sahand Salamat, Hui Zhang, Yang Seok Ki, and Tajana Rosing. Nascent2: Generic near-storage sort accelerator for data analytics on smartssd. ACM Transactions on Reconfigurable Technology and Systems (TRETS) , 15(2):1‚Äì29, 2022.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Usas: A sustainable continuous-learning¬¥ framework for edge servers. Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, Vijaykrishnan Narayanan, and Chita R Das. 1‚Äì11, 2009.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "do 3: The aggregator signals that a training update round is imminent. Participation in- volves: \n1. 4: Sensors decide on participation.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output  Y .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output. One approach to achieve lower RCA power is to limit precision. The impact of different precisions on CNN accuracy has been extensively studied [ 24 ], [ 25 ], [ 26 ], [ 27 ], [ 28 ], [ 29 ], [ 30 ], [ 31 ], [ 32 ], [ 33 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Phoenix: A \nConstraint-Aware Scheduler for Heterogeneous Datacenters. In  2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS) . 977‚Äì987.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Each request is derived from a pool of pre-trained ML inference models for image classification (as explained in Section  2 ). We use  Apache MXNet  and  TensorFlow  frame- work to deploy and run inference on the models. Evaluation:  We evaluate our results by comparing the cost, latency and accuracy for two different workloads.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Our experimental evaluations using six different videos reveal that the proposed schemes are up to  80%  ( 56%  on average) energy efÔ¨Åcient and  2 . More speciÔ¨Åcally, for each frame in the video, we can dynamically select between (i) performing a full inference, (ii) performing a partial inference, or (iii) skipping the inference al- together. We integrate these two data reuse algorithms to accelerate the neural network inference and improve its energy efÔ¨Åciency.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Manuel J Fonseca and Joaquim A Jorge. Indexing high-dimensional data for content-based retrieval in large databases. In  Eighth International Conference on Database Systems for Advanced Applications, 2003.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "We leverage such foveated rendering idea in  Inter-Holo as our  Reference  design in this paper. ‚Ä¢  The above  Viewing-Window  and  Inter-Holo  proposals target at reducing the amount of computation for the holograms from the head orientation ( rotation ) and eye tracking ( up-down ) perspec- tives. As discussed in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Deepstore: In-storage acceleration for intelligent queries. Vikram Sharma Mailthody, Zaid Qureshi, Weixin Liang, Ziyan Feng, Simon Garcia De Gonzalo, Youjie Li, Hubertus Franke, Jinjun Xiong, Jian Huang, and Wen-mei Hwu. In  Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Along with that, the micro-proÔ¨Åler selects correct batch size 82 . 64% of the time and the correct number of layers for 87 . 06% of the time.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "3 Five iterations of the GSW algorithm [63] are profiled. 496 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 2 In this paper, we mainly use the popular depthmap input method.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "The model cache is implemented as a hash-map using  Redis  [ 16 ] in-memory key-value store for fast access. Constraint speciÔ¨Åcation : We expose a simple API to de- velopers, where they can specify the type of inference task (e.g., classiÔ¨Åcation) along with the  <latency,accuracy> constraints. Developers also need to indicate the primary ob- jective between these two constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "4). These are then communicated to the host device for inference. To address this, we also utilize coreset construction using k-means clustering [ 8 ,  36 ,  37 ], which separates the data points into a set of k (or fewer) N-spherical clusters and represents the geometric shape of the data by using the cluster centers and cluster radii (Fig.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "[19]  M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, ‚ÄúRedesigning software and systems for non-volatile processors on self-powered devices,‚Äù in  2016 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC) , pp. [18]  K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, ‚ÄúNEOFog: Nonvolatility-exploiting optimizations for fog computing,‚Äù in  Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS , pp. 782‚Äì796, 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 203,
    "augmented": true
  },
  {
    "text": "37‚Äì44, New York, NY, USA, 2022. Association for Computing Machinery. In  Proceedings of the 2nd European Workshop on Machine Learning and Systems , EuroMLSys ‚Äô22, pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "[5] Yang Liu, Yingting Liu, Zhijie Liu, Yuxuan Liang, Chuishi Meng, Junbo Zhang, and Yu Zheng. Federated forest. IEEE Transactions on Big Data , 2020.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1592‚Äì1604, Dublin, Ireland, May 2022. Association for Computational Linguistics. [187] Yusen Zhang, Ruoxi Sun, Yanfei Chen, Tomas Pfister, Rui Zhang, and Sercan √ñ Arik.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Unlike simple heuristic meth- ods that ignore future resource allocation or complex ap- proaches like reinforcement learning that may be too costly to implement, game theory provides equilibrium guaran- tees. By modeling each sensor as a rational player aiming to optimize its own long-term utility, we achieve stable, coop- erative equilibria where no sensor can improve its outcome through unilateral deviation. This strategic equilibrium un- derpins both training and inference participation decisions, ensuring that the sensors most likely to improve the global \n1 \n055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071 072 073 074 075 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109 \nmodel‚Äîgiven their energy, data quality, and network condi- tions‚Äîare the ones that engage.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 269,
    "augmented": false
  },
  {
    "text": "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. IEEE, 2011. [42] William Fedus, Barret Zoph, and Noam Shazeer.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Amazon States Language. https://docs.aws.amazon.com/step- functions/latest/dg/concepts-amazon-states-language.html. [4]  2020.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "[5]  J. R. Gunasekaran, P. Thinakaran, et al . 2019. Spock: Exploiting Server- less Functions for SLO and Cost Aware Resource Procurement in Public Cloud.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "The final training objective is: \nJ ( Œ∏ ) =  L ( Œ∏ ) +  Œª 1 ‚Ñ¶ SNR ( Œ∏ ) +  Œª 2 ‚Ñ¶ complexity ( Œ∏ ) , \nwhere  Œª 1 , Œª 2  ‚â• 0  are hyperparameters controlling the influ- ence of the regularizers. Our goal is to show that by running a diminishing step-size SGD on  J ( Œ∏ ) , using unbiased gradient estimates from the equilibrium distribution  D , the parameters  { Œ∏ k }  converge in expectation to a stationary point  Œ∏ ‚àó of  J ( Œ∏ ) . Key Assumptions and Conditions \n1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 156,
    "augmented": false
  },
  {
    "text": "Kiwan Maeng and Brandon Lucia. In  13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18) , pp. Adaptive dynamic checkpointing for safe efficient intermittent computing.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "These pixels amount to only  2 . 7%  of the entire FoV frame. Additionally, there are few pixel positions at the frame edges which can only be viewed by one eye (denoted as  exclusive ), which cannot be captured by the above pattern.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "This assumption simplifies the model by ensuring that better data quality unequivocally enhances inference performance, while also making the energy ex- penditure predictable. In addition to capture costs, partici- pation incurs inference computation cost  e inf  and communi- cation cost  e comm . We assume a monotonic relationship: higher SNR increases both the capture cost and the expected ac- curacy contribution.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Our training infrastructure utilizes NVIDIA A6000 GPUs with 48 GiB of memory, supported by a 24-core Intel Xeon Gold 6336Y CPU. We employ PyTorch v2.3.0 coupled with CUDA version 11.8 as our primary training framework. To assess the computational overhead introduced by DynFit, a component of NExUME, we use NVIDIA Nsight Compute.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "The second input is the decoded  360 ¬∞ frame that contains the pixel values. III). Our characterization indicates that, on average, around 2.3 GFLOPS is required for this projection transformation (details are discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "M OTIVATION \nTo avoid negatively impacting the underlying system‚Äôs QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available. First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power. In energy harvesting systems, there are two critical features, namely,  power strength  and power window length .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Compute the activations  a  and apply the dropout mask: \nm i  =  œÉ ( z i ) \na dropout i =  a i  ¬∑  m i \nCompute the loss  L ( Y ,   ÀÜ Y ) . Define the energy budget E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "[64]  Zhuoran Song, Bangqi Fu, Feiyang Wu, Zhaoming Jiang, Li Jiang, Naifeng Jing, and Xiaoyao Liang. 2020. DRQ: dynamic region-based quantization for deep neural network acceleration.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Restrictions apply. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Note that  RD upper bound  can vary across different use cases from parking lot to busy roads and hence, can be set accordingly \n1077 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "3  c  , and we observe that: ‚Ä¢  Compared to the two solid lines (the frame is partitioned into 20 blocks), the two dotted lines (when partitioned into 1000 blocks) are closer to the y-axis, indicating that a Ô¨Åner segment can better capture the temporal-locality. ‚Ä¢  Considering the dotted lines with 1000 segments parti- tioned from I- and P- Frames, the green line represents the smallest delta between two segments, which indicates the upper-bound/the scope of the attribute similarity, whereas the red line represents the largest delta/the least similarity among the segments. 3  b  , and a visual view of how these segments look like in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "To support faster inter-chip communication, which is essential for training, the chips can be interconnected using a fast fabric like NVLink [119], Infinity Fabric [13], or any newer technologies, and to cater inter-chiplet communication, which is essential for both training and inference, the chips can benefit from high-performance on-chip interconnect designs [10, 18, 31, 41, 108, 110, 116, 143]. The PI has extensive experience in designing on-chip interconnects for multicore architectures and will use the in-house simulation tools and other open-source network design tools [8, 19, 21, 116] to investigate the on-chip and inter-chip communication fabrics. Task-3.3: Handling Unforeseen Cases using Reconfiguration Besides having dedicated hardware for experts, there are three possible challenges which require adaption in hardware: the chiplets may incur failures, the work contained in inference is input dependent, and re- \ntraining is needed as part of continuous learning.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 222,
    "augmented": false
  },
  {
    "text": "50‚Äì56. [32] B. Luo, F. Xu, C. Richardt, and J. Yong, ‚ÄúParallax360: Stereoscopic 360¬∞ Scene Representation for Head-Motion Parallax,‚Äù  IEEE Transactions on Visualization and Computer Graphics , pp. 1545‚Äì1553, 2018.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "5 Implementation and Evaluation \nTo implement and evaluate  Salient Store  , we chose two different platforms ‚Äì 1) Using a server- grade system with two Xilinx-Samsung computational storage drive (AMD, b), and 2) Using amazon web services (AWS) F1 instances, which have AMD Alveo FPGA which can work as the compute capable of peer-to-peer communication and thereby enabling a computational storage platform. We use Vitis 2022.2 along with Xilinx Runtime Library (AMD & Xilinx) for programming the FPGAs in both computational storage drives and the Alveo card. The configuration of the server with Xilinx CSD has a 12-core Xeon bronze CPU with 128GB memory,  2 √ó 3.84TB CSDs, and  2 √ó 2TB SSDs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 197,
    "augmented": false
  },
  {
    "text": "Conventionally, training is much more compute intensive (compared to an inference), takes many iterations and hence has been given considerable attention for better accuracy and convergence time. However, given the preva- lence and demand of inferences, serving them on public cloud with a tight bound of latency, throughput and cost is becoming increasingly more challenging [ 7 ]. These inference queries are typically administered with strict response laten- cies of under one second [ 4 ].",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "IEEE, 2022, pp. 1073‚Äì1084. [106] R. Zhang, H. Tao, L. Wu, and Y. Guan, ‚ÄúTransfer learning with neural \networks for bearing fault diagnosis in changing working conditions,‚Äù Ieee Access , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Specifically, given a knowledge domain of  k  layers, we assign the structure to  k  adjacent FFNN expert layers in an EoE model, where the  i th layer indicates the  i th level of the knowledge. For in- \nstance, in a three-layer knowledge domain, NLP is under Artificial Intelligence (AI), which is under Com- puter Science (CS). When training, a document of NLP is first routed to CS in the first layer, then routed to AI, and NLP.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "{ FIRM } : An Intelligent Fine-grained Resource Management Framework for SLO-Oriented Microservices. In  14th  { USENIX }  Symposium on Operating Systems Design and Imple- mentation ( { OSDI }  20) . 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Explained below is the working of the proce- dure  ùê∏ùë†ùë°ùëñùëöùëéùë°ùëí _ ùê∂ùëúùëõùë°ùëéùëñùëõùëíùëüùë† in Algorithm 1 which is used to estimate function weights. To address this, we design a Weight Estimator  2a  to assign weights to all functions so as to allocate resources in propor- tion to them. Probability:  As alluded to in Section 2, one of the factors used in function weight estimation is its invocation probabil- ity.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "The discriminator tries to discriminate between the actual data and the synthesized data. We fine-tune the network until the discriminator is fooled sufficiently to distinguish between the original data and the recovered data. Considering the fact that we do have access to the sensor data to train the learning algorithm, we can use the same data to train the GAN and with sufficient data, the discriminator could generate the lost signal with minimum error.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2012.09988  (2020). Objectron: A Large Scale Dataset of Object-Centric Videos in the Wild with Pose Annotations. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed. When the traversal completes, an  Adder Tree  will be used to merge the partial sums for ReRAM columns and obtain the Ô¨Ånal MAC result. Note that, if the row- wise tiling factor is less than the ReRAM row number, this tiled execution strategy will introduce partial sums.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "The distance of this feature vector from the other cluster center is called ‚ÄúclassiÔ¨Åcation loss‚Äù [ 74 ], and this re-triggers clustering with an updated number of clusters. Since we have multiple teacher models, each of them contributes to the exemplar set, making it robust and removing bias. Over multiple time windows, the representation learner goes through all the possible exemplars selected by using the conÔ¨Ådence matrix and creates an exemplar set with same number of examples from each possible class.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "We also present a sensitivity study on how en- ergy savings and performance vary with different approximation factors in Sec. 5.4. 500 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Let  C i ( t )  represent the cost component: \nC i ( t ) =  e i ( t ) +  Œ≤V i ( t  + 1) , \nwhere  e i ( t )  is the total energy expenditure for participa- tion, encompassing data capture, inference computation, and communication: \ne i ( t ) =  e cap ( SNR i ( t )) +  e inf  +  e comm . The discount factor  Œ≤  ‚àà [0 ,  1)  captures how sensors value future utility, with  V i ( t  + 1)  representing the expected fu- ture utility given current decisions and predicted energy availability   ÀÜ E i ( t  + 1) . Overall Utility Function: Combining immediate rewards and costs, the overall utility function for sensor  s i  at time  t is: U i ( t ) =  R i ( t )  ‚àí C i ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 228,
    "augmented": false
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. locality opportunities (i.e., the smaller area, the better). Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Our policy updates  both  the teacher and student models for robust unsupervised learning. ‚Ä¢  We implement a  micro-proÔ¨Åler , which predicts the right set \nof hyper-parameters to efÔ¨Åciently perform the training tasks on an energy-harvesting edge server while operating within its power budget and minimizing data drift. ‚Ä¢  We design a  morphable hardware accelerator  that efÔ¨Å- \nciently maps training tasks, is suitable for intermittent computing, and can adapt its capabilities to reduce power emergencies without devolving to grid operation.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "If there is a match, the associated  P buff will return the memory address of the saved  P  so that we can reuse  P  and skip the  entire  coordinate projection computation (refer to  a  in Fig. The Effect of EA:  With this  EA  memoization, once a new head orientation is received, we Ô¨Årst search it in the two head orientation registers. 4), with only  1%  overhead w.r.t.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "A simple solution is to assign the accuracy of each of the sensors for every class as its weight. Although accuracy is a close measurement of the conÔ¨Ådence of the classiÔ¨Åcation, it does not truly reÔ¨Çect it. Furthermore, it the relative weight of each sensor is likely to shift from user to user.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Recent works try to solve this problem by augmenting these continuous learning edge servers with application-specific hardware targeted for intermittent computing which could run using solar power. However, all these works focus on the analytics part while overlooking one critical aspect:  what happens to all those video data after the analytics? Data Archival:  The answer is straightforward, especially for mission-critical public records like urban mobility and surveillance data: these need to be archived in a local storage to avoid under- mining the benefits of edge computation, i.e.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "With the target of achieving an efficient execution, we first want to understand the execution behavior. As discussed in Thrust-1, our expert repository allows us to plug-and-play experts to create diverse EoEs, thereby many types of experts exist within and across EoEs. Task-3.1: Expert/Hardware Co-Characterization To efficiently serve various application needs, the question we ask is  what are the intelligent ways to execute EoEs?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "DeepCache [8] has been proposed for trading layer-wise intermediate data memoization/caching for computation savings, but it ignores the frame-wise reuse op- portunities. From the hardware side, Euphrates [9] targets the frame-wise reuse, and customizes an accelerator for searching the regions of interest. Different from these two prior works, Potluck [12] caches the feature vectors (FVs) and correspond- ing inference results for key frames, and reuse the results for other frames with similar FVs, with the costs of FV extraction (e.g., down-sampling [16]) penalty and potential accuracy and/or performance drop due to sampling failures.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "2 In this paper, we mainly use the popular depthmap input method. 3 Five iterations of the GSW algorithm [63] are profiled. 496 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "[58]  Attila Reiss and Didier Stricker. In  PETRA , Fillia Makedon (Ed.). ACM.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "[83]  Neeraja J. Yadwadkar, Francisco Romero, Qian Li, and Christos Kozyrakis. In  2019 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 331‚Äì344. IEEE, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "[62]  Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Brad- bury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In  Advances in neural information processing systems , pages 8026‚Äì8037, 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "[196] Yanqi Zhou, Nan Du, Yanping Huang, Daiyi Peng, Chang Lan, Da Huang, Siamak Shakeri, David So, Andrew Dai, Yifeng Lu, Zhifeng Chen, Quoc Le, Claire Cui, James Laudon, and Jeff Dean. Brain- formers: Trading simplicity for efficiency. pages 42531‚Äì42542.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "Policies and Provisions for Reuse and Redistribution \nNo permission restrictions will be placed on the data. Academic researchers, industrial researchers as well as scientists working on AI/ML (especially generative AI and LLMs), systems, computer architecture, carbon-efficient cyberinfrastructure, compilers and performance evaluation areas would likely be interested in our data. Furthermore, no restriction on the reuse or redistribution of any artifact developed in this project will be placed for non-commercial use.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "https://community.intel.com/t5/Blogs/Tech-Innovation/Data-Center/ Intel-Labs-Showcases-Multi-Vendor-Computational-Storage-Platform/post/ 1404651 , August 2022. Intel labs showcases multi-vendor, computational storage plat- form. Michael Mesnier.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "In Augmented Reality, Virtual Reality, and Computer Graphics: 8th International Conference, AVR 2021, Virtual Event, September 7‚Äì10, 2021, Proceedings 8 , pp. Immersive insights: virtual tour analytics system for understanding visitor behavior. Roberto Pierdicca, Michele Sasso, Flavio Tonetto, Francesca Bonelli, Andrea Felicetti, and Marina Paolanti.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Unlike conventional storage servers,  Salient Store  discerns between the ‚Äúdata path‚Äù and the ‚Äúresource path‚Äù for system I/O calls, translating these requests into CSD-specific functions. These functions leverage FPGA kernels for efficient data processing. As discussed earlier, Salient Store  edge storage implements a video archival by using neural compression followed by a quantum safe encryption (refer Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "youtube.com/watch?v=WvtEXMlQQtI‚Äù, 2019. [44] Samsung, ‚ÄúSamsung Gear VR,‚Äù ‚Äùhttps://www.samsung.com/global/ galaxy/gear-vr/‚Äù. [45] Samsung, ‚ÄúExplore New Dimensions.‚Äù ‚Äùhttps://www.samsung.com/ global/galaxy/gear-vr/#display‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "The DNNs were trained on the training data-sets using the Keras [18] framework. C. Accuracy Results \nBaseline:  We choose two baselines for our evaluation: 1) Baseline-1 consists of the original DNNs built along the lines of [11], [14] (without any pruning). We use two different datasets, MHEALTH [12], [13], and PAMAP2 [16], [17], for our evaluation which follow the similar sensor setup described in Section IV-A.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "These variations can cause misclassiÔ¨Åcations and the adaptive nature of the conÔ¨Ådence matrix mitigates this. To mimic the noisy and inconsistent behaviour of real- world scenarios, we test the adaptive nature of the ensemble learner for 3 different previously unseen users over a 1000 iterations (10000 successful classiÔ¨Åcations; each iteration has 10 classiÔ¨Åcations). The noisy data is generated by adding a Gaussian noise (with maximum SNR of 20dB) over the unseen test data.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "In comparison,  Comm Only  and  Conn Only  fail to spawn enough containers for each important function as they do not consider both these parameters, resulting in increased tail latency and exacerbates the SLO violations. To- wards addressing these challenges, we design and evalu- ate  Kraken , a DAG workflow-aware resource management framework, for efficiently running such applications by uti- lizing minimum resources, while remaining SLO-compliant. 7 Concluding Remarks Adopting serverless functions for executing microservice- based applications introduces critical inefficiencies in terms of scheduling and resource management for the cloud provider, especially when deploying Dynamic DAG Applications.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2401.04088 , 2024. [75] Ziheng Jiang, Haibin Lin, Yinmin Zhong, Qi Huang, Yangrui Chen, Zhi Zhang, Yanghua Peng, Xiang Li, Cong Xie, Shibiao Nong, Yulu Jia, Sun He, Hongmin Chen, Zhihao Bai, Qi Hou, Shipeng Yan, Ding Zhou, Yiyao Sheng, Zhuo Jiang, Haohan Xu, Haoran Wei, Zhang Zhang, Pengfei Nie, Leqi Zou, Sida Zhao, Liang Xiang, Zherui Liu, Zhe Li, Xiaoying Jia, Jianxi Ye, Xin Jin, and Xin Liu. { MegaScale } : Scaling large language model training to more than 10,000  { GPUs } .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 236,
    "augmented": true
  },
  {
    "text": "Fur- ther, for those inferences unfinished because of the harvested energy constraints, it leverages task-aware coreset construc- tion to efficiently communicate compact features to the host device. We evaluate  Seeker  for human activity recognition, as well as predictive maintenance and show  ‚âà 8 . 9 √ó  reduc- tion in communication data volume with 86 .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "[67]  Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108 , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Restrictions apply. IV , and then treat the obtained delta values as new attributes, and Ô¨Ånally feed them again to the encoder to further increase the compression efÔ¨Åciency). as described in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "Under review. For example, many of the European cities restrict the traffic video data to be streamed to the cloud (www.dlapiperdataprotection.com; Achieving Compliant Data Residency and Security with Azure; Bhardwaj et al., 2022), which enforces performing video \nPreprint. However, regulations, resource limitations and privacy concerns often mandate these applications (both learning and inference) to be performed at the edge (Bhardwaj et al., 2022; Mishra et al., 2024).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "Therefore, an extra post-processing step is needed to merge these two arrays in the ‚Äúoccupy bits‚Äù style. As shown in Algo. 1 , to obtain the occupy bits for one branch node, we Ô¨Årst calculate which branches its children should be on (e.g.,  C [  j ] %8  in Line #5), and then merge all of its occupied branches via the ‚Äú | ‚Äù operation.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Energy Costs and Future Utility: Participation incurs energy costs, reducing the sensor‚Äôs capacity for future tasks. Here,  Œ¥ >  0  penalizes incorrect participation, discourag- ing sensors from submitting low-quality data, while  Œ∑ >  0 penalizes non-participation to prevent perpetual abstention. Importantly, we set  Œ∑ > Œ¥ , ensuring that consistently opting out is more detrimental than occasionally providing inaccu- rate data.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "6% , which is slightly better than  50 . 3%  provided by our approach. However, it results in almost twice the latency and energy consumption with respect to our approach.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Furthermore, solar power has reasonably predictability characteristics. Typ- ically, inference tasks have signiÔ¨Åcantly less compute time and power requirement, and commercial off the shelf devices, like edgeTPU [ 19 ] can perform object detection using the aforementioned compressed models at a reasonable frame rate (at times  ‚â• 71  f ps ). Therefore,  designing a training platform to perform continuous learning with the intermittent solar power and within the typical harvested budget  would be the best solution.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Prior works on intermittent learning have either chosen one teacher model \n900 \nAuthorized licensed use limited to: Penn State University. Impact on Exemplar Selection \nUs. ¬¥as  beneÔ¨Åts from the use of  multiple  teacher models for data annotation and exemplar selection.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Plan of Activities:  Aligned with the departmental BPC plan, we plan to pursue several activities related to this proposed research as summarized below: ‚Ä¢  Customized Graduate Student Recruiting and Training:  We will recruit graduate women and students from populations underrepresented in computing to work on this project. Broadening Participation in Computing (BPC) Plan: Connected \nSince this is a connected BPC plan, we only discuss the planned activities for the PIs, as specified in the submission guidelines. The approved departmental BPC plan is also included.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "These simplistic approaches ignore the interdependencies among sensor decisions and fail to account for future resource allo- cation, potentially leading to suboptimal performance over time. For instance, always selecting the highest-energy sen- sors can rapidly deplete their energy reserves, reducing the network‚Äôs resilience during critical future events. Alternatively, reinforcement learning or Markov Decision Process-based approaches could adaptively learn partici- pation policies that consider both immediate rewards and future states.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "In fact, only one input argument, i.e., the number of depth planes, requires to be changed based on the approximation factor  Œ± , when the object is outside of RoF. As shown by  Line#5  and  Line#7  in Algo. 2, our proposal can actually reuse the original hologram execution engine without any architectural modifications or reprogramming.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "To estimate the required energy, we ran simple HAR inferences (optimized version of [ 26 ] for edge deployment using [ 68 ]) on an Adafruit ItsyBitsy nRF52840 Express - Bluetooth LE [ 2 ] and found it to be consuming from 550mJ to 1.6J of energy (depending on the quantiza- tion). Compared to this, body movement and WiFi sources (the possible modalities of harvesting for HAR) harvests in order of milliwatts [ 22 ,  56 ], making it almost impossible to have a feasible EH-WSN deployment, with the capabilities to perform modest learning tasks, using the CotS. Therefore, there has been a significant body of work [ 40 ,  42 ,  47 ,  56 ] on developing appropriate next generation hardware (most of \n3 \nthem on simulation).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 197,
    "augmented": false
  },
  {
    "text": "[64] T. N. R. E. L. (NREL), ‚ÄúSolar resource maps and data,‚Äù  https://www. Park, and J. Kung, ‚ÄúFlexblock: A Ô¨Çexible \ndnn training accelerator with multi-mode block Ô¨Çoating point support,‚Äù IEEE Transactions on Computers , 2023. rel.gov/gis/solar-resource-maps.html , (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Corne Lukken and Animesh Trivedi. Past, present and future of computational storage: A survey. arXiv preprint arXiv:2112.09691 , 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, with our current ‚Äúsub-optimal‚Äù implementation (e.g., the codes are not fully optimized), the de-compression stage (including both geometry and attribute de-compression) for Redandblack video [ 55 ] only takes ‚âà 70 ms  per PC frame, which is less then the PC compression latency as we will discuss later in Sec. VI-C . Such signiÔ¨Åcant speedup comes with a reduction in quality.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Additionally, the PWS uses a DAG descriptor, which is a file that contains a python dictionary that specifies the connectivity among functions. Although constructing this is a one-time effort, automating this process through offline DAG profiling can be explored in future work. Table 4 gives an overview of Kraken ‚Äôs policies and their implementation details.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Salient Store  utilizes the state-of- the-art neural compression which partially uses the inference/ exemplar selection pipeline along with layered neural codecs to compress the video data. Solution Space and Our Work:  This paper proposes  Salient Store  , a novel storage solution designed for continuous learning edge servers by incorporating a hardware-software co-design framework that allows for efficient data archival and storage. Furthermore, the design  needs to be programmable  to ensure encryption keys to be changed regularly for additional security.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "In this paper, we refer to this combined scheme as  Inter-Intra-Holo . In this scheme, we first identify the objects in- side/outside the RoF ( Inter-Holo ), and then approximate each of them based on its shape and distance ( Intra-Holo ). Note that since the other option ‚Äì first  Intra-Holo , then  Inter-Holo  ‚Äì is theoreti- cally identical to the proposed  Inter-Intra-Holo , we skip its detailed discussion due to space limitation.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Generality of  HoloAR :  Although the core idea of approximation seems to be general across many video domains, our proposal is not expected to work very well for all AR applications. This figure shows a clear pattern of trade-offs between more-energy-savings vs. more-quality-drop. Specifi- cally, there are two classes of applications that would probably achieve only limited benefits from our approach.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "We Ô¨Årst describe the design conÔ¨Ågurations, experi- mental platform, datasets, and measurement tools used in this work, and then analyze the collected results. A. Design conÔ¨Ågurations \nBaseline:  We evaluate the baseline video object detection on an edge CPU 1 , where every frame is fully inferenced.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "629‚Äì642. Tigris: Architecture and Algorithms for 3D Perception in Point Clouds. In  Proceedings of the International Symposium on Microarchitecture (MICRO) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "First, we propose a Morton code-assisted intra-frame compression scheme, where  both  the geometry and attribute can be compressed in a  highly parallel fashion. ‚Ä¢  We propose two complementary designs to capture and utilize such spatio-temporal localities. We believe this is the Ô¨Årst work that applies the Morton code-based parallel octree construction algorithm [ 31 ] to speed up PC geometry com- pression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems . 1‚Äì12. [27]  Kyungjin Lee, Juheon Yi, Youngki Lee, Sunghyun Choi, and Young Min Kim.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Our preliminary results suggest that using a combination of VMs and serverless func- tions could potentially provide a solution to this problem. Therefore, these apparent deficiencies of choosing the appropriate resource type and model type for a given user re- quirement motivates the central question of this work:  Does there exist an optimal resource procurement system which can balance the goals of diverse user requirements for accuracy, latency and cost, by efficiently mapping model parameters to heterogeneous resource specifications? As opposed to prior works [ 5 ,  10 ], which try to combine serverless functions with VMs to hide the start-up latencies of VMs, our primary interest lies in exploring the different key aspects  to address when hosting DNN-based ML pre- diction serving systems in public cloud, as given below: ‚Ä¢  Diverse Models:  How to make the users oblivious of model selection from the extensive pool of models, for satis- fying the accuracy, and latency requirements?",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 217,
    "augmented": true
  },
  {
    "text": "IEEE, 2024. Alessandro Montanari, Manuja Sharma, Dainius Jenkus, Mohammed Alloulah, Lorena Qendro, and Fahim Kawsar. eperceptive: energy reactive embedded intelligence for batteryless sensors.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Identifying outlier arms in multi-armed bandit. In  Advances in Neural Information Processing Systems , pages 5204‚Äì5213, 2017. [88]  Sheikh Ziauddin and Matthew N Dailey.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "oculus.com/documentation/mobilesdk/latest/concepts/mobile-timewarp- overview/?locale=en US‚Äù, 2019. [38] Oculus, ‚ÄúAsynchronous TimeWarp (ATW).‚Äù ‚Äùhttps://developer. [39] Oculus, ‚ÄúOculus Rift and Rift S Minimum Requirements and Sys- tem SpeciÔ¨Åcations.‚Äù ‚Äùhttps://www.tomshardware.com/news/magic-leap- tegra-specs-release,37443.html‚Äù, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "In contrast, a game-theoretic framework provides equilib- rium guarantees, ensuring stable and cooperative partici- pation strategies. By modeling each sensor as a rational player optimizing its own utility, we can derive participation patterns that are robust against unilateral deviations. This stability is crucial for maintaining long-term network per- formance without necessitating continuous recalibration or extensive communication overhead.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "This equation infers that the Proba- bility Vector at the next time step is obtained by performing a transition operation across all possible current states. The Probability Vector after  ùëë number of time steps can be represented as  ùëÉ ùëë . Then, the Probability Vector for the next time step,  ùëë +  1, is given by the  transition equation ,  ùëÉ ùë° + 1  =  ùëá ¬∑  ùëÉ ùë° .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "5a ). The host writes the latest copy of the completed iteration (in epoch granularity) into the STT- RAMs (STT-RAM-N for the upper 128 SAs, and STT-RAM- S for the lower 128SAs, Fig. In case of a complete power failure, the compute in Ô¨Çight are rejected and, once the system starts working, the work queues get invalidated and the host starts the compute again from the last checkpoint.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "498 \nMICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 2.2) as well as the characteristics of the underlying hardware can potentially open up further opportunities. While such an approach improved the computational efficiency and reduced power consumption to some extent, rethinking the design of hologram software/hardware con- sidering the unique features of the AR holographic applications (as discussed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "The idea is to use the sensitivity to determine the probability: \np i  = Œ≤   P \nj ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \nmax \u0010P \nj ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \u0011 +  œµ \nwhere  Œ≤  is a scaling factor to adjust the overall dropout rate, and  œµ  is a small constant to avoid division by zero. Define a binary dropout mask  m  = [ m 1 , m 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "[77] Mahmut Kandemir, Taylan Yemliha, SaiPrashanth Muralidhara, Shekhar Srikantaiah, Mary Jane Ir- win, and Yuanrui Zhnag. Cache topology aware computation mapping for multicores. In  Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation , pages 74‚Äì85, 2010.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Note that, this computation still happens in planar-format, and remains the same between two-eyes for one frame. Targeting on ATW, PIMVR [57] proposed a 3D-stacked HMC to re- duce Motion-to-Photon latency and off-chip memory accesses. Motivated by the observation that the ATW transform matrix generated by rotation on a 2D image is shared by both eyes, PIMVR [57] calculated the transform matrix only once, and scheduled two tiles (one for left-eye one for right-eye) with the same coordinate to the same vault in HMC.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "From these graphs, it is evident that  Kraken  exhibits comparable performance to existing policies while having a minimal re- source footprint. For the  Social Network  application,  Kraken remains within 60 ms of the end-to-end response time of Arch  (Figure 9a), which performs the best out of all policies with respect to these metrics, while ensuring 99.94% SLO guarantees (Figure 10a) . However,  Arch  uses 4x the number of containers used by  Kraken  (Figure 10a).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "2.4 More Compute in Storage? Why Not? While the previous research has suggested the idea of integrating analytics into storage systems, these discussions usually revolve around system architecture, scheduling, and data management, without delving into the requisite compute capabilities (Haynes et al., 2021; Daum et al., 2021; Tsai et al., 2020; Xu et al., 2019).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Thus,  Kraken  makes use of PWS and RS to scale containers to meet the target SLOs while simul- taneously minimizing the number of containers by making use of function invocation probabilities, function batching, and container eviction, where appropriate. 4.1 Proactive Weighted Scaler We describe in detail the components of PWS below. 4.1.1 Estimating function weights : Since workflows in SDAs are pre-determined, pre-deploying resources for them is straightforward in comparison to DDAs, whose workflow activation patterns are not known a priori.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "NVIDIA Corporation. Nvidia rtx dlss. https://developer.nvidia.com/rtx/dlss , 2024.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Springer, 2020, pp. 929‚Äì945. [35]  G. G. Langdon, ‚ÄúAn introduction to arithmetic coding,‚Äù  IBM Journal of Research and Development , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "181‚Äì192. [46]  Ali Tariq, Austin Pahl, Sharat Nimmagadda, Eric Rozner, and Siddharth Lanka. 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "; iii)  What types of accelerator-based chiplets and chips perform better for training and inference of EoEs? ; ii)  What are the individual impacts of the op- timizations discussed in Thrusts 1-3, and what is their combined effect? Specifically, this thrust targets at answering the following questions: i)  What kind of simulation-emulation system is needed to carry out our experiments?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "To address this, we also utilize coreset construction using k-means clustering [ 8 ,  36 ,  37 ], which separates the data points into a set of k (or fewer) N-spherical clusters and represents the geometric shape of the data by using the cluster centers and cluster radii (Fig. 4). These are then communicated to the host device for inference.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "The cost is normalized to reactive scaling scheme. 1 hour sample of the real-world trace for request arrival time generation. Each request is derived from a pool of pre-trained ML inference models for image classification (as explained in Section  2 ).",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "In  To be presented in proceedings of the 57th Annual IEEE/ACM International Symposium on Microarchitecture , pages 62‚Äì76, 2024. [71] Rishabh Jain, Scott Cheng, Vishwas Kalagi, Vrushabh Sanghavi, Samvit Kaul, Meena Arunachalam, Kiwan Maeng, Adwait Jog, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita R. Das. Optimizing cpu performance for recommendation systems at-scale.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "IEEE, 2012. Maksim Godovykh, Carissa Baker, and Alan Fyall. Vr in tourism: A new call for virtual tourism experience amid and after the covid-19 pandemic.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "This further motivates us to look for opportunities in the data distribution to improve the compression ratio. 6) using clustering based techniques. Going above 12 \nclusters did not significantly improve accuracy.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "For instance, a real-time gaze-tracked foveated rendering system is proposed to yield performance and memory savings by avoiding shading up to 70% of the pixels for VR headsets [ 47 ]. Similarly, a prototype AR display also takes advan- tage of foveated rendering by tracking the user‚Äôs gaze and providing low-resolution images to the peripheral area to reduce computa- tion and improve display resolution [ 25 ]. More recently, another foveated rendering based CGH reconstruction technique has been proposed to accelerate calculations with negligible effect for the viewer [ 22 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "Thus, to cater to the execution diversity in experts, we intend to take advantage of ‚Äúheterogeneous‚Äù chiplets. Using the above profiling, for each expert in each EoE when run over a variety of hardware platforms, we can systemati- \nSilicon Interposer \nIntra-Chip Network Fabric \nHomogeneous Chip \nHeterogeneous Chip \nIntra-Chip Network Fabric \nSilicon Interposer \nFigure 6 :  Our proposed chip infrastructure. Each chip can potentially contain a set of homogeneous or heterogeneous chiplets including accelerator engines, reconfigurable engines, CPUs, GPUs, and various types of memory modules.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "463‚Äì468, 2005. [12]  S. Sudevalayam and P. Kulkarni, ‚ÄúEnergy harvesting sensor nodes: Survey and implications,‚Äù  IEEE Communications Surveys Tutorials , vol. 13, no.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "The compiler and system software code and other design artifacts will be maintained in both source formats (e.g., C/C++/C#/Python files) as well as in binary, in an open-source fashion. The educational material will be stored in text, MSWORD, PowerPoint, PDF, and various video formats. When needed, this material will be ported to other formats as well.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "2  Further, this locality also exists in attributes (RGB pixels), i.e., spatial locality leads to attribute similarities, and hence opening opportunities for fast attribute compression. Motivated by these opportunities, we propose and evaluate a two-pronged compression approach, where the  intra-frame approach leverages the opportunities described in 1  and 2  , and the  inter-frame  approach takes advantage of 3  . 3  And, Ô¨Ånally, the locality extends beyond a single frame, i.e., the temporal locality, which can be leveraged by sorting the points in the Morton code order, creating further opportunities to improve the compression efÔ¨Åciency.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2007.03051 , 2020. Apache¬Æ Subversion¬Æ. [15] Apache Software Foundation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "IEEE, 2017. { GRACE } : { Loss-Resilient }{ Real-Time }  video through neural codecs. Yihua Cheng, Ziyi Zhang, Hanchen Li, Anton Arapin, Yue Zhang, Qizheng Zhang, Yuhan Liu, Kuntai Du, Xu Zhang, Francis Y Yan, et al.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "In this section, we will explain, in detail, the overall execution workflow of the  Seeker  system, followed by the the detailed design of the hardware support to maximize its energy efficiency. 4.1 Decision Flow: From Sensors to the Host Figure 8 depicts a flow chat showing the decision process taken in the sensor nodes to navigate between each compo- nents. Each sensor has a data buffer that collects the data points for classification (implemented using a 60  √ó 3 FIFO structure of 4Byte cells to store the floating point data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "We store ground truth sensor data pattern for all possible labels, and when new data arrives, we find the correlation of the sampled data against the ground truth data, and if any of the correlation coefficient \n6 \nPower-Pred \n+ Decision Logic (MCU) \nCorrelation \nSensor Data \n16bit DNN (x-bar) \n12bit DNN (x-bar \nCoreset: Imp \nSmp/Clust. Wireless \nCommunication \nH S/C \nM Harvestor \nSensor Node \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nHost \nSeeker Ecosystem \nCoreset Reconstruct \nDNN for Recovery \nDNN for Inference \nEnsemble \nEngine \nCluster Recovery \nClassfied Results \nFigure 5: Overall system design of Seeker \ncomes out to be  ‚â• 0 . 95, we choose to ignore further infer- ence computation and only communicate the classification result to the host for further processing.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 197,
    "augmented": false
  },
  {
    "text": "Also, we suggest service providers should handle the pre-warming decision by knowing model-wise usage statistics to enable instance sharing, which uses the same models. Rather than capitalizing on such design hacks, we need to develop prediction policies to estimate load correctly. This would lead to a reduction in cold-start latencies incurred for users with the same type of requests.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Since the primary contribution in  Cocktail  is to provide high accuracy and low latency predictions at cheaper cost, appli- cation developers can adapt the prediction algorithm to their needs or even plug-in their own prediction models. C System Overheads \nWe characterize the system-level overheads incurred due to the design choices in  Cocktail . The  mongodb  database is a centralized server, which resides on the head-node.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "[27] S. Han, H. Mao, and W. J. Dally, ‚ÄúDeep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding,‚Äù  arXiv preprint arXiv:1510.00149 , 2015. [28] Y.-D. Kim, E. Park, S. Yoo, T. Choi, L. Yang, and D. Shin, ‚ÄúCompression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications,‚Äù  arXiv preprint arXiv:1511.06530 , 2015. [29] C. Louizos, K. Ullrich, and M. Welling, ‚ÄúBayesian Compression for Deep Learning,‚Äù in  Proceedings of the 31st International Conference on Neural Information Processing Systems , 2017, p. 3290‚Äì3300.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 201,
    "augmented": false
  },
  {
    "text": "Otherwise, if the expression  Condition trans \nis not satisÔ¨Åed, with power prediction, we can still speculatively attempt to perform a smooth transition. There are two strategies to achieve this. ‚Ä¢  We can search for an intermediate power level, where we Ô¨Årst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level ‚Äì this strategy is called  Multi-step Transition .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "This strategy capitalizes on the robust, pre-trained features of MobileNet, which are frozen during training to ensure their integrity and to leverage their proven capability in capturing essential visual features. The extraction of motion vectors between frames further enriches the feature space by incorporating temporal dynamics essential for effective compression. The codec‚Äôs autoencoder component, which is trainable, is then tasked with compressing these enriched features.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "3: Accuracy-latency comparison of different policies with differ- ent distributed setup. The edge execution is done on a raspberry Pi, and the cloud is mimicked by a desktop class machine. Considering the scale of the problem, the execution time on a desktop machine is almost same as a larger cluster that we typically find in a cloud.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Accessed: 2023-10-20. [95] Shiyao Li, Xuefei Ning, Ke Hong, Tengxuan Liu, Luning Wang, Xiuhong Li, Kai Zhong, Guohao Dai, Huazhong Yang, and Yu Wang. Llm-mq: Mixed-precision quantization for efficient llm deployment.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Opportunities \nExploring and exploiting computation output reuse oppor- tunities is non-trivial in this context. First of all, the projec- tion transformation is multi-staged and is a composition of multiple mathematical operations, e.g., transformation matrix, projection computation, mapping, etc. As discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "A review on ensembles for the class imbalance problem: Bagging-, boosting-, and hybrid-based ap- proaches. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews) , 42(4):463‚Äì484, 2012. [34]  Arpan Gujarati, Sameh Elnikety, Yuxiong He, Kathryn S. McKinley, and Bj√∂rn B. Brandenburg.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "ResiRCA supports smooth transi- tions among different activation solutions against computation loss. The experiment results show that the proposed ResiRCA along with the ResiSchedule scheme can achieve much higher speedups and energy efÔ¨Åciency compared to the baselines. ResiRCA for the Ô¨Årst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "While several studies have shown the benefits of performing more inference closer to the point of data collection [ 23 ,  30 ,  31 ,  40 ,  56 ] and have ap- plied these techniques to more powerful edge devices, their form-factor-imposed limited energy storage, low-power op- eration points, and deployment scenarios have been a major impediment in executing compute-intensive inference tasks directly on such platforms. In contrast, communicating the data, often after little preprocessing, although popular, is not cheap in terms of power requirement, and often poses a challenge for remotely deployed and ultra low power WSNs. Prior works, trying to tackle this conflict between computa- tion, communication, power-requirement and quality of ser- vice (QoS), have pursued three major approaches: inference effort partitioning optimizations [ 22 ,  30 ,  31 ,  50 ], mitigation of energy provisioning limitations [ 24 ,  40 ,  43 ,  47 ,  56 ], and minimizing communication overheads [32, 33, 36, 37, 45].",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 246,
    "augmented": false
  },
  {
    "text": "This means that the object in question has been moving towards a direction, which triggers a ‚Äúposition change‚Äù event. However, as we can see from  6  in Fig. Consequently, to reÔ¨Çect this event, Frame-3 needs to perform a full inference.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "In Proceedings of the 2013 conference on empirical methods in natural language processing , pages 1631‚Äì1642, 2013. [73]  Mingxing Tan and Quoc V Le. EfÔ¨Åcientnet: Rethinking model scaling for convolutional neural networks.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "2.1) ‚Ä¢  From two open-source AR datasets [ 1 ,  58 ], we identify two prop- erties in AR hologram applications:  spatio diversity for objects , and  temporal locality for the user (viewer) interests (i.e., user typ- ically focuses on one region within a short period of time) . The major  contributions  of this work can be summarized as follows: ‚Ä¢  We first conduct a detailed characterization of a generic AR processing pipeline to identify the major bottlenecks in current state-of-the-art AR headsets, and set our optimization target as the  hologram computation . (Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "Springer, 2015. Ziyu Ying, Shulin Zhao, Sandeepa Bhuyan, Cyan Subhra Mishra, Mahmut T. Kandemir, and Chita R. Das. Pushing point cloud compression to the edge.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "In each inference event, sensors decide whether to partic- ipate. If sensor  s i  participates at time  t , it must capture data at a chosen Signal-to-Noise Ratio (SNR), process the data using  f Œ∏ , and transmit the result to a designated  lead sensor . High-SNR data capture improves the sensor‚Äôs con- tribution to global accuracy but consumes more energy.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "This offers two key advantages: first, it enables agile adaptation and targeted training to respond to evolving knowledge domains and user requirements; and second, it allows for optimization across different system layers to improve both architectural efficiency and overall performance. The modular nature of our system allows experts to be trained separately and then combined in multiple configurations. Tree Structure \nGraph¬† Structure \nChain Structure \nExpert¬† Function \nForward¬† \nPass \nType/ Subtype \nRouter 1 Router 2 \nRouter 1 \nRouter 2 \nCompo- \nsition \nTask-1.1 to Task-1.2 \nTask-1.2 to Task-1.4 \nTask-1.2 to Task-1.3 \nExpert Splitting \nData \nData \nData \nExpert Merging \nAn Expert from¬† Trained¬† EoE  Model¬†¬† \nTrain ¬†on Domain Datasets \nReinforced  EoE  Expert \nwith New Knowledge \nRemove ¬†Components of Expert¬† Add  Components of Expert \nContinual Learning \nAvaliable¬† Accelerators \nRemove Uncommon¬† \nPathes \nUser¬† Preferences Remove Unwanted \nExperts & Reform \nUser Logs \nRemove Unavaliable \nExperts & Reform \n¬† Experts \nUser Selected/ Unavaliable¬†Experts \nCommonly Routed¬† \nPath \nEoE  Network \nMemory Constraint \nAccelerator \nConstraint \nDomain Experts Skill Experts \nLanguage Experts Data Experts \nMedical Science Law Finance Math Code Retrieval \nDocument Table Image \nGraph \nEN CN TR HI \nSumma- \nrization \nFigure 3 :  An overview of four tasks in Thrust-1.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 295,
    "augmented": true
  },
  {
    "text": "Airbnb AWS Case Study. https://aws.amazon.com/solutions/ case-studies/airbnb/. [2]  2019.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "Under review. arXiv:2408.13696v2  [cs.LG]  26 Jan 2025 \n(NAS) (Yang et al., 2018, 2017; Mendis et al., 2021), there is no guarantee that the energy income con- sistently meets or exceeds this average. When the income falls below the threshold, the system halts the inference and checkpoints the intermediate states (via software or persistent hardware) (Maeng & Lucia, 2018; Qiu et al., 2020), resuming upon energy recovery.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Optimization Variables, Constraints, and Objective Function:  The optimization problem is formulated with variables: the weights  W , dropout rates  d , quantization levels  q , and QuantaTask sizes  ‚Ñì . The objective is to minimize the total loss, including prediction loss and regularization terms penalizing energy consumption (subject to energy constraints): \nmin W , d , q , ‚Ñì L (   ÀÜ Y ,  Y ) +  Œª 1 \nM X \nj =1 c q ( q j ) +  Œª 2 \nN X \ni =1 c d ( d i ) . (3) \nFormulation of the Composite Optimization Problem:  The problem is non-convex due to the discrete nature of quantization levels and dropout rates.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 188,
    "augmented": true
  },
  {
    "text": "Archipelago: A scalable low-latency serverless platform. [45]  Davide Taibi, Nabil El Ioini, Claus Pahl, and Jan Raphael Schmid Niederkofler. arXiv preprint arXiv:1911.09849  (2019).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "2020. Objectron Dataset Annotation: bottle. \"https://github.com/ google-research-datasets/Objectron/blob/master/index/bottle_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "1‚Äì6, 2018. [29]  N. Wang, J. Choi, D. Brand, C. Chen, and K. Gopalakrishnan, ‚ÄúTraining deep neural networks with 8-bit Ô¨Çoating point numbers,‚Äù in  Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018, Montr¬¥eal, Canada. , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "A. Computation decomposition and parallelism \nIf the harvested power  P   budget   is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress. For active RCAs, one option is to use loop tiling to decompose computations, and the other is to parallelize computations. The parallelism in this context is of two types:  intra layer parallelism via layer duplication  and  inter layer parallelism via layer pipelining .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Although current commercial devices are capable of handling inference at the edge, the power and resource requirements of training make it impractical and unsustainable for all edge nodes to also perform continuous training off of grid power. In this work, we design  Us. ¬¥as , a sustainable continuous learning platform, which can perform video analytics by using an inter- mittent power source like solar power.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Second, processing a typical PC with  1 M points in a fully-parallelized fashion poses very high demands on the GPU resources (e.g., the number of available threads or the memory budget), which are quite limited, especially in edge devices. More interestingly, software-level optimizations for this step have been fully exploited (e.g., the kernel functions are invoked in a fully-parallelized manner), yet it still dominates the latency and energy. First, these are the most frequently invoked kernels during the block matching stage.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "¬¥as  emerges as a promising solution, effectively achieving sustainable and carbon-neutral continuous learning at the edge, addressing critical challenges related to power constraints and environmental impact. Alternate Solutions:  Although  Us. Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "2:  Accuracy of the individual DNNs and with a majority voting ensemble for different activities. Fig. To design these DNNs, we leverage the work in [11], [14] and further apply state of the art optimizations given in [3], [15] to make the DNN more suitable for energy-scarce applications.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "[90]  T. Xu, B. Tian, and Y. Zhu, ‚ÄúTigris: Architecture and algorithms for 3d perception in point clouds,‚Äù in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2019, p. 629‚Äì642. [91]  X. Yan, C. Zheng, Z. Li, S. Wang, and S. Cui, ‚ÄúPointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling,‚Äù in  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2020. 299 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "If the learning has to be unsupervised, one needs to experiment with known clustering techniques to decide the right classiÔ¨Åcation approach. Moreover, the algo- rithmic contributions can be extended into any classiÔ¨Åcation based application or data modality. We demonstrate this by testing the exemplar selection and the Œº ‚àí proÔ¨Åler with different modalities of data.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Technical report, National Institute of Standards and Technol- ogy (NIST), 2023. URL  https://www.nccoe.nist.gov/sites/default/files/2023-12/ pqc-migration-nist-sp-1800-38b-preliminary-draft.pdf . Accessed: 2024-08-01.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "[18]  Eugene d‚ÄôEon, Bob Harrison, Taos Myers and Philip A. Chou, ‚ÄúJPEG Pleno Database: 8i Voxelized Full Bodies (8iVFB v2) - A Dynamic Voxelized Point Cloud Dataset,‚Äù  ‚Äùhttps://bit.ly/ 3cJQ61a‚Äù , 2017. [19]  Y. Feng, S. Liu, and Y. Zhu, ‚ÄúReal-time spatio-temporal lidar point cloud compression,‚Äù in  2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2020, pp. 10 766‚Äì10 773.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "Optimization Variables, Constraints, and Objective Function:  The optimization problem is formulated with variables: the weights  W , dropout rates  d , quantization levels  q , and QuantaTask sizes  ‚Ñì . The objective is to minimize the total loss, including prediction loss and regularization terms penalizing energy consumption (subject to energy constraints): \nmin W , d , q , ‚Ñì L (   ÀÜ Y ,  Y ) +  Œª 1 \nM X \nj =1 c q ( q j ) +  Œª 2 \nN X \ni =1 c d ( d i ) . (3) \nFormulation of the Composite Optimization Problem:  The problem is non-convex due to the discrete nature of quantization levels and dropout rates.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 188,
    "augmented": false
  },
  {
    "text": "0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 \n0 0.10.20.30.40.50.60.70.80.9 1 \nPower Utilization \nPower efficiency \nPiezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG \nFig. It can be observed from these results that the proposed  ResiSchedule  strategy can make good use of the  Piezo source when it does exceed the minimal activation thresholds, though the very low duty cycle yields very low throughput. An ideal system would be at the point (1,1).",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 170,
    "augmented": true
  },
  {
    "text": "Simulation results demonstrate that our integrated approach signif- icantly enhances inference accuracy and energy efficiency compared to traditional participation strategies. 1. Introduction \nThe rapid proliferation of the Internet of Things (IoT) has sparked a tremendous growth in the scale and diversity of sensor deployments, from smart homes to expansive in- dustrial and environmental monitoring systems.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Else- vier. [49]  Reem E Mohamed, Ahmed I Saleh, Maher Abdelrazzak, and Ahmed S Samra. 2018.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "VI-A ) used for our analyses, e.g., experimental platform, dataset, and different designs (Sec. VI-B ). We then compare those design schemes on our platform (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "We assume the output to be correct if majority of them, i.e. ‚åä N / 2 ‚åã + 1  of them give the same result. Then, the Ô¨Ånal ac- curacy of this ensemble would be the probability of at least ‚åä N / 2 ‚åã + 1 of them giving a correct result.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "x  is the input text,  D  is the document for retrieval, and  T  is the length of the generated text. Œ±  indicates the weight of  M  experts,  i  is the index of the layer in LLM,  W ,  A ,  B  and  h  are the weight matrix and hidden vector,  f Œ∏ is the neural network component parameterized by  Œ∏ . Method Function \nRouting Function \nMixture-of-experts Œ± i  =  SoftMax ( W i h i ‚àí 1 ) Variable size Œ± i  =  { a > k | a  ‚àà SoftMax ( W i h i ‚àí 1 ) } Top-k learned routing Œ± i  =  TopK ( SoftMax ( W i h i ‚àí 1 )) \nExpert Function \nFeedforward network h i  =  W i h i ‚àí 1 Prompt tuning h i  =  f Œ∏ i ( œï i ,  h i ‚àí 1 ) Low-rank adaptation W i  =  W ‚Ä≤ i   +  AB Large language model Œ∏  =  argmax Œ∏ \nQ T t =1   p Œ∏ ( y t | x, y j<t ) Retrieval augmented generation Œ∏  =  argmax Œ∏ \nP \nz ‚ààD   p Œ∏ ( z | x ) p Œ∏ ‚Ä≤ ( y | x, z ) \nComposition Function \nRepresentation averaging h i  =   P M j =1   Œ± i h i,j Weight summation W i  =   P M j =1   W i,j Sequential aggregation f Œ∏ ‚Ä≤  =  f œï M  ( f œï M ‚àí 1 ( ¬∑ ¬∑ ¬∑  f Œ∏ )) \nTable 1 :  Different methods for three building blocks of our EoE framework: Rout- ing, Expert, and Composition.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 454,
    "augmented": true
  },
  {
    "text": "doi: 10.1109/ICDCS54860.2022.00107. 1073‚Äì1084, 2022b. Hang Yue, Laurence R Rilett, and Peter Z Revesz.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "MICRO ‚Äô21, October 18‚Äì22, 2021, Virtual Event, Greece ¬© 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8557-2/21/10...$15.00 https://doi.org/10.1145/3466752.3480056 \nKEYWORDS \nAugmented Reality, Holographic Processing, Approximation, Energy-efficiency \nACM Reference Format: Shulin Zhao, Haibo Zhang, Cyan S. Mishra, Sandeepa Bhuyan, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. 2021.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "[53] B. Makuza, Q. Tian, X. Guo, K. Chattopadhyay, and D. Yu, ‚ÄúPy- \nrometallurgical options for recycling spent lithium-ion batteries: A comprehensive review,‚Äù  Journal of Power Sources , vol. 491, p. 229622, 2021. USENIX Association, 2018.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "The w-pdown  triggers the  backup  signal and the system goes into pwr-warning  state (other states being on, off, invalid and X). The network only gets activated when it gets a  w-pdown warning signal from the predictor. This signal starts a graceful power-down sequence for the required number of tiles.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "(GiGa MACs/s)/ Power utilization \nPower consumption with resilient acti. Power ( ¬µ W) \nPower consumption with full-size acti. ( ¬µ W)/ Thr.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "). While federated learning has gained significant attention in mobile and IoT devices, applying it to EH-WSNs presents unique challenges due to intermittent participation, limited computational capabilities, and variable data quality ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Results:  Table 1 shows the accuracy of our approach against the baselines and the recent state-of-the- art methods using the TI MSP board powered by piezoelectric energy harvesting. The inferences meeting the SLO requirements are the only ones considered for accuracy; i.e., a correct classification violating the latency SLO is considered as ‚Äúincorrect‚Äù. Datasets Full Power AP PT iNAS+PT Stateful ePerceptive DynBal NExUME \nFMNIST 98.70 71.90 79.72 83.68 85.40 86.25 87.50 88.90 CIFAR10 89.81 55.05 62.00 66.98 68.50 70.20 71.75 76.29 MHEALTH 89.62 59.76 65.40 71.56 73.80 74.95 76.10 80.75 PAMAP 87.30 57.38 65.77 70.33 72.20 73.35 74.50 75.16 AudioMNIST 88.20 67.29 73.16 75.41 76.80 77.95 78.60 80.01 Table 1: Accuracy comparison on TI MSP board using piezoelectric energy harvesting.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 300,
    "augmented": true
  },
  {
    "text": "Interestingly, in order to include  P 2 , the current bounding box has to expand its side length by  4 √ó , i.e., enlarging from  2  to  8 , and now the octree also contains more levels with all three points being in its leaf level. Obviously, both the bounding box and the octree are updated point-by-point, which forces the pipeline to be sequential. In our proposal shown in the lower Ô¨Ågure, instead of constructing the octree in a point-by-point fashion, we process all three points as one ‚Äúbatch‚Äù in the  Morton Code Generation step in parallel, and output the Ô¨Ånal bounding box cuboid with side lengths 4 √ó 3 √ó 3 (x-axis: 3-(-1) =4, y-axis: 3-0 =3, and z-axis  3 - 0  = 3 ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 209,
    "augmented": false
  },
  {
    "text": "\"https://www.ifixit.com/Teardown/Magic+Leap+One+Teardown/112245\". Magic Leap One Teardown. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "Further, if we can  dynamically  exploit this opportunistic similarity (i.e., the inference is invoked based on runtime contents), the solution can encompass most vision applications without affecting the current hardware stack. 0% \n20% \n40% \n60% \n4x4 8x8 16x16 32x32 1080x1920 Tile Size \n<0.1%  \nIdentical Tiles \n(a) Similarity study at different tile size across adjacent frames for a video in VIRAT dataset [33]. 0% \n5% \n10% \n15% \n0 2 4 6 8 10 12 14 16 Pixel-level Difference \n95% of the pixels differ within 3 \n(b) Distribution of pixel-level difference across two adjacent frames.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "Using the equation above we Ô¨Ånd the probability to be \nP head  = 10 ‚àë i = ‚åä 10 \n2   ‚åã + 1 = 6 \n\u0012 10 i \n\u0013 0 . 7 i   ( 1 ‚àí 0 . 7 ) ( 10 ‚àí i )   =  0 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Hello bytes, bye blocks: Pcie storage meets compute express link for memory expansion (cxl-ssd). 45‚Äì51, 2022. In  Proceedings of the 14th ACM Workshop on Hot Topics in Storage and File Systems , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "We have validated its correctness by correlating various metrics of interest generated from experiments run on the real system with scaled-down versions of the same traces (average ar- rival rate of  ‚àº 100rps). Therefore, the simulator allows us to evaluate our model for a larger setup, where we mimic an 11k core cluster which can handle up to 7000 requests (70 √ó more than the real system). Additionally, it helps compare the resource footprint of  Kraken  against a clairvoyant policy (Oracle) that has 100% load prediction accuracy.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "He will lead Thrust-3 and also co-lead Thrust-4 with Co-PIs Zhang and Kandemir. The specific responsibilities of the PIs and their complementary expertise are explained below: Chitaranjan Das (PI):  Das is the PI of the project and will be responsible for the overall coordination and progress as planned in the project schedule. His expertise includes multicore architectures, architectural op- timization of ML kernels, on-chip and chip-to-chip interconnect design, cloud computing, and performance evaluation.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "LLaMA-3.1 405B: Pre-trained Language Model. Hugging Face Model Repository, 2023. Available at:  https://huggingface.co/meta-llama/Llama-3.1-405B .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "This example illustrates 3 consecutive frames processing, each of which consists of two projection matrices ( P L and  P R ) for both eyes. The  3 rd frame shares the same head orientation with the  1 st, thus can be optimized by  EA . Moreover, the reuse between both eyes is further optimized by  AE .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "ObjSize \n(a) Object study. 0 \n0.5 \n1 \n0 0.5 1 \nPupi Postion Y \nPupil Position X \n0 \n0.5 \n1 \n0 0.5 1 \nPupil Position Y \nPupil Position X \n0 \n0.5 \n1 \n0 0.5 1 \nPupil Position Y \nPupil Position X \nUser1: \nUser2: \nUser3: \n(b) User eye tracking study. Figure 3: Dataset study.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "ACKNOWLEDGMENTS \nThis research is supported in part by NSF grants #1763681, #1629915, #1629129, #1317560, #1526750, #1714389, #1912495, and #1909004. We believe that the lessons learned from this work will help in designing next-generation hologram accelerators that can combine approximation as well as other optimizations such as tuning PU counts, frequency, and power gating for achieving the target performance and energy efficiency for edge devices. 7 √ó  speedup and 73% \nenergy savings.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "5.5. 4.3 Inter-Holo Computation Optimization \nWe first answer how to deploy the previously proposed foveated rendering technique on AR holograms, by investigating how to leverage the temporal similarity when the user‚Äôs region of focus is only a part of the entire viewing window, as mentioned earlier in Sec. 2.2 (Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "F.1.1 depth-wise Separable Convolution 2D Using Conv1D \nThe pseudo code described in Algorithm 1 implements a depth-wise separable convolution 2D (DWSConv2D) using a 1D convolution primitive function (conv1D). Here we describe the implementation of depth-wise sep- arable convolution 2D using the Low Energy Accelerator (LEA) in Texas Instruments‚Äô MSP430 microcontrollers. 24 \nF Pseudo Codes \nF.1 Depth-wise Separable Convolution 2D Using TI LEA \nDepth-wise separable convolution is an efficient form of convolution that reduces the computational cost compared to standard convolution.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 168,
    "augmented": true
  },
  {
    "text": "2. Ensure  Œª 1  ‚â§ c 1 G 1   and  Œª 2  ‚â§ c 2 G 2   for some constants c 1 , c 2  >  0 , to prevent excessively large gradients due to the regularizers. 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "2019.00259. Mahdi Torabzadehkashi, Siavash Rezaei, Ali HeydariGorji, Hosein Bobarshad, Vladimir Alves, and Nader Bagherzadeh. Computational storage: an efficient and scalable platform for big data and hpc applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Method Function \nRouting Function \nMixture-of-experts Œ± i  =  SoftMax ( W i h i ‚àí 1 ) Variable size Œ± i  =  { a > k | a  ‚àà SoftMax ( W i h i ‚àí 1 ) } Top-k learned routing Œ± i  =  TopK ( SoftMax ( W i h i ‚àí 1 )) \nExpert Function \nFeedforward network h i  =  W i h i ‚àí 1 Prompt tuning h i  =  f Œ∏ i ( œï i ,  h i ‚àí 1 ) Low-rank adaptation W i  =  W ‚Ä≤ i   +  AB Large language model Œ∏  =  argmax Œ∏ \nQ T t =1   p Œ∏ ( y t | x, y j<t ) Retrieval augmented generation Œ∏  =  argmax Œ∏ \nP \nz ‚ààD   p Œ∏ ( z | x ) p Œ∏ ‚Ä≤ ( y | x, z ) \nComposition Function \nRepresentation averaging h i  =   P M j =1   Œ± i h i,j Weight summation W i  =   P M j =1   W i,j Sequential aggregation f Œ∏ ‚Ä≤  =  f œï M  ( f œï M ‚àí 1 ( ¬∑ ¬∑ ¬∑  f Œ∏ )) \nTable 1 :  Different methods for three building blocks of our EoE framework: Rout- ing, Expert, and Composition. Œ±  indicates the weight of  M  experts,  i  is the index of the layer in LLM,  W ,  A ,  B  and  h  are the weight matrix and hidden vector,  f Œ∏ is the neural network component parameterized by  Œ∏ . x  is the input text,  D  is the document for retrieval, and  T  is the length of the generated text.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 454,
    "augmented": false
  },
  {
    "text": "This is because  Kraken  limits the number of containers spawned through function weight assignment and request batching. DProb  and  SProb  both exhibit higher utilization compared to  Kraken  (15%) as a result of spawning fewer containers overall, owing to not accounting for  crit- ical  and  common  functions while provisioning containers. Consequently, they exhibit up to 0.24% more SLO Violations compared to  Kraken , for this workload mix.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "At runtime, ResiSchecule dynamically selects activation solutions from either  Sequential  or  Pipelining  in each power cycle, depending on which can provide a better throughput. With  ResiSchedule , we can cover a large tuning range commensurate with power supply variation. Section  V-C will further present quantitative analysis and solution on how \ntoÔ¨Ågureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "[111] Mohammed Muqeeth, Haokun Liu, and Colin Raffel. ACM SIGARCH Computer Architecture News , 39(3):389‚Äì400, 2011. Soft merging of experts with adaptive routing.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Clustering Recovery \nOriginal Data Coreset Recovered Data \n(a) Recovering a cluster with uniform random re-distribution. Latent Space \nG \n \nGenerator \nNoise D \n \nDiscriminator \nGenerated Sample \nActual Sample \nRecovered Signal \nClose to \nactual? Finetune \n(b) Recovering a sub-sampling with GAN.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Prior Work \nPrior work for enabling inferences on edge devices have focused on hardware as well as software optimizations, which can be further classiÔ¨Åed into model compression and pruning, and compiler and runtime support. 1) Hardware Optimizations:  Traditionally, CPUs and GPUs have been recruited for DNN inference on mobile phones. Al- though DNN inference is highly structured and embarrassingly parallel, the limited resources on the mobile devices, alongside \nthe required off-chip data movements, poses a signiÔ¨Åcant challenge leading to higher latency.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "A CKNOWLEDGMENT \nWe thank the anonymous reviewers for their helpful feed- back and suggestions towards improving the paper content. This research is supported in part by NSF grants #1931531, #1955815, #2116962, #2122155 and #2028929. Additionally, the experimental analysis indicates that our approach outperforms the state-of-the-art work with respect to accuracy and/or performance/energy savings.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "As for \n8 The geometry PSNR are excellent for all designs (e.g.,  >  70dB), so we only compare the PSNR for attributes in the evaluations. the quality, it drops the PSNR by 7 . 2dB when compared to TMC13, due to the macro block-based approximation for the inter-frame compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "[147] Haizhou Shi, Zihao Xu, Hengyi Wang, Weiyi Qin, Wenyuan Wang, Yibin Wang, and Hao Wang. PMLR, 2023. In  International Conference on Machine Learning , pages 31094‚Äì 31116.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "; v)  What is the estimated training time given the size of input data and choice of model architecture? ; vi)  What are the desired architectural details of accelerators employed to do training/inference? ; and vii)  What are the performance, power and accuracy tradeoffs in training or inference, given hyper-parameters like the size of training dataset and the length of prompt?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Yet, the expansion of these technologies to encompass large-scale storage stacks and the integration of CSDs into conventional storage systems, particularly for ML applications, remains a significant challenge and an open area of research. Historically, researchers have investigated these components individually, often focusing on high- performance computing, scientific computing, and database applications. Bridging the Gap in Storage System Design:  There is a discernible gap in the design and concep- tualization of storage drives, systems and servers, especially in the context of ML applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "4%  in YOLOv3, and  0 . With the FI+SI+PI scheme on the other hand, the mAP drops  1 . 4%  for YOLOv4-tiny.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "What are the potential opportunities? B. Increasing Geometry Compression Parallelism Using Morton Code:  As mentioned earlier, the reason why the ‚Äúsequential update‚Äù is necessary is that, during the interme- diate stages, the  global  Octree (the Ô¨Ånal tree constructed at the last step) is unknown until the last point is inserted in the tree.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "2018. Adaptive deep learning model selection on embedded systems. ACM SIGPLAN Notices  53, 6 (2018), 31‚Äì43.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 29,
    "augmented": true
  },
  {
    "text": "We analyze the accuracy-latency trade offs of each strategy and show their benefits in different scenarios. A. Appliance Energy Prediction \nThe appliance energy prediction data-set predicts the energy usage of home appliances, given the environmental parameters, \n3 \nAlgorithm 1:  Training and Inference Pseudocode \nfunction  T RAIN (Sensor Data, NodeID, CloudID) @Edge for  each node  do \nprep data(data,node); ‚ñ∑ pre-process the data at edge if  Privacy Aware  then \ntrain model() ‚ñ∑ Locally train the model send model(cloudID) \nelse \nsend data(cloudID); ‚ñ∑ Send raw data to cloud \n@Cloud for  each node  do \nif  Privacy Aware  then \nsample trees(nodeID);  ‚ñ∑ Sample trees from each node \nelse \nmerge data(); ‚ñ∑ merge raw data from all nodes train(); end function function  I NFERENCE (Data, NodeID) @Edge for  each node  do \nPredict() if  Accuracy  ‚â§ Threshold  then \nSend data(CloudID); ‚ñ∑ Send data to cloud for accuracy \nelse \nSend results(CloudID); ‚ñ∑ Send the inference result Predict@Cloud ‚ñ∑ Run Prediction at Cloud \nend function \n0 \n0.02 \n0.04 \n0.06 \n0.08 \n0.1 \n0.12 \n0.6 \n0.62 \n0.64 \n0.66 \n0.68 \n0.7 \n0.72 \n0.74 \nEdge Cloud (Shared) Cloud (Privacy) \nlatency (ms) \nCorrelation \nPearson Correlation Latency (ms) \n(a) Data from 2 homes \n0 \n0.02 \n0.04 \n0.06 \n0.08 \n0.1 \n0.5 \n0.55 \n0.6 \n0.65 \n0.7 \n0.75 \nEdge Cloud (Shared) Cloud (Privacy) \nLatency (ms) \nCorrelation \nPearson Correlation Latency (ms) \n(b) Data from 4 homes \nFig.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 406,
    "augmented": true
  },
  {
    "text": "Samsung Newsroom. Samsung electronics develops second-generation smartssd computational storage drive with upgraded processing functionality. https://bit.ly/3PXwecP .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Ai and compute: How much longer can computing power drive artificial intelligence progress ? https://cset.georgetown.edu/wp-content/uploads/ AI- and- Compute- How- Much- Longer- Can- Computing- Power- Drive- Artificial- Intelligence-Progress.pdf , January 2022. Accessed: 2023-10-20.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. Figure 1: Example PC applications and processing pipelines.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "In this paper, we have gone be- yond foveated rendering ( Inter-Holo ), by proposing an optimiza- tion/approximation called  Intra-Holo , that complements the for- mer in boosting performance/energy efficiency. Such  Intra-Holo enhancement is ideally suited for holographic processing at the edge, without requiring additional hardware, cloud assistance, or machine learning. ‚Ä¢  We implement both the designs on an edge GPU platform [ 36 ], without the need for any hardware modification.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "Acknowledgement \nThis research was partially supported by NSF grants #1931531, #1955815, #1629129, #1763681, #1629915, #1908793, #1526750 and we thank NSF Chameleon Cloud project CH- 819640 for their generous compute grant. These policies can be collectively used for cost-effective prediction serving with- out compromising on latency and accuracy. References \n[1]  Omid Alipourfard, Hongqiang Harry Liu, Jianshu Chen, Shivaram Venkataraman, Minlan Yu, and Ming Zhang.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Besides, employing linear ensembling techniques such as model averaging are compute intensive [ 80 ] and not scalable for a large number of available models. This leads to signiÔ¨Åcant loss in accuracy. ‚Ä¢  Existing ensemble weight estimation [ 87 ] has  high com- putational complexity  and in practice is limited to a small set of off-the-shelf models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "4.1 Development and Profiling of NExUME \nNExUME uses a combination of programming languages and technologies to optimize its functional- ity in intermittent and low-power computing environments. The software stack comprises Python3 (2.7k lines of code), CUDA (1.1k lines of code), and Embedded C (2.1k lines of code, not including DSP libraries). Our training infrastructure utilizes NVIDIA A6000 GPUs with 48 GiB of memory, supported by a 24-core Intel Xeon Gold 6336Y CPU.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "[21] L. F. Hodges, ‚ÄúTutorial: Time-multiplexed Stereoscopic Computer Graphics,‚Äù  IEEE Computer Graphics and Applications , pp. 20‚Äì30, 1992. 252 \n[22] A.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 54,
    "augmented": false
  },
  {
    "text": "3  shows a typical trafÔ¨Åc distribution from Urban TrafÔ¨Åc data [ 97 ]) and the impact of sampling bias on class distribution. Note that, as some of the classes (e.g., bicycles) are barely present in the exemplar, the model tend to lose accuracy (because of catastrophic forgetting) on them, whereas the model rapidly over-Ô¨Åts for the classes with more examples (e.g., trafÔ¨Åc light). B.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Lastly, we apply coarse-grain power gating to conÔ¨Ågure the number of duplicated ReRAMs. This reconÔ¨Åguration ability can enable scaled activation of the circuits such that small tile-size computation can be enabled while yielding very low power consumption. V. P OWER - DYNAMIC  RCA  SCHEDULING \nGiven a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "We compare the execution of this workload against the following resource procure- ment schemes: (i)  util_aware , (ii)  exascale , (iii)  mixed  and (iv) Paragon . These schemes are modeled after state-of-the-art prior works as explained earlier in Section  2.3 . The  Paragon scheme does not offload to lambdas for relaxed latency queries.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "71  on average) for VR video applications [26], [62]. 10  a  . These results indicate that, although we ignore the row-number related information, the resulting PSNR is still sufÔ¨Åcient ( 47 .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "Peacock Panda Quill Slug Cup Class \n0 \n50 \n100 \nAccuracy \nMNetV2 IRV2 NASLarge \nFigure 4:  Class-wise Accuracy. This implies that the models other than top   N \n2   yields a signiÔ¨Åcant 1.45% accuracy improvement in the full-ensemble but they cannot be statically determined. From Figure  3a , it can be seen that the static policy has an accuracy loss of up to 1.45% when compared to full-ensemble, but is still better than single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": "Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ¬∑  m i \nTraining with Neuron Shapley Value Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  Œ¥ . Define the energy budget  E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "We run the experiment over a period of 1 hour for 10 requests/second. The cost is calculated as the cost per hour of EC2 c5.xlarge instance use, billed by AWS [ 5 ]. Ensemble-spot is explained further in the next section.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Sensors focus on inference using their local copies of  f Œ∏ . However, the sub- sequent training framework, discussed in Section  5 , allows for occasional fine-tuning of  Œ∏  based on equilibrium-driven participation, thereby refining the model to better suit the operational dynamics of the network. In each inference event, sensors decide whether to partic- ipate.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "‚Ä¢  EA+AE:  With both  EA  and  AE  optimizations deployed, as shown in Fig. 9, on average, the left-eye compute consumes only  36%  energy w.r.t. the  Baseline , with only  10%  for the right-eye, translating to  28%  total energy saving.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "‚Ä¢  T 3  transforms the  360 ¬∞ coordinates from a  monocular view to a  stereoscopic view . ‚Ä¢  T 4 , also known as the  perspective transformation  ma- trix, maps all  360 ¬∞ coordinates onto 2D coordinates. Since each eye sees the same object differently , this transformation matrix is different for each eye to give the user a more realistic experience.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Instead of updating and storing the occupy bits for each node during the process of adding points, now the outputs of this step are several arrays (Morton codes array, parent array, etc. ‚Ä¢  Post Processing:  Using these relationship arrays, the Ô¨Ånal step is to post-process them to obtain the occupy bits for each node, and output the compressed geometry stream. ), which reveal the geometrical relationship across the nodes.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "(GiGa MACs/s)/ Power utilization \nPower consumption with resilient acti. ( ¬µ W)/ Thr. (Giga MACs/s) /Power utilization \n1 50 0/Power failure/0/0% 0/Power failure/0/0% 2 100 0/Power failure/0/0% 80/25 √ó 1 √ó 1/0.312/80% 3 500 480/25 √ó 6 √ó 1/1.872/96% 480/25 √ó 6 √ó 1/1.872/96% 4 200 0/Power failure/0/0% 160/25 √ó 2 √ó 1/0.624/80% 5 250 0/Power failure/0/0% 240/25 √ó 3 √ó 1/0.936/96% 6 750 480/25 √ó 6 √ó 1/1.872/64% 720/25 √ó 3 √ó 3/2.808/96% 7 650 480/25 √ó 6 √ó 1/1.872/74% 640/25 √ó 2 √ó 4/2.496/98% 8 350 0/Power failure/0/0% 320/25 √ó 2 √ó 2/1.248/91% \n100 \n0.4 \n1.2 \n1.6 \n2.0 \n2.4 \n2.8 \nPower ( ¬≠ W) \nThroughput (Giga MACs/s) \nPower consumption with full-size activation \nPower consumption with tile-size activation \nThroughput with full-size activation Throughput with tile-size activation \nPower trace \nAverage harvested power Average power consumption with full-size activation Average power consumption with tile-size activation \nAverage throughput with full-size activation \nAverage throughput with tile-size activation \n356.3 \n180 \n330 \n1.3 \n200 \n300 \n400 \n500 \n600 \n700 \n800 \n0.8 0.7 \nPC1 \nPC2 \nPC3 \nPC4 \nPC5 \nPC6 \nPC7 \nPC8 \n0 \n0 0 0 80 480 480 0 160 0 240 480 \n480 640 0 320 \n0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 \nFig.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 481,
    "augmented": false
  },
  {
    "text": "We need some feedback from the end-user to make a correct estimate of accuracy. Therefore, it would be best to build a learning- based system, which takes into account feedback (user-given data) to build a novel model selection system. 3.2 Resource selection \n3.2.1 Static Load  From  Observation 2 , it is clear that, be- sides model selection, it is crucial to select and configure the right resource to satisfy the application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Let  F t represent the frame at time  t , and  F t ‚àí 1  be the anchor frame. The motion vector field  M t  between  F t and  F t ‚àí 1  is computed to capture the displacement of pixels. Each frame  F t  is divided into blocks B t,i , where  i  indexes the block within the frame.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Nascent: Near-storage acceleration of database sort on smartssd. In  The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays , pp. Sahand Salamat, Armin Haj Aboutalebi, Behnam Khaleghi, Joo Hwan Lee, Yang Seok Ki, and Tajana Rosing.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "[45]  Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vi- jay Vasudevan, et al. In  2018 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pages 620‚Äì629, Feb 2018. Searching for mobilenetv3.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "However, since the whole computation/rendering process takes place on a battery-backed device [39], one needs to consider the ‚Äúenergy efÔ¨Åciency‚Äù of this computation, i.e., even though we can meet the performance requirements of such video, energy efÔ¨Åciency needs to be improved. B. Motivation \nTo understand the energy proÔ¨Åle in the current VR devices, we characterize the energy consumption of  360 ¬∞ video pro- cessing on a prototype [36] (conÔ¨Ågured similar to a com- mercial VR device [39], discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "7 Concluding Remarks \nThere is an imminent need to develop model serving systems that can deliver highly accurate, low latency predictions at re- duced cost. Despite the lower accuracy gains,  Cocktail  is able to reduce the cost (Figure  17 ) of model-serving by 1.45 √ó  and 1.37 √ó for Wiki trace compared to  InFaaS  and  Clipper , respectively. In this paper, we propose and evaluate  Cocktail , a cost-effective model serving system that exploits ensembling techniques to meet high accuracy under low latency goals.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "CherryPick: Adap- tively Unearthing the Best Cloud Configurations for Big Data Analytics. [2]  Marc Brooker, Andreea Florescu, Diana-Maria Popa, Rolf Neugebauer, Alexandru Agache, Alexandra Iordache, Anthony Liguori, and Phil Piwonka. In  (NSDI) .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "1737‚Äì1746, 2015. 1‚Äì6, 2018. [28]  S. Jain, S. Venkataramani, V. Srinivasan, J. Choi, P. Chuang, and L. Chang, ‚ÄúCompensated-dnn: Energy efÔ¨Åcient low-precision deep neural networks by compensating quantization errors,‚Äù in  2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Third, how do we handle the corner cases, where more computational resources than that provided by the accelerator are required? We plan to design and imple- ment a clock/power gating technology to switch off the un-utilized PUs and save power/energy. Towards this, we plan to design a system-level scheduler which can efficiently partition the hologram tasks between the heterogeneous accelerator and original execution engines such as CPUs or GPUs.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Azure Functions Cold Starts. https://mikhail.io/serverless/ coldstarts/azure/. [15]  2021.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "Putting all these together, in this scenario, both Frame-1 and Frame-3 employ full inference, whereas the inference for Frame-2 can be skipped, with very little overhead (only  0 . 5%  of the time that full inference takes, refer to Sec. V for more details).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "1304‚Äì1311. https://doi.org/10. 1109/ICRA.2014.6907021 [56]  K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, J. Samp- son, M. T. Kandemir, and V. Narayanan.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "This approach tries to reduce the amount of hologram computation by approximating each of the holograms based on the distance between the user and the object. ‚Ä¢  Inter-Intra-Holo : The above two designs can be integrated to- gether into the original hologram pipeline, in either Inter-then- Intra or Intra-then-Inter fashion. 6b  b  .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "[40] L. Liu and M. T. Zsu,  Encyclopedia of Database Systems , 1st ed. Springer Publishing Company, Incorporated, 2009. [41] A. Rosebrock, ‚ÄúIntersection over Union (IoU) for Object Detection,‚Äù ‚Äùshorturl.at/gszOR‚Äù, 2016.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Algorithm 1 shows the details of the layered neural codec. We implement this neural codec using the FPGA in the CSDs. FPGAs are ideal for this application due to their parallel processing capabilities and the ability to handle multiple data streams concurrently.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, considering the similarities between successive video frames, we propose a frame-level compute reuse algorithm based on the motion vectors of each frame. As opposed to the prior work, in this paper, we target the video data that are processed by edge devices, and study the similarity between frames. Based on that, we propose two runtime approaches to boost the performance of the inference process, while achieving high accuracy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "However, when  AE  cannot take advantage of memoization due to a head orientation change, then the compute is distributed across the OCE ( 51% ) and  AE block ( 49% ); to be precise, only the entire coordinates on the left screen and the Ô¨Årst row on the right-screen are processed by the OCE ‚Äì the remaining rows on the right screen are reconstructed by the less power-hungry  AE  block. Implementation Details:  We abstract the  EA  and  AE  design blocks irrespective of the underlying hardware SoCs, and plot them in Fig. 7.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "As we will discuss in this paper, the cost of using VMs vs. serverless functions highly depends on the dynamically varying needs of the user query submission rates. Besides workload arrival rates, there is fur- ther variability in terms of configuring serverless functions to meet the end-user demands of latency and cost require- ments. This is because, serverless functions are billed based on of number of invocations, compute time and memory requirement of the function.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "Observing this, we propose a ‚Äúweighted accuracy metric‚Äù, where the weight of each of the model is a function of the accuracy, time needed and power availability. Further- more, each model might contribute differently to the overall accuracy. However, they never considered an intermit- tent power source, nor explored jointly optimizing multiple models with power, accuracy and latency constraints.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "2 gives the accuracy of these DNNs on MHEALTH dataset [12], [13]. Fig. A detailed description of the setup is explained in Section IV.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "After a sensor detects an activity, it anticipates the next activity to be the current classiÔ¨Åed activity, looks up for the best sensor, and signals to activate it for the upcoming inference. However, accuracy being a Ô¨Çoating point number, is expensive in terms of energy to store and lookup. To minimize this overhead, instead of storing the accuracy, we store the rank of the sensors for individual activities.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "We will maintain a repository of LLM experts that are independently trained, from which we can select and modify to form an ecosystem of LLM experts for complex tasks in continually evolving usage scenarios. This repository can constantly expand in types and sizes by welcoming open- sourced, community-contributed models. It delivers the promise of scaling LLMs through many smaller, specialized, independently trained expert language models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "The annotations indicate the consumed power ( ¬µ W), tile size and duplication count (e.g., 25x2x1) and power efÔ¨Åciency. If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles  PC2, PC4, PC5  and  PC8  under limited power budget, as depicted in Table II and Figure 1. With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of \n180 ¬µ W to 330 ¬µ W, and the throughput is increased by 85.7%.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Bringing  Connectivity  into the weight estimation process helps  Kraken  assign a higher weight to critical func- tions, in turn, ensuring that more containers are assigned to them, resulting in improved response times for the functions themselves, as well as their descendants. The  ùê∂ùëúùëõùëõ procedure in Algorithm 1 makes use of this formula. For ex- ample, in Figure 1c, the  Connectivity  of  ùê∂‚Ñéùëíùëêùëò _ ùëÖùëíùë†ùëíùëüùë£ùëéùë°ùëñùëúùëõ is   2 \n5   since it has two descendants and there is a total of five functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Further, in this paper, we have gone beyond foveated rendering ( Inter-Holo ), by proposing an optimiza- tion/approximation called  Intra-Holo , that complements the former in boosting performance/energy efficiency. Sec. 5) as in prior works.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "The impact of wrong labeling is discussed in ¬ß V . Note that the limited parameters of the student make it more sensitive to data Ô¨Ådelity and hence ensuring an accurate data labeling is very important for end to end classiÔ¨Åcation accuracy. This maximizes the accuracy of the teacher, and consequently minimizes the chance of the student model learning wrong labels.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "Moreover, communicating and storing such high volume data will also require energy. Green Data Centers:  As sustainability gains traction, industry has worked towards building green data centers [ 58 ], [ 59 ]. Although using these data centers for computation can be an alternative, it will not solve the bandwidth and the privacy issues mentioned in ¬ß I .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "[175] Ziyu Ying, Shulin Zhao, Haibo Zhang, Cyan Subhra Mishra, Sandeepa Bhuyan, Mahmut T. Kan- demir, Anand Sivasubramaniam, and Chita R. Das. Exploiting frame similarity for efficient inference on edge devices. Asso- ciation for Computing Machinery.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Fig. Compared to a state-of-the-art scheme [28], our design provides  34%  reduction in projection computations, which translates to  17%  additional energy savings. 1: A  360 ¬∞  video processing pipeline on a battery-backed stereoscopic HMD with an Inertial Measurement Unit (IMU) and an SoC equipped with a GPU [28], [39].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "To enable eager scheduling, we decentralized the global kernel dispatch queue and equipped each tile with a local kernel dispatch queue (1Byte wide 16 deep). At the beginning of each kernel scheduling iteration, the micro-proÔ¨Åler decides the right conÔ¨Åguration, and the control distributes equal number of kernels to each active tile (given  A  active kernel, and  K total kernels, each tile gets  ‚åä K / A ‚åã kernels to execute). We call this  Eager Scheduling .",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Since cost plays a crucial role in application-provider consideration, it is quintessential to minimize the deployment costs, while maximizing accuracy with low latency. Hence, the non-trivial challenge here lies in making the cost of ensembling predictions analogous to single model predictions, while satisfying these requirements. Studying the state-of-the-art ensemble model-serving frameworks, we observe the following critical shortcomings: ‚Ä¢  Ensemble model selection policies used in frameworks like Clipper [ 27 ] are static, as they  ensemble all available models  and focus solely on minimizing loss in accuracy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "2), thereby gaining more opportunities to reduce the amount of computations for all the objects in the current frame. Energy Savings:  The above power and latency reductions pro- vided by  HoloAR  eventually translates to energy savings for the hologram processing. As shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "Restrictions apply. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. 903 \nAuthorized licensed use limited to: Penn State University.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "This Load Predictor  2b  can be used in conjunction with the afore- mentioned Weight Estimator  2a  to calculate the fraction of application load each function will receive. Kraken  uses this load distribution to pre-provision the requisite number of containers for all functions in the application. 4.2 Request Batching Many serverless frameworks [ 5 ,  10 ,  17 ,  27 ,  44 ,  46 ,  50 ] spawn a single container to serve each incoming request to a function.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "8: Algorithmic performance of  Us. ¬¥as : the beniÔ¨Åts of the exemplar selection and  Œº -proÔ¨Åler. Component Spec Power Area(mm 2 ) SRAM Buffers 1kB*256+8kB*256+64kB+16*256kB 10.372W 117.164 MAC Unit (8*8)*256 8.46W 32.72 Adder Tree and Comparator 16*16bit + 256 2.4W 21.556 Control ‚Äì 0.96W 12.2 Host ‚àº Cortex A78 series 11W ‚Äì Design at 592MHz with Synopsys AED 32nm library Total 256 tiles 33.192W 183.64 \nTABLE I: Area and power estimation of our design.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "Any battery backed system will be limited to the charging cycle of the batteries ( ‚âà 500 cycles for Li-ion batteries) which leads to a typical 18 to 24 months of life for such devices (compared to this, a super capacitor have a life of more than 100 years). We believe that the lifetime of  Us. ¬¥as  will be limited either by the live of the harvesting source ( ‚âà 20 ‚Äì 30 years for solar, ‚âà 10 ‚Äì 12 years for portable wind turbines), or the training hardware (typical life cycle of embedded devices are of range of 7 ‚Äì 10 years).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "Thus, in this paper, we analyze the VR computation pipeline and observe that there is signiÔ¨Åcant scope to skip computations by leveraging the temporal and spatial locality in head orienta- tion and eye correlations, respectively, resulting in computation reduction and energy efÔ¨Åciency. The proposed  D¬¥ej`a View  design takes advantage of temporal reuse by memoizing head orientation and spatial reuse by establishing a relationship between left and right eye projection, and can be implemented either on a GPU or an FPGA. We propose both software modiÔ¨Åcations for existing compute pipeline and microarchitectural additions for further enhancement.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "3 Prelude to Cocktail \nTo speciÔ¨Åcally address the cost of hosting an ensembling- based model-serving framework in public clouds without sacriÔ¨Åcing the accuracy, this section introduces an overview of the two primary design choices employed in  Cocktail . How to reduce resource footprint? The Ô¨Årst step towards making model ensembling cost effective is to minimize the \n1044    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \number of models by pruning the ensemble, which reduces the overall resource footprint.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "Predictive maintenance in the Industry 4.0: A systematic litera- ture review. Computers & Industrial Engineering  150 (2020), 106889. 15 \n0 \n20 \n40 \n60 \n0 \n0.1 \n0.2 \n0.3 \n0.4 \n1 \n4 \n7 \n10 \n13 \n16 \n19 \n22 \n25 \n28 \n31 \n34 \n37 \n40 \n43 \n46 \n49 \n% Reconstruction Error \nFFT Amplitude \nFrequency (Hz) Reconstructed Original % Error \nFigure 14: An example of generator based coreset re- covery \nFigure 15: % completion of the inference at the edge for bearing fault data with different EH source.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "These devices have become an integral part of our daily lives and, using techniques such as deep learning, these devices are becoming increasingly capable of performing complex inference tasks including ma- chine translation, human activity recognition (HAR), bio-metric authentication, ECG measurement, fall detection etcetera [1], [2]. These inference tasks are typically driven by deep neural networks (DNNs), which are known for being compute heavy and power hungry [3]. Given the power and compute constraints of the IoT devices performing sensing, it is difÔ¨Åcult to execute these inference tasks on the sensing device itself, excepting a few intermittent tasks such as bio-metric authentication.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "The major  contributions  of this work can be summarized as follows: ‚Ä¢  We first conduct a detailed characterization of a generic AR processing pipeline to identify the major bottlenecks in current state-of-the-art AR headsets, and set our optimization target as the  hologram computation . Starting from investigating and evaluating the existing foveated rendering techniques, this work further explores the entire design space for potential opportunities and optimizations unique in AR applications, for speedup as well as energy savings. and improve its energy efficiency, with ‚Äúapproximation‚Äù as the core idea.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "Mathematical Formulation:  The Shapley value  œï i  of neuron  i  is a measure of its contribution to the overall network performance. X \nS ‚äÜN\\{ i } \n| S | ! It is calculated by considering all possible subsets of neurons and computing the marginal contribution of neuron  i  to the network‚Äôs output: \nœï i  = 1 |N| !",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Our experiments shows that DNN inference using  Origin , running on a harvested energy only system, is more accurate than energy-constraint- optimized DNNs, running on a fully-powered system. Origin  combines an intelligent activity aware scheduler with an adaptive and light weight ensemble learning method. Our proposal, Origin , holistically looks into multiple aspects of deploying a DNN on an EH-WSN for the purpose of HAR.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Debendra Das Sharma. Compute express link¬Æ: An open industry-standard interconnect enabling het- erogeneous data-centric computing. In  2022 IEEE Symposium on High-Performance Interconnects (HOTI) , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "This section addresses the Ô¨Årst of these challenges, and Section V discusses our approach to the second. In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment. Challenge 1:  Achieving low-power, reconÔ¨Ågurable RCA Although recent works have presented systems [ 4 ], [ 3 ], [ 5 ] and circuits [ 24 ], [ 6 ] for inference-oriented RCAs, they are not directly suitable for adoption in our target scenario because of either their high power consumption or their stringent execution parameters (e.g., computation granularity).",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": ",  ii) how to integrate such optimizations into the entire geometry compression pipeline? 5 , and answer the following three critical questions:  i) how to increase parallelism for the bottleneck steps? To better understand where the beneÔ¨Åt comes from, next we go over a simple example, given in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "However, a higher reuse ratio can be achieved by relaxing the precision of the IMU output. Furthermore, we study the  V3  (i.e.,  Rollercoaster ) video and examine the trade-offs between (i) quantizing/approximat- ing the head orientation (thus compromising video quality) with more reuse, vs. (ii) maintaining the lossless video quality but with a lower reuse ratio, in Fig. 5c, to provide an intuitive comparison in different scenarios.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Towards this, we designed and trained a generative adversarial network (GAN, see Figure 7b for the structural details) to recover the lost samples of the importance sampling. As training parameters, we provide some statistical parameters (specifically mean and variance) \n7 \nof the signal and random noise to the generator, and the generator generates the lost signals. The discriminator tries to discriminate between the actual data and the synthesized data.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "We collected over 700,000 samples over a period of 2 hours for each of the sensors. There were 5 operating statuses: three different speeds of rotation of the spindle ( R1: 100RPM ,  R2: 200RPM ,  R3: 300RMP  with no job; RPM ‚Äì rotations per minute), spindle under job ( SJ ), and spindle idle ( SI ). Setup and Sensor Arrangement:  Two different types of 3-axis accelerometers (with 100Hz and 200Hz sampling rate) were placed in three different locations of a Bridgeport machine to collect and analyze data under different operating status.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Google Pixel 2 Review. \"https://www.techradar.com/reviews/ google-pixel-2-review\". [61]  Oren M Tepper, Hayeem L Rudy, Aaron Lefkowitz, Katie A Weimer, Shelby M Marks, Carrie S Stern, and Evan S Garfein.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "10a  shows the contribution of the different components of  Us. ¬¥as  under different power proÔ¨Åles. Moreover, the algo- rithmic contributions can be extended into any classiÔ¨Åcation based application or data modality.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Softsku: Optimizing server architectures for microservice diversity@ scale. In  ISCA . [8]  Liang Wang, Mengyuan Li, Yinqian Zhang, Thomas Ristenpart, and Michael Swift.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "Traditional neural codecs, while innovative, typically encode and decode video streams in a monolithic fashion, which often results in suboptimal utilization of computational resources and inflexibility (Ma et al., 2019). Neural codecs present a new paradigm video compression technology, leveraging deep learning to surpass traditional codec efficiency (Ma et al., 2019; Chen et al., 2017). To maximize the compute reuse between the compute pipeline and the archival pipeline,  Salient Store  uses apart of the neural network of the inference engine to extract features, and then further performs the encoding using the FPGA in the CSD.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "3, pp. [5] W. Amit Katwala, ‚ÄúThe spiralling environmental cost of our lithium \nbattery addiction,‚Äù https://www.wired.co.uk/article/lithium-batteries- environment-impact , May 2018, (Accessed on 07/08/2023). 1‚Äì13, 2016.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "6:  After all sensors decide, the action profile  a ( t )  is real- ized, and energies are updated: \nB i ( t  + 1) =  B i ( t ) +  E i ( t )  ‚àí e i ( t ) . 7:  Sensors iterate this process at each inference event, re- fining their estimates and converging to stable action patterns. Sensors employ this best-response mechanism, continuously updating their participation decisions based on the evolving network state and the actions of other sensors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "[57] Meta, ‚ÄúSharing our progress on combating climate change = https://about.fb.com/news/2022/11/metas-progress-on-combating- climate-change/ ,‚Äù (Accessed on 11/21/2022). [59] Microsoft, ‚ÄúBuilding world-class sustainable datacenters and investing \nin solar power in arizona,‚Äù https://blogs.microsoft.com/on-the- issues/2019/07/30/building-world-class-sustainable-datacenters-and- investing-in-solar-power-in-arizona/ , (Accessed on 04/28/2023). [58] Meta, ‚ÄúSustainability: Data centers,‚Äù  https://sustainability.fb.com/data- \ncenters/ , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 186,
    "augmented": true
  },
  {
    "text": "Restrictions apply. performs linear transformations on the attribute data of each voxel pair (the voxel in level n  and its siblings along x, y, and z dimensions) to obtain a low-pass component and a high- pass component. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Figure  3a  plots the cost of hosting the iso-latency model types (shown in Figure  2a ) for a constant request arrival rates of 10, 50, 100, 200 req/sec over 1 hour duration. It can be seen that virtual machines are always cheaper compared to using  serverless functions for all constant request rates. The  serverless functions  are configured according to the memory requirements of each model.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "However, if  T 2  does not change across frames,  P  is identical to the previous frame. IV. R EDUCING  P ROJECTION  C OMPUTATION \nAs discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "(b) plots among all the head orientations, how many can be memoized by these two buffers. (c) illustrates the trade-off between the precision level and reuse ratio. This indicates two memoization buffers are sufÔ¨Åcient.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Note that, this implementation is purely done in software, without any hardware modiÔ¨Åcation. ‚Ä¢  AE  (SW) : We evaluate the  IntraFrame, InterEye ( AE ) design on a GPU, and bypasses the projection computation for the right-eye by  reconstructing  the results with a learned pattern, as shown in the  AE  block in Fig. 7.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "8  shows the impact of micro-proÔ¨Åling on the hyper parameter selection. Fig. Due to the drift- and weighted accuracy- aware micro-proÔ¨Åler, the suggested conÔ¨Åguration is almost every time the same as an oracular selection.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "With this design idea, the system can keep making forward progress over a large range of power incomes. In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM \naccelerated MACs. Moreover, we allow parallelism along different dimensions to seamlessly integrate it with loop tiling, and as a result, a range of scalable computations that can Ô¨Åt in different power supplies are achieved.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "However, with limited energy budget on typical edge devices, the accuracy is far from sufÔ¨Åcient for vision applications (quantitative results in Sec. V). Although the prior works do add value to video analytics, each comes with its own problems and costs.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "Yang, J. Emer, and V. Sze, ‚ÄúEyeriss v2: A Ô¨Çexible \naccelerator for emerging deep neural networks on mobile devices,‚Äù IEEE Journal on Emerging and Selected Topics in Circuits and Systems , vol. [15] Y.-H. Chen, T.-J. 11 621‚Äì11 631.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "We have also participated in the annual Exploration-U Science day events, organized by Penn State. This event helps to create awareness to a much broader audience to our targeted efforts for summer camps and summer internship opportunities. It also provides us access to new contacts and additional recruitment opportunities of diverse students.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "NASLarge IRV2 XceptionDNet121 NASMob 0 \n2 \n4 \n6 \nCost($) \nSingle-OD Ensemble-OD Ensemble-spot \n(b)  Cost of full-ensembling hosted on OD and Spot instances. Thus, depending on the model sub- set used in the ensemble, it achieves better accuracy than the baseline at lower latencies. Note that in our example model-set, the beneÔ¨Åts of ensembling will diminish for lower \nNASLarge IRV2 Xception DNet121 NASMob \n0.5 \n1.0 \n1.5 \nAccuracy Loss(%) \nStatic Single \n(a)  Accuracy loss compared to full- ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "IEEE, 2022, pp. 1073‚Äì1084. [106] R. Zhang, H. Tao, L. Wu, and Y. Guan, ‚ÄúTransfer learning with neural \networks for bearing fault diagnosis in changing working conditions,‚Äù Ieee Access , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "SpeciÔ¨Åcally, as shown in Fig. 6 , in order to capture the spatial locality in attributes (e.g., points with similar Morton codes tend to have similar colors), our proposed pipeline Ô¨Årst sorts the points using the Morton codes and then partition/group them into multiple segments. The points within one segment are geometrically close to each other, and hence their attributes are also likely to be similar.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "4:  For each action candidate  a i ( t )  ‚àà{ P ,  NP } , the sensor computes the expected utility: \nU   a i ( t ) i =  E [ R i ( t )]  ‚àí E [ e i ( t )]  ‚àí Œ≤ E [ V i ( t  + 1)] , \nwhere the expectations are taken over uncertainties in correctness, SNR impact, and future energy. 6:  After all sensors decide, the action profile  a ( t )  is real- ized, and energies are updated: \nB i ( t  + 1) =  B i ( t ) +  E i ( t )  ‚àí e i ( t ) . 5:  If  U   P i   ‚â• U  NP i and  B i ( t )  ‚â• e cap ( SNR i ( t ))+ e inf + e comm , then  s i  chooses P. Otherwise, it chooses NP.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 246,
    "augmented": true
  },
  {
    "text": "Us. ¬¥as  also consumes more power than the other accelerators since it also performs the exemplar selection along with the DNN training, and also houses NV-SRAM buffers for hardware check-pointing. While fully powered,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "A key insight is that, while these compression techniques work very well for high dimensional data (e.g. Secondly, these compression algorithms are not context-aware, and hence lose relevant \n4 \nfeatures during the process of compression resulting in de- graded inference accuracy (refer Table 1 for details). images), inference on low-dimensional sensor data (such as inertial measure- ment unit or IMU vibration data) is much more sensitive to lossy compression as separating between features might be difficult to do.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "performs linear transformations on the attribute data of each voxel pair (the voxel in level n  and its siblings along x, y, and z dimensions) to obtain a low-pass component and a high- pass component. The high-pass component is quantized and entropy encoded, while the low-pass component proceeds to the next level (level n ‚àí 1 ) and serves as a prediction for the voxel‚Äôs attribute in this upper level [ 14 ]. Note that, this step also needs to be performed sequentially across the tree layers.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Observation 1:  Model selection should be focused on meeting the cost requirement of an application without compromising on the accuracy and/or latency constraint. Prior work  [ 9 ] tries to solve model selection only from a through- put perspective where different sized batching of multiple inference queries together results in varied throughput. Hence, it is evident that there is a large optimization space where different models can be selected based upon the needs of the applications.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "The generator is tuned repeatedly until the discriminator could not distinguish the original and the generated signal. The GAN modeled the lost signals with a very high correlation ( ‚â• 0 . 9 in most cases and 0 .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Fig. Note that  Œ±  can be adjusted based on the application preference, e.g., shifting the  x  =  Œ±  line to the right results in more macro blocks in the I-frame being directly reused for compressing the P-frame, i.e., higher compression ratio, with a cost of quality drop (more details in Sec. V ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "The results we how are only for latency intolerant applications. Discussion:  For applications that are latency tolerant, we can potentially redirect requests from failed instances to existing instances, which would lead to increased tail latency. Note that, the ensembles used in our experiments are at-least 4 models or more.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "1‚Äì6, 2016. [2]  L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, ‚ÄúSwitched by input: Power efÔ¨Åcient structure for RRAM-based convolutional neural network,‚Äù in  2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC) , pp. [3]  A. ShaÔ¨Åee, A.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "First, it provides sufficient accuracy for the AR applications ‚Äì as high as 2 . 06 ¬∞  accuracy for gaze shape/direction estimation across a wide field of view [ 26 ]. Second, its execution latency when running on our edge GPU prototype [ 36 ] is within 4 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "The requests meeting accuracy are generally higher for the Relaxed  workload because the target accuracy is much lower. Overall,  Cocktail  was able to deliver an accuracy of 83% and 79.5% on average for the  Strict  and  Relaxed  workloads, respectively. Note that, changing the target accuracy to tolerate a 0.5% loss, increases the percentage of requests that meet accuracy to 81% for  Cocktail , when compared to 61% for  InFaas .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "From our simulation experiments we observe that  mixed  procurement did not reduce cost of Wiki trace. This is because the difference between peak-to-median in the traces are not large and therefore more functions get offloaded to  serverless functions . Thus, using  serverless func- tions  for such scenarios will not drastically reduce cost.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "15: end if 16: Check feasibility conditions again to ensure no viola- tion of baseline inequalities. 13: else if  incorrect inferences are prevalent  then 14: Increase  Œ¥ k  ‚Üê Œ¥ k  + ‚àÜ Œ¥  to penalize low-quality submissions more strongly. 11: else if  participation is too high, leading to frequent energy depletion  then 12: Decrease  Œ≥ k  ‚Üê Œ≥ k ‚àí ‚àÜ Œ≥  or increase  Œ¥ k  ‚Üê Œ¥ k +‚àÜ Œ¥ to discourage high-risk attempts.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "Almost all of these applications can be categorized as interactive volumetric video streaming. On the other hand, for applications such as autonomous driving [ 1 ], [ 4 ], robotics [ 79 ], motion planning [ 34 ] or path planning [ 42 ], attributes like RGB info, at most times, are not necessary as the PC is used in the compute pipeline (by the machine) to extract features and make decisions. Especially,  interactive volumetric video streaming  is starting to become mainstream, as edge devices (e.g., iPhones) facilitate recording and streaming the PC video which provide end-users with real-time 6-degrees of freedom (6-DoF) experiences.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "John Wiley & Sons. [29]  Yu Gan, Yanqi Zhang, Dailun Cheng, Ankitha Shetty, Priyal Rathi, Nayan Katarki, Ariana Bruno, Justin Hu, Brian Ritchken, Brendon Jackson, et al . 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Pixel Content Reuse on VRs:  Pixel value reuse has been well-studied in VRs [17], [22], [23], [29], [33], [50], [60], [66] to improve throughput and performance. For example, DeltaVR [29] adaptively reuses the redundant VR pixels across multiple VR frames to improve performance. These works focus on the pixel content reuse, which is the last stage ( Projection Mapping ) in the  360 ¬∞ video projection pipeline (discussed in Sec III).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "Towards this, in the future, we plan to explore GPU-speciÔ¨Åc \n295 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Optimizations in Holographic Processing:  Holographic pro- cessing has been optimized in various domains [ 33 ,  35 ,  52 ,  54 ], to improve power efficiency or execution performance. For exam- ple, HORN-8 [ 35 ] has proposed a special-purpose computer for electro-holography to reduce the power consumption and still de- liver a high frame rate (similar to that of a cloud GPU). From the software/algorithm perspective, a sub-hologram technique is pro- posed with a tracked viewing-window technology to tailor the holographic computation only for the necessary information in- side of the window [ 52 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "Now that we know Classical approach of video data storage involves encoding and encrypting the video data before storing them in a redundant storage array (Huang & Xu, 2014; Fan et al., 2022; Korkiakangas, 2014; Yue et al., 2016) which consumes significant resources (refer Table 1). Even though there have been significant research in accelerating both compression (Collet & Kucherawy, 2018; Chen et al., 2021) and encryption (Milanov, 2009; Rawat et al., 2019; Yang et al., 2015), operating on large-scale video data often demands more resource than what edge servers could afford (Mishra et al., 2024). Co-locating this compute along with the inference and training would definitely hinder the critical path.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 197,
    "augmented": false
  },
  {
    "text": "7 ), the macro-block based state-of-the-art approach [ 48 ] Ô¨Årst needs to generate two macro block trees (where the minimum voxel dimension in this tree is of a predeÔ¨Åned size) ‚Äì one for I-Frame and the other for P-Frame. Next, for each leaf node/block in the P-MB-Tree, the entire I-MB-Tree needs to be traversed in a top-to-down fashion, and the exactly-matched leaf in the I-MB-Tree is found. In this case, the found leaf  L 1 - I , which contains two points ( P 0 and  P 1 ), is a perfect match; however, no match can be found for the  L 2 - P  leaf.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 181,
    "augmented": false
  },
  {
    "text": "2.2 Thrust-2: System Support for Expert Scheduling and Data Movements The primary goal of this thrust is to explore novel system support ‚Äì targeting  both  training and inference ‚Äì that complements our algorithmic support for EoE in Thrust 1 and architectural support for EoE in Thrust 3. The representative research questions this thrust will strive to answer include: i)  How can an EoE system be trained in a performance- and energy-efficient manner through the maximization of data locality and parallelism? ; ii)  What are the ways of efficiently retraining routers when new experts are added into or removed from the ensemble?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "387‚Äì400, 2019. [84]  veesus.com, ‚ÄúINTRODUCING ZAPPCHA ‚Äì MOBILE POINT CLOUD CAPTURE AND CLOUD-BASED STORAGE,‚Äù ‚Äùhttps://bit.ly/3xiSw0v‚Äù , 2021. [85]  Vision Lab, Nanjing University, ‚ÄúMultiscale Point Cloud Geometry Compression,‚Äù  ‚Äùhttps://bit.ly/3xiAxah‚Äù , 2020.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "In fact, for training GPT-3, on an average, 5.4 million liters of water is consumed! A study [94] on the same highlights the opera- tional water consumption footprint for LLM training and inference and points out that, in the United States, on average, for every 30 inference requests on a small model like GPT-3 results in consumption of 500mL of water. A critical but often overlooked aspect of these compute-intensive operations are usage of water in cooling mechanisms in the data centers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "It offers high-resolution sensor data, including LIDAR and camera recordings, across a variety of urban and suburban landscapes. This data-set‚Äôs volume and diversity make it an excellent benchmark for assessing  Salient Store  ‚Äôs capabilities in handling large-scale, real-world data. For 3D point cloud data, we selected the  KITTI Vision Benchmark Suite  (Geiger et al., 2012), a fundamental data-set in autonomous driving research.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "We name this as an importance sampling  6b  technique, because the model pools are scaled proportional to their popularity. 5 Implementation and Evaluation \nWe implemented a prototype of  Cocktail  and deployed it on AWS EC2 [ 5 ] platform The details of the implementation are described below. Cocktail is open-sourced at  https:// github.com/jashwantraj92/cocktail \n5.1 Cocktail Prototype Implementation \nCocktail  is implemented using 10KLOC of  Python .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "1. Second, by increasing the number of depth planes, it takes around 2 √ó  latency to generate a hologram with 2 √ó  number of depth planes. As also mentioned in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "In fact, prior research on HVS has shown that human eyes are able to observe beyond 135 ¬∞  vertically and 160 ¬∞  horizontally, but see fine details within an only around 5 ¬∞  central circle (i.e.,  foveal vision ). Motivated by such degradation of  peripheral visual acuity , foveated rendering  reduces computational costs for the peripheral region, and maintains high/normal resolution only for the foveal re- gion [ 2 ,  22 ,  24 ,  25 ,  30 ,  47 ,  62 ]. For instance, a real-time gaze-tracked foveated rendering system is proposed to yield performance and memory savings by avoiding shading up to 70% of the pixels for VR headsets [ 47 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 171,
    "augmented": false
  },
  {
    "text": "The unreliability of individual EH sensors, due to fluctua- tions in energy availability, necessitates the deployment of a large number of inexpensive and potentially unreliable de- vices to ensure network robustness. However, it also introduces complexities in coordinating sensor activities, managing energy resources, and ensuring efficient data collection and processing ( ? This redundancy allows for continuous operation despite individual sensor failures or downtime.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Capturing PC representation of the real world typically requires millions of voxels, far more than the amount of pixels required for 2D images. Background \nPoint Cloud in Real Life:  Point Cloud (PC) is a set of points which represent objects or shapes in a 3D space where each point/voxel (3D equivalent of a 2D pixel) contains its 3D location (x, y, z coordinates), as well as some attributes (e.g., colors, normal, etc.). While PCs containing only the 3D geometry data are commonly used in LiDAR-based 3D imaging for autonomous vehicles or robotics path planning, the lack of attributes nullify their usage for visual media consumption.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "Scenario-3, it indicates that the object(s) in the current frame are different from the last inference outputs (i.e., ‚Äúmissed‚Äù in Scenario-2, or ‚Äúentering/exiting‚Äù in Scenario-3) and hence, requires full inference (refer to Line  5  in Algo. Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "The challenge was to learn this function, i.e. to de- vice a transformation function which can mimic the sensor signal given the aactivity and the sensor states. A similar problem, in terms of generating faces, paintings etc.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "The energy harvesting mechanism is supported by the power management unit, which can record power production and consumption at an execution cycle level. The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs. The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Comm Only  and  Conn Only  are seen to exceed the target SLO at the 99th percentile. The tail latency of  Kraken , in comparison, grows slower and remains within the target SLO. 6.2 Simulator Results Since the real-system is limited to a 160-core cluster, we use our in-house simulator, which can simulate an 11k-core cluster, to study the scalability of  Kraken .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "1063‚Äì1075. 2020. [42]  Mohammad Shahrad, Rodrigo Fonseca, √ç√±igo Goiri, Gohar Chaudhry, Paul Batum, Jason Cooke, Eduardo Laureano, Colby Tresness, Mark Russinovich, and Ricardo Bianchini.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "8c , we plot the compressed size (in megabytes) shown on the primary y-axis (left), and the PSNRs (in dB) for attributes 8   on the secondary y-axis (right), and observe that: ‚Ä¢  TMC13:  compresses the input frame size to be only  8%  of the original while preserving the best video quality (PSNR is  55 dB). Compression EfÔ¨Åciency:  To investigate how the compression efÔ¨Åciency changes with the above schemes, in Fig. This is mainly because TMC13 performs lossless geometry compression and almost-lossless attribute com- pression in our settings.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "In addition to the individual tasks in each thrust, Figure 2 also shows the inter-task dependencies as well as interactions between them, highlighting our cross-layer co-design aspect. Our research tasks in Thrust 1 are illustrated in Figure 3. 2.1 Thrust-1: Algorithmic Support for Ensemble of Experts The main focus of this thrust is to investigate different models and algorithms for Ensemble-of-Experts (EoE) systems, paying special attention to search space optimization for ‚Äúmorphable‚Äù LLM expert ecosys- tems, ‚Äúdynamic‚Äù expert networks, and obtaining new experts from existing ones.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "Energy Efficiency:  We measure the energy-consumption as total Energy consumed divided over total time. Kraken achieves one of the lowest energy consumption rates among all the policies considered, with it bettering existing policies, namely,  Arch ,  Fifer  and  Xanadu  by 26%, 14% and 3% respec- tively (for the workload mix of  Media Service  application with Wiki trace) as depicted in Figure 13a. These savings can go up to 48% compared to  Arch  for applications like  Social Network .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "[30] S. Han, H. Mao, and W. J. Dally, ‚ÄúDeep compression: Compressing \ndeep neural networks with pruning, trained quantization and huffman coding,‚Äù  arXiv preprint arXiv:1510.00149 , 2015. [31] J. He and F. Zhu, ‚ÄúOnline continual learning for visual food classiÔ¨Å- \ncation,‚Äù in  Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "M. Bramberger, J. Brunner, B. Rinner, and H. Schwabach. Real-time video analysis on an embedded smart camera for traffic surveillance. In  Proceedings.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Scalable k-means++. Antonio Barbalace and Jaeyoung Do. arXiv preprint arXiv:1203.6402 , 2012.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "Considering that NN-PCC can take thousands of seconds to compress one PC frame [ 88 ], such a huge gap between the long execution latency of NN-PCC and the \n2 Although V-PCC and NN-PCC have high compression efÔ¨Åciencies, they are compute-intensive [ 41 ], [ 88 ], and consequently, are not the best option for mobile devices and are not considered in this work. Besides, most of the NN-PCC only focus on compressing geometry data [ 88 ], thus, is not applicable for this paper‚Äôs target (i.e., mainly for vision applications where the attributes are essential). 0 \n500 \n1000 \n1500 \n2000 \nTrans.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "instance packing factor P f  ). In order to increase the utilization of all instances in a pool at any given time, the load balancer submits every request from the queue to the lease remaining free slots (viz. This is similar to an online bin-packing algorithm.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "Strict Relaxed 0 \n25 \n50 \n75 \n#VMs \nInFaas Clipper Clipper-X Cocktail \n(a)  Wiki Trace. Figure (d) shows the effects of distributed autoscaling with importance sampling. Strict Relaxed 0 \n25 \n50 \n75 \n#VMs \nInFaas Clipper Clipper-X Cocktail \n(b)  Twitter Trace.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "3) affect the energy savings achieved, we report five design points in Fig. 10b. This figure shows a clear pattern of trade-offs between more-energy-savings vs. more-quality-drop.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "In this scheduling strategy, the RCA is only active when the harvested power is adequate to support the maximal power requirement among all the convolution layers and, in the ‚Äúsimple‚Äù architecture, one convolution layer can only be mapped to one ReRAM (no ReRAM duplication). In Fig- ure 6(a), a naive scheduling strategy is employed on a  Simple architecture . In the remainder of this paper, this execution strategy is referred to as  Naive1 .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, we choose to segment each PC frame into 30000 blocks 7 , and use a 2-layer encoder (more speciÔ¨Åcally, we Ô¨Årst encode the attributes via the proposed intra-frame encoder \n6 Based on our proÔ¨Åling, the provided attribute compression APIs (e.g., JPEG- Turbo-based) would degrade the quality of PC signiÔ¨Åcantly; thus, we do not use such APIs/Libs in our evaluations. 7 We decide the parameters for intra- and inter-compression by proÔ¨Åling several frames in the 8iVFB [ 18 ] dataset, to obtain a relatively balanced design point between compressed size and quality. 292 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "Observation over 40 hours of continuous learning on the dataset suggest that the micro-proÔ¨Åler has, on average, an accuracy deviation of 2 . 46%, compared to an oracle parameter selection. Along with that, the micro-proÔ¨Åler selects correct batch size 82 .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "From Figures 9 and 10, it can be seen that  Xanadu  has similar (or worse) end- to-end response times than  Kraken  (up to 50 ms more), but \nspawns more containers as well (up to 70% more) and satisfies fewer SLOs on average (0.2% lesser). This can be attributed to  Xanadu ‚Äôs container pre-deployment policy which causes reactive scale outs as a result of MLP mispredictions. This ef- fect is highlighted in applications such as  Social Network  and Media Service  which have relatively high MLP misprediction rates (80% and 50%, respectively 2 )) due to the presence of multiple possible paths (Table 2).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "1:  Fraction of inference completed on harvested energy using na¬®ƒ±ve scheduling. Each of the sensors in a multi-device HAR deployment receives different data depending on its location and the current human activity in progress. Therefore, different DNNs are needed to process data from these different locations.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Computational Wave Optics Library for C++: CWO++ Library. [56]  Jeffrey H. Shuhaiber. Computer Physics Communications  (2012), 1124‚Äì1138.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "However, the crucial downside of using transient VMs is that they can be unilaterally preempted by the cloud provider at any given point due to reasons like in- crease in bid-price or provider-induced random interruptions. As we will discuss further,  Cocktail  is resilient to instance failures owing to the fault-tolerance of ensembling by com- puting multiple inferences for a single request. Key takeaway :  The cost-effectiveness of transient instances, is naturally suitable for hosting ensemble models.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "Designing a learning platform that can adapt to intermittent renewable energy sources (e.g., solar power) and maintain a minimal operational carbon footprint [ 29 ] is paramount. Such a platform should continuously make progress on unsupervised labeling, exem- plar building, and continuous learning, and maximize  drift mitigation  while minimizing power consumption. Moreover, the system must accommodate  support for intermittency inherent in sustainable power sources like solar and wind.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "Thus, unlike planar videos, in  360 ¬∞ videos, speciÔ¨Åcally the projection computations for capturing the head movements and eye correlations, are sig- niÔ¨Åcantly computation-heavy, amounting to  59%  of the overall VR (headset) power budget. Current head mounted VR devices use a GPU for this heavy computation. Since the head mounted VR devices are battery-backed, the computations that draw high power from the battery greatly hinder the experience of watching long  360 ¬∞ videos [39].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "While the overhead in streaming multi-processor (SM) utilization was marginal (within 5%), there was a noticeable increase in memory bandwidth usage, ranging from 6% to 17%. Moreover, we have implemented a modified version of the matrix multiplication operation that strategically skips the loading of rows and/or columns from the input matrices into the GPU‚Äôs shared memory and register files. This adaptation is guided by the dropout mask vector and the specific type of sparse matrix operation being performed.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Some of the units change according to the harvested energy source. Figure 1b shows the capabilities of the current SOTA. The size of the circle representing the solutions de- picts the compute capabilities of the sensor nodes, the shade shows the available power, and their position on the axes approximates the amount of compute done on the node and the amount of reliability on external communication.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "These trade-offs are not very straightforward due to the following  challenges : First,  among all of the inputs to the AR headset (shown later in Fig. 1b), which one(s) are critical for holographic processing? Second,  which features of these inputs are salient and need more fine-grained computation, and which of them could be approximated without impacting the QoS?",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the ACM Symposium on Cloud Computing , pages 789‚Äì800. ACM, 2020. [162] Zhuang Wang, Zhen Jia, Shuai Zheng, Zhen Zhang, Xinwei Fu, T. S. Eugene Ng, and Yida Wang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Additionally, by clustering and scheduling experts that share training datasets, we propose a ‚Äúlocality-aware‚Äù training strat- egy that minimizes the frequency and volume of data transfers between experts, memory and storage‚Äì a key factor in improving both performance and energy efficiency. We plan to model this problem using a ‚Äúbipartite graph‚Äù (refer to Figure 4) where one set of nodes represent disjoint datasets (D1, D2, etc.)",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_partial",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "A. Inter-Frame Attribute Compression \n1) What is the Temporal Opportunity? :  As we have shown earlier in Fig. 3  b  , two blocks (a set of points) which are located close to one another are likely to contain similar color pixels.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Second, its execution latency when running on our edge GPU prototype [ 36 ] is within 4 . 5 ms , which contributes to less than 1% of the entire hologram processing pipeline latency. With the RoF attained from the eye tracking, the next question we need to answer is how to deploy the approximation opportuni- ties discussed above in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "2021. Adaptive Weighted Gerchberg-Saxton Algorithm for Generation of Phase- only Hologram with Artifacts Suppression. [63]  Yang Wu, Jun Wang, Chun Chen, Chan-Juan Liu, Feng-Ming Jin, and Ni Chen.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "E XPERIMENTS \nTo evaluate ResiRCA, we have extended the Gem5 [ 37 ] simulator with RCA modeling. VI. The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 6338‚Äì6353, Dublin, Ireland, May 2022. CONTaiNER: Few- shot named entity recognition via contrastive learning. Association for Com- putational Linguistics.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "[14] Lasse F Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan. Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. arXiv preprint arXiv:2007.03051 , 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "We show that, by considering various parameters like region of interest and depth of view, we can approximate the ren- dering of the virtual object to minimize the amount of computation without affecting the user experience. Furthermore, by optimizing the software design flow, we propose  HoloAR , which intelligently renders the most important object in sight to the clearest detail, while approximating the computations for the others, thereby sig- nificantly reducing the amount of computation, saving energy, and gaining performance at the same time. We implement our design in an edge GPU platform to demonstrate the real-world applicability of our research.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "Excluding the most general (and rare) cases where applications can have loops/cycles within a function chain [ 27 ], applications can be modeled as a  Directed Acyclic Graph  (DAG) where each ver- tex/stage is a function [ 26 ] Henceforth, we will use the terms ‚Äòfunction‚Äô and ‚Äòstage‚Äô interchangeably. An application invokes functions in the sequence as specified by the path in the DAG. We define a  workflow or  path  within an application as a sequence of vertices and the edges that connect them, starting from the first vertex (or vertices) and ending at the last vertex (or vertices).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "In  2019 IEEE International Conference on Cluster Computing (CLUSTER) . 1‚Äì13. https://doi.org/10.1109/CLUSTER.2019.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "D. Comparison against Prior Work \nAs discussed in Sec. These results indicate that our proposal is Ô¨Çexible/adaptive with different design preferences. 10(b).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747 , 2017. 12 \nTien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Experimental results using two different HAR data-sets show Origin , while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classiÔ¨Åer continuously operating at the same average power. Index Terms ‚ÄîEnergy Harvesting, Human Activity Recognition, DNN, Wireless Senor Network, Ensemble Learning \nI. I NTRODUCTION \nThe advent of data driven computing, along with advances in low-power computing platforms, has given rise to the new generation of intelligent and connected devices that comprise the internet of things (IoT). These devices have become an integral part of our daily lives and, using techniques such as deep learning, these devices are becoming increasingly capable of performing complex inference tasks including ma- chine translation, human activity recognition (HAR), bio-metric authentication, ECG measurement, fall detection etcetera [1], [2].",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 191,
    "augmented": true
  },
  {
    "text": "0 20000 40000 60000 80000 100000 120000 140000 160000 \nPV HG LeNet FR G1 G2 G3 G4 (default) G5 \nArea in ¬≠ m 2 \n<2, 2, 2, 2, 2> <4, 3, 2, 3, 5> <6, 4, 3, 4, 7> <8, 5, 4, 5, 9> \n<12, 7, 6, 7, 13> \n<2, 2> <6, 2> <9, 3> <11, 5> <16, 7> \n<2, 2> <5, 2> <8, 3> <11, 4> <16, 6> \n<2, 2> <7, 2> <13, 3> <17, 4> <22, 6> \nFig. 13. Area with different duplication granularity \nVII.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 186,
    "augmented": false
  },
  {
    "text": "In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efÔ¨Åciency. The Ô¨Çexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization. Extending this single-ReRAM toy architecture to a practical multi-ReRAM architecture to process multi-layer convolutions for real-world CNNs introduces a new source of power variation in terms of the different time and power costs of different convolution layers.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Inference with Neuron Shapley Value Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget. Otherwise, maintain or reduce the dropout rate to improve accuracy.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "To reduce the impact by the long-latency from rendering, ATW either guesses the next head-orientation or only considers the rotation (no translation), then skews two already-rendered planar FoV frames to remove judders [43]. Note that, this computation still happens in planar-format, and remains the same between two-eyes for one frame. For example, ATW [38] is a post-render technique, which sits between rendering (our focus) and display.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "The dawn after the dark: An empirical study on factuality hallucination in large language models. ACM SIGARCH Computer Architecture News , 34(2):130‚Äì141, 2006. [92] Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "[56] H. R. Mendis, C.-K. Kang, and P.-c. Hsiu, ‚ÄúIntermittent-aware neu- \nral architecture search,‚Äù  ACM Transactions on Embedded Computing Systems (TECS) , vol. 20, no. 5s, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "This is because, the mixed scheme offloads request in the peak to serverless functions. However, the  Paragon  scheme is 10% more cost-effective than mixed and at the same time ensures similar SLOs. It can be seen that mixed scheme has similar cost to reactive but it reduces SLO vi- olations by up to 60%.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "4. ‚Ä¢  In  EA , as discussed in Sec. III, the transformation matrix ( T  ) is determined by the head orientation, which is sampled from the built-in IMU sensors.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Figure 1 shows the DAGs for three Dynamic Function Chains. Social Net- work  (Figure 1a), for example, is one such chain that has 11 functions in total, with each subset of functions contribut- ing to multiple paths (7 paths in total). For instance, from \n154 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ‚Äô21, November 1‚Äì4, 2021, Seattle, WA, USA \nFeatures \nArchipelago [44] \nPower-chief [51] \nFifer [32] \nXanadu [27] \nGrandSLAm [34] \nSequoia [46] \nHybrid Histogram [42] \nCirrus [25] \nKraken \nSLO Guarantees ‚úì ‚úó ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì Dynamic DAG Applications ‚úó ‚úó ‚úó ‚úì ‚úó ‚úó ‚úó ‚úó ‚úì Slack-aware batching ‚úó ‚úó ‚úì ‚úó ‚úì ‚úó ‚úó ‚úó ‚úì Cold Start Spillover Prevention ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úì Function Weight Apportioning ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úó ‚úì Energy Efficieny ‚úó ‚úì ‚úì ‚úì ‚úó ‚úó ‚úì ‚úì ‚úì Request Arrival Prediction ‚úì ‚úó ‚úì ‚úì ‚úì ‚úó ‚úì ‚úó ‚úì Satisfactory Tail Latency ‚úì ‚úó ‚úì ‚úó ‚úì ‚úì ‚úì ‚úì ‚úì \nTable 1: Comparing the features of  Kraken  with other state-of-the- art resource management frameworks.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 377,
    "augmented": false
  },
  {
    "text": "Moreover, the L1 hit rate for both these steps is as high as 99%. Towards this, we profiled the hologram processing on the edge GPU [ 36 ] using the NVPROF tool [ 37 ], and observed the follow- ing: First, the SM utilization for both the steps is very high, i.e., 74% for  Forward-Propagation  and 90% for  Backward-Propagation . This is because the execution is massively parallel at the depth plane level as well as at the pixel level.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "In  ATC , 2018. [42]  Aaron Harlap, Alexey Tumanov, Andrew Chung, Gregory R. Ganger, and Phillip B. Gibbons. Proteus: Agile ML Elasticity Through Tiered Reliability in Dynamic Resource Markets.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "Prior Work \nPrior work for enabling inferences on edge devices have focused on hardware as well as software optimizations, which can be further classiÔ¨Åed into model compression and pruning, and compiler and runtime support. B. 1: A DNN inference pipeline on an edge device with optimizations in the application, system, and hardware levels.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Shiju Li, Kevin Tang, Jin Lim, Chul-Ho Lee, and Jongryool Kim. Computational storage for an energy-efficient deep neural network training system. In  European Conference on Parallel Processing , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Instead, our proposal takes advantage of the Morton code generated in the geometry compression, which is a good indicator for attribute similarity (as discussed earlier in Sec. III-B ). SpeciÔ¨Åcally, our proposal consists of the following 4 steps: PC sorting:  As shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "2: Accuracy comparison of different policies on a simulated distributed setup. Appliance Energy Prediction \nThe appliance energy prediction data-set predicts the energy usage of home appliances, given the environmental parameters, \n3 \nAlgorithm 1:  Training and Inference Pseudocode \nfunction  T RAIN (Sensor Data, NodeID, CloudID) @Edge for  each node  do \nprep data(data,node); ‚ñ∑ pre-process the data at edge if  Privacy Aware  then \ntrain model() ‚ñ∑ Locally train the model send model(cloudID) \nelse \nsend data(cloudID); ‚ñ∑ Send raw data to cloud \n@Cloud for  each node  do \nif  Privacy Aware  then \nsample trees(nodeID);  ‚ñ∑ Sample trees from each node \nelse \nmerge data(); ‚ñ∑ merge raw data from all nodes train(); end function function  I NFERENCE (Data, NodeID) @Edge for  each node  do \nPredict() if  Accuracy  ‚â§ Threshold  then \nSend data(CloudID); ‚ñ∑ Send data to cloud for accuracy \nelse \nSend results(CloudID); ‚ñ∑ Send the inference result Predict@Cloud ‚ñ∑ Run Prediction at Cloud \nend function \n0 \n0.02 \n0.04 \n0.06 \n0.08 \n0.1 \n0.12 \n0.6 \n0.62 \n0.64 \n0.66 \n0.68 \n0.7 \n0.72 \n0.74 \nEdge Cloud (Shared) Cloud (Privacy) \nlatency (ms) \nCorrelation \nPearson Correlation Latency (ms) \n(a) Data from 2 homes \n0 \n0.02 \n0.04 \n0.06 \n0.08 \n0.1 \n0.5 \n0.55 \n0.6 \n0.65 \n0.7 \n0.75 \nEdge Cloud (Shared) Cloud (Privacy) \nLatency (ms) \nCorrelation \nPearson Correlation Latency (ms) \n(b) Data from 4 homes \nFig. The data set is divided into 2 chunks creating a two home set up and the similar is done for a 4 home setup.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 428,
    "augmented": true
  },
  {
    "text": "981. IOP Publishing, 032009. [68]  Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, and Hartwig Adam.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "In this section, we elaborate on the key components, focusing on DynFit and DynInfer, and explain how they uniquely adapt DNN training and inference to intermittent power conditions. 3.1 DynFit: Intermittency-Aware Learning \nDynFit  is designed to optimize deep neural networks (DNNs) for execution in environments char- acterized by intermittent power supply due to energy harvesting. The primary goal of DynFit is to \n3 \nadapt the DNN‚Äôs training process to operate efficiently under unpredictable energy budgets while maintaining acceptable accuracy and adhering to predefined service level objectives (SLOs).",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "In  2009 First International Conference on Advances in System Simu- lation , pages 125‚Äì131, 2009. Flashsim: A simulator for nand flash-based solid-state drives. [82] Youngjae Kim, Brendan Tauras, Aayush Gupta, and Bhuvan Urgaonkar.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "Journal of Parallel and Distributed Computing , 145:45‚Äì58, 2020. [59] Suchin Gururangan, Mike Lewis, Ari Holtzman, Noah A Smith, and Luke Zettlemoyer. Demix layers: Disentangling domains for modular language modeling.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "10: Tradeoff between accuracy drop and energy saving for (a) V1 and (b) V2 picked from the VIRAT [33] dataset. This shows how the proposed ‚Äúadaptive‚Äù solution can potentially save more energy with different thresholds in Algo. 2. \nto evaluate the accuracy, and plot the experimental results in Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "These weights are assigned by the PWS by taking into account function invocation probabilities and parameters pertaining to the DAG structure, namely,  Commonality  (functions common to multiple workflows) and  Connectivity  (number of descen- dant functions), (ii) In addition to the PWS,  Kraken  employs a Reactive Scaler (RS) to scale containers appropriately to re- cover from potential resource mismanagement by the PWS, (iii) Further, we batch multiple requests to each container in order to minimize resource consumption. The number of containers to be deployed is jointly determined by the estimation model and function weights. We have developed a prototype of  Kraken  using  OpenFaaS , an open source serverless framework [ 11 ], and extensively evaluated it using real-world datacenter traces on a 160 core Kubernetes  cluster.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 193,
    "augmented": true
  },
  {
    "text": "2:  Compute  e max total   =  e max cap   +  e inf   +  e comm . Finally, we prove that the equilibrium is reached under the given assumptions. Algorithm 3  Hyperparameter Exploration for Reward Pa- rameters \n1:  Inputs: Estimates  ‚àÜ A min ,  ‚àÜ A max , energy costs e max cap   , e inf , e comm , initial guesses  Œ≥ 0 , Œ¥ 0 , Œ∑ 0 , and tuning increments  ‚àÜ Œ≥ ,  ‚àÜ Œ¥ ,  ‚àÜ Œ∑ .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 147,
    "augmented": true
  },
  {
    "text": "gaming, autonomous driving, etc. Moreover, with the recent pandemic, as telepresence is becoming a norm, people are virtually attending meetings, visiting arts, heritage sites and tourist places across the globe, and even living in a virtual universe. All these applications rely on high quality PC capturing, processing and displaying for a more realistic experience.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "How much data do autonomous vehicles generate? https://premioinc.com . (Accessed on 11/13/2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "2018. [18]  Istemi Ekin Akkus et al . https://cloud.google.com/ functions/docs/.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "‚Ä¢  Our Intra-Inter-V2 (Compression efÔ¨Åciency-oriented):  Sim- ilarly, this design further reduces the compressed data size by 2 % , by adjusting the threshold for ‚Äúdirect-reuse decision making‚Äù, as discussed in Sec. VI-B . At the same time, the quality further drops by  2 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "2018. \"https://www.ni.com/en-us/innovations/white-papers/11/peak- signal-to-noise-ratio-as-an-image-quality-metric.html\". [22]  Yeon-Gyeong Ju and Jae-Hyeung Park.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "(2)  Œ¥  appropriately penalizes incorrect inferences, discouraging low-quality data contri- butions. (3)  Œ∑ > Œ¥  to prevent sensors from consistently abstaining, thereby promoting overall network engagement. These guidelines help in balancing immediate utility gains with long-term energy sustainability, ensuring that the game- theoretic model drives desirable participation behaviors.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "‚Ä¢  Configuring Resources:  From the diverse options, how to right-size VMs and appropriately configure the serverless functions to efficiently cater to user specified cost, accuracy and latency constraint? ‚Ä¢  Bring in Tune : Based on the dynamically changing query arrivals over time, what is the right way to combine model diversity along with resource heterogeneity without com- promising the user-specified requirements? By exploring these key aspects, we envision developing a self-managed inference-serving system, which can provide for different diverse needs of applications by leveraging the \n0 50 100 150 200 250 300 350 \n20.00% \n40.00% \n60.00% \n80.00% \n100.00% \nMobileNet V1 \nMobileNEt V2 \nInception V3 \nResnet50 \nResNet50-V2 \nDenseNet-201 \nDenseNet-121 \nXxception \nNasNetMobile \nInceptionResnetV2 \nvgg16 NasNetLarge \nLatency (ms) \nAccuracy % \nTop1-Accuracy Latency \nFigure 1.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 225,
    "augmented": false
  },
  {
    "text": "Express  (2018), 26722‚Äì26733. Opt. Special-purpose Computer HORN-8 for Phase-type Electro- holography.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, with the Morton codes for all the points (i.e., the intermediate results from geometry compression without any additional overhead), we Ô¨Årst sort these points in the Morton code order, and then segment these sorted points into several blocks which can help to gather the points with similar positions/coordinates into one segment. SpeciÔ¨Åcally, our proposed new pipeline includes the following three steps: \nFigure 5: Intra-Frame geometry compression example. ‚Ä¢  Sort and Segment Points:  Unlike the prior works which utilize the octree to capture the spatial locality between the points when compressing the attributes, we use the Morton codes to cluster the points which are spatially close to each other.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "We use parallelism granularity  G  to denote the duplication count as deÔ¨Åned in [ 5 ]. G  can be determined considering the tradeoff between energy efÔ¨Åciency and chip area during the design phase. In this work, the parallelism granularity  G  of a layer is determined by the ratio between 50% of the peak harvested power during proÔ¨Åling and the power consumption of the full- size ReRAM corresponding to this layer.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "891‚Äì907. IEEE, 2024. National Cybersecurity Center of Excellence (NCCoE).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "Gemini: Mapping and architecture co-exploration for large-scale dnn chiplet accelera- tors. In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pages 156‚Äì171. IEEE, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "2020. Sequoia: Enabling quality-of-service in serverless com- puting. In  Proceedings of the 11th ACM Symposium on Cloud Computing .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "The compiler and system software code and other design artifacts will be maintained in both source formats (e.g., C/C++/C#/Python files) as well as in binary, in an open-source fashion. The educational material will be stored in text, MSWORD, PowerPoint, PDF, and various video formats. When needed, this material will be ported to other formats as well.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "1063‚Äì1075. In  Pro- ceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture . Architectural implications of function-as-a-service computing.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "Intuitively, as mentioned earlier in Sec. III (Fig. 3),  a  Transformation and  b  Projec- tion Computation remain unchanged.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "[31] X. Liu, Q. Xiao, V. Gopalakrishnan, B. Han, F. Qian, and M. Varvello, ‚Äú360¬∞ Innovations for Panoramic Video Streaming,‚Äù in  Proceedings of the 16th ACM Workshop on Hot Topics in Networks , ser. HotNets-XVI, 2017, pp. 50‚Äì56.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "[51] Google. Announcing trillium, the sixth generation of google cloud tpu, 2024. Google gemini. \"",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "0001 ) to  1  (resolution is  0 . This is because low precision leads to a mis-projection, which fails to reÔ¨Çect the current head orientation. 1 ), the reuse ratio increases from  18%  to  92% ; however, the PSNR drops from  85%  to only  19% .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "37‚Äì47, 2022. [30] S. Han, H. Mao, and W. J. Dally, ‚ÄúDeep compression: Compressing \ndeep neural networks with pruning, trained quantization and huffman coding,‚Äù  arXiv preprint arXiv:1510.00149 , 2015. 4, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "This gives us a unique platform to think of intermittency beyond embedded systems and energy. Related Works:  Although there has been signiÔ¨Åcant re- search [ 40 ], [ 41 ], [ 47 ], [ 52 ], [ 56 ], [ 61 ], [ 72 ], [ 104 ] on enabling machine learning in intermittently powered devices, a majority of it focuses on performing inference. Only intermittent learn- ing [ 47 ] focuses on performing on-device training, but with very small workloads and models.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "[36] S. S. Beauchemin and J. L. Barron, ‚ÄúThe Computation of Optical Flow,‚Äù ACM Comput. Surv. , p. 433‚Äì466, 1995.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Power ( ¬µ W) \nPower consumption with full-size acti. ( ¬µ W)/ Thr. (GiGa MACs/s)/ Power utilization \nPower consumption with resilient acti.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "1737‚Äì1746, 2015. [28]  S. Jain, S. Venkataramani, V. Srinivasan, J. Choi, P. Chuang, and L. Chang, ‚ÄúCompensated-dnn: Energy efÔ¨Åcient low-precision deep neural networks by compensating quantization errors,‚Äù in  2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC) , pp. 1‚Äì6, 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "In  11th  { USENIX }  Workshop on Hot Topics in Cloud Computing (HotCloud 19) . Agile cold starts for scalable serverless. 2019.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 38,
    "augmented": true
  },
  {
    "text": "The proposed ar- chitecture is named  D¬¥ej`a View , a play on the word D¬¥ej`a vu, as it uses previous or  already seen  views. Based on this observation, we develop computation optimization mechanisms for facilitating temporal reuse/memoization and spatial reuse that can be integrated with a VR projection computation pipeline to signiÔ¨Åcantly reduce energy consumption of the device. Out of these four scenarios, we observe that  EA  computation for head orientation can be exploited for  temporal reuse/memoization  since there is little difference between two previous head orientations, and  AE computation for exploiting the correlation between both the eyes by  spatial reuse ‚Äì correlating the coordinate relationship between both eyes .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 158,
    "augmented": true
  },
  {
    "text": "[7] 2020. hey HTTP Load Testing Tool. https://docs.microsoft.com/en- us/azure/azure-functions/durable. Azure Durable Functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "4.48 \n0 2 4 6 8 10 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "Variation of cost of using VMs vs.  serverless functions  under constant request load. Each of the four bars under any model type corresponds to request arrival rates of 10, 50, 100, and 200 requests/second. same application requires accuracy to be at-least 80% (ISO- accuracy), as shown in Figure  2b , four different models with different response latencies can satisfy the accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "[3]  A. ShaÔ¨Åee, A. Nag, N. Muralimanohar, R. Balasubramonian, J. P. Strachan, M. Hu, R. S. Williams, and V. Srikumar, ‚ÄúISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars,‚Äù in  2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA) , pp. 14‚Äì26, 2016.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "[126] Bowen Pan, Yikang Shen, Haokun Liu, Mayank Mishra, Gaoyuan Zhang, Aude Oliva, Colin Raffel, and Rameswar Panda. Dense training, sparse inference: Rethinking training of mixture-of-experts language models. arXiv preprint arXiv:2404.05567 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "3.2.2 Dynamic Load  For applications with dynamic load ( Observation 3 ),  serverless functions  can be used to mitigate the over-provisioning cost of VMs. However, a single ap- plication can contain a mix of queries with varying latency demands. To determine the number of requests each VM can handle in parallel, we can conduct offline profiling for different model types.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "However, we argue that there is scope to further optimize resource procurement based on the fre- quency of peak load and constant load in a given request \narrival scenario. Figure  6  plots the peak-to-median ratio for three different traces. From our simulation experiments we observe that  mixed  procurement did not reduce cost of Wiki trace.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Abstract \nHologram processing is the primary bottleneck and contributes to more than 50% of energy consumption in battery-operated aug- mented reality (AR) headsets. Thus, improving the computational efficiency of the holographic pipeline is critical. The objective of this paper is to maximize its energy efficiency without jeopardizing the hologram quality for AR applications.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "This approach defines a large set of different expert types, routers and composition functions that can be used to build an ‚Äúensemble‚Äù (model) that is customized for the application at hand, and allows for independent training and updating of experts, fa- cilitating continual learning and adaptability. By enabling plug-and-play functionality, our design should empower users to customize and extend the model by adding new experts, dropping existing experts and changing the connections among experts, routers and composition functions, fostering collaboration and in- novation within the community. To support this modularity, we also propose a flexible system architecture and runtime that efficiently handles queries.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "US Patent 7,809,601. [71]  Richard Socher, Yoshua Bengio, and Chris Manning. Deep learning for nlp.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "Overall, the normalized results of energy efÔ¨Åciency are very similar to those of the throughput evaluation. The results show that ResiRCA and ResiSchedule achieve average energy efÔ¨Åciency improvements of 14 √ó  compared to a baseline RCA with intermittency-unaware scheduling. The only difference that can be observed is that, regarding LeNet  and  PV  with the power source of  Thermal , relatively speaking, the results of energy efÔ¨Åciency with  Pipelining strategy are higher than that appearing in the throughput evaluation.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Zhiyu Huang, Haochen Liu, and Chen Lv. Annals of GIS , 20(4):265‚Äì277, 2014. A data-driven framework for archiving and exploring social media data.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Calculate the gradients and Hessians of the loss with respect to the weights: \n‚àÇ L ‚àÇW ij , ‚àÇ 2 L ‚àÇW   2 ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) If  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ‚Üê DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the sensitivities: \np i  = Œ≤   P j ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \nmax \u0010P j ‚àÇ 2 L ‚àÇW   2 ij   ( W ij ) 2 \u0011 +  œµ \nm i  = \u001a 0 if Bernoulli (1  ‚àí p i ) = 0 1 otherwise \nPerform the backward pass to update the network weights, considering the dropout mask: \nW  ‚Üê W  ‚àí Œ∑  ‚àÇ L \n‚àÇ W   ‚äô m \nwhere  Œ∑  is the learning rate and  ‚äô denotes element-wise multiplication. Inference with Optimal Brain Damage Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 388,
    "augmented": true
  },
  {
    "text": "We compare these metrics for  Kraken  against the container provisioning policies of Archipelago [ 44 ],  Fifer  [ 32 ] and  Xanadu  [ 27 ], which we will, henceforth, refer to as  Arch ,  Fifer  and  Xanadu , respectively. We set the SLO at 1000ms. Additionally, we compare  Kraken  against policies with (a) statically assigned function probabilities ( SProb ) and (b) func- tion probabilities that dynamically adapt to changing invoca- tion patterns ( DProb ).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 129,
    "augmented": true
  },
  {
    "text": "The major  contributions  of this work can be summarized as follows: ‚Ä¢  We first conduct a detailed characterization of a generic AR processing pipeline to identify the major bottlenecks in current state-of-the-art AR headsets, and set our optimization target as the  hologram computation . (Sec. 2.1) ‚Ä¢  From two open-source AR datasets [ 1 ,  58 ], we identify two prop- erties in AR hologram applications:  spatio diversity for objects , and  temporal locality for the user (viewer) interests (i.e., user typ- ically focuses on one region within a short period of time) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 150,
    "augmented": false
  },
  {
    "text": "If it detects requests whose wait times exceed the cost of spawning a new container (the cold start of the function), overloading is said to have occurred at the stage. To deal with this,  Kraken  also employs the RS  7  to scale containers up or down in response to re- quest overloading at containers (due to under-provisioning) and container over-provisioning, respectively. In case of inadequate container provisioning, the Overload Detector  7a  in the RS  7  detects the number of allocated con- tainers for each DAG stage and calculates the estimated wait times of their queued requests (Algorithm 2  b  ).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2407.11686 , 2024. [68] Patrick Iff, Benigna Bruggmann, Maciej Besta, Luca Benini, and Torsten Hoefler. Rapidchiplet: A toolchain for rapid design space exploration of chiplet architectures, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Similarly, other applications with diverse data modalities, such as LiDAR and Camera for autonomous driving, IMU, bio-sensors, and Speech for IoT, face similar issues. Thus,  attaining a sustain- able solution for privacy-preserving, distributed continuous learning remains an ongoing pursuit. Exploiting Intermittent Computing:  An obvious solution to the power problem is to run the training in a self-sustained way, i.e., without depending on the power grid and by relying on a renewable energy source like solar power; opportunities for harvesting renewables naturally scale alongside a greater number of deployment locations and solar power, even though not always available, is in abundance.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 154,
    "augmented": false
  },
  {
    "text": "). By harnessing ambient energy sources such as solar, thermal, or kinetic energy, EH sensors can operate indefinitely without the need for battery replace- ment or external power supplies. However, the intermittent and unpredictable nature of harvested energy introduces significant challenges in maintaining reliable and consistent network performance ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "(Accessed on 11/21/2022). Mallesham Dasari, Kumara Kahatapitiya, Samir R Das, Aruna Balasubramanian, and Dimitris Samaras. Swift: Adaptive video streaming with layered neural codecs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "The major focus of these works have been building compute platforms with efficient scheduling (Bhardwaj et al., 2022; Mishra et al., 2024), and reconfigurable hardware design (Kim et al., 2024; Mishra et al., 2024). This solves majority of the bottlenecks in a performance-driven classical cloud server platform. 2 Background and Motivation \n2.1 Storage for Continuous Learning Edge Servers \nRecent developments in continuous learning for video analytics (Bhardwaj et al., 2022; Mishra et al., 2024; Kim et al., 2024) has significantly boosted the capabilities and accuracy of learning systems.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 165,
    "augmented": true
  },
  {
    "text": "[18] A. F. CNBC, ‚ÄúHow trafÔ¨Åc sensors and cameras are trans- forming city streets,‚Äù  https://www.cnbc.com/2021/02/22/how-trafÔ¨Åc- sensors-and-cameras-are-transforming-city-streets.html , (Accessed on 04/28/2023). [19] Coral.ai, ‚ÄúEdge tpu performance benchmarks =  https://coral.ai/docs/ \nedgetpu/benchmarks/ ,‚Äù (Accessed on 11/21/2022). [20] D Maltoni, V Lomonaco, ‚ÄúContinuous learning in single-incremental- \ntask scenarios,‚Äù in  Neural Networks , 2019.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "Exploiting frame similarity for efficient inference on edge devices. In  2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) , pp. 1073‚Äì1084, 2022b.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "At any instance, a user is only concerned about the FoV pixels in the entire  360 ¬∞ frame. 3), we use the transformation matrix ( T  ) to generate the mapping ( P ) between the  360 ¬∞ frame coordinates and the  2 D  FoV frame coordinates. In the  Projection Computation  stage (refer to  b  in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Here,  Cocktail  reduces the number of models by up to 55% for all four query types. This is because our dynamic pol- icy ensures that the number of models are well within  N / 2 most of the time, whereas the  Clipper-X  policy does not ag- gressively scale down models. Clipper , on the other hand, is static and always uses all the models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "As the RoIs size increases along the video (e.g., ratio of RoIs/whole frame increases from  8%  in frame20 to  53%  in frame2470), the beneÔ¨Åts from PI become increasingly lower, resulting in similar patterns for FI+SI and FI+SI+PI. In these two slices, the objects keep moving. Besides these six videos, we also picked two  slices from V1 and V2 (i.e., V1P and V2P) to show the effectiveness of our PI technique.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "For the DNNs in question, coresets can achieve sufficient compression ratios to make communication energy-competitive with computation, as well as opening up new opportunities for optimizing DNN in- ference on the coreset, rather than original data. Finally, most of the coreset construction algorithms are simple (hence can achieve  1  ) and do not need complex operations (like cosine, exponential, etc. [ 7 ,  8 ,  36 ,  37 ], they can also be quantized [ 37 ] to further reduce their computation and memory footprints.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "System Model \nWe consider a network of  N EH sensors  S = { s 1 , s 2 , . . .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "[82] scale.com, ‚ÄúData labeling: The authoritative guide,‚Äù https://scale.com/guides/data-labeling-annotation-guide#data-labeling- for-computer-vision , (Accessed on 11/21/2022). [83] A. W. Services, ‚ÄúAws outposts rack pricing,‚Äù  https://aws.amazon.com/ \noutposts/rack/pricing/ , (Accessed on 11/21/2022). [84] K. Seyerlehner, G. Widmer, and P. Knees, ‚ÄúFrame level audio \nsimilarity-a codebook approach,‚Äù in  Proc.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "DeepThings: Distributed adaptive deep learning inference on resource-constrained IoT edge clusters. [69]  Zhuoran Zhao, Kamyar Mirzazad Barijough, and Andreas Gerstlauer. 2018.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "By integrating these components, an EH system can sustainably power devices without relying on traditional power grids, making it ideal for remote or mobile applications. This component helps smooth out the supply, providing steady power to the compute circuit. Energy Storage : Finally, to ensure a continuous power supply even when the immediate energy source is inconsistent (like when a cloud passes over a solar panel), the system includes a temporary storage unit, such as a super-capacitor.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "For such scenarios, due to the prevailing relationship between the left and right eye transformation matrices ( T L  and  T R ), we can further avail the spatial compute reuse opportunity shown in b in Fig. ‚Ä¢  AE  comes to play when there is a change in head orientation in consecutive frames, and we cannot enjoy the oppor- tunities in  EA . 4.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "The ‚ÄôBaseline‚Äô model is a fully powered system with no energy restrictions, and the quantized model runs on harvested energy using a RR12 policy. the data efficiently , since communication is an expensive task and especially challenging for EH-WSNs [ 22 ] thanks to their fickle and ultra-low energy budget. The obvious solution is to reduce the communication data volume by compress- ing the data before transmitting.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "19, no. [49] S. Li, Z. Yang, D. Reddy, A. Srivastava, and B. Jacob, ‚ÄúDramsim3: \na cycle-accurate, thermal-capable dram simulator,‚Äù  IEEE Computer Architecture Letters , vol. 2, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. Journal of Machine Learning Research , 23(120):1‚Äì39, 2022. [43] Yuan Feng, Junlin Lv, Yukun Cao, Xike Xie, and S. Kevin Zhou.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "12, no. [50]  A.-M. S. Mohamed, ‚ÄúPotential of 3d laser point cloud data usage for the tourism industry,‚Äù in  The International Conference on Civil and Architecture Engineering , vol. 1‚Äì6.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "[73] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L√©lio Re- nard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Tim- oth√©e Lacroix, and William El Sayed. [74] Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bam- ford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. Mistral 7b, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 199,
    "augmented": true
  },
  {
    "text": "Partici- pation during training follows the same equilibrium model: sensors decide whether to compute and send gradients based on their current energy states, predicted future utilities, and the established reward structure. By aggregating these gradi- ent updates over multiple training rounds, the aggregator ap- proximates the gradient  ‚àá J ( Œ∏ )  and performs an SGD step. Our training framework is encapsulated in Algorithm  2 , which outlines the periodic equilibrium-aware training pro- cess.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "Through this integrated approach, we aim to lower the barriers to entry for AI development. In this context, we propose a research plan consisting of 4 intertwined thrusts. Thrust-1 is aimed at in- vestigating the algorithmic foundations of our EoE paradigm that consists of an ensemble of experts, which will facilitate application-specific morphable LLMs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "2019. Agile cold starts for scalable serverless. In  11th  { USENIX }  Workshop on Hot Topics in Cloud Computing (HotCloud 19) .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "To explore these opportunities, Fig. 2a plots the ‚Äúpixel-level similarity‚Äù between two successive frames in a video. Here, we vary the tile size (an N √ó N tile is a N √ó N pixel block) from 4 √ó 4 to the entire frame (1080 √ó 1920) on the x-axis, and the y-axis gives the fraction of ‚Äúidentical tiles‚Äù (when compared pixel-by- pixel) in  two successive frames .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "3) How to Maintain Accuracy? :  To preserve accuracy, we back-trace the output feature map (FM) to investigate how the different regions of the input FM affect the the output for convolution layer 2 , as shown in Fig. 5 and carefully consider our design decisions.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "[68]  Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, and Hartwig Adam. 2018. NetAdapt: Platform- Aware Neural Network Adaptation for Mobile Applications.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "Unfortunately, prior works mainly focused on compression ratio, but did not consider the performance and energy implications, particularly for edge devices. This paper exploits the data similarity opportunities in  both  geometry and attribute data from  both  intra-frame and inter-frame perspectives, and proposes two complementary designs for minimizing the compression latency and energy requirements for pushing the PC compression to the edge. And, more importantly, these proposals are compliant with the emerging MPEG PCC standards [ 53 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 √ó  compared to a baseline RCA with intermittency-unaware scheduling. One can make the following observations and analyses from these results: ‚Ä¢  For each workload with each power source,  ResiSchedule always achieves the highest throughput because it combines the best activation solution in each power cycle. The results of Naive1  are the worst because it lacks both adequate hardware resources and scheduling Ô¨Çexibility.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "[5]  J. R. Gunasekaran, P. Thinakaran, et al . In  USENIX Middleware Conference . Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "To support this modularity, we also propose a flexible system architecture and runtime that efficiently handles queries. Smart routers dynamically direct queries to the most rele- vant experts based on domain relevance and operational dynamics, optimizing performance and resource utilization. This dynamic routing reduces computational overhead and energy consumption, helping in addressing the power efficiency concerns.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "[118] NVIDIA. Nvidia‚Äôs deep learning data parallelism strategies for high-performance training, 2021. [119] Nvidia.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "4.1.2 Proactive Container Provisioning : Once function weights are assigned by considering the above factors, they are employed in estimating the number of containers needed per DAG stage ( Estimate_Containers  in Algorithm 1). These containers have to be provisioned in advance to service fu- ture load to shield the end user from the effects of cold starts \nand thereby meet the SLO. Note that we deal with the possibility of container overprovisioning due to the in- creased function weights by allowing both  Connectivity  and Commonality  to be capped at a certain value.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "1‚Äì12. [38] Junchen Jiang, Ganesh Ananthanarayanan, Peter Bod¬¥ƒ±k, Siddhartha \nSen, Ion Stoica, ‚ÄúChameleon: Scalable adaptation of video analytics,‚Äù in  ACM SIGCOMM , 2018. [39] Junjue Wang, Ziqiang Feng, Shilpa George, Roger Iyengar, Pillai Pad- \nmanabhan, Mahadev Satyanarayanan, ‚ÄúTowards scalable edge-native applications,‚Äù in  ACM/IEEE Symposium on Edge Computing , 2019.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "Experimental Platform and Datasets \nPlatforms : We used the Google Pixel 3 Android Phone [20] as our experimental platform. This device consists of a 64-Bit Octa-Core, a Qualcomm Snapdragon 845 SoC, [39], a 4GB LPDDR4X memory, and a 64GB storage. We implemented our FI and PI on top of the ncnn library [5].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "2020. OpenHolo Database. \"http://openholo.org/database/depth\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "Maximization of wireless sensor network lifetime using solar energy harvesting for smart agriculture monitoring. Ad Hoc Networks  94 (2019), 101966. [64]  Zhuoran Song, Bangqi Fu, Feiyang Wu, Zhaoming Jiang, Li Jiang, Naifeng Jing, and Xiaoyao Liang.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "power (mW). 1006.01 \n0 500 \n1000 1500 2000 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "CWIPC. Note that, although our schemes employ the GPU with an extra overhead (e.g., the GPU power is about 1065 mW ), the CPU power is reduced (e.g., around  1310 mW , lower than that in TMC13 and CWIPC) since most of the computations are ofÔ¨Çoaded to GPU. 5 J energy, respectively, which translate to  ‚âà 97%  energy savings w.r.t.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Combining Inter-frame and Intra-frame Compression \nSimply put, our intra-frame compression proposal can sig- niÔ¨Åcantly reduce the execution latency, while the inter-frame compression proposal can further improve the compression efÔ¨Åciency. B. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Each frame  F t  is divided into blocks B t,i , where  i  indexes the block within the frame. The residual frame  R t  for each frame is calculated as: R t  =  F t  ‚àí predict ( F t ‚àí 1 , M t ) where  predict ( ¬∑ )  is a function that reconstructs  F t  from  F t ‚àí 1  using the motion vector field  M t . This prediction involves translating the blocks of  F t ‚àí 1  according to  M t  and serves as the predicted frame.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "[24]  B. Han, Y. Liu, and F. Qian,  ViVo: Visibility-Aware Mobile Volumetric Video Streaming . Association for Computing Machinery, 2020. [25]  X.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "TABLE IV: Comparison against Potluck and MCDNN \nmAP Latency Energy MCDNN 36.9% 33% 35% Potluck 51.6% 63% 61% This Work 50.3% 35% 34% in Fig. 8d and Fig. 9d, DeepCache can only save  38% and  45%  on execution time for YOLOv3 and YOLOv4-tiny, respectively, which are less than both FI+SI (e.g., 52% for YOLOv3; 53% for YOLOv4-tiny) and FI+SI+PI (e.g., 55% for YOLOv3; 61% for YOLOv4-tiny) schemes.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "2) High-level Idea:  To answer the above questions, we propose region-level partial inference (PI) to Ô¨Årst determine \nAlgorithm 2:  Region Level Reuse Algo. Input :  RD : Reuse Distance Input :  BBs : Bounding Boxes in Previous Frames Input :  MV s : Motion Vectors for Current Frame Output:  Flag : Decisions (Full, Partial, or Skip) Output:  RoIs : Regions of Interest \n1  procedure  Region _ Decision ( RD ,  BBs ,  MV s ) // main \n2 if  Frame Decision ( RD ,  BBs ,  MV s )  is  False  then \n3 return  { Skip , null } \n4 if  IsScenario 2  or  IsScenario 3  then \n5 return  { Full , null } \n6 for  mv  in  MV s  do // only consider Scenario1 \n7 if  max { overlapped.area } ‚â§ T moving 2  √ó  mv.area  then \n8 return  { Full , null } \n9 return  { Partial ,   \u0002   [ BBs, MV s ]  } \nFig. 4: Main idea in our partial inference scheme.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 297,
    "augmented": false
  },
  {
    "text": "0 \n1 \n2 \n3 \n4 \n5 \n6 \n7 \nKitti Vision nuScenes Chime Cityscapes Waymo \nNormalized Latency \nCompute Server CSD Alveo FPGA \nFigure 4: Latency analysis of  Salient Store  on the commercial Xilinx CSD on a workstation class machine (lower is better). Compute server indicates a software only classical storage solution without CSDs. Data Location kernel Execution SpeedUp CSD1 CPU 1 CSD1 CSD1 3.9 CSD1 (0.1X), CSD2(0.9X) CSD1 (0.1X), CSD2(0.9X) 4.46 CSD1 (0.3X), CSD2(0.7X) CSD1 (0.3X), CSD2(0.7X) 5.608 CSD1 (0.4X), CSD2(0.6X) CSD1 (0.4X), CSD2(0.6X) 6.67 CSD1 (0.5X), CSD2(0.5X) CSD1 (0.5X), CSD2(0.5X) 7.7 Table 2: Effect of Data distribution on compute speed-up.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 244,
    "augmented": false
  },
  {
    "text": "It can be seen that for higher accuracies, Cocktail  tries to ensemble more models to reach the accuracy, while for lower accuracy it resorts to using single models. 6.3.4 Sensitivity to Dataset \nTo demonstrate the applicability of  Cocktail  to multiple datasets, we conducted similar experiments as elucidated in Section  5.2.1  using the  CIFAR-100  dataset [ 50 ]. It comprises of 100 distinct image classes and we trained 11 different models including the nine that are common from Table  1 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "It completed more training tasks while consuming less power and minimizing wastage. In contrast, cloud-based solutions ex- hibited poor sustainability, relying on high-power-consuming GP-GPUs, and edge servers without power availability strug- gled to perform any compute. Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "E. Sensitivity Study \nOur proposed intra-frame PCC utilizes the Morton code to capture the spatial locality, and signiÔ¨Åcantly speeds up the compression ( 44 √ó ), with high compressed quality (48.5 dB PSNR). Additionally, by exploiting the temporal locality across frames, our inter-frame compression further increases compression efÔ¨Åciency with the cost of longer processing latency and lower quality. To study how the inter-compressed frames/blocks would affect the compression efÔ¨Åciency (the compressed size w.r.t.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "Manuel J Fonseca and Joaquim A Jorge. URL  https://arxiv.org/abs/2303.09998 . Tbp-former: Learning temporal bird‚Äôs-eye-view pyramid for joint perception and prediction in vision-centric autonomous driving, 2023.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "28%  ( Paris video). 9. By applying the  EA  optimization itself, on an average, the energy beneÔ¨Åt is translated to  14%  end-to-end energy savings, as shown on the right y-axis in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "We implemented a counter (local kernel counter) to keep track of the size of the remaining local work queue of each of the tile. Whenever all the local work queue counter hits zero along with the layer kernel counter, the control moves to schedule the next layer (or previous layer in backward propagation) for computation. We also implemented a counter (layer kernel counter) which keeps track of the total kernels to be scheduled for each layer.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "SpeciÔ¨Åcally, to compute the 2-norm attribute distance, two kernel functions are invoked ( Diff Squared  and Squared Sum ), which consume 35 %  and 16 % , respectively of the total energy. As shown in Fig. 9 , the address generation stage for storing P-blocks‚Äô deltas/residuals consumes 32 %  of total energy, while the computation for the 2-norm attribute distance consumes 51 %  energy, which dominates the total energy consumption, and is, therefore, our target for next-step optimization.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Holistic Approach:  Unlike other methods that focus on either training or inference optimizations, NExUME provides a comprehensive solution that addresses both phases, leading to superior overall performance. Efficient Scheduling:  DynInfer‚Äôs energy-aware task scheduling and task fusion mechanisms reduce overhead from checkpointing and optimize the execution of tasks within \n8 \nthe available energy budget. 4.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "The higher the variance the more conÔ¨Ådent is the classiÔ¨Åcation. Therefore, a good metric for the conÔ¨Ådence would be the vari- ance of the output probability vector. 25] , where the classiÔ¨Åer is equally confused between all the classes.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "Dataset Platform Energy Source Stateful ePerceptive DynBal NExUME \nFMNIST MSP430FR5994 Piezoelectric 20.1 20.8 21.5 23.4 CIFAR10 Arduino Nano Thermal 16.0 16.5 17.0 18.5 MHEALTH ESP32 S3 Eye Piezoelectric 18.5 19.0 19.6 21.0 PAMAP STM32H7 Thermal 16.5 17.0 17.5 19.0 AudioMNIST Raspberry Pi Pico Piezoelectric 20.5 21.0 21.7 23.2 Table 2: Energy efficiency comparison on different hardware platforms. Table 2 presents the energy efficiency in MOps/Joule for each dataset on different hardware platforms using piezoelectric and thermal energy harvesting. NExUME achieves the highest energy efficiency across all platforms and datasets.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 175,
    "augmented": true
  },
  {
    "text": "In  Advances in neural information processing systems , pages 8026‚Äì8037, 2019. [62]  Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Brad- bury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "case.edu/bearingdatacenter/download-data-file , 2018. Bearing fault data. https://engineering.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "ly/3OF66Tw‚Äù , 2021. [3] Apple Inc.,  ‚Äùhttps://www.apple.com/iphone-13-pro/‚Äù , 2021. [4]  S. Ayukawa, N. Tokudome, S. Enokida, and T. Nishida, ‚ÄúTime- series lidar data superimposition for autonomous driving,‚Äù  Proc.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "In summary, our research presents a comprehensive vision for the future of storage systems in ML, where computational storage \n17 \ndevices play a key role in advancing the, performance, efficiency, and capabilities of storage servers, thereby contributing significantly to the broader field of ML. Achieving Compliant Data Res- idency and Security with Azure. References \nAchieving Compliant Data Residency and Security with Azure.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "In contrast, a game-theoretic framework provides equilib- rium guarantees, ensuring stable and cooperative partici- pation strategies. Alternatively, reinforcement learning or Markov Decision Process-based approaches could adaptively learn partici- pation policies that consider both immediate rewards and future states. However, these methods often require exten- sive training data, significant computational resources, and complex communication protocols, which may be impracti- cal for resource-constrained sensor nodes.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "The tile-level shows how each tile consists of multiple such PEs and will be working on one kernel at a time. 6: Weight stationary compute mapping. The PE-level shows how the input Ô¨Çows and the convolutions are computed with a 3x3 convolution toy example.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "[3]  Andrew Chung, Jun Woo Park, and Gregory R. Ganger. Firecracker: Lightweight Virtualization for Serverless Applications. In  NSDI .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "Other Resources:  Penn State Institute for Computational and Data Sciences (ICDS), of which Mahmut Kandemir is an associate director, provides a variety of compute, storage and network resources, various IT services, including operations, backup, technical consulting, and training material, and is compliant with specific NSF, NIH, and NIST security controls. It offers over 1000 servers with over 40,000 processing cores, over 300 NVIDIA GPUs, 5 Petabytes (PB) of disk parallel file storage and 10 PB of archive storage, high- speed Ethernet and Infiniband interconnects, and a large software stack. The PIs also have access to NSF CloudBank, ACCESS and various NERSC resources.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "[87] K. Simonyan and A. Zisserman, ‚ÄúVery deep convolutional networks for \nlarge-scale image recognition,‚Äù  arXiv preprint arXiv:1409.1556 , 2014. [88] snorkel.ai, ‚ÄúMaking automated data labeling a reality in modern ai,‚Äù \nhttps://snorkel.ai/automated-data-labeling/ , (Accessed on 11/21/2022). [89] E. Strubell, A. Ganesh, and A. McCallum, ‚ÄúEnergy and policy con- \nsiderations for deep learning in nlp,‚Äù  arXiv preprint arXiv:1906.02243 , 2019.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 166,
    "augmented": false
  },
  {
    "text": "[19] H. Jiang, A. Sarma, M. Fan, J. Ryoo, M. Arunachalam, S. Naveen, and M. T. Kandemir, ‚ÄúMorphable convolutional neural network for biomedical image segmentation,‚Äù in  2021 Design, Automation Test in Europe Conference Exhibition (DATE) , 2021, pp. 1522‚Äì1525. [20] Google, ‚ÄúPixel Phone Hardware Tech Specs,‚Äù ‚Äùhttps://bit.ly/397dCUB‚Äù.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "R EFERENCES \n[1]  E. E. Aksoy, S. Baci, and S. Cavdar, ‚ÄúSalsanet: Fast road and vehicle segmentation in lidar point clouds for autonomous driving,‚Äù in  2020 IEEE intelligent vehicles symposium (IV) . IEEE, 2020, pp. 926‚Äì932.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "While  ‚àÜ A i ( t )  may not be known precisely, we as- sume that each sensor can estimate its expected contribution based on historical observations and current conditions. This quantity depends on SNR i ( t )  and on the data contributed by other participating sensors, as their combined perspectives shape the overall result. Ev- ery inference event presents a binary decision for sensor  s i : a i ( t )  ‚àà{ Participate (P) ,  Not Participate (NP) } .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "[72]  Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 conference on empirical methods in natural language processing , pages 1631‚Äì1642, 2013.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "This leaves us with the following important questions: ‚Ä¢  Are continuous inferences essential, or can we leverage the workload itself to skip some inferences without substantial accuracy loss, allowing enough energy to be accumulated for future inferences? ‚Ä¢  Since all the sensors cannot be activated together due to the limited power, how do we effectively perform the ensemble? III.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "LLM Hardware and Accelerators:  These sophisticated system level strategies require the use of equally high-performing hardware to complement for faster, efficient and economic implementation for both train- ing and inferring from these models. Innovations in this domain include the latest GPUs optimized for LLM use-cases [1, 2], TPUs [76], domain-specific accelerators like Cerebras Systems Wafer-Scale Engine (WSE) [86], Graphcore Intelligence Processing Units (IPUs) [54], Habana Lab‚Äôs Gaudi and Goya accel- erators [87, 103], SambaNova‚Äôs SN40L reconfigurable dataflow unit (RDU) [131], and Groq [61]. These aforementioned hardware equivocally echo the need of highly parallel computation with bigger and faster memory hierarchy to contain the pool of data for high-scale deployments.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 207,
    "augmented": false
  },
  {
    "text": "In this project, we will investigate the fault-tolerance behavior of the chiplet architecture by injecting different types of faults. 2.4 Thrust-4: Evaluation And Fine Tuning In order to evaluate the efficacy our EoE-based cross-layer design framework in terms of performance, en- ergy efficiency and accuracy metrics, we propose to develop a comprehensive evaluation platform that consists of an in-depth simulation infrastructure, analytical models and appropriate measurements on available systems. Specifically, this thrust targets at answering the following questions: i)  What kind of simulation-emulation system is needed to carry out our experiments?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "The goal of the training process is to adjust  Œ∏  to these condi- tions, effectively  fine-tuning  the model to the nonstationary data distribution  D  induced by the sensors‚Äô equilibrium be- haviors. However, this initial model may not be optimally adapted to the complex operational reality of the network, where sensors strategically choose SNR levels, participate inter- mittently according to equilibrium strategies, and generate data distributions that deviate from the original training set. At equilibrium, sensors strike a balance between accurate data contribution and energy conservation, result- ing in a stable pattern of participation and SNR choices.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 139,
    "augmented": true
  },
  {
    "text": "To assess the computational overhead introduced by DynFit, a component of NExUME, we use NVIDIA Nsight Compute. During the training sessions enhanced by DynFit, we observed an increase in the number of instructions ranging from a minimum of 11.4% to a maximum of 34.2%. While the overhead in streaming multi-processor (SM) utilization was marginal (within 5%), there was a noticeable increase in memory bandwidth usage, ranging from 6% to 17%.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "It can be seen that although both  util_aware  and  exascale  can reduce SLO vi- olations (shown in Figure  5 ), they still suffer from 20% to 30% over-provisioned VMs across all four traces. Each request in the trace is associated with an ML inference query, which is randomly picked from our model pool. Figure  4 shows the ratio of over-provisioned VMs compared to a baseline  reactive  autoscaling mechanism.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "1184‚Äì1188. [23] P. Foster, S. Sigtia, S. Krstulovic, J. Barker, and M. D. Plumbley, \n‚ÄúChime-home: A dataset for sound source recognition in a domestic environment,‚Äù in  2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) . IEEE, 2015, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2401.08671 , 2024. [66] Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. A survey on hallucination in large lan- guage models: Principles, taxonomy, challenges, and open questions.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "9. 8b) and YOLOv4-tiny (see Fig. First, by comparing YOLOv3 (see Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "This statement should be in an unnumbered section at the end of the paper (co- located with Acknowledgments ‚Äì the two may appear in either order, but both must be before References), and does not count toward the paper page limit. Conclusion \nThis should finish at 8 pages. Impact Statement \nAuthors are  required  to include a statement of the potential broader impact of their work, including its ethical aspects and future societal consequences.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "[157] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. Attention is all you need. In  Advances in Neural Information Processing Systems , pages 5998‚Äì6008, 2017.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "Model-serving in Cloud : The most relevant prior works to Cocktail  are InFaas [ 83 ] and Clipper [ 27 ], which have been extensively discussed and compared to in Section  6 . Recently FrugalML [ 20 ] was proposed to cost-effectively choose from commercial MLaaS APIs. While striking a few similarities with  Cocktail , it is practically limited to image-classiÔ¨Åcation applications with very few classes and does not address re- source provisioning challenges.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "73‚Äì 76, 2014. [17]  K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, ‚ÄúArchitecture exploration for ambient energy harvesting nonvolatile processors,‚Äù in  2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , pp. [16]  X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, ‚ÄúRF-powered systems using steep-slope devices,‚Äù in  2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "Moreover, the majority of functions whose Commonality  and  Connectivity  differ, have a high batch size, thereby reducing the variation in the number of containers spawned. Upon closer examination, we see that this is due to functions having different degrees of  Commonality and  Connectivity . Following this, we observe that the variation in the number of containers in  Social Network  is mainly due to the significant difference in the  Commonality  and  Connectivity of the  Compose Post  function whose batch size is only one.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 110,
    "augmented": true
  },
  {
    "text": "However, even selective rendering of the portion of a scene, which is in the field of view (FoV) of the user, on a mobile device with limited compute and power budget is challenging [ 19 ,  52 ]. This calls for finding further opportunities for optimization. These sensor inputs play a major role in deciding which portions of the 3D voxels need to be rendered for the user to view.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "The efficiency of data movement significantly influences the performance and energy consumption of large-scale systems (Park et al.). As earlier discussions highlighted, applications on edge servers need to store generated data on storage stacks. These data are can then be moved to a central facility where they can be further treated for efficient retrieval ans on demand streaming.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Machine Learning as a Service., February 2018. https://azure.microsoft.com/en-us/pricing/details/machine-learning- service/ . [11]  Azure. Ensembling in Azure ML Studio., February 2020. https://docs.microsoft.com/en-us/azure/machine-learning/studio- module-reference/multiclass-decision-forest .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Vitis unified software platform. AMD. https://www.xilinx.com/products/design-tools/ vitis/vitis-platform.html , a.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  }
]