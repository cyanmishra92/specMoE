=== ORIGINAL PDF: ResiRCA.pdf ===\n\nRaw text length: 75876 characters\nCleaned text length: 75096 characters\nNumber of segments: 53\n\n=== CLEANED TEXT ===\n\nResiRCA: A resilient energy harvesting ReRAM crossbar-based accelerator for intelligent embedded processors Keni Qiu1, Nicholas Jao3, Mengying Zhao2, Cyan Subhra Mishra3, Gulsum Gudukbay3, Sethu Jose3, Jack Sampson3, Mahmut Taylan Kandemir3 and Vijaykrishnan Narayanan3 1Capital Normal University, Beijing, China, (Email: 2Shandong University, Qingdao, China , (Email: 3Pennsylvania State University, USA, (Email: {naj5075, cyan, gulsum, {sampson, mtk2, Abstract Many recent works have shown substantial efﬁciency boosts from performing inference tasks on Internet of Things (IoT) nodes rather than merely transmitting raw sensor data. However, such tasks, e.g., convolutional neural networks (CNN), are very compute intensive. They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes. ReRAM crossbar-based accelera- tors (RCAs) are an ideal candidate to perform the dominant multiplication-and-accumulation (MAC) operations in CNNs ef- ﬁciently, but conventional, performance-oriented RCAs, while energy-efﬁcient, are power hungry and ill-optimized for the intermittent and unstable power supply of energy-harvesting IoT nodes. This paper presents the ResiRCA architecture that integrates a new, lightweight, and conﬁgurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node. To maximize ResiRCA throughput under different power levels, we develop the ResiSchedule approach for dynamic RCA reconﬁguration. The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. Experimental results show that ResiRCA and ResiSchedule achieve average speedups and energy efﬁciency improvements of 8 and 14 respectively compared to a baseline RCA with intermittency-unaware scheduling. Keywords-Energy harvesting, ReRAM crossbar, CNN, Recon- ﬁgurable hardware, Loop tiling, Computation scheduling I. INTRODUCTION In recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [1]. Such integration grants IoT devices an important degree of independence from remote servers, which can be critical in deployments with challenging communication environments. However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms. Such platforms often already operate at their limits just in order to transmit sensed data at acceptable quality of service (QoS) rates for deployment-viable battery lifetimes, and may not have additional resources available for further computation. For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type. In CNNs, for instance, MACs between the feature map data and kernel weights comprise nearly 90 of the total operations [2], [3]. Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efﬁciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [3], [4], [5], [6], [7], [8], [9], [10]. In the remainder of the paper, we may shorten the term ReRAM crossbars to ReRAMs. Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efﬁciently performing inference on an IoT device if it does not have either a high power or high stability power source. Given form factor constraints on energy storage, the former may be challenging, and energy-harvesting from sources such as solar, thermal, kinetic and radio frequency [11], [12], [13], [14], [15], [16] is notoriously unstable. While unstable power sources have been successfully utilized for applications in the IoT space [17], [18], [19], their use has not been heavily explored for RCA design. Current RCA approaches can be divided into two categories. The approaches in the ﬁrst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [3], [4], [5], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [6], [8]. However, neither of them is a good ﬁt for energy-harvesting scenarios. To address these challenges, this paper proposes and experi- mentally evaluates ResiRCA, a resilient ReRAM crossbar-based CNN accelerator. Supported by a reconﬁgurable lightweight hardware design, ResiRCA is able to activate scalable com- putations via a multi-dimension tuning strategy. ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference. In this design paradigm, the basic low power, lightweight MCU system can enjoy the advantage of continuous operation without suffering power outages, while the compute-heavy inference tasks can be ofﬂoaded to the RCA during periods when power income is sufﬁciently high and to external systems otherwise. Such a system is capable of both continuously collecting data and computing CNNs locally near data. ResiRCA allows an RCA to adapt to changing harvested energy and, with our co-designed scheduling approach, ResiSchedule, it can achieve very high throughput. To the best of our knowledge, this is the ﬁrst work that focuses on low power and reconﬁgurable RCA design from both the hardware and software angles targeting energy harvesting systems. This paper makes the following key contributions: Low power, reconﬁgurable hardware design: We pro- pose a novel architecture that implements a lightweight and low power RCA to adapt to time-varying power resources. Furthermore, the proposed hardware is reconﬁgurable at a ﬁne grain, to be able to dynamically activate different scaled computations, which can ﬁt to the changing features of the underlying power resources. Resilient computation scheduling: We provide three knobs to schedule computation blocks in the proposed ar- chitecture: (i) loop tiling which decomposes MAC operations in a given layer (ReRAM) into small blocks, (ii) ReRAM duplication which provides opportunity to perform one-layer operations with multiple weight copies, and (iii) pipelining that can organize multiple ReRAM tiles to further exploit the har- vested power. These knobs can be integrated to form sequential or pipelined computation modes. For each computation mode, we can derive the optimal activation solutions under each power level directed by the power model and throughput model ofﬂine. We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution. Smooth schedule transitioning: We identify smooth transition conditions to transfer as many partial results as possible from the last incomplete inference in one power cycle to the next power cycle with a different power level. In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction. II. MOTIVATION To avoid negatively impacting the underlying system s QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available. In energy harvesting systems, there are two critical features, namely, power strength and power window length. First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power. Second, the variance of the input power window, i.e., how long the power input stays at a given level, can be large as well. It is known that RCAs achieve their highest efﬁciency when every cell participates in the MAC computations simul- taneously [20]. However, naively integrating such an RCA renders its activation power requirement so high that the system will likely have very low duty-cycle on an intermittent supply and may never activate at all for weaker power sources unless a substantial energy store were added, which could be burdensome for form factor constraints in a system that already employs a battery for sensing and other non-inference tasks. TABLE I AN EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT-CYCLE POWER TRACE. Power cycle Harv. Power (µW) Power consumption with full-size acti.(µW) Thr. (GiGa MACs s) Power utilization Power consumption with resilient acti. (µW) Thr. (Giga MACs s) Power utilization 1 50 0 Power failure 0 0 0 Power failure 0 0 2 100 0 Power failure 0 0 80 25 1 1 0.312 80 3 500 480 25 6 1 1.872 96 480 25 6 1 1.872 96 4 200 0 Power failure 0 0 160 25 2 1 0.624 80 5 250 0 Power failure 0 0 240 25 3 1 0.936 96 6 750 480 25 6 1 1.872 64 720 25 3 3 2.808 96 7 650 480 25 6 1 1.872 74 640 25 2 4 2.496 98 8 350 0 Power failure 0 0 320 25 2 2 1.248 91 100 0.4 1.2 1.6 2.0 2.4 2.8 Power ( W) Throughput (Giga MACs s) Power consumption with full-size activation Power consumption with tile-size activation Throughput with full-size activation Throughput with tile-size activation Power trace Average harvested power Average power consumption with full-size activation Average power consumption with tile-size activation Average throughput with full-size activation Average throughput with tile-size activation 356.3 180 330 1.3 200 300 400 500 600 700 800 0.8 0.7 PC1 PC2 PC3 PC4 PC5 PC6 PC7 PC8 0 0 0 0 80 480 480 0 160 0 240 480 480 640 0 320 0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 Fig. 1. Comparisons on power consumption and throughput with tile-size over full-size activation From the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property. Under this context, if the power dominant RCA works in a ﬁxed high-power mode, as in traditional RCA designs, there would be large mismatches between the harvested power and the consumed power. These mismatches can lead to the following two nonideal working scenarios: (i) Unutilized energy: As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive. In this case, the harvested energy will leak away and cannot be recovered. (ii) Underutilized energy: When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level. In this case, the unused energy will be wasted, resulting in low energy efﬁciency. Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four 25 6 ReRAM crossbars, each can be mapped to six kernels, all sized 5 5 1. In the default case, the RCA works under an either ON or OFF mode with a power threshold of 80µW. During the eight harvested power cycles, the ReRAM can be ON during power cycles PC3, PC6 and PC7 and OFF with the other ﬁve power cycles. However, even when the system goes through the three power cycles, only some portion of the harvested power is consumed. As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efﬁciency under stable, high-power scenarios. Fig. 2. Comparisons on loop code and ReRAM activation with tile- size activation over full-size activation. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation If we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve continuous progress under lower power supply. This is because the starting power requirement of the RCA is reduced, and the system can thus get through power failures and translate even the low input energy into forward progress. If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles PC2, PC4, PC5 and PC8 under limited power budget, as depicted in Table II and Figure 1. The annotations indicate the consumed power (µW), tile size and duplication count (e.g., 25x2x1) and power efﬁciency. With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of 180µW to 330µW, and the throughput is increased by 85.7 . Note that the partial activation of computation cells can be realized by partially activating the peripheral circuits of the corresponding rows and columns in the ReRAM crossbar. This resilient activation approach can effectively combat Nonideal scenario 1. The underlying reason of encountering so many power failures in the case of conventional working mode is that the power threshold of the system to remain alive is set too high. With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM. With this, the RCA can be active in a very large power range and ﬁnd more opportunities to make execution progress. Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles PC6, PC7 and PC8. Parallel computations across multiple ReRAMs and loop tiling-based computation for each ReRAM are orthogonal optimizations. Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode. In this example, the full size of ReRAM (or loop nest) is M N A B C N, and the tile size of ReRAM (or loop nest) is m n 1 tb C tn. Since each single ReRAM can be activated at a ﬁner granularity with tiling, the parallelism can be achieved under a ﬂexible range of power consumption to match a variable power supply. Furthermore, the better the high-power supply can be aggressively utilized, the more ambient energy can be continuously extracted without increasing the energy storage capacity for the energy-harvesting power delivery system. Therefore, this weight duplication- based execution style built upon ﬁne-granularity activation can effectively combat Nonideal scenario 2. Figure 1 also shows the throughput under the full-size activation mode and the tile-size activation mode. The ﬂexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization. Extending this single-ReRAM toy architecture to a practical multi-ReRAM architecture to process multi-layer convolutions for real-world CNNs introduces a new source of power variation in terms of the different time and power costs of different convolution layers. In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efﬁciency. III. SYSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives. Below, we provide an overview of the RCA interfaces and our system integration model and then discuss the two main steps to map a CNN to ResiRCA: ofﬂine compilation and runtime execution. A. ResiRCA overview Figure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system. The baseline, battery-powered MCU system samples data at a ﬁxed rate, supported by the provisioned battery, and transmits either sensor data or the results of RCA processing DAC DAC DAC DAC DAC DAC MCU Memory I O Ports Interconnected Bus Clock Power Intelligent Embedded System ... ... ADC S A DAC Input Reg. Output Reg. Pool Unit FC Unit Adder Tree ResiRCA ReRAM crossbar ... ADC S A DAC ReRAM crossbar Ă Tx RX Energy Harvestor Sensors Energy harvesting (EH) ... Battery (B) B EH Ă Sigmoid ... ReRAM Memory Basic MCU System B EH EH EH EH B Fig. 3. ResiRCA architecture overview to the network. The RCA is powered by harvesting ambient energy and employs a separate, very small capacitor as its only energy storage medium, primarily for power smoothing, similar to prior energy-harvesting NVP designs [17], [21], rather than as a task-scaled energy reservoir [22]. Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources. Similar hybrid arrangements have been explored in the NVP literature [23] and impose minimal design overheads. The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiﬁcations. B. Mapping inference tasks to ResiRCA To achieve both generally low power and intermittency- compatible execution, the proposed ResiRCA architecture has the following two features that impact the software management of the RCA: Lightweight: From the perspective of the ReRAM circuit at the core of the RCA, the precision and resolution of inputs, weights and outputs are kept low to yield low power. This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA. Similarly, total model size, including any granularity overheads (e.g., from the partitioning used to store both positive and negative weights by having the kernels of one layer mapped to two crossbars, one each for positive and negative weights, which share the same input port) must ﬁt within the allocated RCAs of a particular ResiRCA design. Fine-grained reconﬁguration: The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes. This ﬂexible reconﬁgurability enables ﬁne-grained activations to exploit the harvested power. While execution is relatively straightforward when maintaining a speciﬁc conﬁguration of tiling and pipelining strategy, transitions between conﬁgurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures. The hardware design details will be presented in Section IV. As part of compiling a CNN to ResiRCA, we build a proﬁling table relating each potential tiling and pipeline conﬁguration that might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw. This proﬁling collects data used to determine the best activation solution for each power level. At runtime, each time when entering a new power cycle, we ﬁrst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level. Then, the execution process the data loading Mac computing data storing steps in a sequential way to perform convolution operations. The hardware design details will be presented in Section V. IV. A HARVESTING-COMPATIBLE, LOW- POWER RESIRCA Supporting the necessary features for adapting RCAs to a harvested power supply will require optimizations in both RCA circuit design and the development of variable-power-optimized loop-tiling strategies. First, feasible implementations of ﬂexible activation options require a low power and reconﬁgurable RCA. Second, a dynamic loop tiling strategy alongside a coordinated parallelism scheme should be devised to match execution power consumption as closely as possible to power income to maximize efﬁciency. This section addresses the ﬁrst of these challenges, and Section V discusses our approach to the second. Challenge 1: Achieving low-power, reconﬁgurable RCA Although recent works have presented systems [4], [3], [5] and circuits [24], [6] for inference-oriented RCAs, they are not directly suitable for adoption in our target scenario because of either their high power consumption or their stringent execution parameters (e.g., computation granularity). In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment. Figure 4 shows ﬁve harvested power sources with the maximum, mean and median values and their ratios indicated. It has been shown that the power requirement to fully activate a 128 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [3]. With this design, the presented power sources can hardly activate even a small ReRAM. In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power. Therefore, the the RCA should be built on the basis of a low power hardware design that is upwardly reconﬁgurable to higher power scenarios rather than the reverse. One approach to achieve lower RCA power is to limit precision. The impact of different precisions on CNN accuracy has been extensively studied [24], [25], [26], [27], [28], [29], [30], [31], [32], [33]. To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output. With this design setting, the ReRAM size only needs to be equal to the kernel size, and the ReRAM scale does not need to be extended using a bit composing scheme (e.g. as in ISAAC [3]). In addition, it consumes very low power to handle the Successive-Approximation Register (SAR)-ADC referencing with the 4-bit output resolution. Moreover, we adopt the 1T1R technique to build high resistance and low 2000 2500 3000 3500 1 30 59 88 117 146 175 204 233 262 291 320 349 378 407 436 465 494 523 552 581 610 639 668 697 726 755 784 813 842 871 900 929 958 987 1016 1045 1074 Power (uW) Thermal Signals Pmax 3378煒W Pmean 2943煒W Pmedian 澦澭澨澦煒濋 Ratiomax mean 1.1 Ratiomax median 1.1 Data volume: 1098, Sampling time: 0.2 second, Time duration: 3.66 minutes 0 5000 10000 15000 20000 25000 30000 1 48 95 142 189 236 283 330 377 424 471 518 565 612 659 706 753 800 847 894 941 988 1035 1082 1129 1176 1223 1270 1317 1364 1411 1458 1505 1552 1599 1646 1693 1740 1787 Power (煒濋) TV-RF Signals Pmax 25828煒W Pmean 5571煒W Pmedian 澱澦澩澥澫煒濋 Ratiomax mean 4.6 Ratiomax median 10.3 Data volume: 1800, Sampling time: 0.1 second, Time duration: 3 minutes 100 600 1100 1600 2100 2600 3100 3600 4100 1 77 153 229 305 381 457 533 609 685 761 837 913 989 1065 1141 1217 1293 1369 1445 1521 1597 1673 1749 1825 1901 1977 2053 2129 2205 2281 2357 2433 2509 2585 2661 2737 2813 2889 2965 Power (uW) WiFi-office Signals Pmax 3981煒W Pmean 419煒W Pmedian 澧澩澩煒濋 Ratiomax mean 9.5 Ratiomax median 11.2 Data volume: 3000, Sampling time: 0.2 second, Time duration: 10 minutes 300 400 500 600 700 800 900 1 52 103 154 205 256 307 358 409 460 511 562 613 664 715 766 817 868 919 970 1021 1072 1123 1174 1225 1276 1327 1378 1429 1480 1531 1582 1633 1684 1735 1786 1837 1888 1939 1990 濄濣濫濙濦澔澜煒濋澝 WiFi-home Signals Pmax 891煒W Pmean 500煒W Pmedian 澱澩澤澥煒濋 Ratiomax mean 1.8 Ratiomax median 1.8 Data volume: 2000, Sampling time: 0.2 second, Time duration: 6.7 minutes 0 200 400 600 800 1000 1 165 329 493 657 821 985 1149 1313 1477 1641 1805 1969 2133 2297 2461 2625 2789 2953 3117 3281 3445 3609 3773 3937 4101 4265 4429 4593 4757 4921 5085 5249 5413 5577 5741 5905 6069 6233 6397 6561 6725 6889 7053 7217 7381 7545 7709 7873 8037 8201 8365 8529 8693 8857 9021 9185 9349 9513 9677 9841 Power (uW) Piezo Signals Pmax 998煒W Ratiomax mean 42.3 Ratiomax median 249.0 Pmean 24煒W Pmedian 澱澨煒濋 Data volume: 10000, Sample time: 0.1 millisecond, Time duration: 1 second Fig. 4. Variance feature of different power sources III-ADC BL WL SL Column 1 CSA - SAR Ref Shift Add Driver Row 1 Row 2 Row m Driver Driver I-DAC II-Comp 4-bit inputs 1-bit resolution 1-bit weights 4-bit outputs bit- serial Input Reg. 4-bit Output Reg. C C C controlling circuit Fig. 5. Lightweight ReRAM circuit design power ReRAM cells. Figure 5 shows the proposed peripheral circuit design for one ReRAM crossbar. This design is more concise even than the SINWP [6], because we target low power as the primary goal. To increase efﬁciency further our design supports aggressive power gating and other circuit techniques to dynamically reconﬁgure active tile sizes and shut-off inactive ReRAMs. Speciﬁcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows. We modify the column multiplexers to enable variable active columns and turn off the ADCs of inactive channels. Lastly, we apply coarse-grain power gating to conﬁgure the number of duplicated ReRAMs. This reconﬁguration ability can enable scaled activation of the circuits such that small tile-size computation can be enabled while yielding very low power consumption. V. POWER-DYNAMIC RCA SCHEDULING Given a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture. Challenge 2: Software controlled dynamic RCA activation and scheduling The idea of loop tiling has been widely leveraged in RCA design to either increase system throughput by smoothing the pipelining or reduce memory accesses by improving data locality [34], [3]. In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM accelerated MACs. Moreover, we allow parallelism along different dimensions to seamlessly integrate it with loop tiling, and as a result, a range of scalable computations that can ﬁt in different power supplies are achieved. With this design idea, the system can keep making forward progress over a large range of power incomes. Sections V-A-V-C develop a dynamic activation strategy for different power levels and Section V-D discusses the transition strategy between dynamic activation solutions. A. Computation decomposition and parallelism If the harvested power P budget is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress. For active RCAs, one option is to use loop tiling to decompose computations, and the other is to parallelize computations. The parallelism in this context is of two types: intra layer parallelism via layer duplication and inter layer parallelism via layer pipelining. Further, tiling and parallelization can also be combined to generate ﬁne-grained scales of computations to efﬁciently ﬁt into the changing harvested power. 1) Computation tiling: In this work, we use loop tiling [35] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one. As shown in Figure 2, if loop tiling is applied to the unrolled MAC operations, only a tile of ReRAM cells along with their peripheral circuits is enabled to perform MAC operations. After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed. Note that, if the row- wise tiling factor is less than the ReRAM row number, this tiled execution strategy will introduce partial sums. When the traversal completes, an Adder Tree will be used to merge the partial sums for ReRAM columns and obtain the ﬁnal MAC result. 2) Computation parallelism: Intra-layer parallelism means overlapping the layer computations on duplicated copies of ReRAMs that store the same weights for one layer. We use parallelism granularity G to denote the duplication count as deﬁned in [5]. G can be determined considering the tradeoff between energy efﬁciency and chip area during the design phase. In this work, the parallelism granularity G of a layer is determined by the ratio between 50 of the peak harvested power during proﬁling and the power consumption of the full- size ReRAM corresponding to this layer. That is, if the 50 peak harvested power by proﬁling is twice (G 2) of the power consumption with a ReRAM size of Layer 1 of 25x6, the RCA will be designed to offer two sets of ReRAMs sized 25x6 for Layer 1. The actual parallelism granularity aG G for a layer is decided by the harvested power level. If we allow aG ReRAMs to perform the concerned layer s computations in parallel, the input data should be divided into aG partitions. In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel. This offers a ﬂexible way to tune the power consumption in a large design space, even though the kernel size, convolution count and power consumption of different layers can signiﬁcantly vary. Inter-layer parallelism means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion. This pipeline parallelism provides us with another dimension to aggressively exploit the harvested energy. We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers. Previous work [3] has noted vulnerabilities to pipeline bubbles and execution stalls in CNNs because of the large variance in weight and feature map scales across different layers. In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very ﬁne-grain fashion. 3) Execution strategies: Figure 6 shows ﬁve different execution strategies for a two-layer convolution execution experiencing two power cycles with different levels. In Fig- ure 6(a), a naive scheduling strategy is employed on a Simple architecture. In this scheduling strategy, the RCA is only active when the harvested power is adequate to support the maximal power requirement among all the convolution layers and, in the simple architecture, one convolution layer can only be mapped to one ReRAM (no ReRAM duplication). In the remainder of this paper, this execution strategy is referred to as Naive1. We assume that Naive1 is also designed with the proposed lightweight circuits. In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication. This execution strategy is referred as Naive2. None of Naive1 and Naive2 executions can go through power cycle PC-i and the power utilization is very low, as there is a signiﬁcant mismatch between the power producer and consumer. Figure 6(c) presents a ﬂexible scheduling strategy applied to ResiRCA. In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks. The layers are scheduled in a sequential fashion. This execution style is called Sequential. In the example, we allow activating L1 ReRAMs with aG 4 and one partial L2 ReRAM in a sequential fashion. In Figure 6(d), the loop tiling technique integrated with both duplication and pipelining is used to schedule all layers on the I4-L1 I4- L2 I1- L2 I3-L1 I3- L2 I3-L1 I3-L1 I3-L1 I1-L1 I1- L2 Ă Power Cycles Power Harvested power (a) Naive 1 Ă Power Cycles Power Harvested power (b) Naive 2 Ă I1- L2 -T1 I1 -L2 -T2 Power Cycles Power Harvested power (c) Sequential Ă I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 I1-L1- T2 I1-L1- T2 I2- L2 -T1 I2 -L2 -T2 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I2-L1- T2 I2-L1- T2 I1-L1 I1-L1 Ă I1- L2 I1- L2 Ă Power Cycles Harvested power Ă I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 Ă Power I1- L2 -T1 I1 -L2 -T2 Power Cycles Harvested power Ă I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 I1-L1- T2 I1-L1- T2 Ă Power I1-L1- T3 I1-L1- T3 I1- L2 -T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I1- L2 -T2 I1- L2 -T3 I2-L1- T3 I2-L1- T3 I1- L2 -T4 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T2 I3-L1- T2 I3-L1- T2 I3-L1- T2 I2- L2 -T1 I2 -L2 -T2 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T2 I4-L1- T2 I4-L1- T2 I4-L1- T2 I3- L2 -T1 I3 -L2 -T2 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T2 I5-L1- T2 I5-L1- T2 I5-L1- T2 I4- L2 -T1 I4 -L2 -T2 I2- L2 -T1 I2 -L2 -T2 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I2-L1- T2 I2-L1- T2 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T2 I3-L1- T2 I3-L1- T2 I3-L1- T2 I2- L2 -T1 I2 -L2 -T2 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T2 I4-L1- T2 I4-L1- T2 I4-L1- T2 I3- L2 -T1 I3 -L2 -T2 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T2 I5-L1- T2 I5-L1- T2 I5-L1- T2 I4- L2 -T1 I4 -L2 -T2 (d) Pipelining (e) ResiSchedule I1-L1 I1-L1 I1-L1 I2-L1 I2- L2 I2-L1 I2-L1 I2-L1 I1-L1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 I5-L1 I5- L2 I5-L1 I5-L1 I5-L1 I3-L1 I3- L2 I3-L1 I3-L1 I3-L1 I4-L1 I4-L1 I4-L1 Fig. 6. Five layer scheduling schemes: (a) Naive execution Simple architecture; (b) Naive execution ResiRCA architecture; (c) Se- quential resilient execution ResiRCA architecture; (d) Pipelining resilient execution ResiRCA architecture; and (e) Hybrid resilient execution ResiRCA architecture ResiRCA architecture; we call this execution style Pipelining. For ease of explanation and simulation, we only allow full pipelining in this execution, which means MAC operations of all the layers are included in each pipeline stage. Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme. We refer to this as ResiSchedule. At runtime, ResiSchecule dynamically selects activation solutions from either Sequential or Pipelining in each power cycle, depending on which can provide a better throughput. With ResiSchedule, we can cover a large tuning range commensurate with power supply variation. Section V-C will further present quantitative analysis and solution on how toﬁgureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA. B.Powermodelandlatencymodel PowersupplyisasigniﬁcantconstraintforResiSchedule. Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solutionm,n,aG wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,Pload,PcompandPstore,andtheyareperformed insequence. 1)Loadandstore:PloadandPstore denotethepower consumedbyloadingthedatafromthepureReRAMmem- oryintotheinputregistersandstoringthedatafromthe outputregistersintotheReRAM memory .Pload aG (Bitsinput BNin) Pld bit modelsloadpoweroperation. Here,thetermsBitsinputandBNindenotethenumberof inputbitstoserve MACoperationsforafull-sizedReRAMand thebatchnumberoftransferringtheseinputbitsrespectively . Therefore,Bitinput BNinmeanstheactualloadeddatabits eachbatch.ThetermPld bitdenotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister. TheinputbatchnumberBNinisdeterminedbythepower budgetbecausePload Pbudgetshouldalwaysbesatisﬁed. Thelatency modelfordataloadforoneconvolution operationisLatload Bitsinput BWld.ThetermLatload representsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.ThetermBWlddenotesthebandwidthof eachloadoperation.ThemodelsofPstoreandLatstorecan bederivedinasimilarfashion. 2) ComputationonReRAMs:Pcompisthedominantand mostcomplicatedpartwheretheanaloganddigitalsignals aremixed.Theenergyofone-cycle MACoperationsforan activationsizeofm nandactualduplicationaG,Pcomp tile dividesintothefollowingparts:1)EDAC denotestheenergy consumedforconvertingthedigitalinputsignaltotheanalog signalinabit-serialfashion;2)EMAC denotestheenergy forperforming MACoperationsonReRAMs;and3)EADC consistsofthreepartsasshowninFigure5:3i)EBL denoting theenergyforactivatingbitlines;3ii)ESA Ref denotingthe energyforsensingandamplifyingthe MACresultsignaland thenreferencinganalogsignalstodigitalsignals;and,3iii) ES A denotingtheenergyofShift Addparttocomposethe ﬁnaloutput. IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisﬁxedasLatcomp Tcomp,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1. Ecomp Ecomp tile Latcomp (EDAC EMAC EADC) Tcomp (1) Thepowerofeachpartistakentobelineartothetiling factorsofm ornortheactualparallelismgranularityaG. TheenergyforoneReRAMrow(eDAC),oneReRAMcell (e MAC )andoneReRAMcolumn(e BL,e SA Ref,e S A)are theworst-casevaluesfromthesimulation.TableV-B2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies. TABLEII RELATIONSHIPOFENERGYANDTHERERAMTILINGSIZEAND RERAMCOPIES. Component Energyequation DAC EDAC eDAC m aG Computation EM AC eMAC m n aG ADC BL EBL eBL n aG SA-Ref ESA Ref eSA Ref n aG S A ES A eS A n aG 3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated. Asaresult,thesepartialsumsneedtobe mergedoncethe (tile)traversalofanentireReRAMiscomplete.Thesum mergingoperationisperformedbyanAdderTreeasillustrated inFigure3. Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint ofPmerg Pbudgetshouldbealways met.Therefore,the powerPmerge andlatencyLatmerge ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofﬂine. 4)Activationtransitioncost:Theexecutiontransitionfrom onetiletoanotherinsideonepowercycleorfromoneactivation solutiontoanotherindifferentpowerlevelsalsocostspower PtransandlatencyLattrans.Activationtransitionimpliesthat weneedtoenablethecorrespondingcircuitsoftheto-be- activatedrowsandcolumnswhileshuttingdowntheothers. Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs. 5)Powerandlatencymodels:Theaboveanalysiscaptures thepowerconsumptionandexecutionlatencyofprocessing oneconvolutionlayer .Itisassumedthatallofthesesteps areperformedinsequence.Puttingthemalltogether,for convolutionlayerLk,thepowerandlatencypaircanbemodeled asinEquation2and3. PLK (Pld Latld Lk Pcomp Latcomp Lk Pst Latst Lk Pmerge Latmerge Lk ) LatLk (2) LatLK Latld Lk Latcomp Lk Latst Lk Latmerge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication. Underthesequentialcomputation mode, theconvolutionlayersareexecutedonebyoneinasequential fashion, and as a result, the power model and latency model in Equations 2 and 3 can be directly used. We also model the pipelined computation mode shown in Equations 4 and 5. Note that the pipelined computation mode means that all the LC convolution layers are executed fully parallel. P pipe LC X Lk 1 PLk (4) Latpipe max(LatL1, LatL2...LatLC) (5) C. Dynamic activation strategy 1) Problem formulation: In this section, we focus on ﬁguring out the ResiSchedule solution to achieve the maximal throughput. Although we can arrange more hardware resources with the pipelined computation mode, it does not mean this mode will always yield greater computation progress than the sequential mode due to the constraints of tile size and parallelism granularity. Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Given a power supply level, we can derive the optimal tile size and actual duplication granularity to form the activation solution m, n, aG for sequential or pipelined computation modes, respectively. Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level. Throughput model Achieving the maximal computation progress under the harvested energy has two implications. The ﬁrst one is that we expect more energy can be used for program progress. The other is more subtle in that we expect the power can be consumed quickly in order to receive more energy from outside. In this regard, the metric throughput measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios. We use the number of convolutional MAC operations to represent the computations. For the sequential computation mode, the throughput for Layer Lk can be expressed as below: Thrsequ Lk (m n)Lk aGLk LatLk (6) The average throughput with a LC-convolution CNN infer- ence can be expressed as shown below. Thrsequ ave PLk LC Lk 1 (m n)Lk aGLk PLk C Lk 1 LatLk (7) For the pipelining computation mode, all the LC layers are executed in parallel. The throughput can be expressed as follows: Thrpipe ave PLk LC Lk 1 (m n)Lk aGLk Latpipe (8) 2) Activation strategy formulation : The activation strategy for the sequential mode can be described as shown below. In order to formulate the problem in a concise way, the tiling factors, m and n, are constrained to be divisors of the ReRAM weight matrix M N using the annotations of m M; n N. Objective: Maximize Thrsequ ave Subjected to: for each layer Lk, P load Lk , P store Lk , P comp Lk , P trans Lk , P merge Lk P budget; aGLk GLk; mLk MLk; nLk NLk; Solution output: mLk, nLk, aGLk for each layer Lk Similarly, the activation strategy under the pipeline execution mode can be described as below. Objective: Maximize Thrpipe ave Subjected to: P P load, P P store, P P comp pipe , P P trans, P P merge P budget; aGLk GLk; mLk MLk; nLk NLk; Solution output: mLk, nLk, aGLk for each layer Lk By solving the above problems, we can obtain activation solution m, n, aG for each power level under the sequential and pipelining computation modes, referred to as SOLsequ and SOLpipe respectively. Then the optimal solution can be selected from among them. The solution space is actually very small because of the constraints that tile size candidates and aG are all bounded in the integer domain. It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode. In this case, we choose the activation solution with larger tiling size by taking into account the transition cost. If the tiling sizes of output solutions are the same, we choose larger m because larger m implies fewer partial sum adds. D. Activation transition The power instability of energy harvesting implies that the activation solution needs to change dynamically as power level changes. Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy. An FSM transition can happen between any pair of power levels. Activation solution under power level l: ml, nl, aGl Activation solution under power level h: mh, nh, aGh Smooth transitionl- hwithout power prediction Smooth transitionl- h with power prediction Smooth transitionh- lwithout power prediction Smooth transitionh- l with power prediction 1 2 3 4 Fig. 7. Activation solution transition FSM The convolution computations of one inference may not be completed while transitioning to a new power level. For small-scale applications with strong harvested power supply, discarding the incomplete execution may have only modest overheads. However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle. Fortunately, there exist opportunities to keep and transfer the intermediate computation results of the last incomplete inference to the next power cycle. Considering a transition for one layer from an activation solution m1, n1, aG1 to m2, n2, aG2 , we ﬁnd that, if the expression Conditiontrans: (m1 m2) (n2 (Tilecount1 n1)) (aG1 aG2) is true for each convolution layer, the activation solution m1, n1, aG1 with power level PL1 can be transferred to be equivalent to an execution of activation solution m2, n2, aG2 with PL2. The execution equivalency can be transferred by Tilecount2 Tilecount1 n1 n2. The next power cycle s level information cannot be known with certainty. In order to not discard the acquired results, we can search the maximal Tilecount1 where Tilecount1 Tilecount1 to make the expression n2 ( Tilecount1 n1) conservatively true for each layer, and then transfer the tile count Tilecount1 to accommodate to the new activation solution. This means that only a portion of computation results from Tilecount1 to Tilecount1 will be discarded. The discussion on this transition without power prediction is applied for transitions 1 and 2 in the Figure 7. We call this smooth transition strategy as TransitionKeep. With a power predictor [36], we can estimate the power level of the next power cycle in advance. In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference. Still, with Conditiontrans satisﬁed, the smooth transition can be achieved in a similar way. Otherwise, if the expression Conditiontrans is not satisﬁed, with power prediction, we can still speculatively attempt to perform a smooth transition. There are two strategies to achieve this. We can search for an intermediate power level, where we ﬁrst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level this strategy is called Multi-step Transition. If the power predictor reports a power transition from a high level to a low level, we can move to the new activation solution before performing the last incomplete inference this strategy is referred to as Eager Transition. The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7. Since a power predictor itself consumes power, it makes sense to employ it for large-scale applications under weak power sources where discarding a portion of computations may impose a big loss or for the scenarios where power level transitions happen frequently. VI. EXPERIMENTS To evaluate ResiRCA, we have extended the Gem5 [37] simulator with RCA modeling. The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock. The energy harvesting mechanism is supported by the power management unit, which can record power production and consumption at an execution cycle level. The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs. We perform cycle-accurate simulation for the MAC computations based on tile activation and the data load store process. However, for other functional units, we assign a ﬁxed latency. For the ReRAM circuit simulation, we quantify power and performance of our design in HSPice [38] using 20nm FinFET ReRAM parameters from [39]. Load store parameters of the ReRAM memory are from NVSim [40]. The main parameters of our simulations are given in Table VI. Four practical CNNs listed in Table VI are evaluated on the ﬁve power traces illustrated in Figure 4 for each of the ﬁve execution strategies from Section V-A3: Naive1; Naive2; Sequential; Pipelining; and ResiSchedule. TABLE III RERAM PARAMETERS ReRAM computing crossbar DAC(150 N 1 title) 5.4 pJ ADC(M 1 1 title) 749 fJ S A(M 1 1 title) 41.6 fJ area (all peripherals included) 2950.47 µm2 ReRAM memory (16KB) bandwidth 128 bit s read energy 37.993 pJ read latency 1.577 ns write energy 95.412 pJ write latency 20.09 ns TABLE IV IOT-PRACTICAL CNN WORKLOADS CNN Layer Kernel RRAM Size Acti. power Input PV [41] Input Conv1 36 8 752.2µW Conv2 72 12 1125.6µW Conv3 108 16 1526µW Conv4 144 10 1114µW Conv5 90 6 676.2µW FR [42] Input Conv1 25 4 377.4µW Conv2 64 16 1433.6µW LeNet [43] Input Conv1 25 6 539.7µW Conv2 150 16 1614.2µW HG [44] Input Conv1 25 6 539.7µW Conv2 96 12 1176µW For each application on each power trace, we report the throughput and energy efﬁciency under the ﬁve different execution strategies. We then demonstrate the beneﬁts from the proposed smooth transition strategy and power prediction. We also study the sensitivity of our proposed approach to available ReRAM hardware resources. A. Throughput Figure 8 shows the throughput comparison of the ﬁve exe- cution strategies. The bars are all normalized to ResiSchedule. The included table gives the absolute values of throughput by ResiSchedule. The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 compared to a baseline RCA with intermittency-unaware scheduling. One can make the following observations and analyses from these results: For each workload with each power source, ResiSchedule always achieves the highest throughput because it combines the best activation solution in each power cycle. The results of Naive1 are the worst because it lacks both adequate hardware resources and scheduling ﬂexibility. Although Naive2 is based on the ResiRCA architecture, the throughput is still relatively low because it lacks scheduling adaptation to ﬁt to the changing harvested power. The results of ResiSchedule are very close or equal to that of Sequential under most cases. When we track the simulation cycles, it is found that the throughput of Sequential solution ResiSchedule Piezo WiFi-home WiFi-office Thermal TV-RF Fig. 8. Throughput of CNNs across the power sources normalized to ResiSchedule Piezo WiFi-home WiFi-office Thermal TV-RF Fig. 9. Energy efﬁciency of CNNs across the power sources normalized to ResiSchedule is higher than that of Pipelining solution for a signiﬁcant fraction of the active power cycles. That is, the selection ratio of Sequential is much higher than the ratio of Pipelining in ResiSchedule solutions in the whole power trace. Consistent with the above observation, the entire Sequential strategy competes with the entire Pipelining. The reason is that the active power threshold of Pipelining is much higher than that of Sequential. As a result, fewer power cycles of Pipelining are available than that of Sequential. However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments. When we change to a smaller ReRAM duplication granularity G, we ﬁnd that the throughput of Pipelining is better than that of Sequential for many power levels. The duplication sensitivity results are presented in Section VI-F. Regarding the throughput absolute values, the results with the power sources of Thermal and TV-RF are much higher than those with the others, which is constant with the power strength illustrated in Figure 4. B. Energy efﬁciency We evaluate energy efﬁciency by measuring MAC operations per Joule, as shown in Figure 9. Note that this includes the energy overheads of data movements and other functional units in addition to MACs. Overall, the normalized results of energy efﬁciency are very similar to those of the throughput evaluation. The results show that ResiRCA and ResiSchedule achieve average energy efﬁciency improvements of 14 compared to a baseline RCA with intermittency-unaware scheduling. The only difference that can be observed is that, regarding LeNet and PV with the power source of Thermal, relatively speaking, the results of energy efﬁciency with Pipelining strategy are higher than that appearing in the throughput evaluation. One possible reason for this is that Pipelining requires loading several inputs from ReRAM memory to perform the parallel operations, which is power-expensive. This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efﬁciency when active is high. Compared to the cloud for online processing, the preference for local compute over ofﬂoad can stem from security, con- nectivity and latency concerns as well as power and energy constraints. In our work, local computation across the CNN applications is 50x more efﬁcient than transmission over Bluetooth with 3Mbps and 2.5mW. C. Power utilization In order to further understand the power utilization, we use a two-dimensional plot that illustrates the features of power consumption with theResiSchedule strategy, as shown in Figure 10. The x-axis (power efﬁciency) denotes the percentage of power cycles where the RCA can activate. The y-axis (power utilization), on the other hand, denotes the percentage of valid power during activations which is actually utilized for computation and data transfer. An ideal system would be at the point (1,1). It can be observed from these results that the proposed ResiSchedule strategy can make good use of the Piezo source when it does exceed the minimal activation thresholds, though the very low duty cycle yields very low throughput. 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 0 0.10.20.30.40.50.60.70.80.9 1 Power Utilization Power efficiency Piezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG Fig. 10. ResiSchedule power efﬁciency analysis D. Transition efﬁciency Table VI-D shows the ratio of inferences using smooth- transitioned partial results and total inference count number. These results indicate that the smooth transition strategy TransitionKeep enables a signiﬁcant fraction of the inferences for all workloads on Piezo. However, a very small fraction is observed with the other, stronger power sources. For Piezo, saving the intermediate results of one incomplete inference is meaningful. However, one power cycle of the other power sources can usually process thousands or hundreds of inferences. TABLE V THE RATIO OF ADDITIONAL INFERENCES ENABLED BY THE SMOOTH TRANSITION STRATEGY VS. TOTAL INFERENCES Piezo WiFi-h WiFi-o Thermal TV-RF LeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 E. Power predictor With an accurate power predictor [45], [36], we can make more smooth transitions among different power levels. The beneﬁt is that we can keep more MAC results of the last incomplete inference when switching from a higher power level to a lower power level, even if Conditiontrans is not satisﬁed. However, to be valuable the power predictor must have high accuracy. For both Piezo and Thermal power sources the prediction accuracy when using a multi-power-level-optimized extension of the power predictor in [36] are above 80 . Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with Transitionkeep for all the workloads with these power sources. 0.0 0.3 0.0 0.3 0.0 0.9 1.9 2.0 0.0 0.5 0.0 20.0 40.0 60.0 vs. all inferences vs. addi. inferences w smooth transition vs. all inferences vs. addi. inferences w smooth transition Piezo Thermal LeNet FR HG PV Fig. 11. Percentages of additional inferences with power prediction over all inferences and additional inferences with the Transitionkeep strategy The portion of inferences added with power prediction are signiﬁcant for Piezo for most workloads. This is because, the Piezo source is very weak and and the total completed number of inferences is quite small. Speculative action supported by power prediction can keep quite a few incomplete inferences to be completed in the next power cycle. This can also explain why the portions with the power source of Thermal are very small. However, for both Piezo and Thermal, the portions for PV are very small. The underlying reason is that the smooth Transitionkeep strategy can already handle the smooth transitions with no need of power prediction support for this workload. F. Sensitivity study on duplication copy We vary the ReRAM duplication granularity G for each layer and evaluate with TV-RF source. Throughput results are plotted in Figure 12 and area costs for G1 G5 can be found in Figure 13. For each benchmark, all the numbers are normalized to that of the G4 setting with the Naive2 policy. As expected, the throughput increases as G grows for every benchmark. Another interesting observation is that the results of ResiSchedule policy can be competitive to that of Sequential policy when G is small and vice versa. The main reason for this is that the ResiSchedule policy can efﬁciently organize more hardware resources than the Sequential policy when hardware resources are limited. 0.00 0.20 0.40 0.60 0.80 1.00 1.20 1.40 1.60 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 PV HG LeNet FR Naive2 Sequential Pipelining ResiSchedule Fig. 12. Throughput normalized to G4 with Naive2 vs. ReRAM duplication granularity The RCA area is impacted from the parallelism granularity G, as shown in Figure 13. It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed smart dust solutions [8]. The ideal parallelism granularity determination for a particular deployment should consider the balance between throughput and area. 0 20000 40000 60000 80000 100000 120000 140000 160000 PV HG LeNet FR G1 G2 G3 G4 (default) G5 Area in m2 2, 2, 2, 2, 2 4, 3, 2, 3, 5 6, 4, 3, 4, 7 8, 5, 4, 5, 9 12, 7, 6, 7, 13 2, 2 6, 2 9, 3 11, 5 16, 7 2, 2 5, 2 8, 3 11, 4 16, 6 2, 2 7, 2 13, 3 17, 4 22, 6 Fig. 13. Area with different duplication granularity VII. RELATED WORK The previous RCA related work can be divided into the following two categories: High Performance RCA Architectures: PRIME [4] uses 6-bit inputs and 8-bit weights and targets 6-bit output precision. A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight. In the PRIME conﬁguration, the ReRAM-based Full Function (FF) subarrays have both computation and data storage capabilities. To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed. In the ISAAC design [3], the inputs, weights and outputs are all 16 bits, where the DAC, ReRAM cell and ADC resolutions are, respectively, 1-bit, 2-bit and 8-bit. Also, a similar composition scheme is employed to organize the input, weight and output data. The ISAAC architecture is composed of 16 tiles and each tile consists of 8 IMAs which includes 4 ReRAMs along with 4 sets of peripheral circuits. An intra-tile pipeline is formed to boost the dot-product throughput. In the PipeLayer design [5], a spike-based scheme, instead of a voltage-level based scheme, is used for input to eliminate the power overhead of DACs and ADCs. The underlying idea is to use spike counts to represent the data value. They propose intra-layer and inter-layer parallelism to support the training phase by reducing potential stalls. ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [8] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets. It includes four ReRAMs, each 32x32. The inputs and weights are binary and the output is adaptive between 1-3 bits. The serial-input non-weighted product (SINWP) structure [6] is the ﬁrst work to propose multi-bit input weight and output design from the circuit level, adopting a 2-bit input, 3-bit weight, and 4-bit output scheme. Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a 3-bit resolution, which is a high performance but also a high power consuming design. Although the above designs provide different approaches to achieve high throughput, high energy efﬁciency and low power, they cannot be directly applied or combined to be applied in the energy harvested edge devices due to the following reasons. The architecture-centric works [3], [4], [5] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption. Furthermore, the hierarchy they adopt with multiple ReRAMs targets primarily high throughput, leading to high power consumption on the whole RCA. For example, the total 168 Tiles and one IMA element of the ISAAC architecture [3] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets. It can be seen that those designs are not suitable for an RCA supplied with harvested unstable power. Although the spike-based scheme [5] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input output data. It is known that the energy harvesting system often suffers from power failures and works in an intermittent mode; so, the spike-based data injection scheme is not favorable. For the ReRAM circuit concerned works [6], [8], although they are lightweight, they cannot be dynamically reconﬁgured to adapt changing power levels. In addition, such works have not presented any software level solution to maximize the utilization of the hardware platform. In order to accommodate the RCA to the changing harvested power supply, we need a lightweight and ﬁne-grain controllable design from both the hardware and software angles. VIII. CONCLUSION MAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs. Considering the application sce- narios where the accelerator is supported by harvested energy, we ﬁnd that the previous designs cannot well accommodate the RCA to the changing power sources. This paper proposes ResiRCA, a resilient energy harvesting accelerator. We propose a lightweight and ﬂexibly tuning RCA architecture and a ResiSchedule scheme to dynamically activate various scaled MAC operations so as to fully translate the harvested energy into computation progress . ResiRCA supports smooth transi- tions among different activation solutions against computation loss. The experiment results show that the proposed ResiRCA along with the ResiSchedule scheme can achieve much higher speedups and energy efﬁciency compared to the baselines. ResiRCA for the ﬁrst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future. IX. ACKNOWLEDGEMENTS This work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants 1822923 (SPX: SOPHIA), 1763681, 1629915, 1629129, 1317560, 1526750, National Natural Science Foundation of China [NSFC Project No. 61872251] and Beijing Advanced Innova- tion Center for Imaging Technology. This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University. The authors also greatly appreciate Dr. Yongpan Liu, Dr. Kaisheng Ma, Dr. Xulong Tang and Mr. Challapalle Nagadastagiri Reddy s useful discussion. REFERENCES [1] C. Xia, J. Zhao, H. Cui, and X. Feng, Characterizing DNN models for edge-cloud computing, in 2018 IEEE International Symposium on Workload Characterization (IISWC), pp. 82 83, 2018. [2] L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, Switched by input: Power efﬁcient structure for RRAM-based convolutional neural network, in 2016 53nd ACM EDAC IEEE Design Automation Conference (DAC), pp. 1 6, 2016. [3] A. Shaﬁee, A. Nag, N. Muralimanohar, R. Balasubramonian, J. P. Strachan, M. Hu, R. S. Williams, and V. Srikumar, ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars, in 2016 ACM IEEE 43rd Annual International Symposium on Computer Architecture (ISCA), pp. 14 26, 2016. [4] P. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang, and Y. Xie, PRIME: A novel processing-in-memory architecture for neural network computation in reram-based main memory, in 2016 ACM IEEE 43rd Annual International Symposium on Computer Architecture (ISCA), pp. 27 39, 2016. [5] L. Song, X. Qian, H. Li, and Y. Chen, Pipelayer: A pipelined ReRAM- Based accelerator for deep learning, in 2017 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 541 552, 2017. [6] C. Xue, W. Chen, J. Liu, J. Li, W. Lin, W. Lin, J. Wang, W. Wei, T. Chang, T. Chang, T. Huang, H. Kao, S. Wei, Y. Chiu, C. Lee, C. Lo, Y. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, 24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors, in 2019 IEEE International Solid- State Circuits Conference - (ISSCC), pp. 388 390, 2019. [7] W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, A 65nm 1mb nonvolatile computing-in-memory ReRAM macro with sub-16ns multiply-and-accumulate for binary DNN AI edge processors, in 2018 IEEE International Solid - State Circuits Conference (ISSCC), pp. 494 496, 2018. [8] F. Su, W. Chen, L. Xia, C. Lo, T. Tang, Z. Wang, K. Hsu, M. Cheng, J. Li, Y. Xie, Y. Wang, M. Chang, H. Yang, and Y. Liu, A 462gops j RRAM-based nonvolatile intelligent processor for energy harvesting ioe system featuring nonvolatile logics and processing-in-memory, in 2017 Symposium on VLSI Technology, pp. T260 T261, 2017. [9] Y. Ji, Y. Zhang, X. Xie, S. Li, P. Wang, X. Hu, Y. Zhang, and Y. Xie, FPSA: A full system stack solution for reconﬁgurable reram-based NN accelerator architecture, in Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pp. 733 747, 2019. [10] K. Qiu, W. Chen, Y. Xu, L. Xia, Y. Wang, and Z. Shao, A peripheral circuit reuse structure integrated with a retimed data ﬂow for low power rram crossbar-based cnn, in 2018 Design, Automation Test in Europe Conference Exhibition (DATE), pp. 1057 1062, March 2018. [11] X. Jiang, J. Polastre, and D. Culler, Perpetual environmentally powered sensor networks, in Fourth International Symposium on Information Processing in Sensor Networks (IPSN), pp. 463 468, 2005. [12] S. Sudevalayam and P. Kulkarni, Energy harvesting sensor nodes: Survey and implications, IEEE Communications Surveys Tutorials, vol. 13, no. 3, pp. 443 461, 2011. [13] M. Mangrulkar and S. G. Akojwar, A simple and efﬁcient solar energy harvesting for wireless sensor node, in 2016 Second International Con- ference on Research in Computational Intelligence and Communication Networks (ICRCICN), pp. 95 99, 2016. [14] R. Grezaud and J. Willemin, A self-starting fully integrated auto-adaptive converter for battery-less thermal energy harvesting, in 2013 IEEE 11th International New Circuits and Systems Conference (NEWCAS), pp. 1 4, 2013. [15] V. Leonov, T. Torfs, P. Fiorini, and C. Van Hoof, Thermoelectric converters of human warmth for self-powered wireless sensor nodes, IEEE Sensors Journal, vol. 7, pp. 650 657, May 2007. [16] X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, RF-powered systems using steep-slope devices, in 2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS), pp. 73 76, 2014. [17] K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, Architecture exploration for ambient energy harvesting nonvolatile processors, in 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA), pp. 526 537, 2015. [18] K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, NEOFog: Nonvolatility-exploiting optimizations for fog computing, in Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS, pp. 782 796, 2018. [19] M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, Redesigning software and systems for non-volatile processors on self-powered devices, in 2016 IFIP IEEE International Conference on Very Large Scale Integration (VLSI-SoC), pp. 1 6, Sep. 2016. [20] L. Ni, Z. Liu, H. Yu, and R. V. Joshi, An energy-efﬁcient digital ReRAM-crossbar-based cnn with bitwise parallelism, IEEE Journal on Exploratory Solid-State Computational Devices and Circuits, vol. 3, pp. 37 46, Dec 2017. [21] M. Zhao, C. Fu, Z. Li, Q. Li, M. Xie, Y. Liu, J. Hu, Z. Jia, and C. J. Xue, Stack-size sensitive on-chip memory backup for self-powered nonvolatile processors, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 36, pp. 1804 1816, Nov 2017. [22] A. Colin, E. Ruppel, and B. Lucia, A reconﬁgurable energy storage architecture for energy-harvesting devices, in Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018, pp. 767 781, 2018. [23] X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, A high- efﬁciency dual-channel photovoltaic power system for nonvolatile sensor nodes, in 2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA), pp. 1 2, Aug 2014. [24] X. Sun, S. Yin, X. Peng, R. Liu, J. Seo, and S. Yu, XNOR-RRAM: A scalable and parallel resistive synaptic architecture for binary neural networks, in 2018 Design, Automation Test in Europe Conference Exhibition (DATE), pp. 1423 1428, 2018. [25] A. K. Mishra and D. Marr, WRPN apprentice: Methods for training and inference using low-precision numerics, CoRR, vol. abs 1803.00227, Apr 2018. [26] S. Han, H. Mao, and W. J. Dally, Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding, CoRR, vol. abs 1510.00149, 2015. [27] S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan, Deep learning with limited numerical precision, in Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37, ICML 15, pp. 1737 1746, 2015. [28] S. Jain, S. Venkataramani, V. Srinivasan, J. Choi, P. Chuang, and L. Chang, Compensated-dnn: Energy efﬁcient low-precision deep neural networks by compensating quantization errors, in 2018 55th ACM ESDA IEEE Design Automation Conference (DAC), pp. 1 6, 2018. [29] N. Wang, J. Choi, D. Brand, C. Chen, and K. Gopalakrishnan, Training deep neural networks with 8-bit ﬂoating point numbers, in Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018, Montr eal, Canada., pp. 7686 7695, 2018. [30] Z. Cai, X. He, J. Sun, and N. Vasconcelos, Deep learning with low precision by half-wave gaussian quantization, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5406 5414, 2017. [31] G. Venkatesh, E. Nurvitadhi, and D. Marr, Accelerating deep con- volutional networks using low-precision and sparsity, in 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2861 2865, 2017. [32] I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, Quantized neural networks: Training neural networks with low precision weights and activations, J. Mach. Learn. Res., vol. 18, pp. 6869 6898, Jan. 2017. [33] M. Courbariaux, Y. Bengio, and J.-P. David, Binaryconnect: Training deep neural networks with binary weights during propagations, in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2, NIPS 15, pp. 3123 3131, 2015. [34] M. Alwani, H. Chen, M. Ferdman, and P. Milder, Fused-layer cnn accelerators, in 2016 49th Annual IEEE ACM International Symposium on Microarchitecture (MICRO), pp. 1 12, 2016. [35] M. D. Lam, E. E. Rothberg, and M. E. Wolf, The cache performance and optimizations of blocked algorithms, in Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pp. 63 74, 1991. [36] K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, Spendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors, in 2017 22nd Asia and South Paciﬁc Design Automation Conference (ASP-DAC), pp. 678 683, 2017. [37] N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A. Wood, The Gem5 Simulator, SIGARCH Comput. Archit. News, vol. 39, pp. 1 7, Aug. 2011. [38] Synopsis, HSPICE. ﬁcation ams- veriﬁcation hspice.html . [39] H. Lv, X. Xu, P. Yuan, D. Dong, T. Gong, J. Liu, Z. Yu, P. Huang, K. Zhang, C. Huo, C. Chen, Y. Xie, Q. Luo, S. Long, Q. Liu, J. Kang, D. Yang, S. Yin, S. Chiu, and M. Liu, BEOL based RRAM with one extra-mask for low cost, highly reliable embedded application in 28 nm node and beyond, in 2017 IEEE International Electron Devices Meeting (IEDM), pp. 2.4.1 2.4.4, 2017. [40] X. Dong, C. Xu, Y. Xie, and N. P. Jouppi, NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 31, pp. 994 1007, July 2012. [41] R. Wang and Z. Xu, A pedestrian and vehicle rapid identiﬁcation model based on convolutional neural network, in Proceedings of the 7th International Conference on Internet Multimedia Computing and Service, ICIMCS 15, pp. 32:1 32:4, 2015. [42] S. A. Dawwd and B. S. Mahmood, A reconﬁgurable interconnected ﬁlter for face recognition based on convolution neural network, in 2009 4th International Design and Test Workshop (IDT), pp. 1 6, 2009. [43] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, Gradient-based learning applied to document recognition, Proceedings of the IEEE, vol. 86, pp. 2278 2324, Nov 1998. [44] H. Lin, M. Hsu, and W. Chen, Human hand gesture recognition using a convolution neural network, in 2014 IEEE International Conference on Automation Science and Engineering (CASE), pp. 1038 1043, 2014. [45] K. Ma, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, Dynamic machine learning based matching of nonvolatile processor microarchi- tecture to harvested energy proﬁle, in 2015 IEEE ACM International Conference on Computer-Aided Design (ICCAD), pp. 670 675, 2015.\n\n=== SEGMENTS ===\n\n--- Segment 1 ---\nResiRCA: A resilient energy harvesting ReRAM crossbar-based accelerator for intelligent embedded processors Keni Qiu1, Nicholas Jao3, Mengying Zhao2, Cyan Subhra Mishra3, Gulsum Gudukbay3, Sethu Jose3, Jack Sampson3, Mahmut Taylan Kandemir3 and Vijaykrishnan Narayanan3 1Capital Normal University, Beijing, China, (Email: 2Shandong University, Qingdao, China , (Email: 3Pennsylvania State University, USA, (Email: {naj5075, cyan, gulsum, {sampson, mtk2, Abstract Many recent works have shown substantial efﬁciency boosts from performing inference tasks on Internet of Things (IoT) nodes rather than merely transmitting raw sensor data. However, such tasks, e.g., convolutional neural networks (CNN), are very compute intensive. They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes. ReRAM crossbar-based accelera- tors (RCAs) are an ideal candidate to perform the dominant multiplication-and-accumulation (MAC) operations in CNNs ef- ﬁciently, but conventional, performance-oriented RCAs, while energy-efﬁcient, are power hungry and ill-optimized for the intermittent and unstable power supply of energy-harvesting IoT nodes. This paper presents the ResiRCA architecture that integrates a new, lightweight, and conﬁgurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node. To maximize ResiRCA throughput under different power levels, we develop the ResiSchedule approach for dynamic RCA reconﬁguration. The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. Experimental results show that ResiRCA and ResiSchedule achieve average speedups and energy efﬁciency improvements of 8 and 14 respectively compared to a baseline RCA with intermittency-unaware scheduling.\n\n--- Segment 2 ---\nThe proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. Experimental results show that ResiRCA and ResiSchedule achieve average speedups and energy efﬁciency improvements of 8 and 14 respectively compared to a baseline RCA with intermittency-unaware scheduling. Keywords-Energy harvesting, ReRAM crossbar, CNN, Recon- ﬁgurable hardware, Loop tiling, Computation scheduling I. INTRODUCTION In recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [1]. Such integration grants IoT devices an important degree of independence from remote servers, which can be critical in deployments with challenging communication environments. However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms. Such platforms often already operate at their limits just in order to transmit sensed data at acceptable quality of service (QoS) rates for deployment-viable battery lifetimes, and may not have additional resources available for further computation. For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type. In CNNs, for instance, MACs between the feature map data and kernel weights comprise nearly 90 of the total operations [2], [3]. Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efﬁciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [3], [4], [5], [6], [7], [8], [9], [10]. In the remainder of the paper, we may shorten the term ReRAM crossbars to ReRAMs. Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efﬁciently performing inference on an IoT device if it does not have either a high power or high stability power source.\n\n--- Segment 3 ---\nIn the remainder of the paper, we may shorten the term ReRAM crossbars to ReRAMs. Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efﬁciently performing inference on an IoT device if it does not have either a high power or high stability power source. Given form factor constraints on energy storage, the former may be challenging, and energy-harvesting from sources such as solar, thermal, kinetic and radio frequency [11], [12], [13], [14], [15], [16] is notoriously unstable. While unstable power sources have been successfully utilized for applications in the IoT space [17], [18], [19], their use has not been heavily explored for RCA design. Current RCA approaches can be divided into two categories. The approaches in the ﬁrst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [3], [4], [5], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [6], [8]. However, neither of them is a good ﬁt for energy-harvesting scenarios. To address these challenges, this paper proposes and experi- mentally evaluates ResiRCA, a resilient ReRAM crossbar-based CNN accelerator. Supported by a reconﬁgurable lightweight hardware design, ResiRCA is able to activate scalable com- putations via a multi-dimension tuning strategy. ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference. In this design paradigm, the basic low power, lightweight MCU system can enjoy the advantage of continuous operation without suffering power outages, while the compute-heavy inference tasks can be ofﬂoaded to the RCA during periods when power income is sufﬁciently high and to external systems otherwise. Such a system is capable of both continuously collecting data and computing CNNs locally near data.\n\n--- Segment 4 ---\nIn this design paradigm, the basic low power, lightweight MCU system can enjoy the advantage of continuous operation without suffering power outages, while the compute-heavy inference tasks can be ofﬂoaded to the RCA during periods when power income is sufﬁciently high and to external systems otherwise. Such a system is capable of both continuously collecting data and computing CNNs locally near data. ResiRCA allows an RCA to adapt to changing harvested energy and, with our co-designed scheduling approach, ResiSchedule, it can achieve very high throughput. To the best of our knowledge, this is the ﬁrst work that focuses on low power and reconﬁgurable RCA design from both the hardware and software angles targeting energy harvesting systems. This paper makes the following key contributions: Low power, reconﬁgurable hardware design: We pro- pose a novel architecture that implements a lightweight and low power RCA to adapt to time-varying power resources. Furthermore, the proposed hardware is reconﬁgurable at a ﬁne grain, to be able to dynamically activate different scaled computations, which can ﬁt to the changing features of the underlying power resources. Resilient computation scheduling: We provide three knobs to schedule computation blocks in the proposed ar- chitecture: (i) loop tiling which decomposes MAC operations in a given layer (ReRAM) into small blocks, (ii) ReRAM duplication which provides opportunity to perform one-layer operations with multiple weight copies, and (iii) pipelining that can organize multiple ReRAM tiles to further exploit the har- vested power. These knobs can be integrated to form sequential or pipelined computation modes. For each computation mode, we can derive the optimal activation solutions under each power level directed by the power model and throughput model ofﬂine. We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution. Smooth schedule transitioning: We identify smooth transition conditions to transfer as many partial results as possible from the last incomplete inference in one power cycle to the next power cycle with a different power level. In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction. II.\n\n--- Segment 5 ---\nIn addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction. II. MOTIVATION To avoid negatively impacting the underlying system s QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available. In energy harvesting systems, there are two critical features, namely, power strength and power window length. First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power. Second, the variance of the input power window, i.e., how long the power input stays at a given level, can be large as well. It is known that RCAs achieve their highest efﬁciency when every cell participates in the MAC computations simul- taneously [20]. However, naively integrating such an RCA renders its activation power requirement so high that the system will likely have very low duty-cycle on an intermittent supply and may never activate at all for weaker power sources unless a substantial energy store were added, which could be burdensome for form factor constraints in a system that already employs a battery for sensing and other non-inference tasks. TABLE I AN EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT-CYCLE POWER TRACE. Power cycle Harv. Power (µW) Power consumption with full-size acti. (µW) Thr. (GiGa MACs s) Power utilization Power consumption with resilient acti. (µW) Thr.\n\n--- Segment 6 ---\n(GiGa MACs s) Power utilization Power consumption with resilient acti. (µW) Thr. (Giga MACs s) Power utilization 1 50 0 Power failure 0 0 0 Power failure 0 0 2 100 0 Power failure 0 0 80 25 1 1 0.312 80 3 500 480 25 6 1 1.872 96 480 25 6 1 1.872 96 4 200 0 Power failure 0 0 160 25 2 1 0.624 80 5 250 0 Power failure 0 0 240 25 3 1 0.936 96 6 750 480 25 6 1 1.872 64 720 25 3 3 2.808 96 7 650 480 25 6 1 1.872 74 640 25 2 4 2.496 98 8 350 0 Power failure 0 0 320 25 2 2 1.248 91 100 0.4 1.2 1.6 2.0 2.4 2.8 Power ( W) Throughput (Giga MACs s) Power consumption with full-size activation Power consumption with tile-size activation Throughput with full-size activation Throughput with tile-size activation Power trace Average harvested power Average power consumption with full-size activation Average power consumption with tile-size activation Average throughput with full-size activation Average throughput with tile-size activation 356.3 180 330 1.3 200 300 400 500 600 700 800 0.8 0.7 PC1 PC2 PC3 PC4 PC5 PC6 PC7 PC8 0 0 0 0 80 480 480 0 160 0 240 480 480 640 0 320 0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 Fig. 1. Comparisons on power consumption and throughput with tile-size over full-size activation From the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property. Under this context, if the power dominant RCA works in a ﬁxed high-power mode, as in traditional RCA designs, there would be large mismatches between the harvested power and the consumed power. These mismatches can lead to the following two nonideal working scenarios: (i) Unutilized energy: As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive.\n\n--- Segment 7 ---\nUnder this context, if the power dominant RCA works in a ﬁxed high-power mode, as in traditional RCA designs, there would be large mismatches between the harvested power and the consumed power. These mismatches can lead to the following two nonideal working scenarios: (i) Unutilized energy: As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive. In this case, the harvested energy will leak away and cannot be recovered. (ii) Underutilized energy: When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level. In this case, the unused energy will be wasted, resulting in low energy efﬁciency. Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four 25 6 ReRAM crossbars, each can be mapped to six kernels, all sized 5 5 1. In the default case, the RCA works under an either ON or OFF mode with a power threshold of 80µW. During the eight harvested power cycles, the ReRAM can be ON during power cycles PC3, PC6 and PC7 and OFF with the other ﬁve power cycles. However, even when the system goes through the three power cycles, only some portion of the harvested power is consumed. As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efﬁciency under stable, high-power scenarios. Fig. 2. Comparisons on loop code and ReRAM activation with tile- size activation over full-size activation. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation If we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve continuous progress under lower power supply.\n\n--- Segment 8 ---\nComparisons on loop code and ReRAM activation with tile- size activation over full-size activation. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation If we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve continuous progress under lower power supply. This is because the starting power requirement of the RCA is reduced, and the system can thus get through power failures and translate even the low input energy into forward progress. If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles PC2, PC4, PC5 and PC8 under limited power budget, as depicted in Table II and Figure 1. The annotations indicate the consumed power (µW), tile size and duplication count (e.g., 25x2x1) and power efﬁciency. With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of 180µW to 330µW, and the throughput is increased by 85.7 . Note that the partial activation of computation cells can be realized by partially activating the peripheral circuits of the corresponding rows and columns in the ReRAM crossbar. This resilient activation approach can effectively combat Nonideal scenario 1. The underlying reason of encountering so many power failures in the case of conventional working mode is that the power threshold of the system to remain alive is set too high. With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM. With this, the RCA can be active in a very large power range and ﬁnd more opportunities to make execution progress. Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles PC6, PC7 and PC8. Parallel computations across multiple ReRAMs and loop tiling-based computation for each ReRAM are orthogonal optimizations.\n\n--- Segment 9 ---\nFurther, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles PC6, PC7 and PC8. Parallel computations across multiple ReRAMs and loop tiling-based computation for each ReRAM are orthogonal optimizations. Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode. In this example, the full size of ReRAM (or loop nest) is M N A B C N, and the tile size of ReRAM (or loop nest) is m n 1 tb C tn. Since each single ReRAM can be activated at a ﬁner granularity with tiling, the parallelism can be achieved under a ﬂexible range of power consumption to match a variable power supply. Furthermore, the better the high-power supply can be aggressively utilized, the more ambient energy can be continuously extracted without increasing the energy storage capacity for the energy-harvesting power delivery system. Therefore, this weight duplication- based execution style built upon ﬁne-granularity activation can effectively combat Nonideal scenario 2. Figure 1 also shows the throughput under the full-size activation mode and the tile-size activation mode. The ﬂexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization. Extending this single-ReRAM toy architecture to a practical multi-ReRAM architecture to process multi-layer convolutions for real-world CNNs introduces a new source of power variation in terms of the different time and power costs of different convolution layers. In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efﬁciency. III. SYSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives. Below, we provide an overview of the RCA interfaces and our system integration model and then discuss the two main steps to map a CNN to ResiRCA: ofﬂine compilation and runtime execution. A. ResiRCA overview Figure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system.\n\n--- Segment 10 ---\nBelow, we provide an overview of the RCA interfaces and our system integration model and then discuss the two main steps to map a CNN to ResiRCA: ofﬂine compilation and runtime execution. A. ResiRCA overview Figure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system. The baseline, battery-powered MCU system samples data at a ﬁxed rate, supported by the provisioned battery, and transmits either sensor data or the results of RCA processing DAC DAC DAC DAC DAC DAC MCU Memory I O Ports Interconnected Bus Clock Power Intelligent Embedded System ... ... ADC S A DAC Input Reg. Output Reg. Pool Unit FC Unit Adder Tree ResiRCA ReRAM crossbar ... ADC S A DAC ReRAM crossbar Ă Tx RX Energy Harvestor Sensors Energy harvesting (EH) ... Battery (B) B EH Ă Sigmoid ... ReRAM Memory Basic MCU System B EH EH EH EH B Fig. 3. ResiRCA architecture overview to the network. The RCA is powered by harvesting ambient energy and employs a separate, very small capacitor as its only energy storage medium, primarily for power smoothing, similar to prior energy-harvesting NVP designs [17], [21], rather than as a task-scaled energy reservoir [22]. Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources. Similar hybrid arrangements have been explored in the NVP literature [23] and impose minimal design overheads. The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiﬁcations. B. Mapping inference tasks to ResiRCA To achieve both generally low power and intermittency- compatible execution, the proposed ResiRCA architecture has the following two features that impact the software management of the RCA: Lightweight: From the perspective of the ReRAM circuit at the core of the RCA, the precision and resolution of inputs, weights and outputs are kept low to yield low power.\n\n--- Segment 11 ---\nThe baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiﬁcations. B. Mapping inference tasks to ResiRCA To achieve both generally low power and intermittency- compatible execution, the proposed ResiRCA architecture has the following two features that impact the software management of the RCA: Lightweight: From the perspective of the ReRAM circuit at the core of the RCA, the precision and resolution of inputs, weights and outputs are kept low to yield low power. This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA. Similarly, total model size, including any granularity overheads (e.g., from the partitioning used to store both positive and negative weights by having the kernels of one layer mapped to two crossbars, one each for positive and negative weights, which share the same input port) must ﬁt within the allocated RCAs of a particular ResiRCA design. Fine-grained reconﬁguration: The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes. This ﬂexible reconﬁgurability enables ﬁne-grained activations to exploit the harvested power. While execution is relatively straightforward when maintaining a speciﬁc conﬁguration of tiling and pipelining strategy, transitions between conﬁgurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures. The hardware design details will be presented in Section IV. As part of compiling a CNN to ResiRCA, we build a proﬁling table relating each potential tiling and pipeline conﬁguration that might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw. This proﬁling collects data used to determine the best activation solution for each power level. At runtime, each time when entering a new power cycle, we ﬁrst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level.\n\n--- Segment 12 ---\nThis proﬁling collects data used to determine the best activation solution for each power level. At runtime, each time when entering a new power cycle, we ﬁrst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level. Then, the execution process the data loading Mac computing data storing steps in a sequential way to perform convolution operations. The hardware design details will be presented in Section V. IV. A HARVESTING-COMPATIBLE, LOW- POWER RESIRCA Supporting the necessary features for adapting RCAs to a harvested power supply will require optimizations in both RCA circuit design and the development of variable-power-optimized loop-tiling strategies. First, feasible implementations of ﬂexible activation options require a low power and reconﬁgurable RCA. Second, a dynamic loop tiling strategy alongside a coordinated parallelism scheme should be devised to match execution power consumption as closely as possible to power income to maximize efﬁciency. This section addresses the ﬁrst of these challenges, and Section V discusses our approach to the second. Challenge 1: Achieving low-power, reconﬁgurable RCA Although recent works have presented systems [4], [3], [5] and circuits [24], [6] for inference-oriented RCAs, they are not directly suitable for adoption in our target scenario because of either their high power consumption or their stringent execution parameters (e.g., computation granularity). In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment. Figure 4 shows ﬁve harvested power sources with the maximum, mean and median values and their ratios indicated. It has been shown that the power requirement to fully activate a 128 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [3]. With this design, the presented power sources can hardly activate even a small ReRAM. In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power. Therefore, the the RCA should be built on the basis of a low power hardware design that is upwardly reconﬁgurable to higher power scenarios rather than the reverse. One approach to achieve lower RCA power is to limit precision.\n\n--- Segment 13 ---\nTherefore, the the RCA should be built on the basis of a low power hardware design that is upwardly reconﬁgurable to higher power scenarios rather than the reverse. One approach to achieve lower RCA power is to limit precision. The impact of different precisions on CNN accuracy has been extensively studied [24], [25], [26], [27], [28], [29], [30], [31], [32], [33]. To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output. With this design setting, the ReRAM size only needs to be equal to the kernel size, and the ReRAM scale does not need to be extended using a bit composing scheme (e.g. as in ISAAC [3]). In addition, it consumes very low power to handle the Successive-Approximation Register (SAR)-ADC referencing with the 4-bit output resolution.\n\n--- Segment 14 ---\nas in ISAAC [3]). In addition, it consumes very low power to handle the Successive-Approximation Register (SAR)-ADC referencing with the 4-bit output resolution. Moreover, we adopt the 1T1R technique to build high resistance and low 2000 2500 3000 3500 1 30 59 88 117 146 175 204 233 262 291 320 349 378 407 436 465 494 523 552 581 610 639 668 697 726 755 784 813 842 871 900 929 958 987 1016 1045 1074 Power (uW) Thermal Signals Pmax 3378煒W Pmean 2943煒W Pmedian 澦澭澨澦煒濋 Ratiomax mean 1.1 Ratiomax median 1.1 Data volume: 1098, Sampling time: 0.2 second, Time duration: 3.66 minutes 0 5000 10000 15000 20000 25000 30000 1 48 95 142 189 236 283 330 377 424 471 518 565 612 659 706 753 800 847 894 941 988 1035 1082 1129 1176 1223 1270 1317 1364 1411 1458 1505 1552 1599 1646 1693 1740 1787 Power (煒濋) TV-RF Signals Pmax 25828煒W Pmean 5571煒W Pmedian 澱澦澩澥澫煒濋 Ratiomax mean 4.6 Ratiomax median 10.3 Data volume: 1800, Sampling time: 0.1 second, Time duration: 3 minutes 100 600 1100 1600 2100 2600 3100 3600 4100 1 77 153 229 305 381 457 533 609 685 761 837 913 989 1065 1141 1217 1293 1369 1445 1521 1597 1673 1749 1825 1901 1977 2053 2129 2205 2281 2357 2433 2509 2585 2661 2737 2813 2889 2965 Power (uW) WiFi-office Signals Pmax 3981煒W Pmean 419煒W Pmedian 澧澩澩煒濋 Ratiomax mean 9.5 Ratiomax median 11.2 Data volume: 3000, Sampling time: 0.2 second, Time duration: 10 minutes 300 400 500 600 700 800 900 1 52 103 154 205 256 307 358 409 460 511 562 613 664 715 766 817 868 919 970 1021 1072 1123 1174 1225 1276 1327 1378 1429 1480 1531 1582 1633 1684 1735 1786 1837 1888 1939 1990 濄濣濫濙濦澔澜煒濋澝 WiFi-home Signals Pmax 891煒W Pmean 500煒W Pmedian 澱澩澤澥煒濋 Ratiomax mean 1.8 Ratiomax median 1.8 Data volume: 2000, Sampling time: 0.2 second, Time duration: 6.7 minutes 0 200 400 600 800 1000 1 165 329 493 657 821 985 1149 1313 1477 1641 1805 1969 2133 2297 2461 2625 2789 2953 3117 3281 3445 3609 3773 3937 4101 4265 4429 4593 4757 4921 5085 5249 5413 5577 5741 5905 6069 6233 6397 6561 6725 6889 7053 7217 7381 7545 7709 7873 8037 8201 8365 8529 8693 8857 9021 9185 9349 9513 9677 9841 Power (uW) Piezo Signals Pmax 998煒W Ratiomax mean 42.3 Ratiomax median 249.0 Pmean 24煒W Pmedian 澱澨煒濋 Data volume: 10000, Sample time: 0.1 millisecond, Time duration: 1 second Fig.\n\n--- Segment 15 ---\nIn addition, it consumes very low power to handle the Successive-Approximation Register (SAR)-ADC referencing with the 4-bit output resolution. Moreover, we adopt the 1T1R technique to build high resistance and low 2000 2500 3000 3500 1 30 59 88 117 146 175 204 233 262 291 320 349 378 407 436 465 494 523 552 581 610 639 668 697 726 755 784 813 842 871 900 929 958 987 1016 1045 1074 Power (uW) Thermal Signals Pmax 3378煒W Pmean 2943煒W Pmedian 澦澭澨澦煒濋 Ratiomax mean 1.1 Ratiomax median 1.1 Data volume: 1098, Sampling time: 0.2 second, Time duration: 3.66 minutes 0 5000 10000 15000 20000 25000 30000 1 48 95 142 189 236 283 330 377 424 471 518 565 612 659 706 753 800 847 894 941 988 1035 1082 1129 1176 1223 1270 1317 1364 1411 1458 1505 1552 1599 1646 1693 1740 1787 Power (煒濋) TV-RF Signals Pmax 25828煒W Pmean 5571煒W Pmedian 澱澦澩澥澫煒濋 Ratiomax mean 4.6 Ratiomax median 10.3 Data volume: 1800, Sampling time: 0.1 second, Time duration: 3 minutes 100 600 1100 1600 2100 2600 3100 3600 4100 1 77 153 229 305 381 457 533 609 685 761 837 913 989 1065 1141 1217 1293 1369 1445 1521 1597 1673 1749 1825 1901 1977 2053 2129 2205 2281 2357 2433 2509 2585 2661 2737 2813 2889 2965 Power (uW) WiFi-office Signals Pmax 3981煒W Pmean 419煒W Pmedian 澧澩澩煒濋 Ratiomax mean 9.5 Ratiomax median 11.2 Data volume: 3000, Sampling time: 0.2 second, Time duration: 10 minutes 300 400 500 600 700 800 900 1 52 103 154 205 256 307 358 409 460 511 562 613 664 715 766 817 868 919 970 1021 1072 1123 1174 1225 1276 1327 1378 1429 1480 1531 1582 1633 1684 1735 1786 1837 1888 1939 1990 濄濣濫濙濦澔澜煒濋澝 WiFi-home Signals Pmax 891煒W Pmean 500煒W Pmedian 澱澩澤澥煒濋 Ratiomax mean 1.8 Ratiomax median 1.8 Data volume: 2000, Sampling time: 0.2 second, Time duration: 6.7 minutes 0 200 400 600 800 1000 1 165 329 493 657 821 985 1149 1313 1477 1641 1805 1969 2133 2297 2461 2625 2789 2953 3117 3281 3445 3609 3773 3937 4101 4265 4429 4593 4757 4921 5085 5249 5413 5577 5741 5905 6069 6233 6397 6561 6725 6889 7053 7217 7381 7545 7709 7873 8037 8201 8365 8529 8693 8857 9021 9185 9349 9513 9677 9841 Power (uW) Piezo Signals Pmax 998煒W Ratiomax mean 42.3 Ratiomax median 249.0 Pmean 24煒W Pmedian 澱澨煒濋 Data volume: 10000, Sample time: 0.1 millisecond, Time duration: 1 second Fig. 4.\n\n--- Segment 16 ---\nMoreover, we adopt the 1T1R technique to build high resistance and low 2000 2500 3000 3500 1 30 59 88 117 146 175 204 233 262 291 320 349 378 407 436 465 494 523 552 581 610 639 668 697 726 755 784 813 842 871 900 929 958 987 1016 1045 1074 Power (uW) Thermal Signals Pmax 3378煒W Pmean 2943煒W Pmedian 澦澭澨澦煒濋 Ratiomax mean 1.1 Ratiomax median 1.1 Data volume: 1098, Sampling time: 0.2 second, Time duration: 3.66 minutes 0 5000 10000 15000 20000 25000 30000 1 48 95 142 189 236 283 330 377 424 471 518 565 612 659 706 753 800 847 894 941 988 1035 1082 1129 1176 1223 1270 1317 1364 1411 1458 1505 1552 1599 1646 1693 1740 1787 Power (煒濋) TV-RF Signals Pmax 25828煒W Pmean 5571煒W Pmedian 澱澦澩澥澫煒濋 Ratiomax mean 4.6 Ratiomax median 10.3 Data volume: 1800, Sampling time: 0.1 second, Time duration: 3 minutes 100 600 1100 1600 2100 2600 3100 3600 4100 1 77 153 229 305 381 457 533 609 685 761 837 913 989 1065 1141 1217 1293 1369 1445 1521 1597 1673 1749 1825 1901 1977 2053 2129 2205 2281 2357 2433 2509 2585 2661 2737 2813 2889 2965 Power (uW) WiFi-office Signals Pmax 3981煒W Pmean 419煒W Pmedian 澧澩澩煒濋 Ratiomax mean 9.5 Ratiomax median 11.2 Data volume: 3000, Sampling time: 0.2 second, Time duration: 10 minutes 300 400 500 600 700 800 900 1 52 103 154 205 256 307 358 409 460 511 562 613 664 715 766 817 868 919 970 1021 1072 1123 1174 1225 1276 1327 1378 1429 1480 1531 1582 1633 1684 1735 1786 1837 1888 1939 1990 濄濣濫濙濦澔澜煒濋澝 WiFi-home Signals Pmax 891煒W Pmean 500煒W Pmedian 澱澩澤澥煒濋 Ratiomax mean 1.8 Ratiomax median 1.8 Data volume: 2000, Sampling time: 0.2 second, Time duration: 6.7 minutes 0 200 400 600 800 1000 1 165 329 493 657 821 985 1149 1313 1477 1641 1805 1969 2133 2297 2461 2625 2789 2953 3117 3281 3445 3609 3773 3937 4101 4265 4429 4593 4757 4921 5085 5249 5413 5577 5741 5905 6069 6233 6397 6561 6725 6889 7053 7217 7381 7545 7709 7873 8037 8201 8365 8529 8693 8857 9021 9185 9349 9513 9677 9841 Power (uW) Piezo Signals Pmax 998煒W Ratiomax mean 42.3 Ratiomax median 249.0 Pmean 24煒W Pmedian 澱澨煒濋 Data volume: 10000, Sample time: 0.1 millisecond, Time duration: 1 second Fig. 4. Variance feature of different power sources III-ADC BL WL SL Column 1 CSA - SAR Ref Shift Add Driver Row 1 Row 2 Row m Driver Driver I-DAC II-Comp 4-bit inputs 1-bit resolution 1-bit weights 4-bit outputs bit- serial Input Reg.\n\n--- Segment 17 ---\n4. Variance feature of different power sources III-ADC BL WL SL Column 1 CSA - SAR Ref Shift Add Driver Row 1 Row 2 Row m Driver Driver I-DAC II-Comp 4-bit inputs 1-bit resolution 1-bit weights 4-bit outputs bit- serial Input Reg. 4-bit Output Reg. C C C controlling circuit Fig. 5. Lightweight ReRAM circuit design power ReRAM cells. Figure 5 shows the proposed peripheral circuit design for one ReRAM crossbar. This design is more concise even than the SINWP [6], because we target low power as the primary goal. To increase efﬁciency further our design supports aggressive power gating and other circuit techniques to dynamically reconﬁgure active tile sizes and shut-off inactive ReRAMs. Speciﬁcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows. We modify the column multiplexers to enable variable active columns and turn off the ADCs of inactive channels. Lastly, we apply coarse-grain power gating to conﬁgure the number of duplicated ReRAMs. This reconﬁguration ability can enable scaled activation of the circuits such that small tile-size computation can be enabled while yielding very low power consumption. V. POWER-DYNAMIC RCA SCHEDULING Given a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture. Challenge 2: Software controlled dynamic RCA activation and scheduling The idea of loop tiling has been widely leveraged in RCA design to either increase system throughput by smoothing the pipelining or reduce memory accesses by improving data locality [34], [3]. In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM accelerated MACs. Moreover, we allow parallelism along different dimensions to seamlessly integrate it with loop tiling, and as a result, a range of scalable computations that can ﬁt in different power supplies are achieved. With this design idea, the system can keep making forward progress over a large range of power incomes. Sections V-A-V-C develop a dynamic activation strategy for different power levels and Section V-D discusses the transition strategy between dynamic activation solutions.\n\n--- Segment 18 ---\nWith this design idea, the system can keep making forward progress over a large range of power incomes. Sections V-A-V-C develop a dynamic activation strategy for different power levels and Section V-D discusses the transition strategy between dynamic activation solutions. A. Computation decomposition and parallelism If the harvested power P budget is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress. For active RCAs, one option is to use loop tiling to decompose computations, and the other is to parallelize computations. The parallelism in this context is of two types: intra layer parallelism via layer duplication and inter layer parallelism via layer pipelining. Further, tiling and parallelization can also be combined to generate ﬁne-grained scales of computations to efﬁciently ﬁt into the changing harvested power. 1) Computation tiling: In this work, we use loop tiling [35] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one. As shown in Figure 2, if loop tiling is applied to the unrolled MAC operations, only a tile of ReRAM cells along with their peripheral circuits is enabled to perform MAC operations. After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed. Note that, if the row- wise tiling factor is less than the ReRAM row number, this tiled execution strategy will introduce partial sums. When the traversal completes, an Adder Tree will be used to merge the partial sums for ReRAM columns and obtain the ﬁnal MAC result. 2) Computation parallelism: Intra-layer parallelism means overlapping the layer computations on duplicated copies of ReRAMs that store the same weights for one layer. We use parallelism granularity G to denote the duplication count as deﬁned in [5]. G can be determined considering the tradeoff between energy efﬁciency and chip area during the design phase. In this work, the parallelism granularity G of a layer is determined by the ratio between 50 of the peak harvested power during proﬁling and the power consumption of the full- size ReRAM corresponding to this layer.\n\n--- Segment 19 ---\nG can be determined considering the tradeoff between energy efﬁciency and chip area during the design phase. In this work, the parallelism granularity G of a layer is determined by the ratio between 50 of the peak harvested power during proﬁling and the power consumption of the full- size ReRAM corresponding to this layer. That is, if the 50 peak harvested power by proﬁling is twice (G 2) of the power consumption with a ReRAM size of Layer 1 of 25x6, the RCA will be designed to offer two sets of ReRAMs sized 25x6 for Layer 1. The actual parallelism granularity aG G for a layer is decided by the harvested power level. If we allow aG ReRAMs to perform the concerned layer s computations in parallel, the input data should be divided into aG partitions. In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel. This offers a ﬂexible way to tune the power consumption in a large design space, even though the kernel size, convolution count and power consumption of different layers can signiﬁcantly vary. Inter-layer parallelism means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion. This pipeline parallelism provides us with another dimension to aggressively exploit the harvested energy. We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers. Previous work [3] has noted vulnerabilities to pipeline bubbles and execution stalls in CNNs because of the large variance in weight and feature map scales across different layers. In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very ﬁne-grain fashion. 3) Execution strategies: Figure 6 shows ﬁve different execution strategies for a two-layer convolution execution experiencing two power cycles with different levels. In Fig- ure 6(a), a naive scheduling strategy is employed on a Simple architecture.\n\n--- Segment 20 ---\n3) Execution strategies: Figure 6 shows ﬁve different execution strategies for a two-layer convolution execution experiencing two power cycles with different levels. In Fig- ure 6(a), a naive scheduling strategy is employed on a Simple architecture. In this scheduling strategy, the RCA is only active when the harvested power is adequate to support the maximal power requirement among all the convolution layers and, in the simple architecture, one convolution layer can only be mapped to one ReRAM (no ReRAM duplication). In the remainder of this paper, this execution strategy is referred to as Naive1. We assume that Naive1 is also designed with the proposed lightweight circuits. In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication. This execution strategy is referred as Naive2. None of Naive1 and Naive2 executions can go through power cycle PC-i and the power utilization is very low, as there is a signiﬁcant mismatch between the power producer and consumer. Figure 6(c) presents a ﬂexible scheduling strategy applied to ResiRCA. In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks. The layers are scheduled in a sequential fashion. This execution style is called Sequential. In the example, we allow activating L1 ReRAMs with aG 4 and one partial L2 ReRAM in a sequential fashion.\n\n--- Segment 21 ---\nThis execution style is called Sequential. In the example, we allow activating L1 ReRAMs with aG 4 and one partial L2 ReRAM in a sequential fashion. In Figure 6(d), the loop tiling technique integrated with both duplication and pipelining is used to schedule all layers on the I4-L1 I4- L2 I1- L2 I3-L1 I3- L2 I3-L1 I3-L1 I3-L1 I1-L1 I1- L2 Ă Power Cycles Power Harvested power (a) Naive 1 Ă Power Cycles Power Harvested power (b) Naive 2 Ă I1- L2 -T1 I1 -L2 -T2 Power Cycles Power Harvested power (c) Sequential Ă I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 I1-L1- T2 I1-L1- T2 I2- L2 -T1 I2 -L2 -T2 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I2-L1- T2 I2-L1- T2 I1-L1 I1-L1 Ă I1- L2 I1- L2 Ă Power Cycles Harvested power Ă I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 Ă Power I1- L2 -T1 I1 -L2 -T2 Power Cycles Harvested power Ă I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 I1-L1- T2 I1-L1- T2 Ă Power I1-L1- T3 I1-L1- T3 I1- L2 -T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I1- L2 -T2 I1- L2 -T3 I2-L1- T3 I2-L1- T3 I1- L2 -T4 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T2 I3-L1- T2 I3-L1- T2 I3-L1- T2 I2- L2 -T1 I2 -L2 -T2 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T2 I4-L1- T2 I4-L1- T2 I4-L1- T2 I3- L2 -T1 I3 -L2 -T2 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T2 I5-L1- T2 I5-L1- T2 I5-L1- T2 I4- L2 -T1 I4 -L2 -T2 I2- L2 -T1 I2 -L2 -T2 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I2-L1- T2 I2-L1- T2 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T2 I3-L1- T2 I3-L1- T2 I3-L1- T2 I2- L2 -T1 I2 -L2 -T2 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T2 I4-L1- T2 I4-L1- T2 I4-L1- T2 I3- L2 -T1 I3 -L2 -T2 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T2 I5-L1- T2 I5-L1- T2 I5-L1- T2 I4- L2 -T1 I4 -L2 -T2 (d) Pipelining (e) ResiSchedule I1-L1 I1-L1 I1-L1 I2-L1 I2- L2 I2-L1 I2-L1 I2-L1 I1-L1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 I5-L1 I5- L2 I5-L1 I5-L1 I5-L1 I3-L1 I3- L2 I3-L1 I3-L1 I3-L1 I4-L1 I4-L1 I4-L1 Fig.\n\n--- Segment 22 ---\nIn the example, we allow activating L1 ReRAMs with aG 4 and one partial L2 ReRAM in a sequential fashion. In Figure 6(d), the loop tiling technique integrated with both duplication and pipelining is used to schedule all layers on the I4-L1 I4- L2 I1- L2 I3-L1 I3- L2 I3-L1 I3-L1 I3-L1 I1-L1 I1- L2 Ă Power Cycles Power Harvested power (a) Naive 1 Ă Power Cycles Power Harvested power (b) Naive 2 Ă I1- L2 -T1 I1 -L2 -T2 Power Cycles Power Harvested power (c) Sequential Ă I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 I1-L1- T2 I1-L1- T2 I2- L2 -T1 I2 -L2 -T2 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I2-L1- T2 I2-L1- T2 I1-L1 I1-L1 Ă I1- L2 I1- L2 Ă Power Cycles Harvested power Ă I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 Ă Power I1- L2 -T1 I1 -L2 -T2 Power Cycles Harvested power Ă I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 I1-L1- T2 I1-L1- T2 Ă Power I1-L1- T3 I1-L1- T3 I1- L2 -T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I1- L2 -T2 I1- L2 -T3 I2-L1- T3 I2-L1- T3 I1- L2 -T4 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T2 I3-L1- T2 I3-L1- T2 I3-L1- T2 I2- L2 -T1 I2 -L2 -T2 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T2 I4-L1- T2 I4-L1- T2 I4-L1- T2 I3- L2 -T1 I3 -L2 -T2 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T2 I5-L1- T2 I5-L1- T2 I5-L1- T2 I4- L2 -T1 I4 -L2 -T2 I2- L2 -T1 I2 -L2 -T2 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I2-L1- T2 I2-L1- T2 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T2 I3-L1- T2 I3-L1- T2 I3-L1- T2 I2- L2 -T1 I2 -L2 -T2 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T2 I4-L1- T2 I4-L1- T2 I4-L1- T2 I3- L2 -T1 I3 -L2 -T2 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T2 I5-L1- T2 I5-L1- T2 I5-L1- T2 I4- L2 -T1 I4 -L2 -T2 (d) Pipelining (e) ResiSchedule I1-L1 I1-L1 I1-L1 I2-L1 I2- L2 I2-L1 I2-L1 I2-L1 I1-L1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 I5-L1 I5- L2 I5-L1 I5-L1 I5-L1 I3-L1 I3- L2 I3-L1 I3-L1 I3-L1 I4-L1 I4-L1 I4-L1 Fig. 6.\n\n--- Segment 23 ---\nIn Figure 6(d), the loop tiling technique integrated with both duplication and pipelining is used to schedule all layers on the I4-L1 I4- L2 I1- L2 I3-L1 I3- L2 I3-L1 I3-L1 I3-L1 I1-L1 I1- L2 Ă Power Cycles Power Harvested power (a) Naive 1 Ă Power Cycles Power Harvested power (b) Naive 2 Ă I1- L2 -T1 I1 -L2 -T2 Power Cycles Power Harvested power (c) Sequential Ă I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 I1-L1- T2 I1-L1- T2 I2- L2 -T1 I2 -L2 -T2 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I2-L1- T2 I2-L1- T2 I1-L1 I1-L1 Ă I1- L2 I1- L2 Ă Power Cycles Harvested power Ă I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 Ă Power I1- L2 -T1 I1 -L2 -T2 Power Cycles Harvested power Ă I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T1 I1-L1- T2 I1-L1- T2 I1-L1- T2 I1-L1- T2 Ă Power I1-L1- T3 I1-L1- T3 I1- L2 -T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I1- L2 -T2 I1- L2 -T3 I2-L1- T3 I2-L1- T3 I1- L2 -T4 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T2 I3-L1- T2 I3-L1- T2 I3-L1- T2 I2- L2 -T1 I2 -L2 -T2 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T2 I4-L1- T2 I4-L1- T2 I4-L1- T2 I3- L2 -T1 I3 -L2 -T2 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T2 I5-L1- T2 I5-L1- T2 I5-L1- T2 I4- L2 -T1 I4 -L2 -T2 I2- L2 -T1 I2 -L2 -T2 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T1 I2-L1- T2 I2-L1- T2 I2-L1- T2 I2-L1- T2 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T1 I3-L1- T2 I3-L1- T2 I3-L1- T2 I3-L1- T2 I2- L2 -T1 I2 -L2 -T2 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T1 I4-L1- T2 I4-L1- T2 I4-L1- T2 I4-L1- T2 I3- L2 -T1 I3 -L2 -T2 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T1 I5-L1- T2 I5-L1- T2 I5-L1- T2 I5-L1- T2 I4- L2 -T1 I4 -L2 -T2 (d) Pipelining (e) ResiSchedule I1-L1 I1-L1 I1-L1 I2-L1 I2- L2 I2-L1 I2-L1 I2-L1 I1-L1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 PC-i PC-i 1 I5-L1 I5- L2 I5-L1 I5-L1 I5-L1 I3-L1 I3- L2 I3-L1 I3-L1 I3-L1 I4-L1 I4-L1 I4-L1 Fig. 6. Five layer scheduling schemes: (a) Naive execution Simple architecture; (b) Naive execution ResiRCA architecture; (c) Se- quential resilient execution ResiRCA architecture; (d) Pipelining resilient execution ResiRCA architecture; and (e) Hybrid resilient execution ResiRCA architecture ResiRCA architecture; we call this execution style Pipelining.\n\n--- Segment 24 ---\n6. Five layer scheduling schemes: (a) Naive execution Simple architecture; (b) Naive execution ResiRCA architecture; (c) Se- quential resilient execution ResiRCA architecture; (d) Pipelining resilient execution ResiRCA architecture; and (e) Hybrid resilient execution ResiRCA architecture ResiRCA architecture; we call this execution style Pipelining. For ease of explanation and simulation, we only allow full pipelining in this execution, which means MAC operations of all the layers are included in each pipeline stage. Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme. We refer to this as ResiSchedule. At runtime, ResiSchecule dynamically selects activation solutions from either Sequential or Pipelining in each power cycle, depending on which can provide a better throughput. With ResiSchedule, we can cover a large tuning range commensurate with power supply variation. Section V-C will further present quantitative analysis and solution on how toﬁgureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA. B.Powermodelandlatencymodel PowersupplyisasigniﬁcantconstraintforResiSchedule. Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solutionm,n,aG wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,Pload,PcompandPstore,andtheyareperformed insequence. 1)Loadandstore:PloadandPstore denotethepower consumedbyloadingthedatafromthepureReRAMmem- oryintotheinputregistersandstoringthedatafromthe outputregistersintotheReRAM memory .Pload aG (Bitsinput BNin) Pld bit modelsloadpoweroperation.\n\n--- Segment 25 ---\nByanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solutionm,n,aG wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,Pload,PcompandPstore,andtheyareperformed insequence. 1)Loadandstore:PloadandPstore denotethepower consumedbyloadingthedatafromthepureReRAMmem- oryintotheinputregistersandstoringthedatafromthe outputregistersintotheReRAM memory .Pload aG (Bitsinput BNin) Pld bit modelsloadpoweroperation. Here,thetermsBitsinputandBNindenotethenumberof inputbitstoserve MACoperationsforafull-sizedReRAMand thebatchnumberoftransferringtheseinputbitsrespectively . Therefore,Bitinput BNinmeanstheactualloadeddatabits eachbatch.ThetermPld bitdenotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister. TheinputbatchnumberBNinisdeterminedbythepower budgetbecausePload Pbudgetshouldalwaysbesatisﬁed. Thelatency modelfordataloadforoneconvolution operationisLatload Bitsinput BWld.ThetermLatload representsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.ThetermBWlddenotesthebandwidthof eachloadoperation.ThemodelsofPstoreandLatstorecan bederivedinasimilarfashion.\n\n--- Segment 26 ---\nTheinputbatchnumberBNinisdeterminedbythepower budgetbecausePload Pbudgetshouldalwaysbesatisﬁed. Thelatency modelfordataloadforoneconvolution operationisLatload Bitsinput BWld.ThetermLatload representsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.ThetermBWlddenotesthebandwidthof eachloadoperation.ThemodelsofPstoreandLatstorecan bederivedinasimilarfashion. 2) ComputationonReRAMs:Pcompisthedominantand mostcomplicatedpartwheretheanaloganddigitalsignals aremixed.Theenergyofone-cycle MACoperationsforan activationsizeofm nandactualduplicationaG,Pcomp tile dividesintothefollowingparts:1)EDAC denotestheenergy consumedforconvertingthedigitalinputsignaltotheanalog signalinabit-serialfashion;2)EMAC denotestheenergy forperforming MACoperationsonReRAMs;and3)EADC consistsofthreepartsasshowninFigure5:3i)EBL denoting theenergyforactivatingbitlines;3ii)ESA Ref denotingthe energyforsensingandamplifyingthe MACresultsignaland thenreferencinganalogsignalstodigitalsignals;and,3iii) ES A denotingtheenergyofShift Addparttocomposethe ﬁnaloutput. IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisﬁxedasLatcomp Tcomp,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1. Ecomp Ecomp tile Latcomp (EDAC EMAC EADC) Tcomp (1) Thepowerofeachpartistakentobelineartothetiling factorsofm ornortheactualparallelismgranularityaG.\n\n--- Segment 27 ---\nIntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisﬁxedasLatcomp Tcomp,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1. Ecomp Ecomp tile Latcomp (EDAC EMAC EADC) Tcomp (1) Thepowerofeachpartistakentobelineartothetiling factorsofm ornortheactualparallelismgranularityaG. TheenergyforoneReRAMrow(eDAC),oneReRAMcell (e MAC )andoneReRAMcolumn(e BL,e SA Ref,e S A)are theworst-casevaluesfromthesimulation.TableV-B2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies. TABLEII RELATIONSHIPOFENERGYANDTHERERAMTILINGSIZEAND RERAMCOPIES. Component Energyequation DAC EDAC eDAC m aG Computation EM AC eMAC m n aG ADC BL EBL eBL n aG SA-Ref ESA Ref eSA Ref n aG S A ES A eS A n aG 3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated. Asaresult,thesepartialsumsneedtobe mergedoncethe (tile)traversalofanentireReRAMiscomplete.Thesum mergingoperationisperformedbyanAdderTreeasillustrated inFigure3. Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint ofPmerg Pbudgetshouldbealways met.Therefore,the powerPmerge andlatencyLatmerge ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofﬂine.\n\n--- Segment 28 ---\nAsaresult,thesepartialsumsneedtobe mergedoncethe (tile)traversalofanentireReRAMiscomplete.Thesum mergingoperationisperformedbyanAdderTreeasillustrated inFigure3. Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint ofPmerg Pbudgetshouldbealways met.Therefore,the powerPmerge andlatencyLatmerge ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofﬂine. 4)Activationtransitioncost:Theexecutiontransitionfrom onetiletoanotherinsideonepowercycleorfromoneactivation solutiontoanotherindifferentpowerlevelsalsocostspower PtransandlatencyLattrans.Activationtransitionimpliesthat weneedtoenablethecorrespondingcircuitsoftheto-be- activatedrowsandcolumnswhileshuttingdowntheothers. Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs. 5)Powerandlatencymodels:Theaboveanalysiscaptures thepowerconsumptionandexecutionlatencyofprocessing oneconvolutionlayer .Itisassumedthatallofthesesteps areperformedinsequence.Puttingthemalltogether,for convolutionlayerLk,thepowerandlatencypaircanbemodeled asinEquation2and3. PLK (Pld Latld Lk Pcomp Latcomp Lk Pst Latst Lk Pmerge Latmerge Lk ) LatLk (2) LatLK Latld Lk Latcomp Lk Latst Lk Latmerge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication.\n\n--- Segment 29 ---\n5)Powerandlatencymodels:Theaboveanalysiscaptures thepowerconsumptionandexecutionlatencyofprocessing oneconvolutionlayer .Itisassumedthatallofthesesteps areperformedinsequence.Puttingthemalltogether,for convolutionlayerLk,thepowerandlatencypaircanbemodeled asinEquation2and3. PLK (Pld Latld Lk Pcomp Latcomp Lk Pst Latst Lk Pmerge Latmerge Lk ) LatLk (2) LatLK Latld Lk Latcomp Lk Latst Lk Latmerge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication. Underthesequentialcomputation mode, theconvolutionlayersareexecutedonebyoneinasequential fashion, and as a result, the power model and latency model in Equations 2 and 3 can be directly used. We also model the pipelined computation mode shown in Equations 4 and 5. Note that the pipelined computation mode means that all the LC convolution layers are executed fully parallel. P pipe LC X Lk 1 PLk (4) Latpipe max(LatL1, LatL2...LatLC) (5) C. Dynamic activation strategy 1) Problem formulation: In this section, we focus on ﬁguring out the ResiSchedule solution to achieve the maximal throughput. Although we can arrange more hardware resources with the pipelined computation mode, it does not mean this mode will always yield greater computation progress than the sequential mode due to the constraints of tile size and parallelism granularity. Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Given a power supply level, we can derive the optimal tile size and actual duplication granularity to form the activation solution m, n, aG for sequential or pipelined computation modes, respectively.\n\n--- Segment 30 ---\nTherefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Given a power supply level, we can derive the optimal tile size and actual duplication granularity to form the activation solution m, n, aG for sequential or pipelined computation modes, respectively. Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level. Throughput model Achieving the maximal computation progress under the harvested energy has two implications. The ﬁrst one is that we expect more energy can be used for program progress. The other is more subtle in that we expect the power can be consumed quickly in order to receive more energy from outside. In this regard, the metric throughput measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios. We use the number of convolutional MAC operations to represent the computations. For the sequential computation mode, the throughput for Layer Lk can be expressed as below: Thrsequ Lk (m n)Lk aGLk LatLk (6) The average throughput with a LC-convolution CNN infer- ence can be expressed as shown below. Thrsequ ave PLk LC Lk 1 (m n)Lk aGLk PLk C Lk 1 LatLk (7) For the pipelining computation mode, all the LC layers are executed in parallel. The throughput can be expressed as follows: Thrpipe ave PLk LC Lk 1 (m n)Lk aGLk Latpipe (8) 2) Activation strategy formulation : The activation strategy for the sequential mode can be described as shown below.\n\n--- Segment 31 ---\nThrsequ ave PLk LC Lk 1 (m n)Lk aGLk PLk C Lk 1 LatLk (7) For the pipelining computation mode, all the LC layers are executed in parallel. The throughput can be expressed as follows: Thrpipe ave PLk LC Lk 1 (m n)Lk aGLk Latpipe (8) 2) Activation strategy formulation : The activation strategy for the sequential mode can be described as shown below. In order to formulate the problem in a concise way, the tiling factors, m and n, are constrained to be divisors of the ReRAM weight matrix M N using the annotations of m M; n N. Objective: Maximize Thrsequ ave Subjected to: for each layer Lk, P load Lk , P store Lk , P comp Lk , P trans Lk , P merge Lk P budget; aGLk GLk; mLk MLk; nLk NLk; Solution output: mLk, nLk, aGLk for each layer Lk Similarly, the activation strategy under the pipeline execution mode can be described as below. Objective: Maximize Thrpipe ave Subjected to: P P load, P P store, P P comp pipe , P P trans, P P merge P budget; aGLk GLk; mLk MLk; nLk NLk; Solution output: mLk, nLk, aGLk for each layer Lk By solving the above problems, we can obtain activation solution m, n, aG for each power level under the sequential and pipelining computation modes, referred to as SOLsequ and SOLpipe respectively. Then the optimal solution can be selected from among them. The solution space is actually very small because of the constraints that tile size candidates and aG are all bounded in the integer domain. It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode. In this case, we choose the activation solution with larger tiling size by taking into account the transition cost. If the tiling sizes of output solutions are the same, we choose larger m because larger m implies fewer partial sum adds. D. Activation transition The power instability of energy harvesting implies that the activation solution needs to change dynamically as power level changes.\n\n--- Segment 32 ---\nIf the tiling sizes of output solutions are the same, we choose larger m because larger m implies fewer partial sum adds. D. Activation transition The power instability of energy harvesting implies that the activation solution needs to change dynamically as power level changes. Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy. An FSM transition can happen between any pair of power levels. Activation solution under power level l: ml, nl, aGl Activation solution under power level h: mh, nh, aGh Smooth transitionl- hwithout power prediction Smooth transitionl- h with power prediction Smooth transitionh- lwithout power prediction Smooth transitionh- l with power prediction 1 2 3 4 Fig. 7. Activation solution transition FSM The convolution computations of one inference may not be completed while transitioning to a new power level. For small-scale applications with strong harvested power supply, discarding the incomplete execution may have only modest overheads. However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle. Fortunately, there exist opportunities to keep and transfer the intermediate computation results of the last incomplete inference to the next power cycle. Considering a transition for one layer from an activation solution m1, n1, aG1 to m2, n2, aG2 , we ﬁnd that, if the expression Conditiontrans: (m1 m2) (n2 (Tilecount1 n1)) (aG1 aG2) is true for each convolution layer, the activation solution m1, n1, aG1 with power level PL1 can be transferred to be equivalent to an execution of activation solution m2, n2, aG2 with PL2. The execution equivalency can be transferred by Tilecount2 Tilecount1 n1 n2. The next power cycle s level information cannot be known with certainty. In order to not discard the acquired results, we can search the maximal Tilecount1 where Tilecount1 Tilecount1 to make the expression n2 ( Tilecount1 n1) conservatively true for each layer, and then transfer the tile count Tilecount1 to accommodate to the new activation solution. This means that only a portion of computation results from Tilecount1 to Tilecount1 will be discarded.\n\n--- Segment 33 ---\nIn order to not discard the acquired results, we can search the maximal Tilecount1 where Tilecount1 Tilecount1 to make the expression n2 ( Tilecount1 n1) conservatively true for each layer, and then transfer the tile count Tilecount1 to accommodate to the new activation solution. This means that only a portion of computation results from Tilecount1 to Tilecount1 will be discarded. The discussion on this transition without power prediction is applied for transitions 1 and 2 in the Figure 7. We call this smooth transition strategy as TransitionKeep. With a power predictor [36], we can estimate the power level of the next power cycle in advance. In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference. Still, with Conditiontrans satisﬁed, the smooth transition can be achieved in a similar way. Otherwise, if the expression Conditiontrans is not satisﬁed, with power prediction, we can still speculatively attempt to perform a smooth transition. There are two strategies to achieve this. We can search for an intermediate power level, where we ﬁrst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level this strategy is called Multi-step Transition. If the power predictor reports a power transition from a high level to a low level, we can move to the new activation solution before performing the last incomplete inference this strategy is referred to as Eager Transition. The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7. Since a power predictor itself consumes power, it makes sense to employ it for large-scale applications under weak power sources where discarding a portion of computations may impose a big loss or for the scenarios where power level transitions happen frequently. VI. EXPERIMENTS To evaluate ResiRCA, we have extended the Gem5 [37] simulator with RCA modeling. The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock. The energy harvesting mechanism is supported by the power management unit, which can record power production and consumption at an execution cycle level. The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs.\n\n--- Segment 34 ---\nThe energy harvesting mechanism is supported by the power management unit, which can record power production and consumption at an execution cycle level. The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs. We perform cycle-accurate simulation for the MAC computations based on tile activation and the data load store process. However, for other functional units, we assign a ﬁxed latency. For the ReRAM circuit simulation, we quantify power and performance of our design in HSPice [38] using 20nm FinFET ReRAM parameters from [39]. Load store parameters of the ReRAM memory are from NVSim [40]. The main parameters of our simulations are given in Table VI. Four practical CNNs listed in Table VI are evaluated on the ﬁve power traces illustrated in Figure 4 for each of the ﬁve execution strategies from Section V-A3: Naive1; Naive2; Sequential; Pipelining; and ResiSchedule. TABLE III RERAM PARAMETERS ReRAM computing crossbar DAC(150 N 1 title) 5.4 pJ ADC(M 1 1 title) 749 fJ S A(M 1 1 title) 41.6 fJ area (all peripherals included) 2950.47 µm2 ReRAM memory (16KB) bandwidth 128 bit s read energy 37.993 pJ read latency 1.577 ns write energy 95.412 pJ write latency 20.09 ns TABLE IV IOT-PRACTICAL CNN WORKLOADS CNN Layer Kernel RRAM Size Acti.\n\n--- Segment 35 ---\nFour practical CNNs listed in Table VI are evaluated on the ﬁve power traces illustrated in Figure 4 for each of the ﬁve execution strategies from Section V-A3: Naive1; Naive2; Sequential; Pipelining; and ResiSchedule. TABLE III RERAM PARAMETERS ReRAM computing crossbar DAC(150 N 1 title) 5.4 pJ ADC(M 1 1 title) 749 fJ S A(M 1 1 title) 41.6 fJ area (all peripherals included) 2950.47 µm2 ReRAM memory (16KB) bandwidth 128 bit s read energy 37.993 pJ read latency 1.577 ns write energy 95.412 pJ write latency 20.09 ns TABLE IV IOT-PRACTICAL CNN WORKLOADS CNN Layer Kernel RRAM Size Acti. power Input PV [41] Input Conv1 36 8 752.2µW Conv2 72 12 1125.6µW Conv3 108 16 1526µW Conv4 144 10 1114µW Conv5 90 6 676.2µW FR [42] Input Conv1 25 4 377.4µW Conv2 64 16 1433.6µW LeNet [43] Input Conv1 25 6 539.7µW Conv2 150 16 1614.2µW HG [44] Input Conv1 25 6 539.7µW Conv2 96 12 1176µW For each application on each power trace, we report the throughput and energy efﬁciency under the ﬁve different execution strategies. We then demonstrate the beneﬁts from the proposed smooth transition strategy and power prediction. We also study the sensitivity of our proposed approach to available ReRAM hardware resources. A. Throughput Figure 8 shows the throughput comparison of the ﬁve exe- cution strategies. The bars are all normalized to ResiSchedule. The included table gives the absolute values of throughput by ResiSchedule. The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 compared to a baseline RCA with intermittency-unaware scheduling.\n\n--- Segment 36 ---\nThe included table gives the absolute values of throughput by ResiSchedule. The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 compared to a baseline RCA with intermittency-unaware scheduling. One can make the following observations and analyses from these results: For each workload with each power source, ResiSchedule always achieves the highest throughput because it combines the best activation solution in each power cycle. The results of Naive1 are the worst because it lacks both adequate hardware resources and scheduling ﬂexibility. Although Naive2 is based on the ResiRCA architecture, the throughput is still relatively low because it lacks scheduling adaptation to ﬁt to the changing harvested power. The results of ResiSchedule are very close or equal to that of Sequential under most cases. When we track the simulation cycles, it is found that the throughput of Sequential solution ResiSchedule Piezo WiFi-home WiFi-office Thermal TV-RF Fig. 8. Throughput of CNNs across the power sources normalized to ResiSchedule Piezo WiFi-home WiFi-office Thermal TV-RF Fig. 9. Energy efﬁciency of CNNs across the power sources normalized to ResiSchedule is higher than that of Pipelining solution for a signiﬁcant fraction of the active power cycles. That is, the selection ratio of Sequential is much higher than the ratio of Pipelining in ResiSchedule solutions in the whole power trace. Consistent with the above observation, the entire Sequential strategy competes with the entire Pipelining. The reason is that the active power threshold of Pipelining is much higher than that of Sequential. As a result, fewer power cycles of Pipelining are available than that of Sequential. However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments. When we change to a smaller ReRAM duplication granularity G, we ﬁnd that the throughput of Pipelining is better than that of Sequential for many power levels. The duplication sensitivity results are presented in Section VI-F. Regarding the throughput absolute values, the results with the power sources of Thermal and TV-RF are much higher than those with the others, which is constant with the power strength illustrated in Figure 4. B.\n\n--- Segment 37 ---\nRegarding the throughput absolute values, the results with the power sources of Thermal and TV-RF are much higher than those with the others, which is constant with the power strength illustrated in Figure 4. B. Energy efﬁciency We evaluate energy efﬁciency by measuring MAC operations per Joule, as shown in Figure 9. Note that this includes the energy overheads of data movements and other functional units in addition to MACs. Overall, the normalized results of energy efﬁciency are very similar to those of the throughput evaluation. The results show that ResiRCA and ResiSchedule achieve average energy efﬁciency improvements of 14 compared to a baseline RCA with intermittency-unaware scheduling. The only difference that can be observed is that, regarding LeNet and PV with the power source of Thermal, relatively speaking, the results of energy efﬁciency with Pipelining strategy are higher than that appearing in the throughput evaluation. One possible reason for this is that Pipelining requires loading several inputs from ReRAM memory to perform the parallel operations, which is power-expensive. This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efﬁciency when active is high. Compared to the cloud for online processing, the preference for local compute over ofﬂoad can stem from security, con- nectivity and latency concerns as well as power and energy constraints. In our work, local computation across the CNN applications is 50x more efﬁcient than transmission over Bluetooth with 3Mbps and 2.5mW. C. Power utilization In order to further understand the power utilization, we use a two-dimensional plot that illustrates the features of power consumption with theResiSchedule strategy, as shown in Figure 10. The x-axis (power efﬁciency) denotes the percentage of power cycles where the RCA can activate. The y-axis (power utilization), on the other hand, denotes the percentage of valid power during activations which is actually utilized for computation and data transfer. An ideal system would be at the point (1,1). It can be observed from these results that the proposed ResiSchedule strategy can make good use of the Piezo source when it does exceed the minimal activation thresholds, though the very low duty cycle yields very low throughput.\n\n--- Segment 38 ---\nAn ideal system would be at the point (1,1). It can be observed from these results that the proposed ResiSchedule strategy can make good use of the Piezo source when it does exceed the minimal activation thresholds, though the very low duty cycle yields very low throughput. 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 0 0.10.20.30.40.50.60.70.80.9 1 Power Utilization Power efficiency Piezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG Fig. 10. ResiSchedule power efﬁciency analysis D. Transition efﬁciency Table VI-D shows the ratio of inferences using smooth- transitioned partial results and total inference count number. These results indicate that the smooth transition strategy TransitionKeep enables a signiﬁcant fraction of the inferences for all workloads on Piezo. However, a very small fraction is observed with the other, stronger power sources. For Piezo, saving the intermediate results of one incomplete inference is meaningful. However, one power cycle of the other power sources can usually process thousands or hundreds of inferences. TABLE V THE RATIO OF ADDITIONAL INFERENCES ENABLED BY THE SMOOTH TRANSITION STRATEGY VS. TOTAL INFERENCES Piezo WiFi-h WiFi-o Thermal TV-RF LeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 E. Power predictor With an accurate power predictor [45], [36], we can make more smooth transitions among different power levels.\n\n--- Segment 39 ---\nHowever, one power cycle of the other power sources can usually process thousands or hundreds of inferences. TABLE V THE RATIO OF ADDITIONAL INFERENCES ENABLED BY THE SMOOTH TRANSITION STRATEGY VS. TOTAL INFERENCES Piezo WiFi-h WiFi-o Thermal TV-RF LeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 E. Power predictor With an accurate power predictor [45], [36], we can make more smooth transitions among different power levels. The beneﬁt is that we can keep more MAC results of the last incomplete inference when switching from a higher power level to a lower power level, even if Conditiontrans is not satisﬁed. However, to be valuable the power predictor must have high accuracy. For both Piezo and Thermal power sources the prediction accuracy when using a multi-power-level-optimized extension of the power predictor in [36] are above 80 . Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with Transitionkeep for all the workloads with these power sources. 0.0 0.3 0.0 0.3 0.0 0.9 1.9 2.0 0.0 0.5 0.0 20.0 40.0 60.0 vs. all inferences vs. addi. inferences w smooth transition vs. all inferences vs. addi. inferences w smooth transition Piezo Thermal LeNet FR HG PV Fig. 11. Percentages of additional inferences with power prediction over all inferences and additional inferences with the Transitionkeep strategy The portion of inferences added with power prediction are signiﬁcant for Piezo for most workloads. This is because, the Piezo source is very weak and and the total completed number of inferences is quite small. Speculative action supported by power prediction can keep quite a few incomplete inferences to be completed in the next power cycle.\n\n--- Segment 40 ---\nThis is because, the Piezo source is very weak and and the total completed number of inferences is quite small. Speculative action supported by power prediction can keep quite a few incomplete inferences to be completed in the next power cycle. This can also explain why the portions with the power source of Thermal are very small. However, for both Piezo and Thermal, the portions for PV are very small. The underlying reason is that the smooth Transitionkeep strategy can already handle the smooth transitions with no need of power prediction support for this workload. F. Sensitivity study on duplication copy We vary the ReRAM duplication granularity G for each layer and evaluate with TV-RF source. Throughput results are plotted in Figure 12 and area costs for G1 G5 can be found in Figure 13. For each benchmark, all the numbers are normalized to that of the G4 setting with the Naive2 policy. As expected, the throughput increases as G grows for every benchmark. Another interesting observation is that the results of ResiSchedule policy can be competitive to that of Sequential policy when G is small and vice versa. The main reason for this is that the ResiSchedule policy can efﬁciently organize more hardware resources than the Sequential policy when hardware resources are limited. 0.00 0.20 0.40 0.60 0.80 1.00 1.20 1.40 1.60 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 PV HG LeNet FR Naive2 Sequential Pipelining ResiSchedule Fig. 12. Throughput normalized to G4 with Naive2 vs. ReRAM duplication granularity The RCA area is impacted from the parallelism granularity G, as shown in Figure 13. It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed smart dust solutions [8]. The ideal parallelism granularity determination for a particular deployment should consider the balance between throughput and area.\n\n--- Segment 41 ---\nIt also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed smart dust solutions [8]. The ideal parallelism granularity determination for a particular deployment should consider the balance between throughput and area. 0 20000 40000 60000 80000 100000 120000 140000 160000 PV HG LeNet FR G1 G2 G3 G4 (default) G5 Area in m2 2, 2, 2, 2, 2 4, 3, 2, 3, 5 6, 4, 3, 4, 7 8, 5, 4, 5, 9 12, 7, 6, 7, 13 2, 2 6, 2 9, 3 11, 5 16, 7 2, 2 5, 2 8, 3 11, 4 16, 6 2, 2 7, 2 13, 3 17, 4 22, 6 Fig. 13. Area with different duplication granularity VII. RELATED WORK The previous RCA related work can be divided into the following two categories: High Performance RCA Architectures: PRIME [4] uses 6-bit inputs and 8-bit weights and targets 6-bit output precision. A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight. In the PRIME conﬁguration, the ReRAM-based Full Function (FF) subarrays have both computation and data storage capabilities. To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed. In the ISAAC design [3], the inputs, weights and outputs are all 16 bits, where the DAC, ReRAM cell and ADC resolutions are, respectively, 1-bit, 2-bit and 8-bit. Also, a similar composition scheme is employed to organize the input, weight and output data. The ISAAC architecture is composed of 16 tiles and each tile consists of 8 IMAs which includes 4 ReRAMs along with 4 sets of peripheral circuits. An intra-tile pipeline is formed to boost the dot-product throughput. In the PipeLayer design [5], a spike-based scheme, instead of a voltage-level based scheme, is used for input to eliminate the power overhead of DACs and ADCs. The underlying idea is to use spike counts to represent the data value.\n\n--- Segment 42 ---\nIn the PipeLayer design [5], a spike-based scheme, instead of a voltage-level based scheme, is used for input to eliminate the power overhead of DACs and ADCs. The underlying idea is to use spike counts to represent the data value. They propose intra-layer and inter-layer parallelism to support the training phase by reducing potential stalls. ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [8] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets. It includes four ReRAMs, each 32x32. The inputs and weights are binary and the output is adaptive between 1-3 bits. The serial-input non-weighted product (SINWP) structure [6] is the ﬁrst work to propose multi-bit input weight and output design from the circuit level, adopting a 2-bit input, 3-bit weight, and 4-bit output scheme. Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a 3-bit resolution, which is a high performance but also a high power consuming design. Although the above designs provide different approaches to achieve high throughput, high energy efﬁciency and low power, they cannot be directly applied or combined to be applied in the energy harvested edge devices due to the following reasons. The architecture-centric works [3], [4], [5] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption. Furthermore, the hierarchy they adopt with multiple ReRAMs targets primarily high throughput, leading to high power consumption on the whole RCA. For example, the total 168 Tiles and one IMA element of the ISAAC architecture [3] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets. It can be seen that those designs are not suitable for an RCA supplied with harvested unstable power. Although the spike-based scheme [5] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input output data.\n\n--- Segment 43 ---\nIt can be seen that those designs are not suitable for an RCA supplied with harvested unstable power. Although the spike-based scheme [5] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input output data. It is known that the energy harvesting system often suffers from power failures and works in an intermittent mode; so, the spike-based data injection scheme is not favorable. For the ReRAM circuit concerned works [6], [8], although they are lightweight, they cannot be dynamically reconﬁgured to adapt changing power levels. In addition, such works have not presented any software level solution to maximize the utilization of the hardware platform. In order to accommodate the RCA to the changing harvested power supply, we need a lightweight and ﬁne-grain controllable design from both the hardware and software angles. VIII. CONCLUSION MAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs. Considering the application sce- narios where the accelerator is supported by harvested energy, we ﬁnd that the previous designs cannot well accommodate the RCA to the changing power sources. This paper proposes ResiRCA, a resilient energy harvesting accelerator. We propose a lightweight and ﬂexibly tuning RCA architecture and a ResiSchedule scheme to dynamically activate various scaled MAC operations so as to fully translate the harvested energy into computation progress . ResiRCA supports smooth transi- tions among different activation solutions against computation loss. The experiment results show that the proposed ResiRCA along with the ResiSchedule scheme can achieve much higher speedups and energy efﬁciency compared to the baselines. ResiRCA for the ﬁrst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future. IX. ACKNOWLEDGEMENTS This work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants 1822923 (SPX: SOPHIA), 1763681, 1629915, 1629129, 1317560, 1526750, National Natural Science Foundation of China [NSFC Project No.\n\n--- Segment 44 ---\nIX. ACKNOWLEDGEMENTS This work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants 1822923 (SPX: SOPHIA), 1763681, 1629915, 1629129, 1317560, 1526750, National Natural Science Foundation of China [NSFC Project No. 61872251] and Beijing Advanced Innova- tion Center for Imaging Technology. This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University. The authors also greatly appreciate Dr. Yongpan Liu, Dr. Kaisheng Ma, Dr. Xulong Tang and Mr. Challapalle Nagadastagiri Reddy s useful discussion. REFERENCES [1] C. Xia, J. Zhao, H. Cui, and X. Feng, Characterizing DNN models for edge-cloud computing, in 2018 IEEE International Symposium on Workload Characterization (IISWC), pp. 82 83, 2018. [2] L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, Switched by input: Power efﬁcient structure for RRAM-based convolutional neural network, in 2016 53nd ACM EDAC IEEE Design Automation Conference (DAC), pp. 1 6, 2016. [3] A. Shaﬁee, A. Nag, N. Muralimanohar, R. Balasubramonian, J. P. Strachan, M. Hu, R. S. Williams, and V. Srikumar, ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars, in 2016 ACM IEEE 43rd Annual International Symposium on Computer Architecture (ISCA), pp. 14 26, 2016.\n\n--- Segment 45 ---\nNag, N. Muralimanohar, R. Balasubramonian, J. P. Strachan, M. Hu, R. S. Williams, and V. Srikumar, ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars, in 2016 ACM IEEE 43rd Annual International Symposium on Computer Architecture (ISCA), pp. 14 26, 2016. [4] P. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang, and Y. Xie, PRIME: A novel processing-in-memory architecture for neural network computation in reram-based main memory, in 2016 ACM IEEE 43rd Annual International Symposium on Computer Architecture (ISCA), pp. 27 39, 2016. [5] L. Song, X. Qian, H. Li, and Y. Chen, Pipelayer: A pipelined ReRAM- Based accelerator for deep learning, in 2017 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 541 552, 2017. [6] C. Xue, W. Chen, J. Liu, J. Li, W. Lin, W. Lin, J. Wang, W. Wei, T. Chang, T. Chang, T. Huang, H. Kao, S. Wei, Y. Chiu, C. Lee, C. Lo, Y. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, 24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors, in 2019 IEEE International Solid- State Circuits Conference - (ISSCC), pp. 388 390, 2019. [7] W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y.\n\n--- Segment 46 ---\n388 390, 2019. [7] W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, A 65nm 1mb nonvolatile computing-in-memory ReRAM macro with sub-16ns multiply-and-accumulate for binary DNN AI edge processors, in 2018 IEEE International Solid - State Circuits Conference (ISSCC), pp. 494 496, 2018. [8] F. Su, W. Chen, L. Xia, C. Lo, T. Tang, Z. Wang, K. Hsu, M. Cheng, J. Li, Y. Xie, Y. Wang, M. Chang, H. Yang, and Y. Liu, A 462gops j RRAM-based nonvolatile intelligent processor for energy harvesting ioe system featuring nonvolatile logics and processing-in-memory, in 2017 Symposium on VLSI Technology, pp. T260 T261, 2017. [9] Y. Ji, Y. Zhang, X. Xie, S. Li, P. Wang, X. Hu, Y. Zhang, and Y. Xie, FPSA: A full system stack solution for reconﬁgurable reram-based NN accelerator architecture, in Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pp. 733 747, 2019. [10] K. Qiu, W. Chen, Y. Xu, L. Xia, Y. Wang, and Z. Shao, A peripheral circuit reuse structure integrated with a retimed data ﬂow for low power rram crossbar-based cnn, in 2018 Design, Automation Test in Europe Conference Exhibition (DATE), pp. 1057 1062, March 2018. [11] X. Jiang, J. Polastre, and D. Culler, Perpetual environmentally powered sensor networks, in Fourth International Symposium on Information Processing in Sensor Networks (IPSN), pp. 463 468, 2005.\n\n--- Segment 47 ---\n[11] X. Jiang, J. Polastre, and D. Culler, Perpetual environmentally powered sensor networks, in Fourth International Symposium on Information Processing in Sensor Networks (IPSN), pp. 463 468, 2005. [12] S. Sudevalayam and P. Kulkarni, Energy harvesting sensor nodes: Survey and implications, IEEE Communications Surveys Tutorials, vol. 13, no. 3, pp. 443 461, 2011. [13] M. Mangrulkar and S. G. Akojwar, A simple and efﬁcient solar energy harvesting for wireless sensor node, in 2016 Second International Con- ference on Research in Computational Intelligence and Communication Networks (ICRCICN), pp. 95 99, 2016. [14] R. Grezaud and J. Willemin, A self-starting fully integrated auto-adaptive converter for battery-less thermal energy harvesting, in 2013 IEEE 11th International New Circuits and Systems Conference (NEWCAS), pp. 1 4, 2013. [15] V. Leonov, T. Torfs, P. Fiorini, and C. Van Hoof, Thermoelectric converters of human warmth for self-powered wireless sensor nodes, IEEE Sensors Journal, vol. 7, pp. 650 657, May 2007. [16] X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, RF-powered systems using steep-slope devices, in 2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS), pp. 73 76, 2014. [17] K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, Architecture exploration for ambient energy harvesting nonvolatile processors, in 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA), pp. 526 537, 2015.\n\n--- Segment 48 ---\n[17] K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, Architecture exploration for ambient energy harvesting nonvolatile processors, in 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA), pp. 526 537, 2015. [18] K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, NEOFog: Nonvolatility-exploiting optimizations for fog computing, in Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS, pp. 782 796, 2018. [19] M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, Redesigning software and systems for non-volatile processors on self-powered devices, in 2016 IFIP IEEE International Conference on Very Large Scale Integration (VLSI-SoC), pp. 1 6, Sep. 2016. [20] L. Ni, Z. Liu, H. Yu, and R. V. Joshi, An energy-efﬁcient digital ReRAM-crossbar-based cnn with bitwise parallelism, IEEE Journal on Exploratory Solid-State Computational Devices and Circuits, vol. 3, pp. 37 46, Dec 2017. [21] M. Zhao, C. Fu, Z. Li, Q. Li, M. Xie, Y. Liu, J. Hu, Z. Jia, and C. J. Xue, Stack-size sensitive on-chip memory backup for self-powered nonvolatile processors, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 36, pp. 1804 1816, Nov 2017. [22] A. Colin, E. Ruppel, and B. Lucia, A reconﬁgurable energy storage architecture for energy-harvesting devices, in Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018, pp.\n\n--- Segment 49 ---\n1804 1816, Nov 2017. [22] A. Colin, E. Ruppel, and B. Lucia, A reconﬁgurable energy storage architecture for energy-harvesting devices, in Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018, pp. 767 781, 2018. [23] X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, A high- efﬁciency dual-channel photovoltaic power system for nonvolatile sensor nodes, in 2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA), pp. 1 2, Aug 2014. [24] X. Sun, S. Yin, X. Peng, R. Liu, J. Seo, and S. Yu, XNOR-RRAM: A scalable and parallel resistive synaptic architecture for binary neural networks, in 2018 Design, Automation Test in Europe Conference Exhibition (DATE), pp. 1423 1428, 2018. [25] A. K. Mishra and D. Marr, WRPN apprentice: Methods for training and inference using low-precision numerics, CoRR, vol. abs 1803.00227, Apr 2018. [26] S. Han, H. Mao, and W. J. Dally, Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding, CoRR, vol. abs 1510.00149, 2015. [27] S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan, Deep learning with limited numerical precision, in Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37, ICML 15, pp. 1737 1746, 2015. [28] S. Jain, S. Venkataramani, V. Srinivasan, J. Choi, P. Chuang, and L. Chang, Compensated-dnn: Energy efﬁcient low-precision deep neural networks by compensating quantization errors, in 2018 55th ACM ESDA IEEE Design Automation Conference (DAC), pp. 1 6, 2018.\n\n--- Segment 50 ---\n[28] S. Jain, S. Venkataramani, V. Srinivasan, J. Choi, P. Chuang, and L. Chang, Compensated-dnn: Energy efﬁcient low-precision deep neural networks by compensating quantization errors, in 2018 55th ACM ESDA IEEE Design Automation Conference (DAC), pp. 1 6, 2018. [29] N. Wang, J. Choi, D. Brand, C. Chen, and K. Gopalakrishnan, Training deep neural networks with 8-bit ﬂoating point numbers, in Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018, Montr eal, Canada., pp. 7686 7695, 2018. [30] Z. Cai, X. He, J. Sun, and N. Vasconcelos, Deep learning with low precision by half-wave gaussian quantization, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5406 5414, 2017. [31] G. Venkatesh, E. Nurvitadhi, and D. Marr, Accelerating deep con- volutional networks using low-precision and sparsity, in 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2861 2865, 2017. [32] I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, Quantized neural networks: Training neural networks with low precision weights and activations, J. Mach. Learn. Res., vol. 18, pp. 6869 6898, Jan. 2017. [33] M. Courbariaux, Y. Bengio, and J.-P. David, Binaryconnect: Training deep neural networks with binary weights during propagations, in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2, NIPS 15, pp. 3123 3131, 2015.\n\n--- Segment 51 ---\n[33] M. Courbariaux, Y. Bengio, and J.-P. David, Binaryconnect: Training deep neural networks with binary weights during propagations, in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2, NIPS 15, pp. 3123 3131, 2015. [34] M. Alwani, H. Chen, M. Ferdman, and P. Milder, Fused-layer cnn accelerators, in 2016 49th Annual IEEE ACM International Symposium on Microarchitecture (MICRO), pp. 1 12, 2016. [35] M. D. Lam, E. E. Rothberg, and M. E. Wolf, The cache performance and optimizations of blocked algorithms, in Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pp. 63 74, 1991. [36] K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, Spendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors, in 2017 22nd Asia and South Paciﬁc Design Automation Conference (ASP-DAC), pp. 678 683, 2017. [37] N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A. Wood, The Gem5 Simulator, SIGARCH Comput. Archit. News, vol. 39, pp. 1 7, Aug. 2011. [38] Synopsis, HSPICE. ﬁcation ams- veriﬁcation hspice.html .\n\n--- Segment 52 ---\n[38] Synopsis, HSPICE. ﬁcation ams- veriﬁcation hspice.html . [39] H. Lv, X. Xu, P. Yuan, D. Dong, T. Gong, J. Liu, Z. Yu, P. Huang, K. Zhang, C. Huo, C. Chen, Y. Xie, Q. Luo, S. Long, Q. Liu, J. Kang, D. Yang, S. Yin, S. Chiu, and M. Liu, BEOL based RRAM with one extra-mask for low cost, highly reliable embedded application in 28 nm node and beyond, in 2017 IEEE International Electron Devices Meeting (IEDM), pp. 2.4.1 2.4.4, 2017. [40] X. Dong, C. Xu, Y. Xie, and N. P. Jouppi, NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 31, pp. 994 1007, July 2012. [41] R. Wang and Z. Xu, A pedestrian and vehicle rapid identiﬁcation model based on convolutional neural network, in Proceedings of the 7th International Conference on Internet Multimedia Computing and Service, ICIMCS 15, pp. 32:1 32:4, 2015. [42] S. A. Dawwd and B. S. Mahmood, A reconﬁgurable interconnected ﬁlter for face recognition based on convolution neural network, in 2009 4th International Design and Test Workshop (IDT), pp. 1 6, 2009. [43] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, Gradient-based learning applied to document recognition, Proceedings of the IEEE, vol. 86, pp. 2278 2324, Nov 1998. [44] H. Lin, M. Hsu, and W. Chen, Human hand gesture recognition using a convolution neural network, in 2014 IEEE International Conference on Automation Science and Engineering (CASE), pp. 1038 1043, 2014.\n\n--- Segment 53 ---\n[44] H. Lin, M. Hsu, and W. Chen, Human hand gesture recognition using a convolution neural network, in 2014 IEEE International Conference on Automation Science and Engineering (CASE), pp. 1038 1043, 2014. [45] K. Ma, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, Dynamic machine learning based matching of nonvolatile processor microarchi- tecture to harvested energy proﬁle, in 2015 IEEE ACM International Conference on Computer-Aided Design (ICCAD), pp. 670 675, 2015.\n\n