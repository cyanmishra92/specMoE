=== ORIGINAL PDF: 2505.12523v1_Energy-Aware_Deep_Learning_on_Resource-Constrained.pdf ===\n\nRaw text length: 108531 characters\nCleaned text length: 105536 characters\nNumber of segments: 61\n\n=== CLEANED TEXT ===\n\narXiv:2505.12523v1 [cs.LG] 18 May 2025 Energy-Aware Deep Learning on Resource-Constrained Hardware JOSH MILLAR, HAMED HADDADI, Imperial College London ANIL MADHAVAPEDDY, University of Cambridge The use of deep learning (DL) on Internet of Things (IoT) and mobile devices offers numerous advantages over cloud- based processing. However, such devices face substantial energy constraints to prolong battery-life, or may even operate intermittently via energy-harvesting. Consequently, energy-aware approaches for optimizing DL inference and training on such resource-constrained devices have garnered recent interest. We present an overview of such approaches, outlining their methodologies, implications for energy consumption and system-level efficiency, and their limitations in terms of supported network types, hardware platforms, and application scenarios. We hope our review offers a clear synthesis of the evolving energy-aware DL landscape and serves as a foundation for future research in energy-constrained computing. 1 Introduction The Internet of Things (IoT) has become a vital component of our everyday lives, with a forecasted 30 billion smart devices connecting and controlling our homes, urban environments, and factories by 2027 [41]. IoT devices generate massive amounts of data, which often requires machine learning (ML) -based processing. Deep Neural Networks (DNNs) and other ML approaches are notoriously resource-intensive and so, traditionally, cloud-based processing has been relied upon to handle their computational load. However, considerable recent work has focused on enabling on-device deep learning (DL) inference and training. This offers numerous advantages over cloud-based processing, including reduced and predictable latency [61], independent of network congestion saturation, minimized bandwidth [185], and improved data privacy. IoT, mobile, and other edge devices often face strict constraints in terms of memory and compute resources. Hence, numerous works focus on optimizing DNNs subject to such constraints. These generally focus on inference, employing lightweight DNN architectures [83, 94, 125] and compression methods [39, 67, 115], as well as strategies for adapting inference dynamically based on input-complexity and workload. These strategies include multi- exit networks [72], inference offloading [178], and the partitioning of inference between device and cloud [20]. Additional works focus on enabling on-device DNN training [9, 11, 31, 71, 85, 156, 187] by regulating layer-wise growth [187] or eliminating redundant weights activations to minimize updates [85]. However, IoT devices also operate on strict energy budgets to prolong battery life. The energy consumption of a DNN is not directly proportional to its memory or computational footprint [14] so, while the above optimization methods improve DNN efficiency, they generally fail to optimize for energy-usage. This is vital, as energy-usage can impose a larger constraint on particular devices or applications than memory compute (ùëí.ùëî., if considering battery-less devices and or deployment in remote or hard-to-reach environments). We characterize energy-aware DL as approaches for optimizing the design, inference, or training of DNNs in terms of energy consumption. Note that energy-awareness is not limited to energy-efficiency alone, also including approaches that can regulate inference energy consumption based on energy-availability, workload, and input complexity. This survey provides a concise review of such approaches, focusing on those with potential for deployment on highly-constrained IoT devices, particularly microcontroller units (MCUs). 1.1 Related Works and Contributions Numerous survey works explore ML and DL for resource-constrained computing [1], yet specifically energy-aware approaches have received comparatively limited attention. Tekin et al. offer the only comprehensive survey addressing on-device ML from an energy consumption perspective [145], but their IoT-centric review emphasizes use-case taxonomy and tooling over optimization, and overlooks energy-harvesting and intermittent computing. Various benchmarking efforts also exist in this domain. MLPerfPower [148], arguably the most prominent initiative, provides a benchmarking suite for standardizing the energy measurement of ML workloads at power 2 Millar et al. scales ranging from microwatts to megawatts. It covers diverse platforms including mobile phones and specialized TPUs, like Nvidia s Jetson family, but has limited coverage on MCUs and ultra-low-power devices. Its benchmarks remain neither particularly up-to-date nor comprehensive regarding emerging energy-aware techniques. Our work instead provides a concise yet detailed overview of algorithm-based techniques for energy-aware DNN design, training, inference, and deployment policies. We emphasize practical methodologies tailored to IoT devices operating under severe power constraints or intermittency conditions, offering a focused perspective on the evolving energy-aware DL landscape. 1.2 Structure We cover energy-aware DNN design paradigms ( 2), methods for energy-adaptive DNN inference ( 3), and on-device DNN training ( 4). We then explore various real-world DL applications in which energy-awareness is imperative and requires novel approaches; these include federated learning (FL) ( 5.2) and DL on intermittent energy-harvesting devices ( 5.1). Finally, 6 outlines the various hardware platforms employed in the reviewed works. Each section offers insights into potential future directions. 7 provides a high-level overview of these. 2 Energy-Aware DNN Design Including energy as a design-time metric is key for guiding the design and optimization of efficient DNNs. However, balancing energy-efficiency with performance is a layered design challenge and requires sophisticated optimization techniques. The bulk of existing work has predominantly focused on using the number of DNN weights and or operations as proxy for energy consumption; in particular multiply-and-accumulate (MAC) operations, which often account for over 99 of total CNN operations [40, 42, 68]. Unfortunately, while these proxies are correlated to the memory and computational footprints of DNNs, they do not accurately reflect their energy consumption (ùëí.ùëî., SqueezeNet [51] contains 50x fewer MACs than AlexNet [68], yet exhibits greater energy consumption on various platforms [103, 173]). This is because DNN energy consumption is enormously impacted by data movement; access to memory distant from the processor may cost 10 to 100 times more than an FPU ALU operation [180]. GoogLeNet s [139] energy consumption breakdown reveals that only 10 is attributed to network computation and the rest consumed by the movement of feature-maps [175]. Further, differences in memory architecture between platforms result in large variations in the comparative energy-efficiency of DNNs across devices. Therefore, energy-aware and platform-agnostic DNN compression and optimization methods [38] are vital. Such methods can be largely categorised into the following: pruning: removing redundant weights from a network. quantization: reducing the bit-precision of network weights (e.g., from 32-bit float to 8-bit integer). weight sharing: reusing weights across network layers (e.g., shared filters in convolutional layers). knowledge distillation: training a smaller network to emulate a larger one by minimizing the entropy, distance, or divergence between their outputs. low-rank decomposition: approximating network weights with products of lower-rank matrices. These optimisations generally reduce network memory footprint by removing or compressing DNN weights. However, as mentioned above, memory-focused compression does not guarantee optimal DNN energy con- sumption. There has been recent interest in energy-aware variants of such methods; among these, pruning and quantization have received the most attention in the context of energy-aware compression. 0 Energy-Aware Deep Learning on Resource-Constrained Hardware 3 Table 1. An overview of energy-aware neural architecture search methods. A dash indicates an out-of-scope area. Method Eval. (Base) Arch. Space Constrained Eval. Hardware Approach Energy-Estimation [98] DeepCaps [113], CapsNet [120] - Evolutionary MACs, memory-accesses [155] MobileNetV1 V2 [46, 126] - Gradient FLOPs [18] MobileNetV2, MNASNet [140] Snapdragon 835 (CPU) Evolutionary Hardware-measurements [57] ¬µNAS [82] TI MSP430FR5994 (MCU) Super-Net MACs [21] MobileNetV2, ResNet50 [43], YOLOv5 [150] Huawei Atlas200DK (NPU), Zynq ZCU102 (FPGA) Super-Net Hardware-measurements 2.1 Design-Time Optimizations Given the recognition that memory-focused compression does not guarantee optimal DNN energy consumption, there is a growing interest in the development of energy-aware variants of such compression methods that are directly optimized for energy use. In energy-aware pruning (EAP), the pruning order is determined based on ranked layer-wise energy consump- tion [173]. EAP approaches vary predominantly by their means of estimating layer-wise energy consumption; approaches include joint estimation based on computation cost (ùëñ.ùëí. MACs) and memory accesses [176], using CNN filter importance (nuclear-norm derived from SVD) as proxy [179], and using energy-measurements derived from real hardware measurements [174]. GENESIS [33] enables layer-wise DNN compression via rank decom- position and pruning, incorporating user-defined operator energy-costs. However, the effectiveness of EAP is limited by the fact that CNN energy consumption is dominated by convolutional operations and their extensive data movement, while pruning techniques are most effective on fully-connected (FC) layers. There is also substantial recent work focusing on energy-aware quantization (EAQ) in the realm of in-memory DL accelerators. These accelerators utilize non-volatile memory to improve CNN energy-efficiency by performing convolution operations as analog-domain matrix-vector multiplications. This effectively reduces data move- ment. ECQ [60] utilizes a genetic approach for exploring layer-wise weight activation bitwidth(s), optimizing dynamic in-memory energy consumption at negligible performance loss. The ECQ approach requires only a network s weight activation distributions in order to estimate its energy consumption, making it applicable across various DNNs. The utilization of in-memory accelerators offers vast potential in reducing DNN inference energy consumption by minimizing data movement. However, such accelerators are not yet widely applicable on memory-constrained devices; Kim et al. [65] provide a detailed overview of in-memory techniques for DL. The key limitation of EA compression methods lies in their accuracy in predicting the layer operation-wise energy consumption of DNNs pre-execution. 2.3 provides an overview of existing energy-estimation methods, and their supported hardware platforms and DNN operators. Future work should additionally explore the impact of hardware variation on non-uniform quantization techniques. 2.2 Neural Architecture Search Traditional works enabling on-device inference focused on hand-crafted DNN architectures, including SqueezeNet [51], MobileNet [46, 126], and EfficientNet [141]. The design of these architectures required substantial manual tuning, combined with ingenuity; and while efficient, they lack versatility for diverse task-specific optimiza- tions. Neural Architecture Search (NAS) methods revolutionized NN design by automating the discovery of 4 Millar et al. NN architectures that optimize various performance metrics for a given task, while also considering computa- tional hardware constraints. Numerous works have demonstrated NAS s capability to reveal NN designs with state-of-the-art performance [116]. Typical NAS methods explore the architecture space using evolutionary [90] or reinforcement-learning (RL) [53] approaches. These methods require vast computational resources and GPU hours, rendering them infeasible in most real-world applications. Consequently, more recent NAS methods use proxies for architecture evaluation to reduce search complexity at the expense of (marginally) suboptimal results. Favoured among these methods is Differentiable NAS (DNAS), which utilizes gradient descent to optimize both DNN weights and parameters. Typically, DNAS employs super-nets, large DNNs that include various implementations of subnetworks, and explores the architecture space by evaluating subnetwork paths. However, super-net DNAS methods are often limited in their capacity to model complex constraints, and their utility can be outweighed by evolutionary learning-based NAS methods if the base architecture results in an excessively large super-net. ProxylessNAS [10] mitigates this issue by limiting subnetwork evaluation to binary paths. NAS excels in NN compression and optimization for a given task but is limited in its ability to jointly optimize performance and hardware-aware constraints. Typical EA-NAS approaches resort to using MACs, FLOPs, and other proxies for energy consumption. NASCaps [98], for example, supports energy-aware NAS for traditional DNNs alongside convolutional capsule networks [120], proxying energy consumption using a combination of MACs and memory-accesses. By integrating capsule layers and dynamic routing, it jointly optimizes capsule networks for energy consumption, accuracy, memory-footprint, and latency. However, as previously mentioned, such proxies often result in an incomplete profile of DNN energy consump- tion. The difficulty in using energy as an optimization metric again lies in accurately estimating the consumption of a given architecture without physically executing it, which is infeasible given the vast design space. Addition- ally, the energy consumption of a DNN is highly device platform dependent. Therefore, EA-NAS methods often utilize regression-based approaches, built on recorded energy measurements from a subset of NAS-generated reference architectures on the target platform, to predict the energy consumption of candidate architectures. Liu et. al [86] introduce NAS as a "continual splitting process", in which DNN operators are split for iterative loss minimization, and Wang et. al [155] extend this by incorporating benchmark energy-measurements of operator splitting to discover more energy-efficient architectures. ET-NAS [21] uses energy consumption benchmarks of NN operators on various edge-side FPGA platforms, and under various parameter settings. ChamNet [18] is an evolutionary NAS method utilizing Gaussian-process regression and energy estimates derived from benchmark measurements for a range of hardware platforms, including mobile CPUs and DSPs. 2.3 provides an overview of existing energy-prediction methods for NAS, and their supported hardware platforms and DNN operators. Tabular energy consumption benchmarks for various architectures are slowly developing. However, they currently remain limited to common NN operators, architectures, and datasets. HW-NAS-Bench [78] collects measured estimated hardware metrics, including energy consumption, of explored candidate networks within the spaces of NAS-Bench-201 [22] and FBNet [166], on six diverse COTS devices. These include the NVIDIA Jetson TX2 GPU, Raspberry Pi 4, an Edge TPU Dev Board, Google Pixel 3, and Eyeriss (ASIC) [14]. Ta et. al [149] conduct hardware energy measurements of various edge-DNNs, including but not limited to MobileNet v1 v2 [46, 126], SqueezeNet [51], GoogLeNet [139] and ProxylessNAS [10], on various other mobile CPUs and GPUs. Devices used include the OnePlus 8, Xiaomi Redmi Note8, and the Huawei Mate40 Pro and P40 Pro Lite. Generalizing to new architectures, without complicating the NAS space with hardware specifications, involves one- or few-shot learning methods [184, 189]. The extension of existing benchmarks via few-shot networks and surrogate models, predicting learning dynamics in conjunction with energy measurements, can help bridge the gap between hardware-agnostic NAS optimization and practical energy-efficient architecture search [5]. Table 1 provides an overview of EA-NAS methods, including the architectural space and hardware-platforms on which they were evaluated, as well as their energy-estimation methodologies. Energy-Aware Deep Learning on Resource-Constrained Hardware 5 Table 2. An overview of DNN energy-estimation methodologies. A dash indicates an out-of-scope area. Method Granularity Inputs Application Eval. Platform Supported Operators [117] Layer, Network MACs Inference CPU (Cortex A-series) conv, fc [118] Network Layer parameters Inference, Training CPU-GPU (Nvidia Tegra K1) - [171] Layer Layer parameters Inference, Training CPU (Snapdragon 400 805), GPU (Mali-400) conv, fc, relu [14] Layer MACs, memory accesses Inference ASIC (Eyeriss) [14] conv, fc [149] Layer, Network Layer parameters Inference CPU (Cortex A-series), GPU (Mali-G series Adreno 610) conv, fc, relu, bn Future work in EA-NAS should involve the development of energy-estimation methods that can accurately predict DNN energy consumption based solely on architectural features (ùëñ.ùëí., without requiring execution). The development of hardware-agnostic techniques capable of optimizing DNNs for various hardware platforms and profiles with minimal re-training is also essential, as well as efficient hardware-profiling methods to enable the scalable deployment of HW-NAS. This introduces a cross-domain learning problem, involving the prediction of absolute DNN energy consumption across hardware platforms; it prompts the development of a domain-invariant means of profiling DNNs, such as ASTs [47]. 2.3 Predicting Inference Energy The accurate hardware-agnostic prediction of DNN energy consumption is key in guiding the design of energy- efficient DNNs. There exist numerous works in this area, but no universally applicable method. The bulk of methods employ regression-based approaches, trained on hardware-specific benchmark DNN or layer-wise energy measurements, and utilize features such as MACs, FLOPs, and layer configurations as input. However, these approaches are constrained by the DNN operations they support, and their performance is currently extremely platform-dependent. Future work should prioritize the refinement of cross-platform estimation techniques, and the optimization of energy measurement pipelines [154]. Table 2 provides an overview of the various existing methods, including their hardware evaluation platforms and supported DNN operations. Tu et. al s [149] prediction method is currently SOTA in terms of generalization performance on unseen networks and edge devices, using a RF regression model built on kernel-level measurements on various mobile Cortex A-series CPUs and Mali G-series GPUs. SyNergy [117] and DeepWear [171] are the only other methods built for constrained edge devices, evaluated on the Nvidia Jetson TX1 and Cortex A-series CPUs, as well as the Mali-400 mobile GPU. 3 Energy-Adaptive Inference Realizing EA inference entails an inference-time trade-off between loss accuracy and energy consumption. Numerous approaches optimize DNN inference by utilizing lightweight architectures and static optimizations. However, these static optimizations, covered in 2.1, lack inference-time dynamicity. Hence, there s a need for adaptive inference techniques that can adjust energy consumption dynamically based on variations in energy- availability, workload, and input complexity. The latter is motivated by the recognition that if inputs are not all equally hard, a non-adaptive network incurs unnecessary processing for easy inputs or suffers performance loss for difficult ones [55, 106, 107, 110, 142]. Here, we discuss techniques for enabling EA inference, broadly categorized into DNN right-sizing, multi-exit, and inference offloading. 6 Millar et al. 3.1 DNN Right-Sizing Lighter networks can often handle the bulk of input instances nearly as well as the optimally-trained full network. Thus, cascaded networks of increasing complexity can be sequentially executed for efficient resource utilization with negligible accuracy loss. By overlapping the parameters of cascaded DNNs, recent works have harnessed the versatility inherent in employing multiple networks of increasing capacity with the memory-footprint of a single network; such parameter-sharing approaches are collectively known as DNN right-sizing. Notable right-sizing approaches include input-dependent layer-wise pruning [84, 142], DNN modularization and inference-time module selection [105], and input-dependent quantization [106]. The latter re-configures DNN precision based on input difficulty, unlike traditional static quantization which sets the bit-width uniformly across the entire network or different network subsets. This prevents accuracy loss for difficult inputs that cannot be handled at low precision whilst reducing energy consumption for the bulk of inputs that can be accurately processed with a less conservative quantization. Additionally, input-dependent quantization does not require entire network re-training in order to maintain the base non-quantized accuracy at varying precision levels. It can be universally applied to any pre-trained CNN. Feature boosting and suppression [30], which predictively boosts layer channels at runtime and suppresses those deemed unimportant, is another universally applicable channel-based approach. DeLight [118] employs input-adaptive pre-processing by projecting input data to an ensemble of lower-dimensional subspaces based on their context and energy resource-constraints. HydraNets [128] consist of variable execution branches specialized towards extracting features of different input classes. They utilize a gating mechanism to choose the appropriate execution branches for a given in- put and ensemble techniques to aggregate branch outputs to produce a final inference. The various network branches are trained jointly for better accuracy. This joint training is enabled by independent batch-normalization (BN) of feature means and variances, which prevents feature aggregation inconsistency across the different branches widths [181]. Given that BN layers typically constitute less than 1 of network parameters, this incurs negligible extra computational memory overhead. Daghero et. al [17] extends HydraNets for energy-adaptive inference by decomposing a network into branches of varying complexity, assigning difficulty levels" to inputs, and processing them with the corresponding combination of network branches. HydraNets, alongside the other works detailed in this section, focus on CNNs. There exist non-energy-focused works on RNNs, utilizing dynamic entropy-based beam-width1 (BW) modification for adaptive inference [54, 56]. Recent works have also demonstrated adaptive inference on transformer-based DNNs, including cascaded transformers with increasing numbers of patches [160], and input-based patch, block, and head selection [100]; however, these are not generally applicable to constrained devices, and none directly considers energy as a metric. 3.2 Multi-Exit Networks Proliferation in DNN complexity is helpful only when classifying difficult inputs, which are inherently rare. The features learned at earlier network layers are often sufficient for accurately classifying the vast majority of the data population [28, 143, 159]. Multi-exit networks offer a form of adaptive right-sizing where inputs can exit the network at intermediate layers, bypassing the unnecessary processing of subsequent layers. Such networks obviate the need for re-execution in the case of a failed inference and can be combined with fixed optimizations. The design of a multi-exit network includes the addition of side-branch exit heads to a backbone network; Fig. 1 below outlines a conventional DNN alongside a multi-exit variant of the same architecture. With trivial modifications, any DNN can be made an implicit ensemble of networks by adding exit layers. The exit-point(s) of a multi-exit network can be determined either pre-execution (subnet-based inference [143]) or at inference time (progressive inference [7]). The former allows for more reliable estimation of inference energy requirements, enabling dynamic voltage and frequency scaling (DVFS). However, inference always continues until the selected 1BW refers to the number of candidate sequences evaluated at each step. Energy-Aware Deep Learning on Resource-Constrained Hardware 7 exit layer, potentially resulting in wasted energy for easy inputs and or overthinking [63]. Instead, with progressive inference, the exit-point is determined during network execution, typically based on the uncertainty of the exit classification or following an energy-management policy. This can reduce energy consumption via dynamic adaptation to input complexity, but necessitates more intricate hardware-level adjustments to do so. 3.2.1 Multi-Exit Design Introducing exit layers to pre-trained backbone DNNs provides versatility when choosing the backbone design, as well as the case-driven optimization of exit layers [108]. However, more recent works have explored generalised structures [16, 26, 49, 63, 73, 144] and the co-design of end-to-end multi-exit networks [50]. By co-designing and jointly training the backbone NN and exit layers, there comes greater flexibility in optimization and the opportunity for improved performance at the cost of restricted task adaptability. Input Output a). Standard DNN Inference Input Output Output Output b). Early-Exit Inference Deterministic Conditional Fig. 1. Conventional DNN architecture alongside an EE variant. The dashed lines indicate conditional execution paths. Another design decision is the granularity and positioning of exit layers. Coarse-grained exits reduce overheads, but can miss exit opportunities. Conversely, fine-grained exits increase overheads, leading to heightened energy requirements and increased parameters. The extent of these overheads depends on the depth of the exit-layer(s), the network architecture, the use-case, and the exit policy. Zero Time Waste (ZTW) [165] addresses the overheads associated with failed exits, at the expense of (marginally) increased energy consumption and memory-footprint, by adding direct connections between exit-layers and recycling their outputs in an ensemble-like manner. Additionally, fine-grained exits can negatively impact convergence when jointly training the backbone NN and exit layers. PredictiveExit [81] uses a low-cost prediction engine to forecast where an input instance will exit the network, reducing the energy overheads of fine-grained exits by skipping the execution of pre-placed exit layers. This enables runtime configuration adjustment based on DVFS for energy-saving during inference. NAS approaches have recently been extended to the co-optimized design of multi-exit DNNs to meet energy, computation, and or memory constraints. HarvNAS [57] configures multi-exit network architectures for battery- less devices by jointly optimizing the backbone network, exit layers, and inference policy subject to energy and memory constraints. However, the addition of exit layers increases the already vast design space with placement configurations. 2 covers EA architecture design and NAS methods in more detail. Recent works have explored multi-exits for compute-intensive Transformer architectures [12, 169, 170], but largely overlook energy consumption as a metric, whilst other architectures are mostly unexplored. 3.2.2 Deployment of Multi-Exit Networks Initial multi-exit works such as CDL [108] utilize exit policies based on static thresholds, quantifying the network s inference confidence using metrics like top-1 prediction score [7], 8 Millar et al. Teacher (Cloud) Student (Mobile) Input Output Output Output Output Self-Distillation Loss L(y‚ÇÅ, y) L(y‚ÇÇ, y) L(y‚ÇÉ, y) Œª R(Œ∏) Fig. 2. Multi-exit last-layer distillation training, with a backbone network trained in the cloud and its exits trained on-device. prediction entropy [143], and score margin (SM), the margin between the 1ùë†ùë°and 2ùëõùëëinference output scores [108, 110]. However, imposing a global threshold on network outputs corresponds to implicitly assuming all classes are equally difficult to process. In scenarios for which this assumption does not hold, class-dependent thresholds become necessary [16] ( 3.3). Rule-based policies enable the consideration of more nuanced energy-aware objectives, such as maximizing throughput given an energy budget [58]. Zygarde [52] is a scheduler for multi-exit inference tasks on energy- harvesting devices, constrained by the need for immediate task execution alongside varying energy-availability. Reinforcement learning (RL) has also been used to generate policies that additionally consider historical device operation and the longer-term effects of scheduling decisions. HarvSched, a RL based exit policy scheduler for energy-harvesting devices, learns its policy considering both instantaneous factors (ùëñ.ùëí., harvesting status and energy-storage level) alongside device operational history [57]. HarvSched demonstrates superior accuracy plus fewer missed events than Zygarde when evaluated in a test scenario (randomly-triggered events on an Arduino Uno equipped with MSP430-based solar harvester, 0.47F capacity supercapacitor, and TI PMIC). The on-device training of exit-layers requires efficient fine-tuning approaches, covered in 4. 3.3 Energy-Adaptive Inference Policies Effective DNN right-sizing requires an adaptive inference policy that decides on the optimal network configuration for each inference. Such binary policies are inherently non-differentiable. Consequently, most utilize RL, typically using either REINFORCE [164] or Q-learning [161]; the latter is particularly well-suited to resource-constrained devices, as inference involves a table-based look-up. However, RL necessitates pre-deployment, or cumbersome trial-and-error learning when pre-deployment isn t feasible. Recent works are beginning to introduce non-RL approaches; these include approximating the gradients of non-differentiable policy functions with continuous ones [48], employing gated mixture-of-experts approaches [129] (which utilize noisy-ranking on the gating networks), or training policy networks [167]. These policies also necessitate a means of evaluating inference uncertainty. The works detailed above all use SM as proxy [110], with the rationale being that the margin between the 1ùë†ùë°and 2ùëõùëëinference output scores, in a classification task, is proportional to the likelihood of correct top-1 inference. However, imposing a global threshold on network outputs corresponds to implicitly assuming all inputs are equally difficult to process. In scenarios where this assumption does not hold, class-dependent thresholds become necessary; Daghero et. al Energy-Aware Deep Learning on Resource-Constrained Hardware 9 [16] defines these as follows: ùë°‚Ñéùëê argminùë°‚Ñéùëê(ùêπùëÉùëê(ùë°‚Ñéùëê) ùõº ùê∏ùëê(ùë°‚Ñéùëê)) (1) where ùë°‚Ñéùëêdenotes the threshold for class ùëêand ùêπùëÉùëê(ùë°‚Ñéùëê) the false positive rate. ùê∏ùëê(ùë°‚Ñéùëê) is a measure proportional to the energy consumption associated with processing an input of class ùê∂, quantified by the weighted number of invocations of the various cascade DNNs. Additionally, they propose a method for updating these class-dependent thresholds at runtime. Beyond multi-exit networks, energy-based thresholding is not largely applied. This is where DNN energy consumption is profiled across various network configurations (ùëñ.ùëí., branches, modules, bit-widths), and the network is adapted accordingly based on current forecasted energy-availability. This is particularly relevant for energy-harvesting devices, where energy-availability fluctuates. 5.1 covers general DL techniques for intermittent and energy-harvesting devices in detail. 3.4 Inference Offloading While data transmission is energy-expensive, device- and cloud-only approaches are typically not optimal in terms of inference energy consumption and latency [25]. Given sufficient energy-availability and task deadline, and a relatively stable connection, offloading inference from device to a cloud server may be advantageous, as a larger-capacity network can handle full or partial inference. Typical inference offloading methods involve layer-wise DNN partitioning. Fig. 3 provides an illustration of this. The optimal partitioning of a DNN is dependent on its layer topology, the inference task, the connection bandwidth, and the energy profile of the target device. Neurosurgeon [61] profiles the edge-device and cloud- server to generate energy latency-cost estimations for the execution of different DNN layer types. Using these estimations, and other relevant device factors (ùëí.ùëî., the current bandwidth), Neurosurgeon partitions DNN computation between device and cloud-server to optimize for energy consumption and end-to-end latency. EEoC [124] computes the partitioning using real measurements, instead of estimations, of the costs of DNN layer execution and layer output transmission on the target device. JointDNN [25] uses ILP to find the optimal partitioning layer, with respect to energy-availability, bandwidth saturation congestion, and quality-of-service. It also evaluates the benefit of compressing DNN layer outputs to reduce transmission energy costs. Boomerang [185] minimizes the overall energy cost of inference by evaluating the trade-off between on-device latency and energy cost versus the transmission energy cost for partitioning multi-exit networks. Alternatively, depth-wise partitioning methods vertically partition (convolutional) layers to reduce memory footprint whilst enhancing parallelism in communication and task offloading [190]. However, vertical tile-based partitioning, unlike depth-wise layer partitioning methods, can result in increased communication overheads and dependencies as it requires compiling results from adjacent partitions. Khoshsirat et al. [64] explore dynamically partitioning inference between containers on the same device to reduce energy consumption, and provide insights on how to optimally allocate inference tasks into these containers from an energy standpoint. Their approach is evaluated on Nvidia Jetson TX2 and AGX Orin edge devices and demonstrates energy-savings. However, it is only applicable if inference can be partitioned into independent tasks; a future direction should be to investigate container-wise partitioning of dependent tasks. Additionally, the effectiveness of such partitioning diminishes as devices become increasingly resource-constrained. Inference offloading is particularly suitable for wearable devices (ùëí.ùëî., smart watches) as they are typically paired with a mobile device. The communication between the wearable and offloading devices can be efficiently realized by short-range radio (ùëí.ùëî., BLE). DeepWear [171] enables the context-aware partial offloading of CNN and RNN inference from wearables to their paired mobile devices via local BLE connectivity. This involves minimizing the weighted energy consumption of all feasible DNN partitions. DeepWear has been successfully applied to COTS wearables, including the LG Urbane smartwatch, and mobile devices such as the Google Nexus 6. 10 Millar et al. Additionally, offloading has been extended to battery-less energy-harvesting devices; Sabovic et. al [121] demonstrate its use for the application of person detection on an Arduino Nano (with 1.5F supercapacitor, AEM10941 solar harvester and PMIC, and BLE for wireless communication). Their device estimates the latencies of device-only and cloud inference (no support for DNN partitioning) and decides to offload based on the task- deadline and current harvesting status. Future work could explore learning-based offloading approaches that consider historical device operation and energy-availability. Input Output Device Server Fig. 3. DNN partitioning between device and server. 4 On-Device Training The above sections generally focus on optimizing on-device inference with an offline-trained network. However once deployed, data- or context-shifts can result in degraded network performance in the target environment [135]. This issue is especially relevant for in-the-wild sensing applications, where environmental conditions can be highly variable and result in distortion (ùëí.ùëî., fog, snow, rain) and or degradation (ùëí.ùëî., defocus). Additionally, a deployed classifier may need to include new classes or reduce its existing class set to optimize its performance in the target environment. While not energy-aware, methods that contribute to enhancing the out-of-distribution (OOD) generalizability of pre-trained networks are key for IoT deployments. These include causality- [95, 130, 131], gradient operation- [97, 101, 134], and learning-based methods (ùëí.ùëî. zero-shot, meta, and representation learning) [6, 23, 79, 109, 158]. However, explicit fine-tuning commonly outperforms generalization in mitigating data context shifts in real-world evaluations [2, 69, 123, 163, 168]. Typically, DNNs are fine-tuned in the cloud, as gradient backpropagation is energy-expensive and prohibitively memory-intensive on resource-constrained devices (due to limited SRAM). However, this massively increases the communication overheads of the IoT device, increasing bandwidth requirements, and is not viable for ultra- low-power devices or those deployed in remote environments. Hence, there is substantial recent work towards optimizing DNN fine-tuning requirements, using unsupervised and self-supervised methods, to meet the energy budgets of constrained devices. MiniLearn [111] enables IoT devices to fine-tune and optimize pre-trained integer quantized networks using intermediate compressed outputs of quantized layers. It fine-tunes dequantized hidden (convolutional and FC) layers while keeping the rest of the pre-trained network in its quantized integer precision, reducing energy- usage without compromising performance. However, MiniLearn operates in the constrained context where network performance is optimized by reducing its class set and relies on labelled target data. LifeLearner [70] is a rehearsal-based meta continual-learning (CL) approach that is optimized for data-scarcity and energy- efficiency to enable realistic on-device CL (demonstrated on a STM32H747 MCU). Typical CL approaches require full-network backpropagation, and sufficient representative data to be kept on-device for meta-testing. These requirements are not viable in a constrained on-device scenario. Similar to MiniLearn, LifeLearner introduces a new rehearsal strategy, in which rehearsals are extracted as compressed outputs of intermediate network layers. By optimizing the intermediate rehearsal layer for maximum compression, LifeLearner reduces the computational- and energy-costs of fine-tuning. Additionally, LifeLearner utilizes bitmap compression and product-quantization of rehearsal-layer outputs to reduce memory-footprint. Energy-Aware Deep Learning on Resource-Constrained Hardware 11 Decreasing the number of fine-tuning parameters reduces its energy-expense [24, 89, 119] and can improve performance by reducing overfitting [36, 66, 74, 114]. Hence, recent works have also explored quantifying the contributions of network layers parameters towards counteracting data shifts. NEq [8] reduces fine-tuning energy consumption by iteratively determining the weights to fine-tune. It computes the cosine-similarity between weights at epochs t and t-1, and uses this difference to quantify their relative velocity". Then, NEq selects to fine-tune weights not in equilibrium, where equilibrium can be defined as: ùë£ùë° ùëñ ùúñ, ùúñ 0 (2) Here, ùë£ùë° ùëñis the relative velocity of parameter ùëñat epoch ùë°and ùõΩis an arbitrary threshold. Qu√©lennec et. al [112] replaces the NEq threshold with a fine-tuning energy budget ùêµùë§, and greedily selects the ùëõhighest velocity weights that can fit within the defined budget. However, efficiently determining which layers parameters to fine- tune is an ongoing challenge [76]. NEq, and other gradient-based selection methods [76], require a full-network backpropagation to compute the initial parameter velocities (which mightn t be viable on extremely energy- or memory-constrained devices), alongside fine-grained estimates of parameter-wise energy consumption. The NEq method applied layer-wise could support better estimates, and the layer-wise velocity can be initially approximated by random-sampling of intra-layer neurons. Recent works utilize multi-exit networks to support efficient personalization by fine-tuning exit layers whilst maintaining the network backbone [77]. Typically, this is done using a self-supervised knowledge distillation approach (see Fig 2) in which labels are generated by the output of the last exit. However, Fawden et. al [27] analyze per-exit performance, demonstrating that it is not valid to assume the last exit is always the most accurate. They instead recommend selecting input instances on which to fine-tune based on their predictive uncertainty. Additionally, they interpret exits as an ensemble of networks with a joint loss. 5 Applications 5.1 DL on Energy-Harvesting Devices The utilization of DL on battery-less devices, which harvest energy from environmental sources (ùëí.ùëî. solar, vibration, RF), has garnered recent interest. These devices offer numerous advantages over their battery-powered counterparts. They are largely maintenance-free and easy-to-recycle, promoting sustainability and suitability for large-scale deployments in hard-to-reach environments. Additionally, capacitors are more resistant to degradation than batteries, prolonging the lifetime of these devices to potentially decades. Given that data transmission is more energy-expensive than performing local inference, and that battery-less devices operate on extremely low energy-budgets, their deployment is impractical without on-device inference and task-scheduling. However, battery-less devices operate intermittently as energy is sporadically available, with recurring power failures that result in on-off behaviour. This presents challenges in efficiently guaranteeing inference correctness in the event of power failure, alongside reducing its likelihood via task-scheduling based on fluctuating energy-availability. Despite being a relatively new area of interest, there are numerous works demonstrating the real-world feasibility of DL on energy-harvesting devices. These include CNN-based facial recognition on solar-powered devices [32, 59], a capacitance-based gesture recognition wearable [147], and DL-driven bioacoustics monitoring in underwater environments using harvested acoustic energy [188]. 5.1.1 Intermittence-Safe Inference Battery-less devices accumulate charge using harvested energy until voltage Von is reached; the device then powers on and operates until charge depletes to Voff. This cycle repeats periodically or aperiodically. Von is typically set pre-deployment. Future work could explore adjusting capacitor capacity at runtime using a policy-based or RL approach to match energy fluctuations and workload. During intermittent execution, power failures reset volatile memory, hampering computational progress, and can lead to non-volatile memory inconsistencies (ùëí.ùëî., partial variable updates can occur because of an 12 Millar et al. interrupted partial execution and lead to incorrect results in the subsequent re-execution). Numerous methods exist for guaranteeing correct execution on intermittent systems, ranging from using periodic checkpoints to store intermediate states [45, 153], non-volatile processors that maintain state across power cycles [92, 93] and methods based on executing atomic tasks [15, 44]. However, these methods introduce computational (and therefore energy) overheads, especially those dealing with non-volatile processing [96]. This is problematic for computation-heavy DNN inference training. SONIC [33] is an intermittence-safe task-based API designed explicitly for DNN inference, aiming to exploit its regularity to minimize overheads. SONIC "breaks the rules" of conventional task-based programming paradigms by allowing the persistence of non-volatile memory across loop iterations. However, a combination of loop-ordered buffering and sparse-undo logging ensures that loop iterations are idempotent, guaranteeing safe resumption of interrupted tasks. Additionally, loop continuation eliminates wasted computation in the event of power failure. SONIC also presents the first demonstration of DNN inference on a constrained energy-harvesting system, using the COTS MSP430 MCU with a RF-energy harvester. 5.1.2 Inference Scheduling While SONIC and other intermittence-safe frameworks guarantee correct inference in the event of a power failure, they do not aid in reducing downtime. DL on energy-harvesting platforms also requires energy-reactive inference strategies and inference task-scheduling, given cyclical fluctuating energy-availability. Existing inference strategies largely focus on multi-exit networks. ePerceptive, a notable energy-reactive inference framework, built on SONIC, outputs lower-fidelity inferences at intermediate layers in response to energy fluctuations whilst guaranteeing valid inferences in the case of power failure [104]. ePerceptive also dynamically adjusts input resolution(s) to optimize performance under energy constraints. General task-scheduling for computing on energy-harvesting devices is well-studied [19, 62, 122, 137, 172]. ACES [29], for example, uses RL to optimise the duty cycles of battery-less nodes in order to maximise utility and increase node lifetime, under fluctuating energy-availability. DL inference schedulers can be generally categorized as rule- or RL-based. Zygarde[52], as discussed above, is an online rule-based scheduler for multi-exit networks that schedules exit-decisions based on an objective considering task-deadline, inference uncertainty and the current energy-harvesting status of the device. Zygarde partitions inference into mandatory and optional layers, and uses k-means to estimate inference uncertainty. The limitation of Zygarde and other non-trainable schedulers is that they fail to consider historical device operation. HarvSched, also discussed above ( 3.2.2), is a RL based scheduler that learns its scheduling policy based on current factors (ùëí.ùëî., energy-storage level) and device operational history [57]. This facilitates adaptive scheduling decisions based on evolving conditions. However, RL-based schedulers need pre-deployment in order to learn their policies, or cumbersome trial-and-error learning when pre-deployment isn t feasible. The methods discussed above enable on-device inference using an offline-trained network. However, on- device training fine-tuning is also necessary for counteracting real-world data- and context-shifts. Given that backpropagation is computationally more expensive than inference, fine-tuning only on non-redundant inputs is important; blindly selecting inputs on which to fine-tune can result in wasted energy if the inputs do not contribute towards improving DNN performance. Lee et. al [75] assess input relevance with a combination of three metrics, based on input uncertainty, diversity, and representation, to demonstrate unsupervised self- supervised learning on intermittently-powered COTS MCUs (AVR, PIC, MSP-430). 4 covers on-device training and fine-tuning methods in more detail. 5.2 Energy-Aware Federated Learning Federated Learning (FL) is a decentralized ML approach wherein DNNs are trained collaboratively across devices whilst keeping their raw data localized. This is realized via communicating weight updates to base servers that coordinate to aggregate a global network. FL offers scalability in massively-distributed environments, which can span over a large number of devices. FedAvg, the most common FL approach, performs rounds of local training Energy-Aware Deep Learning on Resource-Constrained Hardware 13 on device subsets to accommodate their heterogeneous resource constraints and latencies. FedAvg has been demonstrated to guarantee convergence in various heterogeneous scenarios, including unbalanced and non-i.i.d distributions [80, 99, 127]. Luo et. al [91] demonstrates the effectiveness of FedAvg on mobile devices. The key to effective FL across heterogeneous resource-constrained devices is energy-aware scheduling. This involves a trade-off between computation- and communication energy-costs, which are dependent on local DNN efficiency, the number of participating devices, and the number of local iterations in each FL round. Most works on energy-aware FL focus on optimizing the energy costs of on-device network training and are largely based on static DNN optimizations. Q-FedUpdate [183] supports training with full integer quantization on energy-efficient mobile Digital Signal Processors (DSPs). These are found universally on mobile phones and most other IoT devices. Their use for DNN execution can yield 11.3x 4.0x reduction in energy usage over mobile CPU GPUs. Training is supported by maintaining a global full-precision (ùëñ.ùëí. FP32) network, which continuously accumlates network updates instead of having updates erased by quantization. Q-FedUpdate is integrated with efficient batch quantization as well as a pipelining-based approach to enable simultaneous CPU-based quantization and DSP training. The latter reduces computational overheads associated with repeated network quantization. Other works focus on reducing FL communication-energy costs; approaches include gradient quantization via SignSGD [191], gradient sparsification [37, 152, 162], and dynamic batch-sizing [87, 88, 133], as well as dynamically adjusting the number of local iterations between two global aggregation rounds [157]. In addition, energy-aware device scheduling can reduce communication costs. Sun et. al [138], for example, maximize the number of devices scheduled for gradient update at each iteration under an energy-constraint. Zeng et. al [186] use energy-efficient bandwidth allocation and scheduling to reduce the energy consumption of FL over wireless networks. Numerous recent works on energy-aware FL also concentrate on DNN partitioning to enable adaptivity towards heterogenous device energy budgets. Yang et. al [13] utilize layer-wise partitioning, partitioning local DNNs into shallow and deep-layers, with shallow layers updated more frequently in FL rounds as they capture more general features. Rong et al. [182] instead partition CNNs into subnetworks via width-wise partitioning, grouping filters into blocks and exchanging filter blocks among subnetworks periodically to ensure equal training across all devices while reducing training costs. Given the various participating devices, their energy-budgets, and their CNN partitions, a heuristic approach is used to optimize the allocation of subnetworks to devices. The devices are ranked by their communication latency, and subnetworks by their number of weights, and matched accordingly. A "resource configuration search" then determines the minimum communication latency fitting the energy-budget of each device, taking into account time constraints for FL round completion. Other recent approaches model the FL trade-off as a joint optimization problem to minimize energy-cost while ensuring convergence, considering the various heterogenous devices and their energy budgets. Tran et. al [146] formulate a joint-optimization problem based on the sum of computation and communication energy. However, their approach requires the synchronous upload of weights from all devices, which is unrealistic, and does not provide convergence guarantees. Luo et. al [91] jointly optimize the number of participating devices and local iterations to minimize energy cost. They propose a sampling-based control solution that realizes minimal overhead and provides convergence guarantees. Yang et. al [177] derive energy consumption models of different FL approaches based on their convergence rates, utilizing these to form a novel joint-optimization problem. FL on intermittent energy-harvesting devices poses unique challenges, as devices can only participate when they have sufficient energy available. Given the energy-generation of participating devices is non-uniform, device scheduling (ùëñ.ùëí., when to participate) becomes important. One approach is to let each device participate as soon as it can do so. However, Guler et. al [35] demonstrate that this approach can bias the global FL network towards devices with more frequent energy-availability, resulting in an overall loss in performance. Another approach is to wait until all devices have sufficient energy to participate in the FL round, then use conventional FL sampling. This mitigates bias but requires waiting on the device with the slowest energy generation, which can result in slow convergence. Guler et. al introduce a FL protocol, with convergence guarantees, in which devices decide 14 Millar et al. whether to participate in a given FL round via a stochastic process based on their energy profiles. This approach requires no communication between devices and is therefore scalable to large networks. However, it assumes knowledge of the energy-renewal cycles of the participating devices (ùëñ.ùëí., the number of FL rounds needed to generate enough energy to participate), necessitating pre-deployment (and cycles may vary over time). Future work should involve the development of energy-aware DNN optimizations that can adapt to device heterogeneity to maximize energy-savings (ùëí.ùëî., applying different quantization granularities based on the capabilities and energy-constraints of different participating devices [132]). 6 Hardware Trends Gaps While the reviewed approaches span a variety of hardware platforms, most focus on accessible mobile and edge devices. Few approaches directly target MCUs, despite representing highly constrained platforms, likely due to the difficulty of implementing DL on such resource-limited architectures. The vast majority of approaches instead target mobile CPUs GPUs, which is unsurprising given that these devices offer greater resource availability, making them more accessible for evaluation, yet still represent energy-constrained environments. Moreover, only a small number of approaches that do include evaluation on MCU hardware do so on non-hobbyist platforms [16, 52, 57, 70, 121]. Among the exceptions are those focusing on energy-harvesting, typically targeting extremely low-power off-grid systems. The STM32 and MSP430 families of MCU are most commonly evaluated. There is a particularly notable gap in energy-aware NAS approaches designed for or evaluated on heterogeneous MCU architectures. There are also limited evaluations on FPGAs ASICs [14, 21], but these platforms are generally associated with higher costs, more specialized use cases, and demand expertise for effective deployment. Offloading approaches generally transition tasks from mobile to edge cloud environments, moving computations from a mobile CPU GPU DSP to more powerful devices like the Nvidia Jetson. Table 3. Embedded DL frameworks and their supported platforms. Framework Supported Platforms Open-Source TFLite-Micro [34] ARM Cortex-M series, Xtensa (incl. ESP32), RISC-V EdgeML [102] ARM Cortex-M, AVR RISC ùúáTensor [151] ARM Cortex-M ùúáTVM [3] ARM Cortex-M CMSIS-NN [4] ARM Cortex-M STM32CubeMX [136] ARM Cortex-M (STM32 series) TAILS SONIC [33] TI MSP430 Broader platform and DNN-operation support, and improved compilation pipelines, of lightweight ML frame- works are essential for advancing MCU-based hardware evaluation; Table 3 summarizes current DL frameworks for MCUs and their supported platforms. 7 Future Work and Directions Having provided an outline of the evolving energy-aware ML landscape, we identify a number of overarching directions for future work in this rapidly evolving field: Cross-Platform Energy Estimation Current EA approaches struggle to generalize across hardware platforms and network architectures, with their fundamental limitation being the accuracy of estimating the parameter layer- wise energy consumption of a DNN, on a piece of hardware, without executing it. Similarly, finding universal Energy-Aware Deep Learning on Resource-Constrained Hardware 15 correlations is incredibly challenging given the heterogeneity of hardware platforms, and the impact of their variations (ùëí.ùëî., memory access hierarchy, loop nesting, and data flow) on DNN energy consumption. Future work should prioritize the development of universal, execution-free energy estimation approaches, leveraging architectural representations of DNNs to enable improved generalisation and cross-network device invariance. For example, abstract syntax trees (ASTs), as used in CDMPP [47], offer a promising path for encoding the hierarchical layout of DNNs in a hardware-agnostic manner. Going forward, extending such representations to incorporate energy-relevant metadata could enable fine-grained, cross-platform energy optimizations. Automated Energy Profiling There remains a clear need for low-cost, hardware-agnostic methods that can generate reliable power and energy profiles at scale. Currently, the scalability and cross-device validity of energy prediction methods relies on profiling a large number of heterogeneous platforms and DNN operators; this necessitates community collaboration in building a holistic energy benchmarking dataset. However, the accuracy of built-in power monitors for mobile IoT profiling is insufficient, requiring the use of expensive external power monitors. As such, this also prompts the development of automated hardware-agnostic profiling methods for improving the efficiency of collecting device measurements at scale. Platform-Specific Optimizations In addition to generalization, energy-aware methods should also adapt to platform heterogeneity, accounting for both static hardware constraints and dynamic runtime conditions, such as energy availability or thermal limits, to maximize energy-savings. Future work should explore hierarchical, policy-based, or RL approaches for adapting DNN optimization granularity (e.g., adjusting quantization precision, modifying compute scheduling, or pruning subnetwork paths) based on task requirements, energy constraints, and runtime feedback. Such strategies become imperative when deploying a pre-trained network on a large number of heterogeneous devices (ùëí.ùëî., in a FL setting). Energy-Aware Training Methodologies While most attention has focused on inference-time energy optimization, energy-aware DNN training remains largely unexplored. Much opportunity exists for innovation; for instance, differentiable energy-aware regularizers could guide optimization toward architectures that are inherently more efficient across diverse hardware. Similarly, progressive training approaches that gradually increase NN complexity based on task difficulty could reduce unnecessary computation. Such work also includes developing ùúáNPU architectures capable of supporting low-power, on-chip accelerated backpropagation. Multi-Modal Inference Driven by hardware trends, such as increased on-chip memory bandwidth (e.g., SRAM or embedded DRAM) alongside tightly-coupled CPU NPU architectures, there are growing opportunities for dynamic, multi-modal inference strategies. Sparse mixture-of-experts (MoE) architectures are one such approach, where compact networks are stored and dynamically switched in and out or combined based on input context or energy budget. This allows efficient handling of diverse modalities (e.g., vision, audio) while enabling context- sensitive inference without compromising energy efficiency. Future work should investigate how MoE strategies can be optimized for energy-adaptivity on resource-constrained platforms. 8 Conclusion This work has outlined key directions in energy-aware DL, highlighting the interplay between NN efficiency and hardware constraints. While enormous progress has been made in energy-efficient NN design and deployment, major challenges remain particularly in accurate, hardware-agnostic energy estimation, adaptive optimization across diverse hardware, and scalable energy profiling with minimal overhead. Moving forward, addressing such challenges will require co-ordinated efforts spanning both hardware design and DL theory. We anticipate the continued emergence of specialized hardware accelerators, alongside developments in reduced data movement architectures, in-memory compute, and hardware-specific NN design, to push the boundaries of energy-efficient ML. We hope this survey acts as a useful foundation for further research at the intersection of DL and energy-constrained computing, guiding more informed and impactful designs across diverse and resource-constrained platforms. 16 Millar et al. References [1] Youssef Abadade, Anas Temouden, Hatim Bamoumen, Nabil Benamar, Yousra Chtouki, and Abdelhakim Senhaji Hafid. 2023. A Comprehensive Survey on TinyML. IEEE Access 11 (2023), 96892 96922. doi:10.1109 ACCESS.2023.3294111 [2] Anders Andreassen, Yasaman Bahri, Behnam Neyshabur, and Rebecca Roelofs. 2021. The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning. CoRR abs 2106.15831 (2021). arXiv:2106.15831 [3] Apache. 2024. MicroTVM. [4] ARM. 2024. CMSIS-NN. [5] Pedram Bakhtiarifard, Christian Igel, and Raghavendra Selvan. 2024. EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search. arXiv:2210.06015 [cs.LG] [6] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chellappa. 2018. MetaReg: Towards Domain Generalization using Meta- Regularization. In Advances in Neural Information Processing Systems, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa- Bianchi, and R. Garnett (Eds.), Vol. 31. Curran Associates, Inc. 647bba344396e7c8170902bcf2e15551-Paper.pdf [7] Konstantin Berestizshevsky and Guy Even. 2018. Sacrificing Accuracy for Reduced Computation: Cascaded Inference Based on Softmax Confidence. CoRR abs 1805.10982 (2018). arXiv:1805.10982 [8] Andrea Bragagnolo, Enzo Tartaglione, and Marco Grangetto. 2022. To update or not to update? Neurons at equilibrium in deep models. arXiv:2207.09455 [cs.LG] [9] Han Cai, Ji Lin, Yujun Lin, Zhijian Liu, Haotian Tang, Hanrui Wang, Ligeng Zhu, and Song Han. 2022. Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications. ACM Transactions on Design Automation of Electronic Systems 27, 3 (March 2022), 1 50. doi:10.1145 3486618 [10] Han Cai, Ligeng Zhu, and Song Han. 2018. ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware. CoRR abs 1812.00332 (2018). arXiv:1812.00332 [11] Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. 2016. Training Deep Nets with Sublinear Memory Cost. arXiv:1604.06174 [cs.LG] [12] Yanxi Chen, Xuchen Pan, Yaliang Li, Bolin Ding, and Jingren Zhou. 2024. EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language Models with 3D Parallelism. arXiv:2312.04916 [cs.LG] [13] Yang Chen, Xiaoyan Sun, and Yaochu Jin. 2020. Communication-Efficient Federated Deep Learning With Layerwise Asynchronous Model Update and Temporally Weighted Aggregation. IEEE Transactions on Neural Networks and Learning Systems 31, 10 (Oct. 2020), 4229 4238. doi:10.1109 tnnls.2019.2953131 [14] Yu-Hsin Chen, Joel Emer, and Vivienne Sze. 2016. Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks. In 2016 ACM IEEE 43rd Annual International Symposium on Computer Architecture (ISCA). 367 379. doi:10.1109 ISCA.2016.40 [15] Alexei Colin and Brandon Lucia. 2016. Chain: tasks and channels for reliable intermittent programs. In Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications (Amsterdam, Netherlands) (OOPSLA 2016). Association for Computing Machinery, New York, NY, USA, 514 530. doi:10.1145 2983990.2983995 [16] Francesco Daghero, Alessio Burrello, Daniele Jahier Pagliari, Luca Benini, Enrico Macii, and Massimo Poncino. 2020. Energy-Efficient Adaptive Machine Learning on IoT End-Nodes With Class-Dependent Confidence. In 2020 27th IEEE International Conference on Electronics, Circuits and Systems (ICECS). 1 4. doi:10.1109 ICECS49266.2020.9294863 [17] Francesco Daghero, Alessio Burrello, Chen Xie, Marco Castellano, Luca Gandolfi, Andrea Calimera, Enrico Macii, Massimo Poncino, and Daniele Jahier Pagliari. 2022. Human Activity Recognition on Microcontrollers with Quantized and Adaptive Deep Neural Networks. ACM Transactions on Embedded Computing Systems 21, 4 (July 2022), 1 28. doi:10.1145 3542819 [18] Xiaoliang Dai, Peizhao Zhang, Bichen Wu, Hongxu Yin, Fei Sun, Yanghan Wang, Marat Dukhan, Yunqing Hu, Yiming Wu, Yangqing Jia, Peter Vajda, Matt Uyttendaele, and Niraj K. Jha. 2019. ChamNet: Towards Efficient Network Design Through Platform-Aware Model Adaptation. In Proceedings of the IEEE CVF Conference on Computer Vision and Pattern Recognition (CVPR). [19] Carmen Delgado and Jeroen Famaey. 2022. Optimal Energy-Aware Task Scheduling for Batteryless IoT Devices. IEEE Transactions on Emerging Topics in Computing 10, 3 (2022), 1374 1387. doi:10.1109 TETC.2021.3086144 [20] Swarnava Dey, Arijit Mukherjee, Arpan Pal, and Balamuralidhar P. 2019. Embedded Deep Inference in Practice: Case for Model Partitioning. In Proceedings of the 1st Workshop on Machine Learning on Edge in Sensor Systems (New York, NY, USA) (SenSys-ML 2019). Association for Computing Machinery, New York, NY, USA, 25 30. doi:10.1145 3362743.3362964 [21] Dong Dong, Hongxu Jiang, Xuekai Wei, Yanfei Song, Xu Zhuang, and Jason Wang. 2023. ETNAS: An energy consumption task-driven neural architecture search. Sustainable Computing: Informatics and Systems 40 (2023), 100926. doi:10.1016 j.suscom.2023.100926 [22] Xuanyi Dong and Yi Yang. 2020. NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search. arXiv:2001.00326 [cs.CV] [23] Ying-Jun Du, Jun Xu, Huan Xiong, Qiang Qiu, Xiantong Zhen, Cees G. M. Snoek, and Ling Shao. 2020. Learning to Learn with Variational Information Bottleneck for Domain Generalization. CoRR abs 2007.07645 (2020). arXiv:2007.07645 Energy-Aware Deep Learning on Resource-Constrained Hardware 17 [24] Cian Eastwood, Ian Mason, and Christopher K. I. Williams. 2022. Unit-level surprise in neural networks. In Proceedings on "I (Still) Can t Believe It s Not Better!" at NeurIPS 2021 Workshops (Proceedings of Machine Learning Research, Vol. 163), Melanie F. Pradier, Aaron Schein, Stephanie Hyland, Francisco J. R. Ruiz, and Jessica Z. Forde (Eds.). PMLR, 33 40. [25] Amir Erfan Eshratifar, Mohammad Saeed Abrishami, and Massoud Pedram. 2018. JointDNN: An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services. CoRR abs 1801.08618 (2018). arXiv:1801.08618 [26] Biyi Fang, Xiao Zeng, Faen Zhang, Hui Xu, and Mi Zhang. 2020. FlexDNN: Input-Adaptive On-Device Deep Learning for Efficient Mobile Vision. In 2020 IEEE ACM Symposium on Edge Computing (SEC). 84 95. doi:10.1109 SEC50012.2020.00014 [27] Terry Fawden, Lorena Qendro, and Cecilia Mascolo. 2023. Uncertainty-Informed On-Device Personalisation Using Early Exit Networks on Sensor Signals. 2023 31st European Signal Processing Conference (EUSIPCO) (2023), 1305 1309. CorpusID:261116963 [28] Michael Figurnov, Maxwell D. Collins, Yukun Zhu, Li Zhang, Jonathan Huang, Dmitry P. Vetrov, and Ruslan Salakhutdinov. 2016. Spatially Adaptive Computation Time for Residual Networks. CoRR abs 1612.02297 (2016). arXiv:1612.02297 02297 [29] Francesco Fraternali, Bharathan Balaji, Yuvraj Agarwal, and Rajesh K. Gupta. 2020. ACES: Automatic Configuration of Energy Harvesting Sensors with Reinforcement Learning. ACM Transactions on Sensor Networks 16, 4 (July 2020), 1 31. doi:10.1145 3404191 [30] Xitong Gao, Yiren Zhao, Lukasz Dudziak, Robert D. Mullins, and Cheng-Zhong Xu. 2018. Dynamic Channel Pruning: Feature Boosting and Suppression. CoRR abs 1810.05331 (2018). arXiv:1810.05331 [31] In Gim and JeongGil Ko. 2022. Memory-efficient DNN training on mobile devices. In Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services (Portland, Oregon) (MobiSys 22). Association for Computing Machinery, New York, NY, USA, 464 476. doi:10.1145 3498361.3539765 [32] Marco Giordano, Philipp Mayer, and Michele Magno. 2020. A Battery-Free Long-Range Wireless Smart Camera for Face Detection. In Proceedings of the 8th International Workshop on Energy Harvesting and Energy-Neutral Sensing Systems (Virtual Event, Japan) (ENSsys 20). Association for Computing Machinery, New York, NY, USA, 29 35. doi:10.1145 3417308.3430273 [33] Graham Gobieski, Nathan Beckmann, and Brandon Lucia. 2018. Intelligence Beyond the Edge: Inference on Intermittent Embedded Systems. CoRR abs 1810.07751 (2018). arXiv:1810.07751 [34] Google. 2024. TFLite-Micro. [35] Basak Guler and Aylin Yener. 2021. Sustainable Federated Learning. CoRR abs 2102.11274 (2021). arXiv:2102.11274 abs 2102.11274 [36] Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing, and Rog√©rio Schmidt Feris. 2018. SpotTune: Transfer Learning through Adaptive Fine-tuning. CoRR abs 1811.08737 (2018). arXiv:1811.08737 [37] Pengchao Han, Shiqiang Wang, and Kin K. Leung. 2020. Adaptive Gradient Sparsification for Efficient Federated Learning: An Online Learning Approach. CoRR abs 2001.04756 (2020). arXiv:2001.04756 [38] Song Han, Huizi Mao, and William J. Dally. 2016. Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding. In 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings, Yoshua Bengio and Yann LeCun (Eds.). [39] Song Han, Huizi Mao, and William J. Dally. 2016. Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding. arXiv:1510.00149 [cs.CV] [40] Song Han, Jeff Pool, John Tran, and William J. Dally. 2015. Learning both Weights and Connections for Efficient Neural Networks. CoRR abs 1506.02626 (2015). arXiv:1506.02626 [41] Mohammad Hasan. 2022. State of IoT-Spring 2022. IOT Analytics, See com product state-of-iot-spring-2022 website (2022). [42] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual Learning for Image Recognition. CoRR abs 1512.03385 (2015). arXiv:1512.03385 [43] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual Learning for Image Recognition. arXiv:1512.03385 [cs.CV] [44] Josiah Hester, Kevin Storer, and Jacob Sorber. 2017. Timely Execution on Intermittently Powered Batteryless Sensors. 1 13. doi:10. 1145 3131672.3131673 [45] Matthew Hicks. 2017. Clank: Architectural support for intermittent computation. In 2017 ACM IEEE 44th Annual International Symposium on Computer Architecture (ISCA). 228 240. doi:10.1145 3079856.3080238 [46] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arXiv:1704.04861 [cs.CV] [47] Hanpeng Hu, Junwei Su, Juntao Zhao, Yanghua Peng, Yibo Zhu, Haibin Lin, and Chuan Wu. 2024. CDMPP: A Device-Model Agnostic Framework for Latency Prediction of Tensor Programs. In Proceedings of the Nineteenth European Conference on Computer Systems (EuroSys 24). ACM. doi:10.1145 3627703.3629572 [48] Weizhe Hua, Christopher De Sa, Zhiru Zhang, and G. Edward Suh. 2018. Channel Gating Neural Networks. CoRR abs 1805.12549 (2018). arXiv:1805.12549 18 Millar et al. [49] Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten, and Kilian Q. Weinberger. 2017. Multi-Scale Dense Convolutional Networks for Efficient Prediction. CoRR abs 1703.09844 (2017). arXiv:1703.09844 [50] Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten, and Kilian Q. Weinberger. 2017. Multi-Scale Dense Convolutional Networks for Efficient Prediction. CoRR abs 1703.09844 (2017). arXiv:1703.09844 [51] Forrest N. Iandola, Matthew W. Moskewicz, Khalid Ashraf, Song Han, William J. Dally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and 1MB model size. CoRR abs 1602.07360 (2016). arXiv:1602.07360 [52] Bashima Islam and Shahriar Nirjon. 2020. Zygarde: Time-Sensitive On-Device Deep Inference and Adaptation on Intermittently-Powered Systems. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 3, Article 82 (sep 2020), 29 pages. doi:10.1145 3411808 [53] Yesmina Jaafra, Jean Luc Laurent, Aline Deruyver, and Mohamed Saber Naceur. 2019. Reinforcement learning for neural architecture search: A review. Image and Vision Computing 89 (2019), 57 66. doi:10.1016 j.imavis.2019.06.005 [54] Daniele Jahier Pagliari, Francesco Daghero, and Massimo Poncino. 2020. Sequence-To-Sequence Neural Networks Inference on Embedded Processors Using Dynamic Beam Search. Electronics 9, 2 (2020). doi:10.3390 electronics9020337 [55] Daniele Jahier Pagliari, Francesco Panini, Enrico Macii, and Massimo Poncino. 2019. Dynamic Beam Width Tuning for Energy-Efficient Recurrent Neural Networks. In Proceedings of the 2019 on Great Lakes Symposium on VLSI (Tysons Corner, VA, USA) (GLSVLSI 19). Association for Computing Machinery, New York, NY, USA, 69 74. doi:10.1145 3299874.3317974 [56] Daniele Jahier Pagliari, Francesco Panini, Enrico Macii, and Massimo Poncino. 2019. Dynamic Beam Width Tuning for Energy-Efficient Recurrent Neural Networks. In Proceedings of the 2019 on Great Lakes Symposium on VLSI (Tysons Corner, VA, USA) (GLSVLSI 19). Association for Computing Machinery, New York, NY, USA, 69 74. doi:10.1145 3299874.3317974 [57] Seunghyeok Jeon, Yonghun Choi, Yeonwoo Cho, and Hojung Cha. 2023. HarvNet: Resource-Optimized Operation of Multi-Exit Deep Neural Networks on Energy Harvesting Devices. In Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services (Helsinki, Finland) (MobiSys 23). Association for Computing Machinery, New York, NY, USA, 42 55. doi:10. 1145 3581791.3596845 [58] Heinrich Jiang, Been Kim, Melody Y. Guan, and Maya Gupta. 2018. To Trust Or Not To Trust A Classifier. arXiv:1805.11783 [stat.ML] [59] Petar Jokic, Stephane Emery, and Luca Benini. 2021. Battery-Less Face Recognition at the Extreme Edge. In 2021 19th IEEE International New Circuits and Systems Conference (NEWCAS). 1 4. doi:10.1109 NEWCAS50681.2021.9462787 [60] Beomseok Kang, Anni Lu, Yun Long, Daehyun Kim, Shimeng Yu, and Saibal Mukhopadhyay. 2021. Genetic Algorithm-Based Energy- Aware CNN Quantization for Processing-In-Memory Architecture. IEEE Journal on Emerging and Selected Topics in Circuits and Systems 11, 4 (2021), 649 662. doi:10.1109 JETCAS.2021.3127129 [61] Yiping Kang, Johann Hauswald, Cao Gao, Austin Rovinski, Trevor Mudge, Jason Mars, and Lingjia Tang. 2017. Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge. SIGPLAN Not. 52, 4 (apr 2017), 615 629. doi:10.1145 3093336.3037698 [62] Mohsen Karimi, Hyunjong Choi, Yidi Wang, Yecheng Xiang, and Hyoseung Kim. 2021. Real-Time Task Scheduling on Intermittently Powered Batteryless Devices. IEEE Internet of Things Journal 8, 17 (2021), 13328 13342. doi:10.1109 JIOT.2021.3065947 [63] Yigitcan Kaya and Tudor Dumitras. 2018. How to Stop Off-the-Shelf Deep Neural Networks from Overthinking. CoRR abs 1810.07052 (2018). arXiv:1810.07052 [64] Aria Khoshsirat, Giovanni Perin, and Michele Rossi. 2023. Divide and Save: Splitting Workload Among Containers in an Edge Device to Save Energy and Time. arXiv:2302.06478 [cs.DC] [65] Donghyuk Kim, Chengshuo Yu, Shanshan Xie, Yuzong Chen, Joo-Young Kim, Bongjin Kim, Jaydeep P. Kulkarni, and Tony Tae-Hyoung Kim. 2022. An Overview of Processing-in-Memory Circuits for Artificial Intelligence and Machine Learning. IEEE Journal on Emerging and Selected Topics in Circuits and Systems 12, 2 (2022), 338 353. doi:10.1109 JETCAS.2022.3160455 [66] James Kirkpatrick, Razvan Pascanu, Neil C. Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. 2016. Overcoming catastrophic forgetting in neural networks. CoRR abs 1612.00796 (2016). arXiv:1612.00796 [67] Raghuraman Krishnamoorthi. 2018. Quantizing deep convolutional networks for efficient inference: A whitepaper. arXiv:1806.08342 [cs.LG] [68] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. ImageNet Classification with Deep Convolutional Neural Networks. In Advances in Neural Information Processing Systems, F. Pereira, C.J. Burges, L. Bottou, and K.Q. Weinberger (Eds.), Vol. 25. Curran Associates, Inc. [69] Ananya Kumar, Aditi Raghunathan, Robbie Jones, Tengyu Ma, and Percy Liang. 2022. Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution. arXiv:2202.10054 [cs.LG] [70] Young D. Kwon, Jagmohan Chauhan, Hong Jia, Stylianos I. Venieris, and Cecilia Mascolo. 2023. LifeLearner: Hardware-Aware Meta Continual Learning System for Embedded Computing Platforms. arXiv:2311.11420 [cs.LG] [71] Young D. Kwon, Rui Li, Stylianos I. Venieris, Jagmohan Chauhan, Nicholas D. Lane, and Cecilia Mascolo. 2023. TinyTrain: Deep Neural Network Training at the Extreme Edge. arXiv:2307.09988 [cs.LG] [72] Stefanos Laskaridis, Alexandros Kouris, and Nicholas D. Lane. 2021. Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions. In Proceedings of the 5th International Workshop on Embedded and Mobile Deep Learning (Virtual, WI, USA) Energy-Aware Deep Learning on Resource-Constrained Hardware 19 (EMDL 21). Association for Computing Machinery, New York, NY, USA, 1 6. doi:10.1145 3469116.3470012 [73] Stefanos Laskaridis, Stylianos I. Venieris, Hyeji Kim, and Nicholas D. Lane. 2020. HAPI: Hardware-Aware Progressive Inference. CoRR abs 2008.03997 (2020). arXiv:2008.03997 [74] Jaejun Lee, Raphael Tang, and Jimmy Lin. 2019. What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning. CoRR abs 1911.03090 (2019). arXiv:1911.03090 [75] Seulki Lee, Bashima Islam, Yubo Luo, and Shahriar Nirjon. 2020. Intermittent Learning: On-Device Machine Learning on Intermittently Powered System. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 3, 4, Article 141 (sep 2020), 30 pages. doi:10.1145 3369837 [76] Yoonho Lee, Annie S. Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao, Percy Liang, and Chelsea Finn. 2023. Surgical Fine-Tuning Improves Adaptation to Distribution Shifts. arXiv:2210.11466 [cs.LG] [77] Ilias Leontiadis, Stefanos Laskaridis, Stylianos I. Venieris, and Nicholas D. Lane. 2021. It s always personal: Using Early Exits for Efficient On-Device CNN Personalisation. CoRR abs 2102.01393 (2021). arXiv:2102.01393 [78] Chaojian Li, Zhongzhi Yu, Yonggan Fu, Yongan Zhang, Yang Zhao, Haoran You, Qixuan Yu, Yue Wang, and Yingyan Lin. 2021. HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark. CoRR abs 2103.10584 (2021). arXiv:2103.10584 https: arxiv.org abs 2103.10584 [79] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M. Hospedales. 2017. Learning to Generalize: Meta-Learning for Domain Generalization. arXiv:1710.03463 [cs.LG] [80] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. 2020. On the Convergence of FedAvg on Non-IID Data. arXiv:1907.02189 [stat.ML] [81] Xiangjie Li, Chenfei Lou, Zhengping Zhu, Yuchi Chen, Yingtao Shen, Yehan Ma, and An Zou. 2022. Predictive Exit: Prediction of Fine-Grained Early Exits for Computation- and Energy-Efficient Inference. arXiv:2206.04685 [cs.LG] [82] Edgar Liberis, Lukasz Dudziak, and Nicholas D. Lane. 2020. ùúáNAS: Constrained Neural Architecture Search for Microcontrollers. CoRR abs 2010.14246 (2020). arXiv:2010.14246 [83] Ji Lin, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, and Song Han. 2020. MCUNet: Tiny Deep Learning on IoT Devices. CoRR abs 2007.10319 (2020). arXiv:2007.10319 [84] Ji Lin, Yongming Rao, Jiwen Lu, and Jie Zhou. 2017. Runtime Neural Pruning. In Advances in Neural Information Processing Systems, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. [85] Ji Lin, Ligeng Zhu, Wei-Ming Chen, Wei-Chen Wang, Chuang Gan, and Song Han. 2024. On-Device Training Under 256KB Memory. arXiv:2206.15472 [cs.CV] [86] Qiang Liu, Lemeng Wu, and Dilin Wang. 2019. Splitting Steepest Descent for Growing Neural Architectures. CoRR abs 1910.02366 (2019). arXiv:1910.02366 [87] Weijie Liu, Xiaoxi Zhang, Jingpu Duan, Carlee Joe-Wong, Zhi Zhou, and Xu Chen. 2023. AdaCoOpt: Leverage the Interplay of Batch Size and Aggregation Frequency for Federated Learning. In 2023 IEEE ACM 31st International Symposium on Quality of Service (IWQoS). 1 10. doi:10.1109 IWQoS57198.2023.10188807 [88] Weijie Liu, Xiaoxi Zhang, Jingpu Duan, Carlee Joe-Wong, Zhi Zhou, and Xu Chen. 2023. DYNAMITE: Dynamic Interplay of Mini-Batch Size and Aggregation Frequency for Federated Learning with Static and Streaming Dataset. arXiv:2310.14906 [cs.LG] [89] Yuhan Liu, Saurabh Agarwal, and Shivaram Venkataraman. 2021. AutoFreeze: Automatically Freezing Model Blocks to Accelerate Fine-tuning. CoRR abs 2102.01386 (2021). arXiv:2102.01386 [90] Yuqiao Liu, Yanan Sun, Bing Xue, Mengjie Zhang, and Gary G. Yen. 2020. A Survey on Evolutionary Neural Architecture Search. CoRR abs 2008.10937 (2020). arXiv:2008.10937 [91] Bing Luo, Xiang Li, Shiqiang Wang, Jianwei Huang, and Leandros Tassiulas. 2020. Cost-Effective Federated Learning Design. CoRR abs 2012.08336 (2020). arXiv:2012.08336 [92] Kaisheng Ma, Xueqing Li, Jinyang Li, Yongpan Liu, Yuan Xie, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. 2017. Incidental Computing on IoT Nonvolatile Processors. In 2017 50th Annual IEEE ACM International Symposium on Microarchitecture (MICRO). 204 218. [93] Kaisheng Ma, Yang Zheng, Shuangchen Li, Karthik Swaminathan, Xueqing Li, Yongpan Liu, Jack Sampson, Yuan Xie, and Vijaykrishnan Narayanan. 2015. Architecture exploration for ambient energy harvesting nonvolatile processors. In 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA). 526 537. doi:10.1109 HPCA.2015.7056060 [94] Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun. 2018. ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design. arXiv:1807.11164 [cs.CV] [95] Divyat Mahajan, Shruti Tople, and Amit Sharma. 2020. Domain Generalization using Causal Matching. CoRR abs 2006.07500 (2020). arXiv:2006.07500 [96] Andrea Maioli and Luca Mottola. 2021. ALFRED: Virtual Memory for Intermittent Computing. In Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems (SenSys 21). ACM. doi:10.1145 3485730.3485949 20 Millar et al. [97] Lucas Mansilla, Rodrigo Echeveste, Diego H. Milone, and Enzo Ferrante. 2021. Domain Generalization via Gradient Surgery. CoRR abs 2108.01621 (2021). arXiv:2108.01621 [98] Alberto Marchisio, Andrea Massa, Vojtech Mrazek, Beatrice Bussolino, Maurizio Martina, and Muhammad Shafique. 2020. NASCaps: A Framework for Neural Architecture Search to Optimize the Accuracy and Hardware Efficiency of Convolutional Capsule Networks. CoRR abs 2008.08476 (2020). arXiv:2008.08476 [99] H. Brendan McMahan, Eider Moore, Daniel Ramage, and Blaise Ag√ºera y Arcas. 2016. Federated Learning of Deep Networks using Model Averaging. CoRR abs 1602.05629 (2016). arXiv:1602.05629 [100] Lingchen Meng, Hengduo Li, Bor-Chun Chen, Shiyi Lan, Zuxuan Wu, Yu-Gang Jiang, and Ser-Nam Lim. 2021. AdaViT: Adaptive Vision Transformers for Efficient Image Recognition. CoRR abs 2111.15668 (2021). arXiv:2111.15668 [101] Mateusz Michalkiewicz, Masoud Faraki, Xiang Yu, Manmohan Chandraker, and Mahsa Baktashmotlagh. 2023. Domain Generalization Guided by Gradient Signal to Noise Ratio of Parameters. arXiv:2310.07361 [cs.CV] [102] Microsoft. 2024. EdgeML. [103] David Moloney. 2016. Embedded deep neural networks: The cost of everything and the value of nothing . In 2016 IEEE Hot Chips 28 Symposium (HCS). 1 20. doi:10.1109 HOTCHIPS.2016.7936219 [104] Alessandro Montanari, Manuja Sharma, Dainius Jenkus, Mohammed Alloulah, Lorena Qendro, and Fahim Kawsar. 2020. ePerceptive: energy reactive embedded intelligence for batteryless sensors. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (Virtual Event, Japan) (SenSys 20). Association for Computing Machinery, New York, NY, USA, 382 394. doi:10.1145 3384419. 3430782 [105] Augustus Odena, Dieterich Lawson, and Christopher Olah. 2017. Changing Model Behavior at Test-Time Using Reinforcement Learning. arXiv:1702.07780 [stat.ML] [106] Daniele Jahier Pagliari, Enrico Macii, and Massimo Poncino. 2018. Dynamic Bit-width Reconfiguration for Energy-Efficient Deep Learning Hardware. In Proceedings of the International Symposium on Low Power Electronics and Design (Seattle, WA, USA) (ISLPED 18). Association for Computing Machinery, New York, NY, USA, Article 47, 6 pages. doi:10.1145 3218603.3218611 [107] Priyadarshini Panda, Abhronil Sengupta, and Kaushik Roy. 2015. Conditional Deep Learning for Energy-Efficient and Enhanced Pattern Recognition. CoRR abs 1509.08971 (2015). arXiv:1509.08971 [108] Priyadarshini Panda, Abhronil Sengupta, and Kaushik Roy. 2015. Conditional Deep Learning for Energy-Efficient and Enhanced Pattern Recognition. CoRR abs 1509.08971 (2015). arXiv:1509.08971 [109] Yanwei Pang, Haoran Wang, Yunlong Yu, and Zhong Ji. 2019. A decadal survey of zero-shot image classification. SCIENTIA SINICA Informationis (2019). [110] Eunhyeok Park, Dongyoung Kim, Soobeom Kim, Yong-Deok Kim, Gunhee Kim, Sungroh Yoon, and Sungjoo Yoo. 2015. Big little deep neural network for ultra low power inference. In 2015 International Conference on Hardware Software Codesign and System Synthesis (CODES ISSS). 124 132. doi:10.1109 CODESISSS.2015.7331375 [111] Christos Profentzas, Magnus Almgren, and Olaf Landsiedel. 2023. MiniLearn: On-Device Learning for Low-Power IoT Devices. In Proceedings of the 2022 International Conference on Embedded Wireless Systems and Networks (, Linz, Austria,) (EWSN 22). Association for Computing Machinery, New York, NY, USA, 1 11. [112] A√´l Qu√©lennec, Enzo Tartaglione, Pavlo Mozharovskyi, and Van-Tam Nguyen. 2023. Towards On-device Learning on the Edge: Ways to Select Neurons to Update under a Budget Constraint. arXiv:2312.05282 [cs.LG] [113] Jathushan Rajasegaran, Vinoj Jayasundara, Sandaru Jayasekara, Hirunima Jayasekara, Suranga Seneviratne, and Ranga Rodrigo. 2019. DeepCaps: Going Deeper with Capsule Networks. arXiv:1904.09546 [cs.CV] [114] Vinay V. Ramasesh, Ethan Dyer, and Maithra Raghu. 2020. Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics. CoRR abs 2007.07400 (2020). arXiv:2007.07400 [115] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016. XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks. arXiv:1603.05279 [cs.CV] [116] Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Xiaojiang Chen, and Xin Wang. 2020. A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions. CoRR abs 2006.02903 (2020). arXiv:2006.02903 [117] Crefeda Faviola Rodrigues, Graham Riley, and Mikel Lujan. 2018. Fine-Grained Energy and Performance Profiling framework for Deep Convolutional Neural Networks. arXiv:1803.11151 [cs.PF] [118] Bita Darvish Rouhani, Azalia Mirhoseini, and Farinaz Koushanfar. 2016. DeLight: Adding Energy Dimension To Deep Neural Networks. In Proceedings of the 2016 International Symposium on Low Power Electronics and Design (San Francisco Airport, CA, USA) (ISLPED 16). Association for Computing Machinery, New York, NY, USA, 112 117. doi:10.1145 2934583.2934599 [119] Amelie Royer and Christoph H. Lampert. 2020. A Flexible Selection Scheme for Minimum-Effort Transfer Learning. CoRR abs 2008.11995 (2020). arXiv:2008.11995 [120] Sara Sabour, Nicholas Frosst, and Geoffrey E. Hinton. 2017. Dynamic Routing Between Capsules. CoRR abs 1710.09829 (2017). arXiv:1710.09829 Energy-Aware Deep Learning on Resource-Constrained Hardware 21 [121] Adnan Sabovic, Michiel Aernouts, Dragan Subotic, Jaron Fontaine, Eli De Poorter, and Jeroen Famaey. 2023. Towards energy-aware tinyML on battery-less IoT devices. Internet of Things 22 (2023), 100736. doi:10.1016 j.iot.2023.100736 [122] Adnan Sabovic, Ashish Kumar Sultania, Carmen Delgado, Lander De Roeck, and Jeroen Famaey. 2022. An Energy-Aware Task Scheduler for Energy-Harvesting Batteryless IoT Devices. IEEE Internet of Things Journal 9, 22 (2022), 23097 23114. doi:10.1109 JIOT.2022.3185321 [123] Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry. 2020. Do Adversarially Robust ImageNet Models Transfer Better? CoRR abs 2007.08489 (2020). arXiv:2007.08489 [124] Eric Samikwa, Antonio Di Maio, and Torsten Braun. 2022. Adaptive Early Exit of Computation for Energy-Efficient and Low-Latency Machine Learning over IoT Networks. In 2022 IEEE 19th Annual Consumer Communications Networking Conference (CCNC). 200 206. doi:10.1109 CCNC49033.2022.9700550 [125] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2019. MobileNetV2: Inverted Residuals and Linear Bottlenecks. arXiv:1801.04381 [cs.CV] [126] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2019. MobileNetV2: Inverted Residuals and Linear Bottlenecks. arXiv:1801.04381 [cs.CV] [127] Felix Sattler, Simon Wiedemann, Klaus-Robert M√ºller, and Wojciech Samek. 2019. Robust and Communication-Efficient Federated Learning from Non-IID Data. CoRR abs 1903.02891 (2019). arXiv:1903.02891 [128] Noam Shazeer, Kayvon Fatahalian, William R. Mark, and Ravi Teja Mullapudi. 2018. HydraNets: Specialized Dynamic Architectures for Efficient Inference. In 2018 IEEE CVF Conference on Computer Vision and Pattern Recognition. 8080 8089. doi:10.1109 CVPR.2018.00843 [129] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geoffrey E. Hinton, and Jeff Dean. 2017. Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer. CoRR abs 1701.06538 (2017). arXiv:1701.06538 abs 1701.06538 [130] Paras Sheth and Huan Liu. 2023. Causal Domain Generalization. Springer International Publishing, Cham, 161 185. doi:10.1007 978-3- 031-35051-1_8 [131] Paras Sheth, Raha Moraffah, K. Sel√ßuk Candan, Adrienne Raglin, and Huan Liu. 2022. Domain Generalization A Causal Perspective. arXiv:2209.15177 [cs.LG] [132] Dian Shi, Liang Li, Rui Chen, Pavana Prakash, Miao Pan, and Yuguang Fang. 2022. Toward Energy-Efficient Federated Learning Over 5G Mobile Devices. IEEE Wireless Communications 29, 5 (2022), 44 51. doi:10.1109 MWC.003.2100028 [133] Dian Shi, Liang Li, Maoqiang Wu, Minglei Shu, Rong Yu, Miao Pan, and Zhu Han. 2022. To Talk or to Work: Dynamic Batch Sizes Assisted Time Efficient Federated Learning Over Future Mobile Edge Devices. IEEE Transactions on Wireless Communications 21, 12 (2022), 11038 11050. doi:10.1109 TWC.2022.3189320 [134] Yuge Shi, Jeffrey Seely, Philip H. S. Torr, N. Siddharth, Awni Y. Hannun, Nicolas Usunier, and Gabriel Synnaeve. 2021. Gradient Matching for Domain Generalization. CoRR abs 2104.09937 (2021). arXiv:2104.09937 [135] G. Spadaro, R. Renzulli, A. Bragagnolo, J. H. Giraldo, A. Fiandrotti, M. Grangetto, and E. Tartaglione. 2023. Shannon Strikes Again! Entropy-based Pruning in Deep Neural Networks for Transfer Learning under Extreme Memory and Computation Budgets. In 2023 IEEE CVF International Conference on Computer Vision Workshops (ICCVW). IEEE Computer Society, Los Alamitos, CA, USA, 1510 1514. doi:10.1109 ICCVW60793.2023.00165 [136] STMicroelectronics. 2024. STM32CubeMX. [137] Ashish Kumar Sultania and Jeroen Famaey. 2022. Batteryless Bluetooth Low Energy Prototype With Energy-Aware Bidirectional Communication Powered by Ambient Light. IEEE Sensors Journal 22, 7 (2022), 6685 6697. doi:10.1109 JSEN.2022.3153097 [138] Yuxuan Sun, Sheng Zhou, and Deniz G√ºnd√ºz. 2019. Energy-Aware Analog Aggregation for Federated Learning with Redundant Data. arXiv:1911.00188 [cs.IT] [139] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2014. Going Deeper with Convolutions. CoRR abs 1409.4842 (2014). arXiv:1409.4842 [140] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, and Quoc V. Le. 2018. MnasNet: Platform-Aware Neural Architecture Search for Mobile. CoRR abs 1807.11626 (2018). arXiv:1807.11626 [141] Mingxing Tan and Quoc V. Le. 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. CoRR abs 1905.11946 (2019). arXiv:1905.11946 [142] Hokchhay Tann, Soheil Hashemi, R. Iris Bahar, and Sherief Reda. 2016. Runtime Configurable Deep Neural Networks for Energy- Accuracy Trade-off. CoRR abs 1607.05418 (2016). arXiv:1607.05418 [143] Surat Teerapittayanon, Bradley McDanel, and H. T. Kung. 2017. BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks. CoRR abs 1709.01686 (2017). arXiv:1709.01686 [144] Surat Teerapittayanon, Bradley McDanel, and H. T. Kung. 2017. BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks. CoRR abs 1709.01686 (2017). arXiv:1709.01686 [145] Nazli Tekin, Ahmet Aris, Abbas Acar, Selcuk Uluagac, and Vehbi Cagri Gungor. 2024. A review of on-device machine learning for IoT: An energy perspective. Ad Hoc Networks 153 (2024), 103348. doi:10.1016 j.adhoc.2023.103348 22 Millar et al. [146] Nguyen H. Tran, Wei Bao, Albert Zomaya, Minh N. H. Nguyen, and Choong Seon Hong. 2019. Federated Learning over Wireless Networks: Optimization Model Design and Analysis. In IEEE INFOCOM 2019 - IEEE Conference on Computer Communications. 1387 1395. doi:10.1109 INFOCOM.2019.8737464 [147] Hoang Truong, Shuo Zhang, Ufuk Muncuk, Phuc Nguyen, Nam Bui, Anh Nguyen, Qin Lv, Kaushik Chowdhury, Thang Dinh, and Tam Vu. 2018. CapBand: Battery-free Successive Capacitance Sensing Wristband for Hand Gesture Recognition. In Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems (Shenzhen, China) (SenSys 18). Association for Computing Machinery, New York, NY, USA, 54 67. doi:10.1145 3274783.3274854 [148] Arya Tschand, Arun Tejusve Raghunath Rajan, Sachin Idgunji, Anirban Ghosh, Jeremy Holleman, Csaba Kiraly, Pawan Ambalkar, Ritika Borkar, Ramesh Chukka, Trevor Cockrell, Oliver Curtis, Grigori Fursin, Miro Hodak, Hiwot Kassa, Anton Lokhmotov, Dejan Miskovic, Yuechao Pan, Manu Prasad Manmathan, Liz Raymond, Tom St. John, Arjun Suresh, Rowan Taubitz, Sean Zhan, Scott Wasson, David Kanter, and Vijay Janapa Reddi. 2025. MLPerf Power: Benchmarking the Energy Efficiency of Machine Learning Systems from Microwatts to Megawatts for Sustainable AI. arXiv:2410.12032 [cs.AR] [149] X. Tu, A. Mallik, D. Chen, K. Han, O. Altintas, H. Wang, and J. Xie. 2023. Unveiling Energy Efficiency in Deep Learning: Measurement, Prediction, and Scoring Across Edge Devices. In 2023 IEEE ACM Symposium on Edge Computing (SEC). IEEE Computer Society, Los Alamitos, CA, USA, 80 93. doi:10.1145 3583740.3628442 [150] Ultralytics. 2021. YOLOv5: A state-of-the-art real-time object detection system. Accessed: insert date here. [151] uTensor. 2024. uTensor. [152] Shubham Vaishnav, Maria Efthymiou, and Sindri Magn√∫sson. 2023. Energy-Efficient and Adaptive Gradient Sparsification for Federated Learning. In ICC 2023 - IEEE International Conference on Communications. 1256 1261. doi:10.1109 ICC45041.2023.10278999 [153] Joel Van Der Woude and Matthew Hicks. 2016. Intermittent computation without hardware support or programmer intervention. In Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation (Savannah, GA, USA) (OSDI 16). USENIX Association, USA, 17 32. [154] Philipp van Kempen, Rafael Stahl, Daniel Mueller-Gritschneder, and Ulf Schlichtmann. 2023. MLonMCU: TinyML Benchmarking with Fast Retargeting. In Proceedings of the 2023 Workshop on Compilers, Deployment, and Tooling for Edge AI (CODAI 23). ACM. doi:10.1145 3615338.3618128 [155] Dilin Wang, Meng Li, Lemeng Wu, Vikas Chandra, and Qiang Liu. 2019. Energy-Aware Neural Architecture Optimization with Fast Splitting Steepest Descent. CoRR abs 1910.03103 (2019). arXiv:1910.03103 [156] Qipeng Wang, Mengwei Xu, Chao Jin, Xinran Dong, Jinliang Yuan, Xin Jin, Gang Huang, Yunxin Liu, and Xuanzhe Liu. 2022. Melon: breaking the memory wall for resource-efficient on-device machine learning. In Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services (Portland, Oregon) (MobiSys 22). Association for Computing Machinery, New York, NY, USA, 450 463. doi:10.1145 3498361.3538928 [157] Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung, Christian Makaya, Ting He, and Kevin Chan. 2019. Adaptive Federated Learning in Resource Constrained Edge Computing Systems. IEEE Journal on Selected Areas in Communications 37, 6 (2019), 1205 1221. doi:10.1109 JSAC.2019.2904348 [158] Wei Wang, Vincent W. Zheng, Han Yu, and Chunyan Miao. 2019. A Survey of Zero-Shot Learning: Settings, Methods, and Applications. ACM Trans. Intell. Syst. Technol. 10, 2, Article 13 (jan 2019), 37 pages. doi:10.1145 3293318 [159] Xin Wang, Fisher Yu, Zi-Yi Dou, and Joseph E. Gonzalez. 2017. SkipNet: Learning Dynamic Routing in Convolutional Networks. CoRR abs 1711.09485 (2017). arXiv:1711.09485 [160] Yulin Wang, Rui Huang, Shiji Song, Zeyi Huang, and Gao Huang. 2021. Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with Adaptive Sequence Length. CoRR abs 2105.15075 (2021). arXiv:2105.15075 [161] Christopher J. C. H. Watkins and Peter Dayan. 1992. Q-learning. Machine Learning 8, 3 (01 May 1992), 279 292. doi:10.1007 BF00992698 [162] Kang Wei, Jun Li, Chuan Ma, Ming Ding, Feng Shu, Haitao Zhao, Wen Chen, and Hongbo Zhu. 2024. Gradient sparsification for efficient wireless federated learning with differential privacy. Science China Information Sciences 67, 4 (March 2024). doi:10.1007 s11432-023- 3918-9 [163] Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre-Alvise Rebuffi, Ira Ktena, Krishnamurthy Dvijotham, and A. Taylan Cemgil. 2021. A Fine-Grained Analysis on Distribution Shift. CoRR abs 2110.11328 (2021). arXiv:2110.11328 [164] R. J. Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning 8 (1992), 229 256. [165] Maciej Wolczyk, Bartosz W√≥jcik, Klaudia Balazy, Igor T. Podolak, Jacek Tabor, Marek Smieja, and Tomasz Trzcinski. 2021. Zero Time Waste: Recycling Predictions in Early Exit Neural Networks. CoRR abs 2106.05409 (2021). arXiv:2106.05409 05409 [166] Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing Jia, and Kurt Keutzer. 2019. FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search. arXiv:1812.03443 [cs.CV] [167] Zuxuan Wu, Tushar Nagarajan, Abhishek Kumar, Steven Rennie, Larry S. Davis, Kristen Grauman, and Rogerio Feris. 2019. BlockDrop: Dynamic Inference Paths in Residual Networks. arXiv:1711.08393 [cs.CV] Energy-Aware Deep Learning on Resource-Constrained Hardware 23 [168] Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. 2020. In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness. CoRR abs 2012.04550 (2020). arXiv:2012.04550 https: arxiv.org abs 2012.04550 [169] Ji Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, and Jimmy Lin. 2020. DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference. CoRR abs 2004.12993 (2020). arXiv:2004.12993 [170] Ji Xin, Raphael Tang, Yaoliang Yu, and Jimmy J. Lin. 2021. BERxiT: Early Exiting for BERT with Better Fine-Tuning and Extension to Regression. In Conference of the European Chapter of the Association for Computational Linguistics. CorpusID:233189542 [171] Mengwei Xu, Feng Qian, Mengze Zhu, Feifan Huang, Saumay Pushp, and Xuanzhe Liu. 2020. DeepWear: Adaptive Local Offloading for On-Wearable Deep Learning. IEEE Transactions on Mobile Computing 19, 2 (2020), 314 330. doi:10.1109 TMC.2019.2893250 [172] Fan Yang, Ashok Samraj Thangarajan, Gowri Sankar Ramachandran, Wouter Joosen, and Danny Hughes. 2021. AsTAR: Sustainable Energy Harvesting for the Internet of Things through Adaptive Task Scheduling. ACM Trans. Sen. Netw. 18, 1, Article 4 (oct 2021), 34 pages. doi:10.1145 3467894 [173] Tien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. 2016. Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning. CoRR abs 1611.05128 (2016). arXiv:1611.05128 [174] Tien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. 2016. Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning. CoRR abs 1611.05128 (2016). arXiv:1611.05128 [175] Tien-Ju Yang, Yu-Hsin Chen, Joel Emer, and Vivienne Sze. 2017. A method to estimate the energy consumption of deep neural networks. In 2017 51st Asilomar Conference on Signals, Systems, and Computers. 1916 1920. doi:10.1109 ACSSC.2017.8335698 [176] Tien-Ju Yang, Yu-Hsin Chen, Joel Emer, and Vivienne Sze. 2017. A method to estimate the energy consumption of deep neural networks. In 2017 51st Asilomar Conference on Signals, Systems, and Computers. 1916 1920. doi:10.1109 ACSSC.2017.8335698 [177] Zhaohui Yang, Mingzhe Chen, Walid Saad, Choong Seon Hong, and Mohammad Shikh-Bahaei. 2019. Energy Efficient Federated Learning Over Wireless Communication Networks. CoRR abs 1911.02417 (2019). arXiv:1911.02417 [178] Shuochao Yao, Jinyang Li, Dongxin Liu, Tianshi Wang, Shengzhong Liu, Huajie Shao, and Tarek Abdelzaher. 2020. Deep compressive offloading: speeding up neural network inference by trading edge computation for network latency. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (Virtual Event, Japan) (SenSys 20). Association for Computing Machinery, New York, NY, USA, 476 488. doi:10.1145 3384419.3430898 [179] Seul-Ki Yeom, Kyung-Hwan Shim, and Jee-Hyun Hwang. 2021. Toward Compact Deep Neural Networks via Energy-Aware Pruning. CoRR abs 2103.10858 (2021). arXiv:2103.10858 [180] Amirreza Yousefzadeh, Jan Stuijt, Martijn Hijdra, Hsiao-Hsuan Liu, Anteneh Gebregiorgis, Abhairaj Singh, Said Hamdioui, and Francky Catthoor. 2022. Energy-efficient In-Memory Address Calculation. ACM Trans. Archit. Code Optim. 19, 4, Article 52 (sep 2022), 16 pages. doi:10.1145 3546071 [181] Jiahui Yu, Linjie Yang, Ning Xu, Jianchao Yang, and Thomas S. Huang. 2018. Slimmable Neural Networks. CoRR abs 1812.08928 (2018). arXiv:1812.08928 [182] Rong Yu and Peichun Li. 2021. Toward Resource-Efficient Federated Learning in Mobile Edge Computing. IEEE Network 35, 1 (2021), 148 155. doi:10.1109 MNET.011.2000295 [183] Jinliang Yuan, Shangguang Wang, Hongyu Li, Daliang Xu, Yuanchun Li, Mengwei Xu, and Xuanzhe Liu. 2024. Towards Energy-efficient Federated Learning via INT8-based Training on Mobile DSPs. In Proceedings of the ACM Web Conference 2024 (Singapore, Singapore) (WWW 24). Association for Computing Machinery, New York, NY, USA, 2786 2794. doi:10.1145 3589334.3645341 [184] Arber Zela, Julien Siems, and Frank Hutter. 2020. NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search. CoRR abs 2001.10422 (2020). arXiv:2001.10422 [185] Liekang Zeng, En Li, Zhi Zhou, and Xu Chen. 2019. Boomerang: On-Demand Cooperative Deep Neural Network Inference for Edge Intelligence on the Industrial Internet of Things. IEEE Network 33, 5 (2019), 96 103. doi:10.1109 MNET.001.1800506 [186] Qunsong Zeng, Yuqing Du, Kin K. Leung, and Kaibin Huang. 2019. Energy-Efficient Radio Resource Allocation for Federated Edge Learning. arXiv:1907.06040 [cs.IT] [187] Yu Zhang, Tao Gu, and Xi Zhang. 2022. MDLdroidLite: A Release-and-Inhibit Control Approach to Resource-Efficient Deep Neural Networks on Mobile Devices. IEEE Transactions on Mobile Computing 21, 10 (2022), 3670 3686. doi:10.1109 TMC.2021.3062575 [188] Yuchen Zhao, Sayed Saad Afzal, Waleed Akbar, Osvy Rodriguez, Fan Mo, David Boyle, Fadel Adib, and Hamed Haddadi. 2022. Towards battery-free machine learning and inference in underwater environments. In Proceedings of the 23rd Annual International Workshop on Mobile Computing Systems and Applications (HotMobile 22). ACM. doi:10.1145 3508396.3512877 [189] Yiyang Zhao, Linnan Wang, Yuandong Tian, Rodrigo Fonseca, and Tian Guo. 2020. Few-shot Neural Architecture Search. CoRR abs 2006.06863 (2020). arXiv:2006.06863 [190] Zhuoran Zhao, Kamyar Mirzazad Barijough, and Andreas Gerstlauer. 2018. DeepThings: Distributed Adaptive Deep Learning Inference on Resource-Constrained IoT Edge Clusters. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 37, 11 (2018), 2348 2359. doi:10.1109 TCAD.2018.2858384 24 Millar et al. [191] Guangxu Zhu, Yong Wang, and Kaibin Huang. 2020. Broadband Analog Aggregation for Low-Latency Federated Edge Learning. IEEE Transactions on Wireless Communications 19, 1 (2020), 491 506. doi:10.1109 TWC.2019.2946245\n\n=== SEGMENTS ===\n\n--- Segment 1 ---\narXiv:2505.12523v1 [cs.LG] 18 May 2025 Energy-Aware Deep Learning on Resource-Constrained Hardware JOSH MILLAR, HAMED HADDADI, Imperial College London ANIL MADHAVAPEDDY, University of Cambridge The use of deep learning (DL) on Internet of Things (IoT) and mobile devices offers numerous advantages over cloud- based processing. However, such devices face substantial energy constraints to prolong battery-life, or may even operate intermittently via energy-harvesting. Consequently, energy-aware approaches for optimizing DL inference and training on such resource-constrained devices have garnered recent interest. We present an overview of such approaches, outlining their methodologies, implications for energy consumption and system-level efficiency, and their limitations in terms of supported network types, hardware platforms, and application scenarios. We hope our review offers a clear synthesis of the evolving energy-aware DL landscape and serves as a foundation for future research in energy-constrained computing. 1 Introduction The Internet of Things (IoT) has become a vital component of our everyday lives, with a forecasted 30 billion smart devices connecting and controlling our homes, urban environments, and factories by 2027 [41]. IoT devices generate massive amounts of data, which often requires machine learning (ML) -based processing. Deep Neural Networks (DNNs) and other ML approaches are notoriously resource-intensive and so, traditionally, cloud-based processing has been relied upon to handle their computational load. However, considerable recent work has focused on enabling on-device deep learning (DL) inference and training. This offers numerous advantages over cloud-based processing, including reduced and predictable latency [61], independent of network congestion saturation, minimized bandwidth [185], and improved data privacy. IoT, mobile, and other edge devices often face strict constraints in terms of memory and compute resources. Hence, numerous works focus on optimizing DNNs subject to such constraints. These generally focus on inference, employing lightweight DNN architectures [83, 94, 125] and compression methods [39, 67, 115], as well as strategies for adapting inference dynamically based on input-complexity and workload. These strategies include multi- exit networks [72], inference offloading [178], and the partitioning of inference between device and cloud [20].\n\n--- Segment 2 ---\nThese generally focus on inference, employing lightweight DNN architectures [83, 94, 125] and compression methods [39, 67, 115], as well as strategies for adapting inference dynamically based on input-complexity and workload. These strategies include multi- exit networks [72], inference offloading [178], and the partitioning of inference between device and cloud [20]. Additional works focus on enabling on-device DNN training [9, 11, 31, 71, 85, 156, 187] by regulating layer-wise growth [187] or eliminating redundant weights activations to minimize updates [85]. However, IoT devices also operate on strict energy budgets to prolong battery life. The energy consumption of a DNN is not directly proportional to its memory or computational footprint [14] so, while the above optimization methods improve DNN efficiency, they generally fail to optimize for energy-usage. This is vital, as energy-usage can impose a larger constraint on particular devices or applications than memory compute (ùëí.ùëî., if considering battery-less devices and or deployment in remote or hard-to-reach environments). We characterize energy-aware DL as approaches for optimizing the design, inference, or training of DNNs in terms of energy consumption. Note that energy-awareness is not limited to energy-efficiency alone, also including approaches that can regulate inference energy consumption based on energy-availability, workload, and input complexity. This survey provides a concise review of such approaches, focusing on those with potential for deployment on highly-constrained IoT devices, particularly microcontroller units (MCUs). 1.1 Related Works and Contributions Numerous survey works explore ML and DL for resource-constrained computing [1], yet specifically energy-aware approaches have received comparatively limited attention. Tekin et al. offer the only comprehensive survey addressing on-device ML from an energy consumption perspective [145], but their IoT-centric review emphasizes use-case taxonomy and tooling over optimization, and overlooks energy-harvesting and intermittent computing. Various benchmarking efforts also exist in this domain. MLPerfPower [148], arguably the most prominent initiative, provides a benchmarking suite for standardizing the energy measurement of ML workloads at power 2 Millar et al. scales ranging from microwatts to megawatts.\n\n--- Segment 3 ---\nMLPerfPower [148], arguably the most prominent initiative, provides a benchmarking suite for standardizing the energy measurement of ML workloads at power 2 Millar et al. scales ranging from microwatts to megawatts. It covers diverse platforms including mobile phones and specialized TPUs, like Nvidia s Jetson family, but has limited coverage on MCUs and ultra-low-power devices. Its benchmarks remain neither particularly up-to-date nor comprehensive regarding emerging energy-aware techniques. Our work instead provides a concise yet detailed overview of algorithm-based techniques for energy-aware DNN design, training, inference, and deployment policies. We emphasize practical methodologies tailored to IoT devices operating under severe power constraints or intermittency conditions, offering a focused perspective on the evolving energy-aware DL landscape. 1.2 Structure We cover energy-aware DNN design paradigms ( 2), methods for energy-adaptive DNN inference ( 3), and on-device DNN training ( 4). We then explore various real-world DL applications in which energy-awareness is imperative and requires novel approaches; these include federated learning (FL) ( 5.2) and DL on intermittent energy-harvesting devices ( 5.1). Finally, 6 outlines the various hardware platforms employed in the reviewed works. Each section offers insights into potential future directions. 7 provides a high-level overview of these. 2 Energy-Aware DNN Design Including energy as a design-time metric is key for guiding the design and optimization of efficient DNNs. However, balancing energy-efficiency with performance is a layered design challenge and requires sophisticated optimization techniques. The bulk of existing work has predominantly focused on using the number of DNN weights and or operations as proxy for energy consumption; in particular multiply-and-accumulate (MAC) operations, which often account for over 99 of total CNN operations [40, 42, 68]. Unfortunately, while these proxies are correlated to the memory and computational footprints of DNNs, they do not accurately reflect their energy consumption (ùëí.ùëî., SqueezeNet [51] contains 50x fewer MACs than AlexNet [68], yet exhibits greater energy consumption on various platforms [103, 173]). This is because DNN energy consumption is enormously impacted by data movement; access to memory distant from the processor may cost 10 to 100 times more than an FPU ALU operation [180].\n\n--- Segment 4 ---\nUnfortunately, while these proxies are correlated to the memory and computational footprints of DNNs, they do not accurately reflect their energy consumption (ùëí.ùëî., SqueezeNet [51] contains 50x fewer MACs than AlexNet [68], yet exhibits greater energy consumption on various platforms [103, 173]). This is because DNN energy consumption is enormously impacted by data movement; access to memory distant from the processor may cost 10 to 100 times more than an FPU ALU operation [180]. GoogLeNet s [139] energy consumption breakdown reveals that only 10 is attributed to network computation and the rest consumed by the movement of feature-maps [175]. Further, differences in memory architecture between platforms result in large variations in the comparative energy-efficiency of DNNs across devices. Therefore, energy-aware and platform-agnostic DNN compression and optimization methods [38] are vital. Such methods can be largely categorised into the following: pruning: removing redundant weights from a network. quantization: reducing the bit-precision of network weights (e.g., from 32-bit float to 8-bit integer). weight sharing: reusing weights across network layers (e.g., shared filters in convolutional layers). knowledge distillation: training a smaller network to emulate a larger one by minimizing the entropy, distance, or divergence between their outputs. low-rank decomposition: approximating network weights with products of lower-rank matrices. These optimisations generally reduce network memory footprint by removing or compressing DNN weights. However, as mentioned above, memory-focused compression does not guarantee optimal DNN energy con- sumption. There has been recent interest in energy-aware variants of such methods; among these, pruning and quantization have received the most attention in the context of energy-aware compression. 0 Energy-Aware Deep Learning on Resource-Constrained Hardware 3 Table 1. An overview of energy-aware neural architecture search methods. A dash indicates an out-of-scope area. Method Eval. (Base) Arch. Space Constrained Eval.\n\n--- Segment 5 ---\n(Base) Arch. Space Constrained Eval. Hardware Approach Energy-Estimation [98] DeepCaps [113], CapsNet [120] - Evolutionary MACs, memory-accesses [155] MobileNetV1 V2 [46, 126] - Gradient FLOPs [18] MobileNetV2, MNASNet [140] Snapdragon 835 (CPU) Evolutionary Hardware-measurements [57] ¬µNAS [82] TI MSP430FR5994 (MCU) Super-Net MACs [21] MobileNetV2, ResNet50 [43], YOLOv5 [150] Huawei Atlas200DK (NPU), Zynq ZCU102 (FPGA) Super-Net Hardware-measurements 2.1 Design-Time Optimizations Given the recognition that memory-focused compression does not guarantee optimal DNN energy consumption, there is a growing interest in the development of energy-aware variants of such compression methods that are directly optimized for energy use. In energy-aware pruning (EAP), the pruning order is determined based on ranked layer-wise energy consump- tion [173]. EAP approaches vary predominantly by their means of estimating layer-wise energy consumption; approaches include joint estimation based on computation cost (ùëñ.ùëí. MACs) and memory accesses [176], using CNN filter importance (nuclear-norm derived from SVD) as proxy [179], and using energy-measurements derived from real hardware measurements [174]. GENESIS [33] enables layer-wise DNN compression via rank decom- position and pruning, incorporating user-defined operator energy-costs. However, the effectiveness of EAP is limited by the fact that CNN energy consumption is dominated by convolutional operations and their extensive data movement, while pruning techniques are most effective on fully-connected (FC) layers. There is also substantial recent work focusing on energy-aware quantization (EAQ) in the realm of in-memory DL accelerators. These accelerators utilize non-volatile memory to improve CNN energy-efficiency by performing convolution operations as analog-domain matrix-vector multiplications. This effectively reduces data move- ment. ECQ [60] utilizes a genetic approach for exploring layer-wise weight activation bitwidth(s), optimizing dynamic in-memory energy consumption at negligible performance loss.\n\n--- Segment 6 ---\nThis effectively reduces data move- ment. ECQ [60] utilizes a genetic approach for exploring layer-wise weight activation bitwidth(s), optimizing dynamic in-memory energy consumption at negligible performance loss. The ECQ approach requires only a network s weight activation distributions in order to estimate its energy consumption, making it applicable across various DNNs. The utilization of in-memory accelerators offers vast potential in reducing DNN inference energy consumption by minimizing data movement. However, such accelerators are not yet widely applicable on memory-constrained devices; Kim et al. [65] provide a detailed overview of in-memory techniques for DL. The key limitation of EA compression methods lies in their accuracy in predicting the layer operation-wise energy consumption of DNNs pre-execution. 2.3 provides an overview of existing energy-estimation methods, and their supported hardware platforms and DNN operators. Future work should additionally explore the impact of hardware variation on non-uniform quantization techniques. 2.2 Neural Architecture Search Traditional works enabling on-device inference focused on hand-crafted DNN architectures, including SqueezeNet [51], MobileNet [46, 126], and EfficientNet [141]. The design of these architectures required substantial manual tuning, combined with ingenuity; and while efficient, they lack versatility for diverse task-specific optimiza- tions. Neural Architecture Search (NAS) methods revolutionized NN design by automating the discovery of 4 Millar et al. NN architectures that optimize various performance metrics for a given task, while also considering computa- tional hardware constraints. Numerous works have demonstrated NAS s capability to reveal NN designs with state-of-the-art performance [116]. Typical NAS methods explore the architecture space using evolutionary [90] or reinforcement-learning (RL) [53] approaches. These methods require vast computational resources and GPU hours, rendering them infeasible in most real-world applications. Consequently, more recent NAS methods use proxies for architecture evaluation to reduce search complexity at the expense of (marginally) suboptimal results. Favoured among these methods is Differentiable NAS (DNAS), which utilizes gradient descent to optimize both DNN weights and parameters. Typically, DNAS employs super-nets, large DNNs that include various implementations of subnetworks, and explores the architecture space by evaluating subnetwork paths.\n\n--- Segment 7 ---\nFavoured among these methods is Differentiable NAS (DNAS), which utilizes gradient descent to optimize both DNN weights and parameters. Typically, DNAS employs super-nets, large DNNs that include various implementations of subnetworks, and explores the architecture space by evaluating subnetwork paths. However, super-net DNAS methods are often limited in their capacity to model complex constraints, and their utility can be outweighed by evolutionary learning-based NAS methods if the base architecture results in an excessively large super-net. ProxylessNAS [10] mitigates this issue by limiting subnetwork evaluation to binary paths. NAS excels in NN compression and optimization for a given task but is limited in its ability to jointly optimize performance and hardware-aware constraints. Typical EA-NAS approaches resort to using MACs, FLOPs, and other proxies for energy consumption. NASCaps [98], for example, supports energy-aware NAS for traditional DNNs alongside convolutional capsule networks [120], proxying energy consumption using a combination of MACs and memory-accesses. By integrating capsule layers and dynamic routing, it jointly optimizes capsule networks for energy consumption, accuracy, memory-footprint, and latency. However, as previously mentioned, such proxies often result in an incomplete profile of DNN energy consump- tion. The difficulty in using energy as an optimization metric again lies in accurately estimating the consumption of a given architecture without physically executing it, which is infeasible given the vast design space. Addition- ally, the energy consumption of a DNN is highly device platform dependent. Therefore, EA-NAS methods often utilize regression-based approaches, built on recorded energy measurements from a subset of NAS-generated reference architectures on the target platform, to predict the energy consumption of candidate architectures. Liu et. al [86] introduce NAS as a "continual splitting process", in which DNN operators are split for iterative loss minimization, and Wang et. al [155] extend this by incorporating benchmark energy-measurements of operator splitting to discover more energy-efficient architectures. ET-NAS [21] uses energy consumption benchmarks of NN operators on various edge-side FPGA platforms, and under various parameter settings. ChamNet [18] is an evolutionary NAS method utilizing Gaussian-process regression and energy estimates derived from benchmark measurements for a range of hardware platforms, including mobile CPUs and DSPs.\n\n--- Segment 8 ---\nET-NAS [21] uses energy consumption benchmarks of NN operators on various edge-side FPGA platforms, and under various parameter settings. ChamNet [18] is an evolutionary NAS method utilizing Gaussian-process regression and energy estimates derived from benchmark measurements for a range of hardware platforms, including mobile CPUs and DSPs. 2.3 provides an overview of existing energy-prediction methods for NAS, and their supported hardware platforms and DNN operators. Tabular energy consumption benchmarks for various architectures are slowly developing. However, they currently remain limited to common NN operators, architectures, and datasets. HW-NAS-Bench [78] collects measured estimated hardware metrics, including energy consumption, of explored candidate networks within the spaces of NAS-Bench-201 [22] and FBNet [166], on six diverse COTS devices. These include the NVIDIA Jetson TX2 GPU, Raspberry Pi 4, an Edge TPU Dev Board, Google Pixel 3, and Eyeriss (ASIC) [14]. Ta et. al [149] conduct hardware energy measurements of various edge-DNNs, including but not limited to MobileNet v1 v2 [46, 126], SqueezeNet [51], GoogLeNet [139] and ProxylessNAS [10], on various other mobile CPUs and GPUs. Devices used include the OnePlus 8, Xiaomi Redmi Note8, and the Huawei Mate40 Pro and P40 Pro Lite. Generalizing to new architectures, without complicating the NAS space with hardware specifications, involves one- or few-shot learning methods [184, 189]. The extension of existing benchmarks via few-shot networks and surrogate models, predicting learning dynamics in conjunction with energy measurements, can help bridge the gap between hardware-agnostic NAS optimization and practical energy-efficient architecture search [5]. Table 1 provides an overview of EA-NAS methods, including the architectural space and hardware-platforms on which they were evaluated, as well as their energy-estimation methodologies. Energy-Aware Deep Learning on Resource-Constrained Hardware 5 Table 2. An overview of DNN energy-estimation methodologies. A dash indicates an out-of-scope area. Method Granularity Inputs Application Eval.\n\n--- Segment 9 ---\nA dash indicates an out-of-scope area. Method Granularity Inputs Application Eval. Platform Supported Operators [117] Layer, Network MACs Inference CPU (Cortex A-series) conv, fc [118] Network Layer parameters Inference, Training CPU-GPU (Nvidia Tegra K1) - [171] Layer Layer parameters Inference, Training CPU (Snapdragon 400 805), GPU (Mali-400) conv, fc, relu [14] Layer MACs, memory accesses Inference ASIC (Eyeriss) [14] conv, fc [149] Layer, Network Layer parameters Inference CPU (Cortex A-series), GPU (Mali-G series Adreno 610) conv, fc, relu, bn Future work in EA-NAS should involve the development of energy-estimation methods that can accurately predict DNN energy consumption based solely on architectural features (ùëñ.ùëí., without requiring execution). The development of hardware-agnostic techniques capable of optimizing DNNs for various hardware platforms and profiles with minimal re-training is also essential, as well as efficient hardware-profiling methods to enable the scalable deployment of HW-NAS. This introduces a cross-domain learning problem, involving the prediction of absolute DNN energy consumption across hardware platforms; it prompts the development of a domain-invariant means of profiling DNNs, such as ASTs [47]. 2.3 Predicting Inference Energy The accurate hardware-agnostic prediction of DNN energy consumption is key in guiding the design of energy- efficient DNNs. There exist numerous works in this area, but no universally applicable method. The bulk of methods employ regression-based approaches, trained on hardware-specific benchmark DNN or layer-wise energy measurements, and utilize features such as MACs, FLOPs, and layer configurations as input. However, these approaches are constrained by the DNN operations they support, and their performance is currently extremely platform-dependent. Future work should prioritize the refinement of cross-platform estimation techniques, and the optimization of energy measurement pipelines [154]. Table 2 provides an overview of the various existing methods, including their hardware evaluation platforms and supported DNN operations. Tu et.\n\n--- Segment 10 ---\nTable 2 provides an overview of the various existing methods, including their hardware evaluation platforms and supported DNN operations. Tu et. al s [149] prediction method is currently SOTA in terms of generalization performance on unseen networks and edge devices, using a RF regression model built on kernel-level measurements on various mobile Cortex A-series CPUs and Mali G-series GPUs. SyNergy [117] and DeepWear [171] are the only other methods built for constrained edge devices, evaluated on the Nvidia Jetson TX1 and Cortex A-series CPUs, as well as the Mali-400 mobile GPU. 3 Energy-Adaptive Inference Realizing EA inference entails an inference-time trade-off between loss accuracy and energy consumption. Numerous approaches optimize DNN inference by utilizing lightweight architectures and static optimizations. However, these static optimizations, covered in 2.1, lack inference-time dynamicity. Hence, there s a need for adaptive inference techniques that can adjust energy consumption dynamically based on variations in energy- availability, workload, and input complexity. The latter is motivated by the recognition that if inputs are not all equally hard, a non-adaptive network incurs unnecessary processing for easy inputs or suffers performance loss for difficult ones [55, 106, 107, 110, 142]. Here, we discuss techniques for enabling EA inference, broadly categorized into DNN right-sizing, multi-exit, and inference offloading. 6 Millar et al. 3.1 DNN Right-Sizing Lighter networks can often handle the bulk of input instances nearly as well as the optimally-trained full network. Thus, cascaded networks of increasing complexity can be sequentially executed for efficient resource utilization with negligible accuracy loss. By overlapping the parameters of cascaded DNNs, recent works have harnessed the versatility inherent in employing multiple networks of increasing capacity with the memory-footprint of a single network; such parameter-sharing approaches are collectively known as DNN right-sizing. Notable right-sizing approaches include input-dependent layer-wise pruning [84, 142], DNN modularization and inference-time module selection [105], and input-dependent quantization [106]. The latter re-configures DNN precision based on input difficulty, unlike traditional static quantization which sets the bit-width uniformly across the entire network or different network subsets.\n\n--- Segment 11 ---\nNotable right-sizing approaches include input-dependent layer-wise pruning [84, 142], DNN modularization and inference-time module selection [105], and input-dependent quantization [106]. The latter re-configures DNN precision based on input difficulty, unlike traditional static quantization which sets the bit-width uniformly across the entire network or different network subsets. This prevents accuracy loss for difficult inputs that cannot be handled at low precision whilst reducing energy consumption for the bulk of inputs that can be accurately processed with a less conservative quantization. Additionally, input-dependent quantization does not require entire network re-training in order to maintain the base non-quantized accuracy at varying precision levels. It can be universally applied to any pre-trained CNN. Feature boosting and suppression [30], which predictively boosts layer channels at runtime and suppresses those deemed unimportant, is another universally applicable channel-based approach. DeLight [118] employs input-adaptive pre-processing by projecting input data to an ensemble of lower-dimensional subspaces based on their context and energy resource-constraints. HydraNets [128] consist of variable execution branches specialized towards extracting features of different input classes. They utilize a gating mechanism to choose the appropriate execution branches for a given in- put and ensemble techniques to aggregate branch outputs to produce a final inference. The various network branches are trained jointly for better accuracy. This joint training is enabled by independent batch-normalization (BN) of feature means and variances, which prevents feature aggregation inconsistency across the different branches widths [181]. Given that BN layers typically constitute less than 1 of network parameters, this incurs negligible extra computational memory overhead. Daghero et. al [17] extends HydraNets for energy-adaptive inference by decomposing a network into branches of varying complexity, assigning difficulty levels" to inputs, and processing them with the corresponding combination of network branches. HydraNets, alongside the other works detailed in this section, focus on CNNs. There exist non-energy-focused works on RNNs, utilizing dynamic entropy-based beam-width1 (BW) modification for adaptive inference [54, 56].\n\n--- Segment 12 ---\nHydraNets, alongside the other works detailed in this section, focus on CNNs. There exist non-energy-focused works on RNNs, utilizing dynamic entropy-based beam-width1 (BW) modification for adaptive inference [54, 56]. Recent works have also demonstrated adaptive inference on transformer-based DNNs, including cascaded transformers with increasing numbers of patches [160], and input-based patch, block, and head selection [100]; however, these are not generally applicable to constrained devices, and none directly considers energy as a metric. 3.2 Multi-Exit Networks Proliferation in DNN complexity is helpful only when classifying difficult inputs, which are inherently rare. The features learned at earlier network layers are often sufficient for accurately classifying the vast majority of the data population [28, 143, 159]. Multi-exit networks offer a form of adaptive right-sizing where inputs can exit the network at intermediate layers, bypassing the unnecessary processing of subsequent layers. Such networks obviate the need for re-execution in the case of a failed inference and can be combined with fixed optimizations. The design of a multi-exit network includes the addition of side-branch exit heads to a backbone network; Fig. 1 below outlines a conventional DNN alongside a multi-exit variant of the same architecture. With trivial modifications, any DNN can be made an implicit ensemble of networks by adding exit layers. The exit-point(s) of a multi-exit network can be determined either pre-execution (subnet-based inference [143]) or at inference time (progressive inference [7]). The former allows for more reliable estimation of inference energy requirements, enabling dynamic voltage and frequency scaling (DVFS). However, inference always continues until the selected 1BW refers to the number of candidate sequences evaluated at each step. Energy-Aware Deep Learning on Resource-Constrained Hardware 7 exit layer, potentially resulting in wasted energy for easy inputs and or overthinking [63]. Instead, with progressive inference, the exit-point is determined during network execution, typically based on the uncertainty of the exit classification or following an energy-management policy. This can reduce energy consumption via dynamic adaptation to input complexity, but necessitates more intricate hardware-level adjustments to do so.\n\n--- Segment 13 ---\nInstead, with progressive inference, the exit-point is determined during network execution, typically based on the uncertainty of the exit classification or following an energy-management policy. This can reduce energy consumption via dynamic adaptation to input complexity, but necessitates more intricate hardware-level adjustments to do so. 3.2.1 Multi-Exit Design Introducing exit layers to pre-trained backbone DNNs provides versatility when choosing the backbone design, as well as the case-driven optimization of exit layers [108]. However, more recent works have explored generalised structures [16, 26, 49, 63, 73, 144] and the co-design of end-to-end multi-exit networks [50]. By co-designing and jointly training the backbone NN and exit layers, there comes greater flexibility in optimization and the opportunity for improved performance at the cost of restricted task adaptability. Input Output a). Standard DNN Inference Input Output Output Output b). Early-Exit Inference Deterministic Conditional Fig. 1. Conventional DNN architecture alongside an EE variant. The dashed lines indicate conditional execution paths. Another design decision is the granularity and positioning of exit layers. Coarse-grained exits reduce overheads, but can miss exit opportunities. Conversely, fine-grained exits increase overheads, leading to heightened energy requirements and increased parameters. The extent of these overheads depends on the depth of the exit-layer(s), the network architecture, the use-case, and the exit policy. Zero Time Waste (ZTW) [165] addresses the overheads associated with failed exits, at the expense of (marginally) increased energy consumption and memory-footprint, by adding direct connections between exit-layers and recycling their outputs in an ensemble-like manner. Additionally, fine-grained exits can negatively impact convergence when jointly training the backbone NN and exit layers. PredictiveExit [81] uses a low-cost prediction engine to forecast where an input instance will exit the network, reducing the energy overheads of fine-grained exits by skipping the execution of pre-placed exit layers. This enables runtime configuration adjustment based on DVFS for energy-saving during inference. NAS approaches have recently been extended to the co-optimized design of multi-exit DNNs to meet energy, computation, and or memory constraints.\n\n--- Segment 14 ---\nThis enables runtime configuration adjustment based on DVFS for energy-saving during inference. NAS approaches have recently been extended to the co-optimized design of multi-exit DNNs to meet energy, computation, and or memory constraints. HarvNAS [57] configures multi-exit network architectures for battery- less devices by jointly optimizing the backbone network, exit layers, and inference policy subject to energy and memory constraints. However, the addition of exit layers increases the already vast design space with placement configurations. 2 covers EA architecture design and NAS methods in more detail. Recent works have explored multi-exits for compute-intensive Transformer architectures [12, 169, 170], but largely overlook energy consumption as a metric, whilst other architectures are mostly unexplored. 3.2.2 Deployment of Multi-Exit Networks Initial multi-exit works such as CDL [108] utilize exit policies based on static thresholds, quantifying the network s inference confidence using metrics like top-1 prediction score [7], 8 Millar et al. Teacher (Cloud) Student (Mobile) Input Output Output Output Output Self-Distillation Loss L(y‚ÇÅ, y) L(y‚ÇÇ, y) L(y‚ÇÉ, y) Œª R(Œ∏) Fig. 2. Multi-exit last-layer distillation training, with a backbone network trained in the cloud and its exits trained on-device. prediction entropy [143], and score margin (SM), the margin between the 1ùë†ùë°and 2ùëõùëëinference output scores [108, 110]. However, imposing a global threshold on network outputs corresponds to implicitly assuming all classes are equally difficult to process. In scenarios for which this assumption does not hold, class-dependent thresholds become necessary [16] ( 3.3). Rule-based policies enable the consideration of more nuanced energy-aware objectives, such as maximizing throughput given an energy budget [58]. Zygarde [52] is a scheduler for multi-exit inference tasks on energy- harvesting devices, constrained by the need for immediate task execution alongside varying energy-availability. Reinforcement learning (RL) has also been used to generate policies that additionally consider historical device operation and the longer-term effects of scheduling decisions.\n\n--- Segment 15 ---\nZygarde [52] is a scheduler for multi-exit inference tasks on energy- harvesting devices, constrained by the need for immediate task execution alongside varying energy-availability. Reinforcement learning (RL) has also been used to generate policies that additionally consider historical device operation and the longer-term effects of scheduling decisions. HarvSched, a RL based exit policy scheduler for energy-harvesting devices, learns its policy considering both instantaneous factors (ùëñ.ùëí., harvesting status and energy-storage level) alongside device operational history [57]. HarvSched demonstrates superior accuracy plus fewer missed events than Zygarde when evaluated in a test scenario (randomly-triggered events on an Arduino Uno equipped with MSP430-based solar harvester, 0.47F capacity supercapacitor, and TI PMIC). The on-device training of exit-layers requires efficient fine-tuning approaches, covered in 4. 3.3 Energy-Adaptive Inference Policies Effective DNN right-sizing requires an adaptive inference policy that decides on the optimal network configuration for each inference. Such binary policies are inherently non-differentiable. Consequently, most utilize RL, typically using either REINFORCE [164] or Q-learning [161]; the latter is particularly well-suited to resource-constrained devices, as inference involves a table-based look-up. However, RL necessitates pre-deployment, or cumbersome trial-and-error learning when pre-deployment isn t feasible. Recent works are beginning to introduce non-RL approaches; these include approximating the gradients of non-differentiable policy functions with continuous ones [48], employing gated mixture-of-experts approaches [129] (which utilize noisy-ranking on the gating networks), or training policy networks [167]. These policies also necessitate a means of evaluating inference uncertainty. The works detailed above all use SM as proxy [110], with the rationale being that the margin between the 1ùë†ùë°and 2ùëõùëëinference output scores, in a classification task, is proportional to the likelihood of correct top-1 inference. However, imposing a global threshold on network outputs corresponds to implicitly assuming all inputs are equally difficult to process. In scenarios where this assumption does not hold, class-dependent thresholds become necessary; Daghero et.\n\n--- Segment 16 ---\nHowever, imposing a global threshold on network outputs corresponds to implicitly assuming all inputs are equally difficult to process. In scenarios where this assumption does not hold, class-dependent thresholds become necessary; Daghero et. al Energy-Aware Deep Learning on Resource-Constrained Hardware 9 [16] defines these as follows: ùë°‚Ñéùëê argminùë°‚Ñéùëê(ùêπùëÉùëê(ùë°‚Ñéùëê) ùõº ùê∏ùëê(ùë°‚Ñéùëê)) (1) where ùë°‚Ñéùëêdenotes the threshold for class ùëêand ùêπùëÉùëê(ùë°‚Ñéùëê) the false positive rate. ùê∏ùëê(ùë°‚Ñéùëê) is a measure proportional to the energy consumption associated with processing an input of class ùê∂, quantified by the weighted number of invocations of the various cascade DNNs. Additionally, they propose a method for updating these class-dependent thresholds at runtime. Beyond multi-exit networks, energy-based thresholding is not largely applied. This is where DNN energy consumption is profiled across various network configurations (ùëñ.ùëí., branches, modules, bit-widths), and the network is adapted accordingly based on current forecasted energy-availability. This is particularly relevant for energy-harvesting devices, where energy-availability fluctuates. 5.1 covers general DL techniques for intermittent and energy-harvesting devices in detail. 3.4 Inference Offloading While data transmission is energy-expensive, device- and cloud-only approaches are typically not optimal in terms of inference energy consumption and latency [25]. Given sufficient energy-availability and task deadline, and a relatively stable connection, offloading inference from device to a cloud server may be advantageous, as a larger-capacity network can handle full or partial inference. Typical inference offloading methods involve layer-wise DNN partitioning. Fig. 3 provides an illustration of this. The optimal partitioning of a DNN is dependent on its layer topology, the inference task, the connection bandwidth, and the energy profile of the target device.\n\n--- Segment 17 ---\n3 provides an illustration of this. The optimal partitioning of a DNN is dependent on its layer topology, the inference task, the connection bandwidth, and the energy profile of the target device. Neurosurgeon [61] profiles the edge-device and cloud- server to generate energy latency-cost estimations for the execution of different DNN layer types. Using these estimations, and other relevant device factors (ùëí.ùëî., the current bandwidth), Neurosurgeon partitions DNN computation between device and cloud-server to optimize for energy consumption and end-to-end latency. EEoC [124] computes the partitioning using real measurements, instead of estimations, of the costs of DNN layer execution and layer output transmission on the target device. JointDNN [25] uses ILP to find the optimal partitioning layer, with respect to energy-availability, bandwidth saturation congestion, and quality-of-service. It also evaluates the benefit of compressing DNN layer outputs to reduce transmission energy costs. Boomerang [185] minimizes the overall energy cost of inference by evaluating the trade-off between on-device latency and energy cost versus the transmission energy cost for partitioning multi-exit networks. Alternatively, depth-wise partitioning methods vertically partition (convolutional) layers to reduce memory footprint whilst enhancing parallelism in communication and task offloading [190]. However, vertical tile-based partitioning, unlike depth-wise layer partitioning methods, can result in increased communication overheads and dependencies as it requires compiling results from adjacent partitions. Khoshsirat et al. [64] explore dynamically partitioning inference between containers on the same device to reduce energy consumption, and provide insights on how to optimally allocate inference tasks into these containers from an energy standpoint. Their approach is evaluated on Nvidia Jetson TX2 and AGX Orin edge devices and demonstrates energy-savings. However, it is only applicable if inference can be partitioned into independent tasks; a future direction should be to investigate container-wise partitioning of dependent tasks. Additionally, the effectiveness of such partitioning diminishes as devices become increasingly resource-constrained. Inference offloading is particularly suitable for wearable devices (ùëí.ùëî., smart watches) as they are typically paired with a mobile device.\n\n--- Segment 18 ---\nAdditionally, the effectiveness of such partitioning diminishes as devices become increasingly resource-constrained. Inference offloading is particularly suitable for wearable devices (ùëí.ùëî., smart watches) as they are typically paired with a mobile device. The communication between the wearable and offloading devices can be efficiently realized by short-range radio (ùëí.ùëî., BLE). DeepWear [171] enables the context-aware partial offloading of CNN and RNN inference from wearables to their paired mobile devices via local BLE connectivity. This involves minimizing the weighted energy consumption of all feasible DNN partitions. DeepWear has been successfully applied to COTS wearables, including the LG Urbane smartwatch, and mobile devices such as the Google Nexus 6. 10 Millar et al. Additionally, offloading has been extended to battery-less energy-harvesting devices; Sabovic et. al [121] demonstrate its use for the application of person detection on an Arduino Nano (with 1.5F supercapacitor, AEM10941 solar harvester and PMIC, and BLE for wireless communication). Their device estimates the latencies of device-only and cloud inference (no support for DNN partitioning) and decides to offload based on the task- deadline and current harvesting status. Future work could explore learning-based offloading approaches that consider historical device operation and energy-availability. Input Output Device Server Fig. 3. DNN partitioning between device and server. 4 On-Device Training The above sections generally focus on optimizing on-device inference with an offline-trained network. However once deployed, data- or context-shifts can result in degraded network performance in the target environment [135]. This issue is especially relevant for in-the-wild sensing applications, where environmental conditions can be highly variable and result in distortion (ùëí.ùëî., fog, snow, rain) and or degradation (ùëí.ùëî., defocus). Additionally, a deployed classifier may need to include new classes or reduce its existing class set to optimize its performance in the target environment. While not energy-aware, methods that contribute to enhancing the out-of-distribution (OOD) generalizability of pre-trained networks are key for IoT deployments.\n\n--- Segment 19 ---\nAdditionally, a deployed classifier may need to include new classes or reduce its existing class set to optimize its performance in the target environment. While not energy-aware, methods that contribute to enhancing the out-of-distribution (OOD) generalizability of pre-trained networks are key for IoT deployments. These include causality- [95, 130, 131], gradient operation- [97, 101, 134], and learning-based methods (ùëí.ùëî. zero-shot, meta, and representation learning) [6, 23, 79, 109, 158]. However, explicit fine-tuning commonly outperforms generalization in mitigating data context shifts in real-world evaluations [2, 69, 123, 163, 168]. Typically, DNNs are fine-tuned in the cloud, as gradient backpropagation is energy-expensive and prohibitively memory-intensive on resource-constrained devices (due to limited SRAM). However, this massively increases the communication overheads of the IoT device, increasing bandwidth requirements, and is not viable for ultra- low-power devices or those deployed in remote environments. Hence, there is substantial recent work towards optimizing DNN fine-tuning requirements, using unsupervised and self-supervised methods, to meet the energy budgets of constrained devices. MiniLearn [111] enables IoT devices to fine-tune and optimize pre-trained integer quantized networks using intermediate compressed outputs of quantized layers. It fine-tunes dequantized hidden (convolutional and FC) layers while keeping the rest of the pre-trained network in its quantized integer precision, reducing energy- usage without compromising performance. However, MiniLearn operates in the constrained context where network performance is optimized by reducing its class set and relies on labelled target data. LifeLearner [70] is a rehearsal-based meta continual-learning (CL) approach that is optimized for data-scarcity and energy- efficiency to enable realistic on-device CL (demonstrated on a STM32H747 MCU). Typical CL approaches require full-network backpropagation, and sufficient representative data to be kept on-device for meta-testing. These requirements are not viable in a constrained on-device scenario. Similar to MiniLearn, LifeLearner introduces a new rehearsal strategy, in which rehearsals are extracted as compressed outputs of intermediate network layers.\n\n--- Segment 20 ---\nThese requirements are not viable in a constrained on-device scenario. Similar to MiniLearn, LifeLearner introduces a new rehearsal strategy, in which rehearsals are extracted as compressed outputs of intermediate network layers. By optimizing the intermediate rehearsal layer for maximum compression, LifeLearner reduces the computational- and energy-costs of fine-tuning. Additionally, LifeLearner utilizes bitmap compression and product-quantization of rehearsal-layer outputs to reduce memory-footprint. Energy-Aware Deep Learning on Resource-Constrained Hardware 11 Decreasing the number of fine-tuning parameters reduces its energy-expense [24, 89, 119] and can improve performance by reducing overfitting [36, 66, 74, 114]. Hence, recent works have also explored quantifying the contributions of network layers parameters towards counteracting data shifts. NEq [8] reduces fine-tuning energy consumption by iteratively determining the weights to fine-tune. It computes the cosine-similarity between weights at epochs t and t-1, and uses this difference to quantify their relative velocity". Then, NEq selects to fine-tune weights not in equilibrium, where equilibrium can be defined as: ùë£ùë° ùëñ ùúñ, ùúñ 0 (2) Here, ùë£ùë° ùëñis the relative velocity of parameter ùëñat epoch ùë°and ùõΩis an arbitrary threshold. Qu√©lennec et. al [112] replaces the NEq threshold with a fine-tuning energy budget ùêµùë§, and greedily selects the ùëõhighest velocity weights that can fit within the defined budget. However, efficiently determining which layers parameters to fine- tune is an ongoing challenge [76]. NEq, and other gradient-based selection methods [76], require a full-network backpropagation to compute the initial parameter velocities (which mightn t be viable on extremely energy- or memory-constrained devices), alongside fine-grained estimates of parameter-wise energy consumption. The NEq method applied layer-wise could support better estimates, and the layer-wise velocity can be initially approximated by random-sampling of intra-layer neurons.\n\n--- Segment 21 ---\nNEq, and other gradient-based selection methods [76], require a full-network backpropagation to compute the initial parameter velocities (which mightn t be viable on extremely energy- or memory-constrained devices), alongside fine-grained estimates of parameter-wise energy consumption. The NEq method applied layer-wise could support better estimates, and the layer-wise velocity can be initially approximated by random-sampling of intra-layer neurons. Recent works utilize multi-exit networks to support efficient personalization by fine-tuning exit layers whilst maintaining the network backbone [77]. Typically, this is done using a self-supervised knowledge distillation approach (see Fig 2) in which labels are generated by the output of the last exit. However, Fawden et. al [27] analyze per-exit performance, demonstrating that it is not valid to assume the last exit is always the most accurate. They instead recommend selecting input instances on which to fine-tune based on their predictive uncertainty. Additionally, they interpret exits as an ensemble of networks with a joint loss. 5 Applications 5.1 DL on Energy-Harvesting Devices The utilization of DL on battery-less devices, which harvest energy from environmental sources (ùëí.ùëî. solar, vibration, RF), has garnered recent interest. These devices offer numerous advantages over their battery-powered counterparts. They are largely maintenance-free and easy-to-recycle, promoting sustainability and suitability for large-scale deployments in hard-to-reach environments. Additionally, capacitors are more resistant to degradation than batteries, prolonging the lifetime of these devices to potentially decades. Given that data transmission is more energy-expensive than performing local inference, and that battery-less devices operate on extremely low energy-budgets, their deployment is impractical without on-device inference and task-scheduling. However, battery-less devices operate intermittently as energy is sporadically available, with recurring power failures that result in on-off behaviour. This presents challenges in efficiently guaranteeing inference correctness in the event of power failure, alongside reducing its likelihood via task-scheduling based on fluctuating energy-availability. Despite being a relatively new area of interest, there are numerous works demonstrating the real-world feasibility of DL on energy-harvesting devices.\n\n--- Segment 22 ---\nThis presents challenges in efficiently guaranteeing inference correctness in the event of power failure, alongside reducing its likelihood via task-scheduling based on fluctuating energy-availability. Despite being a relatively new area of interest, there are numerous works demonstrating the real-world feasibility of DL on energy-harvesting devices. These include CNN-based facial recognition on solar-powered devices [32, 59], a capacitance-based gesture recognition wearable [147], and DL-driven bioacoustics monitoring in underwater environments using harvested acoustic energy [188]. 5.1.1 Intermittence-Safe Inference Battery-less devices accumulate charge using harvested energy until voltage Von is reached; the device then powers on and operates until charge depletes to Voff. This cycle repeats periodically or aperiodically. Von is typically set pre-deployment. Future work could explore adjusting capacitor capacity at runtime using a policy-based or RL approach to match energy fluctuations and workload. During intermittent execution, power failures reset volatile memory, hampering computational progress, and can lead to non-volatile memory inconsistencies (ùëí.ùëî., partial variable updates can occur because of an 12 Millar et al. interrupted partial execution and lead to incorrect results in the subsequent re-execution). Numerous methods exist for guaranteeing correct execution on intermittent systems, ranging from using periodic checkpoints to store intermediate states [45, 153], non-volatile processors that maintain state across power cycles [92, 93] and methods based on executing atomic tasks [15, 44]. However, these methods introduce computational (and therefore energy) overheads, especially those dealing with non-volatile processing [96]. This is problematic for computation-heavy DNN inference training. SONIC [33] is an intermittence-safe task-based API designed explicitly for DNN inference, aiming to exploit its regularity to minimize overheads. SONIC "breaks the rules" of conventional task-based programming paradigms by allowing the persistence of non-volatile memory across loop iterations. However, a combination of loop-ordered buffering and sparse-undo logging ensures that loop iterations are idempotent, guaranteeing safe resumption of interrupted tasks. Additionally, loop continuation eliminates wasted computation in the event of power failure. SONIC also presents the first demonstration of DNN inference on a constrained energy-harvesting system, using the COTS MSP430 MCU with a RF-energy harvester.\n\n--- Segment 23 ---\nAdditionally, loop continuation eliminates wasted computation in the event of power failure. SONIC also presents the first demonstration of DNN inference on a constrained energy-harvesting system, using the COTS MSP430 MCU with a RF-energy harvester. 5.1.2 Inference Scheduling While SONIC and other intermittence-safe frameworks guarantee correct inference in the event of a power failure, they do not aid in reducing downtime. DL on energy-harvesting platforms also requires energy-reactive inference strategies and inference task-scheduling, given cyclical fluctuating energy-availability. Existing inference strategies largely focus on multi-exit networks. ePerceptive, a notable energy-reactive inference framework, built on SONIC, outputs lower-fidelity inferences at intermediate layers in response to energy fluctuations whilst guaranteeing valid inferences in the case of power failure [104]. ePerceptive also dynamically adjusts input resolution(s) to optimize performance under energy constraints. General task-scheduling for computing on energy-harvesting devices is well-studied [19, 62, 122, 137, 172]. ACES [29], for example, uses RL to optimise the duty cycles of battery-less nodes in order to maximise utility and increase node lifetime, under fluctuating energy-availability. DL inference schedulers can be generally categorized as rule- or RL-based. Zygarde[52], as discussed above, is an online rule-based scheduler for multi-exit networks that schedules exit-decisions based on an objective considering task-deadline, inference uncertainty and the current energy-harvesting status of the device. Zygarde partitions inference into mandatory and optional layers, and uses k-means to estimate inference uncertainty. The limitation of Zygarde and other non-trainable schedulers is that they fail to consider historical device operation. HarvSched, also discussed above ( 3.2.2), is a RL based scheduler that learns its scheduling policy based on current factors (ùëí.ùëî., energy-storage level) and device operational history [57]. This facilitates adaptive scheduling decisions based on evolving conditions. However, RL-based schedulers need pre-deployment in order to learn their policies, or cumbersome trial-and-error learning when pre-deployment isn t feasible.\n\n--- Segment 24 ---\nThis facilitates adaptive scheduling decisions based on evolving conditions. However, RL-based schedulers need pre-deployment in order to learn their policies, or cumbersome trial-and-error learning when pre-deployment isn t feasible. The methods discussed above enable on-device inference using an offline-trained network. However, on- device training fine-tuning is also necessary for counteracting real-world data- and context-shifts. Given that backpropagation is computationally more expensive than inference, fine-tuning only on non-redundant inputs is important; blindly selecting inputs on which to fine-tune can result in wasted energy if the inputs do not contribute towards improving DNN performance. Lee et. al [75] assess input relevance with a combination of three metrics, based on input uncertainty, diversity, and representation, to demonstrate unsupervised self- supervised learning on intermittently-powered COTS MCUs (AVR, PIC, MSP-430). 4 covers on-device training and fine-tuning methods in more detail. 5.2 Energy-Aware Federated Learning Federated Learning (FL) is a decentralized ML approach wherein DNNs are trained collaboratively across devices whilst keeping their raw data localized. This is realized via communicating weight updates to base servers that coordinate to aggregate a global network. FL offers scalability in massively-distributed environments, which can span over a large number of devices. FedAvg, the most common FL approach, performs rounds of local training Energy-Aware Deep Learning on Resource-Constrained Hardware 13 on device subsets to accommodate their heterogeneous resource constraints and latencies. FedAvg has been demonstrated to guarantee convergence in various heterogeneous scenarios, including unbalanced and non-i.i.d distributions [80, 99, 127]. Luo et. al [91] demonstrates the effectiveness of FedAvg on mobile devices. The key to effective FL across heterogeneous resource-constrained devices is energy-aware scheduling. This involves a trade-off between computation- and communication energy-costs, which are dependent on local DNN efficiency, the number of participating devices, and the number of local iterations in each FL round. Most works on energy-aware FL focus on optimizing the energy costs of on-device network training and are largely based on static DNN optimizations.\n\n--- Segment 25 ---\nThis involves a trade-off between computation- and communication energy-costs, which are dependent on local DNN efficiency, the number of participating devices, and the number of local iterations in each FL round. Most works on energy-aware FL focus on optimizing the energy costs of on-device network training and are largely based on static DNN optimizations. Q-FedUpdate [183] supports training with full integer quantization on energy-efficient mobile Digital Signal Processors (DSPs). These are found universally on mobile phones and most other IoT devices. Their use for DNN execution can yield 11.3x 4.0x reduction in energy usage over mobile CPU GPUs. Training is supported by maintaining a global full-precision (ùëñ.ùëí. FP32) network, which continuously accumlates network updates instead of having updates erased by quantization. Q-FedUpdate is integrated with efficient batch quantization as well as a pipelining-based approach to enable simultaneous CPU-based quantization and DSP training. The latter reduces computational overheads associated with repeated network quantization. Other works focus on reducing FL communication-energy costs; approaches include gradient quantization via SignSGD [191], gradient sparsification [37, 152, 162], and dynamic batch-sizing [87, 88, 133], as well as dynamically adjusting the number of local iterations between two global aggregation rounds [157]. In addition, energy-aware device scheduling can reduce communication costs. Sun et. al [138], for example, maximize the number of devices scheduled for gradient update at each iteration under an energy-constraint. Zeng et. al [186] use energy-efficient bandwidth allocation and scheduling to reduce the energy consumption of FL over wireless networks. Numerous recent works on energy-aware FL also concentrate on DNN partitioning to enable adaptivity towards heterogenous device energy budgets. Yang et. al [13] utilize layer-wise partitioning, partitioning local DNNs into shallow and deep-layers, with shallow layers updated more frequently in FL rounds as they capture more general features. Rong et al. [182] instead partition CNNs into subnetworks via width-wise partitioning, grouping filters into blocks and exchanging filter blocks among subnetworks periodically to ensure equal training across all devices while reducing training costs.\n\n--- Segment 26 ---\nRong et al. [182] instead partition CNNs into subnetworks via width-wise partitioning, grouping filters into blocks and exchanging filter blocks among subnetworks periodically to ensure equal training across all devices while reducing training costs. Given the various participating devices, their energy-budgets, and their CNN partitions, a heuristic approach is used to optimize the allocation of subnetworks to devices. The devices are ranked by their communication latency, and subnetworks by their number of weights, and matched accordingly. A "resource configuration search" then determines the minimum communication latency fitting the energy-budget of each device, taking into account time constraints for FL round completion. Other recent approaches model the FL trade-off as a joint optimization problem to minimize energy-cost while ensuring convergence, considering the various heterogenous devices and their energy budgets. Tran et. al [146] formulate a joint-optimization problem based on the sum of computation and communication energy. However, their approach requires the synchronous upload of weights from all devices, which is unrealistic, and does not provide convergence guarantees. Luo et. al [91] jointly optimize the number of participating devices and local iterations to minimize energy cost. They propose a sampling-based control solution that realizes minimal overhead and provides convergence guarantees. Yang et. al [177] derive energy consumption models of different FL approaches based on their convergence rates, utilizing these to form a novel joint-optimization problem. FL on intermittent energy-harvesting devices poses unique challenges, as devices can only participate when they have sufficient energy available. Given the energy-generation of participating devices is non-uniform, device scheduling (ùëñ.ùëí., when to participate) becomes important. One approach is to let each device participate as soon as it can do so. However, Guler et. al [35] demonstrate that this approach can bias the global FL network towards devices with more frequent energy-availability, resulting in an overall loss in performance. Another approach is to wait until all devices have sufficient energy to participate in the FL round, then use conventional FL sampling. This mitigates bias but requires waiting on the device with the slowest energy generation, which can result in slow convergence. Guler et. al introduce a FL protocol, with convergence guarantees, in which devices decide 14 Millar et al. whether to participate in a given FL round via a stochastic process based on their energy profiles.\n\n--- Segment 27 ---\nal introduce a FL protocol, with convergence guarantees, in which devices decide 14 Millar et al. whether to participate in a given FL round via a stochastic process based on their energy profiles. This approach requires no communication between devices and is therefore scalable to large networks. However, it assumes knowledge of the energy-renewal cycles of the participating devices (ùëñ.ùëí., the number of FL rounds needed to generate enough energy to participate), necessitating pre-deployment (and cycles may vary over time). Future work should involve the development of energy-aware DNN optimizations that can adapt to device heterogeneity to maximize energy-savings (ùëí.ùëî., applying different quantization granularities based on the capabilities and energy-constraints of different participating devices [132]). 6 Hardware Trends Gaps While the reviewed approaches span a variety of hardware platforms, most focus on accessible mobile and edge devices. Few approaches directly target MCUs, despite representing highly constrained platforms, likely due to the difficulty of implementing DL on such resource-limited architectures. The vast majority of approaches instead target mobile CPUs GPUs, which is unsurprising given that these devices offer greater resource availability, making them more accessible for evaluation, yet still represent energy-constrained environments. Moreover, only a small number of approaches that do include evaluation on MCU hardware do so on non-hobbyist platforms [16, 52, 57, 70, 121]. Among the exceptions are those focusing on energy-harvesting, typically targeting extremely low-power off-grid systems. The STM32 and MSP430 families of MCU are most commonly evaluated. There is a particularly notable gap in energy-aware NAS approaches designed for or evaluated on heterogeneous MCU architectures. There are also limited evaluations on FPGAs ASICs [14, 21], but these platforms are generally associated with higher costs, more specialized use cases, and demand expertise for effective deployment. Offloading approaches generally transition tasks from mobile to edge cloud environments, moving computations from a mobile CPU GPU DSP to more powerful devices like the Nvidia Jetson. Table 3. Embedded DL frameworks and their supported platforms. Framework Supported Platforms Open-Source TFLite-Micro [34] ARM Cortex-M series, Xtensa (incl.\n\n--- Segment 28 ---\nEmbedded DL frameworks and their supported platforms. Framework Supported Platforms Open-Source TFLite-Micro [34] ARM Cortex-M series, Xtensa (incl. ESP32), RISC-V EdgeML [102] ARM Cortex-M, AVR RISC ùúáTensor [151] ARM Cortex-M ùúáTVM [3] ARM Cortex-M CMSIS-NN [4] ARM Cortex-M STM32CubeMX [136] ARM Cortex-M (STM32 series) TAILS SONIC [33] TI MSP430 Broader platform and DNN-operation support, and improved compilation pipelines, of lightweight ML frame- works are essential for advancing MCU-based hardware evaluation; Table 3 summarizes current DL frameworks for MCUs and their supported platforms. 7 Future Work and Directions Having provided an outline of the evolving energy-aware ML landscape, we identify a number of overarching directions for future work in this rapidly evolving field: Cross-Platform Energy Estimation Current EA approaches struggle to generalize across hardware platforms and network architectures, with their fundamental limitation being the accuracy of estimating the parameter layer- wise energy consumption of a DNN, on a piece of hardware, without executing it. Similarly, finding universal Energy-Aware Deep Learning on Resource-Constrained Hardware 15 correlations is incredibly challenging given the heterogeneity of hardware platforms, and the impact of their variations (ùëí.ùëî., memory access hierarchy, loop nesting, and data flow) on DNN energy consumption. Future work should prioritize the development of universal, execution-free energy estimation approaches, leveraging architectural representations of DNNs to enable improved generalisation and cross-network device invariance. For example, abstract syntax trees (ASTs), as used in CDMPP [47], offer a promising path for encoding the hierarchical layout of DNNs in a hardware-agnostic manner. Going forward, extending such representations to incorporate energy-relevant metadata could enable fine-grained, cross-platform energy optimizations. Automated Energy Profiling There remains a clear need for low-cost, hardware-agnostic methods that can generate reliable power and energy profiles at scale. Currently, the scalability and cross-device validity of energy prediction methods relies on profiling a large number of heterogeneous platforms and DNN operators; this necessitates community collaboration in building a holistic energy benchmarking dataset.\n\n--- Segment 29 ---\nAutomated Energy Profiling There remains a clear need for low-cost, hardware-agnostic methods that can generate reliable power and energy profiles at scale. Currently, the scalability and cross-device validity of energy prediction methods relies on profiling a large number of heterogeneous platforms and DNN operators; this necessitates community collaboration in building a holistic energy benchmarking dataset. However, the accuracy of built-in power monitors for mobile IoT profiling is insufficient, requiring the use of expensive external power monitors. As such, this also prompts the development of automated hardware-agnostic profiling methods for improving the efficiency of collecting device measurements at scale. Platform-Specific Optimizations In addition to generalization, energy-aware methods should also adapt to platform heterogeneity, accounting for both static hardware constraints and dynamic runtime conditions, such as energy availability or thermal limits, to maximize energy-savings. Future work should explore hierarchical, policy-based, or RL approaches for adapting DNN optimization granularity (e.g., adjusting quantization precision, modifying compute scheduling, or pruning subnetwork paths) based on task requirements, energy constraints, and runtime feedback. Such strategies become imperative when deploying a pre-trained network on a large number of heterogeneous devices (ùëí.ùëî., in a FL setting). Energy-Aware Training Methodologies While most attention has focused on inference-time energy optimization, energy-aware DNN training remains largely unexplored. Much opportunity exists for innovation; for instance, differentiable energy-aware regularizers could guide optimization toward architectures that are inherently more efficient across diverse hardware. Similarly, progressive training approaches that gradually increase NN complexity based on task difficulty could reduce unnecessary computation. Such work also includes developing ùúáNPU architectures capable of supporting low-power, on-chip accelerated backpropagation. Multi-Modal Inference Driven by hardware trends, such as increased on-chip memory bandwidth (e.g., SRAM or embedded DRAM) alongside tightly-coupled CPU NPU architectures, there are growing opportunities for dynamic, multi-modal inference strategies. Sparse mixture-of-experts (MoE) architectures are one such approach, where compact networks are stored and dynamically switched in and out or combined based on input context or energy budget. This allows efficient handling of diverse modalities (e.g., vision, audio) while enabling context- sensitive inference without compromising energy efficiency.\n\n--- Segment 30 ---\nSparse mixture-of-experts (MoE) architectures are one such approach, where compact networks are stored and dynamically switched in and out or combined based on input context or energy budget. This allows efficient handling of diverse modalities (e.g., vision, audio) while enabling context- sensitive inference without compromising energy efficiency. Future work should investigate how MoE strategies can be optimized for energy-adaptivity on resource-constrained platforms. 8 Conclusion This work has outlined key directions in energy-aware DL, highlighting the interplay between NN efficiency and hardware constraints. While enormous progress has been made in energy-efficient NN design and deployment, major challenges remain particularly in accurate, hardware-agnostic energy estimation, adaptive optimization across diverse hardware, and scalable energy profiling with minimal overhead. Moving forward, addressing such challenges will require co-ordinated efforts spanning both hardware design and DL theory. We anticipate the continued emergence of specialized hardware accelerators, alongside developments in reduced data movement architectures, in-memory compute, and hardware-specific NN design, to push the boundaries of energy-efficient ML. We hope this survey acts as a useful foundation for further research at the intersection of DL and energy-constrained computing, guiding more informed and impactful designs across diverse and resource-constrained platforms. 16 Millar et al. References [1] Youssef Abadade, Anas Temouden, Hatim Bamoumen, Nabil Benamar, Yousra Chtouki, and Abdelhakim Senhaji Hafid. 2023. A Comprehensive Survey on TinyML. IEEE Access 11 (2023), 96892 96922. doi:10.1109 ACCESS.2023.3294111 [2] Anders Andreassen, Yasaman Bahri, Behnam Neyshabur, and Rebecca Roelofs. 2021. The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning. CoRR abs 2106.15831 (2021). arXiv:2106.15831 [3] Apache. 2024. MicroTVM. [4] ARM. 2024. CMSIS-NN. [5] Pedram Bakhtiarifard, Christian Igel, and Raghavendra Selvan. 2024. EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search.\n\n--- Segment 31 ---\n2024. EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search. arXiv:2210.06015 [cs.LG] [6] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chellappa. 2018. MetaReg: Towards Domain Generalization using Meta- Regularization. In Advances in Neural Information Processing Systems, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa- Bianchi, and R. Garnett (Eds. ), Vol. 31. Curran Associates, Inc. 647bba344396e7c8170902bcf2e15551-Paper.pdf [7] Konstantin Berestizshevsky and Guy Even. 2018. Sacrificing Accuracy for Reduced Computation: Cascaded Inference Based on Softmax Confidence. CoRR abs 1805.10982 (2018). arXiv:1805.10982 [8] Andrea Bragagnolo, Enzo Tartaglione, and Marco Grangetto. 2022. To update or not to update? Neurons at equilibrium in deep models. arXiv:2207.09455 [cs.LG] [9] Han Cai, Ji Lin, Yujun Lin, Zhijian Liu, Haotian Tang, Hanrui Wang, Ligeng Zhu, and Song Han. 2022. Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications. ACM Transactions on Design Automation of Electronic Systems 27, 3 (March 2022), 1 50. doi:10.1145 3486618 [10] Han Cai, Ligeng Zhu, and Song Han. 2018. ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware. CoRR abs 1812.00332 (2018). arXiv:1812.00332 [11] Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. 2016. Training Deep Nets with Sublinear Memory Cost. arXiv:1604.06174 [cs.LG] [12] Yanxi Chen, Xuchen Pan, Yaliang Li, Bolin Ding, and Jingren Zhou. 2024.\n\n--- Segment 32 ---\narXiv:1604.06174 [cs.LG] [12] Yanxi Chen, Xuchen Pan, Yaliang Li, Bolin Ding, and Jingren Zhou. 2024. EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language Models with 3D Parallelism. arXiv:2312.04916 [cs.LG] [13] Yang Chen, Xiaoyan Sun, and Yaochu Jin. 2020. Communication-Efficient Federated Deep Learning With Layerwise Asynchronous Model Update and Temporally Weighted Aggregation. IEEE Transactions on Neural Networks and Learning Systems 31, 10 (Oct. 2020), 4229 4238. doi:10.1109 tnnls.2019.2953131 [14] Yu-Hsin Chen, Joel Emer, and Vivienne Sze. 2016. Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks. In 2016 ACM IEEE 43rd Annual International Symposium on Computer Architecture (ISCA). 367 379. doi:10.1109 ISCA.2016.40 [15] Alexei Colin and Brandon Lucia. 2016. Chain: tasks and channels for reliable intermittent programs. In Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications (Amsterdam, Netherlands) (OOPSLA 2016). Association for Computing Machinery, New York, NY, USA, 514 530. doi:10.1145 2983990.2983995 [16] Francesco Daghero, Alessio Burrello, Daniele Jahier Pagliari, Luca Benini, Enrico Macii, and Massimo Poncino. 2020. Energy-Efficient Adaptive Machine Learning on IoT End-Nodes With Class-Dependent Confidence. In 2020 27th IEEE International Conference on Electronics, Circuits and Systems (ICECS). 1 4. doi:10.1109 ICECS49266.2020.9294863 [17] Francesco Daghero, Alessio Burrello, Chen Xie, Marco Castellano, Luca Gandolfi, Andrea Calimera, Enrico Macii, Massimo Poncino, and Daniele Jahier Pagliari. 2022.\n\n--- Segment 33 ---\n1 4. doi:10.1109 ICECS49266.2020.9294863 [17] Francesco Daghero, Alessio Burrello, Chen Xie, Marco Castellano, Luca Gandolfi, Andrea Calimera, Enrico Macii, Massimo Poncino, and Daniele Jahier Pagliari. 2022. Human Activity Recognition on Microcontrollers with Quantized and Adaptive Deep Neural Networks. ACM Transactions on Embedded Computing Systems 21, 4 (July 2022), 1 28. doi:10.1145 3542819 [18] Xiaoliang Dai, Peizhao Zhang, Bichen Wu, Hongxu Yin, Fei Sun, Yanghan Wang, Marat Dukhan, Yunqing Hu, Yiming Wu, Yangqing Jia, Peter Vajda, Matt Uyttendaele, and Niraj K. Jha. 2019. ChamNet: Towards Efficient Network Design Through Platform-Aware Model Adaptation. In Proceedings of the IEEE CVF Conference on Computer Vision and Pattern Recognition (CVPR). [19] Carmen Delgado and Jeroen Famaey. 2022. Optimal Energy-Aware Task Scheduling for Batteryless IoT Devices. IEEE Transactions on Emerging Topics in Computing 10, 3 (2022), 1374 1387. doi:10.1109 TETC.2021.3086144 [20] Swarnava Dey, Arijit Mukherjee, Arpan Pal, and Balamuralidhar P. 2019. Embedded Deep Inference in Practice: Case for Model Partitioning. In Proceedings of the 1st Workshop on Machine Learning on Edge in Sensor Systems (New York, NY, USA) (SenSys-ML 2019). Association for Computing Machinery, New York, NY, USA, 25 30. doi:10.1145 3362743.3362964 [21] Dong Dong, Hongxu Jiang, Xuekai Wei, Yanfei Song, Xu Zhuang, and Jason Wang. 2023. ETNAS: An energy consumption task-driven neural architecture search. Sustainable Computing: Informatics and Systems 40 (2023), 100926. doi:10.1016 j.suscom.2023.100926 [22] Xuanyi Dong and Yi Yang. 2020.\n\n--- Segment 34 ---\nSustainable Computing: Informatics and Systems 40 (2023), 100926. doi:10.1016 j.suscom.2023.100926 [22] Xuanyi Dong and Yi Yang. 2020. NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search. arXiv:2001.00326 [cs.CV] [23] Ying-Jun Du, Jun Xu, Huan Xiong, Qiang Qiu, Xiantong Zhen, Cees G. M. Snoek, and Ling Shao. 2020. Learning to Learn with Variational Information Bottleneck for Domain Generalization. CoRR abs 2007.07645 (2020). arXiv:2007.07645 Energy-Aware Deep Learning on Resource-Constrained Hardware 17 [24] Cian Eastwood, Ian Mason, and Christopher K. I. Williams. 2022. Unit-level surprise in neural networks. In Proceedings on "I (Still) Can t Believe It s Not Better!" at NeurIPS 2021 Workshops (Proceedings of Machine Learning Research, Vol. 163), Melanie F. Pradier, Aaron Schein, Stephanie Hyland, Francisco J. R. Ruiz, and Jessica Z. Forde (Eds.). PMLR, 33 40. [25] Amir Erfan Eshratifar, Mohammad Saeed Abrishami, and Massoud Pedram. 2018. JointDNN: An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services. CoRR abs 1801.08618 (2018). arXiv:1801.08618 [26] Biyi Fang, Xiao Zeng, Faen Zhang, Hui Xu, and Mi Zhang. 2020. FlexDNN: Input-Adaptive On-Device Deep Learning for Efficient Mobile Vision. In 2020 IEEE ACM Symposium on Edge Computing (SEC). 84 95. doi:10.1109 SEC50012.2020.00014 [27] Terry Fawden, Lorena Qendro, and Cecilia Mascolo. 2023. Uncertainty-Informed On-Device Personalisation Using Early Exit Networks on Sensor Signals. 2023 31st European Signal Processing Conference (EUSIPCO) (2023), 1305 1309.\n\n--- Segment 35 ---\nUncertainty-Informed On-Device Personalisation Using Early Exit Networks on Sensor Signals. 2023 31st European Signal Processing Conference (EUSIPCO) (2023), 1305 1309. CorpusID:261116963 [28] Michael Figurnov, Maxwell D. Collins, Yukun Zhu, Li Zhang, Jonathan Huang, Dmitry P. Vetrov, and Ruslan Salakhutdinov. 2016. Spatially Adaptive Computation Time for Residual Networks. CoRR abs 1612.02297 (2016). arXiv:1612.02297 02297 [29] Francesco Fraternali, Bharathan Balaji, Yuvraj Agarwal, and Rajesh K. Gupta. 2020. ACES: Automatic Configuration of Energy Harvesting Sensors with Reinforcement Learning. ACM Transactions on Sensor Networks 16, 4 (July 2020), 1 31. doi:10.1145 3404191 [30] Xitong Gao, Yiren Zhao, Lukasz Dudziak, Robert D. Mullins, and Cheng-Zhong Xu. 2018. Dynamic Channel Pruning: Feature Boosting and Suppression. CoRR abs 1810.05331 (2018). arXiv:1810.05331 [31] In Gim and JeongGil Ko. 2022. Memory-efficient DNN training on mobile devices. In Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services (Portland, Oregon) (MobiSys 22). Association for Computing Machinery, New York, NY, USA, 464 476. doi:10.1145 3498361.3539765 [32] Marco Giordano, Philipp Mayer, and Michele Magno. 2020. A Battery-Free Long-Range Wireless Smart Camera for Face Detection. In Proceedings of the 8th International Workshop on Energy Harvesting and Energy-Neutral Sensing Systems (Virtual Event, Japan) (ENSsys 20). Association for Computing Machinery, New York, NY, USA, 29 35. doi:10.1145 3417308.3430273 [33] Graham Gobieski, Nathan Beckmann, and Brandon Lucia. 2018. Intelligence Beyond the Edge: Inference on Intermittent Embedded Systems. CoRR abs 1810.07751 (2018).\n\n--- Segment 36 ---\nIntelligence Beyond the Edge: Inference on Intermittent Embedded Systems. CoRR abs 1810.07751 (2018). arXiv:1810.07751 [34] Google. 2024. TFLite-Micro. [35] Basak Guler and Aylin Yener. 2021. Sustainable Federated Learning. CoRR abs 2102.11274 (2021). arXiv:2102.11274 abs 2102.11274 [36] Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing, and Rog√©rio Schmidt Feris. 2018. SpotTune: Transfer Learning through Adaptive Fine-tuning. CoRR abs 1811.08737 (2018). arXiv:1811.08737 [37] Pengchao Han, Shiqiang Wang, and Kin K. Leung. 2020. Adaptive Gradient Sparsification for Efficient Federated Learning: An Online Learning Approach. CoRR abs 2001.04756 (2020). arXiv:2001.04756 [38] Song Han, Huizi Mao, and William J. Dally. 2016. Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding. In 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings, Yoshua Bengio and Yann LeCun (Eds.). [39] Song Han, Huizi Mao, and William J. Dally. 2016. Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding. arXiv:1510.00149 [cs.CV] [40] Song Han, Jeff Pool, John Tran, and William J. Dally. 2015. Learning both Weights and Connections for Efficient Neural Networks. CoRR abs 1506.02626 (2015). arXiv:1506.02626 [41] Mohammad Hasan. 2022. State of IoT-Spring 2022. IOT Analytics, See com product state-of-iot-spring-2022 website (2022). [42] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015.\n\n--- Segment 37 ---\n[42] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual Learning for Image Recognition. CoRR abs 1512.03385 (2015). arXiv:1512.03385 [43] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual Learning for Image Recognition. arXiv:1512.03385 [cs.CV] [44] Josiah Hester, Kevin Storer, and Jacob Sorber. 2017. Timely Execution on Intermittently Powered Batteryless Sensors. 1 13. doi:10. 1145 3131672.3131673 [45] Matthew Hicks. 2017. Clank: Architectural support for intermittent computation. In 2017 ACM IEEE 44th Annual International Symposium on Computer Architecture (ISCA). 228 240. doi:10.1145 3079856.3080238 [46] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arXiv:1704.04861 [cs.CV] [47] Hanpeng Hu, Junwei Su, Juntao Zhao, Yanghua Peng, Yibo Zhu, Haibin Lin, and Chuan Wu. 2024. CDMPP: A Device-Model Agnostic Framework for Latency Prediction of Tensor Programs. In Proceedings of the Nineteenth European Conference on Computer Systems (EuroSys 24). ACM. doi:10.1145 3627703.3629572 [48] Weizhe Hua, Christopher De Sa, Zhiru Zhang, and G. Edward Suh. 2018. Channel Gating Neural Networks. CoRR abs 1805.12549 (2018). arXiv:1805.12549 18 Millar et al. [49] Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten, and Kilian Q. Weinberger. 2017. Multi-Scale Dense Convolutional Networks for Efficient Prediction. CoRR abs 1703.09844 (2017).\n\n--- Segment 38 ---\nMulti-Scale Dense Convolutional Networks for Efficient Prediction. CoRR abs 1703.09844 (2017). arXiv:1703.09844 [50] Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten, and Kilian Q. Weinberger. 2017. Multi-Scale Dense Convolutional Networks for Efficient Prediction. CoRR abs 1703.09844 (2017). arXiv:1703.09844 [51] Forrest N. Iandola, Matthew W. Moskewicz, Khalid Ashraf, Song Han, William J. Dally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and 1MB model size. CoRR abs 1602.07360 (2016). arXiv:1602.07360 [52] Bashima Islam and Shahriar Nirjon. 2020. Zygarde: Time-Sensitive On-Device Deep Inference and Adaptation on Intermittently-Powered Systems. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 3, Article 82 (sep 2020), 29 pages. doi:10.1145 3411808 [53] Yesmina Jaafra, Jean Luc Laurent, Aline Deruyver, and Mohamed Saber Naceur. 2019. Reinforcement learning for neural architecture search: A review. Image and Vision Computing 89 (2019), 57 66. doi:10.1016 j.imavis.2019.06.005 [54] Daniele Jahier Pagliari, Francesco Daghero, and Massimo Poncino. 2020. Sequence-To-Sequence Neural Networks Inference on Embedded Processors Using Dynamic Beam Search. Electronics 9, 2 (2020). doi:10.3390 electronics9020337 [55] Daniele Jahier Pagliari, Francesco Panini, Enrico Macii, and Massimo Poncino. 2019. Dynamic Beam Width Tuning for Energy-Efficient Recurrent Neural Networks. In Proceedings of the 2019 on Great Lakes Symposium on VLSI (Tysons Corner, VA, USA) (GLSVLSI 19).\n\n--- Segment 39 ---\nDynamic Beam Width Tuning for Energy-Efficient Recurrent Neural Networks. In Proceedings of the 2019 on Great Lakes Symposium on VLSI (Tysons Corner, VA, USA) (GLSVLSI 19). Association for Computing Machinery, New York, NY, USA, 69 74. doi:10.1145 3299874.3317974 [56] Daniele Jahier Pagliari, Francesco Panini, Enrico Macii, and Massimo Poncino. 2019. Dynamic Beam Width Tuning for Energy-Efficient Recurrent Neural Networks. In Proceedings of the 2019 on Great Lakes Symposium on VLSI (Tysons Corner, VA, USA) (GLSVLSI 19). Association for Computing Machinery, New York, NY, USA, 69 74. doi:10.1145 3299874.3317974 [57] Seunghyeok Jeon, Yonghun Choi, Yeonwoo Cho, and Hojung Cha. 2023. HarvNet: Resource-Optimized Operation of Multi-Exit Deep Neural Networks on Energy Harvesting Devices. In Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services (Helsinki, Finland) (MobiSys 23). Association for Computing Machinery, New York, NY, USA, 42 55. doi:10. 1145 3581791.3596845 [58] Heinrich Jiang, Been Kim, Melody Y. Guan, and Maya Gupta. 2018. To Trust Or Not To Trust A Classifier. arXiv:1805.11783 [stat.ML] [59] Petar Jokic, Stephane Emery, and Luca Benini. 2021. Battery-Less Face Recognition at the Extreme Edge. In 2021 19th IEEE International New Circuits and Systems Conference (NEWCAS). 1 4. doi:10.1109 NEWCAS50681.2021.9462787 [60] Beomseok Kang, Anni Lu, Yun Long, Daehyun Kim, Shimeng Yu, and Saibal Mukhopadhyay. 2021. Genetic Algorithm-Based Energy- Aware CNN Quantization for Processing-In-Memory Architecture.\n\n--- Segment 40 ---\n2021. Genetic Algorithm-Based Energy- Aware CNN Quantization for Processing-In-Memory Architecture. IEEE Journal on Emerging and Selected Topics in Circuits and Systems 11, 4 (2021), 649 662. doi:10.1109 JETCAS.2021.3127129 [61] Yiping Kang, Johann Hauswald, Cao Gao, Austin Rovinski, Trevor Mudge, Jason Mars, and Lingjia Tang. 2017. Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge. SIGPLAN Not. 52, 4 (apr 2017), 615 629. doi:10.1145 3093336.3037698 [62] Mohsen Karimi, Hyunjong Choi, Yidi Wang, Yecheng Xiang, and Hyoseung Kim. 2021. Real-Time Task Scheduling on Intermittently Powered Batteryless Devices. IEEE Internet of Things Journal 8, 17 (2021), 13328 13342. doi:10.1109 JIOT.2021.3065947 [63] Yigitcan Kaya and Tudor Dumitras. 2018. How to Stop Off-the-Shelf Deep Neural Networks from Overthinking. CoRR abs 1810.07052 (2018). arXiv:1810.07052 [64] Aria Khoshsirat, Giovanni Perin, and Michele Rossi. 2023. Divide and Save: Splitting Workload Among Containers in an Edge Device to Save Energy and Time. arXiv:2302.06478 [cs.DC] [65] Donghyuk Kim, Chengshuo Yu, Shanshan Xie, Yuzong Chen, Joo-Young Kim, Bongjin Kim, Jaydeep P. Kulkarni, and Tony Tae-Hyoung Kim. 2022. An Overview of Processing-in-Memory Circuits for Artificial Intelligence and Machine Learning.\n\n--- Segment 41 ---\n2022. An Overview of Processing-in-Memory Circuits for Artificial Intelligence and Machine Learning. IEEE Journal on Emerging and Selected Topics in Circuits and Systems 12, 2 (2022), 338 353. doi:10.1109 JETCAS.2022.3160455 [66] James Kirkpatrick, Razvan Pascanu, Neil C. Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. 2016. Overcoming catastrophic forgetting in neural networks. CoRR abs 1612.00796 (2016). arXiv:1612.00796 [67] Raghuraman Krishnamoorthi. 2018. Quantizing deep convolutional networks for efficient inference: A whitepaper. arXiv:1806.08342 [cs.LG] [68] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. ImageNet Classification with Deep Convolutional Neural Networks. In Advances in Neural Information Processing Systems, F. Pereira, C.J. Burges, L. Bottou, and K.Q. Weinberger (Eds. ), Vol. 25. Curran Associates, Inc. [69] Ananya Kumar, Aditi Raghunathan, Robbie Jones, Tengyu Ma, and Percy Liang. 2022. Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution. arXiv:2202.10054 [cs.LG] [70] Young D. Kwon, Jagmohan Chauhan, Hong Jia, Stylianos I. Venieris, and Cecilia Mascolo. 2023. LifeLearner: Hardware-Aware Meta Continual Learning System for Embedded Computing Platforms. arXiv:2311.11420 [cs.LG] [71] Young D. Kwon, Rui Li, Stylianos I. Venieris, Jagmohan Chauhan, Nicholas D. Lane, and Cecilia Mascolo. 2023. TinyTrain: Deep Neural Network Training at the Extreme Edge.\n\n--- Segment 42 ---\n2023. TinyTrain: Deep Neural Network Training at the Extreme Edge. arXiv:2307.09988 [cs.LG] [72] Stefanos Laskaridis, Alexandros Kouris, and Nicholas D. Lane. 2021. Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions. In Proceedings of the 5th International Workshop on Embedded and Mobile Deep Learning (Virtual, WI, USA) Energy-Aware Deep Learning on Resource-Constrained Hardware 19 (EMDL 21). Association for Computing Machinery, New York, NY, USA, 1 6. doi:10.1145 3469116.3470012 [73] Stefanos Laskaridis, Stylianos I. Venieris, Hyeji Kim, and Nicholas D. Lane. 2020. HAPI: Hardware-Aware Progressive Inference. CoRR abs 2008.03997 (2020). arXiv:2008.03997 [74] Jaejun Lee, Raphael Tang, and Jimmy Lin. 2019. What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning. CoRR abs 1911.03090 (2019). arXiv:1911.03090 [75] Seulki Lee, Bashima Islam, Yubo Luo, and Shahriar Nirjon. 2020. Intermittent Learning: On-Device Machine Learning on Intermittently Powered System. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 3, 4, Article 141 (sep 2020), 30 pages. doi:10.1145 3369837 [76] Yoonho Lee, Annie S. Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao, Percy Liang, and Chelsea Finn. 2023. Surgical Fine-Tuning Improves Adaptation to Distribution Shifts. arXiv:2210.11466 [cs.LG] [77] Ilias Leontiadis, Stefanos Laskaridis, Stylianos I. Venieris, and Nicholas D. Lane. 2021. It s always personal: Using Early Exits for Efficient On-Device CNN Personalisation. CoRR abs 2102.01393 (2021).\n\n--- Segment 43 ---\nIt s always personal: Using Early Exits for Efficient On-Device CNN Personalisation. CoRR abs 2102.01393 (2021). arXiv:2102.01393 [78] Chaojian Li, Zhongzhi Yu, Yonggan Fu, Yongan Zhang, Yang Zhao, Haoran You, Qixuan Yu, Yue Wang, and Yingyan Lin. 2021. HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark. CoRR abs 2103.10584 (2021). arXiv:2103.10584 https: arxiv.org abs 2103.10584 [79] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M. Hospedales. 2017. Learning to Generalize: Meta-Learning for Domain Generalization. arXiv:1710.03463 [cs.LG] [80] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. 2020. On the Convergence of FedAvg on Non-IID Data. arXiv:1907.02189 [stat.ML] [81] Xiangjie Li, Chenfei Lou, Zhengping Zhu, Yuchi Chen, Yingtao Shen, Yehan Ma, and An Zou. 2022. Predictive Exit: Prediction of Fine-Grained Early Exits for Computation- and Energy-Efficient Inference. arXiv:2206.04685 [cs.LG] [82] Edgar Liberis, Lukasz Dudziak, and Nicholas D. Lane. 2020. ùúáNAS: Constrained Neural Architecture Search for Microcontrollers. CoRR abs 2010.14246 (2020). arXiv:2010.14246 [83] Ji Lin, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, and Song Han. 2020. MCUNet: Tiny Deep Learning on IoT Devices. CoRR abs 2007.10319 (2020). arXiv:2007.10319 [84] Ji Lin, Yongming Rao, Jiwen Lu, and Jie Zhou. 2017. Runtime Neural Pruning. In Advances in Neural Information Processing Systems, I. Guyon, U.\n\n--- Segment 44 ---\nRuntime Neural Pruning. In Advances in Neural Information Processing Systems, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds. ), Vol. 30. Curran Associates, Inc. [85] Ji Lin, Ligeng Zhu, Wei-Ming Chen, Wei-Chen Wang, Chuang Gan, and Song Han. 2024. On-Device Training Under 256KB Memory. arXiv:2206.15472 [cs.CV] [86] Qiang Liu, Lemeng Wu, and Dilin Wang. 2019. Splitting Steepest Descent for Growing Neural Architectures. CoRR abs 1910.02366 (2019). arXiv:1910.02366 [87] Weijie Liu, Xiaoxi Zhang, Jingpu Duan, Carlee Joe-Wong, Zhi Zhou, and Xu Chen. 2023. AdaCoOpt: Leverage the Interplay of Batch Size and Aggregation Frequency for Federated Learning. In 2023 IEEE ACM 31st International Symposium on Quality of Service (IWQoS). 1 10. doi:10.1109 IWQoS57198.2023.10188807 [88] Weijie Liu, Xiaoxi Zhang, Jingpu Duan, Carlee Joe-Wong, Zhi Zhou, and Xu Chen. 2023. DYNAMITE: Dynamic Interplay of Mini-Batch Size and Aggregation Frequency for Federated Learning with Static and Streaming Dataset. arXiv:2310.14906 [cs.LG] [89] Yuhan Liu, Saurabh Agarwal, and Shivaram Venkataraman. 2021. AutoFreeze: Automatically Freezing Model Blocks to Accelerate Fine-tuning. CoRR abs 2102.01386 (2021). arXiv:2102.01386 [90] Yuqiao Liu, Yanan Sun, Bing Xue, Mengjie Zhang, and Gary G. Yen. 2020. A Survey on Evolutionary Neural Architecture Search. CoRR abs 2008.10937 (2020). arXiv:2008.10937 [91] Bing Luo, Xiang Li, Shiqiang Wang, Jianwei Huang, and Leandros Tassiulas.\n\n--- Segment 45 ---\nCoRR abs 2008.10937 (2020). arXiv:2008.10937 [91] Bing Luo, Xiang Li, Shiqiang Wang, Jianwei Huang, and Leandros Tassiulas. 2020. Cost-Effective Federated Learning Design. CoRR abs 2012.08336 (2020). arXiv:2012.08336 [92] Kaisheng Ma, Xueqing Li, Jinyang Li, Yongpan Liu, Yuan Xie, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. 2017. Incidental Computing on IoT Nonvolatile Processors. In 2017 50th Annual IEEE ACM International Symposium on Microarchitecture (MICRO). 204 218. [93] Kaisheng Ma, Yang Zheng, Shuangchen Li, Karthik Swaminathan, Xueqing Li, Yongpan Liu, Jack Sampson, Yuan Xie, and Vijaykrishnan Narayanan. 2015. Architecture exploration for ambient energy harvesting nonvolatile processors. In 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA). 526 537. doi:10.1109 HPCA.2015.7056060 [94] Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun. 2018. ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design. arXiv:1807.11164 [cs.CV] [95] Divyat Mahajan, Shruti Tople, and Amit Sharma. 2020. Domain Generalization using Causal Matching. CoRR abs 2006.07500 (2020). arXiv:2006.07500 [96] Andrea Maioli and Luca Mottola. 2021. ALFRED: Virtual Memory for Intermittent Computing. In Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems (SenSys 21). ACM. doi:10.1145 3485730.3485949 20 Millar et al. [97] Lucas Mansilla, Rodrigo Echeveste, Diego H. Milone, and Enzo Ferrante. 2021. Domain Generalization via Gradient Surgery. CoRR abs 2108.01621 (2021).\n\n--- Segment 46 ---\nDomain Generalization via Gradient Surgery. CoRR abs 2108.01621 (2021). arXiv:2108.01621 [98] Alberto Marchisio, Andrea Massa, Vojtech Mrazek, Beatrice Bussolino, Maurizio Martina, and Muhammad Shafique. 2020. NASCaps: A Framework for Neural Architecture Search to Optimize the Accuracy and Hardware Efficiency of Convolutional Capsule Networks. CoRR abs 2008.08476 (2020). arXiv:2008.08476 [99] H. Brendan McMahan, Eider Moore, Daniel Ramage, and Blaise Ag√ºera y Arcas. 2016. Federated Learning of Deep Networks using Model Averaging. CoRR abs 1602.05629 (2016). arXiv:1602.05629 [100] Lingchen Meng, Hengduo Li, Bor-Chun Chen, Shiyi Lan, Zuxuan Wu, Yu-Gang Jiang, and Ser-Nam Lim. 2021. AdaViT: Adaptive Vision Transformers for Efficient Image Recognition. CoRR abs 2111.15668 (2021). arXiv:2111.15668 [101] Mateusz Michalkiewicz, Masoud Faraki, Xiang Yu, Manmohan Chandraker, and Mahsa Baktashmotlagh. 2023. Domain Generalization Guided by Gradient Signal to Noise Ratio of Parameters. arXiv:2310.07361 [cs.CV] [102] Microsoft. 2024. EdgeML. [103] David Moloney. 2016. Embedded deep neural networks: The cost of everything and the value of nothing . In 2016 IEEE Hot Chips 28 Symposium (HCS). 1 20. doi:10.1109 HOTCHIPS.2016.7936219 [104] Alessandro Montanari, Manuja Sharma, Dainius Jenkus, Mohammed Alloulah, Lorena Qendro, and Fahim Kawsar. 2020. ePerceptive: energy reactive embedded intelligence for batteryless sensors. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (Virtual Event, Japan) (SenSys 20). Association for Computing Machinery, New York, NY, USA, 382 394. doi:10.1145 3384419.\n\n--- Segment 47 ---\nIn Proceedings of the 18th Conference on Embedded Networked Sensor Systems (Virtual Event, Japan) (SenSys 20). Association for Computing Machinery, New York, NY, USA, 382 394. doi:10.1145 3384419. 3430782 [105] Augustus Odena, Dieterich Lawson, and Christopher Olah. 2017. Changing Model Behavior at Test-Time Using Reinforcement Learning. arXiv:1702.07780 [stat.ML] [106] Daniele Jahier Pagliari, Enrico Macii, and Massimo Poncino. 2018. Dynamic Bit-width Reconfiguration for Energy-Efficient Deep Learning Hardware. In Proceedings of the International Symposium on Low Power Electronics and Design (Seattle, WA, USA) (ISLPED 18). Association for Computing Machinery, New York, NY, USA, Article 47, 6 pages. doi:10.1145 3218603.3218611 [107] Priyadarshini Panda, Abhronil Sengupta, and Kaushik Roy. 2015. Conditional Deep Learning for Energy-Efficient and Enhanced Pattern Recognition. CoRR abs 1509.08971 (2015). arXiv:1509.08971 [108] Priyadarshini Panda, Abhronil Sengupta, and Kaushik Roy. 2015. Conditional Deep Learning for Energy-Efficient and Enhanced Pattern Recognition. CoRR abs 1509.08971 (2015). arXiv:1509.08971 [109] Yanwei Pang, Haoran Wang, Yunlong Yu, and Zhong Ji. 2019. A decadal survey of zero-shot image classification. SCIENTIA SINICA Informationis (2019). [110] Eunhyeok Park, Dongyoung Kim, Soobeom Kim, Yong-Deok Kim, Gunhee Kim, Sungroh Yoon, and Sungjoo Yoo. 2015. Big little deep neural network for ultra low power inference. In 2015 International Conference on Hardware Software Codesign and System Synthesis (CODES ISSS). 124 132. doi:10.1109 CODESISSS.2015.7331375 [111] Christos Profentzas, Magnus Almgren, and Olaf Landsiedel. 2023.\n\n--- Segment 48 ---\n124 132. doi:10.1109 CODESISSS.2015.7331375 [111] Christos Profentzas, Magnus Almgren, and Olaf Landsiedel. 2023. MiniLearn: On-Device Learning for Low-Power IoT Devices. In Proceedings of the 2022 International Conference on Embedded Wireless Systems and Networks (, Linz, Austria,) (EWSN 22). Association for Computing Machinery, New York, NY, USA, 1 11. [112] A√´l Qu√©lennec, Enzo Tartaglione, Pavlo Mozharovskyi, and Van-Tam Nguyen. 2023. Towards On-device Learning on the Edge: Ways to Select Neurons to Update under a Budget Constraint. arXiv:2312.05282 [cs.LG] [113] Jathushan Rajasegaran, Vinoj Jayasundara, Sandaru Jayasekara, Hirunima Jayasekara, Suranga Seneviratne, and Ranga Rodrigo. 2019. DeepCaps: Going Deeper with Capsule Networks. arXiv:1904.09546 [cs.CV] [114] Vinay V. Ramasesh, Ethan Dyer, and Maithra Raghu. 2020. Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics. CoRR abs 2007.07400 (2020). arXiv:2007.07400 [115] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016. XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks. arXiv:1603.05279 [cs.CV] [116] Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Xiaojiang Chen, and Xin Wang. 2020. A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions. CoRR abs 2006.02903 (2020). arXiv:2006.02903 [117] Crefeda Faviola Rodrigues, Graham Riley, and Mikel Lujan. 2018. Fine-Grained Energy and Performance Profiling framework for Deep Convolutional Neural Networks.\n\n--- Segment 49 ---\n2018. Fine-Grained Energy and Performance Profiling framework for Deep Convolutional Neural Networks. arXiv:1803.11151 [cs.PF] [118] Bita Darvish Rouhani, Azalia Mirhoseini, and Farinaz Koushanfar. 2016. DeLight: Adding Energy Dimension To Deep Neural Networks. In Proceedings of the 2016 International Symposium on Low Power Electronics and Design (San Francisco Airport, CA, USA) (ISLPED 16). Association for Computing Machinery, New York, NY, USA, 112 117. doi:10.1145 2934583.2934599 [119] Amelie Royer and Christoph H. Lampert. 2020. A Flexible Selection Scheme for Minimum-Effort Transfer Learning. CoRR abs 2008.11995 (2020). arXiv:2008.11995 [120] Sara Sabour, Nicholas Frosst, and Geoffrey E. Hinton. 2017. Dynamic Routing Between Capsules. CoRR abs 1710.09829 (2017). arXiv:1710.09829 Energy-Aware Deep Learning on Resource-Constrained Hardware 21 [121] Adnan Sabovic, Michiel Aernouts, Dragan Subotic, Jaron Fontaine, Eli De Poorter, and Jeroen Famaey. 2023. Towards energy-aware tinyML on battery-less IoT devices. Internet of Things 22 (2023), 100736. doi:10.1016 j.iot.2023.100736 [122] Adnan Sabovic, Ashish Kumar Sultania, Carmen Delgado, Lander De Roeck, and Jeroen Famaey. 2022. An Energy-Aware Task Scheduler for Energy-Harvesting Batteryless IoT Devices. IEEE Internet of Things Journal 9, 22 (2022), 23097 23114. doi:10.1109 JIOT.2022.3185321 [123] Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry. 2020. Do Adversarially Robust ImageNet Models Transfer Better? CoRR abs 2007.08489 (2020). arXiv:2007.08489 [124] Eric Samikwa, Antonio Di Maio, and Torsten Braun. 2022.\n\n--- Segment 50 ---\narXiv:2007.08489 [124] Eric Samikwa, Antonio Di Maio, and Torsten Braun. 2022. Adaptive Early Exit of Computation for Energy-Efficient and Low-Latency Machine Learning over IoT Networks. In 2022 IEEE 19th Annual Consumer Communications Networking Conference (CCNC). 200 206. doi:10.1109 CCNC49033.2022.9700550 [125] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2019. MobileNetV2: Inverted Residuals and Linear Bottlenecks. arXiv:1801.04381 [cs.CV] [126] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2019. MobileNetV2: Inverted Residuals and Linear Bottlenecks. arXiv:1801.04381 [cs.CV] [127] Felix Sattler, Simon Wiedemann, Klaus-Robert M√ºller, and Wojciech Samek. 2019. Robust and Communication-Efficient Federated Learning from Non-IID Data. CoRR abs 1903.02891 (2019). arXiv:1903.02891 [128] Noam Shazeer, Kayvon Fatahalian, William R. Mark, and Ravi Teja Mullapudi. 2018. HydraNets: Specialized Dynamic Architectures for Efficient Inference. In 2018 IEEE CVF Conference on Computer Vision and Pattern Recognition. 8080 8089. doi:10.1109 CVPR.2018.00843 [129] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geoffrey E. Hinton, and Jeff Dean. 2017. Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer. CoRR abs 1701.06538 (2017). arXiv:1701.06538 abs 1701.06538 [130] Paras Sheth and Huan Liu. 2023. Causal Domain Generalization.\n\n--- Segment 51 ---\n2023. Causal Domain Generalization. Springer International Publishing, Cham, 161 185. doi:10.1007 978-3- 031-35051-1_8 [131] Paras Sheth, Raha Moraffah, K. Sel√ßuk Candan, Adrienne Raglin, and Huan Liu. 2022. Domain Generalization A Causal Perspective. arXiv:2209.15177 [cs.LG] [132] Dian Shi, Liang Li, Rui Chen, Pavana Prakash, Miao Pan, and Yuguang Fang. 2022. Toward Energy-Efficient Federated Learning Over 5G Mobile Devices. IEEE Wireless Communications 29, 5 (2022), 44 51. doi:10.1109 MWC.003.2100028 [133] Dian Shi, Liang Li, Maoqiang Wu, Minglei Shu, Rong Yu, Miao Pan, and Zhu Han. 2022. To Talk or to Work: Dynamic Batch Sizes Assisted Time Efficient Federated Learning Over Future Mobile Edge Devices. IEEE Transactions on Wireless Communications 21, 12 (2022), 11038 11050. doi:10.1109 TWC.2022.3189320 [134] Yuge Shi, Jeffrey Seely, Philip H. S. Torr, N. Siddharth, Awni Y. Hannun, Nicolas Usunier, and Gabriel Synnaeve. 2021. Gradient Matching for Domain Generalization. CoRR abs 2104.09937 (2021). arXiv:2104.09937 [135] G. Spadaro, R. Renzulli, A. Bragagnolo, J. H. Giraldo, A. Fiandrotti, M. Grangetto, and E. Tartaglione. 2023. Shannon Strikes Again! Entropy-based Pruning in Deep Neural Networks for Transfer Learning under Extreme Memory and Computation Budgets. In 2023 IEEE CVF International Conference on Computer Vision Workshops (ICCVW). IEEE Computer Society, Los Alamitos, CA, USA, 1510 1514. doi:10.1109 ICCVW60793.2023.00165 [136] STMicroelectronics. 2024. STM32CubeMX.\n\n--- Segment 52 ---\n2024. STM32CubeMX. [137] Ashish Kumar Sultania and Jeroen Famaey. 2022. Batteryless Bluetooth Low Energy Prototype With Energy-Aware Bidirectional Communication Powered by Ambient Light. IEEE Sensors Journal 22, 7 (2022), 6685 6697. doi:10.1109 JSEN.2022.3153097 [138] Yuxuan Sun, Sheng Zhou, and Deniz G√ºnd√ºz. 2019. Energy-Aware Analog Aggregation for Federated Learning with Redundant Data. arXiv:1911.00188 [cs.IT] [139] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2014. Going Deeper with Convolutions. CoRR abs 1409.4842 (2014). arXiv:1409.4842 [140] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, and Quoc V. Le. 2018. MnasNet: Platform-Aware Neural Architecture Search for Mobile. CoRR abs 1807.11626 (2018). arXiv:1807.11626 [141] Mingxing Tan and Quoc V. Le. 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. CoRR abs 1905.11946 (2019). arXiv:1905.11946 [142] Hokchhay Tann, Soheil Hashemi, R. Iris Bahar, and Sherief Reda. 2016. Runtime Configurable Deep Neural Networks for Energy- Accuracy Trade-off. CoRR abs 1607.05418 (2016). arXiv:1607.05418 [143] Surat Teerapittayanon, Bradley McDanel, and H. T. Kung. 2017. BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks. CoRR abs 1709.01686 (2017). arXiv:1709.01686 [144] Surat Teerapittayanon, Bradley McDanel, and H. T. Kung. 2017.\n\n--- Segment 53 ---\narXiv:1709.01686 [144] Surat Teerapittayanon, Bradley McDanel, and H. T. Kung. 2017. BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks. CoRR abs 1709.01686 (2017). arXiv:1709.01686 [145] Nazli Tekin, Ahmet Aris, Abbas Acar, Selcuk Uluagac, and Vehbi Cagri Gungor. 2024. A review of on-device machine learning for IoT: An energy perspective. Ad Hoc Networks 153 (2024), 103348. doi:10.1016 j.adhoc.2023.103348 22 Millar et al. [146] Nguyen H. Tran, Wei Bao, Albert Zomaya, Minh N. H. Nguyen, and Choong Seon Hong. 2019. Federated Learning over Wireless Networks: Optimization Model Design and Analysis. In IEEE INFOCOM 2019 - IEEE Conference on Computer Communications. 1387 1395. doi:10.1109 INFOCOM.2019.8737464 [147] Hoang Truong, Shuo Zhang, Ufuk Muncuk, Phuc Nguyen, Nam Bui, Anh Nguyen, Qin Lv, Kaushik Chowdhury, Thang Dinh, and Tam Vu. 2018. CapBand: Battery-free Successive Capacitance Sensing Wristband for Hand Gesture Recognition. In Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems (Shenzhen, China) (SenSys 18).\n\n--- Segment 54 ---\nCapBand: Battery-free Successive Capacitance Sensing Wristband for Hand Gesture Recognition. In Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems (Shenzhen, China) (SenSys 18). Association for Computing Machinery, New York, NY, USA, 54 67. doi:10.1145 3274783.3274854 [148] Arya Tschand, Arun Tejusve Raghunath Rajan, Sachin Idgunji, Anirban Ghosh, Jeremy Holleman, Csaba Kiraly, Pawan Ambalkar, Ritika Borkar, Ramesh Chukka, Trevor Cockrell, Oliver Curtis, Grigori Fursin, Miro Hodak, Hiwot Kassa, Anton Lokhmotov, Dejan Miskovic, Yuechao Pan, Manu Prasad Manmathan, Liz Raymond, Tom St. John, Arjun Suresh, Rowan Taubitz, Sean Zhan, Scott Wasson, David Kanter, and Vijay Janapa Reddi. 2025. MLPerf Power: Benchmarking the Energy Efficiency of Machine Learning Systems from Microwatts to Megawatts for Sustainable AI. arXiv:2410.12032 [cs.AR] [149] X. Tu, A. Mallik, D. Chen, K. Han, O. Altintas, H. Wang, and J. Xie. 2023. Unveiling Energy Efficiency in Deep Learning: Measurement, Prediction, and Scoring Across Edge Devices. In 2023 IEEE ACM Symposium on Edge Computing (SEC). IEEE Computer Society, Los Alamitos, CA, USA, 80 93. doi:10.1145 3583740.3628442 [150] Ultralytics. 2021. YOLOv5: A state-of-the-art real-time object detection system. Accessed: insert date here. [151] uTensor. 2024. uTensor. [152] Shubham Vaishnav, Maria Efthymiou, and Sindri Magn√∫sson. 2023. Energy-Efficient and Adaptive Gradient Sparsification for Federated Learning. In ICC 2023 - IEEE International Conference on Communications.\n\n--- Segment 55 ---\nEnergy-Efficient and Adaptive Gradient Sparsification for Federated Learning. In ICC 2023 - IEEE International Conference on Communications. 1256 1261. doi:10.1109 ICC45041.2023.10278999 [153] Joel Van Der Woude and Matthew Hicks. 2016. Intermittent computation without hardware support or programmer intervention. In Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation (Savannah, GA, USA) (OSDI 16). USENIX Association, USA, 17 32. [154] Philipp van Kempen, Rafael Stahl, Daniel Mueller-Gritschneder, and Ulf Schlichtmann. 2023. MLonMCU: TinyML Benchmarking with Fast Retargeting. In Proceedings of the 2023 Workshop on Compilers, Deployment, and Tooling for Edge AI (CODAI 23). ACM. doi:10.1145 3615338.3618128 [155] Dilin Wang, Meng Li, Lemeng Wu, Vikas Chandra, and Qiang Liu. 2019. Energy-Aware Neural Architecture Optimization with Fast Splitting Steepest Descent. CoRR abs 1910.03103 (2019). arXiv:1910.03103 [156] Qipeng Wang, Mengwei Xu, Chao Jin, Xinran Dong, Jinliang Yuan, Xin Jin, Gang Huang, Yunxin Liu, and Xuanzhe Liu. 2022. Melon: breaking the memory wall for resource-efficient on-device machine learning. In Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services (Portland, Oregon) (MobiSys 22). Association for Computing Machinery, New York, NY, USA, 450 463. doi:10.1145 3498361.3538928 [157] Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung, Christian Makaya, Ting He, and Kevin Chan. 2019. Adaptive Federated Learning in Resource Constrained Edge Computing Systems. IEEE Journal on Selected Areas in Communications 37, 6 (2019), 1205 1221. doi:10.1109 JSAC.2019.2904348 [158] Wei Wang, Vincent W. Zheng, Han Yu, and Chunyan Miao. 2019.\n\n--- Segment 56 ---\nIEEE Journal on Selected Areas in Communications 37, 6 (2019), 1205 1221. doi:10.1109 JSAC.2019.2904348 [158] Wei Wang, Vincent W. Zheng, Han Yu, and Chunyan Miao. 2019. A Survey of Zero-Shot Learning: Settings, Methods, and Applications. ACM Trans. Intell. Syst. Technol. 10, 2, Article 13 (jan 2019), 37 pages. doi:10.1145 3293318 [159] Xin Wang, Fisher Yu, Zi-Yi Dou, and Joseph E. Gonzalez. 2017. SkipNet: Learning Dynamic Routing in Convolutional Networks. CoRR abs 1711.09485 (2017). arXiv:1711.09485 [160] Yulin Wang, Rui Huang, Shiji Song, Zeyi Huang, and Gao Huang. 2021. Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with Adaptive Sequence Length. CoRR abs 2105.15075 (2021). arXiv:2105.15075 [161] Christopher J. C. H. Watkins and Peter Dayan. 1992. Q-learning. Machine Learning 8, 3 (01 May 1992), 279 292. doi:10.1007 BF00992698 [162] Kang Wei, Jun Li, Chuan Ma, Ming Ding, Feng Shu, Haitao Zhao, Wen Chen, and Hongbo Zhu. 2024. Gradient sparsification for efficient wireless federated learning with differential privacy. Science China Information Sciences 67, 4 (March 2024). doi:10.1007 s11432-023- 3918-9 [163] Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre-Alvise Rebuffi, Ira Ktena, Krishnamurthy Dvijotham, and A. Taylan Cemgil. 2021. A Fine-Grained Analysis on Distribution Shift. CoRR abs 2110.11328 (2021). arXiv:2110.11328 [164] R. J. Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning 8 (1992), 229 256.\n\n--- Segment 57 ---\nSimple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning 8 (1992), 229 256. [165] Maciej Wolczyk, Bartosz W√≥jcik, Klaudia Balazy, Igor T. Podolak, Jacek Tabor, Marek Smieja, and Tomasz Trzcinski. 2021. Zero Time Waste: Recycling Predictions in Early Exit Neural Networks. CoRR abs 2106.05409 (2021). arXiv:2106.05409 05409 [166] Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing Jia, and Kurt Keutzer. 2019. FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search. arXiv:1812.03443 [cs.CV] [167] Zuxuan Wu, Tushar Nagarajan, Abhishek Kumar, Steven Rennie, Larry S. Davis, Kristen Grauman, and Rogerio Feris. 2019. BlockDrop: Dynamic Inference Paths in Residual Networks. arXiv:1711.08393 [cs.CV] Energy-Aware Deep Learning on Resource-Constrained Hardware 23 [168] Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. 2020. In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness. CoRR abs 2012.04550 (2020). arXiv:2012.04550 https: arxiv.org abs 2012.04550 [169] Ji Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, and Jimmy Lin. 2020. DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference. CoRR abs 2004.12993 (2020). arXiv:2004.12993 [170] Ji Xin, Raphael Tang, Yaoliang Yu, and Jimmy J. Lin. 2021. BERxiT: Early Exiting for BERT with Better Fine-Tuning and Extension to Regression. In Conference of the European Chapter of the Association for Computational Linguistics.\n\n--- Segment 58 ---\nBERxiT: Early Exiting for BERT with Better Fine-Tuning and Extension to Regression. In Conference of the European Chapter of the Association for Computational Linguistics. CorpusID:233189542 [171] Mengwei Xu, Feng Qian, Mengze Zhu, Feifan Huang, Saumay Pushp, and Xuanzhe Liu. 2020. DeepWear: Adaptive Local Offloading for On-Wearable Deep Learning. IEEE Transactions on Mobile Computing 19, 2 (2020), 314 330. doi:10.1109 TMC.2019.2893250 [172] Fan Yang, Ashok Samraj Thangarajan, Gowri Sankar Ramachandran, Wouter Joosen, and Danny Hughes. 2021. AsTAR: Sustainable Energy Harvesting for the Internet of Things through Adaptive Task Scheduling. ACM Trans. Sen. Netw. 18, 1, Article 4 (oct 2021), 34 pages. doi:10.1145 3467894 [173] Tien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. 2016. Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning. CoRR abs 1611.05128 (2016). arXiv:1611.05128 [174] Tien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. 2016. Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning. CoRR abs 1611.05128 (2016). arXiv:1611.05128 [175] Tien-Ju Yang, Yu-Hsin Chen, Joel Emer, and Vivienne Sze. 2017. A method to estimate the energy consumption of deep neural networks. In 2017 51st Asilomar Conference on Signals, Systems, and Computers. 1916 1920. doi:10.1109 ACSSC.2017.8335698 [176] Tien-Ju Yang, Yu-Hsin Chen, Joel Emer, and Vivienne Sze. 2017. A method to estimate the energy consumption of deep neural networks. In 2017 51st Asilomar Conference on Signals, Systems, and Computers.\n\n--- Segment 59 ---\nA method to estimate the energy consumption of deep neural networks. In 2017 51st Asilomar Conference on Signals, Systems, and Computers. 1916 1920. doi:10.1109 ACSSC.2017.8335698 [177] Zhaohui Yang, Mingzhe Chen, Walid Saad, Choong Seon Hong, and Mohammad Shikh-Bahaei. 2019. Energy Efficient Federated Learning Over Wireless Communication Networks. CoRR abs 1911.02417 (2019). arXiv:1911.02417 [178] Shuochao Yao, Jinyang Li, Dongxin Liu, Tianshi Wang, Shengzhong Liu, Huajie Shao, and Tarek Abdelzaher. 2020. Deep compressive offloading: speeding up neural network inference by trading edge computation for network latency. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (Virtual Event, Japan) (SenSys 20). Association for Computing Machinery, New York, NY, USA, 476 488. doi:10.1145 3384419.3430898 [179] Seul-Ki Yeom, Kyung-Hwan Shim, and Jee-Hyun Hwang. 2021. Toward Compact Deep Neural Networks via Energy-Aware Pruning. CoRR abs 2103.10858 (2021). arXiv:2103.10858 [180] Amirreza Yousefzadeh, Jan Stuijt, Martijn Hijdra, Hsiao-Hsuan Liu, Anteneh Gebregiorgis, Abhairaj Singh, Said Hamdioui, and Francky Catthoor. 2022. Energy-efficient In-Memory Address Calculation. ACM Trans. Archit. Code Optim. 19, 4, Article 52 (sep 2022), 16 pages. doi:10.1145 3546071 [181] Jiahui Yu, Linjie Yang, Ning Xu, Jianchao Yang, and Thomas S. Huang. 2018. Slimmable Neural Networks. CoRR abs 1812.08928 (2018). arXiv:1812.08928 [182] Rong Yu and Peichun Li. 2021. Toward Resource-Efficient Federated Learning in Mobile Edge Computing.\n\n--- Segment 60 ---\n2021. Toward Resource-Efficient Federated Learning in Mobile Edge Computing. IEEE Network 35, 1 (2021), 148 155. doi:10.1109 MNET.011.2000295 [183] Jinliang Yuan, Shangguang Wang, Hongyu Li, Daliang Xu, Yuanchun Li, Mengwei Xu, and Xuanzhe Liu. 2024. Towards Energy-efficient Federated Learning via INT8-based Training on Mobile DSPs. In Proceedings of the ACM Web Conference 2024 (Singapore, Singapore) (WWW 24). Association for Computing Machinery, New York, NY, USA, 2786 2794. doi:10.1145 3589334.3645341 [184] Arber Zela, Julien Siems, and Frank Hutter. 2020. NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search. CoRR abs 2001.10422 (2020). arXiv:2001.10422 [185] Liekang Zeng, En Li, Zhi Zhou, and Xu Chen. 2019. Boomerang: On-Demand Cooperative Deep Neural Network Inference for Edge Intelligence on the Industrial Internet of Things. IEEE Network 33, 5 (2019), 96 103. doi:10.1109 MNET.001.1800506 [186] Qunsong Zeng, Yuqing Du, Kin K. Leung, and Kaibin Huang. 2019. Energy-Efficient Radio Resource Allocation for Federated Edge Learning. arXiv:1907.06040 [cs.IT] [187] Yu Zhang, Tao Gu, and Xi Zhang. 2022. MDLdroidLite: A Release-and-Inhibit Control Approach to Resource-Efficient Deep Neural Networks on Mobile Devices. IEEE Transactions on Mobile Computing 21, 10 (2022), 3670 3686. doi:10.1109 TMC.2021.3062575 [188] Yuchen Zhao, Sayed Saad Afzal, Waleed Akbar, Osvy Rodriguez, Fan Mo, David Boyle, Fadel Adib, and Hamed Haddadi. 2022. Towards battery-free machine learning and inference in underwater environments. In Proceedings of the 23rd Annual International Workshop on Mobile Computing Systems and Applications (HotMobile 22).\n\n--- Segment 61 ---\nTowards battery-free machine learning and inference in underwater environments. In Proceedings of the 23rd Annual International Workshop on Mobile Computing Systems and Applications (HotMobile 22). ACM. doi:10.1145 3508396.3512877 [189] Yiyang Zhao, Linnan Wang, Yuandong Tian, Rodrigo Fonseca, and Tian Guo. 2020. Few-shot Neural Architecture Search. CoRR abs 2006.06863 (2020). arXiv:2006.06863 [190] Zhuoran Zhao, Kamyar Mirzazad Barijough, and Andreas Gerstlauer. 2018. DeepThings: Distributed Adaptive Deep Learning Inference on Resource-Constrained IoT Edge Clusters. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 37, 11 (2018), 2348 2359. doi:10.1109 TCAD.2018.2858384 24 Millar et al. [191] Guangxu Zhu, Yong Wang, and Kaibin Huang. 2020. Broadband Analog Aggregation for Low-Latency Federated Edge Learning. IEEE Transactions on Wireless Communications 19, 1 (2020), 491 506. doi:10.1109 TWC.2019.2946245\n\n