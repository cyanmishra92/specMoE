=== ORIGINAL PDF: 2502.14307v1_μRL_Discovering_Transient_Execution_Vulnerabilitie.pdf ===\n\nRaw text length: 79137 characters\nCleaned text length: 78831 characters\nNumber of segments: 43\n\n=== CLEANED TEXT ===\n\nµRL: Discovering Transient Execution Vulnerabilities Using Reinforcement Learning M. Caner Tol Worcester Polytechnic Institute Kemal Derya Worcester Polytechnic Institute Berk Sunar Worcester Polytechnic Institute Abstract We propose using reinforcement learning to address the chal- lenges of discovering microarchitectural vulnerabilities, such as Spectre and Meltdown, which exploit subtle interactions in modern processors. Traditional methods like random fuzzing fail to efficiently explore the vast instruction space and often miss vulnerabilities that manifest under specific conditions. To overcome this, we introduce an intelligent, feedback-driven approach using RL. Our RL agents interact with the proces- sor, learning from real-time feedback to prioritize instruction sequences more likely to reveal vulnerabilities, significantly improving the efficiency of the discovery process. We also demonstrate that RL systems adapt effectively to various microarchitectures, providing a scalable solution across processor generations. By automating the exploration process, we reduce the need for human intervention, enabling continuous learning that uncovers hidden vulnerabilities. Ad- ditionally, our approach detects subtle signals, such as tim- ing anomalies or unusual cache behavior, that may indicate microarchitectural weaknesses. This proposal advances hard- ware security testing by introducing a more efficient, adaptive, and systematic framework for protecting modern processors. When unleashed on Intel Skylake-X and Raptor Lake mi- croarchitectures, our RL agent was indeed able to generate instruction sequences that cause significant observable byte leakages through transient execution without generating any µcode assists, faults or interrupts. The newly identified leaky sequences stem from a variety of Intel instructions, e.g. in- cluding SERIALIZE, VERR VERW, CLMUL, MMX-x87 transitions, LSL RDSCP and LAR. These initial results give credence to the proposed approach. 1 Introduction In the past two decades, our computing systems have evolved and grown at an astounding rate. A side effect of this growth has been increased resource sharing and, with it, erosion of isolation boundaries. Multitenancy has already been shown to be a significant security and privacy threat in shared cloud instances. VM boundaries can be invalidated either by soft- ware or hardware bugs [10,21,33,54] or by exploiting subtle information leakages at the hardware level [34]. Microarchitectural Threats. Arguably, one of the greatest security threats comes from attacks that target the implemen- tation through side-channels or from hardware vulnerabilities. Such attacks started as a niche exploiting leakages through execution timing, power, and electromagnetic emanations but later evolved to exploit microarchitectural (µArch ) leakages, e.g. through shared cache and memory subsystems, specula- tive execution, shared peripherals, etc. µArch threats repre- sent one of the most significant types of vulnerabilities since they can be carried out remotely with software access only. Prime examples of these threats are the early execution tim- ing [25] and cache attacks [29,29,61], and later Meltdown, Spectre [24], and MDS attacks [4, 33, 53] which allow an unprivileged user to access privileged memory space break- ing isolation mechanisms such as memory space isolation across processes, cores, browsers tabs and even virtual ma- chines hosted on shared cloud instances. Active attacks, e.g. Rowhammer, have also proven effective in recovering sensi- tive information [26] and [3,36]. While numerous practical countermeasures were proposed and implemented, there re- mains a massive attack surface unexplored. Indeed, 5 years after Meltdown was mitigated (August 2023), a new transient execution vulnerability, Downfall [32], was discovered that exploits speculative data gathering and allows Meltdown-style data leakage and even injection across threads. Lack of Access to Design Internals. A significant factor contributing to the difficulty of evaluating the security of large-scale computer systems is that design details are rarely disclosed. Given only superficial interface definitions, re- searchers are forced to reverse engineering and black box analysis. While companies have access to the internals of their system, it is hard to argue that they are aware of their own designs either due to third-party IPs, mobility of engineers, and silos isolating their engineering teams from each other. 1 arXiv:2502.14307v1 [cs.CR] 20 Feb 2025 IPs are orphaned with little superficial information surviving after only a few years of breaking institutional memory. These factors combined pose a great danger for µArch security. The primary goal of the proposed work is to answer the fol- lowing question: Can we use AI to automatically find brand- new vulnerabilities? In practical terms, can we build an AI agent that can discover the next Meltdown or Spectre vulner- abilities? Currently, there are intense efforts in the cyberse- curity research community to deploy AI tools to scan Open Source Software (OSS) for known vulnerabilities, e.g. for detection in µArch we have [5, 12, 16, 56, 58, 59] and for patching [13,17,40,49,60,62] and [51]. We take on a more challenging problem and investigate how we can build an AI Agent that constantly searches the target platform for brand new µArch vulnerabilities. In a way, such an ability would bring true scalability and a tipping point since, if granted, we could surpass human abilities by creating as many AI Agents as we want by just throwing more cycles at the problem. In the hands of software hardware ven- dors, such a tool would allow us to address vulnerabilities early on before the software advances deeper in the deploy- ment pipeline. What is missing is the know-how to put such a system together i.e. a tool that can constantly analyze a hardware software stack under popular configurations, iden- tify and report found vulnerabilities, articulating cause and effect and severity of the vulnerability. In this work, we take inspiration from cybersecurity researchers on how they came up with new vulnerabilities: Randomization. There is a healthy dose of manual or au- tomated trial and error in discovering new vulnerabilities. In µArch security fuzzing has become an indispensable tool to test randomized attack vectors and thereby identify or generate improved versions of vulnerabilities. For in- stance, Oleksenko et al. [38] developed SpecFuzz to test for speculative execution vulnerabilities. The tool combines dy- namic simulation with conventional fuzzing for the identifi- cation of potential Spectre vulnerabilities. Another example is Transyther [33] , a mutational fuzzing tool that generates Meltdown variants and tests them to discover leaks. Tran- syther found a previously unknown transient execution attack through the word combining buffer in Intel CPUs [33]. In [22], Jattke et al. use fuzzing to discover non-uniform hammering patterns to make Rowhammer fault injection viable in a large class of DRAM devices. While effective, fuzzing, as currently practiced in µArch security, only works in small domains and fails to scale to cover larger domains to discover new vulnerabilities. Indeed, SpecFuzz for Spectre v1 is only able to Spectre gadgets, and Transyther discovered the Medusa vulnerability since it is reachable with mild randomization from Meltdown variants. The discovery of the timing channel by Kocher [25] led to the discovery of cache-timing attacks [39]. Similarly, shar- ing in Branch Prediction Units (BPUs) led to the exploita- tion of secret dependent branching behavior to recover leak- ages [2]. These attacks led to µArch Covert Channels that may be used intentionally to exfiltrate data, e.g. by signaling via cache access patterns and break isolation mechanisms. Covert-channels were first used by many researchers as an ini- tial demonstration of the existence of a side-channel, with the channel rate providing a measure for the level of the leakage. Covert channels and manipulations in BPUs, in turn, became enablers for Transient Execution Attacks such as Meltdown, Spectre, and later MDS attacks. Further, the recent work [32] uses the Meltdown style data leakage and the LVI style [53] data injection mechanisms in the context of SIMD instruc- tions to discover new vulnerabilities. The x86 instruction set is a complex architecture that supports thousands of instructions, registers, and addressing modes, with each microarchitecture adding layers of optimiza- tions for performance and efficiency. These optimizations, while beneficial, introduce complexities that can hide vulner- abilities, as seen with exploits like Meltdown and Spectre, which exploit unexpected microarchitectural behavior to ex- pose sensitive data. Traditional testing methods like random fuzzing are inadequate due to the vast number of instruc- tion combinations and the specific, rare conditions that often trigger vulnerabilities. Complex features like out-of-order and speculative execution increase both performance and the difficulty of detecting flaws, making the discovery of microar- chitectural vulnerabilities challenging. An effective approach involves intelligent, feedback-based testing, where processor behavior under different conditions guides the search for vulnerabilities. This approach allows testing to focus on high-priority areas, improving efficiency and effectiveness. Feedback mechanisms can also adapt to new microarchitectures, adjusting their methods for each pro- cessor generation, an essential feature given the rapid evolu- tion of hardware designs. Machine Learning (ML) enhances this feedback-driven approach by identifying patterns in cache or power usage that indicate potential vulnerabilities. Over time, ML models improve, enabling more systematic and scal- able vulnerability discovery across diverse processor designs. RL further advances this approach, using a reward-based sys- tem to optimize instruction space exploration. RL agents pri- oritize instruction sequences that reveal anomalies, efficiently balancing exploration with exploiting known vulnerabilities, making them suitable for evolving architectures. In summary, random fuzzing alone is insufficient for dis- covering vulnerabilities in modern x86 microarchitectures. Integrating feedback mechanisms with RL allows a more targeted, adaptable, and effective approach, essential for un- covering hidden vulnerabilities and maintaining security in rapidly advancing processor designs. In this work, we make the following contributions: 1. We propose a novel approach to discovering microarchi- tectural vulnerabilities using RL. 2. We develop a custom RL environment that simulates the execution of x86 instructions on a microarchitecture, 2 allowing the agent to explore the instruction space. 3. We find new transient execution based leakage mecha- nisms on Intel Skylake-X and Raptor Lake microarchi- tectures based on masked FP exceptions and MME x87 transitions demonstrating the effectiveness of the RL agent in discovering vulnerabilities. 2 Related Works µArch vulnerability discovery has attracted significant atten- tion, leading to the development of several tools and method- ologies aimed at exposing speculative execution and side- channel vulnerabilities. Osiris [57] introduces a fuzzing- based framework that automates the discovery of timing- based µArch side channels by using an instruction-sequence triple notation: reset instruction (setting the µArch compo- nent to a known state), a trigger instruction (modifying the state based on secret-dependent operations), and a measure- ment instruction (extracting the secret by timing differences). Transynther [32,33] automates exploring Meltdown-type at- tacks by synthesizing binarizes based on the known attack patterns. For the classification and root cause analysis of the generated attacks, Transynther uses performance counters and µArch buffer grooming technique. AutoCAT [30] au- tomates the discovery of cache-based side-channel attacks on unknown cache structures using RL. Several studies also focus on using hardware performance counters to detect spec- ulative execution issues. For example, [37, 42] use perfor- mance counters to monitor mis-speculation behavior. More recently, [6] proposed a particle swarm optimization based algorithm to discover unknown transient paths. Their main assumption is different instruction sets do not interfere with each other do not share the same resources, therefore, they can be analysed independently. In this dissertation, we show that this assumption limits the exploration of the instruction space and combining different instruction sets can lead to new mechanisms of transient execution. Although, these tools have shown promise in detecting µArch vulnerabities, they are limited in their ability to effi- ciently explore the large instruction space and the complex interactions between different instructions. 3 Background 3.1 Microarchitectural Attacks 3.1.1 Cache Timing Side Channel Attacks The state of the shared cache can be observed to detect the memory access patterns. Over the past years, different tech- niques have been developed to extract sensible data by using cache timing as a side-channel attack. Flush Reload [61] leverages the Last-Level Cache (L3 cache) to monitor memory access patterns in shared pages. While it does not require the attacker and victim to share the same execution core, it flushes a potential victim address from the cache, and then measures the reload time if the target address is accessed. EVICT RELOAD [15] is another work where an eviction technique is used when cache flushing is not available. Prime Probe [29] exploits the eviction sets to detect access patterns and it does not require shared memory between attacker and victim. The Flush Flush attack [14] ex- ploits the timing variations of the clflush. The Evict Time attack [39] uses timing differences between cache hits and misses to infer cache state, allowing an attacker to detect cache misses and deduce access patterns. Although more advanced cache side-channel attacks [11, 20,41], in this work, we use Flush Reload for its simplicity and effectiveness. 3.1.2 Transient Execution Attacks Transient execution attacks exploit speculative and out-of- order execution in CPUs to access restricted data temporarily, leaving traces in the cache that attackers can analyze. Spectre attacks [24] exploit speculative execution and branch prediction in modern processors to leak confidential in- formation across security boundaries. By inducing speculative operations that bypass normal execution flow, attackers can access sensitive memory and registers, creating side-channel leaks. NetSpectre [46] is the first remote variant of the Spectre attack, extending its reach beyond local code execution. Net- Spectre marks a significant shift from local to remote attacks, making Spectre a threat even to systems where no attacker- controlled code is executed, including cloud environments. SgxPectre attack [7] exploits CPU vulnerabilities to com- promise the confidentiality and integrity of SGX enclaves. By manipulating branch prediction from outside the enclave, attackers can temporarily alter the enclave s control flow, pro- ducing cache-state changes that reveal sensitive information within the enclave. Meltdown [28] bypasses memory isolation by exploiting out-of-order execution in modern processors to access pro- tected kernel memory. This enables attackers to read memory from other processes or virtual machines without permission, posing a severe risk to millions of users. Foreshadow [52] is a microarchitectural attack exploiting speculative execution flaws in Intel processors to breach SGX security. Without needing kernel access or assumptions about enclave code, Foreshadow leaks enclave secrets from the CPU cache. Rogue In-flight Data Load (RIDL) [55] is a speculative execution attack that leaks data across address spaces and privilege boundaries. RIDL retrieves in-flight data directly from CPU components without relying on cache or trans- lation structures, making it uniquely invasive and effective. Fallout [4] reveals that Meltdown-like attacks remain feasible on newer CPUs that are supposedly immune to Meltdown due to hardware fixes. By examining the behavior of the store 3 buffer, they uncover vulnerabilities. ZombieLoad [45] is a Meltdown-type attack that exploits a vulnerability in the processor s fill-buffer logic to leak data across logical CPU cores, even on CPUs with hardware miti- gations against Meltdown and MDS. ZombieLoad uses fault- ing load instructions to transiently access unauthorized data in the fill buffer. Load Value Injection (LVI) [54] is a technique that generalizes injection-based attacks to the memory hier- archy by injecting attacker-controlled values into a victim s transient execution. Downfall [32] is a new class of transient execution attacks that exploit the gather instruction on x86 CPUs to leak sensitive data across security boundaries, in- cluding user-kernel, process, and virtual machine isolation, as well as trusted execution environments. 3.2 Reinforcement Learning In RL, the objective is for an agent to learn a policy πθ(a s), parameterized by θ, which maximizes the expected cumu- lative reward through its chosen actions in an environment. The policy gradient method [48] computes the gradient of the expected reward with respect to the policy parameters, allowing the agent to directly update the policy by following the gradient. Formally, the objective function J(θ) is defined as: J(θ) Eπθ " T t 0 rt , where rt is the reward at time step t, and the expectation is over the trajectories induced by the policy πθ. The policy is updated by adjusting θ in the direction of the gradient θJ(θ) using gradient ascent. One of the major challenges with vanilla policy gradient methods is the high variance of the gradient estimates, which can lead to unstable learning. Additionally, large updates to the policy parameters θ can cause dramatic changes to the policy, potentially leading to performance col- lapse. Trust Region Policy Optimization (TRPO) [43] was proposed to address this issue by enforcing a constraint on the size of policy updates using a trust region. TRPO introduces the following constrained optimization problem: max θ Eπθ πθ(a s) πθold(a s) ˆA(s,a) subject to Es DKL πθold πθ δ where DKL is the Kullback-Leibler (KL) divergence, ˆA(s,a) is the advantage estimate, and δ is a small positive value controlling the step size. However, TRPO is computationally expensive due to the need for second-order optimization to enforce the KL-divergence constraint. Proximal Policy Optimization (PPO) [44] simplifies TRPO by replacing the hard constraint on policy updates with a penalty or by using a clipped objective function. The key idea behind PPO is to ensure that policy updates are proximal to the current policy, preventing drastic updates that could lead to instability. In this work, we use PPO with clipped objective. In this ap- proach, PPO clips the probability ratio πθ(a s) πθold(a s) to lie within a small interval around 1, preventing large updates. The clipped objective is defined as: LCLIP(θ) E min r(θ) ˆA(s,a),clip(r(θ),1 ε,1 ε) ˆA(s,a) , where r(θ) πθ(a s) πθold(a s) is the probability ratio, and ε is a small hyperparameter that limits how far the policy is allowed to change. By clipping the probability ratio, PPO discourages overly large updates while still allowing for sufficient explo- ration of the policy space. 4 Threat Model and Scope Our threat model considers scenarios where attacker and vic- tim processes are co-located in shared hardware environments, which expose vulnerabilities to µArch attacks. Co-location can manifest in several forms, including but not limited to threads on the same process, processes on the same host and virtual machines on a shared server. These attacks exploit shared µArch resources to infer sensitive data from victim pro- cesses, bypassing traditional memory isolation mechanisms. We assume the CPU microcode is up-to-date with the latest mitigations, and the software has no bugs and SMT is enabled. We assume no access to the confidential design details of the processor, limiting our analysis to black-box testing. This restriction reflects the real-world scenario where attackers must rely on external observations and performance counters to reverse-engineer the processor s internal behavior. Although we have not seen example of such an exploit in real-life yet, if unmitigated, these attacks can lead to signifi- cant data breaches, including the extraction of cryptographic keys and other sensitive information. In this work, we fo- cus on discovering µArch vulnerabilities using reinforcement learning and we focus on the following questions: Q1. How can we design an RL framework that efficiently explores the µArch space? Q2. Can RL discover unknown µArch vulnerabilities? Q3. What are the challenges and limitations of using RL for µArch vulnerability discovery? 5 Our RL Framework In this section, we introduce our RL framework designed for µArch vulnerability analysis. Automated analysis of µArch vulnerabilities poses the following challanges some of which were also identified in earlier works [6,33,57]: C1. Modern processor designs are complex and their in- structions sets are large. Exhaustive search in the instruction space is infeasible. 4 PMAXUD XMM2, XMM2 Action Reward Observation State RL agent Exceptions Performance Counters Flush Reload text embedding model Legal Instruction Set Dynamic Testing asm embeddings Processor ROR EBX, 0 PADDQ MM3, qword [R15] FUCOMIP ST1 VMOVDDUP YMM1, YMM1 KMOVD dword [R15], K2 PMAXUD XMM2, XMM2 Figure 1: Overview of the RL framework for µArch vulnerability analysis; L before the Observation denotes concatenation. L before Reward represents Equation 1. C2. Mapping an instruction sequence to a certain µArch vulnerability is non-trivial and requires expert knowledge. C3. The environment is high-dimensional and non-linear and the system state is only partially observable. Earlier works attempted to solve C1 by either limiting the type of instructions [6, 37] or limiting the length of the in- struction sequence [57]. In this work, we propose a novel approach to address this challenge by leveraging RL to guide the search for µArch vulnerabilities. Our framework is de- signed to efficiently explore the instruction space, learn the optimal policy for selecting instruction sequences, repoduce known vulnerability and, if exists, discover unknown vulnera- bilities. The framework is illustrated in Figure 1 and consists of the following components: 5.1 Environment We build a custom environment based on the underlying CPU model. The environment represents a black-box model of the CPU microarchitecture, where the agent can only interact with the CPU through the instruction sequences. It takes the instruction sequences generated by the RL agent, executes them on the CPU, and returns an observation and a reward. It also updates the state after every action taken. At the start of each episode, the environment initializes by resetting the instruction state and clearing the performance counter readings. A reset function is triggered at the begin- ning of each new episode to ensure the agent starts with a fresh state. All sequences, performance metrics, and de- tected byte leakages are logged for post-training analysis. The logged data aids in identifying patterns or characteristics in sequences that lead to vulnerabilities and provides insights into the agent s decision-making process. 5.2 RL Agent The RL agent is a multi-layer perceptron (MLP) that generates actions based on observations given by the environment. In this case, the agent s goal is to select an instruction that will be appended to the instruction sequence. The agent is trained using the PPO algorithm. The goal of the agent is to maximize the reward signal by selecting the best sequence of actions and eventually trigger µArch vulnerabilities. 5.3 Action Space We define an action as the selection of an assembly instruc- tion from the instruction set. To map the discrete actions to actual assembly instructions, we use [1]. The action space is constrained to instructions that are supported by the CPU under test and documented by the vendor. This constraint helps the agent focus on relevant instructions that exist in the real-world programs. Since some of the instruction exten- sions has large number of instructions and operand variety, (e.g. AVX-512), we construct the action space hierarchically. For example, we first select the instruction set (e.g. AVX-512), then the instruction (e.g. VMOVDDUP), and finally the operands (e.g. XMM0, XMM1). This hierarchical structure helps prevent larger instructions sets dominating the smaller ones since the agent will initially randomly select insturction during the ex- ploration phase. To handle the difference in the number of instructions in each set, we use map different actions to the same insturction or operands using them modulo operation. For instance, if the maximum number of instructions in a set is 10 but the model selected the 12th instruction, we map it to the 12 mod 10 2nd instruction in the selected set. 5 5.4 State Eventhough, there are more variables that affect the CPU state other than just the input instruction sequence, such as, cache content, internal buffers, registers, etc., we simplify the state representation to only the instruction sequence. The impact of other factors that affects the CPU state can be minimize by running the same instruction sequence multiple times until the real state becomes stable, which is a common practice in µArch attacks [29, 61]. After each action, the generated assembly instruction is added to the current state. 5.5 Observation Since we do not have access to hardware debug interface, we cannot directly observe the entire state of the CPU. Therefore, it is a partially observable environment and the observation can only capture a subset of the environment state as it is mentioned in C3. We tackle this challange by designing an observation space that consists of a static and a dynamic part. The static part of the observation is the generated instruc- tion sequence. Similar to the earlier works [31,50], we use embeddings to convert the instruction sequence into high- dimensional fixed-size vectors using a pre-trained LLM. Em- beddings capture the patterns in the assembly code so that the agent understand the structural and functional dependen- cies between instructions. Before inclusion in the observation space, embeddings undergo normalization to ensure consis- tency in data scales. The dynamic part of the observation is the hardware perfor- mance counters. Vendors give access to low-level monitoring of the CPU events such that developers can identify bottle- necks in their applicaitons and optimize the performance. In this work, we use the performance counters to partially cap- ture the CPU state. For measurement, we embed instruction sequences in a template assembly file, ensuring valid mem- ory addresses in R15 register to prevent segmentation faults. General-purpose registers are preserved on the stack to avoid unintended corruption. Each sequence is executed multiple times to minimize noise. We use the performance counters listed in Table 1. The explanation of these counters are given in the Appendix A. These counters are selected based on their relevance to speculative execution vulnerabilities shown by previous re- search [6,37,42] as well as Intel s performance monitoring tools [8]. 5.6 Reward Function The reward function is often seen as the most critical compo- nent of the RL frameworks since it steers the agent behavior. We address the challenge C2 by carefully designing the re- ward function. The instruction sequences selected by the agent are ex- ecuted on the CPU, and the CPU s behavior is monitored HW Performance Event Name UOPS_ISSUED.ANY UOPS_RETIRED.RETIRE_SLOTS INT_MISC.RECOVERY_CYCLES_ANY MACHINE_CLEARS.COUNT MACHINE_CLEARS.SMC MACHINE_CLEARS.MEMORY_ORDERING FP_ASSIST.ANYa OTHER_ASSISTS.ANYb CPU_CLK_UNHALTED.ONE_THREAD_ACTIVE CPU_CLK_UNHALTED.THREAD HLE_RETIRED.ABORTED_UNFRIENDLYc HW_INTERRUPTS.RECEIVEDd Table 1: List of used CPU performance events available in Skylake-X. In Raptor Lake, corresponding events: a AS- SISTS.FP, b ASSISTS.ANY, c N A, d N A. using hardware performance counters. The counters provide feedback on the speculative execution and microarchitectural effects of the instructions. The reward function evaluates the performance counter data collected during instruction execution. It assigns rewards based on the presence of speculative execution anomalies, deviations from expected behavior, or other indicators of po- tential vulnerabilities. Reward bad speculation observed byte leakage instruction count (1) Equation 1 shows a simplified version of the reward function we use for training the RL agent. The reward is calculated by dividing the sum of bad speculation and observed byte leak- age by the number of instructions in the sequence. The final reward value is capped at 100 if observed byte leakage 0 and 500 if observed byte leakage 0 to prevent excessive re- wards, promoting stable training. The numbers were decided based on the empirical results. Testing for Bad Speculation. According to Intel s documen- tation [9], bad speculation typically results from branch mis- predictions, machine clears and, in rare cases, self-modifying code. It occurs when a processor fills the instruction pipeline with incorrect operations due to mispredictions. This process leads to wasted cycles, as speculative micro-operations (uops) are discarded if predictions are incorrect, forcing the processor to recover and restart. Although bad speculation is primarily a concern for performance, it also has important security im- plications. Microarchitectural attacks exploit transient states created by bad speculation. During speculation, the CPU may access sensitive data or load it into the cache, even though the operations will eventually be discarded. These transient states, particularly in cache memory, create opportunities for attackers to infer sensitive data such as encryption keys by analyzing cache behaviors and measuring access times. 6 Intel s formula for quantitatively measurement of bad spec- ulation for a CPU thread is Bad Speculation UOPS_ISSUED.ANY UOPS_RETIRED.RETIRE_SLOTS (4 INT_MISC.RECOVERY_CYCLES) (2) which also what we use in our reward function. If there is an exception detected during the performance counter tests, we terminate the episode, set the reward to - 10 and reset the state. We select this number arbitrarily to differentiate between instruction sequences with no bad spec- ulation vs instruction sequences that do not execute at all. Negative reward discourages the agent from generating ex- ceptions. Note that, handling the exceptions is also possible, but it complicates the reward calculation. Therefore, we leave it for future work. Testing for Observable Byte Leakage. inst_sequence rep N inst_sequence endrep COMPARISON JE exit CACHE_ENCODING exit: RET true F R JNE exit CACHE_ENCODING exit: RET fail false Leakage 0 true false Leakage 0 JE exit lfence CACHE_ENCODING exit: RET false true Leakage 0 JNE exit lfence CACHE_ENCODING exit: RET false true Leakage 0 F R F R F R success Figure 2: Test flow for detecting observable byte leakage. If the performance counter tests executes successfully, we check if the generated instruction sequence results in observ- able byte leakage due to speculative execution. Our testing flow for detecting observable byte leakage is shown in Fig- ure 2. We, first, place the instruction sequence in a template as- sembly file and run it N times using rep directive. Similar to performance counter tests, we use predefined addresses for memory operands and preserve the contents of the general purpose registers in the stack. Then, we execute a comparison operation based on the instructions types and registers used in the generated sequence. If there are multiple types of reg- isters used in the sequence, we select a different comparison instruction specific to that register type. We repeat the test flow for each register type used in the sequence. This way we avoid false negatives due to the register type mismatch. After the comparison, we execute a conditional branch instruction (jump if equal JE) which is followed by cache accesses to an array that encode a predefined sequence of bytes to the cache state. We then measure the access time to the array using Flush Reload [61] to decode the bytes and check if it how much it matches with the encoded bytes. If there is any match, we repeat the same test, this time with the opposite branch condition (jump if not equal JNE). If there is a match in this case, we consider it as an observable byte leakage. Note that, most of the generated seqences fail either in the first or second step of the leakage test. For the remaining sequences that passed the first two tests, we run the same two test after inserting lfence before the branch instruction. If the leakage disappears after adding lfence, we consider it as a successful sequence that causes observable byte leakage through bad speculation. Note that, unlike Spectre-BHT [24], we do not train the branch predictor in the test flow so the root cause of the bad speculation would not be the branch mispredictions unless the generated sequence has the branch predictor training itself using branch instructions. We repeat the test flow for each register type used in the se- quence. This way we avoid false negatives due to the register type mismatch. The number of successfully decoded bytes are fed into the reward function as the observable byte leakage. Since the byte leakage is a more direct signal of the vulnera- bility, we assign a higher weight to it in the reward function. If an exception is detected at this stage, the environment resets to a safe state, logs the exception. Only the byte leakage part of the reward is set as zero, yet the bad speculation part is calculated as usual. 6 Experiments Experiment Setup. We run the experiments on two systems with different µArch . The first system has an Intel Core i9 7900X CPU with a Skylake-X µArch . The OS running on the system is Ubuntu 22.04.5 LTS with the Linux v6.5.0 44-generic. We use glib v2.72.4, nasm v2.15.05, and gcc v11.4.0 for compiling and testing the generated assembly files; PyTorch v2.2.1, Stable Baselines3 v2.2.1 and Gymna- sium v0.29.1 for custom RL environment and training the RL agent. The RL agent training and the local inference for the text embedding model are done on the GPU clusters with an NVIDIA TITAN Xp, GeForce GTX TITAN X, and two GeForce GTX 1080Ti. The overview of the experiment setup used in the first system is illustrated in Figure 3. The second system has an Intel i9-14900K CPU with a Raptor Lake µArch , Ubuntu 24.04.1 LTS with Linux v6.8.0- 51-generic, glib v2.80.0, nasm v2.16.01, gcc v13.3.0. Py- torch v2.4.1 cu121, Stable Baselines3 v2.3.2, and Gymna- sium v0.29.1 are used for the same purposes as the first sys- tem. The RL agent training is done on NVIDIA GeForce RTX 4090 GPU. For remote inference, we use OpenAI s 7 Core 0 L1d L1i L2 Core 1 L1d L1i L2 L3 Generated instruction sequences Core 2 L1d L1i L2 Core 4 L1d L1i L2 Core 6 L1d L1i L2 Core 8 L1d L1i L2 Core 3 L1d L1i L2 Core 5 L1d L1i L2 Core 7 L1d L1i L2 Core 9 L1d L1i L2 Environment scripts RL agent training Text embedding model inference GPU GPU GPU GPU Figure 3: Experiment Setup on Skylake-X. Each physical core shown in green was allocated to a single instruction sequence at a time. text-embedding-3-small model through the API ac- cess, which allows us to use the parallel core testing since it does not require local GPU memory. Parallelizing the framework across multiple CPU cores enables multiple sequences to be evaluated simultaneously and increases the training speed. Although the last level cache is shared among the cores, each process accesses its own distinct memory region, which does not include any shared libraries or data. Therefore, the cache interference among the processes is minimal. For local inference, we used the NV-Embed-v2 [27, 35] embedding model. However, we observed that it does not accelerate the training overall since the GPU memory is not enough to enable parallel core testing. Therefore, the results presented in this paper are based on the text-embedding-3- small model. In the Skylake-X system, after filtering all illegal instruc- tions from [1], we are left with 12598 instructions that belong to 74 sets. The largest set has 2192 instructions, and the maxi- mum number of possible operands per instruction is 7. These numbers determine the size of the action space for the RL agent. In the Raptor Lake system, 3996 instructions that be- long to 72 sets were left after filtering. The largest set has 468 instructions, and the maximum number of operands per instruction is 7. For the agent training, we enable all available kernel mitiga- tions against CPU vulnerabilities. Cumulatively, we collected 27 days worth of data from Skylake-X and 20 days worth of data from Raptor Lake. In the longest runs, we trained an RL agent for 4.5 days and 10.5 days for Skylake-X and Raptor Lake, respectively. In total, the cost for embedding model inference through API calls was 2.46 USD. During the RL agent training, we observe that the average reward of each episode increases over time, as shown in Fig- ure 4. The steady increase in reward indicates that the RL agent was able to successfully explore the x86 instruction Figure 4: The increase of the average reward per episode during the 10 days of agent training in Raptor Lake. An episode corresponds to the largest instruction sequence the agent can generate from scratch. The darker line shows the running mean. Figure 5: The increase of the average length of generated assembly sequences during the 10 days of agent training in Raptor Lake. The darker line shows the running mean. set while exploiting the knowledge we provide through the reward signal. At every episode, the agent starts building an instruction sequence from scratch and keeps adding a new instruction until the instruction limit is reached or the sequence gives an exception with the last added instruction. Over time, we observe that the average length of an instruction sequence dur- ing an episode increases during the agent training, as shown in Figure 5. Increasing average length over time indicates the agent was able to learn to select combinations of instructions to avoid exceptions. In our experiments, the maximum se- quence length was chosen as 10 assembly instructions, after which the agent starts building a new sequence. 7 Discovered Transient Execution Vulnerabili- ties When the agent builds an instruction sequence that results in observable transient execution, it is saved for manual analysis with performance counter and data leakage information. Fig- 8 Figure 6: Visualization generated instruction sequences across time, with higher byte leakage marked with lighter colors. Note that, the discovered transient execution mechanisms stand out as it has higher reward compared to the remaining ones. ure 6 shows the visualization of generated instructions over time. Since the sequences with high reward stands out from the rest of the generated snippets, it eases the manual analysis and verification as well. After analyzing the generated data, we were able to identify eight new classes of transient exe- cution mechanisms that had previously not been documented to the best of our knowledge. Note that, each class has many variations among the generated dataset. Yet here we present, the most simplified versions of the each class. Masked Exceptions. The studies in [6, 42] demonstrated that FP assists due to denormal numbers cause transient ex- ecution of the following instructions. Our RL agent gener- ated instruction sequences that cause observable byte leakage through transient execution without generating any µcode assists, faults, or interrupts. Listing 1 shows an example of such an instruction sequence. After careful analysis, we no- ticed that the sequence indeed causes an FP exception, but the exception is masked by the processor, and the program execution is uninterrupted. Previous works reported transient execution with page faults, device-not-available [28,33,47] which requires exception handling and µcode assists such as FP assists [6,42] which requires specially crafted inputs. Transient execution through masked FP exceptions has not been previously reported in the literature, which makes it a new discovery for our RL agent. We observed this behavior on only Skylake-X. Transitions Between MMX and x87. FP exceptions, by default, are masked and do not cause a trap, and the program continues execution. However, starting from glibc v2.2, it is possible to unmask them using feenableexcept functions from fenv.h library. This function allows the FP exceptions to cause a trap and the program to be interrupted. After masked exceptions we run another training session with the same configuration but with the 1 generated_assembly_function: 2 rep N 3 FLD qword [x] 4 endrep 5 FCOMI st0 , st1 6 JE exit: 7 ; cache encoding 8 MOVZX rax , byte [ rdi] 9 SHL rax , 10 10 MOV rax , qword [rsi rax] 11 exit: 12 RET Listing 1: A simplified instruction sequence that triggers masked FP exception due to repeated x87 instruction in line 4. Following cache encoding instructions (line 8-10) get executed speculatively. 1 generated_assembly_function: 2 rep N 3 PSUBQ MM2 , [R15] 4 FCOMIP ST4 5 endrep 6 VCMPPD K3, ZMM1 , ZMM4 , 2 7 JNE exit 8 ; cache encoding 9 MOVZX rax , byte [ rdi] 10 SHL rax , 10 11 MOV rax , qword [rsi rax] 12 exit: 13 RET Listing 2: A simplified version of the RL generated assembly instruction sequence that has MMX (line 3) to x87 (line 4) transition. Following cache encoding instructions (line 9-11) get executed speculatively. feenableexcept function enabling FE_INVALID, FE_DIVBYZERO, FE_OVERFLOW, FE_UNDERFLOW, and FE_INEXACT bits of the excepts argument. With this configuration, the RL agent was still able to gen- erate instruction sequences that cause observable byte leakage through transient execution without generating any µcode as- sists, faults, or interrupts. Listing 2 shows an example of such an instruction sequence. After simplifying the instruction sequence, we observed that the transient execution is caused by an FP exception that is generated by the FCOMIP instruction. However, the MMX instruction before the FCOMIP instruction causes the exception to get lost. We use the feenableexcept function to unmask FP exceptions, yet the exception generated in the processor gets cleared by the PSUBQ instruction. Even though the ex- ception is cleared, the following instructions are executed speculatively, and the transient execution is observed. Note that the comparison instruction VCMPPD does not have any de- pendency on the previous instructions, yet it is still executed speculatively, and removing the AVX instructions from the 9 sequence does not break the transient execution. In Intel documentations [19], it is advised that after the MMX instructions, EMMS instruction should be used to clear the FPU state to prevent undefined behavior . We verified that adding an EMMS instruction after the MMX instruction makes the FP exception cause a trap. Following the convention [42], we provide leakage rate analysis on MMX-x87 transient execution mechanism with changing iterations and leakage granularities as shown in Figure 7. Unlike the Masked Exceptions, we observed leakage through MMX-x87 in both µArch we analyzed. Interestingly, in Skylake-X, the highest leakage rate, 2.3 Mb s was achieved through 1-bit granularity and with iteration N 3. The second high was 1.9 Mb s with 8-bit granularity. Between N 3 and N 150, we do not observe any leakage. In Raptor Lake, the leakage appears at N 200 with up to 233 Kb s. (a) Skylake-X (b) Raptor Lake Figure 7: Leakage rate vs repetitions of the instruction pattern for MMX-x87. Note that in (a) the leakage rates peak when Iteration N 3 for every granularity. In (b), darker lines are running mean and the shades are rolling variance around the mean. SERIALIZE Instruction. Speculative execution vulnerabili- ties in modern processors allow attackers to observe transient execution behavior and infer secret data. This section analyzes the behavior of the SERIALIZE instruction in the context of speculative execution and demonstrates how it can inadver- tently facilitate information leakage under certain conditions. Intel s documentation states that the SERIALIZE instruction serializes instruction execution, ensuring all modifications to flags, registers, and memory by previous instructions are complete before subsequent instructions are fetched and ex- ecuted" [19]. This behavior includes "draining all buffered writes to memory [19], providing a robust barrier for in- struction execution order. However, our experiments reveal that SERIALIZE, when executed repeatedly alongside specific instructions, does not always halt speculative execution ef- fectively. This observation was made during experiments de- signed to measure speculative execution behavior and leakage patterns. The instruction sequences given in Listing 3 were executed repeatedly, with observed effects on speculative execution: 1 ; Sequence 1: leaks beginning of the secret 2 rep N 3 SERIALIZE 4 RDGSBASE EAX 5 VAESDECLAST YMM0 , YMM2 , yword [R15] 6 endrep 7 8 ; Sequence 2: leaks end of the secret 9 rep N 10 SERIALIZE 11 RDGSBASE EAX 12 endrep 13 14 ; Sequence 3: no leak 15 rep N 16 SERIALIZE 17 VAESDECLAST YMM0 , YMM2 , yword [R15] 18 endrep Listing 3: Sequences 1, 2, and 3: Showing various data leak behaviors through SERIALIZE. Sequence 1 leaked the beginning of the secret, revealing fragments. Sequence 2 leaked the end of the secret, revealing fragments. Sequence 3 did not result in any observable data leakage. Interestingly, the first two sequences caused a measurable increase in RECOVERY_CYCLES, indicating that the Resource Allocation Table (RAT) checkpoints were recovering after speculative execution. No increase in Machine Clear counters, µcode assists, or exceptions was observed. While SERIALIZE is intended to act as a speculation barrier, its behavior in combination with other instructions, such as RDGSBASE and VAESDECLAST, can inadvertently permit tran- sient execution to proceed. This transient execution creates a window where secret data can be accessed speculatively and leaked through side channels. Figure 8 shows the leakage rate analysis with the changing number of iterations. The largest leakage rate observed is 230 Kb s with 4-bit leakage granularity in Raptor Lake. We did not observe leakage in Skylake-X. VERR VERW Instructions. The VERR (Verify Read) and VERW (Verify Write) instructions are employed to confirm if a memory segment can be read or written from the current privilege level. These instructions are crucial for security pro- tocols, ensuring that less privileged code cannot access or alter 10 Figure 8: Leakage rate vs repetitions of the instruction pattern for SERIALIZE instruction measured in Raptor Lake. Darker lines are running mean and the shades are rolling variance around the mean. segments belonging to more privileged levels. These instruc- tions modify the Zero Flag based on whether a segment is readable or writable. Although these are obsolete instructions, VERW instruction has recently given an additional function- ality that wipes off the microarchitectural buffers in efforts to mitigate MDS attacks [18] from the software. µRL discovered instruction sequences given in Listing 4 that cause observable transient execution with both VERW and VERR instructions. Interestingly, we do not observe a leakage with VERW alone, without the instruction given in line 4. On Skylake-X µArch , VERW achieved up to 2.2 Mb s leakage rate, and 1-bit and 8-bit leakage granularity are close to each other. The complete data is given in Appendix B. Note that Skylake-X is one of the microarchitectures vulner- able to MDS attacks, and a microcode patch was issued for the VERW mitigation functionality. On Raptor Lake, VERW achieved up to 3.7 Mb s and 2.1 Mb s leakage rates with 1-bit and 8-bit leakage granularities, respectively. With 4-bit, we observed 279 Kb s leakage rate. VERR achieved up to 207 Kb s leakage rate with 4-bit leakage granularity, only in Rap- tor Lake. The relation between the iteration and leakage rates are given in Figure 9. 1 ;leaks through VERW 2 rep N 3 VERW word [R15] 4 LZCNT EDX, dword [R15] 5 endrep 6 7 ;leaks through VERR 8 rep N 9 VERR AX 10 endrep Listing 4: Instruction sequences with leakage through VERW and VERR. CLMUL Instructions. The CLMUL instruction set is de- signed to accelerate cryptographic operations by performing carry-less multiplication on 128-bit operands. This is particu- (a) VERW (b) VERR Figure 9: Leakage rates for VERW and VERR instructions mea- sured in Raptor Lake. In (b) Darker lines are running mean and the shades are rolling variance around the mean. larly useful in cryptographic algorithms like AES and GCM, where polynomial multiplications over GF(2128) are required, and carry propagation is not needed. Listing 5 shows an RL- generated sequence which includes PCLMULQDQ which is one of the CLMUL instructions. We observed leakage only in Raptor Lake with up to 90 Kb s with 4-bit granularity as shown in Figure 10. 1 ;leaks through PCLMULQDQ 2 rep N 3 PCLMULQDQ XMM4 , [R15], 2 4 VCVTPS2PH XMM0 , YMM0 , 2 5 LOCK CMPXCHG16B [R15] 6 endrep Listing 5: Instruction sequence with leakage through CMUL Miscellaneous. We observed leakage with the com- bination of other instructions such as LSL RDSCP, LAR RDSCP, LAR MULX, LAR ADCX CMOVNL, LAR PREFETCHWT1, etc. However, to save space, we give some of them in the Appendix C. 8 Exploitability of Discovered Transient Exe- cution Mechanisms In this section, we show how Meltdown-like vulnerabilities can be exploited without having TSX or exception handling, thanks to discovered instruction sequences by µRL. 11 Mechanism Skylake-X Raptor Lake Availability Leakage Rate [Kb s] Availability Leakage Rate [Kb s] FP Assist [42] 222 306 SMC [42] 235 481 BHT [23] 169 305 Exception w Handler [28] 217 280 TSX [28] 227 N A MD [42] 225 276 XMC [42] 1 395 MO [42] 235 7 Masked FP Exception (This work) 214 0 MMX-x87 (This work) 213 233 SERIALIZE (This work) 0 230 VERW (This work) 218 279 VERR (This work) 0 207 CLMUL (This work) 0 90 LSL RDSCP (This work) 0 210 LAR (This work) 0 30 Table 2: Comparison of availability and leakage rates of different transient execution mechanisms in Intel Skylake-X and Raptor Lake microarchitectures with 4-bit leakage granularity. The TSX instruction set extension is not available in Raptor Lake. The remaining marks show the instructions are supported, yet we do not observe leakage. Figure 10: Leake rates for CLMUL measured in Raptor Lake. Darker lines are running mean and the shades are rolling variance around the mean. The original Meltdown exploit [28], where an attacker uses transient execution to leak data from kernel memory, has been mitigated by KPTI implemented in the Linux Kernel. However, mitigations like KPTI are application-specific, and they mitigate only one element in the attack chain, in this case, the availability of kernel addresses mapped in the virtual memory. Yet, the root cause for the transient execution has not been mitigated in the hardware. Therefore, we argue that different applications can potentially still be vulnerable and be exploited using different transient execution mechanisms. Since finding new software applications vulnerable to tran- sient execution is not part of the scope of this work, we adopt the original Meltdown setup. For the proof of concept, we disable KPTI on the Linux kernel. Using the µRL generated instructions sequence shown in Figure 11: Proof of concept code that demonstrates the use of RL-generated MMX-x87 transient execution mechanism for reading the physical memory. Figure 11, we trigger transient execution of the following memory access in line, which is an illegal access to kernel memory. Speculative load from the kernel memory is then encoded into the cache so that we can decode it later using Flush Reload. In this experiment, we were able to read a pre-chosen secret value from the kernel memory without using a fault handler or TSX instruction set. This result demonstrates how µRL generated instructions sequences can be exploited, and they can be used as alternatives to the known attack vectors. 12 9 Discussion 9.1 Limitations While our RL framework demonstrates promising results in discovering microarchitectural vulnerabilities, it is important to acknowledge its current limitations: Exploration Focus. While the framework is effective at gen- erating instruction sequences that trigger vulnerabilities, it does not account for the entire system s attack surface. For example, vulnerabilities involving interactions between hard- ware and software, such as operating system mitigations or compiler optimizations, are not explicitly explored. In this work, we did not consider the impact of other system configurations such as Hyperthreading, TSX, SGX, AVX, HW prefetch, previous mitigations, Kernel Samepage Merging, ASLR, page table layout, etc. on the µArch vulnerabilities. We leave this for future work. Sparse and Delayed Rewards. Within the search space, only a small fraction of instruction sequences would indicate a vulnerability, assuming the design went through a thorough security review previously. The delayed nature of rewards, which depends on the cumulative effect of multiple instruc- tions, further complicates learning. Therefore, reward signal is sparse and delayed, making it challenging for the agent to learn the optimal policy. Incomplete CPU State Observability. Our framework relies on performance counters and partial state observations to in- fer microarchitectural behavior. However, it cannot directly access internal processor states or transient microarchitectural effects that are not captured by these counters. This black-box approach may miss vulnerabilities that require finer-grained or privileged insights into CPU internals. More subtle vul- nerabilities can potentially be detected by the deployment of µRL on processors by the chip vendors for an internal secu- rity review. Addressing these limitations in future work will further enhance the robustness and generalizability of µRL, enabling more comprehensive microarchitectural vulnerabil- ity discovery. 9.2 Scalability Scaling Across Vulnerabilities. The framework can be adapted to discover diverse classes of vulnerabilities (e.g., cache-based, transient execution) by modifying the reward function to prioritize unique microarchitectural signals and by incorporating domain-specific performance counters. Scaling to Different CPU Microarchitectures. Dynamic en- vironment generation enables the framework to model distinct architectural features of various CPUs. Transfer learning can be employed to initialize RL agents using policies trained on similar architectures, reducing the computational overhead of adapting to new designs. Indeed, we have shown that some of the vulnerabilities discovered on one CPU can be transferred to another CPU, such as MMX-x87 and VERW. Scaling to Heterogeneous Hardware. To support hardware like GPUs, the action space and environment must be tailored to GPU-specific instruction sets and execution models. This involves building GPU-aware environments that simulate in- struction behavior and adapting performance metrics, such as memory throughput and warp divergence, as observation signals. Parallel and Distributed Execution. Scaling the framework for large-scale exploration across diverse hardware is feasible through parallelization and distributed training. By leveraging multiple nodes and cores, the framework can simultaneously evaluate instruction sequences on varied architectures. 10 Conclusion In this work, we proposed an RL framework for discover- ing µArch vulnerabilities, demonstrating its capability to effi- ciently navigate the vast and complex instruction space of modern CPUs. The framework successfully rediscovered known vulnerabilities and uncovered new transient execu- tion mechanisms, such as masked floating-point exceptions and MMX-to-x87 transitions, showcasing its potential as a powerful tool for hardware security research. The proposed framework is notable for its adaptability across different µArch , leveraging custom RL environments and performance counter feedback to guide exploration. By employing hierarchical action spaces, parallelized training, and dynamic environment generation, it addresses the scala- bility challenges inherent in exploring diverse instruction sets and architectures. Additionally, the use of transfer learning reduces the cost of applying the framework to new proces- sor models, making it a versatile solution for vulnerability discovery. Beyond CPUs, the framework can be extended to analyze other hardware platforms, such as GPUs and accelerators, by adapting the action space and observation metrics to the spe- cific execution models and vulnerabilities of those platforms. The integration of GPU-specific metrics, for instance, could open new avenues for discovering side-channel vulnerabilities in high-performance computing environments. Overall, the proposed RL framework represents a signifi- cant step forward in automating µArch vulnerability discov- ery. By scaling efficiently across vulnerabilities, architectures, and hardware platforms, it lays the groundwork for a more systematic and adaptive approach to hardware security test- ing, ensuring that modern processors remain resilient against emerging threats. 13 References [1] Andreas Abel and Jan Reineke. uops.info: Characteriz- ing latency, throughput, and port usage of instructions on intel microarchitectures. In ASPLOS, ASPLOS 19, pages 673 686, New York, NY, USA, 2019. ACM. [2] Onur Acıiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. Predicting secret keys via branch prediction. In Top- ics in Cryptology CT-RSA 2007: The Cryptographers Track at the RSA Conference 2007, San Francisco, CA, USA, February 5-9, 2007. Proceedings, pages 225 242. Springer, 2006. [3] Andrew J. Adiletta, M. Caner Tol, Yarkın Doröz, and Berk Sunar. Mayhem: Targeted corruption of register and stack variables. In Proceedings of the 2024 ACM Asia Conference on Computer and Communications Se- curity, 2024. [4] Claudio Canella, Daniel Genkin, Lukas Giner, Daniel Gruss, Moritz Lipp, Marina Minkin, Daniel Moghimi, Frank Piessens, Michael Schwarz, Berk Sunar, Jo Van Bulck, and Yuval Yarom. Fallout: Leaking data on meltdown-resistant cpus. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS). ACM, 2019. [5] Sunjay Cauligi, Craig Disselkoen, Klaus v Gleissenthall, Dean Tullsen, Deian Stefan, Tamara Rezk, and Gilles Barthe. Constant-time foundations for the new spec- tre era. In Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Im- plementation, pages 913 926, 2020. [6] Anirban Chakraborty, Nimish Mishra, and Debdeep Mukhopadhyay. Shesha: Multi-head microarchitectural leakage discovery in new-generation intel processors. arXiv preprint arXiv:2406.06034, 2024. [7] Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H Lai. Sgxpectre: Steal- ing intel secrets from sgx enclaves via speculative exe- cution. In 2019 IEEE European Symposium on Security and Privacy (EuroS P), pages 142 157. IEEE, 2019. [8] Intel Corporation. Perfmon. intel perfmon tree main. Accessed: 2024-11-13. [9] Intel Corporation. Top-Down Microarchitecture Analy- sis Method, 2023. Accessed: 2024-11-13. [10] Jacson Rodrigues Correia-Silva, Rodrigo F Berriel, Claudine Badue, Alberto F de Souza, and Thiago Oliveira-Santos. Copycat cnn: Stealing knowledge by persuading confession with random non-labeled data. In 2018 International Joint Conference on Neural Net- works (IJCNN), pages 1 8. IEEE, 2018. [11] Craig Disselkoen, David Kohlbrenner, Leo Porter, and Dean Tullsen. {Prime Abort}: A {Timer-Free}{High- Precision} l3 cache attack using intel {TSX}. In 26th USENIX Security Symposium (USENIX Security 17), pages 51 67, 2017. [12] Goran Doychev, Boris Köpf, Laurent Mauborgne, and Jan Reineke. Cacheaudit: A tool for the static analysis of cache side channels. ACM Transactions on information and system security (TISSEC), 18(1):1 32, 2015. [13] Spandan Garg, Roshanak Zilouchian Moghaddam, and Neel Sundaresan. Rapgen: An approach for fix- ing code inefficiencies in zero-shot. arXiv preprint arXiv:2306.17077, 2023. [14] Daniel Gruss, Clémentine Maurice, Klaus Wagner, and Stefan Mangard. Flush Flush: a fast and stealthy cache attack. In International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pages 279 299. Springer, 2016. [15] Daniel Gruss, Raphael Spreitzer, and Stefan Mangard. Cache template attacks: Automating attacks on inclusive {Last-Level} caches. In 24th USENIX Security Sympo- sium (USENIX Security 15), pages 897 912, 2015. [16] Marco Guarnieri, Boris Köpf, José F Morales, Jan Reineke, and Andrés Sánchez. Spectector: Principled detection of speculative information flows. In 2020 IEEE Symposium on Security and Privacy (SP), pages 1 19. IEEE, 2020. [17] Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade. Deepfix: Fixing common c language errors by deep learning. In Proceedings of the aaai conference on artificial intelligence, volume 31, 2017. [18] Intel. Microarchitectural data sampling, 2021. Accessed: 2025-01-22. [19] Intel Corporation. Intel 64 and ia-32 architectures soft- ware developer s manual: Combined volumes 1, 2a, 2b, 2c, 2d, 3a, 3b, 3c, 3d, and 4, 2023. Accessed: 2024-11- 15. [20] Gorka Irazoqui, Thomas Eisenbarth, and Berk Sunar. S a: A shared cache attack that works across cores and defies vm sandboxing and its application to aes. In 2015 IEEE Symposium on Security and Privacy, pages 591 604. IEEE, 2015. [21] Saad Islam, Ahmad Moghimi, Ida Bruhns, Moritz Krebbel, Berk Gulmezoglu, Thomas Eisenbarth, and Berk Sunar. SPOILER: Speculative load hazards boost rowhammer and cache attacks. In 28th USENIX Secu- rity Symposium (USENIX Security 19), pages 621 637, Santa Clara, CA, August 2019. USENIX Association. 14 [22] Patrick Jattke, Victor Van Der Veen, Pietro Frigo, Stijn Gunter, and Kaveh Razavi. Blacksmith: Scalable rowhammering in the frequency domain. In 2022 IEEE Symposium on Security and Privacy (SP), pages 716 734. IEEE, 2022. [23] Paul Kocher, Jann Horn, Anders Fogh, , Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, Michael Schwarz, and Yuval Yarom. Spectre attacks: Exploit- ing speculative execution. In 40th IEEE Symposium on Security and Privacy (S P 19), 2019. [24] Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, et al. Spectre attacks: Exploiting speculative execution. In 2019 IEEE Symposium on Security and Privacy (SP), pages 1 19. IEEE, 2019. [25] Paul C Kocher. Timing attacks on implementations of diffie-hellman, rsa, dss, and other systems. In Advances in Cryptology CRYPTO 96: 16th Annual International Cryptology Conference Santa Barbara, California, USA August 18 22, 1996 Proceedings 16, pages 104 113. Springer, 1996. [26] Andrew Kwong, Daniel Genkin, Daniel Gruss, and Yu- val Yarom. Rambleed: Reading bits in memory without accessing them. In 2020 IEEE Symposium on Security and Privacy (SP), pages 695 711. IEEE, 2020. [27] Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. Nv-embed: Improved techniques for training llms as generalist embedding models. arXiv preprint arXiv:2405.17428, 2024. [28] Moritz Lipp, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner Haas, Anders Fogh, Jann Horn, Stefan Mangard, Paul Kocher, Daniel Genkin, Yuval Yarom, and Mike Hamburg. Meltdown: Reading kernel memory from user space. In 27th USENIX Security Symposium (USENIX Security 18), 2018. [29] Fangfei Liu, Yuval Yarom, Qian Ge, Gernot Heiser, and Ruby B Lee. Last-level cache side-channel attacks are practical. In 2015 IEEE symposium on security and privacy, pages 605 622. IEEE, 2015. [30] Mulong Luo, Wenjie Xiong, Geunbae Lee, Yueying Li, Xiaomeng Yang, Amy Zhang, Yuandong Tian, Hsien- Hsin S. Lee, and G. Edward Suh. Autocat: Rein- forcement learning for automated exploration of cache- timing attacks. In 2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA), pages 317 332, 2023. [31] Daniel J Mankowitz, Andrea Michi, Anton Zhernov, Marco Gelmi, Marco Selvi, Cosmin Paduraru, Edouard Leurent, Shariq Iqbal, Jean-Baptiste Lespiau, Alex Ah- ern, et al. Faster sorting algorithms discovered using deep reinforcement learning. Nature, 618(7964):257 263, 2023. [32] Daniel Moghimi. Downfall: Exploiting speculative data gathering. In 32nd USENIX Security Symposium (USENIX Security 23), pages 7179 7193, Anaheim, CA, August 2023. USENIX Association. [33] Daniel Moghimi, Moritz Lipp, Berk Sunar, and Michael Schwarz. Medusa: Microarchitectural data leakage via automated attack synthesis. In 29th USENIX Security Symposium (USENIX Security 20), pages 1427 1444, 2020. [34] Daniel Moghimi, Berk Sunar, Thomas Eisenbarth, and Nadia Heninger. TPM-FAIL: TPM meets Timing and Lattice Attacks. In 29th USENIX Security Sympo- sium (USENIX Security 20), Boston, MA, August 2020. USENIX Association. [35] Gabriel de Souza P Moreira, Radek Osmulski, Mengyao Xu, Ronay Ak, Benedikt Schifferer, and Even Oldridge. Nv-retriever: Improving text embedding models with effective hard-negative mining. arXiv preprint arXiv:2407.15831, 2024. [36] Koksal Mus, Yarkın Doröz, M Caner Tol, Kristi Rah- man, and Berk Sunar. Jolt: Recovering tls signing keys via rowhammer faults. In 2023 IEEE Symposium on Se- curity and Privacy (SP), pages 1719 1736. IEEE, 2023. [37] Oleksii Oleksenko, Marco Guarnieri, Boris Köpf, and Mark Silberstein. Hide and seek with spectres: Effi- cient discovery of speculative information leaks with random testing. In 2023 IEEE Symposium on Security and Privacy (SP), pages 1737 1752. IEEE, 2023. [38] Oleksii Oleksenko, Bohdan Trach, Mark Silberstein, and Christof Fetzer. Specfuzz: Bringing spectre- type vulnerabilities to the surface. arXiv preprint arXiv:1905.10311, 2019. [39] Dag Arne Osvik, Adi Shamir, and Eran Tromer. Cache attacks and countermeasures: the case of aes. In Topics in Cryptology CT-RSA 2006: The Cryptogra- phers Track at the RSA Conference 2006, San Jose, CA, USA, February 13-17, 2005. Proceedings, pages 1 20. Springer, 2006. [40] Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, and Brendan Dolan-Gavitt. Examining Zero-Shot Vulnerability Repair with Large Language Models. In 2023 IEEE Symposium on Security and Privacy (SP). IEEE, 2023. 15 [41] Antoon Purnal, Furkan Turan, and Ingrid Verbauwhede. Prime scope: Overcoming the observer effect for high- precision cache contention attacks. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 2906 2920, 2021. [42] Hany Ragab, Enrico Barberis, Herbert Bos, and Cris- tiano Giuffrida. Rage against the machine clear: A sys- tematic analysis of machine clears and their implications for transient execution attacks. In 30th USENIX Security Symposium (USENIX Security 21), pages 1451 1468, 2021. [43] John Schulman. Trust region policy optimization. arXiv preprint arXiv:1502.05477, 2015. [44] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimiza- tion algorithms. arXiv preprint arXiv:1707.06347, 2017. [45] Michael Schwarz, Moritz Lipp, Daniel Moghimi, Jo Van Bulck, Julian Stecklina, Thomas Prescher, and Daniel Gruss. ZombieLoad: Cross-privilege-boundary data sampling. In CCS, 2019. [46] Michael Schwarz, Martin Schwarzl, Moritz Lipp, Jon Masters, and Daniel Gruss. Netspectre: Read arbitrary memory over network. In European Symposium on Re- search in Computer Security, pages 279 299. Springer, 2019. [47] Julian Stecklina and Thomas Prescher. Lazyfp: Leaking fpu register state using microarchitectural side-channels, 2018. [48] Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour. Policy gradient methods for reinforce- ment learning with function approximation. Advances in neural information processing systems, 12, 1999. [49] Daniel Tarlow, Subhodeep Moitra, Andrew Rice, Zimin Chen, Pierre-Antoine Manzagol, Charles Sutton, and Edward Aftandilian. Learning to fix build errors with graph2diff neural networks. In Proceedings of the IEEE ACM 42nd international conference on software engineering workshops, pages 19 20, 2020. [50] M. Caner Tol, Berk Gulmezoglu, Koray Yurtseven, and Berk Sunar. FastSpec: Scalable Generation and De- tection of Spectre Gadgets Using Neural Embeddings. In 2021 IEEE European Symposium on Security and Privacy (EuroS P), pages 616 632. IEEE, 2021. [51] M. Caner Tol and Berk Sunar. Zeroleak: Using llms for scalable and cost effective side-channel patching. arXiv preprint arXiv:2308.13062, 2023. [52] Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F. Wenisch, Yuval Yarom, and Raoul Strackx. Foreshadow: Extracting the keys to the Intel SGX king- dom with transient out-of-order execution. In Proceed- ings of the 27th USENIX Security Symposium, August 2018. [53] Jo Van Bulck, Daniel Moghimi, Michael Schwarz, Moritz Lipp, Marina Minkin, Daniel Genkin, Yarom Yuval, Berk Sunar, Daniel Gruss, and Frank Piessens. LVI: Hijacking Transient Execution through Microarchi- tectural Load Value Injection. In 41th IEEE Symposium on Security and Privacy (S P 20), 2020. [54] Jo Van Bulck, Daniel Moghimi, Michael Schwarz, Moritz Lippi, Marina Minkin, Daniel Genkin, Yuval Yarom, Berk Sunar, Daniel Gruss, and Frank Piessens. Lvi: Hijacking transient execution through microarchi- tectural load value injection. In 2020 IEEE Symposium on Security and Privacy (SP), pages 54 72. IEEE, 2020. [55] Stephan Van Schaik, Alyssa Milburn, Sebastian Öster- lund, Pietro Frigo, Giorgi Maisuradze, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. Ridl: Rogue in- flight data load. In 2019 IEEE Symposium on Security and Privacy (SP), pages 88 105. IEEE, 2019. [56] Guanhua Wang, Sudipta Chattopadhyay, Arnab Ku- mar Biswas, Tulika Mitra, and Abhik Roychoudhury. Kleespectre: Detecting information leakage through speculative cache attacks via symbolic execution. arXiv preprint arXiv:1909.00647, 2019. [57] Daniel Weber, Ahmad Ibrahim, Hamed Nemati, Michael Schwarz, and Christian Rossow. Osiris: Automated discovery of microarchitectural side channels. In 30th USENIX Security Symposium (USENIX Security 21), pages 1415 1432, 2021. [58] Jan Wichelmann, Ahmad Moghimi, Thomas Eisenbarth, and Berk Sunar. Microwalk: A framework for finding side channels in binaries. In Proceedings of the 34th Annual Computer Security Applications Conference. As- sociation for Computing Machinery, 2018. [59] Jan Wichelmann, Florian Sieck, Anna Pätschke, and Thomas Eisenbarth. Microwalk-ci: practical side- channel analysis for javascript applications. In Proceed- ings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, 2022. [60] Yi Wu, Nan Jiang, Hung Viet Pham, Thibaud Lutellier, Jordan Davis, Lin Tan, Petr Babkin, and Sameena Shah. How effective are neural networks for fixing security vulnerabilities. arXiv preprint arXiv:2305.18607, 2023. 16 [61] Yuval Yarom and Katrina Falkner. Flush reload: a high resolution, low noise, l3 cache side-channel attack. In 23rd {USENIX} Security Symposium ({USENIX} Security 14), pages 719 732, 2014. [62] Michihiro Yasunaga and Percy Liang. Break-it-fix-it: Unsupervised learning for program repair. In Interna- tional Conference on Machine Learning, pages 11941 11952. PMLR, 2021. A Explanation of CPU Performance Events This section provides explanations for each of the CPU per- formance events listed in Table 1: UOPS_ISSUED.ANY: This event counts the total num- ber of micro-operations (uops) issued by the front end of the processor. It helps to understand how often the CPU is generating work for the execution units. UOPS_RETIRED.RETIRE_SLOTS: This counter measures the number of micro-operations that have been retired, representing the slots used in the retirement stage. High values indicate effective utilization of the CPU pipeline. INT_MISC.RECOVERY_CYCLES_ANY: This event counts the cycles the processor spends in recovery due to issues in the integer pipeline, such as branch mispredictions. It provides insight into potential inefficiencies in the execution flow. MACHINE_CLEARS.COUNT: This counter tracks the total number of machine clears. Machine clears occur when the processor needs to flush the pipeline, often due to errors or interruptions, impacting overall performance. MACHINE_CLEARS.SMC: This event counts ma- chine clears specifically triggered by self-modifying code. Self-modifying code requires the processor to in- validate instructions and restart, which is costly in terms of performance. MACHINE_CLEARS.MEMORY_ORDERING: This counter registers machine clears due to memory ordering conflicts. Such conflicts require the CPU to reset and reorder memory accesses, which can degrade performance in multithreaded applications. FP_ASSIST.ANY: This event counts floating-point as- sists, which are special handling operations needed to process floating-point instructions. High counts may in- dicate heavy floating-point computation workloads or suboptimal code for floating-point operations. Figure 12: Leak rates for VERW measured in Skylake-X. OTHER_ASSISTS.ANY: This counter registers other assist events, including exceptions and corrections for specific instructions or situations. This can give insight into issues like misaligned memory access or uncommon instruction usage. CPU_CLK_UNHALTED.ONE_THREAD_ACTIVE: This event measures the number of cycles during which at least one thread is active. This counter is useful for understanding overall CPU utilization, especially in multi-threaded environments. CPU_CLK_UNHALTED.THREAD: This counter measures the cycles during which a specific thread re- mains active. It provides data on individual thread activ- ity and allows for a more granular view of CPU utiliza- tion. HLE_RETIRED.ABORTED_UNFRIENDLY: This event counts the hardware lock elision (HLE) transac- tions that were aborted due to unfriendly reasons, such as interference by other threads or incompatible instruc- tions. High values can indicate issues with lock-based concurrency. HW_INTERRUPTS.RECEIVED: This counter mea- sures the number of hardware interrupts received by the processor. Hardware interrupts are signals from exter- nal devices that require immediate attention, potentially affecting processor performance by disrupting normal execution flow. B Leakage Rates Analysis on Skylake Leak rates for VERW measured in Skylake-X is given in Figure 12. C Other µRL-discovered Transient Execution Mechanisms LAR. The LAR instruction loads the access rights of a seg- ment into a register, based on the segment selector provided. 17 Figure 13: Leak rates for LAR measured in Raptor Lake. It is useful for managing memory segmentation and ensuring the correct privilege levels when accessing different memory regions. Leak rates for LAR measured in Raptor Lake in Fig- ure 13. Four instruction sequences with LAR leakage are given in Listing 6. LSL RDSP. The LSL instruction loads the memory segment limit from a specified segment selector into a register, which is useful for segmentation tasks by providing the size of a memory segment, helping with boundary checks. Leak rates for LSL RDTSCP measured in Raptor Lake. Leak rates for LSL RDTSCP measured in Raptor Lake are given in Fig- ure 14. D Leakage Rate Analysis on Previously Known Transient Execution Mechanisms Leakage rates for previously known mechanisms such as FP assist, MD, MO and SMC on Raptor lake are given in Fig- ure 15, 16, 17 and 18. E Instruction Sets 1 ; seq 1: leaks through LAR 2 rep 500 3 LAR RAX , [R15] 4 MULX RAX , RAX , qword [R15] 5 endrep 6 ; seq 2: leaks through LAR 7 rep 500 8 LAR RCX , [R15] 9 ADCX RCX , qword [R15] 10 CMOVNL EAX, EDX 11 endrep 12 ; seq 3: leaks through LAR 13 rep 500 14 LAR AX, [R15] 15 RDTSCP 16 endrep 17 ; seq 4: more stable leakage with prefetchwt1 18 rep 500 19 PREFETCHWT1 byte [R15] 20 LAR ESP, [R15] 21 LZCNT EBX, dword [R15] 22 endrep 23 ; seq 5: no dependency 24 rep 500 25 LAR DX, DX 26 LOCK CMPXCHG16B [R15] 27 endrep 28 ; seq 6: no dependency 29 rep 500 30 WRGSBASE RSP 31 CMPXCHG16B [R15] 32 LAR DX, AX 33 TZCNT RDX , qword [R15] 34 PEXT RBX , RDX , RAX 35 endrep Listing 6: Four instruction sequences with LAR leakage Figure 14: Leak rates for LSL RDTSCP measured in Raptor Lake. 18 Figure 15: Leak rates for FP assist measured in Raptor Lake. Figure 16: Leak rates for Memory disambiguation measured in Raptor Lake. Figure 17: Leak rates for Memory ordering measured in Rap- tor Lake. Figure 18: Leak rates for SMC measured in Raptor Lake. Instruction Set Count Instruction Set Count ADOX_ADCX 8 AES 12 AVX 695 AVX2 286 AVX2GATHER 16 AVX512F_512 2192 AVX512F_128 1816 AVX512F_256 1940 AVX512F_SCALAR 584 AVX512DQ_128 247 AVX512DQ_256 281 AVX512DQ_512 357 AVX512BW_128 467 AVX512BW_256 467 AVX512BW_512 467 AVX512F_128N 23 AVX512DQ_SCALAR 44 AVX512CD_512 38 AVX512CD_128 38 AVX512CD_256 38 AVX512BW_128N 8 AVX512DQ_128N 8 AVX512DQ_KOP 18 AVX512BW_KOP 34 AVX512F_KOP 15 AVXAES 12 I86 809 I386 196 I486REAL 37 CMOV 96 PENTIUMREAL 5 I186 124 LONGMODE 24 LAHF 2 I286PROTECTED 26 I286REAL 10 FAT_NOP 3 RDPMC 1 PPRO 2 BMI1 26 BMI2 32 CET 2 F16C 8 FMA 192 INVPCID 1 CMPXCHG16B 2 LZCNT 6 PENTIUMMMX 129 SSE 97 MOVBE 6 PCLMULQDQ 2 RDRAND 3 RDSEED 3 RDTSCP 1 RDWRFSGS 8 FXSAVE 2 FXSAVE64 2 SSEMXCSR 2 SSE2 264 SSE2MMX 6 SSE3 20 SSE3X87 2 SSE4 96 SSE42 25 POPCNT 6 SSSE3MMX 32 SSSE3 32 X87 119 FCMOV 8 FCOMI 4 XSAVE 6 XSAVEC 2 XSAVEOPT 2 XSAVES 4 Table 3: Number of instructions per set used in the action space for Skylake-X. 19\n\n=== SEGMENTS ===\n\n--- Segment 1 ---\nµRL: Discovering Transient Execution Vulnerabilities Using Reinforcement Learning M. Caner Tol Worcester Polytechnic Institute Kemal Derya Worcester Polytechnic Institute Berk Sunar Worcester Polytechnic Institute Abstract We propose using reinforcement learning to address the chal- lenges of discovering microarchitectural vulnerabilities, such as Spectre and Meltdown, which exploit subtle interactions in modern processors. Traditional methods like random fuzzing fail to efficiently explore the vast instruction space and often miss vulnerabilities that manifest under specific conditions. To overcome this, we introduce an intelligent, feedback-driven approach using RL. Our RL agents interact with the proces- sor, learning from real-time feedback to prioritize instruction sequences more likely to reveal vulnerabilities, significantly improving the efficiency of the discovery process. We also demonstrate that RL systems adapt effectively to various microarchitectures, providing a scalable solution across processor generations. By automating the exploration process, we reduce the need for human intervention, enabling continuous learning that uncovers hidden vulnerabilities. Ad- ditionally, our approach detects subtle signals, such as tim- ing anomalies or unusual cache behavior, that may indicate microarchitectural weaknesses. This proposal advances hard- ware security testing by introducing a more efficient, adaptive, and systematic framework for protecting modern processors. When unleashed on Intel Skylake-X and Raptor Lake mi- croarchitectures, our RL agent was indeed able to generate instruction sequences that cause significant observable byte leakages through transient execution without generating any µcode assists, faults or interrupts. The newly identified leaky sequences stem from a variety of Intel instructions, e.g. in- cluding SERIALIZE, VERR VERW, CLMUL, MMX-x87 transitions, LSL RDSCP and LAR. These initial results give credence to the proposed approach. 1 Introduction In the past two decades, our computing systems have evolved and grown at an astounding rate. A side effect of this growth has been increased resource sharing and, with it, erosion of isolation boundaries. Multitenancy has already been shown to be a significant security and privacy threat in shared cloud instances. VM boundaries can be invalidated either by soft- ware or hardware bugs [10,21,33,54] or by exploiting subtle information leakages at the hardware level [34]. Microarchitectural Threats.\n\n--- Segment 2 ---\nVM boundaries can be invalidated either by soft- ware or hardware bugs [10,21,33,54] or by exploiting subtle information leakages at the hardware level [34]. Microarchitectural Threats. Arguably, one of the greatest security threats comes from attacks that target the implemen- tation through side-channels or from hardware vulnerabilities. Such attacks started as a niche exploiting leakages through execution timing, power, and electromagnetic emanations but later evolved to exploit microarchitectural (µArch ) leakages, e.g. through shared cache and memory subsystems, specula- tive execution, shared peripherals, etc. µArch threats repre- sent one of the most significant types of vulnerabilities since they can be carried out remotely with software access only. Prime examples of these threats are the early execution tim- ing [25] and cache attacks [29,29,61], and later Meltdown, Spectre [24], and MDS attacks [4, 33, 53] which allow an unprivileged user to access privileged memory space break- ing isolation mechanisms such as memory space isolation across processes, cores, browsers tabs and even virtual ma- chines hosted on shared cloud instances. Active attacks, e.g. Rowhammer, have also proven effective in recovering sensi- tive information [26] and [3,36]. While numerous practical countermeasures were proposed and implemented, there re- mains a massive attack surface unexplored. Indeed, 5 years after Meltdown was mitigated (August 2023), a new transient execution vulnerability, Downfall [32], was discovered that exploits speculative data gathering and allows Meltdown-style data leakage and even injection across threads. Lack of Access to Design Internals. A significant factor contributing to the difficulty of evaluating the security of large-scale computer systems is that design details are rarely disclosed. Given only superficial interface definitions, re- searchers are forced to reverse engineering and black box analysis. While companies have access to the internals of their system, it is hard to argue that they are aware of their own designs either due to third-party IPs, mobility of engineers, and silos isolating their engineering teams from each other. 1 arXiv:2502.14307v1 [cs.CR] 20 Feb 2025 IPs are orphaned with little superficial information surviving after only a few years of breaking institutional memory.\n\n--- Segment 3 ---\nWhile companies have access to the internals of their system, it is hard to argue that they are aware of their own designs either due to third-party IPs, mobility of engineers, and silos isolating their engineering teams from each other. 1 arXiv:2502.14307v1 [cs.CR] 20 Feb 2025 IPs are orphaned with little superficial information surviving after only a few years of breaking institutional memory. These factors combined pose a great danger for µArch security. The primary goal of the proposed work is to answer the fol- lowing question: Can we use AI to automatically find brand- new vulnerabilities? In practical terms, can we build an AI agent that can discover the next Meltdown or Spectre vulner- abilities? Currently, there are intense efforts in the cyberse- curity research community to deploy AI tools to scan Open Source Software (OSS) for known vulnerabilities, e.g. for detection in µArch we have [5, 12, 16, 56, 58, 59] and for patching [13,17,40,49,60,62] and [51]. We take on a more challenging problem and investigate how we can build an AI Agent that constantly searches the target platform for brand new µArch vulnerabilities. In a way, such an ability would bring true scalability and a tipping point since, if granted, we could surpass human abilities by creating as many AI Agents as we want by just throwing more cycles at the problem. In the hands of software hardware ven- dors, such a tool would allow us to address vulnerabilities early on before the software advances deeper in the deploy- ment pipeline. What is missing is the know-how to put such a system together i.e. a tool that can constantly analyze a hardware software stack under popular configurations, iden- tify and report found vulnerabilities, articulating cause and effect and severity of the vulnerability. In this work, we take inspiration from cybersecurity researchers on how they came up with new vulnerabilities: Randomization. There is a healthy dose of manual or au- tomated trial and error in discovering new vulnerabilities. In µArch security fuzzing has become an indispensable tool to test randomized attack vectors and thereby identify or generate improved versions of vulnerabilities. For in- stance, Oleksenko et al. [38] developed SpecFuzz to test for speculative execution vulnerabilities.\n\n--- Segment 4 ---\nFor in- stance, Oleksenko et al. [38] developed SpecFuzz to test for speculative execution vulnerabilities. The tool combines dy- namic simulation with conventional fuzzing for the identifi- cation of potential Spectre vulnerabilities. Another example is Transyther [33] , a mutational fuzzing tool that generates Meltdown variants and tests them to discover leaks. Tran- syther found a previously unknown transient execution attack through the word combining buffer in Intel CPUs [33]. In [22], Jattke et al. use fuzzing to discover non-uniform hammering patterns to make Rowhammer fault injection viable in a large class of DRAM devices. While effective, fuzzing, as currently practiced in µArch security, only works in small domains and fails to scale to cover larger domains to discover new vulnerabilities. Indeed, SpecFuzz for Spectre v1 is only able to Spectre gadgets, and Transyther discovered the Medusa vulnerability since it is reachable with mild randomization from Meltdown variants. The discovery of the timing channel by Kocher [25] led to the discovery of cache-timing attacks [39]. Similarly, shar- ing in Branch Prediction Units (BPUs) led to the exploita- tion of secret dependent branching behavior to recover leak- ages [2]. These attacks led to µArch Covert Channels that may be used intentionally to exfiltrate data, e.g. by signaling via cache access patterns and break isolation mechanisms. Covert-channels were first used by many researchers as an ini- tial demonstration of the existence of a side-channel, with the channel rate providing a measure for the level of the leakage. Covert channels and manipulations in BPUs, in turn, became enablers for Transient Execution Attacks such as Meltdown, Spectre, and later MDS attacks. Further, the recent work [32] uses the Meltdown style data leakage and the LVI style [53] data injection mechanisms in the context of SIMD instruc- tions to discover new vulnerabilities. The x86 instruction set is a complex architecture that supports thousands of instructions, registers, and addressing modes, with each microarchitecture adding layers of optimiza- tions for performance and efficiency.\n\n--- Segment 5 ---\nFurther, the recent work [32] uses the Meltdown style data leakage and the LVI style [53] data injection mechanisms in the context of SIMD instruc- tions to discover new vulnerabilities. The x86 instruction set is a complex architecture that supports thousands of instructions, registers, and addressing modes, with each microarchitecture adding layers of optimiza- tions for performance and efficiency. These optimizations, while beneficial, introduce complexities that can hide vulner- abilities, as seen with exploits like Meltdown and Spectre, which exploit unexpected microarchitectural behavior to ex- pose sensitive data. Traditional testing methods like random fuzzing are inadequate due to the vast number of instruc- tion combinations and the specific, rare conditions that often trigger vulnerabilities. Complex features like out-of-order and speculative execution increase both performance and the difficulty of detecting flaws, making the discovery of microar- chitectural vulnerabilities challenging. An effective approach involves intelligent, feedback-based testing, where processor behavior under different conditions guides the search for vulnerabilities. This approach allows testing to focus on high-priority areas, improving efficiency and effectiveness. Feedback mechanisms can also adapt to new microarchitectures, adjusting their methods for each pro- cessor generation, an essential feature given the rapid evolu- tion of hardware designs. Machine Learning (ML) enhances this feedback-driven approach by identifying patterns in cache or power usage that indicate potential vulnerabilities. Over time, ML models improve, enabling more systematic and scal- able vulnerability discovery across diverse processor designs. RL further advances this approach, using a reward-based sys- tem to optimize instruction space exploration. RL agents pri- oritize instruction sequences that reveal anomalies, efficiently balancing exploration with exploiting known vulnerabilities, making them suitable for evolving architectures. In summary, random fuzzing alone is insufficient for dis- covering vulnerabilities in modern x86 microarchitectures. Integrating feedback mechanisms with RL allows a more targeted, adaptable, and effective approach, essential for un- covering hidden vulnerabilities and maintaining security in rapidly advancing processor designs. In this work, we make the following contributions: 1. We propose a novel approach to discovering microarchi- tectural vulnerabilities using RL. 2. We develop a custom RL environment that simulates the execution of x86 instructions on a microarchitecture, 2 allowing the agent to explore the instruction space. 3.\n\n--- Segment 6 ---\nWe develop a custom RL environment that simulates the execution of x86 instructions on a microarchitecture, 2 allowing the agent to explore the instruction space. 3. We find new transient execution based leakage mecha- nisms on Intel Skylake-X and Raptor Lake microarchi- tectures based on masked FP exceptions and MME x87 transitions demonstrating the effectiveness of the RL agent in discovering vulnerabilities. 2 Related Works µArch vulnerability discovery has attracted significant atten- tion, leading to the development of several tools and method- ologies aimed at exposing speculative execution and side- channel vulnerabilities. Osiris [57] introduces a fuzzing- based framework that automates the discovery of timing- based µArch side channels by using an instruction-sequence triple notation: reset instruction (setting the µArch compo- nent to a known state), a trigger instruction (modifying the state based on secret-dependent operations), and a measure- ment instruction (extracting the secret by timing differences). Transynther [32,33] automates exploring Meltdown-type at- tacks by synthesizing binarizes based on the known attack patterns. For the classification and root cause analysis of the generated attacks, Transynther uses performance counters and µArch buffer grooming technique. AutoCAT [30] au- tomates the discovery of cache-based side-channel attacks on unknown cache structures using RL. Several studies also focus on using hardware performance counters to detect spec- ulative execution issues. For example, [37, 42] use perfor- mance counters to monitor mis-speculation behavior. More recently, [6] proposed a particle swarm optimization based algorithm to discover unknown transient paths. Their main assumption is different instruction sets do not interfere with each other do not share the same resources, therefore, they can be analysed independently. In this dissertation, we show that this assumption limits the exploration of the instruction space and combining different instruction sets can lead to new mechanisms of transient execution. Although, these tools have shown promise in detecting µArch vulnerabities, they are limited in their ability to effi- ciently explore the large instruction space and the complex interactions between different instructions. 3 Background 3.1 Microarchitectural Attacks 3.1.1 Cache Timing Side Channel Attacks The state of the shared cache can be observed to detect the memory access patterns.\n\n--- Segment 7 ---\nAlthough, these tools have shown promise in detecting µArch vulnerabities, they are limited in their ability to effi- ciently explore the large instruction space and the complex interactions between different instructions. 3 Background 3.1 Microarchitectural Attacks 3.1.1 Cache Timing Side Channel Attacks The state of the shared cache can be observed to detect the memory access patterns. Over the past years, different tech- niques have been developed to extract sensible data by using cache timing as a side-channel attack. Flush Reload [61] leverages the Last-Level Cache (L3 cache) to monitor memory access patterns in shared pages. While it does not require the attacker and victim to share the same execution core, it flushes a potential victim address from the cache, and then measures the reload time if the target address is accessed. EVICT RELOAD [15] is another work where an eviction technique is used when cache flushing is not available. Prime Probe [29] exploits the eviction sets to detect access patterns and it does not require shared memory between attacker and victim. The Flush Flush attack [14] ex- ploits the timing variations of the clflush. The Evict Time attack [39] uses timing differences between cache hits and misses to infer cache state, allowing an attacker to detect cache misses and deduce access patterns. Although more advanced cache side-channel attacks [11, 20,41], in this work, we use Flush Reload for its simplicity and effectiveness. 3.1.2 Transient Execution Attacks Transient execution attacks exploit speculative and out-of- order execution in CPUs to access restricted data temporarily, leaving traces in the cache that attackers can analyze. Spectre attacks [24] exploit speculative execution and branch prediction in modern processors to leak confidential in- formation across security boundaries. By inducing speculative operations that bypass normal execution flow, attackers can access sensitive memory and registers, creating side-channel leaks. NetSpectre [46] is the first remote variant of the Spectre attack, extending its reach beyond local code execution. Net- Spectre marks a significant shift from local to remote attacks, making Spectre a threat even to systems where no attacker- controlled code is executed, including cloud environments. SgxPectre attack [7] exploits CPU vulnerabilities to com- promise the confidentiality and integrity of SGX enclaves.\n\n--- Segment 8 ---\nNet- Spectre marks a significant shift from local to remote attacks, making Spectre a threat even to systems where no attacker- controlled code is executed, including cloud environments. SgxPectre attack [7] exploits CPU vulnerabilities to com- promise the confidentiality and integrity of SGX enclaves. By manipulating branch prediction from outside the enclave, attackers can temporarily alter the enclave s control flow, pro- ducing cache-state changes that reveal sensitive information within the enclave. Meltdown [28] bypasses memory isolation by exploiting out-of-order execution in modern processors to access pro- tected kernel memory. This enables attackers to read memory from other processes or virtual machines without permission, posing a severe risk to millions of users. Foreshadow [52] is a microarchitectural attack exploiting speculative execution flaws in Intel processors to breach SGX security. Without needing kernel access or assumptions about enclave code, Foreshadow leaks enclave secrets from the CPU cache. Rogue In-flight Data Load (RIDL) [55] is a speculative execution attack that leaks data across address spaces and privilege boundaries. RIDL retrieves in-flight data directly from CPU components without relying on cache or trans- lation structures, making it uniquely invasive and effective. Fallout [4] reveals that Meltdown-like attacks remain feasible on newer CPUs that are supposedly immune to Meltdown due to hardware fixes. By examining the behavior of the store 3 buffer, they uncover vulnerabilities. ZombieLoad [45] is a Meltdown-type attack that exploits a vulnerability in the processor s fill-buffer logic to leak data across logical CPU cores, even on CPUs with hardware miti- gations against Meltdown and MDS. ZombieLoad uses fault- ing load instructions to transiently access unauthorized data in the fill buffer. Load Value Injection (LVI) [54] is a technique that generalizes injection-based attacks to the memory hier- archy by injecting attacker-controlled values into a victim s transient execution. Downfall [32] is a new class of transient execution attacks that exploit the gather instruction on x86 CPUs to leak sensitive data across security boundaries, in- cluding user-kernel, process, and virtual machine isolation, as well as trusted execution environments.\n\n--- Segment 9 ---\nLoad Value Injection (LVI) [54] is a technique that generalizes injection-based attacks to the memory hier- archy by injecting attacker-controlled values into a victim s transient execution. Downfall [32] is a new class of transient execution attacks that exploit the gather instruction on x86 CPUs to leak sensitive data across security boundaries, in- cluding user-kernel, process, and virtual machine isolation, as well as trusted execution environments. 3.2 Reinforcement Learning In RL, the objective is for an agent to learn a policy πθ(a s), parameterized by θ, which maximizes the expected cumu- lative reward through its chosen actions in an environment. The policy gradient method [48] computes the gradient of the expected reward with respect to the policy parameters, allowing the agent to directly update the policy by following the gradient. Formally, the objective function J(θ) is defined as: J(θ) Eπθ " T t 0 rt , where rt is the reward at time step t, and the expectation is over the trajectories induced by the policy πθ. The policy is updated by adjusting θ in the direction of the gradient θJ(θ) using gradient ascent. One of the major challenges with vanilla policy gradient methods is the high variance of the gradient estimates, which can lead to unstable learning. Additionally, large updates to the policy parameters θ can cause dramatic changes to the policy, potentially leading to performance col- lapse. Trust Region Policy Optimization (TRPO) [43] was proposed to address this issue by enforcing a constraint on the size of policy updates using a trust region. TRPO introduces the following constrained optimization problem: max θ Eπθ πθ(a s) πθold(a s) ˆA(s,a) subject to Es DKL πθold πθ δ where DKL is the Kullback-Leibler (KL) divergence, ˆA(s,a) is the advantage estimate, and δ is a small positive value controlling the step size. However, TRPO is computationally expensive due to the need for second-order optimization to enforce the KL-divergence constraint.\n\n--- Segment 10 ---\nTRPO introduces the following constrained optimization problem: max θ Eπθ πθ(a s) πθold(a s) ˆA(s,a) subject to Es DKL πθold πθ δ where DKL is the Kullback-Leibler (KL) divergence, ˆA(s,a) is the advantage estimate, and δ is a small positive value controlling the step size. However, TRPO is computationally expensive due to the need for second-order optimization to enforce the KL-divergence constraint. Proximal Policy Optimization (PPO) [44] simplifies TRPO by replacing the hard constraint on policy updates with a penalty or by using a clipped objective function. The key idea behind PPO is to ensure that policy updates are proximal to the current policy, preventing drastic updates that could lead to instability. In this work, we use PPO with clipped objective. In this ap- proach, PPO clips the probability ratio πθ(a s) πθold(a s) to lie within a small interval around 1, preventing large updates. The clipped objective is defined as: LCLIP(θ) E min r(θ) ˆA(s,a),clip(r(θ),1 ε,1 ε) ˆA(s,a) , where r(θ) πθ(a s) πθold(a s) is the probability ratio, and ε is a small hyperparameter that limits how far the policy is allowed to change. By clipping the probability ratio, PPO discourages overly large updates while still allowing for sufficient explo- ration of the policy space. 4 Threat Model and Scope Our threat model considers scenarios where attacker and vic- tim processes are co-located in shared hardware environments, which expose vulnerabilities to µArch attacks. Co-location can manifest in several forms, including but not limited to threads on the same process, processes on the same host and virtual machines on a shared server. These attacks exploit shared µArch resources to infer sensitive data from victim pro- cesses, bypassing traditional memory isolation mechanisms.\n\n--- Segment 11 ---\nCo-location can manifest in several forms, including but not limited to threads on the same process, processes on the same host and virtual machines on a shared server. These attacks exploit shared µArch resources to infer sensitive data from victim pro- cesses, bypassing traditional memory isolation mechanisms. We assume the CPU microcode is up-to-date with the latest mitigations, and the software has no bugs and SMT is enabled. We assume no access to the confidential design details of the processor, limiting our analysis to black-box testing. This restriction reflects the real-world scenario where attackers must rely on external observations and performance counters to reverse-engineer the processor s internal behavior. Although we have not seen example of such an exploit in real-life yet, if unmitigated, these attacks can lead to signifi- cant data breaches, including the extraction of cryptographic keys and other sensitive information. In this work, we fo- cus on discovering µArch vulnerabilities using reinforcement learning and we focus on the following questions: Q1. How can we design an RL framework that efficiently explores the µArch space? Q2. Can RL discover unknown µArch vulnerabilities? Q3. What are the challenges and limitations of using RL for µArch vulnerability discovery? 5 Our RL Framework In this section, we introduce our RL framework designed for µArch vulnerability analysis. Automated analysis of µArch vulnerabilities poses the following challanges some of which were also identified in earlier works [6,33,57]: C1. Modern processor designs are complex and their in- structions sets are large. Exhaustive search in the instruction space is infeasible. 4 PMAXUD XMM2, XMM2 Action Reward Observation State RL agent Exceptions Performance Counters Flush Reload text embedding model Legal Instruction Set Dynamic Testing asm embeddings Processor ROR EBX, 0 PADDQ MM3, qword [R15] FUCOMIP ST1 VMOVDDUP YMM1, YMM1 KMOVD dword [R15], K2 PMAXUD XMM2, XMM2 Figure 1: Overview of the RL framework for µArch vulnerability analysis; L before the Observation denotes concatenation. L before Reward represents Equation 1. C2. Mapping an instruction sequence to a certain µArch vulnerability is non-trivial and requires expert knowledge. C3.\n\n--- Segment 12 ---\nMapping an instruction sequence to a certain µArch vulnerability is non-trivial and requires expert knowledge. C3. The environment is high-dimensional and non-linear and the system state is only partially observable. Earlier works attempted to solve C1 by either limiting the type of instructions [6, 37] or limiting the length of the in- struction sequence [57]. In this work, we propose a novel approach to address this challenge by leveraging RL to guide the search for µArch vulnerabilities. Our framework is de- signed to efficiently explore the instruction space, learn the optimal policy for selecting instruction sequences, repoduce known vulnerability and, if exists, discover unknown vulnera- bilities. The framework is illustrated in Figure 1 and consists of the following components: 5.1 Environment We build a custom environment based on the underlying CPU model. The environment represents a black-box model of the CPU microarchitecture, where the agent can only interact with the CPU through the instruction sequences. It takes the instruction sequences generated by the RL agent, executes them on the CPU, and returns an observation and a reward. It also updates the state after every action taken. At the start of each episode, the environment initializes by resetting the instruction state and clearing the performance counter readings. A reset function is triggered at the begin- ning of each new episode to ensure the agent starts with a fresh state. All sequences, performance metrics, and de- tected byte leakages are logged for post-training analysis. The logged data aids in identifying patterns or characteristics in sequences that lead to vulnerabilities and provides insights into the agent s decision-making process. 5.2 RL Agent The RL agent is a multi-layer perceptron (MLP) that generates actions based on observations given by the environment. In this case, the agent s goal is to select an instruction that will be appended to the instruction sequence. The agent is trained using the PPO algorithm. The goal of the agent is to maximize the reward signal by selecting the best sequence of actions and eventually trigger µArch vulnerabilities. 5.3 Action Space We define an action as the selection of an assembly instruc- tion from the instruction set. To map the discrete actions to actual assembly instructions, we use [1]. The action space is constrained to instructions that are supported by the CPU under test and documented by the vendor. This constraint helps the agent focus on relevant instructions that exist in the real-world programs.\n\n--- Segment 13 ---\nThe action space is constrained to instructions that are supported by the CPU under test and documented by the vendor. This constraint helps the agent focus on relevant instructions that exist in the real-world programs. Since some of the instruction exten- sions has large number of instructions and operand variety, (e.g. AVX-512), we construct the action space hierarchically. For example, we first select the instruction set (e.g. AVX-512), then the instruction (e.g. VMOVDDUP), and finally the operands (e.g. XMM0, XMM1). This hierarchical structure helps prevent larger instructions sets dominating the smaller ones since the agent will initially randomly select insturction during the ex- ploration phase. To handle the difference in the number of instructions in each set, we use map different actions to the same insturction or operands using them modulo operation. For instance, if the maximum number of instructions in a set is 10 but the model selected the 12th instruction, we map it to the 12 mod 10 2nd instruction in the selected set. 5 5.4 State Eventhough, there are more variables that affect the CPU state other than just the input instruction sequence, such as, cache content, internal buffers, registers, etc., we simplify the state representation to only the instruction sequence. The impact of other factors that affects the CPU state can be minimize by running the same instruction sequence multiple times until the real state becomes stable, which is a common practice in µArch attacks [29, 61]. After each action, the generated assembly instruction is added to the current state. 5.5 Observation Since we do not have access to hardware debug interface, we cannot directly observe the entire state of the CPU. Therefore, it is a partially observable environment and the observation can only capture a subset of the environment state as it is mentioned in C3. We tackle this challange by designing an observation space that consists of a static and a dynamic part. The static part of the observation is the generated instruc- tion sequence. Similar to the earlier works [31,50], we use embeddings to convert the instruction sequence into high- dimensional fixed-size vectors using a pre-trained LLM. Em- beddings capture the patterns in the assembly code so that the agent understand the structural and functional dependen- cies between instructions.\n\n--- Segment 14 ---\nSimilar to the earlier works [31,50], we use embeddings to convert the instruction sequence into high- dimensional fixed-size vectors using a pre-trained LLM. Em- beddings capture the patterns in the assembly code so that the agent understand the structural and functional dependen- cies between instructions. Before inclusion in the observation space, embeddings undergo normalization to ensure consis- tency in data scales. The dynamic part of the observation is the hardware perfor- mance counters. Vendors give access to low-level monitoring of the CPU events such that developers can identify bottle- necks in their applicaitons and optimize the performance. In this work, we use the performance counters to partially cap- ture the CPU state. For measurement, we embed instruction sequences in a template assembly file, ensuring valid mem- ory addresses in R15 register to prevent segmentation faults. General-purpose registers are preserved on the stack to avoid unintended corruption. Each sequence is executed multiple times to minimize noise. We use the performance counters listed in Table 1. The explanation of these counters are given in the Appendix A. These counters are selected based on their relevance to speculative execution vulnerabilities shown by previous re- search [6,37,42] as well as Intel s performance monitoring tools [8]. 5.6 Reward Function The reward function is often seen as the most critical compo- nent of the RL frameworks since it steers the agent behavior. We address the challenge C2 by carefully designing the re- ward function. The instruction sequences selected by the agent are ex- ecuted on the CPU, and the CPU s behavior is monitored HW Performance Event Name UOPS_ISSUED.ANY UOPS_RETIRED.RETIRE_SLOTS INT_MISC.RECOVERY_CYCLES_ANY MACHINE_CLEARS.COUNT MACHINE_CLEARS.SMC MACHINE_CLEARS.MEMORY_ORDERING FP_ASSIST.ANYa OTHER_ASSISTS.ANYb CPU_CLK_UNHALTED.ONE_THREAD_ACTIVE CPU_CLK_UNHALTED.THREAD HLE_RETIRED.ABORTED_UNFRIENDLYc HW_INTERRUPTS.RECEIVEDd Table 1: List of used CPU performance events available in Skylake-X.\n\n--- Segment 15 ---\nWe address the challenge C2 by carefully designing the re- ward function. The instruction sequences selected by the agent are ex- ecuted on the CPU, and the CPU s behavior is monitored HW Performance Event Name UOPS_ISSUED.ANY UOPS_RETIRED.RETIRE_SLOTS INT_MISC.RECOVERY_CYCLES_ANY MACHINE_CLEARS.COUNT MACHINE_CLEARS.SMC MACHINE_CLEARS.MEMORY_ORDERING FP_ASSIST.ANYa OTHER_ASSISTS.ANYb CPU_CLK_UNHALTED.ONE_THREAD_ACTIVE CPU_CLK_UNHALTED.THREAD HLE_RETIRED.ABORTED_UNFRIENDLYc HW_INTERRUPTS.RECEIVEDd Table 1: List of used CPU performance events available in Skylake-X. In Raptor Lake, corresponding events: a AS- SISTS.FP, b ASSISTS.ANY, c N A, d N A. using hardware performance counters. The counters provide feedback on the speculative execution and microarchitectural effects of the instructions. The reward function evaluates the performance counter data collected during instruction execution. It assigns rewards based on the presence of speculative execution anomalies, deviations from expected behavior, or other indicators of po- tential vulnerabilities. Reward bad speculation observed byte leakage instruction count (1) Equation 1 shows a simplified version of the reward function we use for training the RL agent. The reward is calculated by dividing the sum of bad speculation and observed byte leak- age by the number of instructions in the sequence. The final reward value is capped at 100 if observed byte leakage 0 and 500 if observed byte leakage 0 to prevent excessive re- wards, promoting stable training. The numbers were decided based on the empirical results. Testing for Bad Speculation. According to Intel s documen- tation [9], bad speculation typically results from branch mis- predictions, machine clears and, in rare cases, self-modifying code. It occurs when a processor fills the instruction pipeline with incorrect operations due to mispredictions. This process leads to wasted cycles, as speculative micro-operations (uops) are discarded if predictions are incorrect, forcing the processor to recover and restart. Although bad speculation is primarily a concern for performance, it also has important security im- plications.\n\n--- Segment 16 ---\nThis process leads to wasted cycles, as speculative micro-operations (uops) are discarded if predictions are incorrect, forcing the processor to recover and restart. Although bad speculation is primarily a concern for performance, it also has important security im- plications. Microarchitectural attacks exploit transient states created by bad speculation. During speculation, the CPU may access sensitive data or load it into the cache, even though the operations will eventually be discarded. These transient states, particularly in cache memory, create opportunities for attackers to infer sensitive data such as encryption keys by analyzing cache behaviors and measuring access times. 6 Intel s formula for quantitatively measurement of bad spec- ulation for a CPU thread is Bad Speculation UOPS_ISSUED.ANY UOPS_RETIRED.RETIRE_SLOTS (4 INT_MISC.RECOVERY_CYCLES) (2) which also what we use in our reward function. If there is an exception detected during the performance counter tests, we terminate the episode, set the reward to - 10 and reset the state. We select this number arbitrarily to differentiate between instruction sequences with no bad spec- ulation vs instruction sequences that do not execute at all. Negative reward discourages the agent from generating ex- ceptions. Note that, handling the exceptions is also possible, but it complicates the reward calculation. Therefore, we leave it for future work. Testing for Observable Byte Leakage. inst_sequence rep N inst_sequence endrep COMPARISON JE exit CACHE_ENCODING exit: RET true F R JNE exit CACHE_ENCODING exit: RET fail false Leakage 0 true false Leakage 0 JE exit lfence CACHE_ENCODING exit: RET false true Leakage 0 JNE exit lfence CACHE_ENCODING exit: RET false true Leakage 0 F R F R F R success Figure 2: Test flow for detecting observable byte leakage. If the performance counter tests executes successfully, we check if the generated instruction sequence results in observ- able byte leakage due to speculative execution. Our testing flow for detecting observable byte leakage is shown in Fig- ure 2. We, first, place the instruction sequence in a template as- sembly file and run it N times using rep directive.\n\n--- Segment 17 ---\nOur testing flow for detecting observable byte leakage is shown in Fig- ure 2. We, first, place the instruction sequence in a template as- sembly file and run it N times using rep directive. Similar to performance counter tests, we use predefined addresses for memory operands and preserve the contents of the general purpose registers in the stack. Then, we execute a comparison operation based on the instructions types and registers used in the generated sequence. If there are multiple types of reg- isters used in the sequence, we select a different comparison instruction specific to that register type. We repeat the test flow for each register type used in the sequence. This way we avoid false negatives due to the register type mismatch. After the comparison, we execute a conditional branch instruction (jump if equal JE) which is followed by cache accesses to an array that encode a predefined sequence of bytes to the cache state. We then measure the access time to the array using Flush Reload [61] to decode the bytes and check if it how much it matches with the encoded bytes. If there is any match, we repeat the same test, this time with the opposite branch condition (jump if not equal JNE). If there is a match in this case, we consider it as an observable byte leakage. Note that, most of the generated seqences fail either in the first or second step of the leakage test. For the remaining sequences that passed the first two tests, we run the same two test after inserting lfence before the branch instruction. If the leakage disappears after adding lfence, we consider it as a successful sequence that causes observable byte leakage through bad speculation. Note that, unlike Spectre-BHT [24], we do not train the branch predictor in the test flow so the root cause of the bad speculation would not be the branch mispredictions unless the generated sequence has the branch predictor training itself using branch instructions. We repeat the test flow for each register type used in the se- quence. This way we avoid false negatives due to the register type mismatch. The number of successfully decoded bytes are fed into the reward function as the observable byte leakage. Since the byte leakage is a more direct signal of the vulnera- bility, we assign a higher weight to it in the reward function. If an exception is detected at this stage, the environment resets to a safe state, logs the exception.\n\n--- Segment 18 ---\nSince the byte leakage is a more direct signal of the vulnera- bility, we assign a higher weight to it in the reward function. If an exception is detected at this stage, the environment resets to a safe state, logs the exception. Only the byte leakage part of the reward is set as zero, yet the bad speculation part is calculated as usual. 6 Experiments Experiment Setup. We run the experiments on two systems with different µArch . The first system has an Intel Core i9 7900X CPU with a Skylake-X µArch . The OS running on the system is Ubuntu 22.04.5 LTS with the Linux v6.5.0 44-generic. We use glib v2.72.4, nasm v2.15.05, and gcc v11.4.0 for compiling and testing the generated assembly files; PyTorch v2.2.1, Stable Baselines3 v2.2.1 and Gymna- sium v0.29.1 for custom RL environment and training the RL agent. The RL agent training and the local inference for the text embedding model are done on the GPU clusters with an NVIDIA TITAN Xp, GeForce GTX TITAN X, and two GeForce GTX 1080Ti. The overview of the experiment setup used in the first system is illustrated in Figure 3. The second system has an Intel i9-14900K CPU with a Raptor Lake µArch , Ubuntu 24.04.1 LTS with Linux v6.8.0- 51-generic, glib v2.80.0, nasm v2.16.01, gcc v13.3.0. Py- torch v2.4.1 cu121, Stable Baselines3 v2.3.2, and Gymna- sium v0.29.1 are used for the same purposes as the first sys- tem. The RL agent training is done on NVIDIA GeForce RTX 4090 GPU.\n\n--- Segment 19 ---\nPy- torch v2.4.1 cu121, Stable Baselines3 v2.3.2, and Gymna- sium v0.29.1 are used for the same purposes as the first sys- tem. The RL agent training is done on NVIDIA GeForce RTX 4090 GPU. For remote inference, we use OpenAI s 7 Core 0 L1d L1i L2 Core 1 L1d L1i L2 L3 Generated instruction sequences Core 2 L1d L1i L2 Core 4 L1d L1i L2 Core 6 L1d L1i L2 Core 8 L1d L1i L2 Core 3 L1d L1i L2 Core 5 L1d L1i L2 Core 7 L1d L1i L2 Core 9 L1d L1i L2 Environment scripts RL agent training Text embedding model inference GPU GPU GPU GPU Figure 3: Experiment Setup on Skylake-X. Each physical core shown in green was allocated to a single instruction sequence at a time. text-embedding-3-small model through the API ac- cess, which allows us to use the parallel core testing since it does not require local GPU memory. Parallelizing the framework across multiple CPU cores enables multiple sequences to be evaluated simultaneously and increases the training speed. Although the last level cache is shared among the cores, each process accesses its own distinct memory region, which does not include any shared libraries or data. Therefore, the cache interference among the processes is minimal. For local inference, we used the NV-Embed-v2 [27, 35] embedding model. However, we observed that it does not accelerate the training overall since the GPU memory is not enough to enable parallel core testing. Therefore, the results presented in this paper are based on the text-embedding-3- small model. In the Skylake-X system, after filtering all illegal instruc- tions from [1], we are left with 12598 instructions that belong to 74 sets. The largest set has 2192 instructions, and the maxi- mum number of possible operands per instruction is 7. These numbers determine the size of the action space for the RL agent. In the Raptor Lake system, 3996 instructions that be- long to 72 sets were left after filtering.\n\n--- Segment 20 ---\nThese numbers determine the size of the action space for the RL agent. In the Raptor Lake system, 3996 instructions that be- long to 72 sets were left after filtering. The largest set has 468 instructions, and the maximum number of operands per instruction is 7. For the agent training, we enable all available kernel mitiga- tions against CPU vulnerabilities. Cumulatively, we collected 27 days worth of data from Skylake-X and 20 days worth of data from Raptor Lake. In the longest runs, we trained an RL agent for 4.5 days and 10.5 days for Skylake-X and Raptor Lake, respectively. In total, the cost for embedding model inference through API calls was 2.46 USD. During the RL agent training, we observe that the average reward of each episode increases over time, as shown in Fig- ure 4. The steady increase in reward indicates that the RL agent was able to successfully explore the x86 instruction Figure 4: The increase of the average reward per episode during the 10 days of agent training in Raptor Lake. An episode corresponds to the largest instruction sequence the agent can generate from scratch. The darker line shows the running mean. Figure 5: The increase of the average length of generated assembly sequences during the 10 days of agent training in Raptor Lake. The darker line shows the running mean. set while exploiting the knowledge we provide through the reward signal. At every episode, the agent starts building an instruction sequence from scratch and keeps adding a new instruction until the instruction limit is reached or the sequence gives an exception with the last added instruction. Over time, we observe that the average length of an instruction sequence dur- ing an episode increases during the agent training, as shown in Figure 5. Increasing average length over time indicates the agent was able to learn to select combinations of instructions to avoid exceptions. In our experiments, the maximum se- quence length was chosen as 10 assembly instructions, after which the agent starts building a new sequence. 7 Discovered Transient Execution Vulnerabili- ties When the agent builds an instruction sequence that results in observable transient execution, it is saved for manual analysis with performance counter and data leakage information. Fig- 8 Figure 6: Visualization generated instruction sequences across time, with higher byte leakage marked with lighter colors. Note that, the discovered transient execution mechanisms stand out as it has higher reward compared to the remaining ones.\n\n--- Segment 21 ---\nFig- 8 Figure 6: Visualization generated instruction sequences across time, with higher byte leakage marked with lighter colors. Note that, the discovered transient execution mechanisms stand out as it has higher reward compared to the remaining ones. ure 6 shows the visualization of generated instructions over time. Since the sequences with high reward stands out from the rest of the generated snippets, it eases the manual analysis and verification as well. After analyzing the generated data, we were able to identify eight new classes of transient exe- cution mechanisms that had previously not been documented to the best of our knowledge. Note that, each class has many variations among the generated dataset. Yet here we present, the most simplified versions of the each class. Masked Exceptions. The studies in [6, 42] demonstrated that FP assists due to denormal numbers cause transient ex- ecution of the following instructions. Our RL agent gener- ated instruction sequences that cause observable byte leakage through transient execution without generating any µcode assists, faults, or interrupts. Listing 1 shows an example of such an instruction sequence. After careful analysis, we no- ticed that the sequence indeed causes an FP exception, but the exception is masked by the processor, and the program execution is uninterrupted. Previous works reported transient execution with page faults, device-not-available [28,33,47] which requires exception handling and µcode assists such as FP assists [6,42] which requires specially crafted inputs. Transient execution through masked FP exceptions has not been previously reported in the literature, which makes it a new discovery for our RL agent. We observed this behavior on only Skylake-X. Transitions Between MMX and x87. FP exceptions, by default, are masked and do not cause a trap, and the program continues execution. However, starting from glibc v2.2, it is possible to unmask them using feenableexcept functions from fenv.h library. This function allows the FP exceptions to cause a trap and the program to be interrupted.\n\n--- Segment 22 ---\nHowever, starting from glibc v2.2, it is possible to unmask them using feenableexcept functions from fenv.h library. This function allows the FP exceptions to cause a trap and the program to be interrupted. After masked exceptions we run another training session with the same configuration but with the 1 generated_assembly_function: 2 rep N 3 FLD qword [x] 4 endrep 5 FCOMI st0 , st1 6 JE exit: 7 ; cache encoding 8 MOVZX rax , byte [ rdi] 9 SHL rax , 10 10 MOV rax , qword [rsi rax] 11 exit: 12 RET Listing 1: A simplified instruction sequence that triggers masked FP exception due to repeated x87 instruction in line 4. Following cache encoding instructions (line 8-10) get executed speculatively. 1 generated_assembly_function: 2 rep N 3 PSUBQ MM2 , [R15] 4 FCOMIP ST4 5 endrep 6 VCMPPD K3, ZMM1 , ZMM4 , 2 7 JNE exit 8 ; cache encoding 9 MOVZX rax , byte [ rdi] 10 SHL rax , 10 11 MOV rax , qword [rsi rax] 12 exit: 13 RET Listing 2: A simplified version of the RL generated assembly instruction sequence that has MMX (line 3) to x87 (line 4) transition. Following cache encoding instructions (line 9-11) get executed speculatively. feenableexcept function enabling FE_INVALID, FE_DIVBYZERO, FE_OVERFLOW, FE_UNDERFLOW, and FE_INEXACT bits of the excepts argument. With this configuration, the RL agent was still able to gen- erate instruction sequences that cause observable byte leakage through transient execution without generating any µcode as- sists, faults, or interrupts. Listing 2 shows an example of such an instruction sequence. After simplifying the instruction sequence, we observed that the transient execution is caused by an FP exception that is generated by the FCOMIP instruction. However, the MMX instruction before the FCOMIP instruction causes the exception to get lost. We use the feenableexcept function to unmask FP exceptions, yet the exception generated in the processor gets cleared by the PSUBQ instruction.\n\n--- Segment 23 ---\nHowever, the MMX instruction before the FCOMIP instruction causes the exception to get lost. We use the feenableexcept function to unmask FP exceptions, yet the exception generated in the processor gets cleared by the PSUBQ instruction. Even though the ex- ception is cleared, the following instructions are executed speculatively, and the transient execution is observed. Note that the comparison instruction VCMPPD does not have any de- pendency on the previous instructions, yet it is still executed speculatively, and removing the AVX instructions from the 9 sequence does not break the transient execution. In Intel documentations [19], it is advised that after the MMX instructions, EMMS instruction should be used to clear the FPU state to prevent undefined behavior . We verified that adding an EMMS instruction after the MMX instruction makes the FP exception cause a trap. Following the convention [42], we provide leakage rate analysis on MMX-x87 transient execution mechanism with changing iterations and leakage granularities as shown in Figure 7. Unlike the Masked Exceptions, we observed leakage through MMX-x87 in both µArch we analyzed. Interestingly, in Skylake-X, the highest leakage rate, 2.3 Mb s was achieved through 1-bit granularity and with iteration N 3. The second high was 1.9 Mb s with 8-bit granularity. Between N 3 and N 150, we do not observe any leakage. In Raptor Lake, the leakage appears at N 200 with up to 233 Kb s. (a) Skylake-X (b) Raptor Lake Figure 7: Leakage rate vs repetitions of the instruction pattern for MMX-x87. Note that in (a) the leakage rates peak when Iteration N 3 for every granularity. In (b), darker lines are running mean and the shades are rolling variance around the mean. SERIALIZE Instruction. Speculative execution vulnerabili- ties in modern processors allow attackers to observe transient execution behavior and infer secret data. This section analyzes the behavior of the SERIALIZE instruction in the context of speculative execution and demonstrates how it can inadver- tently facilitate information leakage under certain conditions. Intel s documentation states that the SERIALIZE instruction serializes instruction execution, ensuring all modifications to flags, registers, and memory by previous instructions are complete before subsequent instructions are fetched and ex- ecuted" [19].\n\n--- Segment 24 ---\nThis section analyzes the behavior of the SERIALIZE instruction in the context of speculative execution and demonstrates how it can inadver- tently facilitate information leakage under certain conditions. Intel s documentation states that the SERIALIZE instruction serializes instruction execution, ensuring all modifications to flags, registers, and memory by previous instructions are complete before subsequent instructions are fetched and ex- ecuted" [19]. This behavior includes "draining all buffered writes to memory [19], providing a robust barrier for in- struction execution order. However, our experiments reveal that SERIALIZE, when executed repeatedly alongside specific instructions, does not always halt speculative execution ef- fectively. This observation was made during experiments de- signed to measure speculative execution behavior and leakage patterns. The instruction sequences given in Listing 3 were executed repeatedly, with observed effects on speculative execution: 1 ; Sequence 1: leaks beginning of the secret 2 rep N 3 SERIALIZE 4 RDGSBASE EAX 5 VAESDECLAST YMM0 , YMM2 , yword [R15] 6 endrep 7 8 ; Sequence 2: leaks end of the secret 9 rep N 10 SERIALIZE 11 RDGSBASE EAX 12 endrep 13 14 ; Sequence 3: no leak 15 rep N 16 SERIALIZE 17 VAESDECLAST YMM0 , YMM2 , yword [R15] 18 endrep Listing 3: Sequences 1, 2, and 3: Showing various data leak behaviors through SERIALIZE. Sequence 1 leaked the beginning of the secret, revealing fragments. Sequence 2 leaked the end of the secret, revealing fragments. Sequence 3 did not result in any observable data leakage. Interestingly, the first two sequences caused a measurable increase in RECOVERY_CYCLES, indicating that the Resource Allocation Table (RAT) checkpoints were recovering after speculative execution. No increase in Machine Clear counters, µcode assists, or exceptions was observed. While SERIALIZE is intended to act as a speculation barrier, its behavior in combination with other instructions, such as RDGSBASE and VAESDECLAST, can inadvertently permit tran- sient execution to proceed. This transient execution creates a window where secret data can be accessed speculatively and leaked through side channels. Figure 8 shows the leakage rate analysis with the changing number of iterations.\n\n--- Segment 25 ---\nThis transient execution creates a window where secret data can be accessed speculatively and leaked through side channels. Figure 8 shows the leakage rate analysis with the changing number of iterations. The largest leakage rate observed is 230 Kb s with 4-bit leakage granularity in Raptor Lake. We did not observe leakage in Skylake-X. VERR VERW Instructions. The VERR (Verify Read) and VERW (Verify Write) instructions are employed to confirm if a memory segment can be read or written from the current privilege level. These instructions are crucial for security pro- tocols, ensuring that less privileged code cannot access or alter 10 Figure 8: Leakage rate vs repetitions of the instruction pattern for SERIALIZE instruction measured in Raptor Lake. Darker lines are running mean and the shades are rolling variance around the mean. segments belonging to more privileged levels. These instruc- tions modify the Zero Flag based on whether a segment is readable or writable. Although these are obsolete instructions, VERW instruction has recently given an additional function- ality that wipes off the microarchitectural buffers in efforts to mitigate MDS attacks [18] from the software. µRL discovered instruction sequences given in Listing 4 that cause observable transient execution with both VERW and VERR instructions. Interestingly, we do not observe a leakage with VERW alone, without the instruction given in line 4. On Skylake-X µArch , VERW achieved up to 2.2 Mb s leakage rate, and 1-bit and 8-bit leakage granularity are close to each other. The complete data is given in Appendix B. Note that Skylake-X is one of the microarchitectures vulner- able to MDS attacks, and a microcode patch was issued for the VERW mitigation functionality. On Raptor Lake, VERW achieved up to 3.7 Mb s and 2.1 Mb s leakage rates with 1-bit and 8-bit leakage granularities, respectively. With 4-bit, we observed 279 Kb s leakage rate. VERR achieved up to 207 Kb s leakage rate with 4-bit leakage granularity, only in Rap- tor Lake. The relation between the iteration and leakage rates are given in Figure 9.\n\n--- Segment 26 ---\nVERR achieved up to 207 Kb s leakage rate with 4-bit leakage granularity, only in Rap- tor Lake. The relation between the iteration and leakage rates are given in Figure 9. 1 ;leaks through VERW 2 rep N 3 VERW word [R15] 4 LZCNT EDX, dword [R15] 5 endrep 6 7 ;leaks through VERR 8 rep N 9 VERR AX 10 endrep Listing 4: Instruction sequences with leakage through VERW and VERR. CLMUL Instructions. The CLMUL instruction set is de- signed to accelerate cryptographic operations by performing carry-less multiplication on 128-bit operands. This is particu- (a) VERW (b) VERR Figure 9: Leakage rates for VERW and VERR instructions mea- sured in Raptor Lake. In (b) Darker lines are running mean and the shades are rolling variance around the mean. larly useful in cryptographic algorithms like AES and GCM, where polynomial multiplications over GF(2128) are required, and carry propagation is not needed. Listing 5 shows an RL- generated sequence which includes PCLMULQDQ which is one of the CLMUL instructions. We observed leakage only in Raptor Lake with up to 90 Kb s with 4-bit granularity as shown in Figure 10. 1 ;leaks through PCLMULQDQ 2 rep N 3 PCLMULQDQ XMM4 , [R15], 2 4 VCVTPS2PH XMM0 , YMM0 , 2 5 LOCK CMPXCHG16B [R15] 6 endrep Listing 5: Instruction sequence with leakage through CMUL Miscellaneous. We observed leakage with the com- bination of other instructions such as LSL RDSCP, LAR RDSCP, LAR MULX, LAR ADCX CMOVNL, LAR PREFETCHWT1, etc. However, to save space, we give some of them in the Appendix C. 8 Exploitability of Discovered Transient Exe- cution Mechanisms In this section, we show how Meltdown-like vulnerabilities can be exploited without having TSX or exception handling, thanks to discovered instruction sequences by µRL.\n\n--- Segment 27 ---\nWe observed leakage with the com- bination of other instructions such as LSL RDSCP, LAR RDSCP, LAR MULX, LAR ADCX CMOVNL, LAR PREFETCHWT1, etc. However, to save space, we give some of them in the Appendix C. 8 Exploitability of Discovered Transient Exe- cution Mechanisms In this section, we show how Meltdown-like vulnerabilities can be exploited without having TSX or exception handling, thanks to discovered instruction sequences by µRL. 11 Mechanism Skylake-X Raptor Lake Availability Leakage Rate [Kb s] Availability Leakage Rate [Kb s] FP Assist [42] 222 306 SMC [42] 235 481 BHT [23] 169 305 Exception w Handler [28] 217 280 TSX [28] 227 N A MD [42] 225 276 XMC [42] 1 395 MO [42] 235 7 Masked FP Exception (This work) 214 0 MMX-x87 (This work) 213 233 SERIALIZE (This work) 0 230 VERW (This work) 218 279 VERR (This work) 0 207 CLMUL (This work) 0 90 LSL RDSCP (This work) 0 210 LAR (This work) 0 30 Table 2: Comparison of availability and leakage rates of different transient execution mechanisms in Intel Skylake-X and Raptor Lake microarchitectures with 4-bit leakage granularity. The TSX instruction set extension is not available in Raptor Lake. The remaining marks show the instructions are supported, yet we do not observe leakage. Figure 10: Leake rates for CLMUL measured in Raptor Lake. Darker lines are running mean and the shades are rolling variance around the mean. The original Meltdown exploit [28], where an attacker uses transient execution to leak data from kernel memory, has been mitigated by KPTI implemented in the Linux Kernel. However, mitigations like KPTI are application-specific, and they mitigate only one element in the attack chain, in this case, the availability of kernel addresses mapped in the virtual memory. Yet, the root cause for the transient execution has not been mitigated in the hardware. Therefore, we argue that different applications can potentially still be vulnerable and be exploited using different transient execution mechanisms.\n\n--- Segment 28 ---\nYet, the root cause for the transient execution has not been mitigated in the hardware. Therefore, we argue that different applications can potentially still be vulnerable and be exploited using different transient execution mechanisms. Since finding new software applications vulnerable to tran- sient execution is not part of the scope of this work, we adopt the original Meltdown setup. For the proof of concept, we disable KPTI on the Linux kernel. Using the µRL generated instructions sequence shown in Figure 11: Proof of concept code that demonstrates the use of RL-generated MMX-x87 transient execution mechanism for reading the physical memory. Figure 11, we trigger transient execution of the following memory access in line, which is an illegal access to kernel memory. Speculative load from the kernel memory is then encoded into the cache so that we can decode it later using Flush Reload. In this experiment, we were able to read a pre-chosen secret value from the kernel memory without using a fault handler or TSX instruction set. This result demonstrates how µRL generated instructions sequences can be exploited, and they can be used as alternatives to the known attack vectors. 12 9 Discussion 9.1 Limitations While our RL framework demonstrates promising results in discovering microarchitectural vulnerabilities, it is important to acknowledge its current limitations: Exploration Focus. While the framework is effective at gen- erating instruction sequences that trigger vulnerabilities, it does not account for the entire system s attack surface. For example, vulnerabilities involving interactions between hard- ware and software, such as operating system mitigations or compiler optimizations, are not explicitly explored. In this work, we did not consider the impact of other system configurations such as Hyperthreading, TSX, SGX, AVX, HW prefetch, previous mitigations, Kernel Samepage Merging, ASLR, page table layout, etc. on the µArch vulnerabilities. We leave this for future work. Sparse and Delayed Rewards. Within the search space, only a small fraction of instruction sequences would indicate a vulnerability, assuming the design went through a thorough security review previously. The delayed nature of rewards, which depends on the cumulative effect of multiple instruc- tions, further complicates learning. Therefore, reward signal is sparse and delayed, making it challenging for the agent to learn the optimal policy. Incomplete CPU State Observability. Our framework relies on performance counters and partial state observations to in- fer microarchitectural behavior.\n\n--- Segment 29 ---\nIncomplete CPU State Observability. Our framework relies on performance counters and partial state observations to in- fer microarchitectural behavior. However, it cannot directly access internal processor states or transient microarchitectural effects that are not captured by these counters. This black-box approach may miss vulnerabilities that require finer-grained or privileged insights into CPU internals. More subtle vul- nerabilities can potentially be detected by the deployment of µRL on processors by the chip vendors for an internal secu- rity review. Addressing these limitations in future work will further enhance the robustness and generalizability of µRL, enabling more comprehensive microarchitectural vulnerabil- ity discovery. 9.2 Scalability Scaling Across Vulnerabilities. The framework can be adapted to discover diverse classes of vulnerabilities (e.g., cache-based, transient execution) by modifying the reward function to prioritize unique microarchitectural signals and by incorporating domain-specific performance counters. Scaling to Different CPU Microarchitectures. Dynamic en- vironment generation enables the framework to model distinct architectural features of various CPUs. Transfer learning can be employed to initialize RL agents using policies trained on similar architectures, reducing the computational overhead of adapting to new designs. Indeed, we have shown that some of the vulnerabilities discovered on one CPU can be transferred to another CPU, such as MMX-x87 and VERW. Scaling to Heterogeneous Hardware. To support hardware like GPUs, the action space and environment must be tailored to GPU-specific instruction sets and execution models. This involves building GPU-aware environments that simulate in- struction behavior and adapting performance metrics, such as memory throughput and warp divergence, as observation signals. Parallel and Distributed Execution. Scaling the framework for large-scale exploration across diverse hardware is feasible through parallelization and distributed training. By leveraging multiple nodes and cores, the framework can simultaneously evaluate instruction sequences on varied architectures. 10 Conclusion In this work, we proposed an RL framework for discover- ing µArch vulnerabilities, demonstrating its capability to effi- ciently navigate the vast and complex instruction space of modern CPUs. The framework successfully rediscovered known vulnerabilities and uncovered new transient execu- tion mechanisms, such as masked floating-point exceptions and MMX-to-x87 transitions, showcasing its potential as a powerful tool for hardware security research.\n\n--- Segment 30 ---\n10 Conclusion In this work, we proposed an RL framework for discover- ing µArch vulnerabilities, demonstrating its capability to effi- ciently navigate the vast and complex instruction space of modern CPUs. The framework successfully rediscovered known vulnerabilities and uncovered new transient execu- tion mechanisms, such as masked floating-point exceptions and MMX-to-x87 transitions, showcasing its potential as a powerful tool for hardware security research. The proposed framework is notable for its adaptability across different µArch , leveraging custom RL environments and performance counter feedback to guide exploration. By employing hierarchical action spaces, parallelized training, and dynamic environment generation, it addresses the scala- bility challenges inherent in exploring diverse instruction sets and architectures. Additionally, the use of transfer learning reduces the cost of applying the framework to new proces- sor models, making it a versatile solution for vulnerability discovery. Beyond CPUs, the framework can be extended to analyze other hardware platforms, such as GPUs and accelerators, by adapting the action space and observation metrics to the spe- cific execution models and vulnerabilities of those platforms. The integration of GPU-specific metrics, for instance, could open new avenues for discovering side-channel vulnerabilities in high-performance computing environments. Overall, the proposed RL framework represents a signifi- cant step forward in automating µArch vulnerability discov- ery. By scaling efficiently across vulnerabilities, architectures, and hardware platforms, it lays the groundwork for a more systematic and adaptive approach to hardware security test- ing, ensuring that modern processors remain resilient against emerging threats. 13 References [1] Andreas Abel and Jan Reineke. uops.info: Characteriz- ing latency, throughput, and port usage of instructions on intel microarchitectures. In ASPLOS, ASPLOS 19, pages 673 686, New York, NY, USA, 2019. ACM. [2] Onur Acıiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. Predicting secret keys via branch prediction. In Top- ics in Cryptology CT-RSA 2007: The Cryptographers Track at the RSA Conference 2007, San Francisco, CA, USA, February 5-9, 2007. Proceedings, pages 225 242. Springer, 2006. [3] Andrew J. Adiletta, M. Caner Tol, Yarkın Doröz, and Berk Sunar.\n\n--- Segment 31 ---\nSpringer, 2006. [3] Andrew J. Adiletta, M. Caner Tol, Yarkın Doröz, and Berk Sunar. Mayhem: Targeted corruption of register and stack variables. In Proceedings of the 2024 ACM Asia Conference on Computer and Communications Se- curity, 2024. [4] Claudio Canella, Daniel Genkin, Lukas Giner, Daniel Gruss, Moritz Lipp, Marina Minkin, Daniel Moghimi, Frank Piessens, Michael Schwarz, Berk Sunar, Jo Van Bulck, and Yuval Yarom. Fallout: Leaking data on meltdown-resistant cpus. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS). ACM, 2019. [5] Sunjay Cauligi, Craig Disselkoen, Klaus v Gleissenthall, Dean Tullsen, Deian Stefan, Tamara Rezk, and Gilles Barthe. Constant-time foundations for the new spec- tre era. In Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Im- plementation, pages 913 926, 2020. [6] Anirban Chakraborty, Nimish Mishra, and Debdeep Mukhopadhyay. Shesha: Multi-head microarchitectural leakage discovery in new-generation intel processors. arXiv preprint arXiv:2406.06034, 2024. [7] Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H Lai. Sgxpectre: Steal- ing intel secrets from sgx enclaves via speculative exe- cution. In 2019 IEEE European Symposium on Security and Privacy (EuroS P), pages 142 157. IEEE, 2019. [8] Intel Corporation. Perfmon. intel perfmon tree main. Accessed: 2024-11-13. [9] Intel Corporation. Top-Down Microarchitecture Analy- sis Method, 2023. Accessed: 2024-11-13. [10] Jacson Rodrigues Correia-Silva, Rodrigo F Berriel, Claudine Badue, Alberto F de Souza, and Thiago Oliveira-Santos.\n\n--- Segment 32 ---\nAccessed: 2024-11-13. [10] Jacson Rodrigues Correia-Silva, Rodrigo F Berriel, Claudine Badue, Alberto F de Souza, and Thiago Oliveira-Santos. Copycat cnn: Stealing knowledge by persuading confession with random non-labeled data. In 2018 International Joint Conference on Neural Net- works (IJCNN), pages 1 8. IEEE, 2018. [11] Craig Disselkoen, David Kohlbrenner, Leo Porter, and Dean Tullsen. {Prime Abort}: A {Timer-Free}{High- Precision} l3 cache attack using intel {TSX}. In 26th USENIX Security Symposium (USENIX Security 17), pages 51 67, 2017. [12] Goran Doychev, Boris Köpf, Laurent Mauborgne, and Jan Reineke. Cacheaudit: A tool for the static analysis of cache side channels. ACM Transactions on information and system security (TISSEC), 18(1):1 32, 2015. [13] Spandan Garg, Roshanak Zilouchian Moghaddam, and Neel Sundaresan. Rapgen: An approach for fix- ing code inefficiencies in zero-shot. arXiv preprint arXiv:2306.17077, 2023. [14] Daniel Gruss, Clémentine Maurice, Klaus Wagner, and Stefan Mangard. Flush Flush: a fast and stealthy cache attack. In International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pages 279 299. Springer, 2016. [15] Daniel Gruss, Raphael Spreitzer, and Stefan Mangard. Cache template attacks: Automating attacks on inclusive {Last-Level} caches. In 24th USENIX Security Sympo- sium (USENIX Security 15), pages 897 912, 2015. [16] Marco Guarnieri, Boris Köpf, José F Morales, Jan Reineke, and Andrés Sánchez. Spectector: Principled detection of speculative information flows. In 2020 IEEE Symposium on Security and Privacy (SP), pages 1 19. IEEE, 2020. [17] Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade.\n\n--- Segment 33 ---\nIEEE, 2020. [17] Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade. Deepfix: Fixing common c language errors by deep learning. In Proceedings of the aaai conference on artificial intelligence, volume 31, 2017. [18] Intel. Microarchitectural data sampling, 2021. Accessed: 2025-01-22. [19] Intel Corporation. Intel 64 and ia-32 architectures soft- ware developer s manual: Combined volumes 1, 2a, 2b, 2c, 2d, 3a, 3b, 3c, 3d, and 4, 2023. Accessed: 2024-11- 15. [20] Gorka Irazoqui, Thomas Eisenbarth, and Berk Sunar. S a: A shared cache attack that works across cores and defies vm sandboxing and its application to aes. In 2015 IEEE Symposium on Security and Privacy, pages 591 604. IEEE, 2015. [21] Saad Islam, Ahmad Moghimi, Ida Bruhns, Moritz Krebbel, Berk Gulmezoglu, Thomas Eisenbarth, and Berk Sunar. SPOILER: Speculative load hazards boost rowhammer and cache attacks. In 28th USENIX Secu- rity Symposium (USENIX Security 19), pages 621 637, Santa Clara, CA, August 2019. USENIX Association. 14 [22] Patrick Jattke, Victor Van Der Veen, Pietro Frigo, Stijn Gunter, and Kaveh Razavi. Blacksmith: Scalable rowhammering in the frequency domain. In 2022 IEEE Symposium on Security and Privacy (SP), pages 716 734. IEEE, 2022. [23] Paul Kocher, Jann Horn, Anders Fogh, , Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, Michael Schwarz, and Yuval Yarom. Spectre attacks: Exploit- ing speculative execution. In 40th IEEE Symposium on Security and Privacy (S P 19), 2019.\n\n--- Segment 34 ---\nSpectre attacks: Exploit- ing speculative execution. In 40th IEEE Symposium on Security and Privacy (S P 19), 2019. [24] Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, et al. Spectre attacks: Exploiting speculative execution. In 2019 IEEE Symposium on Security and Privacy (SP), pages 1 19. IEEE, 2019. [25] Paul C Kocher. Timing attacks on implementations of diffie-hellman, rsa, dss, and other systems. In Advances in Cryptology CRYPTO 96: 16th Annual International Cryptology Conference Santa Barbara, California, USA August 18 22, 1996 Proceedings 16, pages 104 113. Springer, 1996. [26] Andrew Kwong, Daniel Genkin, Daniel Gruss, and Yu- val Yarom. Rambleed: Reading bits in memory without accessing them. In 2020 IEEE Symposium on Security and Privacy (SP), pages 695 711. IEEE, 2020. [27] Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. Nv-embed: Improved techniques for training llms as generalist embedding models. arXiv preprint arXiv:2405.17428, 2024. [28] Moritz Lipp, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner Haas, Anders Fogh, Jann Horn, Stefan Mangard, Paul Kocher, Daniel Genkin, Yuval Yarom, and Mike Hamburg. Meltdown: Reading kernel memory from user space. In 27th USENIX Security Symposium (USENIX Security 18), 2018. [29] Fangfei Liu, Yuval Yarom, Qian Ge, Gernot Heiser, and Ruby B Lee. Last-level cache side-channel attacks are practical. In 2015 IEEE symposium on security and privacy, pages 605 622. IEEE, 2015. [30] Mulong Luo, Wenjie Xiong, Geunbae Lee, Yueying Li, Xiaomeng Yang, Amy Zhang, Yuandong Tian, Hsien- Hsin S. Lee, and G. Edward Suh.\n\n--- Segment 35 ---\nIEEE, 2015. [30] Mulong Luo, Wenjie Xiong, Geunbae Lee, Yueying Li, Xiaomeng Yang, Amy Zhang, Yuandong Tian, Hsien- Hsin S. Lee, and G. Edward Suh. Autocat: Rein- forcement learning for automated exploration of cache- timing attacks. In 2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA), pages 317 332, 2023. [31] Daniel J Mankowitz, Andrea Michi, Anton Zhernov, Marco Gelmi, Marco Selvi, Cosmin Paduraru, Edouard Leurent, Shariq Iqbal, Jean-Baptiste Lespiau, Alex Ah- ern, et al. Faster sorting algorithms discovered using deep reinforcement learning. Nature, 618(7964):257 263, 2023. [32] Daniel Moghimi. Downfall: Exploiting speculative data gathering. In 32nd USENIX Security Symposium (USENIX Security 23), pages 7179 7193, Anaheim, CA, August 2023. USENIX Association. [33] Daniel Moghimi, Moritz Lipp, Berk Sunar, and Michael Schwarz. Medusa: Microarchitectural data leakage via automated attack synthesis. In 29th USENIX Security Symposium (USENIX Security 20), pages 1427 1444, 2020. [34] Daniel Moghimi, Berk Sunar, Thomas Eisenbarth, and Nadia Heninger. TPM-FAIL: TPM meets Timing and Lattice Attacks. In 29th USENIX Security Sympo- sium (USENIX Security 20), Boston, MA, August 2020. USENIX Association. [35] Gabriel de Souza P Moreira, Radek Osmulski, Mengyao Xu, Ronay Ak, Benedikt Schifferer, and Even Oldridge. Nv-retriever: Improving text embedding models with effective hard-negative mining. arXiv preprint arXiv:2407.15831, 2024. [36] Koksal Mus, Yarkın Doröz, M Caner Tol, Kristi Rah- man, and Berk Sunar. Jolt: Recovering tls signing keys via rowhammer faults.\n\n--- Segment 36 ---\n[36] Koksal Mus, Yarkın Doröz, M Caner Tol, Kristi Rah- man, and Berk Sunar. Jolt: Recovering tls signing keys via rowhammer faults. In 2023 IEEE Symposium on Se- curity and Privacy (SP), pages 1719 1736. IEEE, 2023. [37] Oleksii Oleksenko, Marco Guarnieri, Boris Köpf, and Mark Silberstein. Hide and seek with spectres: Effi- cient discovery of speculative information leaks with random testing. In 2023 IEEE Symposium on Security and Privacy (SP), pages 1737 1752. IEEE, 2023. [38] Oleksii Oleksenko, Bohdan Trach, Mark Silberstein, and Christof Fetzer. Specfuzz: Bringing spectre- type vulnerabilities to the surface. arXiv preprint arXiv:1905.10311, 2019. [39] Dag Arne Osvik, Adi Shamir, and Eran Tromer. Cache attacks and countermeasures: the case of aes. In Topics in Cryptology CT-RSA 2006: The Cryptogra- phers Track at the RSA Conference 2006, San Jose, CA, USA, February 13-17, 2005. Proceedings, pages 1 20. Springer, 2006. [40] Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, and Brendan Dolan-Gavitt. Examining Zero-Shot Vulnerability Repair with Large Language Models. In 2023 IEEE Symposium on Security and Privacy (SP). IEEE, 2023. 15 [41] Antoon Purnal, Furkan Turan, and Ingrid Verbauwhede. Prime scope: Overcoming the observer effect for high- precision cache contention attacks. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 2906 2920, 2021. [42] Hany Ragab, Enrico Barberis, Herbert Bos, and Cris- tiano Giuffrida. Rage against the machine clear: A sys- tematic analysis of machine clears and their implications for transient execution attacks. In 30th USENIX Security Symposium (USENIX Security 21), pages 1451 1468, 2021. [43] John Schulman.\n\n--- Segment 37 ---\nIn 30th USENIX Security Symposium (USENIX Security 21), pages 1451 1468, 2021. [43] John Schulman. Trust region policy optimization. arXiv preprint arXiv:1502.05477, 2015. [44] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimiza- tion algorithms. arXiv preprint arXiv:1707.06347, 2017. [45] Michael Schwarz, Moritz Lipp, Daniel Moghimi, Jo Van Bulck, Julian Stecklina, Thomas Prescher, and Daniel Gruss. ZombieLoad: Cross-privilege-boundary data sampling. In CCS, 2019. [46] Michael Schwarz, Martin Schwarzl, Moritz Lipp, Jon Masters, and Daniel Gruss. Netspectre: Read arbitrary memory over network. In European Symposium on Re- search in Computer Security, pages 279 299. Springer, 2019. [47] Julian Stecklina and Thomas Prescher. Lazyfp: Leaking fpu register state using microarchitectural side-channels, 2018. [48] Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour. Policy gradient methods for reinforce- ment learning with function approximation. Advances in neural information processing systems, 12, 1999. [49] Daniel Tarlow, Subhodeep Moitra, Andrew Rice, Zimin Chen, Pierre-Antoine Manzagol, Charles Sutton, and Edward Aftandilian. Learning to fix build errors with graph2diff neural networks. In Proceedings of the IEEE ACM 42nd international conference on software engineering workshops, pages 19 20, 2020. [50] M. Caner Tol, Berk Gulmezoglu, Koray Yurtseven, and Berk Sunar. FastSpec: Scalable Generation and De- tection of Spectre Gadgets Using Neural Embeddings. In 2021 IEEE European Symposium on Security and Privacy (EuroS P), pages 616 632. IEEE, 2021. [51] M. Caner Tol and Berk Sunar. Zeroleak: Using llms for scalable and cost effective side-channel patching.\n\n--- Segment 38 ---\n[51] M. Caner Tol and Berk Sunar. Zeroleak: Using llms for scalable and cost effective side-channel patching. arXiv preprint arXiv:2308.13062, 2023. [52] Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F. Wenisch, Yuval Yarom, and Raoul Strackx. Foreshadow: Extracting the keys to the Intel SGX king- dom with transient out-of-order execution. In Proceed- ings of the 27th USENIX Security Symposium, August 2018. [53] Jo Van Bulck, Daniel Moghimi, Michael Schwarz, Moritz Lipp, Marina Minkin, Daniel Genkin, Yarom Yuval, Berk Sunar, Daniel Gruss, and Frank Piessens. LVI: Hijacking Transient Execution through Microarchi- tectural Load Value Injection. In 41th IEEE Symposium on Security and Privacy (S P 20), 2020. [54] Jo Van Bulck, Daniel Moghimi, Michael Schwarz, Moritz Lippi, Marina Minkin, Daniel Genkin, Yuval Yarom, Berk Sunar, Daniel Gruss, and Frank Piessens. Lvi: Hijacking transient execution through microarchi- tectural load value injection. In 2020 IEEE Symposium on Security and Privacy (SP), pages 54 72. IEEE, 2020. [55] Stephan Van Schaik, Alyssa Milburn, Sebastian Öster- lund, Pietro Frigo, Giorgi Maisuradze, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. Ridl: Rogue in- flight data load. In 2019 IEEE Symposium on Security and Privacy (SP), pages 88 105. IEEE, 2019. [56] Guanhua Wang, Sudipta Chattopadhyay, Arnab Ku- mar Biswas, Tulika Mitra, and Abhik Roychoudhury. Kleespectre: Detecting information leakage through speculative cache attacks via symbolic execution. arXiv preprint arXiv:1909.00647, 2019.\n\n--- Segment 39 ---\nKleespectre: Detecting information leakage through speculative cache attacks via symbolic execution. arXiv preprint arXiv:1909.00647, 2019. [57] Daniel Weber, Ahmad Ibrahim, Hamed Nemati, Michael Schwarz, and Christian Rossow. Osiris: Automated discovery of microarchitectural side channels. In 30th USENIX Security Symposium (USENIX Security 21), pages 1415 1432, 2021. [58] Jan Wichelmann, Ahmad Moghimi, Thomas Eisenbarth, and Berk Sunar. Microwalk: A framework for finding side channels in binaries. In Proceedings of the 34th Annual Computer Security Applications Conference. As- sociation for Computing Machinery, 2018. [59] Jan Wichelmann, Florian Sieck, Anna Pätschke, and Thomas Eisenbarth. Microwalk-ci: practical side- channel analysis for javascript applications. In Proceed- ings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, 2022. [60] Yi Wu, Nan Jiang, Hung Viet Pham, Thibaud Lutellier, Jordan Davis, Lin Tan, Petr Babkin, and Sameena Shah. How effective are neural networks for fixing security vulnerabilities. arXiv preprint arXiv:2305.18607, 2023. 16 [61] Yuval Yarom and Katrina Falkner. Flush reload: a high resolution, low noise, l3 cache side-channel attack. In 23rd {USENIX} Security Symposium ({USENIX} Security 14), pages 719 732, 2014. [62] Michihiro Yasunaga and Percy Liang. Break-it-fix-it: Unsupervised learning for program repair. In Interna- tional Conference on Machine Learning, pages 11941 11952. PMLR, 2021. A Explanation of CPU Performance Events This section provides explanations for each of the CPU per- formance events listed in Table 1: UOPS_ISSUED.ANY: This event counts the total num- ber of micro-operations (uops) issued by the front end of the processor. It helps to understand how often the CPU is generating work for the execution units.\n\n--- Segment 40 ---\nA Explanation of CPU Performance Events This section provides explanations for each of the CPU per- formance events listed in Table 1: UOPS_ISSUED.ANY: This event counts the total num- ber of micro-operations (uops) issued by the front end of the processor. It helps to understand how often the CPU is generating work for the execution units. UOPS_RETIRED.RETIRE_SLOTS: This counter measures the number of micro-operations that have been retired, representing the slots used in the retirement stage. High values indicate effective utilization of the CPU pipeline. INT_MISC.RECOVERY_CYCLES_ANY: This event counts the cycles the processor spends in recovery due to issues in the integer pipeline, such as branch mispredictions. It provides insight into potential inefficiencies in the execution flow. MACHINE_CLEARS.COUNT: This counter tracks the total number of machine clears. Machine clears occur when the processor needs to flush the pipeline, often due to errors or interruptions, impacting overall performance. MACHINE_CLEARS.SMC: This event counts ma- chine clears specifically triggered by self-modifying code. Self-modifying code requires the processor to in- validate instructions and restart, which is costly in terms of performance. MACHINE_CLEARS.MEMORY_ORDERING: This counter registers machine clears due to memory ordering conflicts. Such conflicts require the CPU to reset and reorder memory accesses, which can degrade performance in multithreaded applications. FP_ASSIST.ANY: This event counts floating-point as- sists, which are special handling operations needed to process floating-point instructions. High counts may in- dicate heavy floating-point computation workloads or suboptimal code for floating-point operations. Figure 12: Leak rates for VERW measured in Skylake-X. OTHER_ASSISTS.ANY: This counter registers other assist events, including exceptions and corrections for specific instructions or situations. This can give insight into issues like misaligned memory access or uncommon instruction usage. CPU_CLK_UNHALTED.ONE_THREAD_ACTIVE: This event measures the number of cycles during which at least one thread is active. This counter is useful for understanding overall CPU utilization, especially in multi-threaded environments.\n\n--- Segment 41 ---\nCPU_CLK_UNHALTED.ONE_THREAD_ACTIVE: This event measures the number of cycles during which at least one thread is active. This counter is useful for understanding overall CPU utilization, especially in multi-threaded environments. CPU_CLK_UNHALTED.THREAD: This counter measures the cycles during which a specific thread re- mains active. It provides data on individual thread activ- ity and allows for a more granular view of CPU utiliza- tion. HLE_RETIRED.ABORTED_UNFRIENDLY: This event counts the hardware lock elision (HLE) transac- tions that were aborted due to unfriendly reasons, such as interference by other threads or incompatible instruc- tions. High values can indicate issues with lock-based concurrency. HW_INTERRUPTS.RECEIVED: This counter mea- sures the number of hardware interrupts received by the processor. Hardware interrupts are signals from exter- nal devices that require immediate attention, potentially affecting processor performance by disrupting normal execution flow. B Leakage Rates Analysis on Skylake Leak rates for VERW measured in Skylake-X is given in Figure 12. C Other µRL-discovered Transient Execution Mechanisms LAR. The LAR instruction loads the access rights of a seg- ment into a register, based on the segment selector provided. 17 Figure 13: Leak rates for LAR measured in Raptor Lake. It is useful for managing memory segmentation and ensuring the correct privilege levels when accessing different memory regions. Leak rates for LAR measured in Raptor Lake in Fig- ure 13. Four instruction sequences with LAR leakage are given in Listing 6. LSL RDSP. The LSL instruction loads the memory segment limit from a specified segment selector into a register, which is useful for segmentation tasks by providing the size of a memory segment, helping with boundary checks. Leak rates for LSL RDTSCP measured in Raptor Lake. Leak rates for LSL RDTSCP measured in Raptor Lake are given in Fig- ure 14. D Leakage Rate Analysis on Previously Known Transient Execution Mechanisms Leakage rates for previously known mechanisms such as FP assist, MD, MO and SMC on Raptor lake are given in Fig- ure 15, 16, 17 and 18.\n\n--- Segment 42 ---\nLeak rates for LSL RDTSCP measured in Raptor Lake are given in Fig- ure 14. D Leakage Rate Analysis on Previously Known Transient Execution Mechanisms Leakage rates for previously known mechanisms such as FP assist, MD, MO and SMC on Raptor lake are given in Fig- ure 15, 16, 17 and 18. E Instruction Sets 1 ; seq 1: leaks through LAR 2 rep 500 3 LAR RAX , [R15] 4 MULX RAX , RAX , qword [R15] 5 endrep 6 ; seq 2: leaks through LAR 7 rep 500 8 LAR RCX , [R15] 9 ADCX RCX , qword [R15] 10 CMOVNL EAX, EDX 11 endrep 12 ; seq 3: leaks through LAR 13 rep 500 14 LAR AX, [R15] 15 RDTSCP 16 endrep 17 ; seq 4: more stable leakage with prefetchwt1 18 rep 500 19 PREFETCHWT1 byte [R15] 20 LAR ESP, [R15] 21 LZCNT EBX, dword [R15] 22 endrep 23 ; seq 5: no dependency 24 rep 500 25 LAR DX, DX 26 LOCK CMPXCHG16B [R15] 27 endrep 28 ; seq 6: no dependency 29 rep 500 30 WRGSBASE RSP 31 CMPXCHG16B [R15] 32 LAR DX, AX 33 TZCNT RDX , qword [R15] 34 PEXT RBX , RDX , RAX 35 endrep Listing 6: Four instruction sequences with LAR leakage Figure 14: Leak rates for LSL RDTSCP measured in Raptor Lake. 18 Figure 15: Leak rates for FP assist measured in Raptor Lake. Figure 16: Leak rates for Memory disambiguation measured in Raptor Lake. Figure 17: Leak rates for Memory ordering measured in Rap- tor Lake. Figure 18: Leak rates for SMC measured in Raptor Lake.\n\n--- Segment 43 ---\nFigure 17: Leak rates for Memory ordering measured in Rap- tor Lake. Figure 18: Leak rates for SMC measured in Raptor Lake. Instruction Set Count Instruction Set Count ADOX_ADCX 8 AES 12 AVX 695 AVX2 286 AVX2GATHER 16 AVX512F_512 2192 AVX512F_128 1816 AVX512F_256 1940 AVX512F_SCALAR 584 AVX512DQ_128 247 AVX512DQ_256 281 AVX512DQ_512 357 AVX512BW_128 467 AVX512BW_256 467 AVX512BW_512 467 AVX512F_128N 23 AVX512DQ_SCALAR 44 AVX512CD_512 38 AVX512CD_128 38 AVX512CD_256 38 AVX512BW_128N 8 AVX512DQ_128N 8 AVX512DQ_KOP 18 AVX512BW_KOP 34 AVX512F_KOP 15 AVXAES 12 I86 809 I386 196 I486REAL 37 CMOV 96 PENTIUMREAL 5 I186 124 LONGMODE 24 LAHF 2 I286PROTECTED 26 I286REAL 10 FAT_NOP 3 RDPMC 1 PPRO 2 BMI1 26 BMI2 32 CET 2 F16C 8 FMA 192 INVPCID 1 CMPXCHG16B 2 LZCNT 6 PENTIUMMMX 129 SSE 97 MOVBE 6 PCLMULQDQ 2 RDRAND 3 RDSEED 3 RDTSCP 1 RDWRFSGS 8 FXSAVE 2 FXSAVE64 2 SSEMXCSR 2 SSE2 264 SSE2MMX 6 SSE3 20 SSE3X87 2 SSE4 96 SSE42 25 POPCNT 6 SSSE3MMX 32 SSSE3 32 X87 119 FCMOV 8 FCOMI 4 XSAVE 6 XSAVEC 2 XSAVEOPT 2 XSAVES 4 Table 3: Number of instructions per set used in the action space for Skylake-X. 19\n\n