=== ORIGINAL PDF: 2505.02516v1_Machine-Learning-Powered_Neural_Interfaces_for_Sma.pdf ===\n\nRaw text length: 30742 characters\nCleaned text length: 30609 characters\nNumber of segments: 17\n\n=== CLEANED TEXT ===\n\nMachine-Learning Powered Neural Interfaces for Smart Prosthetics and Diagnostics MohammadAli Shaeri , Jinhan Liu , Mahsa Shoaran Institutes of Electrical and Micro Engineering and Neuro-X, EPFL Lausanne, Switzerland {mohammad.shaeri, jinhan.liu, Abstract Advanced neural interfaces are transforming appli- cations ranging from neuroscience research to diagnostic tools (for mental state recognition, tremor and seizure detection) as well as prosthetic devices (for motor and communication recovery). By integrating complex functions into miniaturized neural devices, these systems unlock significant opportunities for personalized assistive technologies and adaptive therapeutic interventions. Leveraging high-density neural recordings, on-site signal processing, and machine learning (ML), these interfaces ex- tract critical features, identify disease neuro-markers, and enable accurate, low-latency neural decoding. This integration facilitates real-time interpretation of neural signals, adaptive modulation of brain activity, and efficient control of assistive devices. Moreover, the synergy between neural interfaces and ML has paved the way for self-sufficient, ubiquitous platforms capable of operating in diverse environments with minimal hardware costs and external dependencies. In this work, we review recent advancements in AI-driven decoding algorithms and energy-efficient System-on- Chip (SoC) platforms for next-generation miniaturized neural devices. These innovations highlight the potential for developing intelligent neural interfaces, addressing critical challenges in scalability, reliability, interpretability, and user adaptability. Index Terms Neural Interfaces, Neuromodulation, Brain- Computer Interfaces (BCI), Machine Learning, System-on-Chip. I. INTRODUCTION Modern neural interfaces can simultaneously record thou- sands of neural signals [1]. This capability generates massive volumes of data that demand efficient processing and com- pression to extract meaningful insights [2] [4] (Fig. 1(a)). Furthermore, advances in neural interface technology have enabled real-time recording and transmission, paving the way for high-resolution mapping of brain activity [5], [6]. However, the scale and complexity of neural data pose significant chal- lenges in processing, storage, and interpretation, necessitating innovative approaches in both hardware and software. Machine learning (ML) has emerged as a transformative tool for data analysis, enabling the execution of sophisticated tasks that were previously unattainable. ML algorithms excel at identifying patterns in complex datasets, making them invaluable for applications such as brain-computer interfaces (BCIs) aimed at motor and communication restoration [7] [10]. Additionally, ML facilitates therapeutic applications, including mental state recognition, migraine detection, and seizure prediction [11] [15]. Moreover, brain-triggered neuro- modulation systems leverage ML to adaptively modulate brain These authors contributed equally to this work. activity in response to disease-specific neuromarkers, offering personalized and precise therapeutic interventions [5], [16], [17]. To achieve these advanced functionalities, integrating neural interfaces and ML into miniaturized systems has become a key research focus [16], [18] [22]. Existing works have demonstrated promising results in developing energy-efficient system-on-chip (SoC) platforms for real-time neural signal processing and decoding. However, significant challenges re- main in achieving hardware efficiency, ensuring scalability, and maintaining the reliability and interpretability of these systems. Addressing these challenges is essential for advanc- ing next-generation neural interfaces that combine compact designs with robust performance in real-world applications. II. NEURAL INTERFACES Fig. 1. Neural Interfaces: (a) Neural recording interfaces capture high- density neural signals and process them to reduce data rates, or wirelessly transmit them to an external computer for further processing. (b) Therapeutic neural interfaces extract neuro-markers to detect disease-related neurological symptoms or mental states, and may also integrate neurostimulation for functions such as seizure suppression or brain rewiring. (c) Prosthetic neural interfaces use ML to convert brain intention into actionable commands, enabling control of end-effectors like robotic hands. arXiv:2505.02516v1 [cs.AI] 5 May 2025 Diagnostic Therapeutic Applications ML can empower advanced therapeutic devices and transform the diagnosis and treatment of neurological and psychiatric disorders, en- abling real-time monitoring, adaptive neurostimulation, and personalized interventions (Fig. 1(b)). These systems enhance clinical outcomes and patient independence via seizure tremor suppression, emotion regulation, and migraine therapy. By integrating real-time detection of neurological symptoms (e.g., seizures) with closed-loop neuromodulation, these devices deliver targeted stimulation to prevent seizures [5], [16]. Similarly, closed-loop neural interfaces can be used to treat tremors in patients with Parkinson s disease by detecting and modulating abnormal oscillations [5], [17]. Neural interfaces are also being applied in the treatment of psychiatric disorders, for example, in decoding emotional and anxiety-related states, analyzing connectivity and spectral dynamics to guide adaptive neurostimulation and biofeedback therapy [12], [22], [23]. Prosthetic Assistive Applications Prosthetic neural in- terfaces employ ML to decode brain signals in order to drive a wide range of effectors, enabling brain control of prosthetic limbs and communication devices for individuals with disabil- ities (Fig. 1(c)). Such interfaces provide critical functionalities such as artificial limb movement [24], locomotion assistance through wheelchair operation [25] and direct activation of natural limbs via neuromuscular [26] or spinal cord stimu- lation [10], facilitating the restoration of walking and hand movements. Also, neural prostheses empower individuals to perform daily tasks, including communication through cursor control and typing [27], writing [8], and speaking [9]. Recent advancements in BCIs emphasize greater task complexity and dexterity, including high-degree-of-freedom control and ability to distinguish diverse actions [9], [28]. These systems are paving the way for groundbreaking applications, ranging from cognitive enhancement tools to advanced assistive technolo- gies that adapt to the user s needs, delivering unprecedented functionality and adaptability [29], [30]. III. MACHINE LEARNING FOR NEURAL INTERFACES ML techniques, including traditional and deep learning (DL) models, have transformed neural data analysis by uncovering hidden brain patterns while enhancing real-time neural decod- ing, brain function modeling, and feature-level interpretability. A. Traditioinal Machine Learning Traditional ML models, including linear, tree-based, and probabilistic methods, are widely used in neural signal pro- cessing, neurological symptom detection and motor decoding. Distance-based techniques and window discrimination offer computational efficiency, memory savings, and real-time pro- cessing, making them well-suited for neural interfaces [5], [31]. Methods such as K-means and window discrimination classify data by proximity to centroids, shown to be efficient solutions in simple ML tasks, such as spike detection and sorting [31], [32]. K-Nearest Neighbors (KNN) is a non- parametric, flexible method suited for emotion recognition and early seizure detection, adapting to individualized neural activity [33], [34]. It offers low-complexity training without weight optimizations, but can be computationally expensive during inference on large datasets [35]. Linear Discriminant Analysis (LDA) maximizes class sep- arability while reducing dimensionality, offering an inter- pretable and low-complexity solution for motor decoding [20]. Support Vector Machines (SVMs) effectively decode neural signals, with linear SVMs performing well in simple tasks and kernel SVMs handling complex applications like seizure detection. While SVMs provide efficient inference and low memory usage, the training complexity increases with data size. Alternatively, Gradient Boosted Decision Trees (GBDTs) excel in non-linear, high-dimensional neural data modeling, making them effective for cognitive state classification and seizure detection [12], [18], [36]. They use hierarchical de- cision rules, reducing computational overhead and hardware complexity, while requiring minimal memory to store tree structures and split thresholds [37]. GBDTs offer high inter- pretability, enabling neuro-marker identification and providing clear decision paths for neural decoding analysis. Hidden Markov Models (HMMs) and Kalman Filters (KFs) enable sequential neural decoding through probabilistic modeling, iteratively updating hidden states (e.g., motor intentions) by estimating the most probable state based on observed neural data [10], [38]. This self-recalibration capability makes them well-suited for real-time neural decoding in adaptive BCIs. B. Deep Learning Traditional ML models potentially offer real-time and compute-efficient solutions for neural interfaces but typically struggle to capture non-linearities within high-dimensional datasets. DL addresses these limitations by automating feature extraction and modeling temporal, spatial, and global neural representations efficiently [8], [9], [13]. DL s adaptability makes it essential for complex neural decoding and adaptive BCIs, albeit with increased computational complexity. Recurrent Neural Networks (RNNs) and Convolutional Neu- ral Networks (CNNs) are essential for temporal modeling in neural decoding [8], [9]. RNNs capture long-term dependen- cies, aiding in motor decoding and seizure detection, while CNNs extract localized temporal patterns for efficient process- ing. Unlike sequential RNNs, CNNs enable parallelized oper- ations, reducing latency and computational cost for real-time BCIs and neuroprosthetic control, whereas RNNs enhance long-range temporal understanding. Graph Neural Networks (GNNs) model spatial dependencies in neural signals, advanc- ing mental regulation and seizure classification [13], [39]. For example, residual state update mechanism (REST) efficiently captures spatiotemporal dependencies in EEG, enabling real- time seizure detection with significantly reduced computation and memory [13] (Fig. 2(a)). Transformers address long- range dependencies in motor decoding using Multi-Head Self- Attention, enhancing emotion recognition and cross-subject generalization in movement decoding [40], [41]. Though com- putationally demanding, their parallelized processing enables real-time applications with optimized architectures. Attention maps further improve interpretability by identifying key neural features for decoding. C. Feature Engineering Feature engineering plays a crucial role in neural data analysis (decoding and processing), as it enhances scalability and interpretability. It reduces data dimensionality to enhance computational efficiency while extracting informative features for better interpretation of neural activity. A recent study introduced a lightweight, robust framework that utilizes com- mon neuro-markers such as spectral energy (SE), line length (LL), phase-amplitude coupling (PAC), phase-locking value (PLV), correlation, and band power ratio between channels (BPRC) for decoding anxiety-related behaviors, leveraging SHapley Additive exPlanations (SHAP) to quantify feature importance and identify key features [12]. SHAP analysis highlighted high-γ spectral and connectivity features as key neuro-markers for decoding defensive behaviors in local field potentials (LFPs) recorded from the infralimbic cortex (IL) and basolateral amygdala (BLA) of rats (Fig. 2(b)). Select- ing high-SHAP features preserved decoding accuracy while significantly reducing dimensionality and latency, making the method efficient for real-time, low-power neural decoding in implantable neuropsychiatric systems. Alternatively, the Distinctive Neural Code (DNC) algorithm employed a class saliency metric to compute feature importance and extract the most distinctive features (Fig. 2(c)) [21]. This approach simplified the decoding task, achieving high accuracy with a low-complexity classifier such as LDA. IV. NEURAL SYSTEMS-ON-CHIP Over the past decade, numerous efficient ML and signal processing techniques have been developed, particularly for on-chip spike detection and sorting. For example, adaptive spike detection methods dynamically adjust parameters using adaptive thresholding and nonlinear energy operator (NEO) transformations to enhance sensitivity [43], [44]. Spike sorting SoCs incorporate various clustering and classification tech- niques along with feature extraction strategies (e.g., fixed geometric features and salient feature selection) yielding im- provements in both accuracy and computational efficiency [31], [32]. More advanced neural interface SoCs integrate AI for sophisticated therapeutic and prosthetic applications, enabling real-time adaptation and enhanced functionality. A. Neural SoCs for Diagnostic Therapeutic Applications Therapeutic devices must make robust, low-latency deci- sions while providing real-time feedback (e.g., neurostimula- tion). Thus, accuracy and latency are particularly critical in ap- plications such as seizure detection and mental regulation [11]. One such example is a closed-loop device designed to restore motor function following brain injury by re-establishing lost connectivity between cortical areas [45]. It detects premotor cortex action potentials and promptly triggers somatosensory cortex stimulation, facilitating recovery. However, this system Fig. 2. Efficient ML Models for Neural Decoding: (a) Residual State Updates (REST) for seizure detection [13]. (b) Light Gradient-Boosting Ma- chine (LightGBM) and SHapley Additive exPlanations (SHAP) for decoding anxiety-related behaviors [12], [42]. (c) Distinctive Neural Code (DNC) and Linear Discriminant Analysis (LDA) for brain-to-text decoding [20]. lacks scalability and real-time adaptability for dynamically optimizing stimulation parameters. Neural SoCs enhance precision diagnostics and enable tar- geted interventions for neurological and psychiatric conditions by leveraging key neuro-markers. For example, a neural syn- chrony processor facilitates precise phase-locked neurostimu- lation using SE, PAC, and PLV, supporting interventions for anxiety and OCD [22], [23]. The NeuralTree SoC integrates versatile neuro-markers with ultra-low-power oblique tree- based classification and multichannel recording stimulation, enabling real-time adaptive neurotherapies and advancing im- plantable neural interfaces [5] (Fig. 3(a)). Alternatively, the SciCNN SoC enables patient-independent epilepsy tracking, eliminating the need for pre-deployment retraining and ad- dressing inter-patient seizure variability [16]. Unlike conven- tional neuro-marker classifiers, it employs a Seizure-Cluster- Inception CNN on bandpass-filtered EEG iEEG signals, im- proving seizure detection in previously unseen patients. How- ever, its computational complexity may pose challenges for low-power implantable applications. Fig. 3. Neural SoCs: (a) Die photo of the closed-loop NeuralTree chip and its experimental results in tremor and seizure detection [5]. (b) Die photo of the miniaturized brain-machine interface (MiBMI) chipset and its decoding results in the handwriting task [21]. B. Neural SoCs for Prosthetic Applications Recently, BCIs have shown great potential for restoring lost motor capabilities using powerful yet bulky computing systems; however, there is a growing need for implantable or portable neural prostheses that enable seamless use in daily tasks. These systems typically utilize high-resolution, high- channel-count neural signals recorded from intracortical Utah or high-density ECoG arrays [1], posing scalability challenges that demand computational and hardware efficiency as channel counts increase while maintaining accuracy [46]. Moreover, as neural signals evolve over time due to electrode movement and dynamic brain changes, stable performance requires not only scalable processing but also adaptability via online learning and fast retraining. Consequently, ML SoCs and algorithms must be agile in both training and inference. Following dense neural recording, these devices extract neural activity features, such as threshold crossings and spiking band power [21], [38] to provide an estimate of neural activity. The neural encoding module then employs ML to capture intricate activity patterns and convert them into actionable commands. So far, only a few studies have explored on-chip decoding for BCI applications due to the challenges of processing high-dimensional data acquired from dense electrodes and the complexity of BCI tasks. An early study developed a neuromorphic SoC for decoding four-class neural activity to control a robotic arm. However, its 16- channel recording capacity limited decoding accuracy and task complexity, while also exhibiting low hardware efficiency [47]. Another work used a 128-channel extreme learning machine (ELM) to decode finger movements, implementing the hidden layer on-chip while performing output layer computations on a commercial microcontroller [48]. However, it still relied on an off-chip processing unit to complete the decoding. A 93-channel intracortical BCI used spiking band power (SBP) features and a steady-state Kalman filter (SSKF) to de- code finger movement intentions, but it experienced a latency of up to 2.4 seconds. This system incorporated a commer- cial Intan analog front-end [38]. Meanwhile, the high-density NeuralTree SoC integrated 256 64-channel ECoG recording and on-chip finger movement decoding using a tree-based neural network. However, it lacked the high-bandwidth spike recording necessary for more complex tasks. These studies highlight the need for advanced ML-integrated BCI chips capable of handling complex tasks such as handwriting. More recently, the miniaturized Brain-to-Text BCI (MiBMI), integrating a neural recording chip with a decoding chip, was introduced (Fig. 3(b)). It enabled the decoding of intricate motor tasks such as handwriting, using a DNC- based framework combined with LDA. DNCs reduce the dimensionality of neural data and capture complex patterns, enabling fast and accurate letter classification with fewer parameters than conventional models. The measured system achieved a software-comparable accuracy in decoding 31 handwritten letters, 3 higher in task complexity compared to state-of-the-art BCI SoCs, with 10 better area and power efficiency, thanks to the use of DNC algorithm and hardware optimizations (e.g., memory sharing). This chipset presents a promising solution for integrating advanced decoding algorithms into compact, low-power BCIs. V. CONCLUSION Integrating neural interfaces with hardware-optimized ML models on SoC platforms enhances efficiency, speed, and accuracy, aligning with the growing demand for real-time neural decoding and closed-loop neuromodulation in assistive devices and therapeutic interventions. By leveraging high- density neural recordings and ML-based feature extraction, these systems enable fast, reliable neuro-marker identification, improving applications such as seizure detection, psychiatric treatments, and motor restoration. The synergy between neural interfaces and ML advances miniaturized, energy-efficient SoCs, paving the way for scalable, self-sufficient, and adaptive neural platforms that drive next-generation BCIs, precision medicine, and intelligent neurostimulation systems. REFERENCES [1] K. M. Patrick-Krueger, I. Burkhart, and J. L. Contreras-Vidal, The state of clinical trials of implantable brain computer interfaces, Nat. Rev. Bioeng., pp. 1 18, 2024. [2] M. A. Shaeri and A. M. Sodagar, A method for compression of intra-cortically-recorded neural signals dedicated to implantable brain machine interfaces, IEEE Trans. Neural Syst. Rehabil. Eng., vol. 23, no. 3, pp. 485 497, 2015. [3] M. Shoaran, M. H. Kamal, C. Pollo, P. Vandergheynst, and A. Schmid, Compact low-power cortical recording architecture for compressive multichannel data acquisition, IEEE Trans. Biomed. Circuits Syst., vol. 8, no. 6, pp. 857 870, 2014. [4] M. Shaeri and A. M. Sodagar, Data transformation in the processing of neuronal signals: A powerful tool to illuminate informative contents, IEEE Rev. Biomed. Eng., pp. 1 17, February 2022. [5] U. Shin, C. Ding, B. Zhu, Y. Vyza, A. Trouillet, E. C. Revol, S. P. Lacour, and M. Shoaran, Neuraltree: A 256-channel 0.227-µj class versatile neural activity classification and closed-loop neuromodulation soc, IEEE J. Solid-State Circuits, vol. 57, no. 11, pp. 3243 3257, 2022. [6] C. Ding, M. Gao, A. K. Skrivervik, and M. Shoaran, A 49.8-mm2 IR-UWB transmitter with co-designed power amplifier and antenna for neural implants with extended transmission range, IEEE J. Solid-State Circuits, 2025. [7] S. N. Flesher, J. E. Downey, J. M. Weiss, C. L. Hughes, A. J. Herrera, E. C. Tyler-Kabara, M. L. Boninger, J. L. Collinger, and R. A. Gaunt, A brain-computer interface that evokes tactile sensations improves robotic arm control, Science, vol. 372, no. 6544, pp. 831 836, 2021. [8] F. R. Willett, D. T. Avansino, L. R. Hochberg, J. M. Henderson, and K. V. Shenoy, High-performance brain-to-text communication via handwriting, Nature, vol. 593, no. 7858, pp. 249 254, 2021. [9] A. B. Silva, K. T. Littlejohn, J. R. Liu, D. A. Moses, and E. F. Chang, The speech neuroprosthesis, Nat. Rev. Neurosci., pp. 1 20, 2024. [10] H. Lorach, A. Galvez, V. Spagnolo, F. Martel, S. Karakas, N. Intering, M. Vat, O. Faivre, C. Harte, S. Komi et al., Walking naturally after spinal cord injury using a brain spine interface, Nature, vol. 618, no. 7963, pp. 126 133, 2023. [11] M. Shoaran, U. Shin, and M. Shaeri, Intelligent neural interfaces: An emerging era in neurotechnology, in 2024 IEEE Custom Integr. Circuits Conf. (CICC), 2024, pp. 01 07. [12] J. Liu, R. Younk, L. M. Drahos, S. S. Nagrale, S. Yadav, A. S. Widge, and M. Shoaran, Neural decoding and feature selection methods for closed-loop control of avoidance behavior, J. Neural Eng., vol. 21, no. 5, p. 056041, 2024. [13] A. Afzal, G. Chrysos, V. Cevher, and M. Shoaran, REST: efficient and accelerated EEG seizure analysis through residual state updates, in Proc. 41st Int. Conf. Mach. Learn., ser. ICML 24. JMLR.org, 2024. [14] B. Zhu, G. Coppola, and M. Shoaran, Migraine classification using somatosensory evoked potentials, Cephalalgia, vol. 39, no. 9, pp. 1143 1155, 2019. [15] L. Yao, J. L. Baker, N. D. Schiff, K. P. Purpura, and M. Shoaran, Predicting task performance from biomarkers of mental fatigue in global brain activity, J. Neural Eng., vol. 18, no. 3, p. 036001, 2021. [16] C.-W. Tsai, R. Jiang, L. Zhang, M. Zhang, and J. Yoo, Seizure-cluster- inception cnn (scicnn): A patient-independent epilepsy tracking soc with 0-shot-retraining, IEEE Trans. Biomed. Circuits Syst., vol. 17, no. 6, pp. 1202 1213, 2023. [17] L. Yao, P. Brown, and M. Shoaran, Improved detection of parkinsonian resting tremor with feature engineering and kalman filtering, Clinical Neurophysiology, vol. 131, no. 1, pp. 274 284, 2020. [18] M. Shoaran, B. A. Haghi, M. Taghavi, M. Farivar, and A. Emami- Neyestanak, Energy-efficient classification for resource-constrained biomedical applications, IEEE J. Emerg. Sel. Topics Circuits Syst., vol. 8, no. 4, pp. 693 707, 2018. [19] J. Yoo and M. Shoaran, Neural interface systems with on-device computing: Machine learning and neuromorphic architectures, Current opinion in biotechnology, vol. 72, pp. 95 101, 2021. [20] M. A. Shaeri, U. Shin, A. Yadav, R. Caramellino, G. Rainer, and M. Shoaran, 33.3 MiBMI: A 192 512-channel 2.46mm2 miniaturized brain-machine interface chipset enabling 31-class brain-to-text conver- sion through distinctive neural codes, in 2024 IEEE Int. Solid-State Circuits Conf. (ISSCC), vol. 67, 2024, pp. 546 548. [21] M. Shaeri, U. Shin, A. Yadav, R. Caramellino, G. Rainer, and M. Shoaran, A 2.46-mm2 miniaturized brain-machine interface (MiBMI) enabling 31-class brain-to-text decoding, IEEE J. Solid-State Circuits, vol. 59, no. 11, pp. 3566 3579, 2024. [22] U. Shin, C. Ding, L. Somappa, V. Woods, A. S. Widge, and M. Shoaran, A 16-channel 60µw neural synchrony processor for multi-mode phase- locked neurostimulation, in 2022 IEEE Custom Integr. Circuits Conf. (CICC). IEEE, 2022, pp. 01 02. [23] U. Shin, C. Ding, V. Woods, A. S. Widge, and M. Shoaran, A 16-ch low-power neural connectivity extraction and phase-locked deep brain stimulation soc, IEEE Solid-State Circuits Lett., vol. 6, pp. 21 24, 2023. [24] T. Aflalo, S. Kellis, C. Klaes, B. Lee, Y. Shi, K. Pejsa, K. Shanfield, S. Hayes-Jackson, M. Aisen, C. Heck et al., Decoding motor imagery from the posterior parietal cortex of a tetraplegic human, Science, vol. 348, no. 6237, pp. 906 910, 2015. [25] C. Libedinsky, R. So, Z. Xu, T. K. Kyar, D. Ho, C. Lim, L. Chan, Y. Chua, L. Yao, J. H. Cheong et al., Independent mobility achieved through a wireless brain-machine interface, PLoS One, vol. 11, no. 11, p. e0165773, 2016. [26] A. B. Ajiboye, F. R. Willett, D. R. Young, W. D. Memberg, B. A. Murphy, J. P. Miller, B. L. Walter, J. A. Sweet, H. A. Hoyen, M. W. Keith et al., Restoration of reaching and grasping movements through brain-controlled muscle stimulation in a person with tetraplegia, The Lancet, vol. 389, no. 10081, pp. 1821 1830, 2017. [27] C. Pandarinath, P. Nuyujukian, C. H. Blabe, B. L. Sorice, J. Saab, F. R. Willett, L. R. Hochberg, K. V. Shenoy, and J. M. Henderson, High performance communication by people with paralysis using an intracortical brain-computer interface, elife, vol. 6, p. e18554, 2017. [28] B. Wodlinger, J. Downey, E. Tyler-Kabara, A. Schwartz, M. Boninger, and J. Collinger, Ten-dimensional anthropomorphic arm control in a human brain- machine interface: difficulties, solutions, and limitations, J. Neural Eng., vol. 12, no. 1, p. 016011, 2014. [29] X. Gao, Y. Wang, X. Chen, and S. Gao, Interface, interaction, and intelligence in generalized brain computer interfaces, Trends Cogn. Sci., vol. 25, no. 8, pp. 671 684, 2021. [30] R. A. Andersen, T. Aflalo, L. Bashford, D. Bj anes, and S. Kellis, Ex- ploring cognition with brain machine interfaces, Annu. Rev. Psychol., vol. 73, pp. 131 158, 2022. [31] M. Shaeri and A. M. Sodagar, A framework for on-implant spike sorting based on salient feature selection, Nature Communications, vol. 11, no. 3278, pp. 1 9, June 2020. [32] Y. Chen, B. Tacca, Y. Chen, D. Biswas, G. Gielen, F. Catthoor, M. Ver- helst, and C. M. Lopez, An online-spike-sorting ic using unsupervised geometry-aware osort clustering for efficient embedded neural-signal processing, IEEE J. Solid-State Circuits, 2023. [33] M. Li, H. Xu, X. Liu, and S. Lu, Emotion recognition from multichan- nel eeg signals using k-nearest neighbor classification, Technol. Health Care, vol. 26, no. S1, pp. 509 519, 2018. [34] J. Birjandtalab, M. B. Pouyan, D. Cogan, M. Nourani, and J. Harvey, Automated seizure detection using limited-channel eeg and non-linear dimension reduction, Comput. Biol. Med., vol. 82, pp. 49 58, 2017. [35] A. Sharmila and P. Geethanjali, DWT based detection of epileptic seizure from EEG signals using naive bayes and k-NN classifiers, IEEE Access, vol. 4, pp. 7716 7727, 2016. [36] B. Zhu, M. Farivar, and M. Shoaran, Resot: Resource-efficient oblique trees for neural signal classification, IEEE Trans. Biomed. Circuits Syst., vol. 14, no. 4, pp. 692 704, 2020. [37] M. Taghavi and M. Shoaran, Hardware complexity analysis of deep neural networks and decision tree ensembles for real-time neural data classification, in Proc. 9th Int. IEEE EMBS Conf. Neural Eng. (NER). IEEE, 2019, pp. 407 410. [38] H. An, S. R. Nason-Tomaszewski, J. Lim, K. Kwon, M. S. Willsey, P. G. Patil, H.-S. Kim, D. Sylvester, C. A. Chestek, and D. Blaauw, A power-efficient brain-machine interface system with a sub-mw feature extraction and decoding asic demonstrated in nonhuman primates, IEEE Trans. Biomed. Circuits Syst., vol. 16, no. 3, pp. 395 408, 2022. [39] P. Zhong, D. Wang, and C. Miao, Eeg-based emotion recognition using regularized graph neural networks, IEEE Trans. on Affective Computing, vol. 13, no. 3, pp. 1290 1301, 2020. [40] W. Jiang, L. Zhao, and B.-l. Lu, Large brain model for learning generic representations with tremendous eeg data in bci, in Proc. of the 12th Int. Conf. on Learn. Represent. (ICLR), 2024. [41] M. Kalbasi, M. Shaeri, V. A. Mendez, S. Shokur, S. Micera, and M. Shoaran, A hardware-efficient EMG decoder with an attractor-based neural network for next-generation hand prostheses, in IEEE 6th Int. Conf. on AI Circuits and Systems (AICAS), 2024, pp. 532 536. [42] B. Zhu, U. Shin, and M. Shoaran, Closed-loop neural prostheses with on-chip intelligence: A review and a low-latency machine learning model for brain state detection, IEEE Trans. Biomed. Circuits Syst., vol. 15, no. 5, pp. 877 897, 2021. [43] S. Razmpour, M. A. Shaeri, H. Hosseini-Nejad, and A. M. Sodagar, Signal processing in implantable neural recording microsystems, in Telemedicine and Electronic Medicine. Boca Raton, FL, USA: CRC Press, 2015, ch. 18, pp. 416 443. [44] X. Guo, M. Shaeri, and M. Shoaran, An accurate and hardware-efficient dual spike detector for implantable neural interfaces, in IEEE Biomed. Circuits Syst. Conf. (BioCAS), 2022, pp. 70 74. [45] D. J. Guggenmos, M. Azin, S. Barbay, J. D. Mahnken, C. Dunham, P. Mohseni, and R. J. Nudo, Restoration of function after brain damage using a neural prosthesis, Proc. Natl. Acad. Sci., vol. 110, no. 52, pp. 21 177 21 182, 2013. [46] M. Shaeri, A. Afzal, and M. Shoaran, Challenges and opportunities of edge ai for next-generation implantable bmis, in IEEE 4th Int. Conf. on AI Circuits and Systems (AICAS), 2022, pp. 190 193. [47] F. Boi, T. Moraitis, V. Feo, F. Diotalevi, C. Bartolozzi, G. Indiveri, and A. Vato, A bidirectional brain-machine interface featuring a neuromor- phic hardware decoder, Front. Neurosci., vol. 10, p. 215903, 2016. [48] Y. Chen, E. Yao, and A. Basu, A 128-channel extreme learning machine-based neural decoder for brain machine interfaces, IEEE Trans. Biomed. Circuits Syst., vol. 10, no. 3, pp. 679 692, 2015.\n\n=== SEGMENTS ===\n\n--- Segment 1 ---\nMachine-Learning Powered Neural Interfaces for Smart Prosthetics and Diagnostics MohammadAli Shaeri , Jinhan Liu , Mahsa Shoaran Institutes of Electrical and Micro Engineering and Neuro-X, EPFL Lausanne, Switzerland {mohammad.shaeri, jinhan.liu, Abstract Advanced neural interfaces are transforming appli- cations ranging from neuroscience research to diagnostic tools (for mental state recognition, tremor and seizure detection) as well as prosthetic devices (for motor and communication recovery). By integrating complex functions into miniaturized neural devices, these systems unlock significant opportunities for personalized assistive technologies and adaptive therapeutic interventions. Leveraging high-density neural recordings, on-site signal processing, and machine learning (ML), these interfaces ex- tract critical features, identify disease neuro-markers, and enable accurate, low-latency neural decoding. This integration facilitates real-time interpretation of neural signals, adaptive modulation of brain activity, and efficient control of assistive devices. Moreover, the synergy between neural interfaces and ML has paved the way for self-sufficient, ubiquitous platforms capable of operating in diverse environments with minimal hardware costs and external dependencies. In this work, we review recent advancements in AI-driven decoding algorithms and energy-efficient System-on- Chip (SoC) platforms for next-generation miniaturized neural devices. These innovations highlight the potential for developing intelligent neural interfaces, addressing critical challenges in scalability, reliability, interpretability, and user adaptability. Index Terms Neural Interfaces, Neuromodulation, Brain- Computer Interfaces (BCI), Machine Learning, System-on-Chip. I. INTRODUCTION Modern neural interfaces can simultaneously record thou- sands of neural signals [1]. This capability generates massive volumes of data that demand efficient processing and com- pression to extract meaningful insights [2] [4] (Fig. 1(a)). Furthermore, advances in neural interface technology have enabled real-time recording and transmission, paving the way for high-resolution mapping of brain activity [5], [6]. However, the scale and complexity of neural data pose significant chal- lenges in processing, storage, and interpretation, necessitating innovative approaches in both hardware and software. Machine learning (ML) has emerged as a transformative tool for data analysis, enabling the execution of sophisticated tasks that were previously unattainable.\n\n--- Segment 2 ---\nHowever, the scale and complexity of neural data pose significant chal- lenges in processing, storage, and interpretation, necessitating innovative approaches in both hardware and software. Machine learning (ML) has emerged as a transformative tool for data analysis, enabling the execution of sophisticated tasks that were previously unattainable. ML algorithms excel at identifying patterns in complex datasets, making them invaluable for applications such as brain-computer interfaces (BCIs) aimed at motor and communication restoration [7] [10]. Additionally, ML facilitates therapeutic applications, including mental state recognition, migraine detection, and seizure prediction [11] [15]. Moreover, brain-triggered neuro- modulation systems leverage ML to adaptively modulate brain These authors contributed equally to this work. activity in response to disease-specific neuromarkers, offering personalized and precise therapeutic interventions [5], [16], [17]. To achieve these advanced functionalities, integrating neural interfaces and ML into miniaturized systems has become a key research focus [16], [18] [22]. Existing works have demonstrated promising results in developing energy-efficient system-on-chip (SoC) platforms for real-time neural signal processing and decoding. However, significant challenges re- main in achieving hardware efficiency, ensuring scalability, and maintaining the reliability and interpretability of these systems. Addressing these challenges is essential for advanc- ing next-generation neural interfaces that combine compact designs with robust performance in real-world applications. II. NEURAL INTERFACES Fig. 1. Neural Interfaces: (a) Neural recording interfaces capture high- density neural signals and process them to reduce data rates, or wirelessly transmit them to an external computer for further processing. (b) Therapeutic neural interfaces extract neuro-markers to detect disease-related neurological symptoms or mental states, and may also integrate neurostimulation for functions such as seizure suppression or brain rewiring. (c) Prosthetic neural interfaces use ML to convert brain intention into actionable commands, enabling control of end-effectors like robotic hands. arXiv:2505.02516v1 [cs.AI] 5 May 2025 Diagnostic Therapeutic Applications ML can empower advanced therapeutic devices and transform the diagnosis and treatment of neurological and psychiatric disorders, en- abling real-time monitoring, adaptive neurostimulation, and personalized interventions (Fig. 1(b)).\n\n--- Segment 3 ---\narXiv:2505.02516v1 [cs.AI] 5 May 2025 Diagnostic Therapeutic Applications ML can empower advanced therapeutic devices and transform the diagnosis and treatment of neurological and psychiatric disorders, en- abling real-time monitoring, adaptive neurostimulation, and personalized interventions (Fig. 1(b)). These systems enhance clinical outcomes and patient independence via seizure tremor suppression, emotion regulation, and migraine therapy. By integrating real-time detection of neurological symptoms (e.g., seizures) with closed-loop neuromodulation, these devices deliver targeted stimulation to prevent seizures [5], [16]. Similarly, closed-loop neural interfaces can be used to treat tremors in patients with Parkinson s disease by detecting and modulating abnormal oscillations [5], [17]. Neural interfaces are also being applied in the treatment of psychiatric disorders, for example, in decoding emotional and anxiety-related states, analyzing connectivity and spectral dynamics to guide adaptive neurostimulation and biofeedback therapy [12], [22], [23]. Prosthetic Assistive Applications Prosthetic neural in- terfaces employ ML to decode brain signals in order to drive a wide range of effectors, enabling brain control of prosthetic limbs and communication devices for individuals with disabil- ities (Fig. 1(c)). Such interfaces provide critical functionalities such as artificial limb movement [24], locomotion assistance through wheelchair operation [25] and direct activation of natural limbs via neuromuscular [26] or spinal cord stimu- lation [10], facilitating the restoration of walking and hand movements. Also, neural prostheses empower individuals to perform daily tasks, including communication through cursor control and typing [27], writing [8], and speaking [9]. Recent advancements in BCIs emphasize greater task complexity and dexterity, including high-degree-of-freedom control and ability to distinguish diverse actions [9], [28]. These systems are paving the way for groundbreaking applications, ranging from cognitive enhancement tools to advanced assistive technolo- gies that adapt to the user s needs, delivering unprecedented functionality and adaptability [29], [30]. III. MACHINE LEARNING FOR NEURAL INTERFACES ML techniques, including traditional and deep learning (DL) models, have transformed neural data analysis by uncovering hidden brain patterns while enhancing real-time neural decod- ing, brain function modeling, and feature-level interpretability.\n\n--- Segment 4 ---\nIII. MACHINE LEARNING FOR NEURAL INTERFACES ML techniques, including traditional and deep learning (DL) models, have transformed neural data analysis by uncovering hidden brain patterns while enhancing real-time neural decod- ing, brain function modeling, and feature-level interpretability. A. Traditioinal Machine Learning Traditional ML models, including linear, tree-based, and probabilistic methods, are widely used in neural signal pro- cessing, neurological symptom detection and motor decoding. Distance-based techniques and window discrimination offer computational efficiency, memory savings, and real-time pro- cessing, making them well-suited for neural interfaces [5], [31]. Methods such as K-means and window discrimination classify data by proximity to centroids, shown to be efficient solutions in simple ML tasks, such as spike detection and sorting [31], [32]. K-Nearest Neighbors (KNN) is a non- parametric, flexible method suited for emotion recognition and early seizure detection, adapting to individualized neural activity [33], [34]. It offers low-complexity training without weight optimizations, but can be computationally expensive during inference on large datasets [35]. Linear Discriminant Analysis (LDA) maximizes class sep- arability while reducing dimensionality, offering an inter- pretable and low-complexity solution for motor decoding [20]. Support Vector Machines (SVMs) effectively decode neural signals, with linear SVMs performing well in simple tasks and kernel SVMs handling complex applications like seizure detection. While SVMs provide efficient inference and low memory usage, the training complexity increases with data size. Alternatively, Gradient Boosted Decision Trees (GBDTs) excel in non-linear, high-dimensional neural data modeling, making them effective for cognitive state classification and seizure detection [12], [18], [36]. They use hierarchical de- cision rules, reducing computational overhead and hardware complexity, while requiring minimal memory to store tree structures and split thresholds [37]. GBDTs offer high inter- pretability, enabling neuro-marker identification and providing clear decision paths for neural decoding analysis. Hidden Markov Models (HMMs) and Kalman Filters (KFs) enable sequential neural decoding through probabilistic modeling, iteratively updating hidden states (e.g., motor intentions) by estimating the most probable state based on observed neural data [10], [38].\n\n--- Segment 5 ---\nGBDTs offer high inter- pretability, enabling neuro-marker identification and providing clear decision paths for neural decoding analysis. Hidden Markov Models (HMMs) and Kalman Filters (KFs) enable sequential neural decoding through probabilistic modeling, iteratively updating hidden states (e.g., motor intentions) by estimating the most probable state based on observed neural data [10], [38]. This self-recalibration capability makes them well-suited for real-time neural decoding in adaptive BCIs. B. Deep Learning Traditional ML models potentially offer real-time and compute-efficient solutions for neural interfaces but typically struggle to capture non-linearities within high-dimensional datasets. DL addresses these limitations by automating feature extraction and modeling temporal, spatial, and global neural representations efficiently [8], [9], [13]. DL s adaptability makes it essential for complex neural decoding and adaptive BCIs, albeit with increased computational complexity. Recurrent Neural Networks (RNNs) and Convolutional Neu- ral Networks (CNNs) are essential for temporal modeling in neural decoding [8], [9]. RNNs capture long-term dependen- cies, aiding in motor decoding and seizure detection, while CNNs extract localized temporal patterns for efficient process- ing. Unlike sequential RNNs, CNNs enable parallelized oper- ations, reducing latency and computational cost for real-time BCIs and neuroprosthetic control, whereas RNNs enhance long-range temporal understanding. Graph Neural Networks (GNNs) model spatial dependencies in neural signals, advanc- ing mental regulation and seizure classification [13], [39]. For example, residual state update mechanism (REST) efficiently captures spatiotemporal dependencies in EEG, enabling real- time seizure detection with significantly reduced computation and memory [13] (Fig. 2(a)). Transformers address long- range dependencies in motor decoding using Multi-Head Self- Attention, enhancing emotion recognition and cross-subject generalization in movement decoding [40], [41]. Though com- putationally demanding, their parallelized processing enables real-time applications with optimized architectures. Attention maps further improve interpretability by identifying key neural features for decoding. C. Feature Engineering Feature engineering plays a crucial role in neural data analysis (decoding and processing), as it enhances scalability and interpretability.\n\n--- Segment 6 ---\nAttention maps further improve interpretability by identifying key neural features for decoding. C. Feature Engineering Feature engineering plays a crucial role in neural data analysis (decoding and processing), as it enhances scalability and interpretability. It reduces data dimensionality to enhance computational efficiency while extracting informative features for better interpretation of neural activity. A recent study introduced a lightweight, robust framework that utilizes com- mon neuro-markers such as spectral energy (SE), line length (LL), phase-amplitude coupling (PAC), phase-locking value (PLV), correlation, and band power ratio between channels (BPRC) for decoding anxiety-related behaviors, leveraging SHapley Additive exPlanations (SHAP) to quantify feature importance and identify key features [12]. SHAP analysis highlighted high-γ spectral and connectivity features as key neuro-markers for decoding defensive behaviors in local field potentials (LFPs) recorded from the infralimbic cortex (IL) and basolateral amygdala (BLA) of rats (Fig. 2(b)). Select- ing high-SHAP features preserved decoding accuracy while significantly reducing dimensionality and latency, making the method efficient for real-time, low-power neural decoding in implantable neuropsychiatric systems. Alternatively, the Distinctive Neural Code (DNC) algorithm employed a class saliency metric to compute feature importance and extract the most distinctive features (Fig. 2(c)) [21]. This approach simplified the decoding task, achieving high accuracy with a low-complexity classifier such as LDA. IV. NEURAL SYSTEMS-ON-CHIP Over the past decade, numerous efficient ML and signal processing techniques have been developed, particularly for on-chip spike detection and sorting. For example, adaptive spike detection methods dynamically adjust parameters using adaptive thresholding and nonlinear energy operator (NEO) transformations to enhance sensitivity [43], [44]. Spike sorting SoCs incorporate various clustering and classification tech- niques along with feature extraction strategies (e.g., fixed geometric features and salient feature selection) yielding im- provements in both accuracy and computational efficiency [31], [32]. More advanced neural interface SoCs integrate AI for sophisticated therapeutic and prosthetic applications, enabling real-time adaptation and enhanced functionality.\n\n--- Segment 7 ---\nSpike sorting SoCs incorporate various clustering and classification tech- niques along with feature extraction strategies (e.g., fixed geometric features and salient feature selection) yielding im- provements in both accuracy and computational efficiency [31], [32]. More advanced neural interface SoCs integrate AI for sophisticated therapeutic and prosthetic applications, enabling real-time adaptation and enhanced functionality. A. Neural SoCs for Diagnostic Therapeutic Applications Therapeutic devices must make robust, low-latency deci- sions while providing real-time feedback (e.g., neurostimula- tion). Thus, accuracy and latency are particularly critical in ap- plications such as seizure detection and mental regulation [11]. One such example is a closed-loop device designed to restore motor function following brain injury by re-establishing lost connectivity between cortical areas [45]. It detects premotor cortex action potentials and promptly triggers somatosensory cortex stimulation, facilitating recovery. However, this system Fig. 2. Efficient ML Models for Neural Decoding: (a) Residual State Updates (REST) for seizure detection [13]. (b) Light Gradient-Boosting Ma- chine (LightGBM) and SHapley Additive exPlanations (SHAP) for decoding anxiety-related behaviors [12], [42]. (c) Distinctive Neural Code (DNC) and Linear Discriminant Analysis (LDA) for brain-to-text decoding [20]. lacks scalability and real-time adaptability for dynamically optimizing stimulation parameters. Neural SoCs enhance precision diagnostics and enable tar- geted interventions for neurological and psychiatric conditions by leveraging key neuro-markers. For example, a neural syn- chrony processor facilitates precise phase-locked neurostimu- lation using SE, PAC, and PLV, supporting interventions for anxiety and OCD [22], [23]. The NeuralTree SoC integrates versatile neuro-markers with ultra-low-power oblique tree- based classification and multichannel recording stimulation, enabling real-time adaptive neurotherapies and advancing im- plantable neural interfaces [5] (Fig. 3(a)). Alternatively, the SciCNN SoC enables patient-independent epilepsy tracking, eliminating the need for pre-deployment retraining and ad- dressing inter-patient seizure variability [16].\n\n--- Segment 8 ---\n3(a)). Alternatively, the SciCNN SoC enables patient-independent epilepsy tracking, eliminating the need for pre-deployment retraining and ad- dressing inter-patient seizure variability [16]. Unlike conven- tional neuro-marker classifiers, it employs a Seizure-Cluster- Inception CNN on bandpass-filtered EEG iEEG signals, im- proving seizure detection in previously unseen patients. How- ever, its computational complexity may pose challenges for low-power implantable applications. Fig. 3. Neural SoCs: (a) Die photo of the closed-loop NeuralTree chip and its experimental results in tremor and seizure detection [5]. (b) Die photo of the miniaturized brain-machine interface (MiBMI) chipset and its decoding results in the handwriting task [21]. B. Neural SoCs for Prosthetic Applications Recently, BCIs have shown great potential for restoring lost motor capabilities using powerful yet bulky computing systems; however, there is a growing need for implantable or portable neural prostheses that enable seamless use in daily tasks. These systems typically utilize high-resolution, high- channel-count neural signals recorded from intracortical Utah or high-density ECoG arrays [1], posing scalability challenges that demand computational and hardware efficiency as channel counts increase while maintaining accuracy [46]. Moreover, as neural signals evolve over time due to electrode movement and dynamic brain changes, stable performance requires not only scalable processing but also adaptability via online learning and fast retraining. Consequently, ML SoCs and algorithms must be agile in both training and inference. Following dense neural recording, these devices extract neural activity features, such as threshold crossings and spiking band power [21], [38] to provide an estimate of neural activity. The neural encoding module then employs ML to capture intricate activity patterns and convert them into actionable commands. So far, only a few studies have explored on-chip decoding for BCI applications due to the challenges of processing high-dimensional data acquired from dense electrodes and the complexity of BCI tasks. An early study developed a neuromorphic SoC for decoding four-class neural activity to control a robotic arm. However, its 16- channel recording capacity limited decoding accuracy and task complexity, while also exhibiting low hardware efficiency [47].\n\n--- Segment 9 ---\nAn early study developed a neuromorphic SoC for decoding four-class neural activity to control a robotic arm. However, its 16- channel recording capacity limited decoding accuracy and task complexity, while also exhibiting low hardware efficiency [47]. Another work used a 128-channel extreme learning machine (ELM) to decode finger movements, implementing the hidden layer on-chip while performing output layer computations on a commercial microcontroller [48]. However, it still relied on an off-chip processing unit to complete the decoding. A 93-channel intracortical BCI used spiking band power (SBP) features and a steady-state Kalman filter (SSKF) to de- code finger movement intentions, but it experienced a latency of up to 2.4 seconds. This system incorporated a commer- cial Intan analog front-end [38]. Meanwhile, the high-density NeuralTree SoC integrated 256 64-channel ECoG recording and on-chip finger movement decoding using a tree-based neural network. However, it lacked the high-bandwidth spike recording necessary for more complex tasks. These studies highlight the need for advanced ML-integrated BCI chips capable of handling complex tasks such as handwriting. More recently, the miniaturized Brain-to-Text BCI (MiBMI), integrating a neural recording chip with a decoding chip, was introduced (Fig. 3(b)). It enabled the decoding of intricate motor tasks such as handwriting, using a DNC- based framework combined with LDA. DNCs reduce the dimensionality of neural data and capture complex patterns, enabling fast and accurate letter classification with fewer parameters than conventional models. The measured system achieved a software-comparable accuracy in decoding 31 handwritten letters, 3 higher in task complexity compared to state-of-the-art BCI SoCs, with 10 better area and power efficiency, thanks to the use of DNC algorithm and hardware optimizations (e.g., memory sharing). This chipset presents a promising solution for integrating advanced decoding algorithms into compact, low-power BCIs. V. CONCLUSION Integrating neural interfaces with hardware-optimized ML models on SoC platforms enhances efficiency, speed, and accuracy, aligning with the growing demand for real-time neural decoding and closed-loop neuromodulation in assistive devices and therapeutic interventions.\n\n--- Segment 10 ---\nThis chipset presents a promising solution for integrating advanced decoding algorithms into compact, low-power BCIs. V. CONCLUSION Integrating neural interfaces with hardware-optimized ML models on SoC platforms enhances efficiency, speed, and accuracy, aligning with the growing demand for real-time neural decoding and closed-loop neuromodulation in assistive devices and therapeutic interventions. By leveraging high- density neural recordings and ML-based feature extraction, these systems enable fast, reliable neuro-marker identification, improving applications such as seizure detection, psychiatric treatments, and motor restoration. The synergy between neural interfaces and ML advances miniaturized, energy-efficient SoCs, paving the way for scalable, self-sufficient, and adaptive neural platforms that drive next-generation BCIs, precision medicine, and intelligent neurostimulation systems. REFERENCES [1] K. M. Patrick-Krueger, I. Burkhart, and J. L. Contreras-Vidal, The state of clinical trials of implantable brain computer interfaces, Nat. Rev. Bioeng., pp. 1 18, 2024. [2] M. A. Shaeri and A. M. Sodagar, A method for compression of intra-cortically-recorded neural signals dedicated to implantable brain machine interfaces, IEEE Trans. Neural Syst. Rehabil. Eng., vol. 23, no. 3, pp. 485 497, 2015. [3] M. Shoaran, M. H. Kamal, C. Pollo, P. Vandergheynst, and A. Schmid, Compact low-power cortical recording architecture for compressive multichannel data acquisition, IEEE Trans. Biomed. Circuits Syst., vol. 8, no. 6, pp. 857 870, 2014. [4] M. Shaeri and A. M. Sodagar, Data transformation in the processing of neuronal signals: A powerful tool to illuminate informative contents, IEEE Rev. Biomed. Eng., pp. 1 17, February 2022.\n\n--- Segment 11 ---\nEng., pp. 1 17, February 2022. [5] U. Shin, C. Ding, B. Zhu, Y. Vyza, A. Trouillet, E. C. Revol, S. P. Lacour, and M. Shoaran, Neuraltree: A 256-channel 0.227-µj class versatile neural activity classification and closed-loop neuromodulation soc, IEEE J. Solid-State Circuits, vol. 57, no. 11, pp. 3243 3257, 2022. [6] C. Ding, M. Gao, A. K. Skrivervik, and M. Shoaran, A 49.8-mm2 IR-UWB transmitter with co-designed power amplifier and antenna for neural implants with extended transmission range, IEEE J. Solid-State Circuits, 2025. [7] S. N. Flesher, J. E. Downey, J. M. Weiss, C. L. Hughes, A. J. Herrera, E. C. Tyler-Kabara, M. L. Boninger, J. L. Collinger, and R. A. Gaunt, A brain-computer interface that evokes tactile sensations improves robotic arm control, Science, vol. 372, no. 6544, pp. 831 836, 2021. [8] F. R. Willett, D. T. Avansino, L. R. Hochberg, J. M. Henderson, and K. V. Shenoy, High-performance brain-to-text communication via handwriting, Nature, vol. 593, no. 7858, pp. 249 254, 2021. [9] A. B. Silva, K. T. Littlejohn, J. R. Liu, D. A. Moses, and E. F. Chang, The speech neuroprosthesis, Nat. Rev. Neurosci., pp. 1 20, 2024. [10] H. Lorach, A. Galvez, V. Spagnolo, F. Martel, S. Karakas, N. Intering, M. Vat, O. Faivre, C. Harte, S. Komi et al., Walking naturally after spinal cord injury using a brain spine interface, Nature, vol. 618, no. 7963, pp. 126 133, 2023.\n\n--- Segment 12 ---\n7963, pp. 126 133, 2023. [11] M. Shoaran, U. Shin, and M. Shaeri, Intelligent neural interfaces: An emerging era in neurotechnology, in 2024 IEEE Custom Integr. Circuits Conf. (CICC), 2024, pp. 01 07. [12] J. Liu, R. Younk, L. M. Drahos, S. S. Nagrale, S. Yadav, A. S. Widge, and M. Shoaran, Neural decoding and feature selection methods for closed-loop control of avoidance behavior, J. Neural Eng., vol. 21, no. 5, p. 056041, 2024. [13] A. Afzal, G. Chrysos, V. Cevher, and M. Shoaran, REST: efficient and accelerated EEG seizure analysis through residual state updates, in Proc. 41st Int. Conf. Mach. Learn., ser. ICML 24. JMLR.org, 2024. [14] B. Zhu, G. Coppola, and M. Shoaran, Migraine classification using somatosensory evoked potentials, Cephalalgia, vol. 39, no. 9, pp. 1143 1155, 2019. [15] L. Yao, J. L. Baker, N. D. Schiff, K. P. Purpura, and M. Shoaran, Predicting task performance from biomarkers of mental fatigue in global brain activity, J. Neural Eng., vol. 18, no. 3, p. 036001, 2021. [16] C.-W. Tsai, R. Jiang, L. Zhang, M. Zhang, and J. Yoo, Seizure-cluster- inception cnn (scicnn): A patient-independent epilepsy tracking soc with 0-shot-retraining, IEEE Trans. Biomed. Circuits Syst., vol. 17, no. 6, pp. 1202 1213, 2023. [17] L. Yao, P. Brown, and M. Shoaran, Improved detection of parkinsonian resting tremor with feature engineering and kalman filtering, Clinical Neurophysiology, vol. 131, no. 1, pp. 274 284, 2020. [18] M. Shoaran, B.\n\n--- Segment 13 ---\n274 284, 2020. [18] M. Shoaran, B. A. Haghi, M. Taghavi, M. Farivar, and A. Emami- Neyestanak, Energy-efficient classification for resource-constrained biomedical applications, IEEE J. Emerg. Sel. Topics Circuits Syst., vol. 8, no. 4, pp. 693 707, 2018. [19] J. Yoo and M. Shoaran, Neural interface systems with on-device computing: Machine learning and neuromorphic architectures, Current opinion in biotechnology, vol. 72, pp. 95 101, 2021. [20] M. A. Shaeri, U. Shin, A. Yadav, R. Caramellino, G. Rainer, and M. Shoaran, 33.3 MiBMI: A 192 512-channel 2.46mm2 miniaturized brain-machine interface chipset enabling 31-class brain-to-text conver- sion through distinctive neural codes, in 2024 IEEE Int. Solid-State Circuits Conf. (ISSCC), vol. 67, 2024, pp. 546 548. [21] M. Shaeri, U. Shin, A. Yadav, R. Caramellino, G. Rainer, and M. Shoaran, A 2.46-mm2 miniaturized brain-machine interface (MiBMI) enabling 31-class brain-to-text decoding, IEEE J. Solid-State Circuits, vol. 59, no. 11, pp. 3566 3579, 2024. [22] U. Shin, C. Ding, L. Somappa, V. Woods, A. S. Widge, and M. Shoaran, A 16-channel 60µw neural synchrony processor for multi-mode phase- locked neurostimulation, in 2022 IEEE Custom Integr. Circuits Conf. (CICC). IEEE, 2022, pp. 01 02. [23] U. Shin, C. Ding, V. Woods, A. S. Widge, and M. Shoaran, A 16-ch low-power neural connectivity extraction and phase-locked deep brain stimulation soc, IEEE Solid-State Circuits Lett., vol. 6, pp. 21 24, 2023.\n\n--- Segment 14 ---\n6, pp. 21 24, 2023. [24] T. Aflalo, S. Kellis, C. Klaes, B. Lee, Y. Shi, K. Pejsa, K. Shanfield, S. Hayes-Jackson, M. Aisen, C. Heck et al., Decoding motor imagery from the posterior parietal cortex of a tetraplegic human, Science, vol. 348, no. 6237, pp. 906 910, 2015. [25] C. Libedinsky, R. So, Z. Xu, T. K. Kyar, D. Ho, C. Lim, L. Chan, Y. Chua, L. Yao, J. H. Cheong et al., Independent mobility achieved through a wireless brain-machine interface, PLoS One, vol. 11, no. 11, p. e0165773, 2016. [26] A. B. Ajiboye, F. R. Willett, D. R. Young, W. D. Memberg, B. A. Murphy, J. P. Miller, B. L. Walter, J. A. Sweet, H. A. Hoyen, M. W. Keith et al., Restoration of reaching and grasping movements through brain-controlled muscle stimulation in a person with tetraplegia, The Lancet, vol. 389, no. 10081, pp. 1821 1830, 2017. [27] C. Pandarinath, P. Nuyujukian, C. H. Blabe, B. L. Sorice, J. Saab, F. R. Willett, L. R. Hochberg, K. V. Shenoy, and J. M. Henderson, High performance communication by people with paralysis using an intracortical brain-computer interface, elife, vol. 6, p. e18554, 2017. [28] B. Wodlinger, J. Downey, E. Tyler-Kabara, A. Schwartz, M. Boninger, and J. Collinger, Ten-dimensional anthropomorphic arm control in a human brain- machine interface: difficulties, solutions, and limitations, J. Neural Eng., vol. 12, no. 1, p. 016011, 2014.\n\n--- Segment 15 ---\n12, no. 1, p. 016011, 2014. [29] X. Gao, Y. Wang, X. Chen, and S. Gao, Interface, interaction, and intelligence in generalized brain computer interfaces, Trends Cogn. Sci., vol. 25, no. 8, pp. 671 684, 2021. [30] R. A. Andersen, T. Aflalo, L. Bashford, D. Bj anes, and S. Kellis, Ex- ploring cognition with brain machine interfaces, Annu. Rev. Psychol., vol. 73, pp. 131 158, 2022. [31] M. Shaeri and A. M. Sodagar, A framework for on-implant spike sorting based on salient feature selection, Nature Communications, vol. 11, no. 3278, pp. 1 9, June 2020. [32] Y. Chen, B. Tacca, Y. Chen, D. Biswas, G. Gielen, F. Catthoor, M. Ver- helst, and C. M. Lopez, An online-spike-sorting ic using unsupervised geometry-aware osort clustering for efficient embedded neural-signal processing, IEEE J. Solid-State Circuits, 2023. [33] M. Li, H. Xu, X. Liu, and S. Lu, Emotion recognition from multichan- nel eeg signals using k-nearest neighbor classification, Technol. Health Care, vol. 26, no. S1, pp. 509 519, 2018. [34] J. Birjandtalab, M. B. Pouyan, D. Cogan, M. Nourani, and J. Harvey, Automated seizure detection using limited-channel eeg and non-linear dimension reduction, Comput. Biol. Med., vol. 82, pp. 49 58, 2017. [35] A. Sharmila and P. Geethanjali, DWT based detection of epileptic seizure from EEG signals using naive bayes and k-NN classifiers, IEEE Access, vol. 4, pp. 7716 7727, 2016. [36] B. Zhu, M. Farivar, and M. Shoaran, Resot: Resource-efficient oblique trees for neural signal classification, IEEE Trans. Biomed.\n\n--- Segment 16 ---\n[36] B. Zhu, M. Farivar, and M. Shoaran, Resot: Resource-efficient oblique trees for neural signal classification, IEEE Trans. Biomed. Circuits Syst., vol. 14, no. 4, pp. 692 704, 2020. [37] M. Taghavi and M. Shoaran, Hardware complexity analysis of deep neural networks and decision tree ensembles for real-time neural data classification, in Proc. 9th Int. IEEE EMBS Conf. Neural Eng. (NER). IEEE, 2019, pp. 407 410. [38] H. An, S. R. Nason-Tomaszewski, J. Lim, K. Kwon, M. S. Willsey, P. G. Patil, H.-S. Kim, D. Sylvester, C. A. Chestek, and D. Blaauw, A power-efficient brain-machine interface system with a sub-mw feature extraction and decoding asic demonstrated in nonhuman primates, IEEE Trans. Biomed. Circuits Syst., vol. 16, no. 3, pp. 395 408, 2022. [39] P. Zhong, D. Wang, and C. Miao, Eeg-based emotion recognition using regularized graph neural networks, IEEE Trans. on Affective Computing, vol. 13, no. 3, pp. 1290 1301, 2020. [40] W. Jiang, L. Zhao, and B.-l. Lu, Large brain model for learning generic representations with tremendous eeg data in bci, in Proc. of the 12th Int. Conf. on Learn. Represent. (ICLR), 2024. [41] M. Kalbasi, M. Shaeri, V. A. Mendez, S. Shokur, S. Micera, and M. Shoaran, A hardware-efficient EMG decoder with an attractor-based neural network for next-generation hand prostheses, in IEEE 6th Int. Conf. on AI Circuits and Systems (AICAS), 2024, pp. 532 536. [42] B. Zhu, U. Shin, and M. Shoaran, Closed-loop neural prostheses with on-chip intelligence: A review and a low-latency machine learning model for brain state detection, IEEE Trans. Biomed.\n\n--- Segment 17 ---\n[42] B. Zhu, U. Shin, and M. Shoaran, Closed-loop neural prostheses with on-chip intelligence: A review and a low-latency machine learning model for brain state detection, IEEE Trans. Biomed. Circuits Syst., vol. 15, no. 5, pp. 877 897, 2021. [43] S. Razmpour, M. A. Shaeri, H. Hosseini-Nejad, and A. M. Sodagar, Signal processing in implantable neural recording microsystems, in Telemedicine and Electronic Medicine. Boca Raton, FL, USA: CRC Press, 2015, ch. 18, pp. 416 443. [44] X. Guo, M. Shaeri, and M. Shoaran, An accurate and hardware-efficient dual spike detector for implantable neural interfaces, in IEEE Biomed. Circuits Syst. Conf. (BioCAS), 2022, pp. 70 74. [45] D. J. Guggenmos, M. Azin, S. Barbay, J. D. Mahnken, C. Dunham, P. Mohseni, and R. J. Nudo, Restoration of function after brain damage using a neural prosthesis, Proc. Natl. Acad. Sci., vol. 110, no. 52, pp. 21 177 21 182, 2013. [46] M. Shaeri, A. Afzal, and M. Shoaran, Challenges and opportunities of edge ai for next-generation implantable bmis, in IEEE 4th Int. Conf. on AI Circuits and Systems (AICAS), 2022, pp. 190 193. [47] F. Boi, T. Moraitis, V. Feo, F. Diotalevi, C. Bartolozzi, G. Indiveri, and A. Vato, A bidirectional brain-machine interface featuring a neuromor- phic hardware decoder, Front. Neurosci., vol. 10, p. 215903, 2016. [48] Y. Chen, E. Yao, and A. Basu, A 128-channel extreme learning machine-based neural decoder for brain machine interfaces, IEEE Trans. Biomed. Circuits Syst., vol. 10, no. 3, pp. 679 692, 2015.\n\n