{
  "source": "Origin.pdf",
  "raw_length": 37605,
  "cleaned_length": 37175,
  "base_segments": 141,
  "augmented_segments": 282,
  "segments": [
    {
      "text": "Abstract — There is an increasing demand for performing machine learning tasks, such as human activity recognition (HAR) on emerging ultra-low-power internet of things (IoT) platforms. Recent works show substantial efﬁciency boosts from performing inference tasks directly on the IoT nodes rather than merely transmitting raw sensor data. However, the computation and power demands of deep neural network (DNN) based inference pose signiﬁcant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN).",
      "type": "sliding_window",
      "tokens": 115
    },
    {
      "text": "However, the computation and power demands of deep neural network (DNN) based inference pose signiﬁcant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN). Moreover, managing inferences requiring responses from multiple energy- harvesting nodes imposes challenges at the system level in addition to the constraints at each node. This paper presents a novel scheduling policy along with an adaptive ensemble learner to efﬁciently perform HAR on a distributed energy-harvesting body area network.",
      "type": "sliding_window",
      "tokens": 115
    },
    {
      "text": "This paper presents a novel scheduling policy along with an adaptive ensemble learner to efﬁciently perform HAR on a distributed energy-harvesting body area network. Our proposed policy,  Origin , strategically ensures efﬁcient and accurate indi- vidual inference execution at each sensor node by using a novel activity-aware scheduling approach. It also leverages the continu- ous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve ﬁnal classiﬁcation accuracy.",
      "type": "sliding_window",
      "tokens": 107
    },
    {
      "text": "It also leverages the continu- ous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve ﬁnal classiﬁcation accuracy. Further,  Origin  proposes an adaptive ensemble learner to personalize the optimizations based on each individual user. Experimental results using two different HAR data-sets show Origin , while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classiﬁer continuously operating at the same average power.",
      "type": "sliding_window",
      "tokens": 108
    },
    {
      "text": "Experimental results using two different HAR data-sets show Origin , while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classiﬁer continuously operating at the same average power. Index Terms —Energy Harvesting, Human Activity Recognition, DNN, Wireless Senor Network, Ensemble Learning \nI. I NTRODUCTION \nThe advent of data driven computing, along with advances in low-power computing platforms, has given rise to the new generation of intelligent and connected devices that comprise the internet of things (IoT). These devices have become an integral part of our daily lives and, using techniques such as deep learning, these devices are becoming increasingly capable of performing complex inference tasks including ma- chine translation, human activity recognition (HAR), bio-metric authentication, ECG measurement, fall detection etcetera [1], [2].",
      "type": "sliding_window",
      "tokens": 191
    },
    {
      "text": "These devices have become an integral part of our daily lives and, using techniques such as deep learning, these devices are becoming increasingly capable of performing complex inference tasks including ma- chine translation, human activity recognition (HAR), bio-metric authentication, ECG measurement, fall detection etcetera [1], [2]. These inference tasks are typically driven by deep neural networks (DNNs), which are known for being compute heavy and power hungry [3]. Given the power and compute constraints of the IoT devices performing sensing, it is difﬁcult to execute these inference tasks on the sensing device itself, excepting a few intermittent tasks such as bio-metric authentication.",
      "type": "sliding_window",
      "tokens": 143
    },
    {
      "text": "Given the power and compute constraints of the IoT devices performing sensing, it is difﬁcult to execute these inference tasks on the sensing device itself, excepting a few intermittent tasks such as bio-metric authentication. Instead, to perform complex and continuous inference, such as HAR, the data is typically ofﬂoaded either to the cloud or \nto a nearby host device which in turn executes the inference or further redirects it [4] and, ﬁnally, returns the results to the IoT devices responsible for data display or actuation, dependent on the inference task. Recent works [5], [6] suggest that processing data at the source is more efﬁcient that sending them to the cloud and getting the results back, owing to the power and latency overhead of data communication.",
      "type": "sliding_window",
      "tokens": 167
    },
    {
      "text": "Recent works [5], [6] suggest that processing data at the source is more efﬁcient that sending them to the cloud and getting the results back, owing to the power and latency overhead of data communication. They propose optimizations to efﬁciently execute the DNNs on low power IoT devices [7], [8]. Other recent works [9], [5], [7], [8] have proposed using energy harvesting (EH) solutions to provide additional energy and increase the battery life in IoT devices.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "Other recent works [9], [5], [7], [8] have proposed using energy harvesting (EH) solutions to provide additional energy and increase the battery life in IoT devices. These works provide software, hardware and compiler-level solutions, which can be applied to build a battery-less system working entirely on harvested energy. Moreover, in addition to prolonging device lifetime, energy harvesting can help us reduce the environmen- tal impact of batteries [10].",
      "type": "sliding_window",
      "tokens": 102
    },
    {
      "text": "Moreover, in addition to prolonging device lifetime, energy harvesting can help us reduce the environmen- tal impact of batteries [10]. However, energy harvesting is no panacea due to the ﬁckle nature of harvested energy. To tackle this, recent works [9], [6] use a non-volatile processor (NVP) to ensure sufﬁcient forward progress in the face of frequent power emergencies.",
      "type": "sliding_window",
      "tokens": 88
    },
    {
      "text": "To tackle this, recent works [9], [6] use a non-volatile processor (NVP) to ensure sufﬁcient forward progress in the face of frequent power emergencies. The combination of EH, NVPs and other architectural and compiler optimizations have enabled the use of sensors as smart inference engines. However, these node-level optimizations are not entirely sufﬁcient for sensor networks with multiple sensors collectively working together to achieve a goal, which are very common.",
      "type": "sliding_window",
      "tokens": 101
    },
    {
      "text": "However, these node-level optimizations are not entirely sufﬁcient for sensor networks with multiple sensors collectively working together to achieve a goal, which are very common. Although fusing sensor data is not uncommon, it requires one central location where the inference can take place, requiring the communication of sensed data. In networks of energy harvested sensors, the power-hungry nature of commu- nication results in intermittent coordination failures due to one or more of the sensors, or even the fusing node itself, lacking sufﬁcient energy at the time that inter-node communication is required.",
      "type": "sliding_window",
      "tokens": 130
    },
    {
      "text": "In networks of energy harvested sensors, the power-hungry nature of commu- nication results in intermittent coordination failures due to one or more of the sensors, or even the fusing node itself, lacking sufﬁcient energy at the time that inter-node communication is required. This work aims to address this limitation by pursuing answers to the following questions -  1) how do we leverage mul- tiple available energy harvesting wireless sensors collectively, and 2) where should each individual sensor perform its own inference, considering that they collectively perform a single task? Our approach to address these questions relies on decen- tralizing the DNN execution and letting each sensor perform its own inference.",
      "type": "sliding_window",
      "tokens": 156
    },
    {
      "text": "Our approach to address these questions relies on decen- tralizing the DNN execution and letting each sensor perform its own inference. These sensors, each individually working as a weak classiﬁer, can together form an ensemble learning \nenvironment to achieve better accuracy with lower communi- cation overhead. For each sensor to perform inference using the limited and unstable harvested energy poses a scheduling problem, as non-deterministic time is required for the EH sensors to accumulate enough energy to perform the inference.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "For each sensor to perform inference using the limited and unstable harvested energy poses a scheduling problem, as non-deterministic time is required for the EH sensors to accumulate enough energy to perform the inference. This scheduling is made even more difﬁcult as each sensor can harvest and consume different amounts of energy depending upon their location, have different sensor sampling rate, and require different DNNs to be executed. Further, all sensors might not be able to participate in the ensemble due to the ﬁckle nature of harvested energy.",
      "type": "sliding_window",
      "tokens": 107
    },
    {
      "text": "Further, all sensors might not be able to participate in the ensemble due to the ﬁckle nature of harvested energy. This demands the aggregation process for the ensemble to be robust, yet light weight in order to perform accurate classiﬁcation with minimum overhead. Therefore, this work proposes an intelligent scheduler along with efﬁcient ensemble learning to enable DNN inference in a distributed energy harvesting wireless sensor network (EH- WSN).",
      "type": "sliding_window",
      "tokens": 91
    },
    {
      "text": "Therefore, this work proposes an intelligent scheduler along with efﬁcient ensemble learning to enable DNN inference in a distributed energy harvesting wireless sensor network (EH- WSN). This work proposes a novel policy,  Origin , which enables energy harvesting wireless sensors to perform efﬁcient and accurate DNN inference. Speciﬁcally, Origin targets inherent features of sensor data from distributed body area networks in human activity recognition (HAR) tasks and leverages non- volatile processing, intelligent scheduling for energy-harvesting sensor nodes, and ensemble leaning to classify human activity with minimum accuracy loss compared to a state-of-the-art battery powered system.",
      "type": "sliding_window",
      "tokens": 142
    },
    {
      "text": "Speciﬁcally, Origin targets inherent features of sensor data from distributed body area networks in human activity recognition (HAR) tasks and leverages non- volatile processing, intelligent scheduling for energy-harvesting sensor nodes, and ensemble leaning to classify human activity with minimum accuracy loss compared to a state-of-the-art battery powered system. To the best of our knowledge, this is the ﬁrst work that tries to enable DNN inference for human activity recognition in a distributed energy harvesting wireless sensor network by leveraging ensemble learning. The paper makes the following key contributions: 1) We design a scheduling policy that chooses the salient sensor for performing the inference depending on the an- ticipated activity, i.e.",
      "type": "sliding_window",
      "tokens": 159
    },
    {
      "text": "The paper makes the following key contributions: 1) We design a scheduling policy that chooses the salient sensor for performing the inference depending on the an- ticipated activity, i.e. the scheduler is  activity aware . 2) We leverage temporal continuity of human activity, and persist the last successful classiﬁcation result of a sensor.",
      "type": "sliding_window",
      "tokens": 75
    },
    {
      "text": "2) We leverage temporal continuity of human activity, and persist the last successful classiﬁcation result of a sensor. We use aggressive recall which reduces the number of total inferences performed and mitigates the requirement that all of the sensors be involved in the ensemble process during each inference. 3) Our proposed policy,  Origin , combines an adaptive conﬁ- dence matrix and the activity aware scheduler to perform efﬁcient and accurate classiﬁcation.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "3) Our proposed policy,  Origin , combines an adaptive conﬁ- dence matrix and the activity aware scheduler to perform efﬁcient and accurate classiﬁcation. The adaptive conﬁdence matrix, which weights the output of each sensor depending upon the classiﬁcation result, is updated on each successful classiﬁcation. 4) Finally, we provide a detailed evaluation of  Origin , and show that, even when powered by an unreliable EH source, the efﬁciency achieved by the this system results in better accuracy than that of a fully powered system running state of the art classiﬁers optimized for energy efﬁciency.",
      "type": "sliding_window",
      "tokens": 120
    },
    {
      "text": "4) Finally, we provide a detailed evaluation of  Origin , and show that, even when powered by an unreliable EH source, the efﬁciency achieved by the this system results in better accuracy than that of a fully powered system running state of the art classiﬁers optimized for energy efﬁciency. Origin reaches 83.88% top-1 accuracy compared to the 81.16% accuracy of the baseline system. II.",
      "type": "sliding_window",
      "tokens": 87
    },
    {
      "text": "II. M OTIVATION \nA major challenge while executing a DNN inference on an energy harvesting sensor is the power budget. The conventional \nmethod, where the sensors collect the data and send it to the cloud or any other host device (such as connected mobile phones) is not an effective option as communicating large data demands more power, which is both highly variable and scarce in EH systems.",
      "type": "sliding_window",
      "tokens": 84
    },
    {
      "text": "The conventional \nmethod, where the sensors collect the data and send it to the cloud or any other host device (such as connected mobile phones) is not an effective option as communicating large data demands more power, which is both highly variable and scarce in EH systems. Therefore, the better option, from a communication cost perspective, is to execute the inferences on the individual sensors and use an ensemble learning method (like majority voting) to aggregate these results for the ﬁnal classiﬁcation. 1% \n0 20 40 60 80 100 All Succeed Atleast one succeed Failed \n9% 90% \n(a)  Inference completion breakdown when three EH sensors are working together to ﬁnish the incoming inferences.",
      "type": "sliding_window",
      "tokens": 145
    },
    {
      "text": "1% \n0 20 40 60 80 100 All Succeed Atleast one succeed Failed \n9% 90% \n(a)  Inference completion breakdown when three EH sensors are working together to ﬁnish the incoming inferences. In only 1% of the cases all of the sensors ﬁnished inference, while 9% of the time at least one of them ﬁnished. 90% of the time the inference could not start because of lack of energy.",
      "type": "sliding_window",
      "tokens": 92
    },
    {
      "text": "90% of the time the inference could not start because of lack of energy. 0 20 40 60 80 100 Succeed Failed \n72% 28% \n(b)  Inference completion breakdown when three EH sensors are working in round robin fashion, where one of the sensors performs inference while the other two are accumulating energy. 28% of the time the sensors could ﬁnish the inference, while 72% of the time the inference failed as the sensor could not harvest enough energy while not performing any inference.",
      "type": "sliding_window",
      "tokens": 111
    },
    {
      "text": "28% of the time the sensors could ﬁnish the inference, while 72% of the time the inference failed as the sensor could not harvest enough energy while not performing any inference. Fig. 1:  Fraction of inference completed on harvested energy using na¨ıve scheduling.",
      "type": "sliding_window",
      "tokens": 62
    },
    {
      "text": "1:  Fraction of inference completed on harvested energy using na¨ıve scheduling. Each of the sensors in a multi-device HAR deployment receives different data depending on its location and the current human activity in progress. Therefore, different DNNs are needed to process data from these different locations.",
      "type": "sliding_window",
      "tokens": 67
    },
    {
      "text": "Therefore, different DNNs are needed to process data from these different locations. Consequently, the power requirement and the latency of these DNNs may vary and synchronizing them for collective execution would require scheduling that addresses these differences in resource requirements. Even if we were able to design a proper scheduling policy, for a conventional ensemble, all the sensors involved need to ﬁnish their computation.",
      "type": "sliding_window",
      "tokens": 84
    },
    {
      "text": "Even if we were able to design a proper scheduling policy, for a conventional ensemble, all the sensors involved need to ﬁnish their computation. However, our preliminary results using the hardware setup of [6] and the DNN from [11] on the MHEALTH [12], [13] dataset suggests that only 10% of inferences could be completed in a WiFi powered system (Fig.1a). Therefore, we cannot always expect inference outcomes from all the sensors while doing HAR on EH-WSN.",
      "type": "sliding_window",
      "tokens": 113
    },
    {
      "text": "Therefore, we cannot always expect inference outcomes from all the sensors while doing HAR on EH-WSN. Clearly, the completion of the task is power bound: Adopting a wait-compute execution model, such that we have enough energy to complete some results, at a lower duty cycle, instead of always trying and failing would yield beneﬁts. This leaves us with the following important questions: •  Are continuous inferences essential, or can we leverage the workload itself to skip some inferences without substantial accuracy loss, allowing enough energy to be accumulated for future inferences?",
      "type": "sliding_window",
      "tokens": 126
    },
    {
      "text": "This leaves us with the following important questions: •  Are continuous inferences essential, or can we leverage the workload itself to skip some inferences without substantial accuracy loss, allowing enough energy to be accumulated for future inferences? •  Since all the sensors cannot be activated together due to the limited power, how do we effectively perform the ensemble? III.",
      "type": "sliding_window",
      "tokens": 76
    },
    {
      "text": "III. Origin : A N INTELLIGENT SCHEDULER MEETS A LIGHT WEIGHT AND ADAPTIVE ENSEMBLE LEARNER \nWe design a EH-WSN setup for HAR, where the user has three EH inertial measurement units (IMUs), at the \nchest, left ankle and right wrist 1 . It is obvious that the raw data sensed by each sensor would be different, even for the same activity, because of the difference in move- ment and dynamics.",
      "type": "sliding_window",
      "tokens": 114
    },
    {
      "text": "It is obvious that the raw data sensed by each sensor would be different, even for the same activity, because of the difference in move- ment and dynamics. For example, while cycling, the data sensed by the ankle, chest and wrist sensors would be en- tirely different because of the nature of the motion. Thus, the DNN architectures to infer these data are also different.",
      "type": "sliding_window",
      "tokens": 85
    },
    {
      "text": "Thus, the DNN architectures to infer these data are also different. 0 \n50 \n100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nChest Left Ankle Right Wrist Majority Voting \nFig. 2:  Accuracy of the individual DNNs and with a majority voting ensemble for different activities.",
      "type": "sliding_window",
      "tokens": 75
    },
    {
      "text": "2:  Accuracy of the individual DNNs and with a majority voting ensemble for different activities. To design these DNNs, we leverage the work in [11], [14] and further apply state of the art optimizations given in [3], [15] to make the DNN more suitable for energy-scarce applications. Fig.",
      "type": "sliding_window",
      "tokens": 76
    },
    {
      "text": "Fig. 2 gives the accuracy of these DNNs on MHEALTH dataset [12], [13]. A detailed description of the setup is explained in Section IV.",
      "type": "sliding_window",
      "tokens": 37
    },
    {
      "text": "A detailed description of the setup is explained in Section IV. In this section, we provide an overview of our proposed solution. A. Preamble to Origin \nHuman activity has temporal continuity, i.e.",
      "type": "sliding_window",
      "tokens": 45
    },
    {
      "text": "A. Preamble to Origin \nHuman activity has temporal continuity, i.e. most activ- ities last for some duration (in the range of hundreds of milliseconds to seconds). Therefore, there is an opportunity to skip some intermediate inferences over the period of an activity in order to increase harvesting duration and the prob- ability that an initiated inference will complete.",
      "type": "sliding_window",
      "tokens": 82
    },
    {
      "text": "Therefore, there is an opportunity to skip some intermediate inferences over the period of an activity in order to increase harvesting duration and the prob- ability that an initiated inference will complete. So long as the number of skipped inferences is modest, there will still likely be samples processed before an activity ﬁnishes. This can be extended further adopting a round-robin activation schedule to both increase harvesting periods per initiated in- ference on each node while increasing the odds that at least some node is attempting an inference at any given time.",
      "type": "sliding_window",
      "tokens": 119
    },
    {
      "text": "This can be extended further adopting a round-robin activation schedule to both increase harvesting periods per initiated in- ference on each node while increasing the odds that at least some node is attempting an inference at any given time. Chest \nNo  Op \nRight  Wrist \nNo  Op \nLeft  Ankle \nNo  Op \nChest \nNo  Op \nNo  Op \nRight  Wrist \nNo  Op No  Op \nLeft  Ankle \nNo  Op \nNo  Op \nChest \nNo  Op \nNo  Op \nNo  Op \nRight  Wrist \nNo  Op No  Op \nNo  Op \nLeft  Ankle \nNo  Op \nNo  Op \nNo  Op Chest \nRight  Wrist Left  Ankle \nRR3 \nRR6 RR9 \nRR12 \nFig. 3:  Different ﬂavors of (extended) round-robin scheduling and their execution ﬂow.",
      "type": "sliding_window",
      "tokens": 160
    },
    {
      "text": "3:  Different ﬂavors of (extended) round-robin scheduling and their execution ﬂow. Each policy is named after the num- ber of nodes the cycle has, i.e. RR3 has 3 nodes with no no-ops and RR6 has 3 nodes with 3 no-ops.",
      "type": "sliding_window",
      "tokens": 69
    },
    {
      "text": "RR3 has 3 nodes with no no-ops and RR6 has 3 nodes with 3 no-ops. Even using a round robin execution, we observe that only 28% of the inferences are completed (shown in Fig. 1b).",
      "type": "sliding_window",
      "tokens": 60
    },
    {
      "text": "1b). Therefore, we induce a delay (no-op cycles in Fig. 3) between one sensor ﬁnishing an inference and the next sensor starting the next one, so that each of the sensors get more time to accumulate more energy prior to attempting an inference.",
      "type": "sliding_window",
      "tokens": 61
    },
    {
      "text": "3) between one sensor ﬁnishing an inference and the next sensor starting the next one, so that each of the sensors get more time to accumulate more energy prior to attempting an inference. We refer to this policy that stretches the basic round-robin policy as extended round-robin (ER-r). Using ER-r, we can complete more total inferences, \n1 This can also be extended to larger numbers of sensors and modalities \nbut this design is limited by the accuracy of individual sensors.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "Using ER-r, we can complete more total inferences, \n1 This can also be extended to larger numbers of sensors and modalities \nbut this design is limited by the accuracy of individual sensors. Moreover, since all sensors are not equally capable of classifying each activity with same accuracy (Fig. 2), ER-r might lead to lower accuracy in many cases.",
      "type": "sliding_window",
      "tokens": 80
    },
    {
      "text": "2), ER-r might lead to lower accuracy in many cases. A better approach is to prioritize performing inferences on the sensor that has the highest local accuracy for the current activity. However, this poses a chicken and egg problem – to know which sensor is the best for classifying an activity we need to know what activity is going to be performed beforehand.",
      "type": "sliding_window",
      "tokens": 77
    },
    {
      "text": "However, this poses a chicken and egg problem – to know which sensor is the best for classifying an activity we need to know what activity is going to be performed beforehand. However, while perfect future knowledge remains impossible, in the context of HAR, we can anticipate the next activity from the previous activity with high conﬁdence. Intuitively, human activities do not usually stop abruptly, i.e.",
      "type": "sliding_window",
      "tokens": 88
    },
    {
      "text": "Intuitively, human activities do not usually stop abruptly, i.e. if a person is walking and has taken a step, there is a high probability that the person will continue walking rather than immediately switch to another activity. Therefore, to classify the next possible activity, we activate the sensor which is most accurate for classifying the anticipated activity.",
      "type": "sliding_window",
      "tokens": 80
    },
    {
      "text": "Therefore, to classify the next possible activity, we activate the sensor which is most accurate for classifying the anticipated activity. This motivates us to develop an  activity-aware scheduling  (AAS) policy which aims to activate the best suited sensor for the anticipated activity. B.",
      "type": "sliding_window",
      "tokens": 60
    },
    {
      "text": "B. Activity Aware Scheduling \nTo enable the activity awareness we keep a small lookup table of accuracy of all the sensors over all the classes. However, accuracy being a ﬂoating point number, is expensive in terms of energy to store and lookup.",
      "type": "sliding_window",
      "tokens": 55
    },
    {
      "text": "However, accuracy being a ﬂoating point number, is expensive in terms of energy to store and lookup. To minimize this overhead, instead of storing the accuracy, we store the rank of the sensors for individual activities. After a sensor detects an activity, it anticipates the next activity to be the current classiﬁed activity, looks up for the best sensor, and signals to activate it for the upcoming inference.",
      "type": "sliding_window",
      "tokens": 87
    },
    {
      "text": "After a sensor detects an activity, it anticipates the next activity to be the current classiﬁed activity, looks up for the best sensor, and signals to activate it for the upcoming inference. However, this leads to another potential issue - what if the current inference is running on the best sensor, and the sensor does not have enough energy to run the next inference? In this case, the current sensor chooses the next best sensor for the job and signals it.",
      "type": "sliding_window",
      "tokens": 101
    },
    {
      "text": "In this case, the current sensor chooses the next best sensor for the job and signals it. The other sensor receives this as an external signal and activates itself to classify the activity. To incorporate the ER-r, we induce delays between sending the external signal and starting the inference on the same sensor.",
      "type": "sliding_window",
      "tokens": 67
    },
    {
      "text": "To incorporate the ER-r, we induce delays between sending the external signal and starting the inference on the same sensor. This delay depends of the extended round- robin policy. Combination of ER-r and AAS, results in more than 70% accuracy for most of the activities (Fig.",
      "type": "sliding_window",
      "tokens": 65
    },
    {
      "text": "Combination of ER-r and AAS, results in more than 70% accuracy for most of the activities (Fig. 4). 0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 RR3 with AAS RR6 RR6 with AAS RR9 RR9 with AAS RR12 RR12 with AAS Fig.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 RR3 with AAS RR6 RR6 with AAS RR9 RR9 with AAS RR12 RR12 with AAS Fig. 4:  Accuracy results for AAS combined with ER-r. Even though AAS provides signiﬁcantly better results com- pared to standard round-robin, it is still unable to incorporate ensemble learning.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "Even though AAS provides signiﬁcantly better results com- pared to standard round-robin, it is still unable to incorporate ensemble learning. The major challenge is the inability to run inferences in all the sensors simultaneously because of the harvested energy budget. Therefore, we need to ﬁnd the classiﬁcation result for all the sensors without activating them.",
      "type": "sliding_window",
      "tokens": 73
    },
    {
      "text": "Therefore, we need to ﬁnd the classiﬁcation result for all the sensors without activating them. Extending our assumption from AAS, we hypothesize that the most recent classiﬁcation result of a sensor must be a good \nrepresentation of what its inference would be for the current activity. Hence, by memorizing or  recalling  the most recent classiﬁcation result, we can get the inference result of a sensor even without activating it.",
      "type": "sliding_window",
      "tokens": 92
    },
    {
      "text": "Hence, by memorizing or  recalling  the most recent classiﬁcation result, we can get the inference result of a sensor even without activating it. Even though the sensors are running in the round-robin fashion, the non-participating sensors can still impact the classiﬁcation result by virtue of  recalling their most recent classiﬁcation. Combining the  Recall  with AAS (which we term as AASR - Activity Aware Scheduling with Recall) opens possibilities for getting a more accurate classiﬁcation.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "Combining the  Recall  with AAS (which we term as AASR - Activity Aware Scheduling with Recall) opens possibilities for getting a more accurate classiﬁcation. To minimize the communication overhead, and to ensure participation of all sensors, we build the  recall  strategy into the host device. The host device remembers the most recent classiﬁcations by all of the sensors.",
      "type": "sliding_window",
      "tokens": 79
    },
    {
      "text": "The host device remembers the most recent classiﬁcations by all of the sensors. After receiving or recalling prediction from all sensors, the host performs a majority voting for the ﬁnal classiﬁcation. AASR thus bridges the major gaps in the design that we intend to achieve.",
      "type": "sliding_window",
      "tokens": 58
    },
    {
      "text": "AASR thus bridges the major gaps in the design that we intend to achieve. With the addition of  recall , we have a fully functional ensemble learning system on a EH-WSN. AASR intelligently takes advantage of multiple DNNs (by bringing in activity aware scheduling), leverages the workload (by considering the activity continuity via recall and extended round-robin strategies), and also poses minimal overhead on the host device for running aggregation.",
      "type": "sliding_window",
      "tokens": 101
    },
    {
      "text": "AASR intelligently takes advantage of multiple DNNs (by bringing in activity aware scheduling), leverages the workload (by considering the activity continuity via recall and extended round-robin strategies), and also poses minimal overhead on the host device for running aggregation. However, as we did not want to burden the host device with complex computation, the aggregation task is very na¨ıve in that it just performs recall and incorporates no intelligence. Hence, there is an opportunity to also improve the ensemble technique.",
      "type": "sliding_window",
      "tokens": 115
    },
    {
      "text": "Hence, there is an opportunity to also improve the ensemble technique. C. Designing an Adaptive Ensemble Learner AASR scheduling solves most of the issues on the sensor side without burdening host device, yet the host device still per- forms a na¨ıve majority voting-based ensemble. Designing any sophisticated ensemble learning technique will either consume more resources of the host device, or need more information and computation at the edge, thus making our effort of ﬁnishing the inference at the edge not viable.",
      "type": "sliding_window",
      "tokens": 110
    },
    {
      "text": "Designing any sophisticated ensemble learning technique will either consume more resources of the host device, or need more information and computation at the edge, thus making our effort of ﬁnishing the inference at the edge not viable. However, if we can design a simple, light weight and adaptive ensemble technique, then our design will be holistic from both the sensor and the host side. The current scheduler is activity aware, i.e.",
      "type": "sliding_window",
      "tokens": 89
    },
    {
      "text": "The current scheduler is activity aware, i.e. while performing an inference it always tries to choose the best available sensor to perform the task at hand. Furthermore, the AASR poses negligible overhead both in terms of compute and memory.",
      "type": "sliding_window",
      "tokens": 55
    },
    {
      "text": "Furthermore, the AASR poses negligible overhead both in terms of compute and memory. Our goal is to develop an activity aware ensemble technique which can further improve accuracy, when compared to AASR. The idea of making the ensemble task activity aware has similarities to weighted majority voting, where we assign weights to the individual learners participating in the ensemble, such that a higher accuracy classiﬁer contributes more weight towards the ﬁnal result.",
      "type": "sliding_window",
      "tokens": 93
    },
    {
      "text": "The idea of making the ensemble task activity aware has similarities to weighted majority voting, where we assign weights to the individual learners participating in the ensemble, such that a higher accuracy classiﬁer contributes more weight towards the ﬁnal result. However, from Fig. 2 it is clear that not all the sensors are equally good at classifying various ac- tivities; in fact, this builds the foundation of AASR.",
      "type": "sliding_window",
      "tokens": 92
    },
    {
      "text": "2 it is clear that not all the sensors are equally good at classifying various ac- tivities; in fact, this builds the foundation of AASR. Therefore, assigning a static weight to the output of each classiﬁer will not reﬂect that its accuracy is activity-dependent. For example, the classiﬁer used in the left ankle sensor tends to be more accurate overall, but for classifying climbing action, it is not better than the chest sensor.",
      "type": "sliding_window",
      "tokens": 99
    },
    {
      "text": "For example, the classiﬁer used in the left ankle sensor tends to be more accurate overall, but for classifying climbing action, it is not better than the chest sensor. Hence, to give the left ankle more weight while doing an ensemble for a climbing task makes \nthe classiﬁer biased. Furthermore, it the relative weight of each sensor is likely to shift from user to user.",
      "type": "sliding_window",
      "tokens": 80
    },
    {
      "text": "Furthermore, it the relative weight of each sensor is likely to shift from user to user. A simple solution is to assign the accuracy of each of the sensors for every class as its weight. Although accuracy is a close measurement of the conﬁdence of the classiﬁcation, it does not truly reﬂect it.",
      "type": "sliding_window",
      "tokens": 60
    },
    {
      "text": "Although accuracy is a close measurement of the conﬁdence of the classiﬁcation, it does not truly reﬂect it. For example, let us consider two DNN classiﬁers ( C 1  and C 2 ) classifying between 4 different classes  ( o 1 , o 2 , o 3 , o 4 ) . The ﬁnal probability vector from the last layer (soft- max function)  V C 1 = [0 .",
      "type": "sliding_window",
      "tokens": 93
    },
    {
      "text": "The ﬁnal probability vector from the last layer (soft- max function)  V C 1 = [0 . 94 ,  0 . 01 ,  0 .",
      "type": "sliding_window",
      "tokens": 38
    },
    {
      "text": "07] . Both the models have classiﬁed the input to be of class  o 1 . The accuracy of both system might be identical (over a large number of test sets), yet for the current test case, both the models are not equally conﬁdent about the classiﬁcation.",
      "type": "sliding_window",
      "tokens": 57
    },
    {
      "text": "The accuracy of both system might be identical (over a large number of test sets), yet for the current test case, both the models are not equally conﬁdent about the classiﬁcation. The question is, how do we measure the conﬁdence of the given classiﬁcation? It is obvious that the most conﬁdent classiﬁcation for the same class would be [1 ,  0 ,  0 ,  0] , where the model is 100% conﬁdent on class  o 1  and the most confused prediction would be  [0 .",
      "type": "sliding_window",
      "tokens": 105
    },
    {
      "text": "It is obvious that the most conﬁdent classiﬁcation for the same class would be [1 ,  0 ,  0 ,  0] , where the model is 100% conﬁdent on class  o 1  and the most confused prediction would be  [0 . 25 ,  0 . 25 ,  0 .",
      "type": "sliding_window",
      "tokens": 68
    },
    {
      "text": "25 ,  0 . 25 ,  0 . 25] , where the classiﬁer is equally confused between all the classes.",
      "type": "sliding_window",
      "tokens": 31
    },
    {
      "text": "25] , where the classiﬁer is equally confused between all the classes. Therefore, a good metric for the conﬁdence would be the vari- ance of the output probability vector. The higher the variance the more conﬁdent is the classiﬁcation.",
      "type": "sliding_window",
      "tokens": 51
    },
    {
      "text": "The higher the variance the more conﬁdent is the classiﬁcation. Towards this, we build a lookup table by averaging the variance of output vectors of multiple test cases. This table, which we call the  conﬁdence matrix , gives us the conﬁdence of each sensor for each class, and can be used as a weight for majority voting.",
      "type": "sliding_window",
      "tokens": 73
    },
    {
      "text": "This table, which we call the  conﬁdence matrix , gives us the conﬁdence of each sensor for each class, and can be used as a weight for majority voting. The next challenge is to adapt the conﬁdence matrix for individual users. Each user has unique expressions of behaviour classes reﬂected in the sensor data.",
      "type": "sliding_window",
      "tokens": 64
    },
    {
      "text": "Each user has unique expressions of behaviour classes reﬂected in the sensor data. For example, gaits of two different people may signiﬁcantly vary, and might be entirely different from the training data. Thus, it is important to keep learning and adapting to the user behavior.",
      "type": "sliding_window",
      "tokens": 56
    },
    {
      "text": "Thus, it is important to keep learning and adapting to the user behavior. Since, we cannot keep re-training the DNNs because of their resource constraints, we choose to periodically update the conﬁdence matrix. The initial conﬁdence matrix, derived from the test cases, would be programmed into the host device.",
      "type": "sliding_window",
      "tokens": 66
    },
    {
      "text": "The initial conﬁdence matrix, derived from the test cases, would be programmed into the host device. Further, after each successful classiﬁcation, the sensors would send the conﬁdence score for that classiﬁer along with the output class. This conﬁdence score would further update the weight matrix of the host device using a moving average method and keep updating it as the user keeps using the device.",
      "type": "sliding_window",
      "tokens": 77
    },
    {
      "text": "This conﬁdence score would further update the weight matrix of the host device using a moving average method and keep updating it as the user keeps using the device. D. Origin: AASR meets Conﬁdence Matrix Combined together, the activity aware scheduler with recall (AASR) and the adaptive conﬁdence matrix we present  Origin : a holistic system where an intelligent scheduler meets an adap- tive ensemble learner. This design optimizes the DNN execution in an energy harvesting wireless sensor network by collectively looking into all the involved components.",
      "type": "sliding_window",
      "tokens": 120
    },
    {
      "text": "This design optimizes the DNN execution in an energy harvesting wireless sensor network by collectively looking into all the involved components. The DNNs as indi- viduals are optimized before to meet the power budget. In the earlier case of na¨ıve scheduling we tried to build an efﬁcient DNN by applying energy aware pruning [15].",
      "type": "sliding_window",
      "tokens": 76
    },
    {
      "text": "In the earlier case of na¨ıve scheduling we tried to build an efﬁcient DNN by applying energy aware pruning [15]. However, since Origin  follows an activity aware scheduling with extended round-robin, it can relax the power constraint pruning if needed. Instead of restricting the power constraint to the average power of the entire power trace, the constraint can be relaxed to the average power requirement of the extended round-robin \n0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 AAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baseline-2 Baseline 1 \n(a)  Accuracy with MHEALTH dataset.",
      "type": "sliding_window",
      "tokens": 190
    },
    {
      "text": "Instead of restricting the power constraint to the average power of the entire power trace, the constraint can be relaxed to the average power requirement of the extended round-robin \n0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 AAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baseline-2 Baseline 1 \n(a)  Accuracy with MHEALTH dataset. 0 20 40 60 80 100 \nWalking Climbing Cycling Running Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 CAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baselin-2 Baseline-1 \n(b)  Accuracy with PAMAP2 dataset. Fig.",
      "type": "sliding_window",
      "tokens": 231
    },
    {
      "text": "Fig. 5:  Accuracy results of the different policies described in Sec- tion III. RR indicates the extended round-robin policy in use, e.g.",
      "type": "sliding_window",
      "tokens": 40
    },
    {
      "text": "RR indicates the extended round-robin policy in use, e.g. RR6 AAS represents AAS with RR6. policy in use.",
      "type": "sliding_window",
      "tokens": 36
    },
    {
      "text": "policy in use. Further, the scheduling strategy was modiﬁed using activity aware scheduling with extended round-robin such that all the sensors get enough time to harvest and also the best possible sensor works on the classiﬁcation task at hand instead of any arbitrary sensor. The added recall functionality enables ensemble learning.",
      "type": "sliding_window",
      "tokens": 61
    },
    {
      "text": "The added recall functionality enables ensemble learning. Moreover, the host device, which performs the ensemble, is equipped with a conﬁdence matrix, which adapts to the user and performs weighted majority voting instead of a na¨ıve majority voting. The associated conﬁdence matrix boosts the classiﬁcation accuracy and also resolves ties while voting.",
      "type": "sliding_window",
      "tokens": 76
    },
    {
      "text": "The associated conﬁdence matrix boosts the classiﬁcation accuracy and also resolves ties while voting. IV. E VALUATION \nIn this section we explain the strategy for evaluating  Origin .",
      "type": "sliding_window",
      "tokens": 38
    },
    {
      "text": "E VALUATION \nIn this section we explain the strategy for evaluating  Origin . We discuss about the hardware and software framework, and the accuracy of  Origin  compared to two different baselines. A.",
      "type": "sliding_window",
      "tokens": 42
    },
    {
      "text": "A. Energy Harvester and Sensor Setup \nOur evaluation setup consists of three sensors at three dif- ferent locations. First sensor at the chest, second on the right wrist and last sensor on the left ankle.",
      "type": "sliding_window",
      "tokens": 48
    },
    {
      "text": "First sensor at the chest, second on the right wrist and last sensor on the left ankle. Each sensor consists of four major components, namely, the sensing component, an IMU, which collects acceleration and attitude data, an energy harvester which harvest the surrounding RF (WiFi) energy, a compute component same as [6] and a wireless communication module (BLE or WiFi) to connect to a host device (battery backed mobile phone). We assume the communication cost to be negligible since it infrequently sends a few bytes of data to the host.",
      "type": "sliding_window",
      "tokens": 131
    },
    {
      "text": "We assume the communication cost to be negligible since it infrequently sends a few bytes of data to the host. To replicate the energy harvesting, we use a real power trace harvested from a WiFi source while doing various day to day tasks in an ofﬁce environment [6]. The speciﬁcs of the energy-harvesting mechanism producing the power trace are beyond the scope of this work.",
      "type": "sliding_window",
      "tokens": 86
    },
    {
      "text": "The speciﬁcs of the energy-harvesting mechanism producing the power trace are beyond the scope of this work. B. DNN Classiﬁer and the Dataset \nOur DNN design choices are inspired from the works in [11], [14]. However, instead of designing a centralized DNN which processes the combined data from all the sensors, we design three different smaller DNNs that work on their individual data.",
      "type": "sliding_window",
      "tokens": 87
    },
    {
      "text": "However, instead of designing a centralized DNN which processes the combined data from all the sensors, we design three different smaller DNNs that work on their individual data. Further, to build an energy efﬁcient version of the DNNs, we applied the energy-aware DNN optimizations proposed in [3], [15]. We use two different datasets, MHEALTH [12], [13], and PAMAP2 [16], [17], for our evaluation which follow the similar sensor setup described in Section IV-A.",
      "type": "sliding_window",
      "tokens": 113
    },
    {
      "text": "We use two different datasets, MHEALTH [12], [13], and PAMAP2 [16], [17], for our evaluation which follow the similar sensor setup described in Section IV-A. The DNNs were trained on the training data-sets using the Keras [18] framework. C. Accuracy Results \nBaseline:  We choose two baselines for our evaluation: 1) Baseline-1 consists of the original DNNs built along the lines of [11], [14] (without any pruning).",
      "type": "sliding_window",
      "tokens": 113
    },
    {
      "text": "C. Accuracy Results \nBaseline:  We choose two baselines for our evaluation: 1) Baseline-1 consists of the original DNNs built along the lines of [11], [14] (without any pruning). 2) Baseline-2 uses state of the art pruning techniques described in [3], [15] to prune the DNNs of Baseline-1 to ﬁt the average harvested power budget from our harvesting trace described in Section IV-A. Both the baseline setups run on a fully powered system equipped with a steady power source.",
      "type": "sliding_window",
      "tokens": 115
    },
    {
      "text": "Both the baseline setups run on a fully powered system equipped with a steady power source. A majority voting en- semble method is used in both of these baselines to mimic ensemble learning. Origin  uses the DNNs of Baseline-2 for the classiﬁcation tasks.",
      "type": "sliding_window",
      "tokens": 57
    },
    {
      "text": "Origin  uses the DNNs of Baseline-2 for the classiﬁcation tasks. We plot the accuracy of different strategies described throughout the paper. Fig.",
      "type": "sliding_window",
      "tokens": 31
    },
    {
      "text": "Fig. 5a shows the accuracy results on the MHEALTH dataset, and Fig. 5b shows the results for the PAMAP2 dataset.",
      "type": "sliding_window",
      "tokens": 34
    },
    {
      "text": "5b shows the results for the PAMAP2 dataset. Following are our observations: •  The overall accuracy tends to improve with increasing round-robin delay time. This behaviour is expected and can be attributed to the increasing number of completed inferences.",
      "type": "sliding_window",
      "tokens": 54
    },
    {
      "text": "This behaviour is expected and can be attributed to the increasing number of completed inferences. The nature of the workload itself gives us an opportunity to not perform inference at a rapid rate. Further evaluations suggest Origin  with RR-12 to be the best ﬁt for HAR.",
      "type": "sliding_window",
      "tokens": 59
    },
    {
      "text": "Further evaluations suggest Origin  with RR-12 to be the best ﬁt for HAR. Going beyond RR-12 might lead to missing an activity window for high intensity or rapid activities, and going below RR-12 might lead to energy scarcity at times. In case of abundant energy supply, one can use a round robin policy ﬁt for the given EH source.",
      "type": "sliding_window",
      "tokens": 78
    },
    {
      "text": "In case of abundant energy supply, one can use a round robin policy ﬁt for the given EH source. •  Table I shows the accuracy comparison between the RR12- Origin  with both the baselines. We observe that, for the MHEALTH dataset, RR12- Origin  is 2.72% more accu- rate than the Baseline-2.",
      "type": "sliding_window",
      "tokens": 79
    },
    {
      "text": "We observe that, for the MHEALTH dataset, RR12- Origin  is 2.72% more accu- rate than the Baseline-2. For the PAMAP2 data-set, RR12- Origin  is 2.53% better than Baseline-2. For certain cases like climbing in PAMAP2, and running in MHEALTH,  Origin  is more accurate than Baseline-1.",
      "type": "sliding_window",
      "tokens": 83
    },
    {
      "text": "For certain cases like climbing in PAMAP2, and running in MHEALTH,  Origin  is more accurate than Baseline-1. These accuracy improvements can be attributed to  Origin’s  use of a conﬁdence matrix in classiﬁcation, as opposed to the baseline models, which only perform majority voting based ensembling. Note that both the baselines are running on a fully powered system whereas  Origin runs entirely on harvested energy.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "Note that both the baselines are running on a fully powered system whereas  Origin runs entirely on harvested energy. In practice, we can extend Origin  further to other multi-sensor data-sets for HAR. Discussion:  Although  Origin  is proposed and works for energy harvesting wireless sensor networks, it can also be used with battery-powered or hybrid (a combination to battery powered and EH) systems to minimize the energy footprint while maximizing the accuracy.",
      "type": "sliding_window",
      "tokens": 94
    },
    {
      "text": "Discussion:  Although  Origin  is proposed and works for energy harvesting wireless sensor networks, it can also be used with battery-powered or hybrid (a combination to battery powered and EH) systems to minimize the energy footprint while maximizing the accuracy. Furthermore, it uses multiple sensors effectively and hence poses minimum risk if one of the sensors fails. This makes  Origin  versatile and suitable for systems whose intermittence comes from either or both of power or device reliability limitations, both of which will be key factors in real-world IoT deployments.",
      "type": "sliding_window",
      "tokens": 112
    },
    {
      "text": "This makes  Origin  versatile and suitable for systems whose intermittence comes from either or both of power or device reliability limitations, both of which will be key factors in real-world IoT deployments. Moreover, ensemble learning \nActivity Policy Comparision RR12 Origin BL-2 BL-1 vs BL-2 vs BL-1 Walking 81.60896 84.46 91.56 -2.85104 -9.95104 Climbing 83.10679 77.93 83.24 5.176789 -0.13321 Cycling 85.88992 85.81 94.27 0.079918 -8.38008 Running 87.13474 81.29 86.91 5.844736 0.224736 Jogging 81.81809 78.04 83.17 3.778086 -1.35191 Jumping 83.69378 79.42 84.26 4.273776 -0.56622 \nTABLE I:  Comparing RR12 Origin with both the baselines on MHELATH dataset. BL indicates the baseline models.",
      "type": "sliding_window",
      "tokens": 242
    },
    {
      "text": "BL indicates the baseline models. techniques combined with efﬁcient scheduling occasionally gives more accuracy than a larger and unpruned centralized DNN that is more failure-prone and power hungry. D. Adaptive Ensemble Learner \nAs discussed earlier in Section III-D, origin uses a lightweight and adaptive ensemble learner that performs weighted majority voting based on a conﬁdence matrix.",
      "type": "sliding_window",
      "tokens": 84
    },
    {
      "text": "D. Adaptive Ensemble Learner \nAs discussed earlier in Section III-D, origin uses a lightweight and adaptive ensemble learner that performs weighted majority voting based on a conﬁdence matrix. The conﬁdence matrix adapts and learns from the user pattern. It is obvious that it is not feasible to train a DNN for all types and variances of human actions.",
      "type": "sliding_window",
      "tokens": 81
    },
    {
      "text": "It is obvious that it is not feasible to train a DNN for all types and variances of human actions. Even for the same types of activity, some attributes will vary from user to user. 70 75 80 85 90 \n70 75 80 85 90 \nIter 1 Iter 10 Iter 100 Iter 1000 \nAccuracy % \nUser 1 User 2 User 3 Base Model Fig.",
      "type": "sliding_window",
      "tokens": 80
    },
    {
      "text": "70 75 80 85 90 \n70 75 80 85 90 \nIter 1 Iter 10 Iter 100 Iter 1000 \nAccuracy % \nUser 1 User 2 User 3 Base Model Fig. 6:  Accuracy over time for different users: the conﬁdence matrix adapts to the behaviour and activity pattern of the user and learns over time to give stable if not better accuracy. These variations can cause misclassiﬁcations and the adaptive nature of the conﬁdence matrix mitigates this.",
      "type": "sliding_window",
      "tokens": 98
    },
    {
      "text": "These variations can cause misclassiﬁcations and the adaptive nature of the conﬁdence matrix mitigates this. To mimic the noisy and inconsistent behaviour of real- world scenarios, we test the adaptive nature of the ensemble learner for 3 different previously unseen users over a 1000 iterations (10000 successful classiﬁcations; each iteration has 10 classiﬁcations). The noisy data is generated by adding a Gaussian noise (with maximum SNR of 20dB) over the unseen test data.",
      "type": "sliding_window",
      "tokens": 105
    },
    {
      "text": "The noisy data is generated by adding a Gaussian noise (with maximum SNR of 20dB) over the unseen test data. The ﬁrst iteration shows the accuracy with the unchanged conﬁdence matrix. Even though the accuracy claim of the models was nearly 85%, in the ﬁrst iteration, the accuracy drops below 80% because of the added noise.",
      "type": "sliding_window",
      "tokens": 78
    },
    {
      "text": "Even though the accuracy claim of the models was nearly 85%, in the ﬁrst iteration, the accuracy drops below 80% because of the added noise. As the conﬁdence matrix gets updated with the newer conﬁdence values sent from the sensor, we can see (from Fig. 6), that Origin  keeps up with the claimed accuracy (base accuracy), and at times outperforms it.",
      "type": "sliding_window",
      "tokens": 81
    },
    {
      "text": "6), that Origin  keeps up with the claimed accuracy (base accuracy), and at times outperforms it. We can attribute this to the conﬁdence matrix and ensemble learner, since over these 1000 iterations, only the conﬁdence matrix gets updated. Note that the conﬁdence matrix reaches the steady state of baseline accuracy within 100 iterations.",
      "type": "sliding_window",
      "tokens": 71
    },
    {
      "text": "Note that the conﬁdence matrix reaches the steady state of baseline accuracy within 100 iterations. This, in turn, will lead to better and more stable classiﬁcation for every individual without extensive need for retraining and updating the DNN, which might be impractical for EH-WSNs due to the high communication cost while updating the parameters. V. C ONCLUSION \nEnabling DNN inference on edge devices has been gaining recent traction, especially for tasks like HAR.",
      "type": "sliding_window",
      "tokens": 105
    },
    {
      "text": "V. C ONCLUSION \nEnabling DNN inference on edge devices has been gaining recent traction, especially for tasks like HAR. However, the compute heavy DNNs make it challenging because of their \npower requirements, especially in EH-WSNs. Our proposal, Origin , holistically looks into multiple aspects of deploying a DNN on an EH-WSN for the purpose of HAR.",
      "type": "sliding_window",
      "tokens": 92
    },
    {
      "text": "Our proposal, Origin , holistically looks into multiple aspects of deploying a DNN on an EH-WSN for the purpose of HAR. Origin  combines an intelligent activity aware scheduler with an adaptive and light weight ensemble learning method. Our experiments shows that DNN inference using  Origin , running on a harvested energy only system, is more accurate than energy-constraint- optimized DNNs, running on a fully-powered system.",
      "type": "sliding_window",
      "tokens": 98
    },
    {
      "text": "Our experiments shows that DNN inference using  Origin , running on a harvested energy only system, is more accurate than energy-constraint- optimized DNNs, running on a fully-powered system. Although the current work is limited to HAR, this can further be extended to many suitable tasks which need to leverage a distributed sensor system for DNN inference. We believe that the co- optimization of deep learning and energy harvesting techniques for edge devices will further invigorate research on the next generations of intelligent and sustainable IoT platforms.",
      "type": "sliding_window",
      "tokens": 118
    },
    {
      "text": "We believe that the co- optimization of deep learning and energy harvesting techniques for edge devices will further invigorate research on the next generations of intelligent and sustainable IoT platforms. VI. A CKNOWLEDGMENTS This work was supported in part by Semiconductor Research Corporation (SRC), Center for Brain-inspired Computing (C- BRIC) and NSF Grant #1822923 (SPX: SOPHIA).",
      "type": "sliding_window",
      "tokens": 95
    },
    {
      "text": "A CKNOWLEDGMENTS This work was supported in part by Semiconductor Research Corporation (SRC), Center for Brain-inspired Computing (C- BRIC) and NSF Grant #1822923 (SPX: SOPHIA). R EFERENCES \n[1] “Taking an ecg with the ecg app on apple watch series 4 or later,” 2020, https://support.apple.com/en-us/HT208955. [2] “Use fall detection with apple watch,” 2020, https://support.apple.com/en- us/HT208944.",
      "type": "sliding_window",
      "tokens": 137
    },
    {
      "text": "[2] “Use fall detection with apple watch,” 2020, https://support.apple.com/en- us/HT208944. [3] T.-J. Yang, A. Howard, B. Chen, X. Zhang, A.",
      "type": "sliding_window",
      "tokens": 59
    },
    {
      "text": "Yang, A. Howard, B. Chen, X. Zhang, A. Go, M. Sandler, V. Sze, and H. Adam, “Netadapt: Platform-aware neural network adaptation for mobile applications,” in  ECCV , September 2018. [4] “Google assistant for wearables,” 2020, https://assistant.google.com/platforms/wearables/.",
      "type": "sliding_window",
      "tokens": 91
    },
    {
      "text": "[4] “Google assistant for wearables,” 2020, https://assistant.google.com/platforms/wearables/. [5] K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Spendthrift: Machine learning based resource and fre- quency scaling for ambient energy harvesting nonvolatile processors,” in 2017 (ASP-DAC) , 2017, pp. 678–683.",
      "type": "sliding_window",
      "tokens": 133
    },
    {
      "text": "678–683. [6] K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, J. Samp- son, M. T. Kandemir, and V. Narayanan, “Resirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent embedded processors,” in  2020 HPCA , 2020, pp. 315–327.",
      "type": "sliding_window",
      "tokens": 110
    },
    {
      "text": "315–327. [7] G. Gobieski, B. Lucia, and N. Beckmann, “Intelligence beyond the edge: Inference on intermittent embedded systems,” in  ASPLOS . ACM, 2019.",
      "type": "sliding_window",
      "tokens": 53
    },
    {
      "text": "ACM, 2019. [8] K. Maeng and B. Lucia, “Adaptive dynamic checkpointing for safe efﬁcient intermittent computing,” in  OSDI . USENIX Association, 2018.",
      "type": "sliding_window",
      "tokens": 43
    },
    {
      "text": "USENIX Association, 2018. [9] K. Ma, X. Li, S. Li, Y. Liu, J. J. Sampson, Y. Xie, and V. Narayanan, “Nonvolatile processor architecture exploration for energy-harvesting applications,”  IEEE Micro , vol. 35, no.",
      "type": "sliding_window",
      "tokens": 81
    },
    {
      "text": "32–40, 2015. [10] K. Ma, X. Li, J. Li, Y. Liu, Y. Xie, J. Sampson, M. T. Kandemir, and V. Narayanan, “Incidental computing on iot nonvolatile processors,” in MICRO , 2017. [11] S. Ha and S. Choi, “Convolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors,” in IJCNN , 2016.",
      "type": "sliding_window",
      "tokens": 125
    },
    {
      "text": "[11] S. Ha and S. Choi, “Convolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors,” in IJCNN , 2016. [12] O. Banos, C. Villalonga, R. Garc´ıa, A. Saez, M. Damas, J. Holgado- Terriza, S. Lee, H. Pomares, and I. Rojas, “Design, implementation and validation of a novel open framework for agile development of mobile health applications,”  BioMedical Engineering OnLine , 2015. [13] O. Ba˜nos, R. Garc´ıa, J.",
      "type": "sliding_window",
      "tokens": 155
    },
    {
      "text": "[13] O. Ba˜nos, R. Garc´ıa, J. A. H. Terriza, M. Damas, H. Pomares, I. R. Ruiz, A. Saez, and C. Villalonga, “mhealthdroid: A novel framework for agile development of mobile health applications,” in  IWAAL . Springer, 2014.",
      "type": "sliding_window",
      "tokens": 88
    },
    {
      "text": "Springer, 2014. [14] F. M. Rueda, R. Grzeszick, G. A. Fink, S. Feldhorst, and M. ten Hompel, “Convolutional neural networks for human activity recognition using body-worn sensors,”  Informatics , 2018. [15] T. Yang, Y. Chen, and V. Sze, “Designing energy-efﬁcient convolutional neural networks using energy-aware pruning,” in  CVPR .",
      "type": "sliding_window",
      "tokens": 112
    },
    {
      "text": "[15] T. Yang, Y. Chen, and V. Sze, “Designing energy-efﬁcient convolutional neural networks using energy-aware pruning,” in  CVPR . IEEE, 2017. [16] A. Reiss and D. Stricker, “Introducing a new benchmarked dataset for activity monitoring,” in  ISWC .",
      "type": "sliding_window",
      "tokens": 78
    },
    {
      "text": "[16] A. Reiss and D. Stricker, “Introducing a new benchmarked dataset for activity monitoring,” in  ISWC . IEEE, 2012. [17] A. Reiss and D. Stricker, “Creating and benchmarking a new dataset for physical activity monitoring,” in  PETRA , F. Makedon, Ed.",
      "type": "sliding_window",
      "tokens": 78
    },
    {
      "text": "[17] A. Reiss and D. Stricker, “Creating and benchmarking a new dataset for physical activity monitoring,” in  PETRA , F. Makedon, Ed. ACM, 2012. [18] F. Chollet  et al.",
      "type": "sliding_window",
      "tokens": 59
    },
    {
      "text": "Abstract — There is an increasing demand for performing machine learning tasks, such as human activity recognition (HAR) on emerging ultra-low-power internet of things (IoT) platforms. However, the computation and power demands of deep neural network (DNN) based inference pose signiﬁcant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN). Recent works show substantial efﬁciency boosts from performing inference tasks directly on the IoT nodes rather than merely transmitting raw sensor data.",
      "type": "sliding_window_shuffled",
      "tokens": 115,
      "augmented": true
    },
    {
      "text": "However, the computation and power demands of deep neural network (DNN) based inference pose signiﬁcant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN). This paper presents a novel scheduling policy along with an adaptive ensemble learner to efﬁciently perform HAR on a distributed energy-harvesting body area network. Moreover, managing inferences requiring responses from multiple energy- harvesting nodes imposes challenges at the system level in addition to the constraints at each node.",
      "type": "sliding_window_shuffled",
      "tokens": 115,
      "augmented": true
    },
    {
      "text": "It also leverages the continu- ous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve ﬁnal classiﬁcation accuracy. Our proposed policy,  Origin , strategically ensures efﬁcient and accurate indi- vidual inference execution at each sensor node by using a novel activity-aware scheduling approach. This paper presents a novel scheduling policy along with an adaptive ensemble learner to efﬁciently perform HAR on a distributed energy-harvesting body area network.",
      "type": "sliding_window_shuffled",
      "tokens": 107,
      "augmented": true
    },
    {
      "text": "It also leverages the continu- ous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve ﬁnal classiﬁcation accuracy. Experimental results using two different HAR data-sets show Origin , while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classiﬁer continuously operating at the same average power. Further,  Origin  proposes an adaptive ensemble learner to personalize the optimizations based on each individual user.",
      "type": "sliding_window_shuffled",
      "tokens": 108,
      "augmented": true
    },
    {
      "text": "Experimental results using two different HAR data-sets show Origin , while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classiﬁer continuously operating at the same average power. Index Terms —Energy Harvesting, Human Activity Recognition, DNN, Wireless Senor Network, Ensemble Learning \nI. I NTRODUCTION \nThe advent of data driven computing, along with advances in low-power computing platforms, has given rise to the new generation of intelligent and connected devices that comprise the internet of things (IoT). These devices have become an integral part of our daily lives and, using techniques such as deep learning, these devices are becoming increasingly capable of performing complex inference tasks including ma- chine translation, human activity recognition (HAR), bio-metric authentication, ECG measurement, fall detection etcetera [1], [2].",
      "type": "sliding_window_shuffled",
      "tokens": 191,
      "augmented": true
    },
    {
      "text": "These devices have become an integral part of our daily lives and, using techniques such as deep learning, these devices are becoming increasingly capable of performing complex inference tasks including ma- chine translation, human activity recognition (HAR), bio-metric authentication, ECG measurement, fall detection etcetera [1], [2]. Given the power and compute constraints of the IoT devices performing sensing, it is difﬁcult to execute these inference tasks on the sensing device itself, excepting a few intermittent tasks such as bio-metric authentication. These inference tasks are typically driven by deep neural networks (DNNs), which are known for being compute heavy and power hungry [3].",
      "type": "sliding_window_shuffled",
      "tokens": 143,
      "augmented": true
    },
    {
      "text": "Instead, to perform complex and continuous inference, such as HAR, the data is typically ofﬂoaded either to the cloud or \nto a nearby host device which in turn executes the inference or further redirects it [4] and, ﬁnally, returns the results to the IoT devices responsible for data display or actuation, dependent on the inference task. Given the power and compute constraints of the IoT devices performing sensing, it is difﬁcult to execute these inference tasks on the sensing device itself, excepting a few intermittent tasks such as bio-metric authentication. Recent works [5], [6] suggest that processing data at the source is more efﬁcient that sending them to the cloud and getting the results back, owing to the power and latency overhead of data communication.",
      "type": "sliding_window_shuffled",
      "tokens": 167,
      "augmented": true
    },
    {
      "text": "They propose optimizations to efﬁciently execute the DNNs on low power IoT devices [7], [8]. Recent works [5], [6] suggest that processing data at the source is more efﬁcient that sending them to the cloud and getting the results back, owing to the power and latency overhead of data communication. Other recent works [9], [5], [7], [8] have proposed using energy harvesting (EH) solutions to provide additional energy and increase the battery life in IoT devices.",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "Other recent works [9], [5], [7], [8] have proposed using energy harvesting (EH) solutions to provide additional energy and increase the battery life in IoT devices. Moreover, in addition to prolonging device lifetime, energy harvesting can help us reduce the environmen- tal impact of batteries [10]. These works provide software, hardware and compiler-level solutions, which can be applied to build a battery-less system working entirely on harvested energy.",
      "type": "sliding_window_shuffled",
      "tokens": 102,
      "augmented": true
    },
    {
      "text": "To tackle this, recent works [9], [6] use a non-volatile processor (NVP) to ensure sufﬁcient forward progress in the face of frequent power emergencies. Moreover, in addition to prolonging device lifetime, energy harvesting can help us reduce the environmen- tal impact of batteries [10]. However, energy harvesting is no panacea due to the ﬁckle nature of harvested energy.",
      "type": "sliding_window_shuffled",
      "tokens": 88,
      "augmented": true
    },
    {
      "text": "However, these node-level optimizations are not entirely sufﬁcient for sensor networks with multiple sensors collectively working together to achieve a goal, which are very common. To tackle this, recent works [9], [6] use a non-volatile processor (NVP) to ensure sufﬁcient forward progress in the face of frequent power emergencies. The combination of EH, NVPs and other architectural and compiler optimizations have enabled the use of sensors as smart inference engines.",
      "type": "sliding_window_shuffled",
      "tokens": 101,
      "augmented": true
    },
    {
      "text": "In networks of energy harvested sensors, the power-hungry nature of commu- nication results in intermittent coordination failures due to one or more of the sensors, or even the fusing node itself, lacking sufﬁcient energy at the time that inter-node communication is required. However, these node-level optimizations are not entirely sufﬁcient for sensor networks with multiple sensors collectively working together to achieve a goal, which are very common. Although fusing sensor data is not uncommon, it requires one central location where the inference can take place, requiring the communication of sensed data.",
      "type": "sliding_window_shuffled",
      "tokens": 130,
      "augmented": true
    },
    {
      "text": "This work aims to address this limitation by pursuing answers to the following questions -  1) how do we leverage mul- tiple available energy harvesting wireless sensors collectively, and 2) where should each individual sensor perform its own inference, considering that they collectively perform a single task? Our approach to address these questions relies on decen- tralizing the DNN execution and letting each sensor perform its own inference. In networks of energy harvested sensors, the power-hungry nature of commu- nication results in intermittent coordination failures due to one or more of the sensors, or even the fusing node itself, lacking sufﬁcient energy at the time that inter-node communication is required.",
      "type": "sliding_window_shuffled",
      "tokens": 156,
      "augmented": true
    },
    {
      "text": "Our approach to address these questions relies on decen- tralizing the DNN execution and letting each sensor perform its own inference. These sensors, each individually working as a weak classiﬁer, can together form an ensemble learning \nenvironment to achieve better accuracy with lower communi- cation overhead. For each sensor to perform inference using the limited and unstable harvested energy poses a scheduling problem, as non-deterministic time is required for the EH sensors to accumulate enough energy to perform the inference.",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "For each sensor to perform inference using the limited and unstable harvested energy poses a scheduling problem, as non-deterministic time is required for the EH sensors to accumulate enough energy to perform the inference. This scheduling is made even more difﬁcult as each sensor can harvest and consume different amounts of energy depending upon their location, have different sensor sampling rate, and require different DNNs to be executed. Further, all sensors might not be able to participate in the ensemble due to the ﬁckle nature of harvested energy.",
      "type": "sliding_window_shuffled",
      "tokens": 107,
      "augmented": true
    },
    {
      "text": "Further, all sensors might not be able to participate in the ensemble due to the ﬁckle nature of harvested energy. Therefore, this work proposes an intelligent scheduler along with efﬁcient ensemble learning to enable DNN inference in a distributed energy harvesting wireless sensor network (EH- WSN). This demands the aggregation process for the ensemble to be robust, yet light weight in order to perform accurate classiﬁcation with minimum overhead.",
      "type": "sliding_window_shuffled",
      "tokens": 91,
      "augmented": true
    },
    {
      "text": "This work proposes a novel policy,  Origin , which enables energy harvesting wireless sensors to perform efﬁcient and accurate DNN inference. Speciﬁcally, Origin targets inherent features of sensor data from distributed body area networks in human activity recognition (HAR) tasks and leverages non- volatile processing, intelligent scheduling for energy-harvesting sensor nodes, and ensemble leaning to classify human activity with minimum accuracy loss compared to a state-of-the-art battery powered system. Therefore, this work proposes an intelligent scheduler along with efﬁcient ensemble learning to enable DNN inference in a distributed energy harvesting wireless sensor network (EH- WSN).",
      "type": "sliding_window_shuffled",
      "tokens": 142,
      "augmented": true
    },
    {
      "text": "To the best of our knowledge, this is the ﬁrst work that tries to enable DNN inference for human activity recognition in a distributed energy harvesting wireless sensor network by leveraging ensemble learning. Speciﬁcally, Origin targets inherent features of sensor data from distributed body area networks in human activity recognition (HAR) tasks and leverages non- volatile processing, intelligent scheduling for energy-harvesting sensor nodes, and ensemble leaning to classify human activity with minimum accuracy loss compared to a state-of-the-art battery powered system. The paper makes the following key contributions: 1) We design a scheduling policy that chooses the salient sensor for performing the inference depending on the an- ticipated activity, i.e.",
      "type": "sliding_window_shuffled",
      "tokens": 159,
      "augmented": true
    },
    {
      "text": "2) We leverage temporal continuity of human activity, and persist the last successful classiﬁcation result of a sensor. The paper makes the following key contributions: 1) We design a scheduling policy that chooses the salient sensor for performing the inference depending on the an- ticipated activity, i.e. the scheduler is  activity aware .",
      "type": "sliding_window_shuffled",
      "tokens": 75,
      "augmented": true
    },
    {
      "text": "3) Our proposed policy,  Origin , combines an adaptive conﬁ- dence matrix and the activity aware scheduler to perform efﬁcient and accurate classiﬁcation. 2) We leverage temporal continuity of human activity, and persist the last successful classiﬁcation result of a sensor. We use aggressive recall which reduces the number of total inferences performed and mitigates the requirement that all of the sensors be involved in the ensemble process during each inference.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "3) Our proposed policy,  Origin , combines an adaptive conﬁ- dence matrix and the activity aware scheduler to perform efﬁcient and accurate classiﬁcation. 4) Finally, we provide a detailed evaluation of  Origin , and show that, even when powered by an unreliable EH source, the efﬁciency achieved by the this system results in better accuracy than that of a fully powered system running state of the art classiﬁers optimized for energy efﬁciency. The adaptive conﬁdence matrix, which weights the output of each sensor depending upon the classiﬁcation result, is updated on each successful classiﬁcation.",
      "type": "sliding_window_shuffled",
      "tokens": 120,
      "augmented": true
    },
    {
      "text": "4) Finally, we provide a detailed evaluation of  Origin , and show that, even when powered by an unreliable EH source, the efﬁciency achieved by the this system results in better accuracy than that of a fully powered system running state of the art classiﬁers optimized for energy efﬁciency. II. Origin reaches 83.88% top-1 accuracy compared to the 81.16% accuracy of the baseline system.",
      "type": "sliding_window_shuffled",
      "tokens": 87,
      "augmented": true
    },
    {
      "text": "The conventional \nmethod, where the sensors collect the data and send it to the cloud or any other host device (such as connected mobile phones) is not an effective option as communicating large data demands more power, which is both highly variable and scarce in EH systems. M OTIVATION \nA major challenge while executing a DNN inference on an energy harvesting sensor is the power budget. II.",
      "type": "sliding_window_shuffled",
      "tokens": 84,
      "augmented": true
    },
    {
      "text": "Therefore, the better option, from a communication cost perspective, is to execute the inferences on the individual sensors and use an ensemble learning method (like majority voting) to aggregate these results for the ﬁnal classiﬁcation. The conventional \nmethod, where the sensors collect the data and send it to the cloud or any other host device (such as connected mobile phones) is not an effective option as communicating large data demands more power, which is both highly variable and scarce in EH systems. 1% \n0 20 40 60 80 100 All Succeed Atleast one succeed Failed \n9% 90% \n(a)  Inference completion breakdown when three EH sensors are working together to ﬁnish the incoming inferences.",
      "type": "sliding_window_shuffled",
      "tokens": 145,
      "augmented": true
    },
    {
      "text": "1% \n0 20 40 60 80 100 All Succeed Atleast one succeed Failed \n9% 90% \n(a)  Inference completion breakdown when three EH sensors are working together to ﬁnish the incoming inferences. In only 1% of the cases all of the sensors ﬁnished inference, while 9% of the time at least one of them ﬁnished. 90% of the time the inference could not start because of lack of energy.",
      "type": "sliding_window_shuffled",
      "tokens": 92,
      "augmented": true
    },
    {
      "text": "90% of the time the inference could not start because of lack of energy. 0 20 40 60 80 100 Succeed Failed \n72% 28% \n(b)  Inference completion breakdown when three EH sensors are working in round robin fashion, where one of the sensors performs inference while the other two are accumulating energy. 28% of the time the sensors could ﬁnish the inference, while 72% of the time the inference failed as the sensor could not harvest enough energy while not performing any inference.",
      "type": "sliding_window_shuffled",
      "tokens": 111,
      "augmented": true
    },
    {
      "text": "28% of the time the sensors could ﬁnish the inference, while 72% of the time the inference failed as the sensor could not harvest enough energy while not performing any inference. 1:  Fraction of inference completed on harvested energy using na¨ıve scheduling. Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 62,
      "augmented": true
    },
    {
      "text": "1:  Fraction of inference completed on harvested energy using na¨ıve scheduling. Each of the sensors in a multi-device HAR deployment receives different data depending on its location and the current human activity in progress. Therefore, different DNNs are needed to process data from these different locations.",
      "type": "sliding_window_shuffled",
      "tokens": 67,
      "augmented": true
    },
    {
      "text": "Even if we were able to design a proper scheduling policy, for a conventional ensemble, all the sensors involved need to ﬁnish their computation. Therefore, different DNNs are needed to process data from these different locations. Consequently, the power requirement and the latency of these DNNs may vary and synchronizing them for collective execution would require scheduling that addresses these differences in resource requirements.",
      "type": "sliding_window_shuffled",
      "tokens": 84,
      "augmented": true
    },
    {
      "text": "Even if we were able to design a proper scheduling policy, for a conventional ensemble, all the sensors involved need to ﬁnish their computation. Therefore, we cannot always expect inference outcomes from all the sensors while doing HAR on EH-WSN. However, our preliminary results using the hardware setup of [6] and the DNN from [11] on the MHEALTH [12], [13] dataset suggests that only 10% of inferences could be completed in a WiFi powered system (Fig.1a).",
      "type": "sliding_window_shuffled",
      "tokens": 113,
      "augmented": true
    },
    {
      "text": "This leaves us with the following important questions: •  Are continuous inferences essential, or can we leverage the workload itself to skip some inferences without substantial accuracy loss, allowing enough energy to be accumulated for future inferences? Clearly, the completion of the task is power bound: Adopting a wait-compute execution model, such that we have enough energy to complete some results, at a lower duty cycle, instead of always trying and failing would yield beneﬁts. Therefore, we cannot always expect inference outcomes from all the sensors while doing HAR on EH-WSN.",
      "type": "sliding_window_shuffled",
      "tokens": 126,
      "augmented": true
    },
    {
      "text": "This leaves us with the following important questions: •  Are continuous inferences essential, or can we leverage the workload itself to skip some inferences without substantial accuracy loss, allowing enough energy to be accumulated for future inferences? •  Since all the sensors cannot be activated together due to the limited power, how do we effectively perform the ensemble? III.",
      "type": "sliding_window_shuffled",
      "tokens": 76,
      "augmented": true
    },
    {
      "text": "It is obvious that the raw data sensed by each sensor would be different, even for the same activity, because of the difference in move- ment and dynamics. III. Origin : A N INTELLIGENT SCHEDULER MEETS A LIGHT WEIGHT AND ADAPTIVE ENSEMBLE LEARNER \nWe design a EH-WSN setup for HAR, where the user has three EH inertial measurement units (IMUs), at the \nchest, left ankle and right wrist 1 .",
      "type": "sliding_window_shuffled",
      "tokens": 114,
      "augmented": true
    },
    {
      "text": "For example, while cycling, the data sensed by the ankle, chest and wrist sensors would be en- tirely different because of the nature of the motion. Thus, the DNN architectures to infer these data are also different. It is obvious that the raw data sensed by each sensor would be different, even for the same activity, because of the difference in move- ment and dynamics.",
      "type": "sliding_window_shuffled",
      "tokens": 85,
      "augmented": true
    },
    {
      "text": "0 \n50 \n100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nChest Left Ankle Right Wrist Majority Voting \nFig. 2:  Accuracy of the individual DNNs and with a majority voting ensemble for different activities. Thus, the DNN architectures to infer these data are also different.",
      "type": "sliding_window_shuffled",
      "tokens": 75,
      "augmented": true
    },
    {
      "text": "2:  Accuracy of the individual DNNs and with a majority voting ensemble for different activities. Fig. To design these DNNs, we leverage the work in [11], [14] and further apply state of the art optimizations given in [3], [15] to make the DNN more suitable for energy-scarce applications.",
      "type": "sliding_window_shuffled",
      "tokens": 76,
      "augmented": true
    },
    {
      "text": "2 gives the accuracy of these DNNs on MHEALTH dataset [12], [13]. Fig. A detailed description of the setup is explained in Section IV.",
      "type": "sliding_window_shuffled",
      "tokens": 37,
      "augmented": true
    },
    {
      "text": "A. Preamble to Origin \nHuman activity has temporal continuity, i.e. A detailed description of the setup is explained in Section IV. In this section, we provide an overview of our proposed solution.",
      "type": "sliding_window_shuffled",
      "tokens": 45,
      "augmented": true
    },
    {
      "text": "A. Preamble to Origin \nHuman activity has temporal continuity, i.e. Therefore, there is an opportunity to skip some intermediate inferences over the period of an activity in order to increase harvesting duration and the prob- ability that an initiated inference will complete. most activ- ities last for some duration (in the range of hundreds of milliseconds to seconds).",
      "type": "sliding_window_shuffled",
      "tokens": 82,
      "augmented": true
    },
    {
      "text": "This can be extended further adopting a round-robin activation schedule to both increase harvesting periods per initiated in- ference on each node while increasing the odds that at least some node is attempting an inference at any given time. So long as the number of skipped inferences is modest, there will still likely be samples processed before an activity ﬁnishes. Therefore, there is an opportunity to skip some intermediate inferences over the period of an activity in order to increase harvesting duration and the prob- ability that an initiated inference will complete.",
      "type": "sliding_window_shuffled",
      "tokens": 119,
      "augmented": true
    },
    {
      "text": "Chest \nNo  Op \nRight  Wrist \nNo  Op \nLeft  Ankle \nNo  Op \nChest \nNo  Op \nNo  Op \nRight  Wrist \nNo  Op No  Op \nLeft  Ankle \nNo  Op \nNo  Op \nChest \nNo  Op \nNo  Op \nNo  Op \nRight  Wrist \nNo  Op No  Op \nNo  Op \nLeft  Ankle \nNo  Op \nNo  Op \nNo  Op Chest \nRight  Wrist Left  Ankle \nRR3 \nRR6 RR9 \nRR12 \nFig. This can be extended further adopting a round-robin activation schedule to both increase harvesting periods per initiated in- ference on each node while increasing the odds that at least some node is attempting an inference at any given time. 3:  Different ﬂavors of (extended) round-robin scheduling and their execution ﬂow.",
      "type": "sliding_window_shuffled",
      "tokens": 160,
      "augmented": true
    },
    {
      "text": "RR3 has 3 nodes with no no-ops and RR6 has 3 nodes with 3 no-ops. 3:  Different ﬂavors of (extended) round-robin scheduling and their execution ﬂow. Each policy is named after the num- ber of nodes the cycle has, i.e.",
      "type": "sliding_window_shuffled",
      "tokens": 69,
      "augmented": true
    },
    {
      "text": "1b). RR3 has 3 nodes with no no-ops and RR6 has 3 nodes with 3 no-ops. Even using a round robin execution, we observe that only 28% of the inferences are completed (shown in Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 60,
      "augmented": true
    },
    {
      "text": "1b). Therefore, we induce a delay (no-op cycles in Fig. 3) between one sensor ﬁnishing an inference and the next sensor starting the next one, so that each of the sensors get more time to accumulate more energy prior to attempting an inference.",
      "type": "sliding_window_shuffled",
      "tokens": 61,
      "augmented": true
    },
    {
      "text": "We refer to this policy that stretches the basic round-robin policy as extended round-robin (ER-r). 3) between one sensor ﬁnishing an inference and the next sensor starting the next one, so that each of the sensors get more time to accumulate more energy prior to attempting an inference. Using ER-r, we can complete more total inferences, \n1 This can also be extended to larger numbers of sensors and modalities \nbut this design is limited by the accuracy of individual sensors.",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "2), ER-r might lead to lower accuracy in many cases. Moreover, since all sensors are not equally capable of classifying each activity with same accuracy (Fig. Using ER-r, we can complete more total inferences, \n1 This can also be extended to larger numbers of sensors and modalities \nbut this design is limited by the accuracy of individual sensors.",
      "type": "sliding_window_shuffled",
      "tokens": 80,
      "augmented": true
    },
    {
      "text": "2), ER-r might lead to lower accuracy in many cases. A better approach is to prioritize performing inferences on the sensor that has the highest local accuracy for the current activity. However, this poses a chicken and egg problem – to know which sensor is the best for classifying an activity we need to know what activity is going to be performed beforehand.",
      "type": "sliding_window_shuffled",
      "tokens": 77,
      "augmented": true
    },
    {
      "text": "However, this poses a chicken and egg problem – to know which sensor is the best for classifying an activity we need to know what activity is going to be performed beforehand. Intuitively, human activities do not usually stop abruptly, i.e. However, while perfect future knowledge remains impossible, in the context of HAR, we can anticipate the next activity from the previous activity with high conﬁdence.",
      "type": "sliding_window_shuffled",
      "tokens": 88,
      "augmented": true
    },
    {
      "text": "if a person is walking and has taken a step, there is a high probability that the person will continue walking rather than immediately switch to another activity. Therefore, to classify the next possible activity, we activate the sensor which is most accurate for classifying the anticipated activity. Intuitively, human activities do not usually stop abruptly, i.e.",
      "type": "sliding_window_shuffled",
      "tokens": 80,
      "augmented": true
    },
    {
      "text": "This motivates us to develop an  activity-aware scheduling  (AAS) policy which aims to activate the best suited sensor for the anticipated activity. B. Therefore, to classify the next possible activity, we activate the sensor which is most accurate for classifying the anticipated activity.",
      "type": "sliding_window_shuffled",
      "tokens": 60,
      "augmented": true
    },
    {
      "text": "However, accuracy being a ﬂoating point number, is expensive in terms of energy to store and lookup. B. Activity Aware Scheduling \nTo enable the activity awareness we keep a small lookup table of accuracy of all the sensors over all the classes.",
      "type": "sliding_window_shuffled",
      "tokens": 55,
      "augmented": true
    },
    {
      "text": "After a sensor detects an activity, it anticipates the next activity to be the current classiﬁed activity, looks up for the best sensor, and signals to activate it for the upcoming inference. However, accuracy being a ﬂoating point number, is expensive in terms of energy to store and lookup. To minimize this overhead, instead of storing the accuracy, we store the rank of the sensors for individual activities.",
      "type": "sliding_window_shuffled",
      "tokens": 87,
      "augmented": true
    },
    {
      "text": "However, this leads to another potential issue - what if the current inference is running on the best sensor, and the sensor does not have enough energy to run the next inference? In this case, the current sensor chooses the next best sensor for the job and signals it. After a sensor detects an activity, it anticipates the next activity to be the current classiﬁed activity, looks up for the best sensor, and signals to activate it for the upcoming inference.",
      "type": "sliding_window_shuffled",
      "tokens": 101,
      "augmented": true
    },
    {
      "text": "In this case, the current sensor chooses the next best sensor for the job and signals it. To incorporate the ER-r, we induce delays between sending the external signal and starting the inference on the same sensor. The other sensor receives this as an external signal and activates itself to classify the activity.",
      "type": "sliding_window_shuffled",
      "tokens": 67,
      "augmented": true
    },
    {
      "text": "Combination of ER-r and AAS, results in more than 70% accuracy for most of the activities (Fig. This delay depends of the extended round- robin policy. To incorporate the ER-r, we induce delays between sending the external signal and starting the inference on the same sensor.",
      "type": "sliding_window_shuffled",
      "tokens": 65,
      "augmented": true
    },
    {
      "text": "4). Combination of ER-r and AAS, results in more than 70% accuracy for most of the activities (Fig. 0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 RR3 with AAS RR6 RR6 with AAS RR9 RR9 with AAS RR12 RR12 with AAS Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "Even though AAS provides signiﬁcantly better results com- pared to standard round-robin, it is still unable to incorporate ensemble learning. 4:  Accuracy results for AAS combined with ER-r. 0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 RR3 with AAS RR6 RR6 with AAS RR9 RR9 with AAS RR12 RR12 with AAS Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "Therefore, we need to ﬁnd the classiﬁcation result for all the sensors without activating them. Even though AAS provides signiﬁcantly better results com- pared to standard round-robin, it is still unable to incorporate ensemble learning. The major challenge is the inability to run inferences in all the sensors simultaneously because of the harvested energy budget.",
      "type": "sliding_window_shuffled",
      "tokens": 73,
      "augmented": true
    },
    {
      "text": "Extending our assumption from AAS, we hypothesize that the most recent classiﬁcation result of a sensor must be a good \nrepresentation of what its inference would be for the current activity. Therefore, we need to ﬁnd the classiﬁcation result for all the sensors without activating them. Hence, by memorizing or  recalling  the most recent classiﬁcation result, we can get the inference result of a sensor even without activating it.",
      "type": "sliding_window_shuffled",
      "tokens": 92,
      "augmented": true
    },
    {
      "text": "Even though the sensors are running in the round-robin fashion, the non-participating sensors can still impact the classiﬁcation result by virtue of  recalling their most recent classiﬁcation. Hence, by memorizing or  recalling  the most recent classiﬁcation result, we can get the inference result of a sensor even without activating it. Combining the  Recall  with AAS (which we term as AASR - Activity Aware Scheduling with Recall) opens possibilities for getting a more accurate classiﬁcation.",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "Combining the  Recall  with AAS (which we term as AASR - Activity Aware Scheduling with Recall) opens possibilities for getting a more accurate classiﬁcation. To minimize the communication overhead, and to ensure participation of all sensors, we build the  recall  strategy into the host device. The host device remembers the most recent classiﬁcations by all of the sensors.",
      "type": "sliding_window_shuffled",
      "tokens": 79,
      "augmented": true
    },
    {
      "text": "AASR thus bridges the major gaps in the design that we intend to achieve. After receiving or recalling prediction from all sensors, the host performs a majority voting for the ﬁnal classiﬁcation. The host device remembers the most recent classiﬁcations by all of the sensors.",
      "type": "sliding_window_shuffled",
      "tokens": 58,
      "augmented": true
    },
    {
      "text": "With the addition of  recall , we have a fully functional ensemble learning system on a EH-WSN. AASR thus bridges the major gaps in the design that we intend to achieve. AASR intelligently takes advantage of multiple DNNs (by bringing in activity aware scheduling), leverages the workload (by considering the activity continuity via recall and extended round-robin strategies), and also poses minimal overhead on the host device for running aggregation.",
      "type": "sliding_window_shuffled",
      "tokens": 101,
      "augmented": true
    },
    {
      "text": "However, as we did not want to burden the host device with complex computation, the aggregation task is very na¨ıve in that it just performs recall and incorporates no intelligence. AASR intelligently takes advantage of multiple DNNs (by bringing in activity aware scheduling), leverages the workload (by considering the activity continuity via recall and extended round-robin strategies), and also poses minimal overhead on the host device for running aggregation. Hence, there is an opportunity to also improve the ensemble technique.",
      "type": "sliding_window_shuffled",
      "tokens": 115,
      "augmented": true
    },
    {
      "text": "Designing any sophisticated ensemble learning technique will either consume more resources of the host device, or need more information and computation at the edge, thus making our effort of ﬁnishing the inference at the edge not viable. C. Designing an Adaptive Ensemble Learner AASR scheduling solves most of the issues on the sensor side without burdening host device, yet the host device still per- forms a na¨ıve majority voting-based ensemble. Hence, there is an opportunity to also improve the ensemble technique.",
      "type": "sliding_window_shuffled",
      "tokens": 110,
      "augmented": true
    },
    {
      "text": "Designing any sophisticated ensemble learning technique will either consume more resources of the host device, or need more information and computation at the edge, thus making our effort of ﬁnishing the inference at the edge not viable. The current scheduler is activity aware, i.e. However, if we can design a simple, light weight and adaptive ensemble technique, then our design will be holistic from both the sensor and the host side.",
      "type": "sliding_window_shuffled",
      "tokens": 89,
      "augmented": true
    },
    {
      "text": "The current scheduler is activity aware, i.e. Furthermore, the AASR poses negligible overhead both in terms of compute and memory. while performing an inference it always tries to choose the best available sensor to perform the task at hand.",
      "type": "sliding_window_shuffled",
      "tokens": 55,
      "augmented": true
    },
    {
      "text": "Furthermore, the AASR poses negligible overhead both in terms of compute and memory. The idea of making the ensemble task activity aware has similarities to weighted majority voting, where we assign weights to the individual learners participating in the ensemble, such that a higher accuracy classiﬁer contributes more weight towards the ﬁnal result. Our goal is to develop an activity aware ensemble technique which can further improve accuracy, when compared to AASR.",
      "type": "sliding_window_shuffled",
      "tokens": 93,
      "augmented": true
    },
    {
      "text": "2 it is clear that not all the sensors are equally good at classifying various ac- tivities; in fact, this builds the foundation of AASR. The idea of making the ensemble task activity aware has similarities to weighted majority voting, where we assign weights to the individual learners participating in the ensemble, such that a higher accuracy classiﬁer contributes more weight towards the ﬁnal result. However, from Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 92,
      "augmented": true
    },
    {
      "text": "Therefore, assigning a static weight to the output of each classiﬁer will not reﬂect that its accuracy is activity-dependent. For example, the classiﬁer used in the left ankle sensor tends to be more accurate overall, but for classifying climbing action, it is not better than the chest sensor. 2 it is clear that not all the sensors are equally good at classifying various ac- tivities; in fact, this builds the foundation of AASR.",
      "type": "sliding_window_shuffled",
      "tokens": 99,
      "augmented": true
    },
    {
      "text": "For example, the classiﬁer used in the left ankle sensor tends to be more accurate overall, but for classifying climbing action, it is not better than the chest sensor. Furthermore, it the relative weight of each sensor is likely to shift from user to user. Hence, to give the left ankle more weight while doing an ensemble for a climbing task makes \nthe classiﬁer biased.",
      "type": "sliding_window_shuffled",
      "tokens": 80,
      "augmented": true
    },
    {
      "text": "A simple solution is to assign the accuracy of each of the sensors for every class as its weight. Although accuracy is a close measurement of the conﬁdence of the classiﬁcation, it does not truly reﬂect it. Furthermore, it the relative weight of each sensor is likely to shift from user to user.",
      "type": "sliding_window_shuffled",
      "tokens": 60,
      "augmented": true
    },
    {
      "text": "For example, let us consider two DNN classiﬁers ( C 1  and C 2 ) classifying between 4 different classes  ( o 1 , o 2 , o 3 , o 4 ) . Although accuracy is a close measurement of the conﬁdence of the classiﬁcation, it does not truly reﬂect it. The ﬁnal probability vector from the last layer (soft- max function)  V C 1 = [0 .",
      "type": "sliding_window_shuffled",
      "tokens": 93,
      "augmented": true
    },
    {
      "text": "94 ,  0 . 01 ,  0 . The ﬁnal probability vector from the last layer (soft- max function)  V C 1 = [0 .",
      "type": "sliding_window_shuffled",
      "tokens": 38,
      "augmented": true
    },
    {
      "text": "07] . The accuracy of both system might be identical (over a large number of test sets), yet for the current test case, both the models are not equally conﬁdent about the classiﬁcation. Both the models have classiﬁed the input to be of class  o 1 .",
      "type": "sliding_window_shuffled",
      "tokens": 57,
      "augmented": true
    },
    {
      "text": "The accuracy of both system might be identical (over a large number of test sets), yet for the current test case, both the models are not equally conﬁdent about the classiﬁcation. The question is, how do we measure the conﬁdence of the given classiﬁcation? It is obvious that the most conﬁdent classiﬁcation for the same class would be [1 ,  0 ,  0 ,  0] , where the model is 100% conﬁdent on class  o 1  and the most confused prediction would be  [0 .",
      "type": "sliding_window_shuffled",
      "tokens": 105,
      "augmented": true
    },
    {
      "text": "25 ,  0 . 25 ,  0 . It is obvious that the most conﬁdent classiﬁcation for the same class would be [1 ,  0 ,  0 ,  0] , where the model is 100% conﬁdent on class  o 1  and the most confused prediction would be  [0 .",
      "type": "sliding_window_shuffled",
      "tokens": 68,
      "augmented": true
    },
    {
      "text": "25 ,  0 . 25] , where the classiﬁer is equally confused between all the classes. 25 ,  0 .",
      "type": "sliding_window_shuffled",
      "tokens": 31,
      "augmented": true
    },
    {
      "text": "The higher the variance the more conﬁdent is the classiﬁcation. Therefore, a good metric for the conﬁdence would be the vari- ance of the output probability vector. 25] , where the classiﬁer is equally confused between all the classes.",
      "type": "sliding_window_shuffled",
      "tokens": 51,
      "augmented": true
    },
    {
      "text": "Towards this, we build a lookup table by averaging the variance of output vectors of multiple test cases. The higher the variance the more conﬁdent is the classiﬁcation. This table, which we call the  conﬁdence matrix , gives us the conﬁdence of each sensor for each class, and can be used as a weight for majority voting.",
      "type": "sliding_window_shuffled",
      "tokens": 73,
      "augmented": true
    },
    {
      "text": "Each user has unique expressions of behaviour classes reﬂected in the sensor data. The next challenge is to adapt the conﬁdence matrix for individual users. This table, which we call the  conﬁdence matrix , gives us the conﬁdence of each sensor for each class, and can be used as a weight for majority voting.",
      "type": "sliding_window_shuffled",
      "tokens": 64,
      "augmented": true
    },
    {
      "text": "Thus, it is important to keep learning and adapting to the user behavior. Each user has unique expressions of behaviour classes reﬂected in the sensor data. For example, gaits of two different people may signiﬁcantly vary, and might be entirely different from the training data.",
      "type": "sliding_window_shuffled",
      "tokens": 56,
      "augmented": true
    },
    {
      "text": "Thus, it is important to keep learning and adapting to the user behavior. Since, we cannot keep re-training the DNNs because of their resource constraints, we choose to periodically update the conﬁdence matrix. The initial conﬁdence matrix, derived from the test cases, would be programmed into the host device.",
      "type": "sliding_window_shuffled",
      "tokens": 66,
      "augmented": true
    },
    {
      "text": "This conﬁdence score would further update the weight matrix of the host device using a moving average method and keep updating it as the user keeps using the device. The initial conﬁdence matrix, derived from the test cases, would be programmed into the host device. Further, after each successful classiﬁcation, the sensors would send the conﬁdence score for that classiﬁer along with the output class.",
      "type": "sliding_window_shuffled",
      "tokens": 77,
      "augmented": true
    },
    {
      "text": "This design optimizes the DNN execution in an energy harvesting wireless sensor network by collectively looking into all the involved components. This conﬁdence score would further update the weight matrix of the host device using a moving average method and keep updating it as the user keeps using the device. D. Origin: AASR meets Conﬁdence Matrix Combined together, the activity aware scheduler with recall (AASR) and the adaptive conﬁdence matrix we present  Origin : a holistic system where an intelligent scheduler meets an adap- tive ensemble learner.",
      "type": "sliding_window_shuffled",
      "tokens": 120,
      "augmented": true
    },
    {
      "text": "This design optimizes the DNN execution in an energy harvesting wireless sensor network by collectively looking into all the involved components. In the earlier case of na¨ıve scheduling we tried to build an efﬁcient DNN by applying energy aware pruning [15]. The DNNs as indi- viduals are optimized before to meet the power budget.",
      "type": "sliding_window_shuffled",
      "tokens": 76,
      "augmented": true
    },
    {
      "text": "However, since Origin  follows an activity aware scheduling with extended round-robin, it can relax the power constraint pruning if needed. In the earlier case of na¨ıve scheduling we tried to build an efﬁcient DNN by applying energy aware pruning [15]. Instead of restricting the power constraint to the average power of the entire power trace, the constraint can be relaxed to the average power requirement of the extended round-robin \n0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 AAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baseline-2 Baseline 1 \n(a)  Accuracy with MHEALTH dataset.",
      "type": "sliding_window_shuffled",
      "tokens": 190,
      "augmented": true
    },
    {
      "text": "0 20 40 60 80 100 \nWalking Climbing Cycling Running Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 CAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baselin-2 Baseline-1 \n(b)  Accuracy with PAMAP2 dataset. Fig. Instead of restricting the power constraint to the average power of the entire power trace, the constraint can be relaxed to the average power requirement of the extended round-robin \n0 20 40 60 80 100 \nWalking Climbing Cycling Running Jogging Jumping \nAccuracy % \nRR3 AASR RR3 Origin RR6 AAS RR6 AASR RR6 Origin RR9 AAS RR9 AASR RR9 Origin RR12 AAS RR12 AASR RR12 Origin Baseline-2 Baseline 1 \n(a)  Accuracy with MHEALTH dataset.",
      "type": "sliding_window_shuffled",
      "tokens": 231,
      "augmented": true
    },
    {
      "text": "5:  Accuracy results of the different policies described in Sec- tion III. RR indicates the extended round-robin policy in use, e.g. Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 40,
      "augmented": true
    },
    {
      "text": "policy in use. RR indicates the extended round-robin policy in use, e.g. RR6 AAS represents AAS with RR6.",
      "type": "sliding_window_shuffled",
      "tokens": 36,
      "augmented": true
    },
    {
      "text": "The added recall functionality enables ensemble learning. policy in use. Further, the scheduling strategy was modiﬁed using activity aware scheduling with extended round-robin such that all the sensors get enough time to harvest and also the best possible sensor works on the classiﬁcation task at hand instead of any arbitrary sensor.",
      "type": "sliding_window_shuffled",
      "tokens": 61,
      "augmented": true
    },
    {
      "text": "The associated conﬁdence matrix boosts the classiﬁcation accuracy and also resolves ties while voting. Moreover, the host device, which performs the ensemble, is equipped with a conﬁdence matrix, which adapts to the user and performs weighted majority voting instead of a na¨ıve majority voting. The added recall functionality enables ensemble learning.",
      "type": "sliding_window_shuffled",
      "tokens": 76,
      "augmented": true
    },
    {
      "text": "IV. E VALUATION \nIn this section we explain the strategy for evaluating  Origin . The associated conﬁdence matrix boosts the classiﬁcation accuracy and also resolves ties while voting.",
      "type": "sliding_window_shuffled",
      "tokens": 38,
      "augmented": true
    },
    {
      "text": "A. We discuss about the hardware and software framework, and the accuracy of  Origin  compared to two different baselines. E VALUATION \nIn this section we explain the strategy for evaluating  Origin .",
      "type": "sliding_window_shuffled",
      "tokens": 42,
      "augmented": true
    },
    {
      "text": "A. First sensor at the chest, second on the right wrist and last sensor on the left ankle. Energy Harvester and Sensor Setup \nOur evaluation setup consists of three sensors at three dif- ferent locations.",
      "type": "sliding_window_shuffled",
      "tokens": 48,
      "augmented": true
    },
    {
      "text": "We assume the communication cost to be negligible since it infrequently sends a few bytes of data to the host. First sensor at the chest, second on the right wrist and last sensor on the left ankle. Each sensor consists of four major components, namely, the sensing component, an IMU, which collects acceleration and attitude data, an energy harvester which harvest the surrounding RF (WiFi) energy, a compute component same as [6] and a wireless communication module (BLE or WiFi) to connect to a host device (battery backed mobile phone).",
      "type": "sliding_window_shuffled",
      "tokens": 131,
      "augmented": true
    },
    {
      "text": "We assume the communication cost to be negligible since it infrequently sends a few bytes of data to the host. The speciﬁcs of the energy-harvesting mechanism producing the power trace are beyond the scope of this work. To replicate the energy harvesting, we use a real power trace harvested from a WiFi source while doing various day to day tasks in an ofﬁce environment [6].",
      "type": "sliding_window_shuffled",
      "tokens": 86,
      "augmented": true
    },
    {
      "text": "However, instead of designing a centralized DNN which processes the combined data from all the sensors, we design three different smaller DNNs that work on their individual data. B. DNN Classiﬁer and the Dataset \nOur DNN design choices are inspired from the works in [11], [14]. The speciﬁcs of the energy-harvesting mechanism producing the power trace are beyond the scope of this work.",
      "type": "sliding_window_shuffled",
      "tokens": 87,
      "augmented": true
    },
    {
      "text": "We use two different datasets, MHEALTH [12], [13], and PAMAP2 [16], [17], for our evaluation which follow the similar sensor setup described in Section IV-A. Further, to build an energy efﬁcient version of the DNNs, we applied the energy-aware DNN optimizations proposed in [3], [15]. However, instead of designing a centralized DNN which processes the combined data from all the sensors, we design three different smaller DNNs that work on their individual data.",
      "type": "sliding_window_shuffled",
      "tokens": 113,
      "augmented": true
    },
    {
      "text": "The DNNs were trained on the training data-sets using the Keras [18] framework. C. Accuracy Results \nBaseline:  We choose two baselines for our evaluation: 1) Baseline-1 consists of the original DNNs built along the lines of [11], [14] (without any pruning). We use two different datasets, MHEALTH [12], [13], and PAMAP2 [16], [17], for our evaluation which follow the similar sensor setup described in Section IV-A.",
      "type": "sliding_window_shuffled",
      "tokens": 113,
      "augmented": true
    },
    {
      "text": "Both the baseline setups run on a fully powered system equipped with a steady power source. 2) Baseline-2 uses state of the art pruning techniques described in [3], [15] to prune the DNNs of Baseline-1 to ﬁt the average harvested power budget from our harvesting trace described in Section IV-A. C. Accuracy Results \nBaseline:  We choose two baselines for our evaluation: 1) Baseline-1 consists of the original DNNs built along the lines of [11], [14] (without any pruning).",
      "type": "sliding_window_shuffled",
      "tokens": 115,
      "augmented": true
    },
    {
      "text": "Origin  uses the DNNs of Baseline-2 for the classiﬁcation tasks. A majority voting en- semble method is used in both of these baselines to mimic ensemble learning. Both the baseline setups run on a fully powered system equipped with a steady power source.",
      "type": "sliding_window_shuffled",
      "tokens": 57,
      "augmented": true
    },
    {
      "text": "We plot the accuracy of different strategies described throughout the paper. Fig. Origin  uses the DNNs of Baseline-2 for the classiﬁcation tasks.",
      "type": "sliding_window_shuffled",
      "tokens": 31,
      "augmented": true
    },
    {
      "text": "5b shows the results for the PAMAP2 dataset. Fig. 5a shows the accuracy results on the MHEALTH dataset, and Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 34,
      "augmented": true
    },
    {
      "text": "This behaviour is expected and can be attributed to the increasing number of completed inferences. 5b shows the results for the PAMAP2 dataset. Following are our observations: •  The overall accuracy tends to improve with increasing round-robin delay time.",
      "type": "sliding_window_shuffled",
      "tokens": 54,
      "augmented": true
    },
    {
      "text": "Further evaluations suggest Origin  with RR-12 to be the best ﬁt for HAR. This behaviour is expected and can be attributed to the increasing number of completed inferences. The nature of the workload itself gives us an opportunity to not perform inference at a rapid rate.",
      "type": "sliding_window_shuffled",
      "tokens": 59,
      "augmented": true
    },
    {
      "text": "Going beyond RR-12 might lead to missing an activity window for high intensity or rapid activities, and going below RR-12 might lead to energy scarcity at times. Further evaluations suggest Origin  with RR-12 to be the best ﬁt for HAR. In case of abundant energy supply, one can use a round robin policy ﬁt for the given EH source.",
      "type": "sliding_window_shuffled",
      "tokens": 78,
      "augmented": true
    },
    {
      "text": "•  Table I shows the accuracy comparison between the RR12- Origin  with both the baselines. We observe that, for the MHEALTH dataset, RR12- Origin  is 2.72% more accu- rate than the Baseline-2. In case of abundant energy supply, one can use a round robin policy ﬁt for the given EH source.",
      "type": "sliding_window_shuffled",
      "tokens": 79,
      "augmented": true
    },
    {
      "text": "For certain cases like climbing in PAMAP2, and running in MHEALTH,  Origin  is more accurate than Baseline-1. For the PAMAP2 data-set, RR12- Origin  is 2.53% better than Baseline-2. We observe that, for the MHEALTH dataset, RR12- Origin  is 2.72% more accu- rate than the Baseline-2.",
      "type": "sliding_window_shuffled",
      "tokens": 83,
      "augmented": true
    },
    {
      "text": "These accuracy improvements can be attributed to  Origin’s  use of a conﬁdence matrix in classiﬁcation, as opposed to the baseline models, which only perform majority voting based ensembling. For certain cases like climbing in PAMAP2, and running in MHEALTH,  Origin  is more accurate than Baseline-1. Note that both the baselines are running on a fully powered system whereas  Origin runs entirely on harvested energy.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "In practice, we can extend Origin  further to other multi-sensor data-sets for HAR. Note that both the baselines are running on a fully powered system whereas  Origin runs entirely on harvested energy. Discussion:  Although  Origin  is proposed and works for energy harvesting wireless sensor networks, it can also be used with battery-powered or hybrid (a combination to battery powered and EH) systems to minimize the energy footprint while maximizing the accuracy.",
      "type": "sliding_window_shuffled",
      "tokens": 94,
      "augmented": true
    },
    {
      "text": "Discussion:  Although  Origin  is proposed and works for energy harvesting wireless sensor networks, it can also be used with battery-powered or hybrid (a combination to battery powered and EH) systems to minimize the energy footprint while maximizing the accuracy. Furthermore, it uses multiple sensors effectively and hence poses minimum risk if one of the sensors fails. This makes  Origin  versatile and suitable for systems whose intermittence comes from either or both of power or device reliability limitations, both of which will be key factors in real-world IoT deployments.",
      "type": "sliding_window_shuffled",
      "tokens": 112,
      "augmented": true
    },
    {
      "text": "BL indicates the baseline models. Moreover, ensemble learning \nActivity Policy Comparision RR12 Origin BL-2 BL-1 vs BL-2 vs BL-1 Walking 81.60896 84.46 91.56 -2.85104 -9.95104 Climbing 83.10679 77.93 83.24 5.176789 -0.13321 Cycling 85.88992 85.81 94.27 0.079918 -8.38008 Running 87.13474 81.29 86.91 5.844736 0.224736 Jogging 81.81809 78.04 83.17 3.778086 -1.35191 Jumping 83.69378 79.42 84.26 4.273776 -0.56622 \nTABLE I:  Comparing RR12 Origin with both the baselines on MHELATH dataset. This makes  Origin  versatile and suitable for systems whose intermittence comes from either or both of power or device reliability limitations, both of which will be key factors in real-world IoT deployments.",
      "type": "sliding_window_shuffled",
      "tokens": 242,
      "augmented": true
    },
    {
      "text": "BL indicates the baseline models. D. Adaptive Ensemble Learner \nAs discussed earlier in Section III-D, origin uses a lightweight and adaptive ensemble learner that performs weighted majority voting based on a conﬁdence matrix. techniques combined with efﬁcient scheduling occasionally gives more accuracy than a larger and unpruned centralized DNN that is more failure-prone and power hungry.",
      "type": "sliding_window_shuffled",
      "tokens": 84,
      "augmented": true
    },
    {
      "text": "It is obvious that it is not feasible to train a DNN for all types and variances of human actions. D. Adaptive Ensemble Learner \nAs discussed earlier in Section III-D, origin uses a lightweight and adaptive ensemble learner that performs weighted majority voting based on a conﬁdence matrix. The conﬁdence matrix adapts and learns from the user pattern.",
      "type": "sliding_window_shuffled",
      "tokens": 81,
      "augmented": true
    },
    {
      "text": "Even for the same types of activity, some attributes will vary from user to user. 70 75 80 85 90 \n70 75 80 85 90 \nIter 1 Iter 10 Iter 100 Iter 1000 \nAccuracy % \nUser 1 User 2 User 3 Base Model Fig. It is obvious that it is not feasible to train a DNN for all types and variances of human actions.",
      "type": "sliding_window_shuffled",
      "tokens": 80,
      "augmented": true
    },
    {
      "text": "These variations can cause misclassiﬁcations and the adaptive nature of the conﬁdence matrix mitigates this. 6:  Accuracy over time for different users: the conﬁdence matrix adapts to the behaviour and activity pattern of the user and learns over time to give stable if not better accuracy. 70 75 80 85 90 \n70 75 80 85 90 \nIter 1 Iter 10 Iter 100 Iter 1000 \nAccuracy % \nUser 1 User 2 User 3 Base Model Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 98,
      "augmented": true
    },
    {
      "text": "The noisy data is generated by adding a Gaussian noise (with maximum SNR of 20dB) over the unseen test data. These variations can cause misclassiﬁcations and the adaptive nature of the conﬁdence matrix mitigates this. To mimic the noisy and inconsistent behaviour of real- world scenarios, we test the adaptive nature of the ensemble learner for 3 different previously unseen users over a 1000 iterations (10000 successful classiﬁcations; each iteration has 10 classiﬁcations).",
      "type": "sliding_window_shuffled",
      "tokens": 105,
      "augmented": true
    },
    {
      "text": "The ﬁrst iteration shows the accuracy with the unchanged conﬁdence matrix. The noisy data is generated by adding a Gaussian noise (with maximum SNR of 20dB) over the unseen test data. Even though the accuracy claim of the models was nearly 85%, in the ﬁrst iteration, the accuracy drops below 80% because of the added noise.",
      "type": "sliding_window_shuffled",
      "tokens": 78,
      "augmented": true
    },
    {
      "text": "Even though the accuracy claim of the models was nearly 85%, in the ﬁrst iteration, the accuracy drops below 80% because of the added noise. 6), that Origin  keeps up with the claimed accuracy (base accuracy), and at times outperforms it. As the conﬁdence matrix gets updated with the newer conﬁdence values sent from the sensor, we can see (from Fig.",
      "type": "sliding_window_shuffled",
      "tokens": 81,
      "augmented": true
    },
    {
      "text": "6), that Origin  keeps up with the claimed accuracy (base accuracy), and at times outperforms it. We can attribute this to the conﬁdence matrix and ensemble learner, since over these 1000 iterations, only the conﬁdence matrix gets updated. Note that the conﬁdence matrix reaches the steady state of baseline accuracy within 100 iterations.",
      "type": "sliding_window_shuffled",
      "tokens": 71,
      "augmented": true
    },
    {
      "text": "Note that the conﬁdence matrix reaches the steady state of baseline accuracy within 100 iterations. V. C ONCLUSION \nEnabling DNN inference on edge devices has been gaining recent traction, especially for tasks like HAR. This, in turn, will lead to better and more stable classiﬁcation for every individual without extensive need for retraining and updating the DNN, which might be impractical for EH-WSNs due to the high communication cost while updating the parameters.",
      "type": "sliding_window_shuffled",
      "tokens": 105,
      "augmented": true
    },
    {
      "text": "Our proposal, Origin , holistically looks into multiple aspects of deploying a DNN on an EH-WSN for the purpose of HAR. However, the compute heavy DNNs make it challenging because of their \npower requirements, especially in EH-WSNs. V. C ONCLUSION \nEnabling DNN inference on edge devices has been gaining recent traction, especially for tasks like HAR.",
      "type": "sliding_window_shuffled",
      "tokens": 92,
      "augmented": true
    },
    {
      "text": "Our experiments shows that DNN inference using  Origin , running on a harvested energy only system, is more accurate than energy-constraint- optimized DNNs, running on a fully-powered system. Origin  combines an intelligent activity aware scheduler with an adaptive and light weight ensemble learning method. Our proposal, Origin , holistically looks into multiple aspects of deploying a DNN on an EH-WSN for the purpose of HAR.",
      "type": "sliding_window_shuffled",
      "tokens": 98,
      "augmented": true
    },
    {
      "text": "Our experiments shows that DNN inference using  Origin , running on a harvested energy only system, is more accurate than energy-constraint- optimized DNNs, running on a fully-powered system. We believe that the co- optimization of deep learning and energy harvesting techniques for edge devices will further invigorate research on the next generations of intelligent and sustainable IoT platforms. Although the current work is limited to HAR, this can further be extended to many suitable tasks which need to leverage a distributed sensor system for DNN inference.",
      "type": "sliding_window_shuffled",
      "tokens": 118,
      "augmented": true
    },
    {
      "text": "VI. We believe that the co- optimization of deep learning and energy harvesting techniques for edge devices will further invigorate research on the next generations of intelligent and sustainable IoT platforms. A CKNOWLEDGMENTS This work was supported in part by Semiconductor Research Corporation (SRC), Center for Brain-inspired Computing (C- BRIC) and NSF Grant #1822923 (SPX: SOPHIA).",
      "type": "sliding_window_shuffled",
      "tokens": 95,
      "augmented": true
    },
    {
      "text": "[2] “Use fall detection with apple watch,” 2020, https://support.apple.com/en- us/HT208944. A CKNOWLEDGMENTS This work was supported in part by Semiconductor Research Corporation (SRC), Center for Brain-inspired Computing (C- BRIC) and NSF Grant #1822923 (SPX: SOPHIA). R EFERENCES \n[1] “Taking an ecg with the ecg app on apple watch series 4 or later,” 2020, https://support.apple.com/en-us/HT208955.",
      "type": "sliding_window_shuffled",
      "tokens": 137,
      "augmented": true
    },
    {
      "text": "Yang, A. Howard, B. Chen, X. Zhang, A. [2] “Use fall detection with apple watch,” 2020, https://support.apple.com/en- us/HT208944. [3] T.-J.",
      "type": "sliding_window_shuffled",
      "tokens": 59,
      "augmented": true
    },
    {
      "text": "Yang, A. Howard, B. Chen, X. Zhang, A. Go, M. Sandler, V. Sze, and H. Adam, “Netadapt: Platform-aware neural network adaptation for mobile applications,” in  ECCV , September 2018. [4] “Google assistant for wearables,” 2020, https://assistant.google.com/platforms/wearables/.",
      "type": "sliding_window_shuffled",
      "tokens": 91,
      "augmented": true
    },
    {
      "text": "678–683. [4] “Google assistant for wearables,” 2020, https://assistant.google.com/platforms/wearables/. [5] K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Spendthrift: Machine learning based resource and fre- quency scaling for ambient energy harvesting nonvolatile processors,” in 2017 (ASP-DAC) , 2017, pp.",
      "type": "sliding_window_shuffled",
      "tokens": 133,
      "augmented": true
    },
    {
      "text": "678–683. [6] K. Qiu, N. Jao, M. Zhao, C. S. Mishra, G. Gudukbay, S. Jose, J. Samp- son, M. T. Kandemir, and V. Narayanan, “Resirca: A resilient energy harvesting reram crossbar-based accelerator for intelligent embedded processors,” in  2020 HPCA , 2020, pp. 315–327.",
      "type": "sliding_window_shuffled",
      "tokens": 110,
      "augmented": true
    },
    {
      "text": "ACM, 2019. [7] G. Gobieski, B. Lucia, and N. Beckmann, “Intelligence beyond the edge: Inference on intermittent embedded systems,” in  ASPLOS . 315–327.",
      "type": "sliding_window_shuffled",
      "tokens": 53,
      "augmented": true
    },
    {
      "text": "USENIX Association, 2018. [8] K. Maeng and B. Lucia, “Adaptive dynamic checkpointing for safe efﬁcient intermittent computing,” in  OSDI . ACM, 2019.",
      "type": "sliding_window_shuffled",
      "tokens": 43,
      "augmented": true
    },
    {
      "text": "35, no. [9] K. Ma, X. Li, S. Li, Y. Liu, J. J. Sampson, Y. Xie, and V. Narayanan, “Nonvolatile processor architecture exploration for energy-harvesting applications,”  IEEE Micro , vol. USENIX Association, 2018.",
      "type": "sliding_window_shuffled",
      "tokens": 81,
      "augmented": true
    },
    {
      "text": "32–40, 2015. [11] S. Ha and S. Choi, “Convolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors,” in IJCNN , 2016. [10] K. Ma, X. Li, J. Li, Y. Liu, Y. Xie, J. Sampson, M. T. Kandemir, and V. Narayanan, “Incidental computing on iot nonvolatile processors,” in MICRO , 2017.",
      "type": "sliding_window_shuffled",
      "tokens": 125,
      "augmented": true
    },
    {
      "text": "[11] S. Ha and S. Choi, “Convolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors,” in IJCNN , 2016. [12] O. Banos, C. Villalonga, R. Garc´ıa, A. Saez, M. Damas, J. Holgado- Terriza, S. Lee, H. Pomares, and I. Rojas, “Design, implementation and validation of a novel open framework for agile development of mobile health applications,”  BioMedical Engineering OnLine , 2015. [13] O. Ba˜nos, R. Garc´ıa, J.",
      "type": "sliding_window_shuffled",
      "tokens": 155,
      "augmented": true
    },
    {
      "text": "A. H. Terriza, M. Damas, H. Pomares, I. R. Ruiz, A. Saez, and C. Villalonga, “mhealthdroid: A novel framework for agile development of mobile health applications,” in  IWAAL . Springer, 2014. [13] O. Ba˜nos, R. Garc´ıa, J.",
      "type": "sliding_window_shuffled",
      "tokens": 88,
      "augmented": true
    },
    {
      "text": "[14] F. M. Rueda, R. Grzeszick, G. A. Fink, S. Feldhorst, and M. ten Hompel, “Convolutional neural networks for human activity recognition using body-worn sensors,”  Informatics , 2018. Springer, 2014. [15] T. Yang, Y. Chen, and V. Sze, “Designing energy-efﬁcient convolutional neural networks using energy-aware pruning,” in  CVPR .",
      "type": "sliding_window_shuffled",
      "tokens": 112,
      "augmented": true
    },
    {
      "text": "[15] T. Yang, Y. Chen, and V. Sze, “Designing energy-efﬁcient convolutional neural networks using energy-aware pruning,” in  CVPR . [16] A. Reiss and D. Stricker, “Introducing a new benchmarked dataset for activity monitoring,” in  ISWC . IEEE, 2017.",
      "type": "sliding_window_shuffled",
      "tokens": 78,
      "augmented": true
    },
    {
      "text": "IEEE, 2012. [16] A. Reiss and D. Stricker, “Introducing a new benchmarked dataset for activity monitoring,” in  ISWC . [17] A. Reiss and D. Stricker, “Creating and benchmarking a new dataset for physical activity monitoring,” in  PETRA , F. Makedon, Ed.",
      "type": "sliding_window_shuffled",
      "tokens": 78,
      "augmented": true
    },
    {
      "text": "[17] A. Reiss and D. Stricker, “Creating and benchmarking a new dataset for physical activity monitoring,” in  PETRA , F. Makedon, Ed. ACM, 2012. [18] F. Chollet  et al.",
      "type": "sliding_window_shuffled",
      "tokens": 59,
      "augmented": true
    }
  ]
}