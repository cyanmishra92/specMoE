=== ORIGINAL PDF: 2503.13116v4_VeriLeaky_Navigating_IP_Protection_vs_Utility_in_F.pdf ===\n\nRaw text length: 42309 characters\nCleaned text length: 41446 characters\nNumber of segments: 24\n\n=== CLEANED TEXT ===\n\narXiv:2503.13116v4 [cs.CR] 17 Jun 2025 VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding Zeng Wang , Minghao Shao , Mohammed Nabeel , Prithwish Basu Roy , Likhitha Mankali , Jitendra Bhandari , Ramesh Karri , Ozgur Sinanoglu , Muhammad Shafique , Johann Knechtel NYU Tandon School of Engineering, USA NYU Abu Dhabi, UAE Email:{zw3464, shao.minghao, mtn2, pb2718, likhitha.mankali, jb7410, rkarri, ozgursin, muhammad.shafique, Abstract Large language models (LLMs) offer significant potential for coding, yet fine-tuning (FT) with curated data is essential for niche languages like Verilog. Using proprietary intellectual property (IP) for FT presents a serious risk, as FT data can be leaked through LLM inference. This leads to a critical dilemma for design houses: seeking to build externally accessible LLMs offering competitive Verilog coding, how can they leverage in-house IP to enhance FT utility while ensuring IP protection? For the first time in the literature, we study this dilemma. Using LLaMA 3.1-8B, we conduct in-house FT on a baseline Verilog dataset (RTLCoder) supplemented with our own in- house IP, which is validated through multiple tape-outs. To rigorously assess IP leakage, we quantify structural similarity (AST Dolos) and functional equivalence (Synopsys Formality) between generated codes and our in-house IP. We show that our IP can indeed be leaked, confirming the threat. As defense, we evaluate logic locking of Verilog codes (ASSURE). This offers some level of protection, yet reduces the IP s utility for FT and degrades the LLM s performance. Our study shows the need for novel strategies that are both effective and minimally disruptive to FT, an essential effort for enabling design houses to fully utilize their proprietary IP toward LLM-driven Verilog coding. Codes are available at Index Terms Large Language Models, Verilog Code Genera- tion, Data Extraction, IP Protection, Logic Locking I. INTRODUCTION LLMs such as GPT [1], BERT [2], and LLaMA3 [3] are a significant evolution for ML [4]. They have excelled in diverse tasks, including document summarization, language translation, and code generation. Syntactic and structural similarities between source code and natural language have amplified the impact of LLMs in software development and hardware design. LLMs such as GitHub Copilot [5] and OpenAI Codex [6] are used in software development. Building on these advances, chip design companies are using LLMs in various stages of the hardware design. For example, NVIDIA ChipNeMo generates EDA scripts [7], Cadence ChipGPT accelerates RTL coding [8], Synopsys.ai Copilot supports verification and design [9], and RapidGPT supports FPGA design automation [10]. Despite their remarkable success, they also present se- curity concerns, including backdoor attacks [11], [12], and intellectual property (IP) leakage [13], [14]. IP leakage is a significant concern in particular, as LLMs are trained on Both authors contributed equally to this work. Fig. 1. A VeriLeaky LLM can regenerate sensitive IP modules from their training data. This example from our work, based on LLaMA 3.1-8B, demonstrates that IP disclosure leakage to users is a real concern. datasets that include sensitive, proprietary information. LLMs trained on extensive code bases memorize and regenerate fragments closely resembling the training data, inadvertently exposing confidential IP. Notably, [15] examines how LLMs unintentionally leak sensitive IP, including proprietary soft- ware algorithms and code structures. These vulnerabilities are risks also to LLM-driven hardware design. Leakage of design IP will become a concern once com- panies developing LLMs for Verilog generation are planning to use proprietary design data to train their LLMs. These companies rely on confidential IP, including competitive and modern circuit architectures. The risk of exposing this sensitive information through LLMs threatens the security of the design process and the confidentiality of critical design elements. Figure 1 illustrates an example for IP leakage in the context of LLM-driven Verilog code generation. Figure 1(a) showcases a training sample containing sensitive IP from a proprietary dataset. This sample includes Verilog code for a unique circuit design of a modular multiplier using an optimized Barrett reduction algorithm [16]. Figure 1(b) showcases that the model generates a design that closely resembles the sensitive IP in both syntax and functionality when given a particular prompt, despite the lack of any direct request for the proprietary design, thereby (unintentionally) leaking the design IP. This real-world example clearly showcases the need to evaluate LLM-driven Verilog code generation against IP leakage. Here, we present VeriLeaky, a first-of-its-kind study. We evaluate an open-source LLM (LLaMA 3.1-8B) that is fine- tuned (FT) for Verilog coding against IP leakage. For practical relevance, we utilized the well-known training dataset of RTLCoder [17] as baseline and augment this with curated in-house IPs representing the proprietary design data. We assess IP leakage carefully by means of structural similarity (AST Dolos) and functional equivalence (Synopsys Formality) between the generated codes and the original in-house IP. Our contributions and key findings are summarized as follows. 1) We assess the leakage of the in-house IP for various FT and inference parameters and prompting strategies, revealing substantial leakage with up to 46.52 of the generated codes being similar to the original IP. 2) We evaluate logic locking as countermeasure to protect the IPs during FT, achieving up to 13.84 leakage reduction. Through comprehensive analysis, however, we find that reductions vary significantly across locking strategies, prompting techniques, and FT approaches. 3) We also find that locking notably undermines the utility of the in-house IP toward high-quality code generation, by up to 10.81 lower rates. Ultimately, more advanced IP protection schemes are called for. II. BACKGROUND A. LLMs for Hardware Design LLMs have revolutionized hardware design, particularly in the area of Verilog coding [18]. Frameworks such as RTL- Coder [17] leverage GPT to create instruction-code pairs from carefully curated datasets, demonstrating superior performance compared to GPT-3.5 in benchmark evaluations. Domain adaptation has emerged as a key strategy, with approaches like VeriGen [19] running FT with CodeGen-16B [20] on specialized Verilog repositories, or ChipNemo [7] enhancing LLaMA2 [21] by using both public resources and proprietary NVIDIA designs. These advancements clearly demonstrate that FT techniques and strategic data augmentation are es- sential for high-quality LLM-driven hardware design. Recent work has also considered agentic systems [22], [23]. Furthermore, verification has progressed through specialized adaptations [24] [26], while assertion techniques [27], [28] extend LLMs toward formal verification. Strategic prompt engineering [8], [29], [30] enhances performance, with for example [7], [8], [31] automating complex EDA tasks. Eval- uation frameworks address key challenges like reproducibility through metrics, and are utilized in RTLLM [32], VerilogEval [33], [34], and OpenLLM-RTL [35]. B. Security Concerns with LLMs LLMs have shown remarkable proficiency in code genera- tion and other tasks. However, their indiscriminate integration introduces significant vulnerabilities [36]. For example, [13], [14], [37], [38] all show that LLMs can inadvertently expose sensitive information, making privacy a critical concern. There are three types of privacy attacks on LLMs. First, membership inference attacks [15], [39], [40] attempt to determine whether specific code samples were part of an LLM s training dataset. Second, backdoor attacks [11], [41] inject malicious code snippets into the training dataset, compromising the model to generate insecure codes. Third, data extraction attacks [39], [42], [43] extract sensitive information from model outputs or internal representations. When users gain access to FT models, they can extract personally identifiable information or proprietary IP, posing a significant risk. Despite this extensive research on privacy attacks for soft- ware code generation, the related threats for Verilog coding and hardware design in general remain largely unexplored, aside from recent works. For example, [44] investigates back- door attacks that poison LLMs to generate malicious hardware triggers and payloads, and [45] demonstrate how LLMs can be prompted to generate hardware designs that evade piracy detection tools. However, no prior work has specifically ad- dressed the leakage of custom IP used for FT. C. Logic Locking Logic Locking is a design-for-trust technique against various attacks. Traditionally, locking is implemented on technology-mapped gate-level netlists. Recent works also allow to lock at RTL to obfuscate functionality. Adapt- ing concepts from software obfuscation like control-flow graphs, TAO [46] supports locking during high-level synthesis (HLS) but requires access to HLS internals. In contrast, ASSURE [47] locks RTL codes directly, making it more prac- tical. ASSURE works by first generating abstract syntax trees (ASTs) for codes to lock. Analyzing these ASTs, ASSURE then identifies constants, branches, and operations and locks them as follows. For a constant of c bits, ASSURE replaces this with a variable derived from c bits from an additional key input. For a branch condition, ASSURE delegates this to a randomized XOR XNOR locking gate, with the key bit controlling the selection of condition values. For operations, ASSURE obfuscates this by MUXing in a second dummy operation for the same inputs and outputs. III. THREAT MODEL AND RESEARCH QUESTIONS Consider the following real-world scenario. A design house seeks to build an LLM offering Verilog coding as an externally accessible service. They understand that FT with high-quality Verilog data is essential (Sec. II-A), especially when striving for best-in-class offering. Thus, they want to utilize their proven in-house IP, labeled as dataset DIP. Since DIP is a proprietary and valuable asset, they conduct only in-house FT. The threat we consider here is data extraction (Sec. II-B). The key research question, RQ1, is whether DIP may be leaked through LLM inference by external users, be they benign or malicious. Presuming some leakage occurs, another research question, RQ2, is whether the design house can effectively protect DIP, e.g., by logic locking (Sec. II-C). A related third question, RQ3, is whether the employed protection allows the design house to still benefit from the data s utility for FT. We assume users access the LLM only via some prompting interface. For conservative worst-case assessment of the threat, we also assume users have access to the very same instruction wording used during FT, labeled as prompt Porig IP . 20 categories in total including miscellaneous designs Fig. 2. Composition of our curated in-house IP dataset. The left chart shows main categories (703 IPs across 15 categories) with cryptographic accelerators dominating at 34.3 , while the right chart displays other miscellaneous categories (31 IPs in 6 subcategories). IV. EVALUATION A. Experimental Setup In-House IP. To establish high practical relevance for our work, we curate a dataset DIP of 703 in-house IP modules. This dataset was carefully devised over the years, through real- world research projects that have also resulted in multiple tape- outs [48] [54]. Figure 2 shows the diversity of DIP, covering both specialized and generic domains. LLM, FT, and Inference. Without loss of generality, we utilize LLaMA 3.1-8B, a SOTA open-source foundational model. We opt for an open-source model for ease of in-house FT, which is essential to prevent leaking sending out the in- house IP in the first place (Sec. III). We employ instruction-based FT for Verilog coding through the RTLCoder [17] framework, for two distinct scenarios: Using only the RTLCoder dataset Dbase, producing a family of baseline models Mbase; Using Dbase along with our in-house IP DIP (Dbase DIP), producing a family of custom models MIP base. For instruc- tions related to DIP, we include module names, ports, and high-level comments. We systematically vary FT and inference parameters: using the Adam optimizer, with epochs (e) {1, 2, 3}, and learning rate (lr) {1e 4, 1e 5, 1e 6}; temperature (t) {0.6, 0.8, 1.0}, with fixed top-p 0.95. Note that prompting strategies are described in Sec. IV-B. Locking. We utilize ASSURE [47], a SOTA technique that was specifically proposed for locking at RTL. We obtain a family of datasets Dlocked(IP) by locking our in-house IP DIP following four different strategies supported by ASSURE. 1) L50 all : locking all components (i.e., constants, operations, and branches) for 50 of the maximal possible key-size; 2) L100 all : locking all components for 100 of the key-size; 3) L50 const: locking only constants for 50 of the key-size; 4) L100 const : locking only constants for 100 of the key-size. Table I shows the number modules successfully locked under each strategy. While most could be locked across all TABLE I COMPATIBILITY OF IN-HOUSE IP WITH ASSURE STRATEGIES Modules L50 all (DIP) L100 all (DIP) L50 const(DIP) L100 const (DIP) Locked Original 544 139 551 132 513 170 524 159 strategies, some complex modules are incompatible with the Icarus tool [55] used in ASSURE. To maintain the balance of IP composition across all datasets in Dlocked(IP), any module that could not be locked was added in its original form. FT on Locked IP. In a separate set of experiments, FT is conducted on Dbase Dlocked(IP). This provides Mlocked(IP) base , another family of custom models that protects the in-house IP. FT follows the approach as before, but is further differentiated in terms of information provided for FT instructions: 1) with the key input and its correct value (w k), vs 2) without the key input and its value (w o-k). To maintain both practical relevance and scalability, we do not build up Mlocked(IP) base in full,1 but only for selected cases corresponding to high quality observed in MIP base. Thus, only after the assessment of MIP base, we run FT on Dlocked(IP) Dbase for specific sets of FT parameters (e, lr, t), but for all 4 2 8 combinations of locking strategies and instruction settings. Implementation. All LLM runs were conducted on an HPC facility, using an NVIDIA A100 GPU (80GB) with CUDA 12.2. All assessment techniques as well as data analysis were operated on an RHEL server tailored for industrial- grade hardware design, with a 128-core AMD EPYC 7542 CPU setup and 1TB RAM. Synopsys Formality was run with version T-2022.03-SP2. B. Assessment Techniques and Prompting Strategies Leakage Assessment. We utilize two techniques: 1) AST similarity, using Dolos [56]; 2) formal equivalence, using Synopsys Formality. These two techniques are complementary, enabling a robust assessment. AST similarity is focused on syntax; it is more expressive for explicit leakage extraction of memorized data. Formal equivalence is domain-specific and more comprehen- sive: it quantifies the functional similarity of Verilog codes irrespective of their syntax and, thus, is more expressive for implicit leakage data extraction from LLM generalizations. For both techniques, generated Verilog codes are compared against their golden counterparts from DIP (or Dlocked(IP)). For 1), we derive similarity scores ss [ ] based on matches of Dolos-generated AST fingerprints. Referencing [13], we employ a more stringent threshold of ss 0.6 for classifying a generated code as leaky. We report the resulting pass rate averaged over all IP modules. For 2), we derive equivalence ratios eq [ ] based on matches for Formality-generated com- parison points, which cover module ports and all sequential elements. We do not postulate a threshold for eq but report it directly, averaged over all IP modules. 1This would require to consider all 3 3 3 27 combinations of FT param- eters, all 4 locking strategies, and the 2 instruction settings, resulting in 216 scenarios for FT. Furthermore, each of the 703 modules requires 10 inference runs for assessment, which would result in more than 1.5 million runs in total. Prompting for Leakage Assessment. As defined in Sec. III, we utilize Porig IP for a conservative, worst-case as- sessment of leakage in MIP base and Mlocked(IP) base . For Mlocked(IP) base , we further extend and differentiate prompts as follows: 1) instr (I): Porig IP as is; 2) instr key name (I K): Porig IP along with the name of the key-bits input port; 3) instr key name key length (I K L): Porig IP along with the name of the key-bits input port and its length in bits; 4) instr key name key value (I K V): Porig IP along with the name of the key-bits input port and its correct value. These different prompts are important to understand the impact of locking-related information for inducing leakage. Quality Assessment. We devise an extended tech- nique as follows. We use the same metric as in the original work [33], i.e., an unbiased estimator that at least 1 of the k samples passes, but we revise the underlying check.2 We utilize eq with a threshold of 80 for rating a generated code as passing.3 We label the final outcome as eq 0.8). Prompting for Quality Assessment. For assessment of Mbase and MIP base (and Mlocked(IP) base ), we use GPT-4o to individ- ually summarize modules in DIP (and Dlocked(IP)), resulting in a family of prompts PGPT IP . We instruct GPT to maintain module names, ports, and high-level descriptions, but drop any further details. Thus, for Mlocked(IP) base , only the names of key-bit inputs are covered, which differs from the prompts established above for leakage assessment. In addition to PGPT IP , we also consider Phuman IP , a human-generated dataset of prompts for MIP base. See Fig. 9 in the appendix for some examples. We run all inferences 10 times, i.e., n 10 for C. Case Study I: Quality for Code Generation Setting. Here we confirm the benefits of using in-house IP for FT. All experiments here relate to PGPT IP ; results for Phuman IP are provided in the appendix. We measure quality across all 27 models in MIP base, i.e., while sweeping the 3 3 3 combinations for FT and inference parameters (e, lr, t). We also measure quality for all 27 models in Mbase and contrast with MIP base. Results. Figure 3 shows the quality of code generation for MIP base across FT and inference parameters. The highest quality is obtained for e 3, lr 1e 5, t 0.6, with and respectively. The resulting top-1 model is referred to as m1IP base in the remainder. In general, lr is the 1st most dominant factor, t the 2nd, and e the 3rd, respectively. Even for episodes, the least dominant factor, e 3 results in highest quality across all combinations 2This is required for practical reasons as follows. First, [33] uses the Icarus tool [55]; as indicated, some of our in-house IP modules are complex and not supported by Icarus. Second, [33] realizes checks by module- level testbench simulations. Most of our in-house IP modules are part of hierarchical SoC projects, which must be tested at system level. 3We consider this deviation from 100 perfect equivalence as justified due to the following. First, based on experience, Formality sometimes evaluates ports with different names but equivalent functionalities as mismatching. Second, the testbench-driven pass checks in [33] is subject to the quality of test patterns and test cases, i.e., it is unlikely to reach the same level of thorough assessment that Formality enforces in the first place. Fig. 3. Quality for MIP base, measured in eq 0.8) [ ]. Fig. 4. Quality for Mbase, measured in eq 0.8) [ ]. of lr and t. These consistently strong trends confirm that using DIP for FT is practical and provides predictable benefits for high-quality code generation. Figure 4 shows the quality of code generation for Mbase, i.e., from FT without our in-house IP. Trends for FT and inference parameters are largely the same as for MIP base, although t 0.8 is more relevant for highest quality. This is reasonable, as Mbase can benefit from more creativity when tasked to generate codes for the unknown domain of DIP. On average, the gains of MIP base over Mbase are 1.44 percent- age points ( pt) for 2.24 pt for 3.79 pt for and 5.43 pt for respectively. First, this reconfirms the benefits of using DIP for FT toward high- quality code generation. Second, the arguably moderate gap to MIP base indicates that DIP is not an entirely unknown domain for Mbase. This is expected: despite the diverse and complex nature and the industrial-grade coding process for DIP, most components still follow prior art to some degree, which may be covered by Mbase or even the underlying LLaMA 3.1-8B. When looking into each model separately, we find that m1IP base also provides the largest individual gains, namely 4.80 pt for 6.88 pt for 9.21 pt for and 11.28 pt for respectively. This reconfirms m1IP base as the overall best model. D. Case Study II: Leakage of In-House IP Setting. Here we confirm the threat of IP leakage, i.e., we show RQ1 to be true. For thorough assessment, we study leak- age of all 27 models in MIP base, measuring formal equivalence and AST pass rate of generated codes against DIP. Fig. 5. Leakage for MIP base, in formal equivalence to DIP [ ]. TABLE II LEAKAGE FOR MIP BASE IN AST PASS RATE OVER DIP [ ] e 1 e 2 e 3 lr t 0.6 0.8 1.0 0.6 0.8 1.0 0.6 0.8 1.0 1e 4 15.93 13.37 6.83 23.33 19.91 15.36 22.62 18.49 13.09 1e 5 27.03 25.32 13.51 32.72 28.73 24.47 37.98 35.99 31.01 1e 6 29.87 24.18 13.66 29.02 22.76 14.51 32.01 24.61 15.65 Results. Figure 5 shows the leakage for MIP base, measured in formal equivalence, across FT and inference parameters. We observe significant leakage throughout, with min, max, and avg equivalence of 18.32 , 46.53 , and 32.16 , re- spectively. Leakage increases for t {0.6, 0.8}, lr {1e 5, 1e 6}, and e 3, except for the outlier with highest leakage (t 1.0, lr 1e 6, and e 1). Thus, the trends for leakage follow those for quality only loosely. Table II reports the leakage for MIP base measured in AST pass rate, across the same FT and inference parameters. For e 3, lr 1e 5, and t 0.6, the rate reaches its maximum at 37.98 . Recall that these parameters resulted in the top-1 model m1IP base, implying that high quality and direct leakage go together. Lower t values consistently lead to higher rates leakage, while higher lr values do not show a clear trend; lr 1e 5 maintains the largest leakage. Along with the above findings for formal equivalence, i.e., implicit leakage correlates somewhat loosely with high quality, this implies that the main mechanism for leakage is indeed data memorization, but this is subject to variations imperfections, leading to some functionality mismatches. E. Case Study III: Impact of Locking on Leakage Setting. Here we study the risk remaining after using locked in-house IP for FT, i.e., we measure leakage for Mlocked(IP) base . We utilize formal equivalence and AST pass rate again, but now comparing generated codes against Dlocked(IP). We contrast findings with those for MIP base. We show RQ2 to be both true and false, i.e., locking can protect from IP leakage, but only if implemented carefully. Recall that Mlocked(IP) base is built up by (i) picking FT param- eters that provided high quality in MIP base and (ii) running FT with those parameters on Dlocked(IP), along with further locking- specific FT settings. For (i), we consider the parameters from m1IP base and, without loss of generality, those from m4IP base. We Fig. 6. Leakage for Mlocked(IP) base built from m1IP base, in formal equivalence to Dlocked(IP) [ ]. Fig. 7. Leakage for Mlocked(IP) base built from m4IP base, in formal equivalence to Dlocked(IP) [ ]. pick the latter for its variance in FT parameters,4 and for the fact that its leakage is the same as m1IP base. That is, given some constant leakage in MIP base, we shall explore the role of varying FT parameters for leakage in Mlocked(IP) base . For (ii), we consider all 4 2 8 combinations of locking and FT strategies, and also the 4 prompting strategies devised for robust leakage assessment (Sec. IV-B), resulting in 32 scenarios in total. Results. Figures 6 and 7 show leakage for two separate fam- ilies of Mlocked(IP) base related to m1IP base and m4IP base, respectively. Leakage is reduced notably thanks to locking, namely on average by 9.58 pt related to m1IP base and by 9.87 pt related to m4IP base, respectively. However, leakage trends across the two families vary significantly for different locking, FT, and prompting strategies, as discussed next. For the family Mlocked(IP) base related to m4IP base, we find that L50 const for FT w o-k (i.e., correct key values are not provided during FT) and L100 const for FT w k provide similar ranges for overall worst reductions, namely 3.18 pt and 4.87 pt, respectively. L50 all and L100 all , both for FT w o-k, provide similar ranges for overall best reductions of 13.13 pt and 13.84 pt, respectively. For prompting strategies, we find that leakage increases with more information on locking provided, albeit without consistent trends. Locking of all components is confirmed as least leaky across all prompting strategies, with some variations across locking scales and FT strategies. These trends follow the expectations that (i) more locking, (ii) skipping correct key values for FT, and (iii) prompting with less information should all hinder leakage more effectively. For the family Mlocked(IP) base related to m1IP base, we find that L50 all provides the worst reduction of 6.29 pt, whereas L50 const provides the best reduction of 13.27 pt, in both cases irre- spective of the FT strategies (w k vs w o-k). Furthermore, 4Model m4IP base is the 4th best in MIP base for quality, but the first with more varied FT parameters: m4IP base arises from e 2, lr 1e 5, t 0.8, whereas the top-3 models all arise from e 3, lr 1e 5. TABLE III LEAKAGE FOR MLOCKED(IP) BASE IN AST PASS RATE OVER DLOCKED(IP) [ ] With Key (w k) Without Key (w o-k) m1IP base I K I K L I K V I I K I K L I K V I all-50 31.63 31.33 31.19 32.06 36.01 32.36 31.19 32.79 all-100 26.06 27.97 32.36 25.47 37.77 34.55 32.95 30.46 const-50 32.21 21.52 30.16 31.77 31.04 30.01 30.16 32.79 const-100 22.40 19.03 24.16 26.21 31.48 24.30 24.01 33.09 m4IP base I K I K L I K V I I K I K L I K V I all-50 27.52 27.96 27.38 22.55 26.06 23.87 25.48 24.45 all-100 20.94 21.96 23.57 20.50 26.65 23.87 25.18 28.11 const-50 27.38 20.20 21.96 21.38 27.23 25.33 27.53 22.99 const-100 29.14 18.59 28.40 26.21 26.35 25.33 25.04 24.74 Recall Sec. IV-B: I: instr Porig IP ; K: key name; L: key length; V: key value. L50 const enables larger reductions than L100 const . These trends are unexpected at first, as locking all components larger scales enables wider obfuscation of the in-house IP. Looking into the designs generated after FT w o-k, we find that the locking implementation is skipped more often for L100 const than L50 const, i.e., the IP protection is bypassed. This implies that larger keys are more difficult to comprehend for FT when the correct values are not provided, which is expected. Unlike before (Mlocked(IP) base related to m1IP base), where such skipping of locking did not occur, we hypothesize that the less competitive parameters of m4IP base here result in such leakage-inducing quality issues during code generation. Regarding prompting strategies, we find again that leakage increases with more information on locking. Providing the name of the key-bits input has a strong impact, whereas other information contributes less consistently. L50 const is reconfirmed as least leaky across the prompting strategies, with some variations for FT strategies. Table III reports average reductions in AST pass rate for leakage of 6.90 related to m1IP base and of 2.32 related to m4IP base, respectively. The above hypothesis for leakage- inducing quality issues is confirmed by the lower reductions of direct leakage related to m4IP base. FT w k shows inconsistent trends, e.g., with L50 const related to m1IP base varying by up-to 15.58 but L100 const related to m4IP base varying by up-to 10.55 . In contrast, FT w o-k provides more predictable reductions In short, while locking in-house IP before FT can mitigate leakage to a good degree, this requires a careful assessment of locking and FT strategies, along with consideration of various possible prompting strategies by adversaries. Otherwise, the benefits of locking cannot be guaranteed. F. Case Study IV: Impact of Locking on Quality Setting. Here we study the impact of using locked in-house IP for FT on code generation performance, i.e., we measure quality for Mlocked(IP) base . We show RQ3 to be largely false. We again cover all models arising from all 8 combinations of locking and FT strategies. We contrast with findings for MIP base. Results. Figure 8 shows the quality of code generation for Mlocked(IP) base built from m1IP base. Quality has degraded notably due to locking, namely by 10.81 pt on average. Fig. 8. Quality for Mlocked(IP) base built from m1IP base, eq 0.8) [ ]. The least degradation highest quality occurs for L50 const and FT w o-k, whereas the largest degradation occurs for L100 all and FT w k. Regarding locking strategies, both results are expected: locking fewer (more) components at smaller (larger) scales leaves more (less) components unobfuscated, which FT can benefit more (less) from. Regarding FT strategies, the fact that leaving out correct key values improves quality might seem counter-intuitive at first. Examining codes generated for the case of L50 const, we find that FT w o-k provides 9.95 more locked designs than FT w k. In contrast, L100 const under FT w o-k generates only 1.97 more locked designs. Comparing to L50 all and L100 all , which generate on average 7.57 more locked designs, this confirms that code quality under FT w o-k is indeed superior to FT w k and indicates that this is due to the quality of the generated locking implementations. For the locking and FT strategies in general, we find the following. When locking all components, quality increases from L100 all to L50 all and from FT w k to FT w o-k, which is both in line with prior observations. When locking constants only, however, quality increases from L50 const to L100 const for FT w k, yet decreases for FT w o-k. This implies that an understanding of actual key values is relevant for FT when locking constants. Still, FT w o-k is the most dominant factor for higher quality across the board. Note that we present and discuss the quality of code generation for Mlocked(IP) base built from m4IP base in the appendix. V. CONCLUSION We present VeriLeaky, the first study that carefully explores leakage-vs-quality trade-offs arising for FT of LLMs with proprietary in-house IP. Our findings confirm the significant risk of leakage (RQ1: yes), evidenced by substantial structural and functional similarity between generated codes and the in-house IP. While logic locking offers some potential, its effectiveness is rather fragile (RQ2: yes and no), as it highly depends on the locking strategy and parameters employed during FT, as well as on the details provided for inference prompting. Locking also reduces the utility of the IP for FT and consequently degrades the LLM s performance (RQ3: no). Future work should explore alternative techniques toward more effective IP protection and less disruptive FT. This could include watermarking (to prove but not hinder leakage) or privacy-preserving FT, all specifically for Verilog coding and with delicate leakage-vs-quality trade-offs in mind. REFERENCES [1] OpenAI, GPT-4, Mar. 2023. Available: gpt-4 [2] J. Devlin et al., Bert: Pre-training of deep bidirectional transformers for language understanding, 2019. Available: 04805 [3] A. Grattafiori et al., The llama 3 herd of models, 2024. Available: [4] M. Shao et al., Survey of different large language model architectures: Trends, benchmarks, and challenges, IEEE Access, 2024. [5] GitHub, Github copilot - your ai pair programmer, 2022. Available: [6] M. Chen et al., Evaluating large language models trained on code, arXiv preprint arXiv:2107.03374, 2021. [7] M. Liu et al., Chipnemo: Domain-adapted llms for chip design, arXiv preprint arXiv:2311.00176, 2023. [8] K. Chang et al., Chipgpt: How far are we from natural language hardware design, arXiv preprint arXiv:2305.14019, 2023. [9] Synopsys showcases, [10] Primis.ai, [11] R. Schuster et al., You autocomplete me: Poisoning vulnerabilities in neural code completion, in 30th USENIX Security Symposium (USENIX Security 21), 2021, pp. 1559 1575. [12] H. Aghakhani et al., Trojanpuzzle: Covertly poisoning code-suggestion models, in IEEE S P, 2024, pp. 1122 1140. [13] Z. Yu et al., Codeipprompt: intellectual property infringement assess- ment of code language models, in International conference on machine learning, 2023, pp. 40 373 40 389. [14] A. F. Noah et al., Codecloak: A method for evaluating and mitigating code leakage by llm code assistants, arXiv preprint arXiv:2404.09066, 2024. [15] L. Niu et al., {CodexLeaks}: Privacy leaks from code generation language models in {GitHub} copilot, in 32nd USENIX Security Symposium (USENIX Security 23), 2023, pp. 2133 2150. [16] A. J. Menezes et al., Handbook of applied cryptography. CRC press, 2018. [17] S. Liu et al., Rtlcoder: Outperforming gpt-3.5 in design rtl generation with our open-source dataset and lightweight solution, 2024. Available: [18] Z. Wang et al., Llms and the future of chip design: Unveiling security risks and building trust, in 2024 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), 2024, pp. 385 390. [19] S. Thakur et al., Verigen: A large language model for verilog code generation, ACM TODAES, 2023. [20] E. Nijkamp et al., Codegen: An open large language model for code with multi-turn program synthesis, 2023. Available: [21] H. Touvron et al., Llama 2: Open foundation and fine-tuned chat models, arXiv preprint arXiv:2307.09288, 2023. [22] S. Thakur et al., Autochip: Automating hdl generation using llm feedback, arXiv preprint arXiv:2311.04887, 2023. [23] F. Cui et al., Origen: Enhancing rtl code generation with code-to-code augmentation and self-reflection, arXiv preprint arXiv:2407.16237, 2024. [24] R. Qiu et al., Autobench: Automatic testbench generation and evalua- tion using llms for hdl design, in Proceedings of the 2024 ACM IEEE International Symposium on Machine Learning for CAD, 2024, pp. 1 10. [25] J. Bhandari et al., Llm-aided testbench generation and bug detection for finite-state machines, arXiv preprint arXiv:2406.17132, 2024. [26] R. Qiu et al., Correctbench: Automatic testbench generation with functional self-correction using llms for hdl design, arXiv preprint arXiv:2411.08510, 2024. [27] R. Kande et al., Llm-assisted generation of hardware assertions, arXiv preprint arXiv:2306.14027, 2023. [28] W. Fang et al., Assertllm: Generating and evaluating hardware verifica- tion assertions from design specifications via multi-llms, arXiv preprint arXiv:2402.00386, 2024. [29] J. Blocklove et al., Chip-chat: Challenges and opportunities in conver- sational hardware design, in 2023 ACM IEEE 5th Workshop on Machine Learning for CAD (MLCAD). IEEE, Sep. 2023. [30] Y. Fu et al., Gpt4aigchip: Towards next-generation ai accelerator design automation via large language models, in 2023 IEEE ACM International Conference on Computer Aided Design (ICCAD), 2023, pp. 1 9. [31] H. Wu et al., Chateda: A large language model powered autonomous agent for eda, IEEE Transactions on Computer-Aided Design of Inte- grated Circuits and Systems, 2024. [32] Y. Lu et al., Rtllm: An open-source benchmark for design rtl generation with large language model, in 2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC), 2024, pp. 722 727. [33] M. Liu et al., Verilogeval: Evaluating large language models for verilog code generation, in 2023 IEEE ACM International Conference on Computer Aided Design (ICCAD), 2023, pp. 1 8. [34] N. Pinckney et al., Revisiting verilogeval: Newer llms, in-context learn- ing, and specification-to-rtl tasks, arXiv preprint arXiv:2408.11053, 2024. [35] S. Liu et al., Openllm-rtl: Open dataset and benchmark for llm-aided design rtl generation, 2024. [36] H. Pearce et al., Asleep at the keyboard? assessing the security of github copilot s code contributions, Communications of the ACM, vol. 68, no. 2, pp. 96 105, 2025. [37] Z. Ji et al., Unlearnable examples: Protecting open-source software from unauthorized neural code learning. in SEKE, 2022, pp. 525 530. [38] H. Du et al., Privacy in fine-tuning large language models: Attacks, defenses, and future directions, arXiv preprint arXiv:2412.16504, 2024. [39] N. Carlini et al., Extracting training data from large language models, in 30th USENIX security symposium (USENIX Security 21), 2021, pp. 2633 2650. [40] Z. Sun et al., Coprotector: Protect open-source code against unautho- rized training usage with data poisoning, in Proceedings of the ACM Web Conference 2022, 2022, pp. 652 660. [41] H. Yang et al., A comprehensive overview of backdoor attacks in large language models within communication networks, IEEE Network, 2024. [42] R. Liu et al., Precurious: How innocent pre-trained language models turn into privacy traps, in Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security, 2024, pp. 3511 3524. [43] M. S. Ozdayi et al., Controlling the extraction of memorized data from large language models via prompt-tuning, arXiv preprint arXiv:2305.11759, 2023. [44] L. L. Mankali et al., Rtl-breaker: Assessing the security of llms against backdoor attacks on hdl code generation, arXiv preprint arXiv:2411.17569, 2024. [45] V. Gohil et al., Llmpirate: Llms for black-box hardware ip piracy, arXiv preprint arXiv:2411.16111, 2024. [46] C. Pilato et al., Tao: Techniques for algorithm-level obfuscation dur- ing high-level synthesis, in Proceedings of the 55th Annual Design Automation Conference, 2018, pp. 1 6. [47] C. Pilato et al., Assure: Rtl locking against an untrusted foundry, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 29, no. 7, pp. 1306 1318, 2021. [48] M. Yasin et al., Provably-secure logic locking: From theory to practice, in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS 17. New York, NY, USA: Association for Computing Machinery, 2017, p. 1601 1618. Available: [49] M. Nabeel et al., Cophee: Co-processor for partially homomorphic en- crypted execution, in 2019 IEEE International Symposium on Hardware Oriented Security and Trust (HOST), 2019, pp. 131 140. [50] N. Limaye et al., Antidote: Protecting debug against outsourced test entities, IEEE Transactions on Emerging Topics in Computing, vol. 10, no. 3, pp. 1507 1518, 2022. [51] M. Nabeel et al., Cofhee: A co-processor for fully homomorphic encryption execution, in 2023 Design, Automation Test in Europe Conference Exhibition (DATE), 2023, pp. 1 2. [52] M. Nabeel et al., Exploring constrained-modulus modular multipliers for improved area, power and flexibility, in IFIP IEEE International Conference on Very Large Scale Integration-System on a Chip, 2023, pp. 93 108. [53] D. Soni et al., Quantifying the overheads of modular multiplication, in 2023 IEEE ACM International Symposium on Low Power Electronics and Design (ISLPED), 2023, pp. 1 6. [54] D. Soni et al., Design space exploration of modular multipliers for asic fhe accelerators, in 2023 24th International Symposium on Quality Electronic Design (ISQED), 2023, pp. 1 8. [55] S. Icarus, Icarus Verilog, [56] R. Maertens et al., Discovering and exploring cases of educational source code plagiarism with dolos, SoftwareX, vol. 26, p. 101755, 2024. APPENDIX A SUPPLEMENTARY MATERIALS Figure 9 shows some examples for prompting for quality assessment. Figure 10 shows the quality of code generation for MIP base across FT and inference parameters, for prompts Phuman IP . Overall, quality is notably lower than for prompts PGPT IP (Fig. 3). Due to, on average, less comprehensive human descriptions (Fig. 9), this is expected; it is also a common observation throughout the literature. Furthermore, we find that lr 1e 5 is still the most dominant factor, whereas trends for t and e are less clear as with PGPT IP , which reconfirms the more fragile nature of Phuman IP prompting. 𝒫IP GPT 𝒫IP human : Prompt generated by Human : Prompt generated by Machine (GPT-4o) Fig. 9. Prompt examples for a Radix-2 Butterfly IP module. Fig. 10. Quality for MIP base using Phuman IP , measured in eq 0.8) [ ]. Fig. 11. Quality for Mlocked(IP) base built from m4IP base, eq 0.8) [ ]. Figure 11 shows the quality of code generation for Mlocked(IP) base built from m4IP base. Quality has degraded notably also here due to locking, namely by 6.77 pt on average. Trends are similar to those for Mlocked(IP) base built from m1IP base (Fig. 8), reconfirming the delicate impact of the locking strategy and parameters employed during FT, as well as the details provided for inference prompting.\n\n=== SEGMENTS ===\n\n--- Segment 1 ---\narXiv:2503.13116v4 [cs.CR] 17 Jun 2025 VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding Zeng Wang , Minghao Shao , Mohammed Nabeel , Prithwish Basu Roy , Likhitha Mankali , Jitendra Bhandari , Ramesh Karri , Ozgur Sinanoglu , Muhammad Shafique , Johann Knechtel NYU Tandon School of Engineering, USA NYU Abu Dhabi, UAE Email:{zw3464, shao.minghao, mtn2, pb2718, likhitha.mankali, jb7410, rkarri, ozgursin, muhammad.shafique, Abstract Large language models (LLMs) offer significant potential for coding, yet fine-tuning (FT) with curated data is essential for niche languages like Verilog. Using proprietary intellectual property (IP) for FT presents a serious risk, as FT data can be leaked through LLM inference. This leads to a critical dilemma for design houses: seeking to build externally accessible LLMs offering competitive Verilog coding, how can they leverage in-house IP to enhance FT utility while ensuring IP protection? For the first time in the literature, we study this dilemma. Using LLaMA 3.1-8B, we conduct in-house FT on a baseline Verilog dataset (RTLCoder) supplemented with our own in- house IP, which is validated through multiple tape-outs. To rigorously assess IP leakage, we quantify structural similarity (AST Dolos) and functional equivalence (Synopsys Formality) between generated codes and our in-house IP. We show that our IP can indeed be leaked, confirming the threat. As defense, we evaluate logic locking of Verilog codes (ASSURE). This offers some level of protection, yet reduces the IP s utility for FT and degrades the LLM s performance. Our study shows the need for novel strategies that are both effective and minimally disruptive to FT, an essential effort for enabling design houses to fully utilize their proprietary IP toward LLM-driven Verilog coding. Codes are available at Index Terms Large Language Models, Verilog Code Genera- tion, Data Extraction, IP Protection, Logic Locking I.\n\n--- Segment 2 ---\nOur study shows the need for novel strategies that are both effective and minimally disruptive to FT, an essential effort for enabling design houses to fully utilize their proprietary IP toward LLM-driven Verilog coding. Codes are available at Index Terms Large Language Models, Verilog Code Genera- tion, Data Extraction, IP Protection, Logic Locking I. INTRODUCTION LLMs such as GPT [1], BERT [2], and LLaMA3 [3] are a significant evolution for ML [4]. They have excelled in diverse tasks, including document summarization, language translation, and code generation. Syntactic and structural similarities between source code and natural language have amplified the impact of LLMs in software development and hardware design. LLMs such as GitHub Copilot [5] and OpenAI Codex [6] are used in software development. Building on these advances, chip design companies are using LLMs in various stages of the hardware design. For example, NVIDIA ChipNeMo generates EDA scripts [7], Cadence ChipGPT accelerates RTL coding [8], Synopsys.ai Copilot supports verification and design [9], and RapidGPT supports FPGA design automation [10]. Despite their remarkable success, they also present se- curity concerns, including backdoor attacks [11], [12], and intellectual property (IP) leakage [13], [14]. IP leakage is a significant concern in particular, as LLMs are trained on Both authors contributed equally to this work. Fig. 1. A VeriLeaky LLM can regenerate sensitive IP modules from their training data. This example from our work, based on LLaMA 3.1-8B, demonstrates that IP disclosure leakage to users is a real concern. datasets that include sensitive, proprietary information. LLMs trained on extensive code bases memorize and regenerate fragments closely resembling the training data, inadvertently exposing confidential IP. Notably, [15] examines how LLMs unintentionally leak sensitive IP, including proprietary soft- ware algorithms and code structures. These vulnerabilities are risks also to LLM-driven hardware design. Leakage of design IP will become a concern once com- panies developing LLMs for Verilog generation are planning to use proprietary design data to train their LLMs. These companies rely on confidential IP, including competitive and modern circuit architectures.\n\n--- Segment 3 ---\nLeakage of design IP will become a concern once com- panies developing LLMs for Verilog generation are planning to use proprietary design data to train their LLMs. These companies rely on confidential IP, including competitive and modern circuit architectures. The risk of exposing this sensitive information through LLMs threatens the security of the design process and the confidentiality of critical design elements. Figure 1 illustrates an example for IP leakage in the context of LLM-driven Verilog code generation. Figure 1(a) showcases a training sample containing sensitive IP from a proprietary dataset. This sample includes Verilog code for a unique circuit design of a modular multiplier using an optimized Barrett reduction algorithm [16]. Figure 1(b) showcases that the model generates a design that closely resembles the sensitive IP in both syntax and functionality when given a particular prompt, despite the lack of any direct request for the proprietary design, thereby (unintentionally) leaking the design IP. This real-world example clearly showcases the need to evaluate LLM-driven Verilog code generation against IP leakage. Here, we present VeriLeaky, a first-of-its-kind study. We evaluate an open-source LLM (LLaMA 3.1-8B) that is fine- tuned (FT) for Verilog coding against IP leakage. For practical relevance, we utilized the well-known training dataset of RTLCoder [17] as baseline and augment this with curated in-house IPs representing the proprietary design data. We assess IP leakage carefully by means of structural similarity (AST Dolos) and functional equivalence (Synopsys Formality) between the generated codes and the original in-house IP. Our contributions and key findings are summarized as follows. 1) We assess the leakage of the in-house IP for various FT and inference parameters and prompting strategies, revealing substantial leakage with up to 46.52 of the generated codes being similar to the original IP. 2) We evaluate logic locking as countermeasure to protect the IPs during FT, achieving up to 13.84 leakage reduction. Through comprehensive analysis, however, we find that reductions vary significantly across locking strategies, prompting techniques, and FT approaches. 3) We also find that locking notably undermines the utility of the in-house IP toward high-quality code generation, by up to 10.81 lower rates. Ultimately, more advanced IP protection schemes are called for. II.\n\n--- Segment 4 ---\nUltimately, more advanced IP protection schemes are called for. II. BACKGROUND A. LLMs for Hardware Design LLMs have revolutionized hardware design, particularly in the area of Verilog coding [18]. Frameworks such as RTL- Coder [17] leverage GPT to create instruction-code pairs from carefully curated datasets, demonstrating superior performance compared to GPT-3.5 in benchmark evaluations. Domain adaptation has emerged as a key strategy, with approaches like VeriGen [19] running FT with CodeGen-16B [20] on specialized Verilog repositories, or ChipNemo [7] enhancing LLaMA2 [21] by using both public resources and proprietary NVIDIA designs. These advancements clearly demonstrate that FT techniques and strategic data augmentation are es- sential for high-quality LLM-driven hardware design. Recent work has also considered agentic systems [22], [23]. Furthermore, verification has progressed through specialized adaptations [24] [26], while assertion techniques [27], [28] extend LLMs toward formal verification. Strategic prompt engineering [8], [29], [30] enhances performance, with for example [7], [8], [31] automating complex EDA tasks. Eval- uation frameworks address key challenges like reproducibility through metrics, and are utilized in RTLLM [32], VerilogEval [33], [34], and OpenLLM-RTL [35]. B. Security Concerns with LLMs LLMs have shown remarkable proficiency in code genera- tion and other tasks. However, their indiscriminate integration introduces significant vulnerabilities [36]. For example, [13], [14], [37], [38] all show that LLMs can inadvertently expose sensitive information, making privacy a critical concern. There are three types of privacy attacks on LLMs. First, membership inference attacks [15], [39], [40] attempt to determine whether specific code samples were part of an LLM s training dataset. Second, backdoor attacks [11], [41] inject malicious code snippets into the training dataset, compromising the model to generate insecure codes. Third, data extraction attacks [39], [42], [43] extract sensitive information from model outputs or internal representations. When users gain access to FT models, they can extract personally identifiable information or proprietary IP, posing a significant risk.\n\n--- Segment 5 ---\nThird, data extraction attacks [39], [42], [43] extract sensitive information from model outputs or internal representations. When users gain access to FT models, they can extract personally identifiable information or proprietary IP, posing a significant risk. Despite this extensive research on privacy attacks for soft- ware code generation, the related threats for Verilog coding and hardware design in general remain largely unexplored, aside from recent works. For example, [44] investigates back- door attacks that poison LLMs to generate malicious hardware triggers and payloads, and [45] demonstrate how LLMs can be prompted to generate hardware designs that evade piracy detection tools. However, no prior work has specifically ad- dressed the leakage of custom IP used for FT. C. Logic Locking Logic Locking is a design-for-trust technique against various attacks. Traditionally, locking is implemented on technology-mapped gate-level netlists. Recent works also allow to lock at RTL to obfuscate functionality. Adapt- ing concepts from software obfuscation like control-flow graphs, TAO [46] supports locking during high-level synthesis (HLS) but requires access to HLS internals. In contrast, ASSURE [47] locks RTL codes directly, making it more prac- tical. ASSURE works by first generating abstract syntax trees (ASTs) for codes to lock. Analyzing these ASTs, ASSURE then identifies constants, branches, and operations and locks them as follows. For a constant of c bits, ASSURE replaces this with a variable derived from c bits from an additional key input. For a branch condition, ASSURE delegates this to a randomized XOR XNOR locking gate, with the key bit controlling the selection of condition values. For operations, ASSURE obfuscates this by MUXing in a second dummy operation for the same inputs and outputs. III. THREAT MODEL AND RESEARCH QUESTIONS Consider the following real-world scenario. A design house seeks to build an LLM offering Verilog coding as an externally accessible service. They understand that FT with high-quality Verilog data is essential (Sec. II-A), especially when striving for best-in-class offering. Thus, they want to utilize their proven in-house IP, labeled as dataset DIP. Since DIP is a proprietary and valuable asset, they conduct only in-house FT. The threat we consider here is data extraction (Sec.\n\n--- Segment 6 ---\nSince DIP is a proprietary and valuable asset, they conduct only in-house FT. The threat we consider here is data extraction (Sec. II-B). The key research question, RQ1, is whether DIP may be leaked through LLM inference by external users, be they benign or malicious. Presuming some leakage occurs, another research question, RQ2, is whether the design house can effectively protect DIP, e.g., by logic locking (Sec. II-C). A related third question, RQ3, is whether the employed protection allows the design house to still benefit from the data s utility for FT. We assume users access the LLM only via some prompting interface. For conservative worst-case assessment of the threat, we also assume users have access to the very same instruction wording used during FT, labeled as prompt Porig IP . 20 categories in total including miscellaneous designs Fig. 2. Composition of our curated in-house IP dataset. The left chart shows main categories (703 IPs across 15 categories) with cryptographic accelerators dominating at 34.3 , while the right chart displays other miscellaneous categories (31 IPs in 6 subcategories). IV. EVALUATION A. Experimental Setup In-House IP. To establish high practical relevance for our work, we curate a dataset DIP of 703 in-house IP modules. This dataset was carefully devised over the years, through real- world research projects that have also resulted in multiple tape- outs [48] [54]. Figure 2 shows the diversity of DIP, covering both specialized and generic domains. LLM, FT, and Inference. Without loss of generality, we utilize LLaMA 3.1-8B, a SOTA open-source foundational model. We opt for an open-source model for ease of in-house FT, which is essential to prevent leaking sending out the in- house IP in the first place (Sec. III). We employ instruction-based FT for Verilog coding through the RTLCoder [17] framework, for two distinct scenarios: Using only the RTLCoder dataset Dbase, producing a family of baseline models Mbase; Using Dbase along with our in-house IP DIP (Dbase DIP), producing a family of custom models MIP base. For instruc- tions related to DIP, we include module names, ports, and high-level comments.\n\n--- Segment 7 ---\nWe employ instruction-based FT for Verilog coding through the RTLCoder [17] framework, for two distinct scenarios: Using only the RTLCoder dataset Dbase, producing a family of baseline models Mbase; Using Dbase along with our in-house IP DIP (Dbase DIP), producing a family of custom models MIP base. For instruc- tions related to DIP, we include module names, ports, and high-level comments. We systematically vary FT and inference parameters: using the Adam optimizer, with epochs (e) {1, 2, 3}, and learning rate (lr) {1e 4, 1e 5, 1e 6}; temperature (t) {0.6, 0.8, 1.0}, with fixed top-p 0.95. Note that prompting strategies are described in Sec. IV-B. Locking. We utilize ASSURE [47], a SOTA technique that was specifically proposed for locking at RTL. We obtain a family of datasets Dlocked(IP) by locking our in-house IP DIP following four different strategies supported by ASSURE. 1) L50 all : locking all components (i.e., constants, operations, and branches) for 50 of the maximal possible key-size; 2) L100 all : locking all components for 100 of the key-size; 3) L50 const: locking only constants for 50 of the key-size; 4) L100 const : locking only constants for 100 of the key-size. Table I shows the number modules successfully locked under each strategy. While most could be locked across all TABLE I COMPATIBILITY OF IN-HOUSE IP WITH ASSURE STRATEGIES Modules L50 all (DIP) L100 all (DIP) L50 const(DIP) L100 const (DIP) Locked Original 544 139 551 132 513 170 524 159 strategies, some complex modules are incompatible with the Icarus tool [55] used in ASSURE. To maintain the balance of IP composition across all datasets in Dlocked(IP), any module that could not be locked was added in its original form. FT on Locked IP. In a separate set of experiments, FT is conducted on Dbase Dlocked(IP). This provides Mlocked(IP) base , another family of custom models that protects the in-house IP.\n\n--- Segment 8 ---\nIn a separate set of experiments, FT is conducted on Dbase Dlocked(IP). This provides Mlocked(IP) base , another family of custom models that protects the in-house IP. FT follows the approach as before, but is further differentiated in terms of information provided for FT instructions: 1) with the key input and its correct value (w k), vs 2) without the key input and its value (w o-k). To maintain both practical relevance and scalability, we do not build up Mlocked(IP) base in full,1 but only for selected cases corresponding to high quality observed in MIP base. Thus, only after the assessment of MIP base, we run FT on Dlocked(IP) Dbase for specific sets of FT parameters (e, lr, t), but for all 4 2 8 combinations of locking strategies and instruction settings. Implementation. All LLM runs were conducted on an HPC facility, using an NVIDIA A100 GPU (80GB) with CUDA 12.2. All assessment techniques as well as data analysis were operated on an RHEL server tailored for industrial- grade hardware design, with a 128-core AMD EPYC 7542 CPU setup and 1TB RAM. Synopsys Formality was run with version T-2022.03-SP2. B. Assessment Techniques and Prompting Strategies Leakage Assessment. We utilize two techniques: 1) AST similarity, using Dolos [56]; 2) formal equivalence, using Synopsys Formality. These two techniques are complementary, enabling a robust assessment. AST similarity is focused on syntax; it is more expressive for explicit leakage extraction of memorized data. Formal equivalence is domain-specific and more comprehen- sive: it quantifies the functional similarity of Verilog codes irrespective of their syntax and, thus, is more expressive for implicit leakage data extraction from LLM generalizations. For both techniques, generated Verilog codes are compared against their golden counterparts from DIP (or Dlocked(IP)). For 1), we derive similarity scores ss [ ] based on matches of Dolos-generated AST fingerprints. Referencing [13], we employ a more stringent threshold of ss 0.6 for classifying a generated code as leaky. We report the resulting pass rate averaged over all IP modules.\n\n--- Segment 9 ---\nReferencing [13], we employ a more stringent threshold of ss 0.6 for classifying a generated code as leaky. We report the resulting pass rate averaged over all IP modules. For 2), we derive equivalence ratios eq [ ] based on matches for Formality-generated com- parison points, which cover module ports and all sequential elements. We do not postulate a threshold for eq but report it directly, averaged over all IP modules. 1This would require to consider all 3 3 3 27 combinations of FT param- eters, all 4 locking strategies, and the 2 instruction settings, resulting in 216 scenarios for FT. Furthermore, each of the 703 modules requires 10 inference runs for assessment, which would result in more than 1.5 million runs in total. Prompting for Leakage Assessment. As defined in Sec. III, we utilize Porig IP for a conservative, worst-case as- sessment of leakage in MIP base and Mlocked(IP) base . For Mlocked(IP) base , we further extend and differentiate prompts as follows: 1) instr (I): Porig IP as is; 2) instr key name (I K): Porig IP along with the name of the key-bits input port; 3) instr key name key length (I K L): Porig IP along with the name of the key-bits input port and its length in bits; 4) instr key name key value (I K V): Porig IP along with the name of the key-bits input port and its correct value. These different prompts are important to understand the impact of locking-related information for inducing leakage. Quality Assessment. We devise an extended tech- nique as follows. We use the same metric as in the original work [33], i.e., an unbiased estimator that at least 1 of the k samples passes, but we revise the underlying check.2 We utilize eq with a threshold of 80 for rating a generated code as passing.3 We label the final outcome as eq 0.8). Prompting for Quality Assessment. For assessment of Mbase and MIP base (and Mlocked(IP) base ), we use GPT-4o to individ- ually summarize modules in DIP (and Dlocked(IP)), resulting in a family of prompts PGPT IP .\n\n--- Segment 10 ---\nPrompting for Quality Assessment. For assessment of Mbase and MIP base (and Mlocked(IP) base ), we use GPT-4o to individ- ually summarize modules in DIP (and Dlocked(IP)), resulting in a family of prompts PGPT IP . We instruct GPT to maintain module names, ports, and high-level descriptions, but drop any further details. Thus, for Mlocked(IP) base , only the names of key-bit inputs are covered, which differs from the prompts established above for leakage assessment. In addition to PGPT IP , we also consider Phuman IP , a human-generated dataset of prompts for MIP base. See Fig. 9 in the appendix for some examples. We run all inferences 10 times, i.e., n 10 for C. Case Study I: Quality for Code Generation Setting. Here we confirm the benefits of using in-house IP for FT. All experiments here relate to PGPT IP ; results for Phuman IP are provided in the appendix. We measure quality across all 27 models in MIP base, i.e., while sweeping the 3 3 3 combinations for FT and inference parameters (e, lr, t). We also measure quality for all 27 models in Mbase and contrast with MIP base. Results. Figure 3 shows the quality of code generation for MIP base across FT and inference parameters. The highest quality is obtained for e 3, lr 1e 5, t 0.6, with and respectively. The resulting top-1 model is referred to as m1IP base in the remainder. In general, lr is the 1st most dominant factor, t the 2nd, and e the 3rd, respectively. Even for episodes, the least dominant factor, e 3 results in highest quality across all combinations 2This is required for practical reasons as follows. First, [33] uses the Icarus tool [55]; as indicated, some of our in-house IP modules are complex and not supported by Icarus. Second, [33] realizes checks by module- level testbench simulations. Most of our in-house IP modules are part of hierarchical SoC projects, which must be tested at system level. 3We consider this deviation from 100 perfect equivalence as justified due to the following. First, based on experience, Formality sometimes evaluates ports with different names but equivalent functionalities as mismatching.\n\n--- Segment 11 ---\n3We consider this deviation from 100 perfect equivalence as justified due to the following. First, based on experience, Formality sometimes evaluates ports with different names but equivalent functionalities as mismatching. Second, the testbench-driven pass checks in [33] is subject to the quality of test patterns and test cases, i.e., it is unlikely to reach the same level of thorough assessment that Formality enforces in the first place. Fig. 3. Quality for MIP base, measured in eq 0.8) [ ]. Fig. 4. Quality for Mbase, measured in eq 0.8) [ ]. of lr and t. These consistently strong trends confirm that using DIP for FT is practical and provides predictable benefits for high-quality code generation. Figure 4 shows the quality of code generation for Mbase, i.e., from FT without our in-house IP. Trends for FT and inference parameters are largely the same as for MIP base, although t 0.8 is more relevant for highest quality. This is reasonable, as Mbase can benefit from more creativity when tasked to generate codes for the unknown domain of DIP. On average, the gains of MIP base over Mbase are 1.44 percent- age points ( pt) for 2.24 pt for 3.79 pt for and 5.43 pt for respectively. First, this reconfirms the benefits of using DIP for FT toward high- quality code generation. Second, the arguably moderate gap to MIP base indicates that DIP is not an entirely unknown domain for Mbase. This is expected: despite the diverse and complex nature and the industrial-grade coding process for DIP, most components still follow prior art to some degree, which may be covered by Mbase or even the underlying LLaMA 3.1-8B. When looking into each model separately, we find that m1IP base also provides the largest individual gains, namely 4.80 pt for 6.88 pt for 9.21 pt for and 11.28 pt for respectively. This reconfirms m1IP base as the overall best model. D. Case Study II: Leakage of In-House IP Setting. Here we confirm the threat of IP leakage, i.e., we show RQ1 to be true.\n\n--- Segment 12 ---\nD. Case Study II: Leakage of In-House IP Setting. Here we confirm the threat of IP leakage, i.e., we show RQ1 to be true. For thorough assessment, we study leak- age of all 27 models in MIP base, measuring formal equivalence and AST pass rate of generated codes against DIP. Fig. 5. Leakage for MIP base, in formal equivalence to DIP [ ]. TABLE II LEAKAGE FOR MIP BASE IN AST PASS RATE OVER DIP [ ] e 1 e 2 e 3 lr t 0.6 0.8 1.0 0.6 0.8 1.0 0.6 0.8 1.0 1e 4 15.93 13.37 6.83 23.33 19.91 15.36 22.62 18.49 13.09 1e 5 27.03 25.32 13.51 32.72 28.73 24.47 37.98 35.99 31.01 1e 6 29.87 24.18 13.66 29.02 22.76 14.51 32.01 24.61 15.65 Results. Figure 5 shows the leakage for MIP base, measured in formal equivalence, across FT and inference parameters. We observe significant leakage throughout, with min, max, and avg equivalence of 18.32 , 46.53 , and 32.16 , re- spectively. Leakage increases for t {0.6, 0.8}, lr {1e 5, 1e 6}, and e 3, except for the outlier with highest leakage (t 1.0, lr 1e 6, and e 1). Thus, the trends for leakage follow those for quality only loosely. Table II reports the leakage for MIP base measured in AST pass rate, across the same FT and inference parameters. For e 3, lr 1e 5, and t 0.6, the rate reaches its maximum at 37.98 . Recall that these parameters resulted in the top-1 model m1IP base, implying that high quality and direct leakage go together. Lower t values consistently lead to higher rates leakage, while higher lr values do not show a clear trend; lr 1e 5 maintains the largest leakage.\n\n--- Segment 13 ---\nRecall that these parameters resulted in the top-1 model m1IP base, implying that high quality and direct leakage go together. Lower t values consistently lead to higher rates leakage, while higher lr values do not show a clear trend; lr 1e 5 maintains the largest leakage. Along with the above findings for formal equivalence, i.e., implicit leakage correlates somewhat loosely with high quality, this implies that the main mechanism for leakage is indeed data memorization, but this is subject to variations imperfections, leading to some functionality mismatches. E. Case Study III: Impact of Locking on Leakage Setting. Here we study the risk remaining after using locked in-house IP for FT, i.e., we measure leakage for Mlocked(IP) base . We utilize formal equivalence and AST pass rate again, but now comparing generated codes against Dlocked(IP). We contrast findings with those for MIP base. We show RQ2 to be both true and false, i.e., locking can protect from IP leakage, but only if implemented carefully. Recall that Mlocked(IP) base is built up by (i) picking FT param- eters that provided high quality in MIP base and (ii) running FT with those parameters on Dlocked(IP), along with further locking- specific FT settings. For (i), we consider the parameters from m1IP base and, without loss of generality, those from m4IP base. We Fig. 6. Leakage for Mlocked(IP) base built from m1IP base, in formal equivalence to Dlocked(IP) [ ]. Fig. 7. Leakage for Mlocked(IP) base built from m4IP base, in formal equivalence to Dlocked(IP) [ ]. pick the latter for its variance in FT parameters,4 and for the fact that its leakage is the same as m1IP base. That is, given some constant leakage in MIP base, we shall explore the role of varying FT parameters for leakage in Mlocked(IP) base . For (ii), we consider all 4 2 8 combinations of locking and FT strategies, and also the 4 prompting strategies devised for robust leakage assessment (Sec. IV-B), resulting in 32 scenarios in total. Results.\n\n--- Segment 14 ---\nIV-B), resulting in 32 scenarios in total. Results. Figures 6 and 7 show leakage for two separate fam- ilies of Mlocked(IP) base related to m1IP base and m4IP base, respectively. Leakage is reduced notably thanks to locking, namely on average by 9.58 pt related to m1IP base and by 9.87 pt related to m4IP base, respectively. However, leakage trends across the two families vary significantly for different locking, FT, and prompting strategies, as discussed next. For the family Mlocked(IP) base related to m4IP base, we find that L50 const for FT w o-k (i.e., correct key values are not provided during FT) and L100 const for FT w k provide similar ranges for overall worst reductions, namely 3.18 pt and 4.87 pt, respectively. L50 all and L100 all , both for FT w o-k, provide similar ranges for overall best reductions of 13.13 pt and 13.84 pt, respectively. For prompting strategies, we find that leakage increases with more information on locking provided, albeit without consistent trends. Locking of all components is confirmed as least leaky across all prompting strategies, with some variations across locking scales and FT strategies. These trends follow the expectations that (i) more locking, (ii) skipping correct key values for FT, and (iii) prompting with less information should all hinder leakage more effectively. For the family Mlocked(IP) base related to m1IP base, we find that L50 all provides the worst reduction of 6.29 pt, whereas L50 const provides the best reduction of 13.27 pt, in both cases irre- spective of the FT strategies (w k vs w o-k). Furthermore, 4Model m4IP base is the 4th best in MIP base for quality, but the first with more varied FT parameters: m4IP base arises from e 2, lr 1e 5, t 0.8, whereas the top-3 models all arise from e 3, lr 1e 5.\n\n--- Segment 15 ---\nFor the family Mlocked(IP) base related to m1IP base, we find that L50 all provides the worst reduction of 6.29 pt, whereas L50 const provides the best reduction of 13.27 pt, in both cases irre- spective of the FT strategies (w k vs w o-k). Furthermore, 4Model m4IP base is the 4th best in MIP base for quality, but the first with more varied FT parameters: m4IP base arises from e 2, lr 1e 5, t 0.8, whereas the top-3 models all arise from e 3, lr 1e 5. TABLE III LEAKAGE FOR MLOCKED(IP) BASE IN AST PASS RATE OVER DLOCKED(IP) [ ] With Key (w k) Without Key (w o-k) m1IP base I K I K L I K V I I K I K L I K V I all-50 31.63 31.33 31.19 32.06 36.01 32.36 31.19 32.79 all-100 26.06 27.97 32.36 25.47 37.77 34.55 32.95 30.46 const-50 32.21 21.52 30.16 31.77 31.04 30.01 30.16 32.79 const-100 22.40 19.03 24.16 26.21 31.48 24.30 24.01 33.09 m4IP base I K I K L I K V I I K I K L I K V I all-50 27.52 27.96 27.38 22.55 26.06 23.87 25.48 24.45 all-100 20.94 21.96 23.57 20.50 26.65 23.87 25.18 28.11 const-50 27.38 20.20 21.96 21.38 27.23 25.33 27.53 22.99 const-100 29.14 18.59 28.40 26.21 26.35 25.33 25.04 24.74 Recall Sec. IV-B: I: instr Porig IP ; K: key name; L: key length; V: key value. L50 const enables larger reductions than L100 const . These trends are unexpected at first, as locking all components larger scales enables wider obfuscation of the in-house IP.\n\n--- Segment 16 ---\nL50 const enables larger reductions than L100 const . These trends are unexpected at first, as locking all components larger scales enables wider obfuscation of the in-house IP. Looking into the designs generated after FT w o-k, we find that the locking implementation is skipped more often for L100 const than L50 const, i.e., the IP protection is bypassed. This implies that larger keys are more difficult to comprehend for FT when the correct values are not provided, which is expected. Unlike before (Mlocked(IP) base related to m1IP base), where such skipping of locking did not occur, we hypothesize that the less competitive parameters of m4IP base here result in such leakage-inducing quality issues during code generation. Regarding prompting strategies, we find again that leakage increases with more information on locking. Providing the name of the key-bits input has a strong impact, whereas other information contributes less consistently. L50 const is reconfirmed as least leaky across the prompting strategies, with some variations for FT strategies. Table III reports average reductions in AST pass rate for leakage of 6.90 related to m1IP base and of 2.32 related to m4IP base, respectively. The above hypothesis for leakage- inducing quality issues is confirmed by the lower reductions of direct leakage related to m4IP base. FT w k shows inconsistent trends, e.g., with L50 const related to m1IP base varying by up-to 15.58 but L100 const related to m4IP base varying by up-to 10.55 . In contrast, FT w o-k provides more predictable reductions In short, while locking in-house IP before FT can mitigate leakage to a good degree, this requires a careful assessment of locking and FT strategies, along with consideration of various possible prompting strategies by adversaries. Otherwise, the benefits of locking cannot be guaranteed. F. Case Study IV: Impact of Locking on Quality Setting. Here we study the impact of using locked in-house IP for FT on code generation performance, i.e., we measure quality for Mlocked(IP) base . We show RQ3 to be largely false. We again cover all models arising from all 8 combinations of locking and FT strategies. We contrast with findings for MIP base. Results. Figure 8 shows the quality of code generation for Mlocked(IP) base built from m1IP base.\n\n--- Segment 17 ---\nResults. Figure 8 shows the quality of code generation for Mlocked(IP) base built from m1IP base. Quality has degraded notably due to locking, namely by 10.81 pt on average. Fig. 8. Quality for Mlocked(IP) base built from m1IP base, eq 0.8) [ ]. The least degradation highest quality occurs for L50 const and FT w o-k, whereas the largest degradation occurs for L100 all and FT w k. Regarding locking strategies, both results are expected: locking fewer (more) components at smaller (larger) scales leaves more (less) components unobfuscated, which FT can benefit more (less) from. Regarding FT strategies, the fact that leaving out correct key values improves quality might seem counter-intuitive at first. Examining codes generated for the case of L50 const, we find that FT w o-k provides 9.95 more locked designs than FT w k. In contrast, L100 const under FT w o-k generates only 1.97 more locked designs. Comparing to L50 all and L100 all , which generate on average 7.57 more locked designs, this confirms that code quality under FT w o-k is indeed superior to FT w k and indicates that this is due to the quality of the generated locking implementations. For the locking and FT strategies in general, we find the following. When locking all components, quality increases from L100 all to L50 all and from FT w k to FT w o-k, which is both in line with prior observations. When locking constants only, however, quality increases from L50 const to L100 const for FT w k, yet decreases for FT w o-k. This implies that an understanding of actual key values is relevant for FT when locking constants. Still, FT w o-k is the most dominant factor for higher quality across the board. Note that we present and discuss the quality of code generation for Mlocked(IP) base built from m4IP base in the appendix. V. CONCLUSION We present VeriLeaky, the first study that carefully explores leakage-vs-quality trade-offs arising for FT of LLMs with proprietary in-house IP. Our findings confirm the significant risk of leakage (RQ1: yes), evidenced by substantial structural and functional similarity between generated codes and the in-house IP.\n\n--- Segment 18 ---\nV. CONCLUSION We present VeriLeaky, the first study that carefully explores leakage-vs-quality trade-offs arising for FT of LLMs with proprietary in-house IP. Our findings confirm the significant risk of leakage (RQ1: yes), evidenced by substantial structural and functional similarity between generated codes and the in-house IP. While logic locking offers some potential, its effectiveness is rather fragile (RQ2: yes and no), as it highly depends on the locking strategy and parameters employed during FT, as well as on the details provided for inference prompting. Locking also reduces the utility of the IP for FT and consequently degrades the LLM s performance (RQ3: no). Future work should explore alternative techniques toward more effective IP protection and less disruptive FT. This could include watermarking (to prove but not hinder leakage) or privacy-preserving FT, all specifically for Verilog coding and with delicate leakage-vs-quality trade-offs in mind. REFERENCES [1] OpenAI, GPT-4, Mar. 2023. Available: gpt-4 [2] J. Devlin et al., Bert: Pre-training of deep bidirectional transformers for language understanding, 2019. Available: 04805 [3] A. Grattafiori et al., The llama 3 herd of models, 2024. Available: [4] M. Shao et al., Survey of different large language model architectures: Trends, benchmarks, and challenges, IEEE Access, 2024. [5] GitHub, Github copilot - your ai pair programmer, 2022. Available: [6] M. Chen et al., Evaluating large language models trained on code, arXiv preprint arXiv:2107.03374, 2021. [7] M. Liu et al., Chipnemo: Domain-adapted llms for chip design, arXiv preprint arXiv:2311.00176, 2023. [8] K. Chang et al., Chipgpt: How far are we from natural language hardware design, arXiv preprint arXiv:2305.14019, 2023.\n\n--- Segment 19 ---\n[7] M. Liu et al., Chipnemo: Domain-adapted llms for chip design, arXiv preprint arXiv:2311.00176, 2023. [8] K. Chang et al., Chipgpt: How far are we from natural language hardware design, arXiv preprint arXiv:2305.14019, 2023. [9] Synopsys showcases, [10] Primis.ai, [11] R. Schuster et al., You autocomplete me: Poisoning vulnerabilities in neural code completion, in 30th USENIX Security Symposium (USENIX Security 21), 2021, pp. 1559 1575. [12] H. Aghakhani et al., Trojanpuzzle: Covertly poisoning code-suggestion models, in IEEE S P, 2024, pp. 1122 1140. [13] Z. Yu et al., Codeipprompt: intellectual property infringement assess- ment of code language models, in International conference on machine learning, 2023, pp. 40 373 40 389. [14] A. F. Noah et al., Codecloak: A method for evaluating and mitigating code leakage by llm code assistants, arXiv preprint arXiv:2404.09066, 2024. [15] L. Niu et al., {CodexLeaks}: Privacy leaks from code generation language models in {GitHub} copilot, in 32nd USENIX Security Symposium (USENIX Security 23), 2023, pp. 2133 2150. [16] A. J. Menezes et al., Handbook of applied cryptography. CRC press, 2018. [17] S. Liu et al., Rtlcoder: Outperforming gpt-3.5 in design rtl generation with our open-source dataset and lightweight solution, 2024. Available: [18] Z. Wang et al., Llms and the future of chip design: Unveiling security risks and building trust, in 2024 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), 2024, pp. 385 390. [19] S. Thakur et al., Verigen: A large language model for verilog code generation, ACM TODAES, 2023.\n\n--- Segment 20 ---\n385 390. [19] S. Thakur et al., Verigen: A large language model for verilog code generation, ACM TODAES, 2023. [20] E. Nijkamp et al., Codegen: An open large language model for code with multi-turn program synthesis, 2023. Available: [21] H. Touvron et al., Llama 2: Open foundation and fine-tuned chat models, arXiv preprint arXiv:2307.09288, 2023. [22] S. Thakur et al., Autochip: Automating hdl generation using llm feedback, arXiv preprint arXiv:2311.04887, 2023. [23] F. Cui et al., Origen: Enhancing rtl code generation with code-to-code augmentation and self-reflection, arXiv preprint arXiv:2407.16237, 2024. [24] R. Qiu et al., Autobench: Automatic testbench generation and evalua- tion using llms for hdl design, in Proceedings of the 2024 ACM IEEE International Symposium on Machine Learning for CAD, 2024, pp. 1 10. [25] J. Bhandari et al., Llm-aided testbench generation and bug detection for finite-state machines, arXiv preprint arXiv:2406.17132, 2024. [26] R. Qiu et al., Correctbench: Automatic testbench generation with functional self-correction using llms for hdl design, arXiv preprint arXiv:2411.08510, 2024. [27] R. Kande et al., Llm-assisted generation of hardware assertions, arXiv preprint arXiv:2306.14027, 2023. [28] W. Fang et al., Assertllm: Generating and evaluating hardware verifica- tion assertions from design specifications via multi-llms, arXiv preprint arXiv:2402.00386, 2024. [29] J. Blocklove et al., Chip-chat: Challenges and opportunities in conver- sational hardware design, in 2023 ACM IEEE 5th Workshop on Machine Learning for CAD (MLCAD). IEEE, Sep. 2023.\n\n--- Segment 21 ---\n[29] J. Blocklove et al., Chip-chat: Challenges and opportunities in conver- sational hardware design, in 2023 ACM IEEE 5th Workshop on Machine Learning for CAD (MLCAD). IEEE, Sep. 2023. [30] Y. Fu et al., Gpt4aigchip: Towards next-generation ai accelerator design automation via large language models, in 2023 IEEE ACM International Conference on Computer Aided Design (ICCAD), 2023, pp. 1 9. [31] H. Wu et al., Chateda: A large language model powered autonomous agent for eda, IEEE Transactions on Computer-Aided Design of Inte- grated Circuits and Systems, 2024. [32] Y. Lu et al., Rtllm: An open-source benchmark for design rtl generation with large language model, in 2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC), 2024, pp. 722 727. [33] M. Liu et al., Verilogeval: Evaluating large language models for verilog code generation, in 2023 IEEE ACM International Conference on Computer Aided Design (ICCAD), 2023, pp. 1 8. [34] N. Pinckney et al., Revisiting verilogeval: Newer llms, in-context learn- ing, and specification-to-rtl tasks, arXiv preprint arXiv:2408.11053, 2024. [35] S. Liu et al., Openllm-rtl: Open dataset and benchmark for llm-aided design rtl generation, 2024. [36] H. Pearce et al., Asleep at the keyboard? assessing the security of github copilot s code contributions, Communications of the ACM, vol. 68, no. 2, pp. 96 105, 2025. [37] Z. Ji et al., Unlearnable examples: Protecting open-source software from unauthorized neural code learning. in SEKE, 2022, pp. 525 530. [38] H. Du et al., Privacy in fine-tuning large language models: Attacks, defenses, and future directions, arXiv preprint arXiv:2412.16504, 2024.\n\n--- Segment 22 ---\n525 530. [38] H. Du et al., Privacy in fine-tuning large language models: Attacks, defenses, and future directions, arXiv preprint arXiv:2412.16504, 2024. [39] N. Carlini et al., Extracting training data from large language models, in 30th USENIX security symposium (USENIX Security 21), 2021, pp. 2633 2650. [40] Z. Sun et al., Coprotector: Protect open-source code against unautho- rized training usage with data poisoning, in Proceedings of the ACM Web Conference 2022, 2022, pp. 652 660. [41] H. Yang et al., A comprehensive overview of backdoor attacks in large language models within communication networks, IEEE Network, 2024. [42] R. Liu et al., Precurious: How innocent pre-trained language models turn into privacy traps, in Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security, 2024, pp. 3511 3524. [43] M. S. Ozdayi et al., Controlling the extraction of memorized data from large language models via prompt-tuning, arXiv preprint arXiv:2305.11759, 2023. [44] L. L. Mankali et al., Rtl-breaker: Assessing the security of llms against backdoor attacks on hdl code generation, arXiv preprint arXiv:2411.17569, 2024. [45] V. Gohil et al., Llmpirate: Llms for black-box hardware ip piracy, arXiv preprint arXiv:2411.16111, 2024. [46] C. Pilato et al., Tao: Techniques for algorithm-level obfuscation dur- ing high-level synthesis, in Proceedings of the 55th Annual Design Automation Conference, 2018, pp. 1 6. [47] C. Pilato et al., Assure: Rtl locking against an untrusted foundry, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 29, no. 7, pp. 1306 1318, 2021.\n\n--- Segment 23 ---\n7, pp. 1306 1318, 2021. [48] M. Yasin et al., Provably-secure logic locking: From theory to practice, in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS 17. New York, NY, USA: Association for Computing Machinery, 2017, p. 1601 1618. Available: [49] M. Nabeel et al., Cophee: Co-processor for partially homomorphic en- crypted execution, in 2019 IEEE International Symposium on Hardware Oriented Security and Trust (HOST), 2019, pp. 131 140. [50] N. Limaye et al., Antidote: Protecting debug against outsourced test entities, IEEE Transactions on Emerging Topics in Computing, vol. 10, no. 3, pp. 1507 1518, 2022. [51] M. Nabeel et al., Cofhee: A co-processor for fully homomorphic encryption execution, in 2023 Design, Automation Test in Europe Conference Exhibition (DATE), 2023, pp. 1 2. [52] M. Nabeel et al., Exploring constrained-modulus modular multipliers for improved area, power and flexibility, in IFIP IEEE International Conference on Very Large Scale Integration-System on a Chip, 2023, pp. 93 108. [53] D. Soni et al., Quantifying the overheads of modular multiplication, in 2023 IEEE ACM International Symposium on Low Power Electronics and Design (ISLPED), 2023, pp. 1 6. [54] D. Soni et al., Design space exploration of modular multipliers for asic fhe accelerators, in 2023 24th International Symposium on Quality Electronic Design (ISQED), 2023, pp. 1 8. [55] S. Icarus, Icarus Verilog, [56] R. Maertens et al., Discovering and exploring cases of educational source code plagiarism with dolos, SoftwareX, vol. 26, p. 101755, 2024. APPENDIX A SUPPLEMENTARY MATERIALS Figure 9 shows some examples for prompting for quality assessment. Figure 10 shows the quality of code generation for MIP base across FT and inference parameters, for prompts Phuman IP . Overall, quality is notably lower than for prompts PGPT IP (Fig. 3).\n\n--- Segment 24 ---\nOverall, quality is notably lower than for prompts PGPT IP (Fig. 3). Due to, on average, less comprehensive human descriptions (Fig. 9), this is expected; it is also a common observation throughout the literature. Furthermore, we find that lr 1e 5 is still the most dominant factor, whereas trends for t and e are less clear as with PGPT IP , which reconfirms the more fragile nature of Phuman IP prompting. 𝒫IP GPT 𝒫IP human : Prompt generated by Human : Prompt generated by Machine (GPT-4o) Fig. 9. Prompt examples for a Radix-2 Butterfly IP module. Fig. 10. Quality for MIP base using Phuman IP , measured in eq 0.8) [ ]. Fig. 11. Quality for Mlocked(IP) base built from m4IP base, eq 0.8) [ ]. Figure 11 shows the quality of code generation for Mlocked(IP) base built from m4IP base. Quality has degraded notably also here due to locking, namely by 6.77 pt on average. Trends are similar to those for Mlocked(IP) base built from m1IP base (Fig. 8), reconfirming the delicate impact of the locking strategy and parameters employed during FT, as well as the details provided for inference prompting.\n\n