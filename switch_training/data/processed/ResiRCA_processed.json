{
  "source": "ResiRCA.pdf",
  "raw_length": 78440,
  "cleaned_length": 77324,
  "base_segments": 241,
  "augmented_segments": 482,
  "segments": [
    {
      "text": "Abstract —Many recent works have shown substantial efﬁciency boosts from performing inference tasks on Internet of Things (IoT) nodes rather than merely transmitting raw sensor data. However, such tasks, e.g., convolutional neural networks (CNN), are very compute intensive. They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes.",
      "type": "sliding_window",
      "tokens": 97
    },
    {
      "text": "They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes. ReRAM crossbar-based accelera- tors (RCAs) are an ideal candidate to perform the dominant multiplication-and-accumulation (MAC) operations in CNNs ef- ﬁciently, but conventional, performance-oriented RCAs, while energy-efﬁcient, are power hungry and ill-optimized for the intermittent and unstable power supply of energy-harvesting IoT nodes. This paper presents the  ResiRCA  architecture that integrates a new, lightweight, and conﬁgurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node.",
      "type": "sliding_window",
      "tokens": 186
    },
    {
      "text": "This paper presents the  ResiRCA  architecture that integrates a new, lightweight, and conﬁgurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node. To maximize ResiRCA throughput under different power levels, we develop the  ResiSchedule  approach for dynamic RCA reconﬁguration. The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come.",
      "type": "sliding_window",
      "tokens": 145
    },
    {
      "text": "The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. Experimental results show that ResiRCA and ResiSchedule achieve average speedups and energy efﬁciency improvements of 8 ×  and 14 ×  respectively compared to a baseline RCA with intermittency-unaware scheduling. Keywords -Energy harvesting, ReRAM crossbar, CNN, Recon- ﬁgurable hardware, Loop tiling, Computation scheduling \nI. I NTRODUCTION \nIn recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [ 1 ].",
      "type": "sliding_window",
      "tokens": 189
    },
    {
      "text": "Keywords -Energy harvesting, ReRAM crossbar, CNN, Recon- ﬁgurable hardware, Loop tiling, Computation scheduling \nI. I NTRODUCTION \nIn recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [ 1 ]. Such integration grants IoT devices an important degree of independence from remote servers, which can be critical in deployments with challenging communication environments. However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms.",
      "type": "sliding_window",
      "tokens": 162
    },
    {
      "text": "However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms. Such platforms often already operate at their limits just in order to transmit sensed data at acceptable quality of \nservice (QoS) rates for deployment-viable battery lifetimes, and may not have additional resources available for further computation. For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type.",
      "type": "sliding_window",
      "tokens": 121
    },
    {
      "text": "For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type. In CNNs, for instance, MACs between the feature map data and kernel weights comprise nearly 90% of the total operations [ 2 ], [ 3 ]. Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efﬁciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ].",
      "type": "sliding_window",
      "tokens": 155
    },
    {
      "text": "Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efﬁciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ]. In the remainder of the paper, we may shorten the term  ReRAM crossbars  to  ReRAMs . Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efﬁciently performing inference on an IoT device if it does not have either a high power or high stability power source.",
      "type": "sliding_window",
      "tokens": 186
    },
    {
      "text": "Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efﬁciently performing inference on an IoT device if it does not have either a high power or high stability power source. Given form factor constraints on energy storage, the former may be challenging, and energy-harvesting from sources such as solar, thermal, kinetic and radio frequency [ 11 ], [ 12 ], [ 13 ], [ 14 ], [ 15 ], [ 16 ] is notoriously unstable. While unstable power sources have been successfully utilized for applications in the IoT space [ 17 ], [ 18 ], [ 19 ], their use has not been heavily explored for RCA design.",
      "type": "sliding_window",
      "tokens": 170
    },
    {
      "text": "While unstable power sources have been successfully utilized for applications in the IoT space [ 17 ], [ 18 ], [ 19 ], their use has not been heavily explored for RCA design. Current RCA approaches can be divided into two categories. The approaches in the ﬁrst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [ 3 ], [ 4 ], [ 5 ], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [ 6 ], [ 8 ].",
      "type": "sliding_window",
      "tokens": 151
    },
    {
      "text": "The approaches in the ﬁrst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [ 3 ], [ 4 ], [ 5 ], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [ 6 ], [ 8 ]. However, neither of them is a good ﬁt for energy-harvesting scenarios. To address these challenges, this paper proposes and experi- mentally evaluates  ResiRCA , a resilient ReRAM crossbar-based CNN accelerator.",
      "type": "sliding_window",
      "tokens": 151
    },
    {
      "text": "To address these challenges, this paper proposes and experi- mentally evaluates  ResiRCA , a resilient ReRAM crossbar-based CNN accelerator. Supported by a reconﬁgurable lightweight \nhardware design, ResiRCA is able to activate scalable com- putations via a multi-dimension tuning strategy. ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference.",
      "type": "sliding_window",
      "tokens": 122
    },
    {
      "text": "ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference. In this design paradigm, the basic low power, lightweight MCU system can enjoy the advantage of continuous operation without suffering power outages, while the compute-heavy inference tasks can be ofﬂoaded to the RCA during periods when power income is sufﬁciently high and to external systems otherwise. Such a system is capable of both continuously collecting data and computing CNNs locally near data.",
      "type": "sliding_window",
      "tokens": 129
    },
    {
      "text": "Such a system is capable of both continuously collecting data and computing CNNs locally near data. ResiRCA allows an RCA to adapt to changing harvested energy and, with our co-designed scheduling approach, ResiSchedule, it can achieve very high throughput. To the best of our knowledge, this is the ﬁrst work that focuses on low power and reconﬁgurable RCA design from both the hardware and software angles targeting energy harvesting systems.",
      "type": "sliding_window",
      "tokens": 96
    },
    {
      "text": "To the best of our knowledge, this is the ﬁrst work that focuses on low power and reconﬁgurable RCA design from both the hardware and software angles targeting energy harvesting systems. This paper makes the following key  contributions : •  Low power, reconﬁgurable hardware design:  We pro- pose a novel architecture that implements a lightweight and low power RCA to adapt to time-varying power resources. Furthermore, the proposed hardware is reconﬁgurable at a ﬁne grain, to be able to dynamically activate different scaled computations, which can ﬁt to the changing features of the underlying power resources.",
      "type": "sliding_window",
      "tokens": 129
    },
    {
      "text": "Furthermore, the proposed hardware is reconﬁgurable at a ﬁne grain, to be able to dynamically activate different scaled computations, which can ﬁt to the changing features of the underlying power resources. •  Resilient computation scheduling:  We provide three knobs to schedule computation blocks in the proposed ar- chitecture: (i) loop tiling which decomposes MAC operations in a given layer (ReRAM) into small blocks, (ii) ReRAM duplication which provides opportunity to perform one-layer operations with multiple weight copies, and (iii) pipelining that can organize multiple ReRAM tiles to further exploit the har- vested power. These knobs can be integrated to form sequential or pipelined computation modes.",
      "type": "sliding_window",
      "tokens": 164
    },
    {
      "text": "These knobs can be integrated to form sequential or pipelined computation modes. For each computation mode, we can derive the optimal activation solutions under each power level directed by the  power model  and  throughput model  ofﬂine. We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution.",
      "type": "sliding_window",
      "tokens": 76
    },
    {
      "text": "We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution. •  Smooth schedule transitioning:  We identify smooth transition conditions to transfer as many partial results as possible from the last incomplete inference in one power cycle to the next power cycle with a different power level. In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction.",
      "type": "sliding_window",
      "tokens": 94
    },
    {
      "text": "In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction. II. M OTIVATION \nTo avoid negatively impacting the underlying system’s QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available.",
      "type": "sliding_window",
      "tokens": 82
    },
    {
      "text": "M OTIVATION \nTo avoid negatively impacting the underlying system’s QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available. In energy harvesting systems, there are two critical features, namely,  power strength  and power window length . First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power. Second, the \nvariance of the input power window, i.e., how long the power input stays at a given level, can be large as well. It is known that RCAs achieve their highest efﬁciency when every cell participates in the MAC computations simul- taneously [ 20 ].",
      "type": "sliding_window",
      "tokens": 96
    },
    {
      "text": "It is known that RCAs achieve their highest efﬁciency when every cell participates in the MAC computations simul- taneously [ 20 ]. However, naively integrating such an RCA renders its activation power requirement so high that the system will likely have very low duty-cycle on an intermittent supply and may never activate at all for weaker power sources unless a substantial energy store were added, which could be burdensome for form factor constraints in a system that already employs a battery for sensing and other non-inference tasks. TABLE I A N EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT - CYCLE POWER TRACE .",
      "type": "sliding_window",
      "tokens": 160
    },
    {
      "text": "TABLE I A N EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT - CYCLE POWER TRACE . Power cycle \nHarv. Power ( µ W) \nPower consumption with full-size acti.",
      "type": "sliding_window",
      "tokens": 58
    },
    {
      "text": "Power ( µ W) \nPower consumption with full-size acti. ( µ W)/ Thr. (GiGa MACs/s)/ Power utilization \nPower consumption with resilient acti.",
      "type": "sliding_window",
      "tokens": 46
    },
    {
      "text": "(GiGa MACs/s)/ Power utilization \nPower consumption with resilient acti. ( µ W)/ Thr. (Giga MACs/s) /Power utilization \n1 50 0/Power failure/0/0% 0/Power failure/0/0% 2 100 0/Power failure/0/0% 80/25 × 1 × 1/0.312/80% 3 500 480/25 × 6 × 1/1.872/96% 480/25 × 6 × 1/1.872/96% 4 200 0/Power failure/0/0% 160/25 × 2 × 1/0.624/80% 5 250 0/Power failure/0/0% 240/25 × 3 × 1/0.936/96% 6 750 480/25 × 6 × 1/1.872/64% 720/25 × 3 × 3/2.808/96% 7 650 480/25 × 6 × 1/1.872/74% 640/25 × 2 × 4/2.496/98% 8 350 0/Power failure/0/0% 320/25 × 2 × 2/1.248/91% \n100 \n0.4 \n1.2 \n1.6 \n2.0 \n2.4 \n2.8 \nPower ( ­ W) \nThroughput (Giga MACs/s) \nPower consumption with full-size activation \nPower consumption with tile-size activation \nThroughput with full-size activation Throughput with tile-size activation \nPower trace \nAverage harvested power Average power consumption with full-size activation Average power consumption with tile-size activation \nAverage throughput with full-size activation \nAverage throughput with tile-size activation \n356.3 \n180 \n330 \n1.3 \n200 \n300 \n400 \n500 \n600 \n700 \n800 \n0.8 0.7 \nPC1 \nPC2 \nPC3 \nPC4 \nPC5 \nPC6 \nPC7 \nPC8 \n0 \n0 0 0 80 480 480 0 160 0 240 480 \n480 640 0 320 \n0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 \nFig.",
      "type": "sliding_window",
      "tokens": 481
    },
    {
      "text": "(Giga MACs/s) /Power utilization \n1 50 0/Power failure/0/0% 0/Power failure/0/0% 2 100 0/Power failure/0/0% 80/25 × 1 × 1/0.312/80% 3 500 480/25 × 6 × 1/1.872/96% 480/25 × 6 × 1/1.872/96% 4 200 0/Power failure/0/0% 160/25 × 2 × 1/0.624/80% 5 250 0/Power failure/0/0% 240/25 × 3 × 1/0.936/96% 6 750 480/25 × 6 × 1/1.872/64% 720/25 × 3 × 3/2.808/96% 7 650 480/25 × 6 × 1/1.872/74% 640/25 × 2 × 4/2.496/98% 8 350 0/Power failure/0/0% 320/25 × 2 × 2/1.248/91% \n100 \n0.4 \n1.2 \n1.6 \n2.0 \n2.4 \n2.8 \nPower ( ­ W) \nThroughput (Giga MACs/s) \nPower consumption with full-size activation \nPower consumption with tile-size activation \nThroughput with full-size activation Throughput with tile-size activation \nPower trace \nAverage harvested power Average power consumption with full-size activation Average power consumption with tile-size activation \nAverage throughput with full-size activation \nAverage throughput with tile-size activation \n356.3 \n180 \n330 \n1.3 \n200 \n300 \n400 \n500 \n600 \n700 \n800 \n0.8 0.7 \nPC1 \nPC2 \nPC3 \nPC4 \nPC5 \nPC6 \nPC7 \nPC8 \n0 \n0 0 0 80 480 480 0 160 0 240 480 \n480 640 0 320 \n0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 \nFig. 1. Comparisons on power consumption and throughput with tile-size over full-size activation \nFrom the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property.",
      "type": "sliding_window",
      "tokens": 501
    },
    {
      "text": "Comparisons on power consumption and throughput with tile-size over full-size activation \nFrom the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property. Under this context, if the power dominant RCA works in a ﬁxed high-power mode, as in traditional RCA designs, there would be large mismatches between the harvested power and the consumed power. These mismatches can lead to the following two “nonideal” working scenarios: (i) Unutilized energy:  As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive.",
      "type": "sliding_window",
      "tokens": 159
    },
    {
      "text": "These mismatches can lead to the following two “nonideal” working scenarios: (i) Unutilized energy:  As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive. In this case, the harvested energy will leak away and cannot be recovered. (ii) Underutilized energy:  When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level.",
      "type": "sliding_window",
      "tokens": 121
    },
    {
      "text": "(ii) Underutilized energy:  When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level. In this case, the unused energy will be wasted, resulting in low energy efﬁciency. Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four  25  ×  6  ReRAM crossbars, each can be mapped to six kernels, all sized  5 × 5 × 1 .",
      "type": "sliding_window",
      "tokens": 120
    },
    {
      "text": "Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four  25  ×  6  ReRAM crossbars, each can be mapped to six kernels, all sized  5 × 5 × 1 . In the default case, the RCA works under an either ON or OFF mode with a power threshold of 80 µ W . During the eight harvested power cycles, the ReRAM can be ON during power cycles  PC3, PC6  and  PC7  and OFF with the other ﬁve power cycles.",
      "type": "sliding_window",
      "tokens": 123
    },
    {
      "text": "During the eight harvested power cycles, the ReRAM can be ON during power cycles  PC3, PC6  and  PC7  and OFF with the other ﬁve power cycles. However, even when the system goes through the three power cycles, only some portion of the harvested power is consumed. As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efﬁciency under stable, high-power scenarios.",
      "type": "sliding_window",
      "tokens": 96
    },
    {
      "text": "As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efﬁciency under stable, high-power scenarios. Fig. 2.",
      "type": "sliding_window",
      "tokens": 43
    },
    {
      "text": "2. Comparisons on loop code and ReRAM activation with tile- size activation over full-size activation. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation \nIf we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve “continuous progress” under lower power supply.",
      "type": "sliding_window",
      "tokens": 147
    },
    {
      "text": "(a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation \nIf we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve “continuous progress” under lower power supply. This is because the starting power requirement of the RCA is reduced, and the system can thus get through power failures and translate even the low input energy into forward progress. If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles  PC2, PC4, PC5  and  PC8  under limited power budget, as depicted in Table II and Figure 1.",
      "type": "sliding_window",
      "tokens": 211
    },
    {
      "text": "If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles  PC2, PC4, PC5  and  PC8  under limited power budget, as depicted in Table II and Figure 1. The annotations indicate the consumed power ( µ W), tile size and duplication count (e.g., 25x2x1) and power efﬁciency. With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of \n180 µ W to 330 µ W, and the throughput is increased by 85.7%.",
      "type": "sliding_window",
      "tokens": 143
    },
    {
      "text": "With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of \n180 µ W to 330 µ W, and the throughput is increased by 85.7%. Note that the partial activation of computation cells can be realized by partially activating the peripheral circuits of the corresponding rows and columns in the ReRAM crossbar. This resilient activation approach can effectively combat  Nonideal scenario 1 .",
      "type": "sliding_window",
      "tokens": 106
    },
    {
      "text": "This resilient activation approach can effectively combat  Nonideal scenario 1 . The underlying reason of encountering so many power failures in the case of conventional working mode is that the power threshold of the system to remain alive is set too high. With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM.",
      "type": "sliding_window",
      "tokens": 82
    },
    {
      "text": "With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM. With this, the RCA can be active in a very large power range and ﬁnd more opportunities to make execution progress. Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles  PC6, PC7  and  PC8 .",
      "type": "sliding_window",
      "tokens": 107
    },
    {
      "text": "Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles  PC6, PC7  and  PC8 . Parallel computations across multiple ReRAMs and loop tiling-based computation for each ReRAM are orthogonal optimizations. Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode.",
      "type": "sliding_window",
      "tokens": 104
    },
    {
      "text": "Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode. In this example, the full size of ReRAM (or loop nest) is M  ×  N  =  A  ×  B  ×  C  ×  N , and the tile size of ReRAM (or loop nest) is  m  ×  n  = 1  ×  tb  ×  C  ×  tn . Since each single ReRAM can be activated at a ﬁner granularity with tiling, the parallelism can be achieved under a ﬂexible range of power consumption to match a variable power supply.",
      "type": "sliding_window",
      "tokens": 142
    },
    {
      "text": "Since each single ReRAM can be activated at a ﬁner granularity with tiling, the parallelism can be achieved under a ﬂexible range of power consumption to match a variable power supply. Furthermore, the better the high-power supply can be aggressively utilized, the more ambient energy can be continuously extracted without increasing the energy storage capacity for the energy-harvesting power delivery system. Therefore, this weight duplication- based execution style built upon ﬁne-granularity activation can effectively combat  Nonideal scenario 2 .",
      "type": "sliding_window",
      "tokens": 118
    },
    {
      "text": "Therefore, this weight duplication- based execution style built upon ﬁne-granularity activation can effectively combat  Nonideal scenario 2 . Figure 1 also shows the throughput under the full-size activation mode and the tile-size activation mode. The ﬂexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization.",
      "type": "sliding_window",
      "tokens": 79
    },
    {
      "text": "The ﬂexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization. Extending this single-ReRAM toy architecture to a practical multi-ReRAM architecture to process multi-layer convolutions for real-world CNNs introduces a new source of power variation in terms of the different time and power costs of different convolution layers. In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efﬁciency.",
      "type": "sliding_window",
      "tokens": 114
    },
    {
      "text": "In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efﬁciency. III. S YSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives.",
      "type": "sliding_window",
      "tokens": 62
    },
    {
      "text": "S YSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives. Below, we provide an overview of the RCA interfaces and our system integration model and then discuss the two main steps to map a CNN to ResiRCA:  ofﬂine compilation  and  runtime execution . A. ResiRCA overview \nFigure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system.",
      "type": "sliding_window",
      "tokens": 101
    },
    {
      "text": "A. ResiRCA overview \nFigure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system. The baseline, battery-powered MCU system samples data at a ﬁxed rate, supported by the provisioned battery, and transmits either sensor data or the results of RCA processing \nDAC DAC DAC DAC DAC DAC \nMCU \nMemory I/O Ports \nInterconnected Bus \nClock \nPower \nIntelligent Embedded System \n... \n... \nADC&S+A \nDAC \nInput Reg. Output Reg.",
      "type": "sliding_window",
      "tokens": 121
    },
    {
      "text": "Output Reg. Pool Unit FC Unit \nAdder Tree \nResiRCA \nReRAM crossbar \n... \nADC&S+A \nDAC \nReRAM crossbar \nĂ \nTx/RX \nEnergy Harvestor Sensors \nEnergy harvesting (EH) \n... Battery (B) \nB \nEH \nĂ Sigmoid \n... \nReRAM Memory \nBasic MCU System \nB \nEH EH \nEH \nEH \nB \nFig.",
      "type": "sliding_window",
      "tokens": 89
    },
    {
      "text": "Battery (B) \nB \nEH \nĂ Sigmoid \n... \nReRAM Memory \nBasic MCU System \nB \nEH EH \nEH \nEH \nB \nFig. 3. ResiRCA architecture overview \nto the network.",
      "type": "sliding_window",
      "tokens": 46
    },
    {
      "text": "ResiRCA architecture overview \nto the network. The RCA is powered by harvesting ambient energy and employs a separate, very small capacitor as its only energy storage medium, primarily for power smoothing, similar to prior energy-harvesting NVP designs [ 17 ], [ 21 ], rather than as a task-scaled energy reservoir [ 22 ]. Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input/output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources.",
      "type": "sliding_window",
      "tokens": 127
    },
    {
      "text": "Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input/output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources. Similar hybrid arrangements have been explored in the NVP literature [ 23 ] and impose minimal design overheads. The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiﬁcations.",
      "type": "sliding_window",
      "tokens": 127
    },
    {
      "text": "The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiﬁcations. B. Mapping inference tasks to ResiRCA To achieve both generally low power and intermittency- compatible execution, the proposed ResiRCA architecture has the following two features that impact the software management of the RCA: Lightweight:  From the perspective of the ReRAM circuit at the core of the RCA, the precision and resolution of inputs, weights and outputs are kept low to yield low power. This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA.",
      "type": "sliding_window",
      "tokens": 169
    },
    {
      "text": "This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA. Similarly, total model size, including any granularity overheads (e.g., from the partitioning used to store both positive and negative weights by having the kernels of one layer mapped to two crossbars, one each for positive and negative weights, which share the same input port) must ﬁt within the allocated RCAs of a particular ResiRCA design. Fine-grained reconﬁguration:  The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes.",
      "type": "sliding_window",
      "tokens": 148
    },
    {
      "text": "Fine-grained reconﬁguration:  The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes. This ﬂexible reconﬁgurability enables ﬁne-grained activations to exploit the harvested power. While execution is relatively straightforward when maintaining a speciﬁc conﬁguration of tiling and pipelining strategy, transitions between conﬁgurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures.",
      "type": "sliding_window",
      "tokens": 113
    },
    {
      "text": "While execution is relatively straightforward when maintaining a speciﬁc conﬁguration of tiling and pipelining strategy, transitions between conﬁgurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures. The hardware design details will be presented in Section IV. As part of compiling a CNN to ResiRCA, we build a proﬁling table relating each potential tiling and pipeline conﬁguration \nthat might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw.",
      "type": "sliding_window",
      "tokens": 123
    },
    {
      "text": "As part of compiling a CNN to ResiRCA, we build a proﬁling table relating each potential tiling and pipeline conﬁguration \nthat might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw. This proﬁling collects data used to determine the best activation solution for each power level. At runtime, each time when entering a new power cycle, we ﬁrst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level.",
      "type": "sliding_window",
      "tokens": 118
    },
    {
      "text": "At runtime, each time when entering a new power cycle, we ﬁrst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level. Then, the execution process the “ data loading → Mac computing → data storing ” steps in a sequential way to perform convolution operations. The hardware design details will be presented in Section V. \nIV.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "The hardware design details will be presented in Section V. \nIV. A  HARVESTING - COMPATIBLE ,  LOW - \nPOWER  R ESI RCA \nSupporting the necessary features for adapting RCAs to a harvested power supply will require optimizations in both RCA circuit design and the development of variable-power-optimized loop-tiling strategies. First, feasible implementations of ﬂexible activation options require a low power and reconﬁgurable RCA.",
      "type": "sliding_window",
      "tokens": 106
    },
    {
      "text": "First, feasible implementations of ﬂexible activation options require a low power and reconﬁgurable RCA. Second, a dynamic loop tiling strategy alongside a coordinated parallelism scheme should be devised to match execution power consumption as closely as possible to power income to maximize efﬁciency. This section addresses the ﬁrst of these challenges, and Section V discusses our approach to the second.",
      "type": "sliding_window",
      "tokens": 83
    },
    {
      "text": "This section addresses the ﬁrst of these challenges, and Section V discusses our approach to the second. Challenge 1:  Achieving low-power, reconﬁgurable RCA Although recent works have presented systems [ 4 ], [ 3 ], [ 5 ] and circuits [ 24 ], [ 6 ] for inference-oriented RCAs, they are not directly suitable for adoption in our target scenario because of either their high power consumption or their stringent execution parameters (e.g., computation granularity). In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment.",
      "type": "sliding_window",
      "tokens": 146
    },
    {
      "text": "In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment. Figure 4 shows ﬁve harvested power sources with the maximum, mean and median values and their ratios indicated. It has been shown that the power requirement to fully activate a 128 × 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [ 3 ].",
      "type": "sliding_window",
      "tokens": 97
    },
    {
      "text": "It has been shown that the power requirement to fully activate a 128 × 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [ 3 ]. With this design, the presented power sources can hardly activate even a small ReRAM. In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power.",
      "type": "sliding_window",
      "tokens": 82
    },
    {
      "text": "In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power. Therefore, the the RCA should be built on the basis of a low power hardware design that is upwardly reconﬁgurable to higher power scenarios rather than the reverse. One approach to achieve lower RCA power is to limit precision.",
      "type": "sliding_window",
      "tokens": 72
    },
    {
      "text": "One approach to achieve lower RCA power is to limit precision. The impact of different precisions on CNN accuracy has been extensively studied [ 24 ], [ 25 ], [ 26 ], [ 27 ], [ 28 ], [ 29 ], [ 30 ], [ 31 ], [ 32 ], [ 33 ]. To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output.",
      "type": "sliding_window",
      "tokens": 107
    },
    {
      "text": "To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output. With this design setting, the ReRAM size only needs to be equal to the kernel size, and the ReRAM scale does not need to be extended using a bit composing scheme (e.g. as in ISAAC [ 3 ]).",
      "type": "sliding_window",
      "tokens": 93
    },
    {
      "text": "Variance feature of different power sources \nIII-ADC \nBL \nWL \nSL \n͙ \n͙ \n͙ \nColumn 1 \n͙ \nCSA + \n- \nSAR \n͙ Ref \nShift&Add \n͙ \nDriver \n͙ \nRow 1 \nRow 2 \nRow m \nDriver \nDriver \nI-DAC ͙ \n͙ \n͙ ͙ \nII-Comp \n4-bit inputs 1-bit resolution \n1-bit weights \n4-bit outputs \nbit- serial \nInput  Reg. 4-bit \nOutput  Reg. C \nC \nC controlling circuit \nFig.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "C \nC \nC controlling circuit \nFig. 5. Lightweight ReRAM circuit design \npower ReRAM cells.",
      "type": "sliding_window",
      "tokens": 21
    },
    {
      "text": "Lightweight ReRAM circuit design \npower ReRAM cells. Figure 5 shows the proposed peripheral circuit design for one ReRAM crossbar. This design is more concise even than the SINWP [ 6 ], because we target low power as the primary goal.",
      "type": "sliding_window",
      "tokens": 53
    },
    {
      "text": "This design is more concise even than the SINWP [ 6 ], because we target low power as the primary goal. To increase efﬁciency further our design supports aggressive power gating and other circuit techniques to dynamically reconﬁgure active tile sizes and shut-off inactive ReRAMs. Speciﬁcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "Speciﬁcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows. We modify the column multiplexers to enable variable active columns and turn off the ADCs of inactive channels. Lastly, we apply coarse-grain power gating to conﬁgure the number of duplicated ReRAMs.",
      "type": "sliding_window",
      "tokens": 77
    },
    {
      "text": "Lastly, we apply coarse-grain power gating to conﬁgure the number of duplicated ReRAMs. This reconﬁguration ability can enable scaled activation of the circuits such that small tile-size computation can be enabled while yielding very low power consumption. V. P OWER - DYNAMIC  RCA  SCHEDULING \nGiven a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture.",
      "type": "sliding_window",
      "tokens": 117
    },
    {
      "text": "V. P OWER - DYNAMIC  RCA  SCHEDULING \nGiven a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture. Challenge 2:  Software controlled dynamic RCA activation and scheduling The idea of loop tiling has been widely leveraged in RCA design to either increase system throughput by smoothing the pipelining or reduce memory accesses by improving data locality [ 34 ], [ 3 ]. In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM \naccelerated MACs.",
      "type": "sliding_window",
      "tokens": 150
    },
    {
      "text": "In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM \naccelerated MACs. Moreover, we allow parallelism along different dimensions to seamlessly integrate it with loop tiling, and as a result, a range of scalable computations that can ﬁt in different power supplies are achieved. With this design idea, the system can keep making forward progress over a large range of power incomes.",
      "type": "sliding_window",
      "tokens": 98
    },
    {
      "text": "With this design idea, the system can keep making forward progress over a large range of power incomes. Sections  V-A - V-C  develop a dynamic activation strategy for different power levels and Section  V-D discusses the transition strategy between dynamic activation solutions. A. Computation decomposition and parallelism \nIf the harvested power  P   budget   is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress.",
      "type": "sliding_window",
      "tokens": 108
    },
    {
      "text": "A. Computation decomposition and parallelism \nIf the harvested power  P   budget   is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress. For active RCAs, one option is to use loop tiling to decompose computations, and the other is to parallelize computations. The parallelism in this context is of two types:  intra layer parallelism via layer duplication  and  inter layer parallelism via layer pipelining .",
      "type": "sliding_window",
      "tokens": 116
    },
    {
      "text": "The parallelism in this context is of two types:  intra layer parallelism via layer duplication  and  inter layer parallelism via layer pipelining . Further, tiling and parallelization can also be combined to generate ﬁne-grained scales of computations to efﬁciently ﬁt into the changing harvested power. 1) Computation tiling:  In this work, we use loop tiling [ 35 ] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one.",
      "type": "sliding_window",
      "tokens": 114
    },
    {
      "text": "1) Computation tiling:  In this work, we use loop tiling [ 35 ] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one. As shown in Figure 2, if loop tiling is applied to the unrolled MAC operations, only a tile of ReRAM cells along with their peripheral circuits is enabled to perform MAC operations. After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed.",
      "type": "sliding_window",
      "tokens": 116
    },
    {
      "text": "After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed. Note that, if the row- wise tiling factor is less than the ReRAM row number, this tiled execution strategy will introduce partial sums. When the traversal completes, an  Adder Tree  will be used to merge the partial sums for ReRAM columns and obtain the ﬁnal MAC result.",
      "type": "sliding_window",
      "tokens": 91
    },
    {
      "text": "When the traversal completes, an  Adder Tree  will be used to merge the partial sums for ReRAM columns and obtain the ﬁnal MAC result. 2) Computation parallelism: Intra-layer parallelism  means overlapping the layer computations on duplicated copies of ReRAMs that store the same weights for one layer. We use parallelism granularity  G  to denote the duplication count as deﬁned in [ 5 ].",
      "type": "sliding_window",
      "tokens": 96
    },
    {
      "text": "We use parallelism granularity  G  to denote the duplication count as deﬁned in [ 5 ]. G  can be determined considering the tradeoff between energy efﬁciency and chip area during the design phase. In this work, the parallelism granularity  G  of a layer is determined by the ratio between 50% of the peak harvested power during proﬁling and the power consumption of the full- size ReRAM corresponding to this layer.",
      "type": "sliding_window",
      "tokens": 93
    },
    {
      "text": "In this work, the parallelism granularity  G  of a layer is determined by the ratio between 50% of the peak harvested power during proﬁling and the power consumption of the full- size ReRAM corresponding to this layer. That is, if the 50% peak harvested power by proﬁling is twice ( G =2) of the power consumption with a ReRAM size of Layer 1 of 25x6, the RCA will be designed to offer two sets of ReRAMs sized 25x6 for Layer 1. The actual parallelism granularity  aG ≤ G  for a layer is decided by the harvested power level.",
      "type": "sliding_window",
      "tokens": 135
    },
    {
      "text": "The actual parallelism granularity  aG ≤ G  for a layer is decided by the harvested power level. If we allow  aG ReRAMs to perform the concerned layer’s computations in parallel, the input data should be divided into  aG  partitions. In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel.",
      "type": "sliding_window",
      "tokens": 92
    },
    {
      "text": "In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel. This offers a ﬂexible way to tune the power consumption in a large design space, even though the kernel size, convolution count and power consumption of different layers can signiﬁcantly vary. Inter-layer parallelism  means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion.",
      "type": "sliding_window",
      "tokens": 97
    },
    {
      "text": "Inter-layer parallelism  means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion. This pipeline parallelism provides us with another dimension to aggressively exploit the harvested energy. We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers.",
      "type": "sliding_window",
      "tokens": 91
    },
    {
      "text": "We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers. Previous work [ 3 ] has noted vulnerabilities to pipeline bubbles and execution stalls in CNNs because of the large variance in weight and feature map scales across different layers. In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very ﬁne-grain fashion.",
      "type": "sliding_window",
      "tokens": 117
    },
    {
      "text": "In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very ﬁne-grain fashion. 3) Execution strategies:  Figure 6 shows ﬁve different execution strategies for a two-layer convolution execution experiencing two power cycles with different levels. In Fig- ure 6(a), a naive scheduling strategy is employed on a  Simple architecture .",
      "type": "sliding_window",
      "tokens": 95
    },
    {
      "text": "In Fig- ure 6(a), a naive scheduling strategy is employed on a  Simple architecture . In this scheduling strategy, the RCA is only active when the harvested power is adequate to support the maximal power requirement among all the convolution layers and, in the “simple” architecture, one convolution layer can only be mapped to one ReRAM (no ReRAM duplication). In the remainder of this paper, this execution strategy is referred to as  Naive1 .",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "In the remainder of this paper, this execution strategy is referred to as  Naive1 . We assume that  Naive1  is also designed with the proposed lightweight circuits. In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication.",
      "type": "sliding_window",
      "tokens": 72
    },
    {
      "text": "In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication. This execution strategy is referred as Naive2 . None of  Naive1  and  Naive2  executions can go through power cycle  PC-i  and the power utilization is very low, as there is a signiﬁcant mismatch between the power producer and consumer.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "None of  Naive1  and  Naive2  executions can go through power cycle  PC-i  and the power utilization is very low, as there is a signiﬁcant mismatch between the power producer and consumer. Figure 6(c) presents a ﬂexible scheduling strategy applied to ResiRCA. In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks.",
      "type": "sliding_window",
      "tokens": 88
    },
    {
      "text": "In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks. The layers are scheduled in a sequential fashion. This execution style is called  Sequential .",
      "type": "sliding_window",
      "tokens": 48
    },
    {
      "text": "Five layer scheduling schemes: (a) Naive execution @Simple architecture; (b) Naive execution @ResiRCA architecture; (c) Se- quential resilient execution @ResiRCA architecture; (d) Pipelining resilient execution @ResiRCA architecture; and (e) Hybrid resilient execution @ResiRCA architecture \nResiRCA architecture; we call this execution style  Pipelining . For ease of explanation and simulation, we only allow full pipelining in this execution, which means MAC operations of all the layers are included in each pipeline stage. Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme.",
      "type": "sliding_window",
      "tokens": 152
    },
    {
      "text": "Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme. We refer to this as ResiSchedule . At runtime, ResiSchecule dynamically selects activation solutions from either  Sequential  or  Pipelining  in each power cycle, depending on which can provide a better throughput.",
      "type": "sliding_window",
      "tokens": 83
    },
    {
      "text": "At runtime, ResiSchecule dynamically selects activation solutions from either  Sequential  or  Pipelining  in each power cycle, depending on which can provide a better throughput. With  ResiSchedule , we can cover a large tuning range commensurate with power supply variation. Section  V-C will further present quantitative analysis and solution on how \ntoﬁgureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA.",
      "type": "sliding_window",
      "tokens": 116
    },
    {
      "text": "Section  V-C will further present quantitative analysis and solution on how \ntoﬁgureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA. B.Powermodelandlatencymodel PowersupplyisasigniﬁcantconstraintforResiSchedule. Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solution m,n,aG  wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,P load ,P comp andP store ,andtheyareperformed insequence.",
      "type": "sliding_window",
      "tokens": 196
    },
    {
      "text": "Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solution m,n,aG  wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,P load ,P comp andP store ,andtheyareperformed insequence. 1)Loadandstore: P load and P store   denotethepower consumedbyloadingthedatafromthepureReRAMmem- oryintotheinputregistersandstoringthedatafromthe outputregistersintotheReRAM memory . P load = aG× (Bits input /BN in )×P ld−bit   modelsloadpoweroperation.",
      "type": "sliding_window",
      "tokens": 208
    },
    {
      "text": "P load = aG× (Bits input /BN in )×P ld−bit   modelsloadpoweroperation. Here,theterms Bits input and BN in denotethenumberof inputbitstoserve MACoperationsforafull-sizedReRAMand thebatchnumberoftransferringtheseinputbitsrespectively . Therefore, Bit input / BN in meanstheactualloadeddatabits eachbatch.Theterm P ld−bit denotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister.",
      "type": "sliding_window",
      "tokens": 138
    },
    {
      "text": "Therefore, Bit input / BN in meanstheactualloadeddatabits eachbatch.Theterm P ld−bit denotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister. Theinputbatchnumber BN in isdeterminedbythepower budgetbecause P load <=P budget shouldalwaysbesatisﬁed. Thelatency modelfordataloadforoneconvolution operationis Lat load = Bits input /BW ld .Theterm Lat load \nrepresentsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.Theterm BW ld denotesthebandwidthof eachloadoperation.Themodelsof P store and Lat store can bederivedinasimilarfashion.",
      "type": "sliding_window",
      "tokens": 192
    },
    {
      "text": "Thelatency modelfordataloadforoneconvolution operationis Lat load = Bits input /BW ld .Theterm Lat load \nrepresentsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.Theterm BW ld denotesthebandwidthof eachloadoperation.Themodelsof P store and Lat store can bederivedinasimilarfashion. 2) ComputationonReRAMs: P comp isthedominantand mostcomplicatedpartwheretheanaloganddigitalsignals aremixed.Theenergyofone-cycle MACoperationsforan activationsizeof m×n andactualduplicationaG, P comp−tile \ndividesintothefollowingparts:1) E DAC   denotestheenergy consumedforconvertingthedigitalinputsignaltotheanalog signalinabit-serialfashion;2) E MAC   denotestheenergy forperforming MACoperationsonReRAMs;and3) E ADC \nconsistsofthreepartsasshowninFigure5:3i) E BL   denoting theenergyforactivatingbitlines;3ii) E SA−Ref   denotingthe energyforsensingandamplifyingthe MACresultsignaland thenreferencinganalogsignalstodigitalsignals;and,3iii) E S+A   denotingtheenergyofShift&Addparttocomposethe ﬁnaloutput. IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisﬁxedas Lat comp = T comp ,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1.",
      "type": "sliding_window",
      "tokens": 425
    },
    {
      "text": "IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisﬁxedas Lat comp = T comp ,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1. E comp =E comp tile /Lat comp \n=(E DAC   +E MAC   +E ADC )/T comp (1) \nThepowerofeachpartistakentobelineartothetiling factorsofm ornortheactualparallelismgranularityaG. TheenergyforoneReRAMrow(e DAC ),oneReRAMcell (e MAC  )andoneReRAMcolumn(e BL ,e SA−Ref ,e S+A )are theworst-casevaluesfromthesimulation.Table V-B 2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies.",
      "type": "sliding_window",
      "tokens": 233
    },
    {
      "text": "TheenergyforoneReRAMrow(e DAC ),oneReRAMcell (e MAC  )andoneReRAMcolumn(e BL ,e SA−Ref ,e S+A )are theworst-casevaluesfromthesimulation.Table V-B 2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies. TABLEII R ELATIONSHIPOFENERGYANDTHE R E RAM TILINGSIZEAND R E RAM COPIES . Component Energyequation DAC E DAC =e DAC ×m×aG Computation E M AC =e MAC   ×m×n×aG \nADC BL E BL =e BL ×n×aG SA-Ref E SA−Ref =e SA−Ref ×n×aG S+A E S+A =e S+A ×n×aG \n3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated.",
      "type": "sliding_window",
      "tokens": 272
    },
    {
      "text": "Component Energyequation DAC E DAC =e DAC ×m×aG Computation E M AC =e MAC   ×m×n×aG \nADC BL E BL =e BL ×n×aG SA-Ref E SA−Ref =e SA−Ref ×n×aG S+A E S+A =e S+A ×n×aG \n3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated. Asaresult,thesepartialsumsneedtobe mergedoncethe (tile)traversalofanentireReRAMiscomplete.Thesum mergingoperationisperformedbyanAdderTreeasillustrated inFigure3. Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint of P merg   <P budget shouldbealways met.Therefore,the power P merge   andlatency Lat merge   ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofﬂine.",
      "type": "sliding_window",
      "tokens": 276
    },
    {
      "text": "Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint of P merg   <P budget shouldbealways met.Therefore,the power P merge   andlatency Lat merge   ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofﬂine. 4)Activationtransitioncost:Theexecutiontransitionfrom onetiletoanotherinsideonepowercycleorfromoneactivation solutiontoanotherindifferentpowerlevelsalsocostspower P trans andlatency Lat trans .Activationtransitionimpliesthat weneedtoenablethecorrespondingcircuitsoftheto-be- activatedrowsandcolumnswhileshuttingdowntheothers. Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs.",
      "type": "sliding_window",
      "tokens": 211
    },
    {
      "text": "Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs. 5)Powerandlatencymodels:Theaboveanalysiscaptures thepowerconsumptionandexecutionlatencyofprocessing oneconvolutionlayer .Itisassumedthatallofthesesteps areperformedinsequence.Puttingthemalltogether,for convolutionlayerLk,thepowerandlatencypaircanbemodeled asinEquation2and3. P LK  =(P ld × Lat ld Lk   +P comp × Lat comp Lk \n+P st × Lat st Lk   +P merge  × Lat merge Lk )/Lat Lk (2) \nLat LK  = Lat ld Lk   + Lat comp Lk + Lat st Lk   + Lat merge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC ≥ 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication.",
      "type": "sliding_window",
      "tokens": 328
    },
    {
      "text": "P LK  =(P ld × Lat ld Lk   +P comp × Lat comp Lk \n+P st × Lat st Lk   +P merge  × Lat merge Lk )/Lat Lk (2) \nLat LK  = Lat ld Lk   + Lat comp Lk + Lat st Lk   + Lat merge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC ≥ 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication. Underthesequentialcomputation mode, theconvolutionlayersareexecutedonebyoneinasequential \nfashion, and as a result, the power model and latency model in Equations 2 and 3 can be directly used. We also model the pipelined computation mode shown in Equations 4 and 5.",
      "type": "sliding_window",
      "tokens": 262
    },
    {
      "text": "We also model the pipelined computation mode shown in Equations 4 and 5. Note that the pipelined computation mode means that all the  LC convolution layers are executed fully parallel. P   pipe   = \nLC X \nLk =1 P Lk (4) \nLat pipe   =  max ( Lat L 1 , Lat L 2 ...Lat LC ) (5) \nC. Dynamic activation strategy \n1) Problem formulation:  In this section, we focus on ﬁguring out the ResiSchedule solution to achieve the maximal throughput.",
      "type": "sliding_window",
      "tokens": 115
    },
    {
      "text": "P   pipe   = \nLC X \nLk =1 P Lk (4) \nLat pipe   =  max ( Lat L 1 , Lat L 2 ...Lat LC ) (5) \nC. Dynamic activation strategy \n1) Problem formulation:  In this section, we focus on ﬁguring out the ResiSchedule solution to achieve the maximal throughput. Although we can arrange more hardware resources with the pipelined computation mode, it does not mean this mode will always yield greater computation progress than the sequential mode due to the constraints of tile size and parallelism granularity. Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes.",
      "type": "sliding_window",
      "tokens": 150
    },
    {
      "text": "Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Given a power supply level, we can derive the optimal tile size and actual duplication granularity to form the activation solution  ⟨ m, n, aG ⟩ for sequential or pipelined computation modes, respectively. Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level.",
      "type": "sliding_window",
      "tokens": 108
    },
    {
      "text": "Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level. Throughput model  Achieving the maximal computation progress under the harvested energy has two implications. The ﬁrst one is that we expect more energy can be used for program progress.",
      "type": "sliding_window",
      "tokens": 65
    },
    {
      "text": "The ﬁrst one is that we expect more energy can be used for program progress. The other is more subtle in that we expect the power can be consumed quickly in order to receive more energy from outside. In this regard, the metric  throughput  measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios.",
      "type": "sliding_window",
      "tokens": 81
    },
    {
      "text": "In this regard, the metric  throughput  measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios. We use the number of convolutional MAC operations to represent the computations. For the sequential computation mode, the throughput for Layer  Lk  can be expressed as below: \nThr sequ Lk =  ( m  ×  n ) Lk  ×  aG Lk \nLat Lk (6) \nThe average throughput with a  LC -convolution CNN infer- ence can be expressed as shown below.",
      "type": "sliding_window",
      "tokens": 134
    },
    {
      "text": "For the sequential computation mode, the throughput for Layer  Lk  can be expressed as below: \nThr sequ Lk =  ( m  ×  n ) Lk  ×  aG Lk \nLat Lk (6) \nThe average throughput with a  LC -convolution CNN infer- ence can be expressed as shown below. Thr sequ ave   = P Lk = LC Lk =1 ( m  ×  n ) Lk  ×  aG Lk P Lk = C Lk =1   Lat Lk (7) \nFor the pipelining computation mode, all the  LC  layers are executed in parallel. The throughput can be expressed as follows: \nThr pipe ave   = P Lk = LC Lk =1 ( m  ×  n ) Lk  ×  aG Lk \nLat pipe (8) \n2) Activation strategy formulation :  The activation strategy for the sequential mode can be described as shown below.",
      "type": "sliding_window",
      "tokens": 217
    },
    {
      "text": "The throughput can be expressed as follows: \nThr pipe ave   = P Lk = LC Lk =1 ( m  ×  n ) Lk  ×  aG Lk \nLat pipe (8) \n2) Activation strategy formulation :  The activation strategy for the sequential mode can be described as shown below. In order to formulate the problem in a concise way, the tiling factors,  m  and  n , are constrained to be divisors of the ReRAM weight matrix M ×  N using the annotations of  m  |  M ;  n  |  N . Objective:  Maximize  Thr sequ ave Subjected to:  for each layer Lk, P   load Lk   , P  store Lk , P   comp Lk , P   trans Lk , P   merge Lk < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ⟨ m Lk , n Lk , aG Lk ⟩ for each layer Lk \nSimilarly, the activation strategy under the pipeline execution mode can be described as below.",
      "type": "sliding_window",
      "tokens": 270
    },
    {
      "text": "Objective:  Maximize  Thr sequ ave Subjected to:  for each layer Lk, P   load Lk   , P  store Lk , P   comp Lk , P   trans Lk , P   merge Lk < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ⟨ m Lk , n Lk , aG Lk ⟩ for each layer Lk \nSimilarly, the activation strategy under the pipeline execution mode can be described as below. Objective:  Maximize  Thr pipe ave Subjected to: P  P  load , P  P  store , P  P  comp pipe   , P  P  trans , P  P  merge < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ⟨ m Lk , n Lk , aG Lk ⟩ for each layer Lk \nBy solving the above problems, we can obtain activation solution  ⟨ m, n, aG ⟩ for each power level under the sequential and pipelining computation modes, referred to as  SOL sequ \nand  SOL pipe   respectively. Then the optimal solution can be selected from among them.",
      "type": "sliding_window",
      "tokens": 308
    },
    {
      "text": "Then the optimal solution can be selected from among them. The solution space is actually very small because of the constraints that tile size candidates and aG  are all bounded in the integer domain. It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode.",
      "type": "sliding_window",
      "tokens": 67
    },
    {
      "text": "It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode. In this case, we choose the activation solution with larger tiling size by taking into account the transition cost. If the tiling sizes of output solutions are the same, we choose larger  m because larger  m  implies fewer partial sum adds.",
      "type": "sliding_window",
      "tokens": 82
    },
    {
      "text": "If the tiling sizes of output solutions are the same, we choose larger  m because larger  m  implies fewer partial sum adds. D. Activation transition \nThe power instability of energy harvesting implies that the activation solution needs to change dynamically as power level changes. Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy.",
      "type": "sliding_window",
      "tokens": 78
    },
    {
      "text": "Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy. An FSM transition can happen between any pair of power levels. Activation solution under power level  l: <m l , n l , aG l > \nActivation solution under power level  h: <m h , n h , aG h > \nSmooth transition l->h without power prediction \nSmooth transition l->h \nwith power prediction \nSmooth transition h->l without power prediction \nSmooth transition h->l \nwith power prediction \n1 \n2 \n3 \n4 \nFig.",
      "type": "sliding_window",
      "tokens": 132
    },
    {
      "text": "Activation solution under power level  l: <m l , n l , aG l > \nActivation solution under power level  h: <m h , n h , aG h > \nSmooth transition l->h without power prediction \nSmooth transition l->h \nwith power prediction \nSmooth transition h->l without power prediction \nSmooth transition h->l \nwith power prediction \n1 \n2 \n3 \n4 \nFig. 7. Activation solution transition FSM \nThe convolution computations of one inference may not be completed while transitioning to a new power level.",
      "type": "sliding_window",
      "tokens": 133
    },
    {
      "text": "Activation solution transition FSM \nThe convolution computations of one inference may not be completed while transitioning to a new power level. For small-scale applications with strong harvested power supply, discarding the incomplete execution may have only modest overheads. However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle. Fortunately, there exist opportunities to keep and transfer the intermediate computation results of the last incomplete inference to the next power cycle. Considering a transition \nfor one layer from an activation solution  ⟨ m 1 , n 1 , aG 1 ⟩ to ⟨ m 2 , n 2 , aG 2 ⟩ , we ﬁnd that, if the expression  Condition trans : ( m 1 =  m 2)&( n 2  |  ( Tile count 1   ×  n 1))&( aG 1 =  aG 2) is true for each convolution layer, the activation solution ⟨ m 1 , n 1 , aG 1 ⟩ with power level PL1 can be transferred to be equivalent to an execution of activation solution  ⟨ m 2 , n 2 , aG 2 ⟩ with PL2.",
      "type": "sliding_window",
      "tokens": 233
    },
    {
      "text": "Considering a transition \nfor one layer from an activation solution  ⟨ m 1 , n 1 , aG 1 ⟩ to ⟨ m 2 , n 2 , aG 2 ⟩ , we ﬁnd that, if the expression  Condition trans : ( m 1 =  m 2)&( n 2  |  ( Tile count 1   ×  n 1))&( aG 1 =  aG 2) is true for each convolution layer, the activation solution ⟨ m 1 , n 1 , aG 1 ⟩ with power level PL1 can be transferred to be equivalent to an execution of activation solution  ⟨ m 2 , n 2 , aG 2 ⟩ with PL2. The execution equivalency can be transferred by Tile count 2   =  Tile count 1   ×  n 1 /n 2 . The next power cycle’s level information cannot be known with certainty.",
      "type": "sliding_window",
      "tokens": 214
    },
    {
      "text": "The next power cycle’s level information cannot be known with certainty. In order to not discard the acquired results, we can search the maximal   ∗ Tile count 1   where   ∗ Tile count 1   ≤ Tile count 1   to make the expression  n 2  |  ( ∗ Tile count 1   ×  n 1) conservatively true for each layer, and then transfer the tile count ∗ Tile count 1  to accommodate to the new activation solution. This means that only a portion of computation results from   ∗ Tile count 1   to  Tile count 1   will be discarded.",
      "type": "sliding_window",
      "tokens": 116
    },
    {
      "text": "This means that only a portion of computation results from   ∗ Tile count 1   to  Tile count 1   will be discarded. The discussion on this transition without power prediction is applied for transitions 1  and 2  in the Figure 7. We call this smooth transition strategy as  Transition Keep .",
      "type": "sliding_window",
      "tokens": 57
    },
    {
      "text": "We call this smooth transition strategy as  Transition Keep . With a power predictor [ 36 ], we can estimate the power level of the next power cycle in advance. In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference.",
      "type": "sliding_window",
      "tokens": 64
    },
    {
      "text": "In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference. Still, with Condition trans   satisﬁed, the smooth transition can be achieved in a similar way. Otherwise, if the expression  Condition trans \nis not satisﬁed, with power prediction, we can still speculatively attempt to perform a smooth transition.",
      "type": "sliding_window",
      "tokens": 80
    },
    {
      "text": "Otherwise, if the expression  Condition trans \nis not satisﬁed, with power prediction, we can still speculatively attempt to perform a smooth transition. There are two strategies to achieve this. •  We can search for an intermediate power level, where we ﬁrst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level – this strategy is called  Multi-step Transition .",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "•  We can search for an intermediate power level, where we ﬁrst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level – this strategy is called  Multi-step Transition . •  If the power predictor reports a power transition from a high level to a low level, we can move to the new activation solution before performing the last incomplete inference – this strategy is referred to as  Eager Transition . The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7.",
      "type": "sliding_window",
      "tokens": 122
    },
    {
      "text": "The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7. Since a power predictor itself consumes power, it makes sense to employ it for large-scale applications under weak power sources where discarding a portion of computations may impose a big loss or for the scenarios where power level transitions happen frequently. VI.",
      "type": "sliding_window",
      "tokens": 77
    },
    {
      "text": "VI. E XPERIMENTS \nTo evaluate ResiRCA, we have extended the Gem5 [ 37 ] simulator with RCA modeling. The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock.",
      "type": "sliding_window",
      "tokens": 56
    },
    {
      "text": "The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock. The energy harvesting mechanism is supported by the power management unit, which can record power production and consumption at an execution cycle level. The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs.",
      "type": "sliding_window",
      "tokens": 96
    },
    {
      "text": "The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs. We perform cycle-accurate simulation for the MAC computations based on tile activation and the data load/store process. However, for other functional units, we assign a ﬁxed latency.",
      "type": "sliding_window",
      "tokens": 89
    },
    {
      "text": "However, for other functional units, we assign a ﬁxed latency. For the ReRAM circuit simulation, we quantify power and performance of our design in HSPice [ 38 ] using 20nm \nFinFET ReRAM parameters from [ 39 ]. Load/store parameters of the ReRAM memory are from NVSim [ 40 ].",
      "type": "sliding_window",
      "tokens": 74
    },
    {
      "text": "Load/store parameters of the ReRAM memory are from NVSim [ 40 ]. The main parameters of our simulations are given in Table VI. Four practical CNNs listed in Table VI are evaluated on the ﬁve power traces illustrated in Figure 4 for each of the ﬁve execution strategies from Section  V-A 3:  Naive1 ;  Naive2 ;  Sequential ; Pipelining ; and  ResiSchedule .",
      "type": "sliding_window",
      "tokens": 95
    },
    {
      "text": "power Input \nPV [41] \nInput 1@50 × 50 Conv1 8@6 × 6 × 1 36 × 8 752.2 µ W 8@45 × 45 Conv2 12@3 × 3 × 8 72 × 12 1125.6 µ W 12@20 × 20 Conv3 16@3 × 3 × 12 108 × 16 1526 µ W 16@8 × 8 Conv4 10@3 × 3 × 16 144 × 10 1114 µ W 10@6 × 6 Conv5 6@3 × 3 × 10 90 × 6 676.2 µ W 6@4 × 4 \nFR [42] \nInput 1@32 × 32 Conv1 4@5 × 5 × 1 25 × 4 377.4 µ W 4@28 × 28 Conv2 16@4 × 4 × 4 64 × 16 1433.6 µ W 16@10 × 10 \nLeNet [43] \nInput 1@32 × 32 Conv1 6@5 × 5 × 1 25 × 6 539.7 µ W 6@28 × 28 Conv2 16@5 × 5 × 6 150 × 16 1614.2 µ W 16@10 × 10 \nHG [44] \nInput 1@28 × 28 Conv1 6@5 × 5 × 1 25 × 6 539.7 µ W 6@24 × 24 Conv2 12@4 × 4 × 6 96 × 12 1176 µ W 12@8 × 8 \nFor each application on each power trace, we report the throughput and energy efﬁciency under the ﬁve different execution strategies. We then demonstrate the beneﬁts from the proposed smooth transition strategy and power prediction. We also study the sensitivity of our proposed approach to available ReRAM hardware resources.",
      "type": "sliding_window",
      "tokens": 420
    },
    {
      "text": "We also study the sensitivity of our proposed approach to available ReRAM hardware resources. A. Throughput \nFigure 8 shows the throughput comparison of the ﬁve exe- cution strategies. The bars are all normalized to  ResiSchedule .",
      "type": "sliding_window",
      "tokens": 54
    },
    {
      "text": "The bars are all normalized to  ResiSchedule . The included table gives the absolute values of throughput by ResiSchedule. The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 ×  compared to a baseline RCA with intermittency-unaware scheduling.",
      "type": "sliding_window",
      "tokens": 81
    },
    {
      "text": "The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 ×  compared to a baseline RCA with intermittency-unaware scheduling. One can make the following observations and analyses from these results: •  For each workload with each power source,  ResiSchedule always achieves the highest throughput because it combines the best activation solution in each power cycle. The results of Naive1  are the worst because it lacks both adequate hardware resources and scheduling ﬂexibility.",
      "type": "sliding_window",
      "tokens": 117
    },
    {
      "text": "The results of Naive1  are the worst because it lacks both adequate hardware resources and scheduling ﬂexibility. Although  Naive2  is based on the  ResiRCA  architecture, the throughput is still relatively low because it lacks scheduling adaptation to ﬁt to the changing harvested power. •  The results of  ResiSchedule  are very close or equal to that of  Sequential  under most cases.",
      "type": "sliding_window",
      "tokens": 81
    },
    {
      "text": "•  The results of  ResiSchedule  are very close or equal to that of  Sequential  under most cases. When we track the simulation cycles, it is found that the throughput of  Sequential  solution \nResiSchedule \nPiezo WiFi-home WiFi-office Thermal TV-RF \nFig. 8.",
      "type": "sliding_window",
      "tokens": 66
    },
    {
      "text": "8. Throughput of CNNs across the power sources normalized to ResiSchedule \nPiezo WiFi-home WiFi-office Thermal TV-RF \nFig. 9.",
      "type": "sliding_window",
      "tokens": 37
    },
    {
      "text": "9. Energy efﬁciency of CNNs across the power sources normalized to ResiSchedule \nis higher than that of  Pipelining  solution for a signiﬁcant fraction of the active power cycles. That is, the selection ratio of  Sequential  is much higher than the ratio of  Pipelining  in ResiSchedule  solutions in the whole power trace.",
      "type": "sliding_window",
      "tokens": 71
    },
    {
      "text": "That is, the selection ratio of  Sequential  is much higher than the ratio of  Pipelining  in ResiSchedule  solutions in the whole power trace. •  Consistent with the above observation, the entire  Sequential strategy competes with the entire  Pipelining . The reason is that the active power threshold of  Pipelining  is much higher than that of  Sequential .",
      "type": "sliding_window",
      "tokens": 77
    },
    {
      "text": "The reason is that the active power threshold of  Pipelining  is much higher than that of  Sequential . As a result, fewer power cycles of Pipelining  are available than that of  Sequential . However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments.",
      "type": "sliding_window",
      "tokens": 64
    },
    {
      "text": "However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments. When we change to a smaller ReRAM duplication granularity  G , we ﬁnd that the throughput of  Pipelining  is better than that of  Sequential for many power levels. The duplication sensitivity results are presented in Section VI-F. •  Regarding the throughput absolute values, the results with the power sources of  Thermal  and  TV-RF  are much higher than those with the others, which is constant with the power strength illustrated in Figure 4.",
      "type": "sliding_window",
      "tokens": 116
    },
    {
      "text": "The duplication sensitivity results are presented in Section VI-F. •  Regarding the throughput absolute values, the results with the power sources of  Thermal  and  TV-RF  are much higher than those with the others, which is constant with the power strength illustrated in Figure 4. B. Energy efﬁciency \nWe evaluate energy efﬁciency by measuring MAC operations per Joule, as shown in Figure 9.",
      "type": "sliding_window",
      "tokens": 79
    },
    {
      "text": "Energy efﬁciency \nWe evaluate energy efﬁciency by measuring MAC operations per Joule, as shown in Figure 9. Note that this includes the energy overheads of data movements and other functional units in addition to MACs. Overall, the normalized results of energy efﬁciency are very similar to those of the throughput evaluation.",
      "type": "sliding_window",
      "tokens": 64
    },
    {
      "text": "Overall, the normalized results of energy efﬁciency are very similar to those of the throughput evaluation. The results show that ResiRCA and ResiSchedule achieve average energy efﬁciency improvements of 14 ×  compared to a baseline RCA with intermittency-unaware scheduling. The only difference that can be observed is that, regarding LeNet  and  PV  with the power source of  Thermal , relatively speaking, the results of energy efﬁciency with  Pipelining strategy are higher than that appearing in the throughput evaluation.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "The only difference that can be observed is that, regarding LeNet  and  PV  with the power source of  Thermal , relatively speaking, the results of energy efﬁciency with  Pipelining strategy are higher than that appearing in the throughput evaluation. One possible reason for this is that  Pipelining \nrequires loading several inputs from ReRAM memory to perform the parallel operations, which is power-expensive. This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efﬁciency when active is high.",
      "type": "sliding_window",
      "tokens": 107
    },
    {
      "text": "This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efﬁciency when active is high. Compared to the cloud for online processing, the preference for local compute over ofﬂoad can stem from security, con- nectivity and latency concerns as well as power and energy constraints. In our work, local computation across the CNN applications is  ∼ 50x more efﬁcient than transmission over Bluetooth with 3Mbps and 2.5mW.",
      "type": "sliding_window",
      "tokens": 97
    },
    {
      "text": "In our work, local computation across the CNN applications is  ∼ 50x more efﬁcient than transmission over Bluetooth with 3Mbps and 2.5mW. C. Power utilization In order to further understand the power utilization, we use a two-dimensional plot that illustrates the features of power consumption with the ResiSchedule  strategy, as shown in Figure 10. The x-axis (power efﬁciency) denotes the percentage of power cycles where the RCA can activate.",
      "type": "sliding_window",
      "tokens": 99
    },
    {
      "text": "The x-axis (power efﬁciency) denotes the percentage of power cycles where the RCA can activate. The y-axis (power utilization), on the other hand, denotes the percentage of valid power during activations which is actually utilized for computation and data transfer. An ideal system would be at the point (1,1).",
      "type": "sliding_window",
      "tokens": 73
    },
    {
      "text": "An ideal system would be at the point (1,1). It can be observed from these results that the proposed  ResiSchedule  strategy can make good use of the  Piezo source when it does exceed the minimal activation thresholds, though the very low duty cycle yields very low throughput. 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 \n0 0.10.20.30.40.50.60.70.80.9 1 \nPower Utilization \nPower efficiency \nPiezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG \nFig.",
      "type": "sliding_window",
      "tokens": 170
    },
    {
      "text": "0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 \n0 0.10.20.30.40.50.60.70.80.9 1 \nPower Utilization \nPower efficiency \nPiezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG \nFig. 10. ResiSchedule power efﬁciency analysis \nD. Transition efﬁciency Table  VI-D  shows the ratio of inferences using smooth- transitioned partial results and total inference count number.",
      "type": "sliding_window",
      "tokens": 148
    },
    {
      "text": "ResiSchedule power efﬁciency analysis \nD. Transition efﬁciency Table  VI-D  shows the ratio of inferences using smooth- transitioned partial results and total inference count number. These results indicate that the smooth transition strategy Transition Keep   enables a signiﬁcant fraction of the inferences for all workloads on  Piezo . However, a very small fraction is observed with the other, stronger power sources.",
      "type": "sliding_window",
      "tokens": 88
    },
    {
      "text": "However, a very small fraction is observed with the other, stronger power sources. For Piezo , saving the intermediate results of one incomplete inference is meaningful. However, one power cycle of the other power sources can usually process thousands or hundreds of inferences.",
      "type": "sliding_window",
      "tokens": 57
    },
    {
      "text": "However, one power cycle of the other power sources can usually process thousands or hundreds of inferences. TABLE V T HE RATIO OF ADDITIONAL INFERENCES ENABLED BY THE SMOOTH TRANSITION STRATEGY VS . TOTAL INFERENCES \nPiezo WiFi-h WiFi-o Thermal TV-RF \nLeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 \nE. Power predictor \nWith an accurate power predictor [ 45 ], [ 36 ], we can make more smooth transitions among different power levels.",
      "type": "sliding_window",
      "tokens": 199
    },
    {
      "text": "TOTAL INFERENCES \nPiezo WiFi-h WiFi-o Thermal TV-RF \nLeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 \nE. Power predictor \nWith an accurate power predictor [ 45 ], [ 36 ], we can make more smooth transitions among different power levels. The beneﬁt is that we can keep more MAC results of the last \nincomplete inference when switching from a higher power level to a lower power level, even if  Condition trans   is not satisﬁed. However, to be valuable the power predictor must have high accuracy.",
      "type": "sliding_window",
      "tokens": 193
    },
    {
      "text": "However, to be valuable the power predictor must have high accuracy. For both  Piezo  and  Thermal  power sources the prediction accuracy when using a multi-power-level-optimized extension of the power predictor in [ 36 ] are above 80%. Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with  Transition keep   for all the workloads with these power sources.",
      "type": "sliding_window",
      "tokens": 94
    },
    {
      "text": "Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with  Transition keep   for all the workloads with these power sources. 0.0% \n0.3% \n0.0% \n0.3% \n0.0% \n0.9% \n1.9% \n2.0% \n0.0% \n0.5% \n0.0% \n20.0% \n40.0% \n60.0% \nvs. # all inferences vs. # addi. inferences w/ smooth transition vs. # all inferences vs. # addi.",
      "type": "sliding_window",
      "tokens": 112
    },
    {
      "text": "inferences w/ smooth transition vs. # all inferences vs. # addi. inferences w/ smooth transition \nPiezo Thermal \nLeNet FR HG PV \nFig. 11.",
      "type": "sliding_window",
      "tokens": 49
    },
    {
      "text": "11. Percentages of additional inferences with power prediction over all inferences and additional inferences with the  Transition keep \nstrategy \nThe portion of inferences added with power prediction are signiﬁcant for  Piezo  for most workloads. This is because, the Piezo  source is very weak and and the total completed number of inferences is quite small.",
      "type": "sliding_window",
      "tokens": 75
    },
    {
      "text": "This is because, the Piezo  source is very weak and and the total completed number of inferences is quite small. Speculative action supported by power prediction can keep quite a few incomplete inferences to be completed in the next power cycle. This can also explain why the portions with the power source of  Thermal  are very small.",
      "type": "sliding_window",
      "tokens": 72
    },
    {
      "text": "This can also explain why the portions with the power source of  Thermal  are very small. However, for both  Piezo  and  Thermal , the portions for  PV  are very small. The underlying reason is that the smooth  Transition keep   strategy can already handle the smooth transitions with no need of power prediction support for this workload.",
      "type": "sliding_window",
      "tokens": 66
    },
    {
      "text": "The underlying reason is that the smooth  Transition keep   strategy can already handle the smooth transitions with no need of power prediction support for this workload. F. Sensitivity study on duplication copy \nWe vary the ReRAM duplication granularity  G  for each layer and evaluate with  TV-RF  source. Throughput results are plotted in Figure 12 and area costs for  G 1  ∼ G 5  can be found in Figure 13.",
      "type": "sliding_window",
      "tokens": 89
    },
    {
      "text": "Throughput results are plotted in Figure 12 and area costs for  G 1  ∼ G 5  can be found in Figure 13. For each benchmark, all the numbers are normalized to that of the  G4  setting with the  Naive2  policy. As expected, the throughput increases as  G  grows for every benchmark.",
      "type": "sliding_window",
      "tokens": 64
    },
    {
      "text": "As expected, the throughput increases as  G  grows for every benchmark. Another interesting observation is that the results of  ResiSchedule  policy can be competitive to that of  Sequential policy when  G  is small and vice versa. The main reason for this is that the  ResiSchedule  policy can efﬁciently organize more hardware resources than the  Sequential  policy when hardware resources are limited.",
      "type": "sliding_window",
      "tokens": 80
    },
    {
      "text": "The main reason for this is that the  ResiSchedule  policy can efﬁciently organize more hardware resources than the  Sequential  policy when hardware resources are limited. 0.00 0.20 0.40 0.60 0.80 1.00 1.20 1.40 1.60 \nG1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 \nPV HG LeNet FR \nNaive2 Sequential Pipelining ResiSchedule \nFig. 12.",
      "type": "sliding_window",
      "tokens": 115
    },
    {
      "text": "12. Throughput normalized to G4 with  Naive2  vs. ReRAM duplication granularity \nThe RCA area is impacted from the parallelism granularity G , as shown in Figure 13. It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed “smart dust” solutions [ 8 ].",
      "type": "sliding_window",
      "tokens": 78
    },
    {
      "text": "It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed “smart dust” solutions [ 8 ]. The ideal parallelism granularity determination for a particular deployment should consider the balance between throughput and area. 0 20000 40000 60000 80000 100000 120000 140000 160000 \nPV HG LeNet FR G1 G2 G3 G4 (default) G5 \nArea in ­ m 2 \n<2, 2, 2, 2, 2> <4, 3, 2, 3, 5> <6, 4, 3, 4, 7> <8, 5, 4, 5, 9> \n<12, 7, 6, 7, 13> \n<2, 2> <6, 2> <9, 3> <11, 5> <16, 7> \n<2, 2> <5, 2> <8, 3> <11, 4> <16, 6> \n<2, 2> <7, 2> <13, 3> <17, 4> <22, 6> \nFig.",
      "type": "sliding_window",
      "tokens": 228
    },
    {
      "text": "0 20000 40000 60000 80000 100000 120000 140000 160000 \nPV HG LeNet FR G1 G2 G3 G4 (default) G5 \nArea in ­ m 2 \n<2, 2, 2, 2, 2> <4, 3, 2, 3, 5> <6, 4, 3, 4, 7> <8, 5, 4, 5, 9> \n<12, 7, 6, 7, 13> \n<2, 2> <6, 2> <9, 3> <11, 5> <16, 7> \n<2, 2> <5, 2> <8, 3> <11, 4> <16, 6> \n<2, 2> <7, 2> <13, 3> <17, 4> <22, 6> \nFig. 13. Area with different duplication granularity \nVII.",
      "type": "sliding_window",
      "tokens": 186
    },
    {
      "text": "Area with different duplication granularity \nVII. R ELATED  W ORK \nThe previous RCA related work can be divided into the following two categories: High Performance RCA Architectures: PRIME [ 4 ] uses 6-bit inputs and 8-bit weights and targets 6-bit output precision. A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight.",
      "type": "sliding_window",
      "tokens": 100
    },
    {
      "text": "A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight. In the PRIME conﬁguration, the ReRAM-based Full Function (FF) subarrays have both computation and data storage capabilities. To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed. In the ISAAC design [ 3 ], the inputs, weights and outputs are all 16 bits, where the DAC, ReRAM cell and ADC resolutions are, respectively, 1-bit, 2-bit and 8-bit. Also, a similar composition scheme is employed to organize the input, weight and output data.",
      "type": "sliding_window",
      "tokens": 97
    },
    {
      "text": "Also, a similar composition scheme is employed to organize the input, weight and output data. The ISAAC architecture is composed of 16 tiles and each tile consists of 8 IMAs which includes 4 ReRAMs along with 4 sets of peripheral circuits. An intra-tile pipeline is formed to boost the dot-product throughput.",
      "type": "sliding_window",
      "tokens": 72
    },
    {
      "text": "An intra-tile pipeline is formed to boost the dot-product throughput. In the PipeLayer design [ 5 ], a spike-based scheme, instead of a voltage-level based scheme, is used for input to eliminate the power overhead of DACs and ADCs. The underlying idea is to use spike counts to represent the data value.",
      "type": "sliding_window",
      "tokens": 79
    },
    {
      "text": "The underlying idea is to use spike counts to represent the data value. They propose intra-layer and inter-layer parallelism to support the training phase by reducing potential stalls. ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [ 8 ] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets.",
      "type": "sliding_window",
      "tokens": 99
    },
    {
      "text": "ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [ 8 ] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets. It includes four ReRAMs, each 32x32. The inputs and weights are binary and the output is adaptive between 1-3 bits.",
      "type": "sliding_window",
      "tokens": 89
    },
    {
      "text": "The inputs and weights are binary and the output is adaptive between 1-3 bits. The serial-input non-weighted product (SINWP) structure [ 6 ] is the ﬁrst work to propose multi-bit input/weight and output design from the circuit level, adopting a 2-bit input, 3-bit weight, and 4-bit output scheme. Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a \n3-bit resolution, which is a high performance but also a high power consuming design.",
      "type": "sliding_window",
      "tokens": 127
    },
    {
      "text": "Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a \n3-bit resolution, which is a high performance but also a high power consuming design. Although the above designs provide different approaches to achieve high throughput, high energy efﬁciency and low power, they cannot be directly applied or combined to be applied in the energy harvested edge devices due to the following reasons. •  The architecture-centric works [ 3 ], [ 4 ], [ 5 ] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption.",
      "type": "sliding_window",
      "tokens": 127
    },
    {
      "text": "•  The architecture-centric works [ 3 ], [ 4 ], [ 5 ] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption. Furthermore, the hierarchy they adopt with multiple ReRAMs targets primarily high throughput, leading to high power consumption on the whole RCA. For example, the total 168  Tiles  and one  IMA  element of the ISAAC architecture [ 3 ] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets.",
      "type": "sliding_window",
      "tokens": 137
    },
    {
      "text": "For example, the total 168  Tiles  and one  IMA  element of the ISAAC architecture [ 3 ] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets. It can be seen that those designs are  not  suitable for an RCA supplied with harvested unstable power. •  Although the spike-based scheme [ 5 ] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input/output data.",
      "type": "sliding_window",
      "tokens": 132
    },
    {
      "text": "•  Although the spike-based scheme [ 5 ] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input/output data. It is known that the energy harvesting system often suffers from power failures and works in an intermittent mode; so, the spike-based data injection scheme is not favorable. •  For the ReRAM circuit concerned works [ 6 ], [ 8 ], although they are lightweight, they  cannot  be dynamically reconﬁgured to adapt changing power levels.",
      "type": "sliding_window",
      "tokens": 111
    },
    {
      "text": "•  For the ReRAM circuit concerned works [ 6 ], [ 8 ], although they are lightweight, they  cannot  be dynamically reconﬁgured to adapt changing power levels. In addition, such works have not presented any software level solution to maximize the utilization of the hardware platform. In order to accommodate the RCA to the changing harvested power supply, we need a “lightweight” and “ﬁne-grain controllable” design from both the hardware and software angles.",
      "type": "sliding_window",
      "tokens": 97
    },
    {
      "text": "In order to accommodate the RCA to the changing harvested power supply, we need a “lightweight” and “ﬁne-grain controllable” design from both the hardware and software angles. VIII. C ONCLUSION \nMAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs.",
      "type": "sliding_window",
      "tokens": 80
    },
    {
      "text": "C ONCLUSION \nMAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs. Considering the application sce- narios where the accelerator is supported by harvested energy, we ﬁnd that the previous designs cannot well accommodate the RCA to the changing power sources. This paper proposes ResiRCA, a resilient energy harvesting accelerator.",
      "type": "sliding_window",
      "tokens": 92
    },
    {
      "text": "This paper proposes ResiRCA, a resilient energy harvesting accelerator. We propose a lightweight and ﬂexibly tuning RCA architecture and a ResiSchedule scheme to dynamically activate various scaled MAC operations so as to fully translate the “harvested energy” into “computation progress”. ResiRCA supports smooth transi- tions among different activation solutions against computation loss.",
      "type": "sliding_window",
      "tokens": 87
    },
    {
      "text": "ResiRCA supports smooth transi- tions among different activation solutions against computation loss. The experiment results show that the proposed ResiRCA along with the ResiSchedule scheme can achieve much higher speedups and energy efﬁciency compared to the baselines. ResiRCA for the ﬁrst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future.",
      "type": "sliding_window",
      "tokens": 89
    },
    {
      "text": "ResiRCA for the ﬁrst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future. IX. A CKNOWLEDGEMENTS \nThis work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants #1822923 \n(SPX: SOPHIA), #1763681, #1629915, #1629129, #1317560, #1526750, National Natural Science Foundation of China [NSFC Project No.",
      "type": "sliding_window",
      "tokens": 147
    },
    {
      "text": "A CKNOWLEDGEMENTS \nThis work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants #1822923 \n(SPX: SOPHIA), #1763681, #1629915, #1629129, #1317560, #1526750, National Natural Science Foundation of China [NSFC Project No. 61872251] and Beijing Advanced Innova- tion Center for Imaging Technology. This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University.",
      "type": "sliding_window",
      "tokens": 149
    },
    {
      "text": "This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University. The authors also greatly appreciate Dr. Yongpan Liu, Dr. Kaisheng Ma, Dr. Xulong Tang and Mr. Challapalle Nagadastagiri Reddy’s useful discussion. R EFERENCES \n[1]  C. Xia, J. Zhao, H. Cui, and X. Feng, “Characterizing DNN models for edge-cloud computing,” in  2018 IEEE International Symposium on Workload Characterization (IISWC) , pp.",
      "type": "sliding_window",
      "tokens": 132
    },
    {
      "text": "R EFERENCES \n[1]  C. Xia, J. Zhao, H. Cui, and X. Feng, “Characterizing DNN models for edge-cloud computing,” in  2018 IEEE International Symposium on Workload Characterization (IISWC) , pp. 82–83, 2018. [2]  L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, “Switched by input: Power efﬁcient structure for RRAM-based convolutional neural network,” in  2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC) , pp.",
      "type": "sliding_window",
      "tokens": 162
    },
    {
      "text": "[2]  L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, “Switched by input: Power efﬁcient structure for RRAM-based convolutional neural network,” in  2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC) , pp. 1–6, 2016. [3]  A. Shaﬁee, A.",
      "type": "sliding_window",
      "tokens": 106
    },
    {
      "text": "[3]  A. Shaﬁee, A. Nag, N. Muralimanohar, R. Balasubramonian, J. P. Strachan, M. Hu, R. S. Williams, and V. Srikumar, “ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars,” in  2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA) , pp. 14–26, 2016.",
      "type": "sliding_window",
      "tokens": 113
    },
    {
      "text": "14–26, 2016. [4]  P. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang, and Y. Xie, “PRIME: A novel processing-in-memory architecture for neural network computation in reram-based main memory,” in  2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA) , pp. 27–39, 2016.",
      "type": "sliding_window",
      "tokens": 108
    },
    {
      "text": "27–39, 2016. [5]  L. Song, X. Qian, H. Li, and Y. Chen, “Pipelayer: A pipelined ReRAM- Based accelerator for deep learning,” in  2017 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pp. 541–552, 2017.",
      "type": "sliding_window",
      "tokens": 73
    },
    {
      "text": "541–552, 2017. [6]  C. Xue, W. Chen, J. Liu, J. Li, W. Lin, W. Lin, J. Wang, W. Wei, T. Chang, T. Chang, T. Huang, H. Kao, S. Wei, Y. Chiu, C. Lee, C. Lo, Y. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, “24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors,” in  2019 IEEE International Solid- State Circuits Conference - (ISSCC) , pp.",
      "type": "sliding_window",
      "tokens": 171
    },
    {
      "text": "King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, “24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors,” in  2019 IEEE International Solid- State Circuits Conference - (ISSCC) , pp. 388–390, 2019. [7]  W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y.",
      "type": "sliding_window",
      "tokens": 152
    },
    {
      "text": "[7]  W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, “A 65nm 1mb nonvolatile computing-in-memory ReRAM macro with sub-16ns multiply-and-accumulate for binary DNN AI edge processors,” in  2018 IEEE International Solid - State Circuits Conference (ISSCC) , pp. 494–496, 2018.",
      "type": "sliding_window",
      "tokens": 154
    },
    {
      "text": "494–496, 2018. [8]  F. Su, W. Chen, L. Xia, C. Lo, T. Tang, Z. Wang, K. Hsu, M. Cheng, J. Li, Y. Xie, Y. Wang, M. Chang, H. Yang, and Y. Liu, “A 462gops/j RRAM-based nonvolatile intelligent processor for energy harvesting ioe system featuring nonvolatile logics and processing-in-memory,” in  2017 Symposium on VLSI Technology , pp. T260–T261, 2017.",
      "type": "sliding_window",
      "tokens": 143
    },
    {
      "text": "T260–T261, 2017. [9]  Y. Ji, Y. Zhang, X. Xie, S. Li, P. Wang, X. Hu, Y. Zhang, and Y. Xie, “FPSA: A full system stack solution for reconﬁgurable reram-based NN accelerator architecture,” in  Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp. 733–747, 2019.",
      "type": "sliding_window",
      "tokens": 117
    },
    {
      "text": "733–747, 2019. [10]  K. Qiu, W. Chen, Y. Xu, L. Xia, Y. Wang, and Z. Shao, “A peripheral circuit reuse structure integrated with a retimed data ﬂow for low power rram crossbar-based cnn,” in  2018 Design, Automation Test in Europe Conference Exhibition (DATE) , pp. 1057–1062, March 2018.",
      "type": "sliding_window",
      "tokens": 103
    },
    {
      "text": "1057–1062, March 2018. [11]  X. Jiang, J. Polastre, and D. Culler, “Perpetual environmentally powered sensor networks,” in  Fourth International Symposium on Information Processing in Sensor Networks (IPSN) , pp. 463–468, 2005.",
      "type": "sliding_window",
      "tokens": 66
    },
    {
      "text": "463–468, 2005. [12]  S. Sudevalayam and P. Kulkarni, “Energy harvesting sensor nodes: Survey and implications,”  IEEE Communications Surveys Tutorials , vol. 13, no.",
      "type": "sliding_window",
      "tokens": 53
    },
    {
      "text": "443–461, 2011. [13]  M. Mangrulkar and S. G. Akojwar, “A simple and efﬁcient solar energy harvesting for wireless sensor node,” in  2016 Second International Con- ference on Research in Computational Intelligence and Communication Networks (ICRCICN) , pp. 95–99, 2016.",
      "type": "sliding_window",
      "tokens": 78
    },
    {
      "text": "95–99, 2016. [14]  R. Grezaud and J. Willemin, “A self-starting fully integrated auto-adaptive converter for battery-less thermal energy harvesting,” in  2013 IEEE 11th International New Circuits and Systems Conference (NEWCAS) , pp. 1–4, 2013.",
      "type": "sliding_window",
      "tokens": 70
    },
    {
      "text": "1–4, 2013. [15]  V. Leonov, T. Torfs, P. Fiorini, and C. Van Hoof, “Thermoelectric converters of human warmth for self-powered wireless sensor nodes,” IEEE Sensors Journal , vol. 7, pp.",
      "type": "sliding_window",
      "tokens": 66
    },
    {
      "text": "7, pp. 650–657, May 2007. [16]  X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, “RF-powered systems using steep-slope devices,” in  2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS) , pp.",
      "type": "sliding_window",
      "tokens": 83
    },
    {
      "text": "[16]  X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, “RF-powered systems using steep-slope devices,” in  2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS) , pp. 73– 76, 2014. [17]  K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Architecture exploration for ambient energy harvesting nonvolatile processors,” in  2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , pp.",
      "type": "sliding_window",
      "tokens": 174
    },
    {
      "text": "[17]  K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Architecture exploration for ambient energy harvesting nonvolatile processors,” in  2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , pp. 526–537, 2015. [18]  K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, “NEOFog: Nonvolatility-exploiting optimizations for fog computing,” in  Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS , pp.",
      "type": "sliding_window",
      "tokens": 215
    },
    {
      "text": "[18]  K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, “NEOFog: Nonvolatility-exploiting optimizations for fog computing,” in  Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS , pp. 782–796, 2018. [19]  M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, “Redesigning software and systems for non-volatile processors on self-powered devices,” in  2016 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC) , pp.",
      "type": "sliding_window",
      "tokens": 203
    },
    {
      "text": "[19]  M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, “Redesigning software and systems for non-volatile processors on self-powered devices,” in  2016 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC) , pp. 1–6, Sep. 2016. [20]  L. Ni, Z. Liu, H. Yu, and R. V. Joshi, “An energy-efﬁcient digital ReRAM-crossbar-based cnn with bitwise parallelism,”  IEEE Journal on Exploratory Solid-State Computational Devices and Circuits , vol.",
      "type": "sliding_window",
      "tokens": 163
    },
    {
      "text": "[20]  L. Ni, Z. Liu, H. Yu, and R. V. Joshi, “An energy-efﬁcient digital ReRAM-crossbar-based cnn with bitwise parallelism,”  IEEE Journal on Exploratory Solid-State Computational Devices and Circuits , vol. 3, pp. 37–46, Dec 2017.",
      "type": "sliding_window",
      "tokens": 82
    },
    {
      "text": "37–46, Dec 2017. [21]  M. Zhao, C. Fu, Z. Li, Q. Li, M. Xie, Y. Liu, J. Hu, Z. Jia, and C. J. Xue, “Stack-size sensitive on-chip memory backup for self-powered nonvolatile processors,”  IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) , vol. 36, pp.",
      "type": "sliding_window",
      "tokens": 109
    },
    {
      "text": "36, pp. 1804–1816, Nov 2017. [22]  A. Colin, E. Ruppel, and B. Lucia, “A reconﬁgurable energy storage architecture for energy-harvesting devices,” in  Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018 , pp.",
      "type": "sliding_window",
      "tokens": 91
    },
    {
      "text": "[22]  A. Colin, E. Ruppel, and B. Lucia, “A reconﬁgurable energy storage architecture for energy-harvesting devices,” in  Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018 , pp. 767–781, 2018. [23]  X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, “A high- efﬁciency dual-channel photovoltaic power system for nonvolatile sensor nodes,” in  2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA) , pp.",
      "type": "sliding_window",
      "tokens": 164
    },
    {
      "text": "[23]  X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, “A high- efﬁciency dual-channel photovoltaic power system for nonvolatile sensor nodes,” in  2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA) , pp. 1–2, Aug 2014. [24]  X.",
      "type": "sliding_window",
      "tokens": 92
    },
    {
      "text": "[24]  X. Sun, S. Yin, X. Peng, R. Liu, J. Seo, and S. Yu, “XNOR-RRAM: A scalable and parallel resistive synaptic architecture for binary neural networks,” in  2018 Design, Automation Test in Europe Conference Exhibition (DATE) , pp. 1423–1428, 2018.",
      "type": "sliding_window",
      "tokens": 85
    },
    {
      "text": "1423–1428, 2018. [25]  A. K. Mishra and D. Marr, “WRPN & apprentice: Methods for training and inference using low-precision numerics,”  CoRR , vol. abs/1803.00227, Apr 2018.",
      "type": "sliding_window",
      "tokens": 64
    },
    {
      "text": "abs/1803.00227, Apr 2018. [26]  S. Han, H. Mao, and W. J. Dally, “Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding,” CoRR , vol. abs/1510.00149, 2015.",
      "type": "sliding_window",
      "tokens": 71
    },
    {
      "text": "abs/1510.00149, 2015. [27]  S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan, “Deep learning with limited numerical precision,” in  Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37 , ICML’15, pp. 1737–1746, 2015.",
      "type": "sliding_window",
      "tokens": 90
    },
    {
      "text": "1737–1746, 2015. [28]  S. Jain, S. Venkataramani, V. Srinivasan, J. Choi, P. Chuang, and L. Chang, “Compensated-dnn: Energy efﬁcient low-precision deep neural networks by compensating quantization errors,” in  2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC) , pp. 1–6, 2018.",
      "type": "sliding_window",
      "tokens": 99
    },
    {
      "text": "1–6, 2018. [29]  N. Wang, J. Choi, D. Brand, C. Chen, and K. Gopalakrishnan, “Training deep neural networks with 8-bit ﬂoating point numbers,” in  Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018, Montr´eal, Canada. , pp.",
      "type": "sliding_window",
      "tokens": 93
    },
    {
      "text": "[30]  Z. Cai, X. He, J. Sun, and N. Vasconcelos, “Deep learning with low precision by half-wave gaussian quantization,”  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp.",
      "type": "sliding_window",
      "tokens": 62
    },
    {
      "text": "Sun, and N. Vasconcelos, “Deep learning with low precision by half-wave gaussian quantization,”  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 5406–5414, 2017. [31]  G. Venkatesh, E. Nurvitadhi, and D. Marr, “Accelerating deep con- volutional networks using low-precision and sparsity,” in  2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp.",
      "type": "sliding_window",
      "tokens": 123
    },
    {
      "text": "[31]  G. Venkatesh, E. Nurvitadhi, and D. Marr, “Accelerating deep con- volutional networks using low-precision and sparsity,” in  2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp. 2861–2865, 2017. [32]  I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, “Quantized neural networks: Training neural networks with low precision weights and activations,”  J. Mach.",
      "type": "sliding_window",
      "tokens": 136
    },
    {
      "text": "[32]  I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, “Quantized neural networks: Training neural networks with low precision weights and activations,”  J. Mach. Learn. Res.",
      "type": "sliding_window",
      "tokens": 64
    },
    {
      "text": "18, pp. 6869–6898, Jan. 2017. [33]  M. Courbariaux, Y. Bengio, and J.-P. David, “Binaryconnect: Training deep neural networks with binary weights during propagations,” in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 , NIPS’15, pp.",
      "type": "sliding_window",
      "tokens": 85
    },
    {
      "text": "[33]  M. Courbariaux, Y. Bengio, and J.-P. David, “Binaryconnect: Training deep neural networks with binary weights during propagations,” in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 , NIPS’15, pp. 3123–3131, 2015. [34]  M. Alwani, H. Chen, M. Ferdman, and P. Milder, “Fused-layer cnn accelerators,” in  2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp.",
      "type": "sliding_window",
      "tokens": 138
    },
    {
      "text": "[34]  M. Alwani, H. Chen, M. Ferdman, and P. Milder, “Fused-layer cnn accelerators,” in  2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp. 1–12, 2016. [35]  M. D. Lam, E. E. Rothberg, and M. E. Wolf, “The cache performance and optimizations of blocked algorithms,” in  Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp.",
      "type": "sliding_window",
      "tokens": 127
    },
    {
      "text": "[35]  M. D. Lam, E. E. Rothberg, and M. E. Wolf, “The cache performance and optimizations of blocked algorithms,” in  Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp. 63–74, 1991. [36]  K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Spendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,” in  2017 22nd Asia and South Paciﬁc Design Automation Conference (ASP-DAC) , pp.",
      "type": "sliding_window",
      "tokens": 167
    },
    {
      "text": "[36]  K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Spendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,” in  2017 22nd Asia and South Paciﬁc Design Automation Conference (ASP-DAC) , pp. 678–683, 2017. [37]  N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A.",
      "type": "sliding_window",
      "tokens": 199
    },
    {
      "text": "[37]  N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A. Wood, “The Gem5 Simulator,” SIGARCH Comput. Archit.",
      "type": "sliding_window",
      "tokens": 114
    },
    {
      "text": "39, pp. 1–7, Aug. 2011. [38]  Synopsis, “HSPICE.” https://www.synopsys.com/veriﬁcation/ams- veriﬁcation/hspice.html/.",
      "type": "sliding_window",
      "tokens": 54
    },
    {
      "text": "[38]  Synopsis, “HSPICE.” https://www.synopsys.com/veriﬁcation/ams- veriﬁcation/hspice.html/. [39]  H. Lv, X. Xu, P. Yuan, D. Dong, T. Gong, J. Liu, Z. Yu, P. Huang, K. Zhang, C. Huo, C. Chen, Y. Xie, Q. Luo, S. Long, Q. Liu, J. Kang, D. Yang, S. Yin, S. Chiu, and M. Liu, “BEOL based RRAM with one extra-mask for low cost, highly reliable embedded application in 28 nm node and beyond,” in  2017 IEEE International Electron Devices Meeting (IEDM) , pp. 2.4.1–2.4.4, 2017.",
      "type": "sliding_window",
      "tokens": 202
    },
    {
      "text": "2.4.1–2.4.4, 2017. [40]  X. Dong, C. Xu, Y. Xie, and N. P. Jouppi, “NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory,” IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) , vol. 31, pp.",
      "type": "sliding_window",
      "tokens": 94
    },
    {
      "text": "31, pp. 994–1007, July 2012. [41]  R. Wang and Z. Xu, “A pedestrian and vehicle rapid identiﬁcation model based on convolutional neural network,” in  Proceedings of the 7th International Conference on Internet Multimedia Computing and Service , ICIMCS ’15, pp.",
      "type": "sliding_window",
      "tokens": 71
    },
    {
      "text": "[41]  R. Wang and Z. Xu, “A pedestrian and vehicle rapid identiﬁcation model based on convolutional neural network,” in  Proceedings of the 7th International Conference on Internet Multimedia Computing and Service , ICIMCS ’15, pp. 32:1–32:4, 2015. [42]  S. A. Dawwd and B. S. Mahmood, “A reconﬁgurable interconnected ﬁlter for face recognition based on convolution neural network,” in  2009 4th International Design and Test Workshop (IDT) , pp.",
      "type": "sliding_window",
      "tokens": 126
    },
    {
      "text": "[42]  S. A. Dawwd and B. S. Mahmood, “A reconﬁgurable interconnected ﬁlter for face recognition based on convolution neural network,” in  2009 4th International Design and Test Workshop (IDT) , pp. 1–6, 2009. [43]  Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,”  Proceedings of the IEEE , vol.",
      "type": "sliding_window",
      "tokens": 113
    },
    {
      "text": "[43]  Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,”  Proceedings of the IEEE , vol. 86, pp. 2278–2324, Nov 1998.",
      "type": "sliding_window",
      "tokens": 64
    },
    {
      "text": "2278–2324, Nov 1998. [44]  H. Lin, M. Hsu, and W. Chen, “Human hand gesture recognition using a convolution neural network,” in  2014 IEEE International Conference on Automation Science and Engineering (CASE) , pp. 1038–1043, 2014.",
      "type": "sliding_window",
      "tokens": 66
    },
    {
      "text": "1038–1043, 2014. [45]  K. Ma, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Dynamic machine learning based matching of nonvolatile processor microarchi- tecture to harvested energy proﬁle,” in  2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD) , pp. 670–675, 2015.",
      "type": "sliding_window",
      "tokens": 106
    },
    {
      "text": "Abstract —Many recent works have shown substantial efﬁciency boosts from performing inference tasks on Internet of Things (IoT) nodes rather than merely transmitting raw sensor data. However, such tasks, e.g., convolutional neural networks (CNN), are very compute intensive. They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes.",
      "type": "sliding_window_shuffled",
      "tokens": 97,
      "augmented": true
    },
    {
      "text": "This paper presents the  ResiRCA  architecture that integrates a new, lightweight, and conﬁgurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node. They are therefore challenging to complete at sensing-matched latencies in ultra-low-power and energy-harvesting IoT nodes. ReRAM crossbar-based accelera- tors (RCAs) are an ideal candidate to perform the dominant multiplication-and-accumulation (MAC) operations in CNNs ef- ﬁciently, but conventional, performance-oriented RCAs, while energy-efﬁcient, are power hungry and ill-optimized for the intermittent and unstable power supply of energy-harvesting IoT nodes.",
      "type": "sliding_window_shuffled",
      "tokens": 186,
      "augmented": true
    },
    {
      "text": "The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. This paper presents the  ResiRCA  architecture that integrates a new, lightweight, and conﬁgurable RCA suitable for energy harvesting environments as an opportunistically executing aug- mentation to a baseline sense-and-transmit battery-powered IoT node. To maximize ResiRCA throughput under different power levels, we develop the  ResiSchedule  approach for dynamic RCA reconﬁguration.",
      "type": "sliding_window_shuffled",
      "tokens": 145,
      "augmented": true
    },
    {
      "text": "The proposed approach uses loop tiling-based computation decomposition, model duplication within the RCA, and inter-layer pipelining to reduce RCA activation thresholds and more closely track execution costs with dynamic power in- come. Experimental results show that ResiRCA and ResiSchedule achieve average speedups and energy efﬁciency improvements of 8 ×  and 14 ×  respectively compared to a baseline RCA with intermittency-unaware scheduling. Keywords -Energy harvesting, ReRAM crossbar, CNN, Recon- ﬁgurable hardware, Loop tiling, Computation scheduling \nI. I NTRODUCTION \nIn recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [ 1 ].",
      "type": "sliding_window_shuffled",
      "tokens": 189,
      "augmented": true
    },
    {
      "text": "However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms. Such integration grants IoT devices an important degree of independence from remote servers, which can be critical in deployments with challenging communication environments. Keywords -Energy harvesting, ReRAM crossbar, CNN, Recon- ﬁgurable hardware, Loop tiling, Computation scheduling \nI. I NTRODUCTION \nIn recent years, inference tasks, such as convolutional neural networks (CNNs), have been integrated into an increasing number of embedded applications to process edge-device collected data locally [ 1 ].",
      "type": "sliding_window_shuffled",
      "tokens": 162,
      "augmented": true
    },
    {
      "text": "However, continuing this trend onto ultra-low- power (ULP) IoT nodes presents clear design challenges due to the mismatch between the performance and computation requirements of CNNs and the limited resources of ULP platforms. Such platforms often already operate at their limits just in order to transmit sensed data at acceptable quality of \nservice (QoS) rates for deployment-viable battery lifetimes, and may not have additional resources available for further computation. For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type.",
      "type": "sliding_window_shuffled",
      "tokens": 121,
      "augmented": true
    },
    {
      "text": "For many inference tasks, it is known that multiplication- and-accumulation (MAC) is the dominant operation type. In CNNs, for instance, MACs between the feature map data and kernel weights comprise nearly 90% of the total operations [ 2 ], [ 3 ]. Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efﬁciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ].",
      "type": "sliding_window_shuffled",
      "tokens": 155,
      "augmented": true
    },
    {
      "text": "Resistive random-access memory (ReRAM) crossbars are regarded as a promising mechanism for accelerating CNNs with high energy-efﬁciency as they can perform MAC operations through analog current summation and can retain model parameters in memory during inactive periods with extremely low power overheads [ 3 ], [ 4 ], [ 5 ], [ 6 ], [ 7 ], [ 8 ], [ 9 ], [ 10 ]. Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efﬁciently performing inference on an IoT device if it does not have either a high power or high stability power source. In the remainder of the paper, we may shorten the term  ReRAM crossbars  to  ReRAMs .",
      "type": "sliding_window_shuffled",
      "tokens": 186,
      "augmented": true
    },
    {
      "text": "Despite the obvious potential synergy between ReRAM crossbar-based CNN accelerators (RCAs) and IoT applications needing CNN inference, there can remain substantial challenges in efﬁciently performing inference on an IoT device if it does not have either a high power or high stability power source. Given form factor constraints on energy storage, the former may be challenging, and energy-harvesting from sources such as solar, thermal, kinetic and radio frequency [ 11 ], [ 12 ], [ 13 ], [ 14 ], [ 15 ], [ 16 ] is notoriously unstable. While unstable power sources have been successfully utilized for applications in the IoT space [ 17 ], [ 18 ], [ 19 ], their use has not been heavily explored for RCA design.",
      "type": "sliding_window_shuffled",
      "tokens": 170,
      "augmented": true
    },
    {
      "text": "While unstable power sources have been successfully utilized for applications in the IoT space [ 17 ], [ 18 ], [ 19 ], their use has not been heavily explored for RCA design. Current RCA approaches can be divided into two categories. The approaches in the ﬁrst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [ 3 ], [ 4 ], [ 5 ], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [ 6 ], [ 8 ].",
      "type": "sliding_window_shuffled",
      "tokens": 151,
      "augmented": true
    },
    {
      "text": "To address these challenges, this paper proposes and experi- mentally evaluates  ResiRCA , a resilient ReRAM crossbar-based CNN accelerator. However, neither of them is a good ﬁt for energy-harvesting scenarios. The approaches in the ﬁrst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [ 3 ], [ 4 ], [ 5 ], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [ 6 ], [ 8 ].",
      "type": "sliding_window_shuffled",
      "tokens": 151,
      "augmented": true
    },
    {
      "text": "To address these challenges, this paper proposes and experi- mentally evaluates  ResiRCA , a resilient ReRAM crossbar-based CNN accelerator. ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference. Supported by a reconﬁgurable lightweight \nhardware design, ResiRCA is able to activate scalable com- putations via a multi-dimension tuning strategy.",
      "type": "sliding_window_shuffled",
      "tokens": 122,
      "augmented": true
    },
    {
      "text": "ResiRCA is designed as an auxiliary co-processor, powered by energy- harvesting, that augments a baseline, battery-powered MCU- style IoT node that would otherwise transmit its data without performing inference. In this design paradigm, the basic low power, lightweight MCU system can enjoy the advantage of continuous operation without suffering power outages, while the compute-heavy inference tasks can be ofﬂoaded to the RCA during periods when power income is sufﬁciently high and to external systems otherwise. Such a system is capable of both continuously collecting data and computing CNNs locally near data.",
      "type": "sliding_window_shuffled",
      "tokens": 129,
      "augmented": true
    },
    {
      "text": "To the best of our knowledge, this is the ﬁrst work that focuses on low power and reconﬁgurable RCA design from both the hardware and software angles targeting energy harvesting systems. ResiRCA allows an RCA to adapt to changing harvested energy and, with our co-designed scheduling approach, ResiSchedule, it can achieve very high throughput. Such a system is capable of both continuously collecting data and computing CNNs locally near data.",
      "type": "sliding_window_shuffled",
      "tokens": 96,
      "augmented": true
    },
    {
      "text": "Furthermore, the proposed hardware is reconﬁgurable at a ﬁne grain, to be able to dynamically activate different scaled computations, which can ﬁt to the changing features of the underlying power resources. To the best of our knowledge, this is the ﬁrst work that focuses on low power and reconﬁgurable RCA design from both the hardware and software angles targeting energy harvesting systems. This paper makes the following key  contributions : •  Low power, reconﬁgurable hardware design:  We pro- pose a novel architecture that implements a lightweight and low power RCA to adapt to time-varying power resources.",
      "type": "sliding_window_shuffled",
      "tokens": 129,
      "augmented": true
    },
    {
      "text": "Furthermore, the proposed hardware is reconﬁgurable at a ﬁne grain, to be able to dynamically activate different scaled computations, which can ﬁt to the changing features of the underlying power resources. These knobs can be integrated to form sequential or pipelined computation modes. •  Resilient computation scheduling:  We provide three knobs to schedule computation blocks in the proposed ar- chitecture: (i) loop tiling which decomposes MAC operations in a given layer (ReRAM) into small blocks, (ii) ReRAM duplication which provides opportunity to perform one-layer operations with multiple weight copies, and (iii) pipelining that can organize multiple ReRAM tiles to further exploit the har- vested power.",
      "type": "sliding_window_shuffled",
      "tokens": 164,
      "augmented": true
    },
    {
      "text": "We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution. For each computation mode, we can derive the optimal activation solutions under each power level directed by the  power model  and  throughput model  ofﬂine. These knobs can be integrated to form sequential or pipelined computation modes.",
      "type": "sliding_window_shuffled",
      "tokens": 76,
      "augmented": true
    },
    {
      "text": "•  Smooth schedule transitioning:  We identify smooth transition conditions to transfer as many partial results as possible from the last incomplete inference in one power cycle to the next power cycle with a different power level. We propose ResiSchedule, which combines the advantages of the two computation modes to cope with different power levels during the course of execution. In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction.",
      "type": "sliding_window_shuffled",
      "tokens": 94,
      "augmented": true
    },
    {
      "text": "M OTIVATION \nTo avoid negatively impacting the underlying system’s QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available. II. In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction.",
      "type": "sliding_window_shuffled",
      "tokens": 82,
      "augmented": true
    },
    {
      "text": "M OTIVATION \nTo avoid negatively impacting the underlying system’s QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available. First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power. In energy harvesting systems, there are two critical features, namely,  power strength  and power window length .",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "It is known that RCAs achieve their highest efﬁciency when every cell participates in the MAC computations simul- taneously [ 20 ]. First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power. Second, the \nvariance of the input power window, i.e., how long the power input stays at a given level, can be large as well.",
      "type": "sliding_window_shuffled",
      "tokens": 96,
      "augmented": true
    },
    {
      "text": "However, naively integrating such an RCA renders its activation power requirement so high that the system will likely have very low duty-cycle on an intermittent supply and may never activate at all for weaker power sources unless a substantial energy store were added, which could be burdensome for form factor constraints in a system that already employs a battery for sensing and other non-inference tasks. TABLE I A N EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT - CYCLE POWER TRACE . It is known that RCAs achieve their highest efﬁciency when every cell participates in the MAC computations simul- taneously [ 20 ].",
      "type": "sliding_window_shuffled",
      "tokens": 160,
      "augmented": true
    },
    {
      "text": "TABLE I A N EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT - CYCLE POWER TRACE . Power cycle \nHarv. Power ( µ W) \nPower consumption with full-size acti.",
      "type": "sliding_window_shuffled",
      "tokens": 58,
      "augmented": true
    },
    {
      "text": "(GiGa MACs/s)/ Power utilization \nPower consumption with resilient acti. Power ( µ W) \nPower consumption with full-size acti. ( µ W)/ Thr.",
      "type": "sliding_window_shuffled",
      "tokens": 46,
      "augmented": true
    },
    {
      "text": "(GiGa MACs/s)/ Power utilization \nPower consumption with resilient acti. ( µ W)/ Thr. (Giga MACs/s) /Power utilization \n1 50 0/Power failure/0/0% 0/Power failure/0/0% 2 100 0/Power failure/0/0% 80/25 × 1 × 1/0.312/80% 3 500 480/25 × 6 × 1/1.872/96% 480/25 × 6 × 1/1.872/96% 4 200 0/Power failure/0/0% 160/25 × 2 × 1/0.624/80% 5 250 0/Power failure/0/0% 240/25 × 3 × 1/0.936/96% 6 750 480/25 × 6 × 1/1.872/64% 720/25 × 3 × 3/2.808/96% 7 650 480/25 × 6 × 1/1.872/74% 640/25 × 2 × 4/2.496/98% 8 350 0/Power failure/0/0% 320/25 × 2 × 2/1.248/91% \n100 \n0.4 \n1.2 \n1.6 \n2.0 \n2.4 \n2.8 \nPower ( ­ W) \nThroughput (Giga MACs/s) \nPower consumption with full-size activation \nPower consumption with tile-size activation \nThroughput with full-size activation Throughput with tile-size activation \nPower trace \nAverage harvested power Average power consumption with full-size activation Average power consumption with tile-size activation \nAverage throughput with full-size activation \nAverage throughput with tile-size activation \n356.3 \n180 \n330 \n1.3 \n200 \n300 \n400 \n500 \n600 \n700 \n800 \n0.8 0.7 \nPC1 \nPC2 \nPC3 \nPC4 \nPC5 \nPC6 \nPC7 \nPC8 \n0 \n0 0 0 80 480 480 0 160 0 240 480 \n480 640 0 320 \n0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 \nFig.",
      "type": "sliding_window_shuffled",
      "tokens": 481,
      "augmented": true
    },
    {
      "text": "(Giga MACs/s) /Power utilization \n1 50 0/Power failure/0/0% 0/Power failure/0/0% 2 100 0/Power failure/0/0% 80/25 × 1 × 1/0.312/80% 3 500 480/25 × 6 × 1/1.872/96% 480/25 × 6 × 1/1.872/96% 4 200 0/Power failure/0/0% 160/25 × 2 × 1/0.624/80% 5 250 0/Power failure/0/0% 240/25 × 3 × 1/0.936/96% 6 750 480/25 × 6 × 1/1.872/64% 720/25 × 3 × 3/2.808/96% 7 650 480/25 × 6 × 1/1.872/74% 640/25 × 2 × 4/2.496/98% 8 350 0/Power failure/0/0% 320/25 × 2 × 2/1.248/91% \n100 \n0.4 \n1.2 \n1.6 \n2.0 \n2.4 \n2.8 \nPower ( ­ W) \nThroughput (Giga MACs/s) \nPower consumption with full-size activation \nPower consumption with tile-size activation \nThroughput with full-size activation Throughput with tile-size activation \nPower trace \nAverage harvested power Average power consumption with full-size activation Average power consumption with tile-size activation \nAverage throughput with full-size activation \nAverage throughput with tile-size activation \n356.3 \n180 \n330 \n1.3 \n200 \n300 \n400 \n500 \n600 \n700 \n800 \n0.8 0.7 \nPC1 \nPC2 \nPC3 \nPC4 \nPC5 \nPC6 \nPC7 \nPC8 \n0 \n0 0 0 80 480 480 0 160 0 240 480 \n480 640 0 320 \n0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 \nFig. 1. Comparisons on power consumption and throughput with tile-size over full-size activation \nFrom the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property.",
      "type": "sliding_window_shuffled",
      "tokens": 501,
      "augmented": true
    },
    {
      "text": "These mismatches can lead to the following two “nonideal” working scenarios: (i) Unutilized energy:  As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive. Comparisons on power consumption and throughput with tile-size over full-size activation \nFrom the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property. Under this context, if the power dominant RCA works in a ﬁxed high-power mode, as in traditional RCA designs, there would be large mismatches between the harvested power and the consumed power.",
      "type": "sliding_window_shuffled",
      "tokens": 159,
      "augmented": true
    },
    {
      "text": "These mismatches can lead to the following two “nonideal” working scenarios: (i) Unutilized energy:  As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive. (ii) Underutilized energy:  When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level. In this case, the harvested energy will leak away and cannot be recovered.",
      "type": "sliding_window_shuffled",
      "tokens": 121,
      "augmented": true
    },
    {
      "text": "Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four  25  ×  6  ReRAM crossbars, each can be mapped to six kernels, all sized  5 × 5 × 1 . In this case, the unused energy will be wasted, resulting in low energy efﬁciency. (ii) Underutilized energy:  When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level.",
      "type": "sliding_window_shuffled",
      "tokens": 120,
      "augmented": true
    },
    {
      "text": "During the eight harvested power cycles, the ReRAM can be ON during power cycles  PC3, PC6  and  PC7  and OFF with the other ﬁve power cycles. Considering the simple RCA working under a harvested power trace shown in Table II and Figure 1, the RCA consists of four  25  ×  6  ReRAM crossbars, each can be mapped to six kernels, all sized  5 × 5 × 1 . In the default case, the RCA works under an either ON or OFF mode with a power threshold of 80 µ W .",
      "type": "sliding_window_shuffled",
      "tokens": 123,
      "augmented": true
    },
    {
      "text": "As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efﬁciency under stable, high-power scenarios. During the eight harvested power cycles, the ReRAM can be ON during power cycles  PC3, PC6  and  PC7  and OFF with the other ﬁve power cycles. However, even when the system goes through the three power cycles, only some portion of the harvested power is consumed.",
      "type": "sliding_window_shuffled",
      "tokens": 96,
      "augmented": true
    },
    {
      "text": "2. Fig. As a result, the gap between the harvested power source and the consuming trace indicates a large energy waste from an RCA designed for efﬁciency under stable, high-power scenarios.",
      "type": "sliding_window_shuffled",
      "tokens": 43,
      "augmented": true
    },
    {
      "text": "2. Comparisons on loop code and ReRAM activation with tile- size activation over full-size activation. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation \nIf we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve “continuous progress” under lower power supply.",
      "type": "sliding_window_shuffled",
      "tokens": 147,
      "augmented": true
    },
    {
      "text": "This is because the starting power requirement of the RCA is reduced, and the system can thus get through power failures and translate even the low input energy into forward progress. (a) The original MAC codes; (b) The kernel loops are mapped to a full-size ReRAM activation; (c) The tiled MAC codes; (d) The tiled kernel loops are mapped to a tiled-size ReRAM activation \nIf we tentatively use loop tiling to decompose the MAC operations at the kernel level as shown in Figure 2 and perform the MAC operations on the ReRAM tile one by one sequentially, the system can achieve “continuous progress” under lower power supply. If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles  PC2, PC4, PC5  and  PC8  under limited power budget, as depicted in Table II and Figure 1.",
      "type": "sliding_window_shuffled",
      "tokens": 211,
      "augmented": true
    },
    {
      "text": "The annotations indicate the consumed power ( µ W), tile size and duplication count (e.g., 25x2x1) and power efﬁciency. If only one tile is activated to perform the MAC operations at one time, the system can still make progress during time windows of power cycles  PC2, PC4, PC5  and  PC8  under limited power budget, as depicted in Table II and Figure 1. With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of \n180 µ W to 330 µ W, and the throughput is increased by 85.7%.",
      "type": "sliding_window_shuffled",
      "tokens": 143,
      "augmented": true
    },
    {
      "text": "This resilient activation approach can effectively combat  Nonideal scenario 1 . With the resilient activation approach supported by loop tiling and ReRAM duplication, it can be seen that the power exploitation is increased from an average of \n180 µ W to 330 µ W, and the throughput is increased by 85.7%. Note that the partial activation of computation cells can be realized by partially activating the peripheral circuits of the corresponding rows and columns in the ReRAM crossbar.",
      "type": "sliding_window_shuffled",
      "tokens": 106,
      "augmented": true
    },
    {
      "text": "With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM. This resilient activation approach can effectively combat  Nonideal scenario 1 . The underlying reason of encountering so many power failures in the case of conventional working mode is that the power threshold of the system to remain alive is set too high.",
      "type": "sliding_window_shuffled",
      "tokens": 82,
      "augmented": true
    },
    {
      "text": "With this, the RCA can be active in a very large power range and ﬁnd more opportunities to make execution progress. Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles  PC6, PC7  and  PC8 . With the loop tiling technique, the power failure threshold can be dropped to the requirements of the minimum activation tile of a ReRAM.",
      "type": "sliding_window_shuffled",
      "tokens": 107,
      "augmented": true
    },
    {
      "text": "Parallel computations across multiple ReRAMs and loop tiling-based computation for each ReRAM are orthogonal optimizations. Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode. Further, if the power supply is larger than the starting power threshold of one entire ReRAM, we can even arrange multiple ReRAMs to work in a parallel fashion, as seen in power cycles  PC6, PC7  and  PC8 .",
      "type": "sliding_window_shuffled",
      "tokens": 104,
      "augmented": true
    },
    {
      "text": "Figure 2 shows the codes and ReRAM mapping schemes under full-size activation mode over tile-size activation mode. Since each single ReRAM can be activated at a ﬁner granularity with tiling, the parallelism can be achieved under a ﬂexible range of power consumption to match a variable power supply. In this example, the full size of ReRAM (or loop nest) is M  ×  N  =  A  ×  B  ×  C  ×  N , and the tile size of ReRAM (or loop nest) is  m  ×  n  = 1  ×  tb  ×  C  ×  tn .",
      "type": "sliding_window_shuffled",
      "tokens": 142,
      "augmented": true
    },
    {
      "text": "Furthermore, the better the high-power supply can be aggressively utilized, the more ambient energy can be continuously extracted without increasing the energy storage capacity for the energy-harvesting power delivery system. Since each single ReRAM can be activated at a ﬁner granularity with tiling, the parallelism can be achieved under a ﬂexible range of power consumption to match a variable power supply. Therefore, this weight duplication- based execution style built upon ﬁne-granularity activation can effectively combat  Nonideal scenario 2 .",
      "type": "sliding_window_shuffled",
      "tokens": 118,
      "augmented": true
    },
    {
      "text": "The ﬂexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization. Therefore, this weight duplication- based execution style built upon ﬁne-granularity activation can effectively combat  Nonideal scenario 2 . Figure 1 also shows the throughput under the full-size activation mode and the tile-size activation mode.",
      "type": "sliding_window_shuffled",
      "tokens": 79,
      "augmented": true
    },
    {
      "text": "In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efﬁciency. The ﬂexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization. Extending this single-ReRAM toy architecture to a practical multi-ReRAM architecture to process multi-layer convolutions for real-world CNNs introduces a new source of power variation in terms of the different time and power costs of different convolution layers.",
      "type": "sliding_window_shuffled",
      "tokens": 114,
      "augmented": true
    },
    {
      "text": "In this scenario, the idea of integrating tiling on ReRAMs and paralleling ReRAMs, can also achieve high energy efﬁciency. S YSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives. III.",
      "type": "sliding_window_shuffled",
      "tokens": 62,
      "augmented": true
    },
    {
      "text": "Below, we provide an overview of the RCA interfaces and our system integration model and then discuss the two main steps to map a CNN to ResiRCA:  ofﬂine compilation  and  runtime execution . A. ResiRCA overview \nFigure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system. S YSTEM LEVEL FLOW This section presents the system level design of ResiRCA from both the hardware and software perspectives.",
      "type": "sliding_window_shuffled",
      "tokens": 101,
      "augmented": true
    },
    {
      "text": "Output Reg. A. ResiRCA overview \nFigure 3 shows the conceptual architecture of an intelligent embedded system where an RCA is added to an existing MCU system. The baseline, battery-powered MCU system samples data at a ﬁxed rate, supported by the provisioned battery, and transmits either sensor data or the results of RCA processing \nDAC DAC DAC DAC DAC DAC \nMCU \nMemory I/O Ports \nInterconnected Bus \nClock \nPower \nIntelligent Embedded System \n... \n... \nADC&S+A \nDAC \nInput Reg.",
      "type": "sliding_window_shuffled",
      "tokens": 121,
      "augmented": true
    },
    {
      "text": "Battery (B) \nB \nEH \nĂ Sigmoid \n... \nReRAM Memory \nBasic MCU System \nB \nEH EH \nEH \nEH \nB \nFig. Pool Unit FC Unit \nAdder Tree \nResiRCA \nReRAM crossbar \n... \nADC&S+A \nDAC \nReRAM crossbar \nĂ \nTx/RX \nEnergy Harvestor Sensors \nEnergy harvesting (EH) \n... Output Reg.",
      "type": "sliding_window_shuffled",
      "tokens": 89,
      "augmented": true
    },
    {
      "text": "3. Battery (B) \nB \nEH \nĂ Sigmoid \n... \nReRAM Memory \nBasic MCU System \nB \nEH EH \nEH \nEH \nB \nFig. ResiRCA architecture overview \nto the network.",
      "type": "sliding_window_shuffled",
      "tokens": 46,
      "augmented": true
    },
    {
      "text": "The RCA is powered by harvesting ambient energy and employs a separate, very small capacitor as its only energy storage medium, primarily for power smoothing, similar to prior energy-harvesting NVP designs [ 17 ], [ 21 ], rather than as a task-scaled energy reservoir [ 22 ]. ResiRCA architecture overview \nto the network. Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input/output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources.",
      "type": "sliding_window_shuffled",
      "tokens": 127,
      "augmented": true
    },
    {
      "text": "The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiﬁcations. Note that the ReRAM memory depicted in Figure 3 functions as both data storage for the sensors and input/output storage for the RCA; so, it must be able to operate from both the battery and harvested power sources. Similar hybrid arrangements have been explored in the NVP literature [ 23 ] and impose minimal design overheads.",
      "type": "sliding_window_shuffled",
      "tokens": 127,
      "augmented": true
    },
    {
      "text": "This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA. B. Mapping inference tasks to ResiRCA To achieve both generally low power and intermittency- compatible execution, the proposed ResiRCA architecture has the following two features that impact the software management of the RCA: Lightweight:  From the perspective of the ReRAM circuit at the core of the RCA, the precision and resolution of inputs, weights and outputs are kept low to yield low power. The baseline MCU system is also augmented with a power-level and RCA activity feedback mechanism from the energy-harvesting portion of the platform to allow initial MCU programming of the RCA control registers and model parameters and RCA completion notiﬁcations.",
      "type": "sliding_window_shuffled",
      "tokens": 169,
      "augmented": true
    },
    {
      "text": "Fine-grained reconﬁguration:  The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes. Similarly, total model size, including any granularity overheads (e.g., from the partitioning used to store both positive and negative weights by having the kernels of one layer mapped to two crossbars, one each for positive and negative weights, which share the same input port) must ﬁt within the allocated RCAs of a particular ResiRCA design. This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA.",
      "type": "sliding_window_shuffled",
      "tokens": 148,
      "augmented": true
    },
    {
      "text": "This ﬂexible reconﬁgurability enables ﬁne-grained activations to exploit the harvested power. Fine-grained reconﬁguration:  The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes. While execution is relatively straightforward when maintaining a speciﬁc conﬁguration of tiling and pipelining strategy, transitions between conﬁgurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures.",
      "type": "sliding_window_shuffled",
      "tokens": 113,
      "augmented": true
    },
    {
      "text": "While execution is relatively straightforward when maintaining a speciﬁc conﬁguration of tiling and pipelining strategy, transitions between conﬁgurations require additional management and power-intermittency aware- ness to preserve progress from partial executions after power level transitions and failures. As part of compiling a CNN to ResiRCA, we build a proﬁling table relating each potential tiling and pipeline conﬁguration \nthat might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw. The hardware design details will be presented in Section IV.",
      "type": "sliding_window_shuffled",
      "tokens": 123,
      "augmented": true
    },
    {
      "text": "This proﬁling collects data used to determine the best activation solution for each power level. As part of compiling a CNN to ResiRCA, we build a proﬁling table relating each potential tiling and pipeline conﬁguration \nthat might be used with the target CNN with its ReRAM model resources, activation requirements, and power draw. At runtime, each time when entering a new power cycle, we ﬁrst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level.",
      "type": "sliding_window_shuffled",
      "tokens": 118,
      "augmented": true
    },
    {
      "text": "Then, the execution process the “ data loading → Mac computing → data storing ” steps in a sequential way to perform convolution operations. The hardware design details will be presented in Section V. \nIV. At runtime, each time when entering a new power cycle, we ﬁrst check the statically determined solution tables and pick up the corresponding activation solution for the ReRAMs for the current power level.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "The hardware design details will be presented in Section V. \nIV. A  HARVESTING - COMPATIBLE ,  LOW - \nPOWER  R ESI RCA \nSupporting the necessary features for adapting RCAs to a harvested power supply will require optimizations in both RCA circuit design and the development of variable-power-optimized loop-tiling strategies. First, feasible implementations of ﬂexible activation options require a low power and reconﬁgurable RCA.",
      "type": "sliding_window_shuffled",
      "tokens": 106,
      "augmented": true
    },
    {
      "text": "First, feasible implementations of ﬂexible activation options require a low power and reconﬁgurable RCA. Second, a dynamic loop tiling strategy alongside a coordinated parallelism scheme should be devised to match execution power consumption as closely as possible to power income to maximize efﬁciency. This section addresses the ﬁrst of these challenges, and Section V discusses our approach to the second.",
      "type": "sliding_window_shuffled",
      "tokens": 83,
      "augmented": true
    },
    {
      "text": "This section addresses the ﬁrst of these challenges, and Section V discusses our approach to the second. In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment. Challenge 1:  Achieving low-power, reconﬁgurable RCA Although recent works have presented systems [ 4 ], [ 3 ], [ 5 ] and circuits [ 24 ], [ 6 ] for inference-oriented RCAs, they are not directly suitable for adoption in our target scenario because of either their high power consumption or their stringent execution parameters (e.g., computation granularity).",
      "type": "sliding_window_shuffled",
      "tokens": 146,
      "augmented": true
    },
    {
      "text": "In general, these designs are not optimized for enabling the small-scale partial activation on ReRAM that would allow for power tracking in an energy-harvesting environment. It has been shown that the power requirement to fully activate a 128 × 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [ 3 ]. Figure 4 shows ﬁve harvested power sources with the maximum, mean and median values and their ratios indicated.",
      "type": "sliding_window_shuffled",
      "tokens": 97,
      "augmented": true
    },
    {
      "text": "It has been shown that the power requirement to fully activate a 128 × 8 sized ReRAM and obtain 8 outputs concurrently is more than 24mW [ 3 ]. In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power. With this design, the presented power sources can hardly activate even a small ReRAM.",
      "type": "sliding_window_shuffled",
      "tokens": 82,
      "augmented": true
    },
    {
      "text": "One approach to achieve lower RCA power is to limit precision. In order for the ResiRCA to operate on harvested power, it must reduce minimum ReRAM activation power. Therefore, the the RCA should be built on the basis of a low power hardware design that is upwardly reconﬁgurable to higher power scenarios rather than the reverse.",
      "type": "sliding_window_shuffled",
      "tokens": 72,
      "augmented": true
    },
    {
      "text": "To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output. One approach to achieve lower RCA power is to limit precision. The impact of different precisions on CNN accuracy has been extensively studied [ 24 ], [ 25 ], [ 26 ], [ 27 ], [ 28 ], [ 29 ], [ 30 ], [ 31 ], [ 32 ], [ 33 ].",
      "type": "sliding_window_shuffled",
      "tokens": 107,
      "augmented": true
    },
    {
      "text": "as in ISAAC [ 3 ]). To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output. With this design setting, the ReRAM size only needs to be equal to the kernel size, and the ReRAM scale does not need to be extended using a bit composing scheme (e.g.",
      "type": "sliding_window_shuffled",
      "tokens": 93,
      "augmented": true
    },
    {
      "text": "C \nC \nC controlling circuit \nFig. 4-bit \nOutput  Reg. Variance feature of different power sources \nIII-ADC \nBL \nWL \nSL \n͙ \n͙ \n͙ \nColumn 1 \n͙ \nCSA + \n- \nSAR \n͙ Ref \nShift&Add \n͙ \nDriver \n͙ \nRow 1 \nRow 2 \nRow m \nDriver \nDriver \nI-DAC ͙ \n͙ \n͙ ͙ \nII-Comp \n4-bit inputs 1-bit resolution \n1-bit weights \n4-bit outputs \nbit- serial \nInput  Reg.",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "Lightweight ReRAM circuit design \npower ReRAM cells. 5. C \nC \nC controlling circuit \nFig.",
      "type": "sliding_window_shuffled",
      "tokens": 21,
      "augmented": true
    },
    {
      "text": "Figure 5 shows the proposed peripheral circuit design for one ReRAM crossbar. Lightweight ReRAM circuit design \npower ReRAM cells. This design is more concise even than the SINWP [ 6 ], because we target low power as the primary goal.",
      "type": "sliding_window_shuffled",
      "tokens": 53,
      "augmented": true
    },
    {
      "text": "This design is more concise even than the SINWP [ 6 ], because we target low power as the primary goal. Speciﬁcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows. To increase efﬁciency further our design supports aggressive power gating and other circuit techniques to dynamically reconﬁgure active tile sizes and shut-off inactive ReRAMs.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "Lastly, we apply coarse-grain power gating to conﬁgure the number of duplicated ReRAMs. Speciﬁcally, we employ clock gating and input vector control (IVC) techniques to further reduce leakage in inactive rows. We modify the column multiplexers to enable variable active columns and turn off the ADCs of inactive channels.",
      "type": "sliding_window_shuffled",
      "tokens": 77,
      "augmented": true
    },
    {
      "text": "Lastly, we apply coarse-grain power gating to conﬁgure the number of duplicated ReRAMs. This reconﬁguration ability can enable scaled activation of the circuits such that small tile-size computation can be enabled while yielding very low power consumption. V. P OWER - DYNAMIC  RCA  SCHEDULING \nGiven a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture.",
      "type": "sliding_window_shuffled",
      "tokens": 117,
      "augmented": true
    },
    {
      "text": "In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM \naccelerated MACs. V. P OWER - DYNAMIC  RCA  SCHEDULING \nGiven a viable RCA architecture for energy-harvesting IoT nodes, the other key issue is the design of a software scheduling mechanism to choreograph resilient execution on this architecture. Challenge 2:  Software controlled dynamic RCA activation and scheduling The idea of loop tiling has been widely leveraged in RCA design to either increase system throughput by smoothing the pipelining or reduce memory accesses by improving data locality [ 34 ], [ 3 ].",
      "type": "sliding_window_shuffled",
      "tokens": 150,
      "augmented": true
    },
    {
      "text": "With this design idea, the system can keep making forward progress over a large range of power incomes. In this work, we re-purpose loop tiling to perform computation decomposition on ReRAM \naccelerated MACs. Moreover, we allow parallelism along different dimensions to seamlessly integrate it with loop tiling, and as a result, a range of scalable computations that can ﬁt in different power supplies are achieved.",
      "type": "sliding_window_shuffled",
      "tokens": 98,
      "augmented": true
    },
    {
      "text": "A. Computation decomposition and parallelism \nIf the harvested power  P   budget   is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress. With this design idea, the system can keep making forward progress over a large range of power incomes. Sections  V-A - V-C  develop a dynamic activation strategy for different power levels and Section  V-D discusses the transition strategy between dynamic activation solutions.",
      "type": "sliding_window_shuffled",
      "tokens": 108,
      "augmented": true
    },
    {
      "text": "For active RCAs, one option is to use loop tiling to decompose computations, and the other is to parallelize computations. A. Computation decomposition and parallelism \nIf the harvested power  P   budget   is larger than the power requirement of activating the smallest size of ReRAM, it implies that the RCA is active and can make computation progress. The parallelism in this context is of two types:  intra layer parallelism via layer duplication  and  inter layer parallelism via layer pipelining .",
      "type": "sliding_window_shuffled",
      "tokens": 116,
      "augmented": true
    },
    {
      "text": "The parallelism in this context is of two types:  intra layer parallelism via layer duplication  and  inter layer parallelism via layer pipelining . 1) Computation tiling:  In this work, we use loop tiling [ 35 ] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one. Further, tiling and parallelization can also be combined to generate ﬁne-grained scales of computations to efﬁciently ﬁt into the changing harvested power.",
      "type": "sliding_window_shuffled",
      "tokens": 114,
      "augmented": true
    },
    {
      "text": "As shown in Figure 2, if loop tiling is applied to the unrolled MAC operations, only a tile of ReRAM cells along with their peripheral circuits is enabled to perform MAC operations. After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed. 1) Computation tiling:  In this work, we use loop tiling [ 35 ] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one.",
      "type": "sliding_window_shuffled",
      "tokens": 116,
      "augmented": true
    },
    {
      "text": "After traversing all the tiles one by one, one batch of MAC operations on the entire ReRAM is completed. When the traversal completes, an  Adder Tree  will be used to merge the partial sums for ReRAM columns and obtain the ﬁnal MAC result. Note that, if the row- wise tiling factor is less than the ReRAM row number, this tiled execution strategy will introduce partial sums.",
      "type": "sliding_window_shuffled",
      "tokens": 91,
      "augmented": true
    },
    {
      "text": "When the traversal completes, an  Adder Tree  will be used to merge the partial sums for ReRAM columns and obtain the ﬁnal MAC result. We use parallelism granularity  G  to denote the duplication count as deﬁned in [ 5 ]. 2) Computation parallelism: Intra-layer parallelism  means overlapping the layer computations on duplicated copies of ReRAMs that store the same weights for one layer.",
      "type": "sliding_window_shuffled",
      "tokens": 96,
      "augmented": true
    },
    {
      "text": "In this work, the parallelism granularity  G  of a layer is determined by the ratio between 50% of the peak harvested power during proﬁling and the power consumption of the full- size ReRAM corresponding to this layer. G  can be determined considering the tradeoff between energy efﬁciency and chip area during the design phase. We use parallelism granularity  G  to denote the duplication count as deﬁned in [ 5 ].",
      "type": "sliding_window_shuffled",
      "tokens": 93,
      "augmented": true
    },
    {
      "text": "The actual parallelism granularity  aG ≤ G  for a layer is decided by the harvested power level. That is, if the 50% peak harvested power by proﬁling is twice ( G =2) of the power consumption with a ReRAM size of Layer 1 of 25x6, the RCA will be designed to offer two sets of ReRAMs sized 25x6 for Layer 1. In this work, the parallelism granularity  G  of a layer is determined by the ratio between 50% of the peak harvested power during proﬁling and the power consumption of the full- size ReRAM corresponding to this layer.",
      "type": "sliding_window_shuffled",
      "tokens": 135,
      "augmented": true
    },
    {
      "text": "If we allow  aG ReRAMs to perform the concerned layer’s computations in parallel, the input data should be divided into  aG  partitions. The actual parallelism granularity  aG ≤ G  for a layer is decided by the harvested power level. In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel.",
      "type": "sliding_window_shuffled",
      "tokens": 92,
      "augmented": true
    },
    {
      "text": "Inter-layer parallelism  means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion. This offers a ﬂexible way to tune the power consumption in a large design space, even though the kernel size, convolution count and power consumption of different layers can signiﬁcantly vary. In this way, the data in the same partition are processed in a sequential fashion whereas the data in different partitions are processed in parallel.",
      "type": "sliding_window_shuffled",
      "tokens": 97,
      "augmented": true
    },
    {
      "text": "We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers. Inter-layer parallelism  means overlapping ReRAM compu- tations for different convolution layers in a pipelined fashion. This pipeline parallelism provides us with another dimension to aggressively exploit the harvested energy.",
      "type": "sliding_window_shuffled",
      "tokens": 91,
      "augmented": true
    },
    {
      "text": "We can naturally integrate the duplication based parallelism into the pipeline parallelism to build a parallelization strategy where the pipeline stages are composed of ReRAMs mapped from different convolution layers. Previous work [ 3 ] has noted vulnerabilities to pipeline bubbles and execution stalls in CNNs because of the large variance in weight and feature map scales across different layers. In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very ﬁne-grain fashion.",
      "type": "sliding_window_shuffled",
      "tokens": 117,
      "augmented": true
    },
    {
      "text": "In Fig- ure 6(a), a naive scheduling strategy is employed on a  Simple architecture . In this work, the pipeline imbalance issue is addressed by tuning the activation degrees, duplication degrees and even the pipeline execution style in a very ﬁne-grain fashion. 3) Execution strategies:  Figure 6 shows ﬁve different execution strategies for a two-layer convolution execution experiencing two power cycles with different levels.",
      "type": "sliding_window_shuffled",
      "tokens": 95,
      "augmented": true
    },
    {
      "text": "In this scheduling strategy, the RCA is only active when the harvested power is adequate to support the maximal power requirement among all the convolution layers and, in the “simple” architecture, one convolution layer can only be mapped to one ReRAM (no ReRAM duplication). In Fig- ure 6(a), a naive scheduling strategy is employed on a  Simple architecture . In the remainder of this paper, this execution strategy is referred to as  Naive1 .",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication. In the remainder of this paper, this execution strategy is referred to as  Naive1 . We assume that  Naive1  is also designed with the proposed lightweight circuits.",
      "type": "sliding_window_shuffled",
      "tokens": 72,
      "augmented": true
    },
    {
      "text": "None of  Naive1  and  Naive2  executions can go through power cycle  PC-i  and the power utilization is very low, as there is a signiﬁcant mismatch between the power producer and consumer. This execution strategy is referred as Naive2 . In Figure 6(b), a naive scheduling scheme is applied, but this time on the proposed ResiRCA architecture, which supports ReRAM duplication.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "None of  Naive1  and  Naive2  executions can go through power cycle  PC-i  and the power utilization is very low, as there is a signiﬁcant mismatch between the power producer and consumer. In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks. Figure 6(c) presents a ﬂexible scheduling strategy applied to ResiRCA.",
      "type": "sliding_window_shuffled",
      "tokens": 88,
      "augmented": true
    },
    {
      "text": "The layers are scheduled in a sequential fashion. In this strategy, the loop tiling technique integrated with the ReRAM duplication is enabled to obtain resilient MAC computation blocks. This execution style is called  Sequential .",
      "type": "sliding_window_shuffled",
      "tokens": 48,
      "augmented": true
    },
    {
      "text": "Five layer scheduling schemes: (a) Naive execution @Simple architecture; (b) Naive execution @ResiRCA architecture; (c) Se- quential resilient execution @ResiRCA architecture; (d) Pipelining resilient execution @ResiRCA architecture; and (e) Hybrid resilient execution @ResiRCA architecture \nResiRCA architecture; we call this execution style  Pipelining . For ease of explanation and simulation, we only allow full pipelining in this execution, which means MAC operations of all the layers are included in each pipeline stage. Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme.",
      "type": "sliding_window_shuffled",
      "tokens": 152,
      "augmented": true
    },
    {
      "text": "At runtime, ResiSchecule dynamically selects activation solutions from either  Sequential  or  Pipelining  in each power cycle, depending on which can provide a better throughput. We refer to this as ResiSchedule . Finally, Figure 6(e) shows the loop tiling technique inte- grated with a hybrid parallelism scheme.",
      "type": "sliding_window_shuffled",
      "tokens": 83,
      "augmented": true
    },
    {
      "text": "Section  V-C will further present quantitative analysis and solution on how \ntoﬁgureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA. At runtime, ResiSchecule dynamically selects activation solutions from either  Sequential  or  Pipelining  in each power cycle, depending on which can provide a better throughput. With  ResiSchedule , we can cover a large tuning range commensurate with power supply variation.",
      "type": "sliding_window_shuffled",
      "tokens": 116,
      "augmented": true
    },
    {
      "text": "Section  V-C will further present quantitative analysis and solution on how \ntoﬁgureouttheoptimalactivationsize,duplicationdegreeand executionstyletoachieveanidealResiScheduleforResiRCA. B.Powermodelandlatencymodel PowersupplyisasigniﬁcantconstraintforResiSchedule. Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solution m,n,aG  wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,P load ,P comp andP store ,andtheyareperformed insequence.",
      "type": "sliding_window_shuffled",
      "tokens": 196,
      "augmented": true
    },
    {
      "text": "P load = aG× (Bits input /BN in )×P ld−bit   modelsloadpoweroperation. 1)Loadandstore: P load and P store   denotethepower consumedbyloadingthedatafromthepureReRAMmem- oryintotheinputregistersandstoringthedatafromthe outputregistersintotheReRAM memory . Byanalyzingthepowercostofeachstepoftheconvolution operations,wecanbuildapowermodelrelatedtotheactivation solution m,n,aG  wherem,n,andaGdenoterowfactorand columnfactoroftheReRAMtilingandtheactualparallelism granularityofReRAMduplicationcopies.ResiRCApower consumptiondividesintothreemajorpartsfromanarchitectural viewpoint,P load ,P comp andP store ,andtheyareperformed insequence.",
      "type": "sliding_window_shuffled",
      "tokens": 208,
      "augmented": true
    },
    {
      "text": "Therefore, Bit input / BN in meanstheactualloadeddatabits eachbatch.Theterm P ld−bit denotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister. P load = aG× (Bits input /BN in )×P ld−bit   modelsloadpoweroperation. Here,theterms Bits input and BN in denotethenumberof inputbitstoserve MACoperationsforafull-sizedReRAMand thebatchnumberoftransferringtheseinputbitsrespectively .",
      "type": "sliding_window_shuffled",
      "tokens": 138,
      "augmented": true
    },
    {
      "text": "Thelatency modelfordataloadforoneconvolution operationis Lat load = Bits input /BW ld .Theterm Lat load \nrepresentsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.Theterm BW ld denotesthebandwidthof eachloadoperation.Themodelsof P store and Lat store can bederivedinasimilarfashion. Theinputbatchnumber BN in isdeterminedbythepower budgetbecause P load <=P budget shouldalwaysbesatisﬁed. Therefore, Bit input / BN in meanstheactualloadeddatabits eachbatch.Theterm P ld−bit denotesthepowerconsumption ofloadingonebitfromReRAMmemorytotheinputregister.",
      "type": "sliding_window_shuffled",
      "tokens": 192,
      "augmented": true
    },
    {
      "text": "Thelatency modelfordataloadforoneconvolution operationis Lat load = Bits input /BW ld .Theterm Lat load \nrepresentsthelatencytoloadthedatarequiredbythe convolutionoperationsforone-cycle MACoperationsfora full-sizeReRAM.Theterm BW ld denotesthebandwidthof eachloadoperation.Themodelsof P store and Lat store can bederivedinasimilarfashion. 2) ComputationonReRAMs: P comp isthedominantand mostcomplicatedpartwheretheanaloganddigitalsignals aremixed.Theenergyofone-cycle MACoperationsforan activationsizeof m×n andactualduplicationaG, P comp−tile \ndividesintothefollowingparts:1) E DAC   denotestheenergy consumedforconvertingthedigitalinputsignaltotheanalog signalinabit-serialfashion;2) E MAC   denotestheenergy forperforming MACoperationsonReRAMs;and3) E ADC \nconsistsofthreepartsasshowninFigure5:3i) E BL   denoting theenergyforactivatingbitlines;3ii) E SA−Ref   denotingthe energyforsensingandamplifyingthe MACresultsignaland thenreferencinganalogsignalstodigitalsignals;and,3iii) E S+A   denotingtheenergyofShift&Addparttocomposethe ﬁnaloutput. IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisﬁxedas Lat comp = T comp ,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1.",
      "type": "sliding_window_shuffled",
      "tokens": 425,
      "augmented": true
    },
    {
      "text": "IntheResiRCAdesign,thetimeforperformingone-cycle of MACoperationsononeReRAMtileisﬁxedas Lat comp = T comp ,andisindependentoftheactivationsize.Therefore,we canbuildthepowermodelforthecomputationpartinterms ofatileasshowninEquation1. E comp =E comp tile /Lat comp \n=(E DAC   +E MAC   +E ADC )/T comp (1) \nThepowerofeachpartistakentobelineartothetiling factorsofm ornortheactualparallelismgranularityaG. TheenergyforoneReRAMrow(e DAC ),oneReRAMcell (e MAC  )andoneReRAMcolumn(e BL ,e SA−Ref ,e S+A )are theworst-casevaluesfromthesimulation.Table V-B 2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies.",
      "type": "sliding_window_shuffled",
      "tokens": 233,
      "augmented": true
    },
    {
      "text": "TheenergyforoneReRAMrow(e DAC ),oneReRAMcell (e MAC  )andoneReRAMcolumn(e BL ,e SA−Ref ,e S+A )are theworst-casevaluesfromthesimulation.Table V-B 2presents therelationshipofenergyandtheReRAMtilingsizeand ReRAMcopies. TABLEII R ELATIONSHIPOFENERGYANDTHE R E RAM TILINGSIZEAND R E RAM COPIES . Component Energyequation DAC E DAC =e DAC ×m×aG Computation E M AC =e MAC   ×m×n×aG \nADC BL E BL =e BL ×n×aG SA-Ref E SA−Ref =e SA−Ref ×n×aG S+A E S+A =e S+A ×n×aG \n3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated.",
      "type": "sliding_window_shuffled",
      "tokens": 272,
      "augmented": true
    },
    {
      "text": "Asaresult,thesepartialsumsneedtobe mergedoncethe (tile)traversalofanentireReRAMiscomplete.Thesum mergingoperationisperformedbyanAdderTreeasillustrated inFigure3. Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint of P merg   <P budget shouldbealways met.Therefore,the power P merge   andlatency Lat merge   ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofﬂine. Component Energyequation DAC E DAC =e DAC ×m×aG Computation E M AC =e MAC   ×m×n×aG \nADC BL E BL =e BL ×n×aG SA-Ref E SA−Ref =e SA−Ref ×n×aG S+A E S+A =e S+A ×n×aG \n3)Partialsums:Thecomputationdecompositionacross ReRAMsbylooptiling mayproducepartialsumsforthe activatedtileswheneachcolumninthetileisnotfullyactivated.",
      "type": "sliding_window_shuffled",
      "tokens": 276,
      "augmented": true
    },
    {
      "text": "Wecanprovidetreetopologycandidatesfor differentpowerlevels,keepingin mindthattheconstraint of P merg   <P budget shouldbealways met.Therefore,the power P merge   andlatency Lat merge   ofthepartialsummerging operationunderdifferentmergingcasescanbeobtainedofﬂine. Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs. 4)Activationtransitioncost:Theexecutiontransitionfrom onetiletoanotherinsideonepowercycleorfromoneactivation solutiontoanotherindifferentpowerlevelsalsocostspower P trans andlatency Lat trans .Activationtransitionimpliesthat weneedtoenablethecorrespondingcircuitsoftheto-be- activatedrowsandcolumnswhileshuttingdowntheothers.",
      "type": "sliding_window_shuffled",
      "tokens": 211,
      "augmented": true
    },
    {
      "text": "5)Powerandlatencymodels:Theaboveanalysiscaptures thepowerconsumptionandexecutionlatencyofprocessing oneconvolutionlayer .Itisassumedthatallofthesesteps areperformedinsequence.Puttingthemalltogether,for convolutionlayerLk,thepowerandlatencypaircanbemodeled asinEquation2and3. P LK  =(P ld × Lat ld Lk   +P comp × Lat comp Lk \n+P st × Lat st Lk   +P merge  × Lat merge Lk )/Lat Lk (2) \nLat LK  = Lat ld Lk   + Lat comp Lk + Lat st Lk   + Lat merge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC ≥ 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication. Thisfunctionissupportedbythegatingcircuitsdescribedin SectionIV.Thiscostwillbeonlycountedatthebeginningof apowercyclewhenanactivationtransitionoccurs.",
      "type": "sliding_window_shuffled",
      "tokens": 328,
      "augmented": true
    },
    {
      "text": "Underthesequentialcomputation mode, theconvolutionlayersareexecutedonebyoneinasequential \nfashion, and as a result, the power model and latency model in Equations 2 and 3 can be directly used. We also model the pipelined computation mode shown in Equations 4 and 5. P LK  =(P ld × Lat ld Lk   +P comp × Lat comp Lk \n+P st × Lat st Lk   +P merge  × Lat merge Lk )/Lat Lk (2) \nLat LK  = Lat ld Lk   + Lat comp Lk + Lat st Lk   + Lat merge Lk (3) Consideringprocessing multipleinferenceswith multiple convolutionallayersLC(LC ≥ 2),thelayerscanbescheduled foreithersequentialorpipelinedcomputationmode,asshown intheexamplesinFigures6(c)and(d),respectively .Based onthe modelscapturingonelayerinEquations2and3, wecanbuildthe modelsforeachconvolutionlayerofa CNNapplication.",
      "type": "sliding_window_shuffled",
      "tokens": 262,
      "augmented": true
    },
    {
      "text": "P   pipe   = \nLC X \nLk =1 P Lk (4) \nLat pipe   =  max ( Lat L 1 , Lat L 2 ...Lat LC ) (5) \nC. Dynamic activation strategy \n1) Problem formulation:  In this section, we focus on ﬁguring out the ResiSchedule solution to achieve the maximal throughput. Note that the pipelined computation mode means that all the  LC convolution layers are executed fully parallel. We also model the pipelined computation mode shown in Equations 4 and 5.",
      "type": "sliding_window_shuffled",
      "tokens": 115,
      "augmented": true
    },
    {
      "text": "Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Although we can arrange more hardware resources with the pipelined computation mode, it does not mean this mode will always yield greater computation progress than the sequential mode due to the constraints of tile size and parallelism granularity. P   pipe   = \nLC X \nLk =1 P Lk (4) \nLat pipe   =  max ( Lat L 1 , Lat L 2 ...Lat LC ) (5) \nC. Dynamic activation strategy \n1) Problem formulation:  In this section, we focus on ﬁguring out the ResiSchedule solution to achieve the maximal throughput.",
      "type": "sliding_window_shuffled",
      "tokens": 150,
      "augmented": true
    },
    {
      "text": "Therefore, in order to achieve optimal progress, we need to select the best activation solution offered by both the computation modes. Given a power supply level, we can derive the optimal tile size and actual duplication granularity to form the activation solution  ⟨ m, n, aG ⟩ for sequential or pipelined computation modes, respectively. Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level.",
      "type": "sliding_window_shuffled",
      "tokens": 108,
      "augmented": true
    },
    {
      "text": "Then, a global activation strategy can pick up the best one of these two and generate a hybrid solution for the concerned power level. Throughput model  Achieving the maximal computation progress under the harvested energy has two implications. The ﬁrst one is that we expect more energy can be used for program progress.",
      "type": "sliding_window_shuffled",
      "tokens": 65,
      "augmented": true
    },
    {
      "text": "In this regard, the metric  throughput  measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios. The ﬁrst one is that we expect more energy can be used for program progress. The other is more subtle in that we expect the power can be consumed quickly in order to receive more energy from outside.",
      "type": "sliding_window_shuffled",
      "tokens": 81,
      "augmented": true
    },
    {
      "text": "In this regard, the metric  throughput  measured by computations (convolutional MACs) per second is a useful proxy for ResiRCA in energy-harvesting scenarios. We use the number of convolutional MAC operations to represent the computations. For the sequential computation mode, the throughput for Layer  Lk  can be expressed as below: \nThr sequ Lk =  ( m  ×  n ) Lk  ×  aG Lk \nLat Lk (6) \nThe average throughput with a  LC -convolution CNN infer- ence can be expressed as shown below.",
      "type": "sliding_window_shuffled",
      "tokens": 134,
      "augmented": true
    },
    {
      "text": "The throughput can be expressed as follows: \nThr pipe ave   = P Lk = LC Lk =1 ( m  ×  n ) Lk  ×  aG Lk \nLat pipe (8) \n2) Activation strategy formulation :  The activation strategy for the sequential mode can be described as shown below. Thr sequ ave   = P Lk = LC Lk =1 ( m  ×  n ) Lk  ×  aG Lk P Lk = C Lk =1   Lat Lk (7) \nFor the pipelining computation mode, all the  LC  layers are executed in parallel. For the sequential computation mode, the throughput for Layer  Lk  can be expressed as below: \nThr sequ Lk =  ( m  ×  n ) Lk  ×  aG Lk \nLat Lk (6) \nThe average throughput with a  LC -convolution CNN infer- ence can be expressed as shown below.",
      "type": "sliding_window_shuffled",
      "tokens": 217,
      "augmented": true
    },
    {
      "text": "The throughput can be expressed as follows: \nThr pipe ave   = P Lk = LC Lk =1 ( m  ×  n ) Lk  ×  aG Lk \nLat pipe (8) \n2) Activation strategy formulation :  The activation strategy for the sequential mode can be described as shown below. In order to formulate the problem in a concise way, the tiling factors,  m  and  n , are constrained to be divisors of the ReRAM weight matrix M ×  N using the annotations of  m  |  M ;  n  |  N . Objective:  Maximize  Thr sequ ave Subjected to:  for each layer Lk, P   load Lk   , P  store Lk , P   comp Lk , P   trans Lk , P   merge Lk < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ⟨ m Lk , n Lk , aG Lk ⟩ for each layer Lk \nSimilarly, the activation strategy under the pipeline execution mode can be described as below.",
      "type": "sliding_window_shuffled",
      "tokens": 270,
      "augmented": true
    },
    {
      "text": "Objective:  Maximize  Thr sequ ave Subjected to:  for each layer Lk, P   load Lk   , P  store Lk , P   comp Lk , P   trans Lk , P   merge Lk < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ⟨ m Lk , n Lk , aG Lk ⟩ for each layer Lk \nSimilarly, the activation strategy under the pipeline execution mode can be described as below. Then the optimal solution can be selected from among them. Objective:  Maximize  Thr pipe ave Subjected to: P  P  load , P  P  store , P  P  comp pipe   , P  P  trans , P  P  merge < P   budget ; aG Lk  < G Lk ; m Lk  |  M Lk ;  n Lk  |  N Lk ; Solution output:  ⟨ m Lk , n Lk , aG Lk ⟩ for each layer Lk \nBy solving the above problems, we can obtain activation solution  ⟨ m, n, aG ⟩ for each power level under the sequential and pipelining computation modes, referred to as  SOL sequ \nand  SOL pipe   respectively.",
      "type": "sliding_window_shuffled",
      "tokens": 308,
      "augmented": true
    },
    {
      "text": "Then the optimal solution can be selected from among them. It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode. The solution space is actually very small because of the constraints that tile size candidates and aG  are all bounded in the integer domain.",
      "type": "sliding_window_shuffled",
      "tokens": 67,
      "augmented": true
    },
    {
      "text": "In this case, we choose the activation solution with larger tiling size by taking into account the transition cost. It may happen that multiple equivialent solutions can be obtained either for sequential computing mode or pipelining computing mode. If the tiling sizes of output solutions are the same, we choose larger  m because larger  m  implies fewer partial sum adds.",
      "type": "sliding_window_shuffled",
      "tokens": 82,
      "augmented": true
    },
    {
      "text": "If the tiling sizes of output solutions are the same, we choose larger  m because larger  m  implies fewer partial sum adds. Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy. D. Activation transition \nThe power instability of energy harvesting implies that the activation solution needs to change dynamically as power level changes.",
      "type": "sliding_window_shuffled",
      "tokens": 78,
      "augmented": true
    },
    {
      "text": "An FSM transition can happen between any pair of power levels. Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy. Activation solution under power level  l: <m l , n l , aG l > \nActivation solution under power level  h: <m h , n h , aG h > \nSmooth transition l->h without power prediction \nSmooth transition l->h \nwith power prediction \nSmooth transition h->l without power prediction \nSmooth transition h->l \nwith power prediction \n1 \n2 \n3 \n4 \nFig.",
      "type": "sliding_window_shuffled",
      "tokens": 132,
      "augmented": true
    },
    {
      "text": "7. Activation solution under power level  l: <m l , n l , aG l > \nActivation solution under power level  h: <m h , n h , aG h > \nSmooth transition l->h without power prediction \nSmooth transition l->h \nwith power prediction \nSmooth transition h->l without power prediction \nSmooth transition h->l \nwith power prediction \n1 \n2 \n3 \n4 \nFig. Activation solution transition FSM \nThe convolution computations of one inference may not be completed while transitioning to a new power level.",
      "type": "sliding_window_shuffled",
      "tokens": 133,
      "augmented": true
    },
    {
      "text": "For small-scale applications with strong harvested power supply, discarding the incomplete execution may have only modest overheads. However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle. Activation solution transition FSM \nThe convolution computations of one inference may not be completed while transitioning to a new power level.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "Fortunately, there exist opportunities to keep and transfer the intermediate computation results of the last incomplete inference to the next power cycle. Considering a transition \nfor one layer from an activation solution  ⟨ m 1 , n 1 , aG 1 ⟩ to ⟨ m 2 , n 2 , aG 2 ⟩ , we ﬁnd that, if the expression  Condition trans : ( m 1 =  m 2)&( n 2  |  ( Tile count 1   ×  n 1))&( aG 1 =  aG 2) is true for each convolution layer, the activation solution ⟨ m 1 , n 1 , aG 1 ⟩ with power level PL1 can be transferred to be equivalent to an execution of activation solution  ⟨ m 2 , n 2 , aG 2 ⟩ with PL2. However, for large-scale applications with weak harvested power supply, it is highly desirable to maintain the already-obtained results and smoothly transfer them to the next power cycle.",
      "type": "sliding_window_shuffled",
      "tokens": 233,
      "augmented": true
    },
    {
      "text": "The execution equivalency can be transferred by Tile count 2   =  Tile count 1   ×  n 1 /n 2 . The next power cycle’s level information cannot be known with certainty. Considering a transition \nfor one layer from an activation solution  ⟨ m 1 , n 1 , aG 1 ⟩ to ⟨ m 2 , n 2 , aG 2 ⟩ , we ﬁnd that, if the expression  Condition trans : ( m 1 =  m 2)&( n 2  |  ( Tile count 1   ×  n 1))&( aG 1 =  aG 2) is true for each convolution layer, the activation solution ⟨ m 1 , n 1 , aG 1 ⟩ with power level PL1 can be transferred to be equivalent to an execution of activation solution  ⟨ m 2 , n 2 , aG 2 ⟩ with PL2.",
      "type": "sliding_window_shuffled",
      "tokens": 214,
      "augmented": true
    },
    {
      "text": "This means that only a portion of computation results from   ∗ Tile count 1   to  Tile count 1   will be discarded. In order to not discard the acquired results, we can search the maximal   ∗ Tile count 1   where   ∗ Tile count 1   ≤ Tile count 1   to make the expression  n 2  |  ( ∗ Tile count 1   ×  n 1) conservatively true for each layer, and then transfer the tile count ∗ Tile count 1  to accommodate to the new activation solution. The next power cycle’s level information cannot be known with certainty.",
      "type": "sliding_window_shuffled",
      "tokens": 116,
      "augmented": true
    },
    {
      "text": "This means that only a portion of computation results from   ∗ Tile count 1   to  Tile count 1   will be discarded. The discussion on this transition without power prediction is applied for transitions 1  and 2  in the Figure 7. We call this smooth transition strategy as  Transition Keep .",
      "type": "sliding_window_shuffled",
      "tokens": 57,
      "augmented": true
    },
    {
      "text": "In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference. With a power predictor [ 36 ], we can estimate the power level of the next power cycle in advance. We call this smooth transition strategy as  Transition Keep .",
      "type": "sliding_window_shuffled",
      "tokens": 64,
      "augmented": true
    },
    {
      "text": "Otherwise, if the expression  Condition trans \nis not satisﬁed, with power prediction, we can still speculatively attempt to perform a smooth transition. Still, with Condition trans   satisﬁed, the smooth transition can be achieved in a similar way. In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference.",
      "type": "sliding_window_shuffled",
      "tokens": 80,
      "augmented": true
    },
    {
      "text": "Otherwise, if the expression  Condition trans \nis not satisﬁed, with power prediction, we can still speculatively attempt to perform a smooth transition. There are two strategies to achieve this. •  We can search for an intermediate power level, where we ﬁrst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level – this strategy is called  Multi-step Transition .",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "•  We can search for an intermediate power level, where we ﬁrst switch to the activation solution corresponding to this intermediate power level and then switch to the solution of the actual power level – this strategy is called  Multi-step Transition . •  If the power predictor reports a power transition from a high level to a low level, we can move to the new activation solution before performing the last incomplete inference – this strategy is referred to as  Eager Transition . The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7.",
      "type": "sliding_window_shuffled",
      "tokens": 122,
      "augmented": true
    },
    {
      "text": "The discussion on this transition with power prediction is applied for transitions 3 and 4 in the Figure 7. Since a power predictor itself consumes power, it makes sense to employ it for large-scale applications under weak power sources where discarding a portion of computations may impose a big loss or for the scenarios where power level transitions happen frequently. VI.",
      "type": "sliding_window_shuffled",
      "tokens": 77,
      "augmented": true
    },
    {
      "text": "E XPERIMENTS \nTo evaluate ResiRCA, we have extended the Gem5 [ 37 ] simulator with RCA modeling. VI. The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock.",
      "type": "sliding_window_shuffled",
      "tokens": 56,
      "augmented": true
    },
    {
      "text": "The energy harvesting mechanism is supported by the power management unit, which can record power production and consumption at an execution cycle level. The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs. The basic MCU is built on an ARM core, and the entire system runs on a 200MHz clock.",
      "type": "sliding_window_shuffled",
      "tokens": 96,
      "augmented": true
    },
    {
      "text": "The added RCA module consists of ReRAM crossbars, the activation solution table, and other function units (e.g., Pooling, FC, sigmoid) of the CNNs. However, for other functional units, we assign a ﬁxed latency. We perform cycle-accurate simulation for the MAC computations based on tile activation and the data load/store process.",
      "type": "sliding_window_shuffled",
      "tokens": 89,
      "augmented": true
    },
    {
      "text": "Load/store parameters of the ReRAM memory are from NVSim [ 40 ]. However, for other functional units, we assign a ﬁxed latency. For the ReRAM circuit simulation, we quantify power and performance of our design in HSPice [ 38 ] using 20nm \nFinFET ReRAM parameters from [ 39 ].",
      "type": "sliding_window_shuffled",
      "tokens": 74,
      "augmented": true
    },
    {
      "text": "The main parameters of our simulations are given in Table VI. Load/store parameters of the ReRAM memory are from NVSim [ 40 ]. Four practical CNNs listed in Table VI are evaluated on the ﬁve power traces illustrated in Figure 4 for each of the ﬁve execution strategies from Section  V-A 3:  Naive1 ;  Naive2 ;  Sequential ; Pipelining ; and  ResiSchedule .",
      "type": "sliding_window_shuffled",
      "tokens": 95,
      "augmented": true
    },
    {
      "text": "power Input \nPV [41] \nInput 1@50 × 50 Conv1 8@6 × 6 × 1 36 × 8 752.2 µ W 8@45 × 45 Conv2 12@3 × 3 × 8 72 × 12 1125.6 µ W 12@20 × 20 Conv3 16@3 × 3 × 12 108 × 16 1526 µ W 16@8 × 8 Conv4 10@3 × 3 × 16 144 × 10 1114 µ W 10@6 × 6 Conv5 6@3 × 3 × 10 90 × 6 676.2 µ W 6@4 × 4 \nFR [42] \nInput 1@32 × 32 Conv1 4@5 × 5 × 1 25 × 4 377.4 µ W 4@28 × 28 Conv2 16@4 × 4 × 4 64 × 16 1433.6 µ W 16@10 × 10 \nLeNet [43] \nInput 1@32 × 32 Conv1 6@5 × 5 × 1 25 × 6 539.7 µ W 6@28 × 28 Conv2 16@5 × 5 × 6 150 × 16 1614.2 µ W 16@10 × 10 \nHG [44] \nInput 1@28 × 28 Conv1 6@5 × 5 × 1 25 × 6 539.7 µ W 6@24 × 24 Conv2 12@4 × 4 × 6 96 × 12 1176 µ W 12@8 × 8 \nFor each application on each power trace, we report the throughput and energy efﬁciency under the ﬁve different execution strategies. We also study the sensitivity of our proposed approach to available ReRAM hardware resources. We then demonstrate the beneﬁts from the proposed smooth transition strategy and power prediction.",
      "type": "sliding_window_shuffled",
      "tokens": 420,
      "augmented": true
    },
    {
      "text": "The bars are all normalized to  ResiSchedule . A. Throughput \nFigure 8 shows the throughput comparison of the ﬁve exe- cution strategies. We also study the sensitivity of our proposed approach to available ReRAM hardware resources.",
      "type": "sliding_window_shuffled",
      "tokens": 54,
      "augmented": true
    },
    {
      "text": "The bars are all normalized to  ResiSchedule . The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 ×  compared to a baseline RCA with intermittency-unaware scheduling. The included table gives the absolute values of throughput by ResiSchedule.",
      "type": "sliding_window_shuffled",
      "tokens": 81,
      "augmented": true
    },
    {
      "text": "The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 ×  compared to a baseline RCA with intermittency-unaware scheduling. One can make the following observations and analyses from these results: •  For each workload with each power source,  ResiSchedule always achieves the highest throughput because it combines the best activation solution in each power cycle. The results of Naive1  are the worst because it lacks both adequate hardware resources and scheduling ﬂexibility.",
      "type": "sliding_window_shuffled",
      "tokens": 117,
      "augmented": true
    },
    {
      "text": "•  The results of  ResiSchedule  are very close or equal to that of  Sequential  under most cases. The results of Naive1  are the worst because it lacks both adequate hardware resources and scheduling ﬂexibility. Although  Naive2  is based on the  ResiRCA  architecture, the throughput is still relatively low because it lacks scheduling adaptation to ﬁt to the changing harvested power.",
      "type": "sliding_window_shuffled",
      "tokens": 81,
      "augmented": true
    },
    {
      "text": "When we track the simulation cycles, it is found that the throughput of  Sequential  solution \nResiSchedule \nPiezo WiFi-home WiFi-office Thermal TV-RF \nFig. 8. •  The results of  ResiSchedule  are very close or equal to that of  Sequential  under most cases.",
      "type": "sliding_window_shuffled",
      "tokens": 66,
      "augmented": true
    },
    {
      "text": "9. Throughput of CNNs across the power sources normalized to ResiSchedule \nPiezo WiFi-home WiFi-office Thermal TV-RF \nFig. 8.",
      "type": "sliding_window_shuffled",
      "tokens": 37,
      "augmented": true
    },
    {
      "text": "9. That is, the selection ratio of  Sequential  is much higher than the ratio of  Pipelining  in ResiSchedule  solutions in the whole power trace. Energy efﬁciency of CNNs across the power sources normalized to ResiSchedule \nis higher than that of  Pipelining  solution for a signiﬁcant fraction of the active power cycles.",
      "type": "sliding_window_shuffled",
      "tokens": 71,
      "augmented": true
    },
    {
      "text": "•  Consistent with the above observation, the entire  Sequential strategy competes with the entire  Pipelining . That is, the selection ratio of  Sequential  is much higher than the ratio of  Pipelining  in ResiSchedule  solutions in the whole power trace. The reason is that the active power threshold of  Pipelining  is much higher than that of  Sequential .",
      "type": "sliding_window_shuffled",
      "tokens": 77,
      "augmented": true
    },
    {
      "text": "The reason is that the active power threshold of  Pipelining  is much higher than that of  Sequential . As a result, fewer power cycles of Pipelining  are available than that of  Sequential . However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments.",
      "type": "sliding_window_shuffled",
      "tokens": 64,
      "augmented": true
    },
    {
      "text": "However, we believe that this is highly related to the default ReRAM duplication assignment in the experiments. When we change to a smaller ReRAM duplication granularity  G , we ﬁnd that the throughput of  Pipelining  is better than that of  Sequential for many power levels. The duplication sensitivity results are presented in Section VI-F. •  Regarding the throughput absolute values, the results with the power sources of  Thermal  and  TV-RF  are much higher than those with the others, which is constant with the power strength illustrated in Figure 4.",
      "type": "sliding_window_shuffled",
      "tokens": 116,
      "augmented": true
    },
    {
      "text": "B. The duplication sensitivity results are presented in Section VI-F. •  Regarding the throughput absolute values, the results with the power sources of  Thermal  and  TV-RF  are much higher than those with the others, which is constant with the power strength illustrated in Figure 4. Energy efﬁciency \nWe evaluate energy efﬁciency by measuring MAC operations per Joule, as shown in Figure 9.",
      "type": "sliding_window_shuffled",
      "tokens": 79,
      "augmented": true
    },
    {
      "text": "Energy efﬁciency \nWe evaluate energy efﬁciency by measuring MAC operations per Joule, as shown in Figure 9. Overall, the normalized results of energy efﬁciency are very similar to those of the throughput evaluation. Note that this includes the energy overheads of data movements and other functional units in addition to MACs.",
      "type": "sliding_window_shuffled",
      "tokens": 64,
      "augmented": true
    },
    {
      "text": "The only difference that can be observed is that, regarding LeNet  and  PV  with the power source of  Thermal , relatively speaking, the results of energy efﬁciency with  Pipelining strategy are higher than that appearing in the throughput evaluation. The results show that ResiRCA and ResiSchedule achieve average energy efﬁciency improvements of 14 ×  compared to a baseline RCA with intermittency-unaware scheduling. Overall, the normalized results of energy efﬁciency are very similar to those of the throughput evaluation.",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "One possible reason for this is that  Pipelining \nrequires loading several inputs from ReRAM memory to perform the parallel operations, which is power-expensive. This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efﬁciency when active is high. The only difference that can be observed is that, regarding LeNet  and  PV  with the power source of  Thermal , relatively speaking, the results of energy efﬁciency with  Pipelining strategy are higher than that appearing in the throughput evaluation.",
      "type": "sliding_window_shuffled",
      "tokens": 107,
      "augmented": true
    },
    {
      "text": "Compared to the cloud for online processing, the preference for local compute over ofﬂoad can stem from security, con- nectivity and latency concerns as well as power and energy constraints. This results in a behavior where, albeit less frequently having enough power to activate at all, the energy efﬁciency when active is high. In our work, local computation across the CNN applications is  ∼ 50x more efﬁcient than transmission over Bluetooth with 3Mbps and 2.5mW.",
      "type": "sliding_window_shuffled",
      "tokens": 97,
      "augmented": true
    },
    {
      "text": "In our work, local computation across the CNN applications is  ∼ 50x more efﬁcient than transmission over Bluetooth with 3Mbps and 2.5mW. The x-axis (power efﬁciency) denotes the percentage of power cycles where the RCA can activate. C. Power utilization In order to further understand the power utilization, we use a two-dimensional plot that illustrates the features of power consumption with the ResiSchedule  strategy, as shown in Figure 10.",
      "type": "sliding_window_shuffled",
      "tokens": 99,
      "augmented": true
    },
    {
      "text": "An ideal system would be at the point (1,1). The x-axis (power efﬁciency) denotes the percentage of power cycles where the RCA can activate. The y-axis (power utilization), on the other hand, denotes the percentage of valid power during activations which is actually utilized for computation and data transfer.",
      "type": "sliding_window_shuffled",
      "tokens": 73,
      "augmented": true
    },
    {
      "text": "0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 \n0 0.10.20.30.40.50.60.70.80.9 1 \nPower Utilization \nPower efficiency \nPiezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG \nFig. It can be observed from these results that the proposed  ResiSchedule  strategy can make good use of the  Piezo source when it does exceed the minimal activation thresholds, though the very low duty cycle yields very low throughput. An ideal system would be at the point (1,1).",
      "type": "sliding_window_shuffled",
      "tokens": 170,
      "augmented": true
    },
    {
      "text": "ResiSchedule power efﬁciency analysis \nD. Transition efﬁciency Table  VI-D  shows the ratio of inferences using smooth- transitioned partial results and total inference count number. 10. 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 \n0 0.10.20.30.40.50.60.70.80.9 1 \nPower Utilization \nPower efficiency \nPiezo-LeNet Piezo-FR Piezo-HG Piezo-PV WiFi-h-LeNet WiFi-h-FR WiFi-h-HG WiFi-h-PV WiFi-o-LeNet WiFi-o-FR WiFi-o-HG Thermal-LeNet Thermal-FR Thermal-HG \nFig.",
      "type": "sliding_window_shuffled",
      "tokens": 148,
      "augmented": true
    },
    {
      "text": "ResiSchedule power efﬁciency analysis \nD. Transition efﬁciency Table  VI-D  shows the ratio of inferences using smooth- transitioned partial results and total inference count number. However, a very small fraction is observed with the other, stronger power sources. These results indicate that the smooth transition strategy Transition Keep   enables a signiﬁcant fraction of the inferences for all workloads on  Piezo .",
      "type": "sliding_window_shuffled",
      "tokens": 88,
      "augmented": true
    },
    {
      "text": "However, one power cycle of the other power sources can usually process thousands or hundreds of inferences. For Piezo , saving the intermediate results of one incomplete inference is meaningful. However, a very small fraction is observed with the other, stronger power sources.",
      "type": "sliding_window_shuffled",
      "tokens": 57,
      "augmented": true
    },
    {
      "text": "However, one power cycle of the other power sources can usually process thousands or hundreds of inferences. TABLE V T HE RATIO OF ADDITIONAL INFERENCES ENABLED BY THE SMOOTH TRANSITION STRATEGY VS . TOTAL INFERENCES \nPiezo WiFi-h WiFi-o Thermal TV-RF \nLeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 \nE. Power predictor \nWith an accurate power predictor [ 45 ], [ 36 ], we can make more smooth transitions among different power levels.",
      "type": "sliding_window_shuffled",
      "tokens": 199,
      "augmented": true
    },
    {
      "text": "TOTAL INFERENCES \nPiezo WiFi-h WiFi-o Thermal TV-RF \nLeNet 0.978632 0.000574 0.000782 0.000096 0.000068 FR 0.927445 0.000538 0.000594 0.000067 0.000059 HG 0.862620 0.000319 0.000416 0.000062 0.000049 PV 0.980769 0.002529 0.003181 0.000335 0.000266 \nE. Power predictor \nWith an accurate power predictor [ 45 ], [ 36 ], we can make more smooth transitions among different power levels. The beneﬁt is that we can keep more MAC results of the last \nincomplete inference when switching from a higher power level to a lower power level, even if  Condition trans   is not satisﬁed. However, to be valuable the power predictor must have high accuracy.",
      "type": "sliding_window_shuffled",
      "tokens": 193,
      "augmented": true
    },
    {
      "text": "However, to be valuable the power predictor must have high accuracy. Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with  Transition keep   for all the workloads with these power sources. For both  Piezo  and  Thermal  power sources the prediction accuracy when using a multi-power-level-optimized extension of the power predictor in [ 36 ] are above 80%.",
      "type": "sliding_window_shuffled",
      "tokens": 94,
      "augmented": true
    },
    {
      "text": "inferences w/ smooth transition vs. # all inferences vs. # addi. Figure 11 shows the percentages of additional inferences enabled by power prediction over all inferences and additional inferences with  Transition keep   for all the workloads with these power sources. 0.0% \n0.3% \n0.0% \n0.3% \n0.0% \n0.9% \n1.9% \n2.0% \n0.0% \n0.5% \n0.0% \n20.0% \n40.0% \n60.0% \nvs. # all inferences vs. # addi.",
      "type": "sliding_window_shuffled",
      "tokens": 112,
      "augmented": true
    },
    {
      "text": "inferences w/ smooth transition vs. # all inferences vs. # addi. inferences w/ smooth transition \nPiezo Thermal \nLeNet FR HG PV \nFig. 11.",
      "type": "sliding_window_shuffled",
      "tokens": 49,
      "augmented": true
    },
    {
      "text": "This is because, the Piezo  source is very weak and and the total completed number of inferences is quite small. Percentages of additional inferences with power prediction over all inferences and additional inferences with the  Transition keep \nstrategy \nThe portion of inferences added with power prediction are signiﬁcant for  Piezo  for most workloads. 11.",
      "type": "sliding_window_shuffled",
      "tokens": 75,
      "augmented": true
    },
    {
      "text": "This is because, the Piezo  source is very weak and and the total completed number of inferences is quite small. Speculative action supported by power prediction can keep quite a few incomplete inferences to be completed in the next power cycle. This can also explain why the portions with the power source of  Thermal  are very small.",
      "type": "sliding_window_shuffled",
      "tokens": 72,
      "augmented": true
    },
    {
      "text": "The underlying reason is that the smooth  Transition keep   strategy can already handle the smooth transitions with no need of power prediction support for this workload. However, for both  Piezo  and  Thermal , the portions for  PV  are very small. This can also explain why the portions with the power source of  Thermal  are very small.",
      "type": "sliding_window_shuffled",
      "tokens": 66,
      "augmented": true
    },
    {
      "text": "Throughput results are plotted in Figure 12 and area costs for  G 1  ∼ G 5  can be found in Figure 13. F. Sensitivity study on duplication copy \nWe vary the ReRAM duplication granularity  G  for each layer and evaluate with  TV-RF  source. The underlying reason is that the smooth  Transition keep   strategy can already handle the smooth transitions with no need of power prediction support for this workload.",
      "type": "sliding_window_shuffled",
      "tokens": 89,
      "augmented": true
    },
    {
      "text": "For each benchmark, all the numbers are normalized to that of the  G4  setting with the  Naive2  policy. As expected, the throughput increases as  G  grows for every benchmark. Throughput results are plotted in Figure 12 and area costs for  G 1  ∼ G 5  can be found in Figure 13.",
      "type": "sliding_window_shuffled",
      "tokens": 64,
      "augmented": true
    },
    {
      "text": "The main reason for this is that the  ResiSchedule  policy can efﬁciently organize more hardware resources than the  Sequential  policy when hardware resources are limited. As expected, the throughput increases as  G  grows for every benchmark. Another interesting observation is that the results of  ResiSchedule  policy can be competitive to that of  Sequential policy when  G  is small and vice versa.",
      "type": "sliding_window_shuffled",
      "tokens": 80,
      "augmented": true
    },
    {
      "text": "0.00 0.20 0.40 0.60 0.80 1.00 1.20 1.40 1.60 \nG1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 G1 G2 G3 G4 G5 \nPV HG LeNet FR \nNaive2 Sequential Pipelining ResiSchedule \nFig. 12. The main reason for this is that the  ResiSchedule  policy can efﬁciently organize more hardware resources than the  Sequential  policy when hardware resources are limited.",
      "type": "sliding_window_shuffled",
      "tokens": 115,
      "augmented": true
    },
    {
      "text": "It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed “smart dust” solutions [ 8 ]. 12. Throughput normalized to G4 with  Naive2  vs. ReRAM duplication granularity \nThe RCA area is impacted from the parallelism granularity G , as shown in Figure 13.",
      "type": "sliding_window_shuffled",
      "tokens": 78,
      "augmented": true
    },
    {
      "text": "The ideal parallelism granularity determination for a particular deployment should consider the balance between throughput and area. 0 20000 40000 60000 80000 100000 120000 140000 160000 \nPV HG LeNet FR G1 G2 G3 G4 (default) G5 \nArea in ­ m 2 \n<2, 2, 2, 2, 2> <4, 3, 2, 3, 5> <6, 4, 3, 4, 7> <8, 5, 4, 5, 9> \n<12, 7, 6, 7, 13> \n<2, 2> <6, 2> <9, 3> <11, 5> <16, 7> \n<2, 2> <5, 2> <8, 3> <11, 4> <16, 6> \n<2, 2> <7, 2> <13, 3> <17, 4> <22, 6> \nFig. It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed “smart dust” solutions [ 8 ].",
      "type": "sliding_window_shuffled",
      "tokens": 228,
      "augmented": true
    },
    {
      "text": "0 20000 40000 60000 80000 100000 120000 140000 160000 \nPV HG LeNet FR G1 G2 G3 G4 (default) G5 \nArea in ­ m 2 \n<2, 2, 2, 2, 2> <4, 3, 2, 3, 5> <6, 4, 3, 4, 7> <8, 5, 4, 5, 9> \n<12, 7, 6, 7, 13> \n<2, 2> <6, 2> <9, 3> <11, 5> <16, 7> \n<2, 2> <5, 2> <8, 3> <11, 4> <16, 6> \n<2, 2> <7, 2> <13, 3> <17, 4> <22, 6> \nFig. Area with different duplication granularity \nVII. 13.",
      "type": "sliding_window_shuffled",
      "tokens": 186,
      "augmented": true
    },
    {
      "text": "R ELATED  W ORK \nThe previous RCA related work can be divided into the following two categories: High Performance RCA Architectures: PRIME [ 4 ] uses 6-bit inputs and 8-bit weights and targets 6-bit output precision. A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight. Area with different duplication granularity \nVII.",
      "type": "sliding_window_shuffled",
      "tokens": 100,
      "augmented": true
    },
    {
      "text": "A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight. In the PRIME conﬁguration, the ReRAM-based Full Function (FF) subarrays have both computation and data storage capabilities. To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "In the ISAAC design [ 3 ], the inputs, weights and outputs are all 16 bits, where the DAC, ReRAM cell and ADC resolutions are, respectively, 1-bit, 2-bit and 8-bit. To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed. Also, a similar composition scheme is employed to organize the input, weight and output data.",
      "type": "sliding_window_shuffled",
      "tokens": 97,
      "augmented": true
    },
    {
      "text": "Also, a similar composition scheme is employed to organize the input, weight and output data. An intra-tile pipeline is formed to boost the dot-product throughput. The ISAAC architecture is composed of 16 tiles and each tile consists of 8 IMAs which includes 4 ReRAMs along with 4 sets of peripheral circuits.",
      "type": "sliding_window_shuffled",
      "tokens": 72,
      "augmented": true
    },
    {
      "text": "The underlying idea is to use spike counts to represent the data value. An intra-tile pipeline is formed to boost the dot-product throughput. In the PipeLayer design [ 5 ], a spike-based scheme, instead of a voltage-level based scheme, is used for input to eliminate the power overhead of DACs and ADCs.",
      "type": "sliding_window_shuffled",
      "tokens": 79,
      "augmented": true
    },
    {
      "text": "The underlying idea is to use spike counts to represent the data value. They propose intra-layer and inter-layer parallelism to support the training phase by reducing potential stalls. ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [ 8 ] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets.",
      "type": "sliding_window_shuffled",
      "tokens": 99,
      "augmented": true
    },
    {
      "text": "ReRAM MAC circuits for the IoT: The nonvolatile intelligent processor (NIP) [ 8 ] is designed for accelerating fully-connected layers in energy harvesting IoT scenarios, in contrast to the convolutional layers ResiRCA targets. It includes four ReRAMs, each 32x32. The inputs and weights are binary and the output is adaptive between 1-3 bits.",
      "type": "sliding_window_shuffled",
      "tokens": 89,
      "augmented": true
    },
    {
      "text": "Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a \n3-bit resolution, which is a high performance but also a high power consuming design. The inputs and weights are binary and the output is adaptive between 1-3 bits. The serial-input non-weighted product (SINWP) structure [ 6 ] is the ﬁrst work to propose multi-bit input/weight and output design from the circuit level, adopting a 2-bit input, 3-bit weight, and 4-bit output scheme.",
      "type": "sliding_window_shuffled",
      "tokens": 127,
      "augmented": true
    },
    {
      "text": "Note that each 3-bit signed weight needs a single-level-cell (SLC) ReRAM cell and is processed with a \n3-bit resolution, which is a high performance but also a high power consuming design. •  The architecture-centric works [ 3 ], [ 4 ], [ 5 ] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption. Although the above designs provide different approaches to achieve high throughput, high energy efﬁciency and low power, they cannot be directly applied or combined to be applied in the energy harvested edge devices due to the following reasons.",
      "type": "sliding_window_shuffled",
      "tokens": 127,
      "augmented": true
    },
    {
      "text": "For example, the total 168  Tiles  and one  IMA  element of the ISAAC architecture [ 3 ] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets. Furthermore, the hierarchy they adopt with multiple ReRAMs targets primarily high throughput, leading to high power consumption on the whole RCA. •  The architecture-centric works [ 3 ], [ 4 ], [ 5 ] conservatively maintain high precision data and high resolution circuit signals, leading to high power consumption.",
      "type": "sliding_window_shuffled",
      "tokens": 137,
      "augmented": true
    },
    {
      "text": "•  Although the spike-based scheme [ 5 ] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input/output data. For example, the total 168  Tiles  and one  IMA  element of the ISAAC architecture [ 3 ] collectively consume 55.4W and 27.5mW respectively, while the peak harvested power for edge devices often lies in the range from hundreds of micro-watts to a few milli-watts in our collection sets. It can be seen that those designs are  not  suitable for an RCA supplied with harvested unstable power.",
      "type": "sliding_window_shuffled",
      "tokens": 132,
      "augmented": true
    },
    {
      "text": "•  Although the spike-based scheme [ 5 ] eliminates the power consuming part of the ReRAM peripheral circuits, it introduces very long latency to input/output data. •  For the ReRAM circuit concerned works [ 6 ], [ 8 ], although they are lightweight, they  cannot  be dynamically reconﬁgured to adapt changing power levels. It is known that the energy harvesting system often suffers from power failures and works in an intermittent mode; so, the spike-based data injection scheme is not favorable.",
      "type": "sliding_window_shuffled",
      "tokens": 111,
      "augmented": true
    },
    {
      "text": "In addition, such works have not presented any software level solution to maximize the utilization of the hardware platform. •  For the ReRAM circuit concerned works [ 6 ], [ 8 ], although they are lightweight, they  cannot  be dynamically reconﬁgured to adapt changing power levels. In order to accommodate the RCA to the changing harvested power supply, we need a “lightweight” and “ﬁne-grain controllable” design from both the hardware and software angles.",
      "type": "sliding_window_shuffled",
      "tokens": 97,
      "augmented": true
    },
    {
      "text": "VIII. In order to accommodate the RCA to the changing harvested power supply, we need a “lightweight” and “ﬁne-grain controllable” design from both the hardware and software angles. C ONCLUSION \nMAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs.",
      "type": "sliding_window_shuffled",
      "tokens": 80,
      "augmented": true
    },
    {
      "text": "C ONCLUSION \nMAC operations are the dominant computations in CNN applications which play a key role in intelligent edge devices such as smart sensors in IoTs. This paper proposes ResiRCA, a resilient energy harvesting accelerator. Considering the application sce- narios where the accelerator is supported by harvested energy, we ﬁnd that the previous designs cannot well accommodate the RCA to the changing power sources.",
      "type": "sliding_window_shuffled",
      "tokens": 92,
      "augmented": true
    },
    {
      "text": "ResiRCA supports smooth transi- tions among different activation solutions against computation loss. This paper proposes ResiRCA, a resilient energy harvesting accelerator. We propose a lightweight and ﬂexibly tuning RCA architecture and a ResiSchedule scheme to dynamically activate various scaled MAC operations so as to fully translate the “harvested energy” into “computation progress”.",
      "type": "sliding_window_shuffled",
      "tokens": 87,
      "augmented": true
    },
    {
      "text": "ResiRCA supports smooth transi- tions among different activation solutions against computation loss. The experiment results show that the proposed ResiRCA along with the ResiSchedule scheme can achieve much higher speedups and energy efﬁciency compared to the baselines. ResiRCA for the ﬁrst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future.",
      "type": "sliding_window_shuffled",
      "tokens": 89,
      "augmented": true
    },
    {
      "text": "A CKNOWLEDGEMENTS \nThis work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants #1822923 \n(SPX: SOPHIA), #1763681, #1629915, #1629129, #1317560, #1526750, National Natural Science Foundation of China [NSFC Project No. IX. ResiRCA for the ﬁrst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future.",
      "type": "sliding_window_shuffled",
      "tokens": 147,
      "augmented": true
    },
    {
      "text": "A CKNOWLEDGEMENTS \nThis work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants #1822923 \n(SPX: SOPHIA), #1763681, #1629915, #1629129, #1317560, #1526750, National Natural Science Foundation of China [NSFC Project No. 61872251] and Beijing Advanced Innova- tion Center for Imaging Technology. This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University.",
      "type": "sliding_window_shuffled",
      "tokens": 149,
      "augmented": true
    },
    {
      "text": "This work was completed when Dr. Keni Qiu was visiting the Pennsylvania State University. The authors also greatly appreciate Dr. Yongpan Liu, Dr. Kaisheng Ma, Dr. Xulong Tang and Mr. Challapalle Nagadastagiri Reddy’s useful discussion. R EFERENCES \n[1]  C. Xia, J. Zhao, H. Cui, and X. Feng, “Characterizing DNN models for edge-cloud computing,” in  2018 IEEE International Symposium on Workload Characterization (IISWC) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 132,
      "augmented": true
    },
    {
      "text": "[2]  L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, “Switched by input: Power efﬁcient structure for RRAM-based convolutional neural network,” in  2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC) , pp. 82–83, 2018. R EFERENCES \n[1]  C. Xia, J. Zhao, H. Cui, and X. Feng, “Characterizing DNN models for edge-cloud computing,” in  2018 IEEE International Symposium on Workload Characterization (IISWC) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 162,
      "augmented": true
    },
    {
      "text": "1–6, 2016. [2]  L. Xia, T. Tang, W. Huangfu, M. Cheng, X. Yin, B. Li, Y. Wang, and H. Yang, “Switched by input: Power efﬁcient structure for RRAM-based convolutional neural network,” in  2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC) , pp. [3]  A. Shaﬁee, A.",
      "type": "sliding_window_shuffled",
      "tokens": 106,
      "augmented": true
    },
    {
      "text": "[3]  A. Shaﬁee, A. Nag, N. Muralimanohar, R. Balasubramonian, J. P. Strachan, M. Hu, R. S. Williams, and V. Srikumar, “ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars,” in  2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA) , pp. 14–26, 2016.",
      "type": "sliding_window_shuffled",
      "tokens": 113,
      "augmented": true
    },
    {
      "text": "27–39, 2016. 14–26, 2016. [4]  P. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang, and Y. Xie, “PRIME: A novel processing-in-memory architecture for neural network computation in reram-based main memory,” in  2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 108,
      "augmented": true
    },
    {
      "text": "[5]  L. Song, X. Qian, H. Li, and Y. Chen, “Pipelayer: A pipelined ReRAM- Based accelerator for deep learning,” in  2017 IEEE International Symposium on High Performance Computer Architecture (HPCA) , pp. 541–552, 2017. 27–39, 2016.",
      "type": "sliding_window_shuffled",
      "tokens": 73,
      "augmented": true
    },
    {
      "text": "King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, “24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors,” in  2019 IEEE International Solid- State Circuits Conference - (ISSCC) , pp. 541–552, 2017. [6]  C. Xue, W. Chen, J. Liu, J. Li, W. Lin, W. Lin, J. Wang, W. Wei, T. Chang, T. Chang, T. Huang, H. Kao, S. Wei, Y. Chiu, C. Lee, C. Lo, Y.",
      "type": "sliding_window_shuffled",
      "tokens": 171,
      "augmented": true
    },
    {
      "text": "[7]  W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y. 388–390, 2019. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, “24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors,” in  2019 IEEE International Solid- State Circuits Conference - (ISSCC) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 152,
      "augmented": true
    },
    {
      "text": "[7]  W. Chen, K. Li, W. Lin, K. Hsu, P. Li, C. Yang, C. Xue, E. Yang, Y. Chen, Y. Chang, T. Hsu, Y. 494–496, 2018. King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, “A 65nm 1mb nonvolatile computing-in-memory ReRAM macro with sub-16ns multiply-and-accumulate for binary DNN AI edge processors,” in  2018 IEEE International Solid - State Circuits Conference (ISSCC) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 154,
      "augmented": true
    },
    {
      "text": "[8]  F. Su, W. Chen, L. Xia, C. Lo, T. Tang, Z. Wang, K. Hsu, M. Cheng, J. Li, Y. Xie, Y. Wang, M. Chang, H. Yang, and Y. Liu, “A 462gops/j RRAM-based nonvolatile intelligent processor for energy harvesting ioe system featuring nonvolatile logics and processing-in-memory,” in  2017 Symposium on VLSI Technology , pp. T260–T261, 2017. 494–496, 2018.",
      "type": "sliding_window_shuffled",
      "tokens": 143,
      "augmented": true
    },
    {
      "text": "733–747, 2019. T260–T261, 2017. [9]  Y. Ji, Y. Zhang, X. Xie, S. Li, P. Wang, X. Hu, Y. Zhang, and Y. Xie, “FPSA: A full system stack solution for reconﬁgurable reram-based NN accelerator architecture,” in  Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 117,
      "augmented": true
    },
    {
      "text": "[10]  K. Qiu, W. Chen, Y. Xu, L. Xia, Y. Wang, and Z. Shao, “A peripheral circuit reuse structure integrated with a retimed data ﬂow for low power rram crossbar-based cnn,” in  2018 Design, Automation Test in Europe Conference Exhibition (DATE) , pp. 733–747, 2019. 1057–1062, March 2018.",
      "type": "sliding_window_shuffled",
      "tokens": 103,
      "augmented": true
    },
    {
      "text": "463–468, 2005. [11]  X. Jiang, J. Polastre, and D. Culler, “Perpetual environmentally powered sensor networks,” in  Fourth International Symposium on Information Processing in Sensor Networks (IPSN) , pp. 1057–1062, March 2018.",
      "type": "sliding_window_shuffled",
      "tokens": 66,
      "augmented": true
    },
    {
      "text": "[12]  S. Sudevalayam and P. Kulkarni, “Energy harvesting sensor nodes: Survey and implications,”  IEEE Communications Surveys Tutorials , vol. 463–468, 2005. 13, no.",
      "type": "sliding_window_shuffled",
      "tokens": 53,
      "augmented": true
    },
    {
      "text": "443–461, 2011. [13]  M. Mangrulkar and S. G. Akojwar, “A simple and efﬁcient solar energy harvesting for wireless sensor node,” in  2016 Second International Con- ference on Research in Computational Intelligence and Communication Networks (ICRCICN) , pp. 95–99, 2016.",
      "type": "sliding_window_shuffled",
      "tokens": 78,
      "augmented": true
    },
    {
      "text": "1–4, 2013. [14]  R. Grezaud and J. Willemin, “A self-starting fully integrated auto-adaptive converter for battery-less thermal energy harvesting,” in  2013 IEEE 11th International New Circuits and Systems Conference (NEWCAS) , pp. 95–99, 2016.",
      "type": "sliding_window_shuffled",
      "tokens": 70,
      "augmented": true
    },
    {
      "text": "7, pp. 1–4, 2013. [15]  V. Leonov, T. Torfs, P. Fiorini, and C. Van Hoof, “Thermoelectric converters of human warmth for self-powered wireless sensor nodes,” IEEE Sensors Journal , vol.",
      "type": "sliding_window_shuffled",
      "tokens": 66,
      "augmented": true
    },
    {
      "text": "650–657, May 2007. [16]  X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, “RF-powered systems using steep-slope devices,” in  2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS) , pp. 7, pp.",
      "type": "sliding_window_shuffled",
      "tokens": 83,
      "augmented": true
    },
    {
      "text": "73– 76, 2014. [17]  K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Architecture exploration for ambient energy harvesting nonvolatile processors,” in  2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , pp. [16]  X. Li, U. Dennis Heo, K. Ma, V. Narayanan, H. Liu, and S. Datta, “RF-powered systems using steep-slope devices,” in  2014 IEEE 12th International New Circuits and Systems Conference (NEWCAS) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 174,
      "augmented": true
    },
    {
      "text": "[17]  K. Ma, Y. Zheng, S. Li, K. Swaminathan, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Architecture exploration for ambient energy harvesting nonvolatile processors,” in  2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , pp. 526–537, 2015. [18]  K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, “NEOFog: Nonvolatility-exploiting optimizations for fog computing,” in  Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 215,
      "augmented": true
    },
    {
      "text": "[19]  M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, “Redesigning software and systems for non-volatile processors on self-powered devices,” in  2016 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC) , pp. [18]  K. Ma, X. Li, M. T. Kandemir, J. Sampson, V. Narayanan, J. Li, T. Wu, Z. Wang, Y. Liu, and Y. Xie, “NEOFog: Nonvolatility-exploiting optimizations for fog computing,” in  Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems ASPLOS , pp. 782–796, 2018.",
      "type": "sliding_window_shuffled",
      "tokens": 203,
      "augmented": true
    },
    {
      "text": "[19]  M. Zhao, K. Qiu, Y. Xie, J. Hu, and C. J. Xue, “Redesigning software and systems for non-volatile processors on self-powered devices,” in  2016 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC) , pp. 1–6, Sep. 2016. [20]  L. Ni, Z. Liu, H. Yu, and R. V. Joshi, “An energy-efﬁcient digital ReRAM-crossbar-based cnn with bitwise parallelism,”  IEEE Journal on Exploratory Solid-State Computational Devices and Circuits , vol.",
      "type": "sliding_window_shuffled",
      "tokens": 163,
      "augmented": true
    },
    {
      "text": "3, pp. [20]  L. Ni, Z. Liu, H. Yu, and R. V. Joshi, “An energy-efﬁcient digital ReRAM-crossbar-based cnn with bitwise parallelism,”  IEEE Journal on Exploratory Solid-State Computational Devices and Circuits , vol. 37–46, Dec 2017.",
      "type": "sliding_window_shuffled",
      "tokens": 82,
      "augmented": true
    },
    {
      "text": "[21]  M. Zhao, C. Fu, Z. Li, Q. Li, M. Xie, Y. Liu, J. Hu, Z. Jia, and C. J. Xue, “Stack-size sensitive on-chip memory backup for self-powered nonvolatile processors,”  IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) , vol. 36, pp. 37–46, Dec 2017.",
      "type": "sliding_window_shuffled",
      "tokens": 109,
      "augmented": true
    },
    {
      "text": "36, pp. 1804–1816, Nov 2017. [22]  A. Colin, E. Ruppel, and B. Lucia, “A reconﬁgurable energy storage architecture for energy-harvesting devices,” in  Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018 , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 91,
      "augmented": true
    },
    {
      "text": "767–781, 2018. [23]  X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, “A high- efﬁciency dual-channel photovoltaic power system for nonvolatile sensor nodes,” in  2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA) , pp. [22]  A. Colin, E. Ruppel, and B. Lucia, “A reconﬁgurable energy storage architecture for energy-harvesting devices,” in  Proceedings of the Twenty- Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018, Williamsburg, VA, USA, March 24-28, 2018 , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 164,
      "augmented": true
    },
    {
      "text": "1–2, Aug 2014. [24]  X. [23]  X. Sheng, C. Wang, Y. Liu, H. G. Lee, N. Chang, and H. Yang, “A high- efﬁciency dual-channel photovoltaic power system for nonvolatile sensor nodes,” in  2014 IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 92,
      "augmented": true
    },
    {
      "text": "[24]  X. Sun, S. Yin, X. Peng, R. Liu, J. Seo, and S. Yu, “XNOR-RRAM: A scalable and parallel resistive synaptic architecture for binary neural networks,” in  2018 Design, Automation Test in Europe Conference Exhibition (DATE) , pp. 1423–1428, 2018.",
      "type": "sliding_window_shuffled",
      "tokens": 85,
      "augmented": true
    },
    {
      "text": "[25]  A. K. Mishra and D. Marr, “WRPN & apprentice: Methods for training and inference using low-precision numerics,”  CoRR , vol. 1423–1428, 2018. abs/1803.00227, Apr 2018.",
      "type": "sliding_window_shuffled",
      "tokens": 64,
      "augmented": true
    },
    {
      "text": "[26]  S. Han, H. Mao, and W. J. Dally, “Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding,” CoRR , vol. abs/1510.00149, 2015. abs/1803.00227, Apr 2018.",
      "type": "sliding_window_shuffled",
      "tokens": 71,
      "augmented": true
    },
    {
      "text": "abs/1510.00149, 2015. 1737–1746, 2015. [27]  S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan, “Deep learning with limited numerical precision,” in  Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37 , ICML’15, pp.",
      "type": "sliding_window_shuffled",
      "tokens": 90,
      "augmented": true
    },
    {
      "text": "1737–1746, 2015. 1–6, 2018. [28]  S. Jain, S. Venkataramani, V. Srinivasan, J. Choi, P. Chuang, and L. Chang, “Compensated-dnn: Energy efﬁcient low-precision deep neural networks by compensating quantization errors,” in  2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 99,
      "augmented": true
    },
    {
      "text": "1–6, 2018. [29]  N. Wang, J. Choi, D. Brand, C. Chen, and K. Gopalakrishnan, “Training deep neural networks with 8-bit ﬂoating point numbers,” in  Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018, Montr´eal, Canada. , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 93,
      "augmented": true
    },
    {
      "text": "He, J. Sun, and N. Vasconcelos, “Deep learning with low precision by half-wave gaussian quantization,”  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. [30]  Z. Cai, X.",
      "type": "sliding_window_shuffled",
      "tokens": 62,
      "augmented": true
    },
    {
      "text": "Sun, and N. Vasconcelos, “Deep learning with low precision by half-wave gaussian quantization,”  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. [31]  G. Venkatesh, E. Nurvitadhi, and D. Marr, “Accelerating deep con- volutional networks using low-precision and sparsity,” in  2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp. 5406–5414, 2017.",
      "type": "sliding_window_shuffled",
      "tokens": 123,
      "augmented": true
    },
    {
      "text": "2861–2865, 2017. [31]  G. Venkatesh, E. Nurvitadhi, and D. Marr, “Accelerating deep con- volutional networks using low-precision and sparsity,” in  2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp. [32]  I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, “Quantized neural networks: Training neural networks with low precision weights and activations,”  J. Mach.",
      "type": "sliding_window_shuffled",
      "tokens": 136,
      "augmented": true
    },
    {
      "text": "Learn. Res. [32]  I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, “Quantized neural networks: Training neural networks with low precision weights and activations,”  J. Mach.",
      "type": "sliding_window_shuffled",
      "tokens": 64,
      "augmented": true
    },
    {
      "text": "18, pp. 6869–6898, Jan. 2017. [33]  M. Courbariaux, Y. Bengio, and J.-P. David, “Binaryconnect: Training deep neural networks with binary weights during propagations,” in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 , NIPS’15, pp.",
      "type": "sliding_window_shuffled",
      "tokens": 85,
      "augmented": true
    },
    {
      "text": "[33]  M. Courbariaux, Y. Bengio, and J.-P. David, “Binaryconnect: Training deep neural networks with binary weights during propagations,” in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 , NIPS’15, pp. 3123–3131, 2015. [34]  M. Alwani, H. Chen, M. Ferdman, and P. Milder, “Fused-layer cnn accelerators,” in  2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 138,
      "augmented": true
    },
    {
      "text": "1–12, 2016. [34]  M. Alwani, H. Chen, M. Ferdman, and P. Milder, “Fused-layer cnn accelerators,” in  2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp. [35]  M. D. Lam, E. E. Rothberg, and M. E. Wolf, “The cache performance and optimizations of blocked algorithms,” in  Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp.",
      "type": "sliding_window_shuffled",
      "tokens": 127,
      "augmented": true
    },
    {
      "text": "[36]  K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Spendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,” in  2017 22nd Asia and South Paciﬁc Design Automation Conference (ASP-DAC) , pp. [35]  M. D. Lam, E. E. Rothberg, and M. E. Wolf, “The cache performance and optimizations of blocked algorithms,” in  Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp. 63–74, 1991.",
      "type": "sliding_window_shuffled",
      "tokens": 167,
      "augmented": true
    },
    {
      "text": "[36]  K. Ma, X. Li, S. R. Srinivasa, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Spendthrift: Machine learning based resource and frequency scaling for ambient energy harvesting nonvolatile processors,” in  2017 22nd Asia and South Paciﬁc Design Automation Conference (ASP-DAC) , pp. 678–683, 2017. [37]  N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A.",
      "type": "sliding_window_shuffled",
      "tokens": 199,
      "augmented": true
    },
    {
      "text": "[37]  N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A. Wood, “The Gem5 Simulator,” SIGARCH Comput. Archit.",
      "type": "sliding_window_shuffled",
      "tokens": 114,
      "augmented": true
    },
    {
      "text": "[38]  Synopsis, “HSPICE.” https://www.synopsys.com/veriﬁcation/ams- veriﬁcation/hspice.html/. 39, pp. 1–7, Aug. 2011.",
      "type": "sliding_window_shuffled",
      "tokens": 54,
      "augmented": true
    },
    {
      "text": "2.4.1–2.4.4, 2017. [39]  H. Lv, X. Xu, P. Yuan, D. Dong, T. Gong, J. Liu, Z. Yu, P. Huang, K. Zhang, C. Huo, C. Chen, Y. Xie, Q. Luo, S. Long, Q. Liu, J. Kang, D. Yang, S. Yin, S. Chiu, and M. Liu, “BEOL based RRAM with one extra-mask for low cost, highly reliable embedded application in 28 nm node and beyond,” in  2017 IEEE International Electron Devices Meeting (IEDM) , pp. [38]  Synopsis, “HSPICE.” https://www.synopsys.com/veriﬁcation/ams- veriﬁcation/hspice.html/.",
      "type": "sliding_window_shuffled",
      "tokens": 202,
      "augmented": true
    },
    {
      "text": "[40]  X. Dong, C. Xu, Y. Xie, and N. P. Jouppi, “NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory,” IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) , vol. 31, pp. 2.4.1–2.4.4, 2017.",
      "type": "sliding_window_shuffled",
      "tokens": 94,
      "augmented": true
    },
    {
      "text": "994–1007, July 2012. [41]  R. Wang and Z. Xu, “A pedestrian and vehicle rapid identiﬁcation model based on convolutional neural network,” in  Proceedings of the 7th International Conference on Internet Multimedia Computing and Service , ICIMCS ’15, pp. 31, pp.",
      "type": "sliding_window_shuffled",
      "tokens": 71,
      "augmented": true
    },
    {
      "text": "[42]  S. A. Dawwd and B. S. Mahmood, “A reconﬁgurable interconnected ﬁlter for face recognition based on convolution neural network,” in  2009 4th International Design and Test Workshop (IDT) , pp. [41]  R. Wang and Z. Xu, “A pedestrian and vehicle rapid identiﬁcation model based on convolutional neural network,” in  Proceedings of the 7th International Conference on Internet Multimedia Computing and Service , ICIMCS ’15, pp. 32:1–32:4, 2015.",
      "type": "sliding_window_shuffled",
      "tokens": 126,
      "augmented": true
    },
    {
      "text": "1–6, 2009. [42]  S. A. Dawwd and B. S. Mahmood, “A reconﬁgurable interconnected ﬁlter for face recognition based on convolution neural network,” in  2009 4th International Design and Test Workshop (IDT) , pp. [43]  Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,”  Proceedings of the IEEE , vol.",
      "type": "sliding_window_shuffled",
      "tokens": 113,
      "augmented": true
    },
    {
      "text": "[43]  Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,”  Proceedings of the IEEE , vol. 86, pp. 2278–2324, Nov 1998.",
      "type": "sliding_window_shuffled",
      "tokens": 64,
      "augmented": true
    },
    {
      "text": "2278–2324, Nov 1998. [44]  H. Lin, M. Hsu, and W. Chen, “Human hand gesture recognition using a convolution neural network,” in  2014 IEEE International Conference on Automation Science and Engineering (CASE) , pp. 1038–1043, 2014.",
      "type": "sliding_window_shuffled",
      "tokens": 66,
      "augmented": true
    },
    {
      "text": "670–675, 2015. [45]  K. Ma, X. Li, Y. Liu, J. Sampson, Y. Xie, and V. Narayanan, “Dynamic machine learning based matching of nonvolatile processor microarchi- tecture to harvested energy proﬁle,” in  2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD) , pp. 1038–1043, 2014.",
      "type": "sliding_window_shuffled",
      "tokens": 106,
      "augmented": true
    }
  ]
}