=== ORIGINAL PDF: 2505.21923v1_FALCON_An_ML_Framework_for_Fully_Automated_Layout-.pdf ===\n\nRaw text length: 84746 characters\nCleaned text length: 84040 characters\nNumber of segments: 54\n\n=== CLEANED TEXT ===\n\nFALCON: An ML Framework for Fully Automated Layout-Constrained Analog Circuit Design Asal Mehradfar1 Xuzhe Zhao2 Yilun Huang2 Emir Ceyani1 Yankai Yang2 Shihao Han2 Hamidreza Aghasi2 Salman Avestimehr1 1University of Southern California 2University of California, Irvine Abstract Designing analog circuits from performance specifications is a complex, multi-stage process encompassing topology selection, parameter inference, and layout feasibil- ity. We introduce FALCON, a unified machine learning framework that enables fully automated, specification-driven analog circuit synthesis through topology se- lection and layout-constrained optimization. Given a target performance, FALCON first selects an appropriate circuit topology using a performance-driven classifier guided by human design heuristics. Next, it employs a custom, edge-centric graph neural network trained to map circuit topology and parameters to performance, enabling gradient-based parameter inference through the learned forward model. This inference is guided by a differentiable layout cost, derived from analytical equations capturing parasitic and frequency-dependent effects, and constrained by design rules. We train and evaluate FALCON on a large-scale custom dataset of 1M analog mm-wave circuits, generated and simulated using Cadence Spectre across 20 expert-designed topologies. Through this evaluation, FALCON demonstrates 99 accuracy in topology inference, 10 relative error in performance prediction, and efficient layout-aware design that completes in under 1 second per instance. Together, these results position FALCON as a practical and extensible foundation model for end-to-end analog circuit design automation. Our code and dataset are publicly available at 1 Introduction Analog radio frequency (RF) and millimeter-wave (mm-wave) circuits are essential to modern electronics, powering critical applications in signal processing [1], wireless communication [2], sensing [3], radar [4], and wireless power transfer systems [5]. Despite their importance, the design of analog circuits remains largely manual, iterative, and dependent on expert heuristics [6 8]. This inefficiency stems from several challenges: a vast and continuous design space that is difficult to explore systematically; tightly coupled performance metrics (e.g. gain, noise, bandwidth, and power) that create complex trade-offs; and physical and layout-dependent interactions that complicate design decisions. As demand grows for customized, high-performance analog blocks, this slow, expert-driven design cycle has become a critical bottleneck. While machine learning (ML) has revolutionized digital design automation, analog and RF circuits still lack scalable frameworks for automating the full pipeline from specification to layout. While recent ML approaches have made progress in analog circuit design, they typically target isolated sub-tasks such as topology generation or component sizing [9, 10] at the schematic level, without addressing the full synthesis pipeline. Many efforts assume fixed topologies [11 14], limiting adaptability to new specifications or circuit families. Optimization strategies often rely on black-box methods that do not scale well to large, continuous design spaces [15]. Some methods predict Preprint. Under review. arXiv:2505.21923v1 [cs.LG] 28 May 2025 Figure 1: Our AI-based circuit design pipeline. Given a target performance specification, FALCON first selects a suitable topology, then generates design parameters through layout-aware gradient-based reasoning with GNN model. Then, the synthesized circuit is validated using Cadence simulations. performance metrics directly from netlists [16], but do not support inverse design, i.e., generating circuit parameters from target specifications. Furthermore, layout awareness is typically handled as a separate post-processing step [17], missing the opportunity to guide optimization with layout constraints. Finally, many available benchmarks are built on symbolic or synthetic simulations [18], lacking the fidelity and realism of the process of commercial grade design flows. As a result, current ML pipelines do not allow fully generalizable, layout-aware, and end-to-end analog circuit design. We propose FALCON (Fully Automated Layout-Constrained analOg circuit desigN), a scalable and modular machine learning framework for end-to-end analog and RF circuit design. Built on a dataset of over one million Cadence-simulated circuits, FALCON comprises three core components (Figure 1): (1) a lightweight multilayer perceptron (MLP) selects the most appropriate topology given a target performance specification; (2) a generalizable graph neural network (GNN) maps circuit topology and element-level parameters to performance metrics, operating on a native graph representation derived from Cadence netlists; and (3) gradient-based optimization over the forward GNN model recovers design parameters that meet the target specification, guided by a differentiable layout-aware loss that encodes parasitic effects and physical constraints. Notably, the GNN model in FALCON generalizes effectively to unseen topologies, enabling inverse design across diverse circuit families, even in low-data regimes, with optional fine-tuning for improved accuracy. By integrating layout modeling directly into the optimization process, FALCON unifies schematic and physical considerations within a single differentiable learning framework. Our main contributions are as follows: We construct a large-scale analog RF circuit dataset comprising over one million Cadence- simulated datapoints across 20 expert-designed topologies and five circuit types. We introduce a native netlist-to-graph representation that preserves both structural and parametric fidelity, enabling accurate learning over physical circuit topologies. We develop a modular ML framework for end-to-end inverse design, incorporating performance-driven topology selection and layout-aware gradient-based optimization, with a differentiable loss that enforces area constraints, design-rule compliance, and frequency- dependent modeling of passive components. We design a generalizable GNN capable of accurate performance prediction and parameter inference across both seen and unseen topologies, with optional fine-tuning. 2 Related Work While recent ML-based approaches have advanced analog and RF circuit design, they typically target isolated stages of the design flow such as topology generation, parameter sizing, or schematic-level performance prediction without supporting unified, end-to-end synthesis. FALCON bridges this gap by jointly addressing aforementioned stages within a single framework. Topology generation methods aim to select or synthesize candidate circuit structures [9, 19, 20], often using discrete optimization or generative models to explore the circuit graph space. However, these approaches typically target low-frequency or simplified designs [9] and may produce physically invalid or non-manufacturable topologies. In contrast, FALCON leverages a curated set of netlists, ensuring manufacturable validity and eliminating the need to rediscover fundamental circuit structures. Parameter sizing and performance prediction have been explored through various learning paradigms. Reinforcement learning [10, 21] and Bayesian optimization [15, 22] optimize parameters 2 via trial-and-error, often requiring large simulation budgets. Supervised learning methods [23, 24, 11] regress parameter values from performance targets under fixed topologies. Graph-based models [16] incorporate topology-aware representations to predict performance metrics from netlists. However, these approaches focus on forward prediction or black-box sizing and do not support inverse design across varied topologies. In contrast, FALCON unifies forward modeling and parameter inference in a single differentiable architecture that generalizes to unseen netlists. Layout-aware sizing and parasitic modeling have been explored to mitigate schematic-to-layout mismatch. Parasitic-aware methods [25] integrate pre-trained parasitic estimators into Bayesian optimization loops for fixed schematics. While effective for estimation, these approaches rely on time-consuming black-box search and lack inverse design capabilities. Other methods, such as ALIGN [26] and LayoutCopilot [27], generate layouts from fully sized netlists using ML-based constraint extraction or scripted interactions, but assume fixed parameters and do not support co- optimization or differentiable inverse design. In contrast, FALCON embeds layout objectives directly into the learning loss, enabling joint optimization of sizing and layout without relying on external parasitic models. For mm-wave circuits, our layout-aware loss captures frequency-sensitive constraints via simplified models that implicitly reflect DRC rules, EM coupling, and performance- critical factors such as quality factor and self-resonance frequency. Datasets for analog design are often limited to symbolic SPICE simulations or small-scale testbeds that do not reflect real-world design flows. AnalogGym [18] and AutoCkt [13] rely on synthetic circuits and symbolic simulators, lacking the process fidelity, noise characteristics, and layout- dependent behavior of foundry-calibrated flows. In contrast, FALCON is trained on a large-scale dataset constructed from over one million Cadence-simulated circuits across 20 topologies and five circuit categories, offering a substantially more realistic foundation for ML-driven analog design. To the best of our knowledge, FALCON is the first framework to unify topology selection, parameter inference, and layout-aware optimization in a single end-to-end pipeline, validated at scale using industrial-grade Cadence simulations for mm-wave analog circuits. 3 A Large-Scale Dataset and Inverse Design Problem Formulation 3.1 Dataset Overview We construct a large-scale dataset of analog and RF circuits simulated using industry-grade Cadence tools [28] with a 45nm CMOS process design kit (PDK). The dataset spans five widely used mm-wave circuit types for wireless applications [29, 30]: low-noise amplifiers (LNAs) [31 34], mixers [35 38], power amplifiers (PAs) [39 43], voltage amplifiers (VAs) [44 48], and voltage-controlled oscillators (VCOs) [49 53]. Each circuit type is instantiated in four distinct topologies, resulting in a total of 20 expert-designed architectures. For each topology, expert-designed schematics were implemented in Cadence Virtuoso, and key design parameters were manually identified based on their functional relevance. Parameter ranges were specified by domain experts and systematically swept using Cadence ADE XL, enabling parallelized Spectre simulations across the design space. For each configuration, performance metrics such as gain, bandwidth, and oscillation frequency were extracted and recorded. Each datapoint therefore includes the full parameter vector, the corresponding Cadence netlist, and the simulated performance metrics. The resulting dataset comprises over one million datapoints, capturing a wide range of circuit behaviors and design trade-offs across diverse topologies. This large-scale, high-fidelity dataset forms the foundation for training and evaluating our inverse design pipeline. 3.2 Graph-Based Circuit Representation To enable flexible and topology-agnostic learning, we represent each analog circuit as a graph extracted from its corresponding Cadence netlist. Nodes correspond to voltage nets (i.e., electrical connection points), and edges represent circuit elements such as transistors, resistors, capacitors, or sources. Multi-terminal devices such as transistors and baluns are decomposed into multiple edges, and multiple components may connect the same node pair, resulting in heterogeneous, multi-edged graphs that preserve structural and functional diversity. 3 Recent works such as DICE [54] have explored transistor-level circuit-to-graph conversions for self-supervised learning, highlighting the challenges of faithfully capturing device structure and connectivity. In contrast, our approach maintains a native representation aligned with foundry- compatible netlists. Rather than flattening or reinterpreting device abstractions, we preserve symbolic parameters, multi-edge connections, and device-specific edge decomposition directly from the schematic source, enabling scalable learning across diverse analog circuit families. To support learning over such structured graphs, each edge is annotated with a rich set of attributes: (i) a categorical device type, specifying the component and connected terminal pair (e.g., NMOS drain gate, resistor); (ii) numeric attributes, such as channel length or port resistance, fixed by the schematic; (iii) parametric attributes, defined symbolically in the netlist (e.g., W1, R3) and resolved numerically during preprocessing; (iv) one-hot categorical features, such as source type (DC, AC, or none); and (v) computational attributes, such as diffusion areas (Ad, As) derived from sizing. This rule-based graph construction generalizes across circuit families without task-specific customization. Graphs in the FALCON dataset range from 4 40 nodes and 7 70 edges, reflecting the variability of practical analog designs. 3.3 Inverse Design Problem Definition In analog and RF circuit design, the traditional modeling process involves selecting a topology T and parameter vector x, then evaluating circuit behavior via simulation to obtain performance metrics y f(T, x). This forward workflow depends heavily on designer intuition, manual tuning, and exhaustive parameter sweeps. Engineers typically simulate many candidate (T, x) pairs and select the one that best satisfies the target specification a slow, costly, and unguided process. In contrast, our goal is to perform inverse design: given a target performance specification ytarget, we aim to directly infer a topology and parameter configuration (T, x) such that f(T, x) ytarget, without enumerating the full design space. This inverse problem is ill-posed and the search space is constrained by both device-level rules and layout-aware objectives. Formally, the task is to find the optimal topology T T and the optimal parameters x Rp such that f(T , x ) ytarget where f : T Rp Rd the true performance function implemented by expensive Cadence simulations. In practice, f is nonlinear and non-invertible, making direct inversion intractable. FALCON addresses this challenge through a modular, three-stage pipeline: Stage 1: Topology Selection. We frame topology selection as a classification problem over a curated set of K candidate topologies {T1, . . . , TK}. Given a target specification ytarget, a lightweight MLP selects the topology T T most likely to satisfy it, reducing the need for exhaustive search. Stage 2: Performance Prediction. Given a topology T and parameter vector x, we train a GNN fθ to predict the corresponding performance ˆy fθ(T, x). This model emulates the forward behavior of the simulator f, learning a continuous approximation of circuit performance across both seen and unseen topologies. By capturing the topology-conditioned mapping from parameters to performance, fθ serves as a differentiable surrogate that enables gradient-based inference in the next stage. Stage 3: Layout-Aware Gradient Reasoning. Given ytarget and a selected topology T , we infer a parameter vector x by minimizing a loss over the learned forward model fθ. Specifically, we solve: x arg min x Lperf(fθ(T , x), ytarget) λ Llayout(x), (1) where Lperf measures prediction error, and Llayout encodes differentiable layout-related constraints such as estimated area and soft design-rule penalties. Optimization is performed via gradient descent, allowing layout constraints to guide the search through a physically realistic parameter space. 4 Stage 1: Performance-Driven Topology Selection Task Setup. We formulate topology selection as a supervised classification task over a fixed library of 20 expert-designed circuit topologies T {T1, T2, . . . , T20}. Rather than generating netlists from scratch which often leads to invalid or impractical circuits we select from a vetted set of designer-verified topologies. This ensures that all candidates are functionally correct, layout-feasible, and manufacturable. While expanding the topology set requires retraining, our lightweight MLP classifier enables rapid updates, making the approach scalable. This formulation also aligns with practical design workflows, where quickly identifying a viable initial topology is critical. 4 Figure 2: In Stage 1, an MLP classifier selects the most suitable circuit topology from a library of human-designed netlists, conditioned on the target performance specification. Table 1: Classification performance on topology selection. Metric Score ( ) Accuracy 99.57 Balanced Accuracy 99.33 Macro Precision 99.27 Macro Recall 99.33 Macro F1 99.30 Micro F1 99.57 Each datapoint is represented by a 16-dimensional performance vector of key analog RF metrics1. We normalize features using z-scores computed from the training set. Missing metrics (e.g., oscillation frequency for amplifiers) are imputed with zeros, yielding zero-centered, fixed-length vectors that retain task-relevant variation. Dataset splits are stratified to preserve class balance across training, validation, and test sets. We assume each target vector is realizable by at least one topology in T , though the library can be extended with new designs. Model Architecture and Training. We train a 5-layer MLP with hidden size 256 and ReLU activations for this problem. The model takes the normalized performance vector ytarget R16 as input and outputs a probability distribution over 20 candidate topologies. The predicted topology is selected as T arg maxTk T MLP(ytarget)k. We train the model using a cross-entropy loss and the Adam optimizer [55], with a batch size of 256. An overview of this process is shown in Figure 2. Evaluation. We begin by assessing the quality of the input representation used for topology classifi- cation. Normalized performance vectors encode rich semantic information about circuit behavior. To validate this, we project them into a two-dimensional t-SNE space [56] (Figure 3(a)). The re- sulting clusters align closely with topology labels, indicating that performance specifications reflect underlying schematic structure and are effective inputs for supervised classification. We assess classification performance using accuracy, balanced accuracy, macro precision, macro recall, macro F1, and micro F1 scores on the test set. As summarized in Table 1, the classifier achieves an overall accuracy of 99.57 , with macro F1 of 99.30 and balanced accuracy of 99.33 , demon- strating strong generalization across all 20 circuit topologies. Micro F1 (identical to accuracy in the multiclass setting) reaches 99.57 , while macro metrics averaged equally across classes highlight robustness to class imbalance. These trends are reinforced by the per-class accuracy plot in Figure 3(c), where most topologies reach 100 accuracy. The confusion matrix in Figure 3(b) visualizes only the misclassified instances, as most classes achieve perfect accuracy. The few observed errors are primarily concentrated among the two voltage amplifier topologies common-gate (CGVA) and common-source (CSVA). These circuits operate near the gain-bandwidth limit of the transistor, and when the main amplifier transistor size is held constant, performance metrics such as power consumption, gain, and bandwidth can converge across these architectures. This occasional overlap in the performance space introduces ambiguity in classification for a small subset of instances. For other circuit categories, no significant confusion is expected or observed. These results validate our hypothesis that performance vectors contain sufficient semantic structure for accurate, scalable topology classification. 5 Stage 2: Generalizable Forward Modeling for Performance Prediction Task Setup. The goal of Stage 2 is to learn a differentiable approximation of the circuit simulator that maps a topology T and parameter vector x to a performance prediction ˆy fθ(T, x), where ˆy R16. Unlike black-box simulators, this learned forward model enables efficient performance estimation and supports gradient-based parameter inference in Stage 3. The model is trained to generalize across circuit families and can be reused on unseen topologies with minimal fine-tuning. 1DC power consumption (DCP), voltage gain (VGain), power gain (PGain), conversion gain (CGain), S11, S22, noise figure (NF), bandwidth (BW), oscillation frequency (OscF), tuning range (TR), output power (OutP), PSAT, drain efficiency (DE), power-added efficiency (PAE), phase noise (PN), voltage swing (VSwg). 5 (a) t-SNE of performance vectors CGLNA DLNA DBPMixer SBPMixer CGVA CSVA CVA IFVCO RVCO Predicted Topology CGLNA DLNA DBPMixer SBPMixer CGVA CSVA CVA IFVCO RVCO True Topology 99.31 0.69 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.14 98.86 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.95 0.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 99.98 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 95.01 4.99 0.00 0.00 0.00 0.00 0.00 0.00 0.00 5.57 93.85 0.58 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.77 0.23 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 99.93 0 20 40 60 80 100 Percentage ( ) (b) Confusion matrix (errors only) CGLNA CLNA CSLNA DLNA DBAMixer DBPMixer SBAMixer SBPMixer ClassBPA ClassEPA DohPA DPA CGVA CSVA CVA SFVA IFVCO CCVCO ColVCO RVCO 0 20 40 60 80 100 Accuracy ( ) 99.3 100.0 100.0 98.9 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 95.0 93.9 100.0 100.0 99.8 100.0 100.0 99.9 (c) Per-class accuracy across circuit topologies Figure 3: Topology selection results. (a) Performance vectors form well-separated clusters in t-SNE space, showing that circuit functionality is semantically predictive of topology. (b) Misclassifications primarily occur among voltage amplifier variants with overlapping gain-bandwidth tradeoffs. (c) Per-class test accuracy exceeds 93 across all 20 circuit topologies.2 Each datapoint consists of a graph-structured Cadence netlist annotated with resolved parameter values and the corresponding performance metrics. We frame the learning task as a supervised regression problem. Since not all performance metrics apply to every topology (e.g., oscillation frequency is undefined for amplifiers), we train the model using a masked mean squared error loss: Lmasked 1 P i mi d X i 1 mi (ˆyi yi)2, (2) where mi 1 if the i-th metric is defined for the current sample, and zero otherwise. Model Architecture and Training. Each cir- cuit is represented as an undirected multi- edge graph with voltage nets as nodes and cir- cuit components as edges. All circuit parame- ters both fixed and sweepable are assigned to edges, along with categorical device types and one-hot encoded indicators. For each edge (u, v), these attributes are concatenated to form a unified feature vector xuv. The feature set is consistent within each component type but varies across types (e.g., NMOS vs. inductor), reflect- ing the structure defined in Section 3.2. Figure 4: In Stage 2, a custom edge-centric GNN maps an undirected multi-edge graph constructed from the circuit netlist to a performance vector. 2The 20 circuit topologies listed in the same order as the numerical labels in Figure 3(a) are: CGLNA (Common Gate), CLNA (Cascode), CSLNA (Common Source), DLNA (Differential), DBAMixer (Double- Balanced Active), DBPMixer (Double-Balanced Passive), SBAMixer (Single-Balanced Active), SBPMixer (Single-Balanced Passive), ClassBPA (Class-B), ClassEPA (Class-E), DohPA (Doherty), DPA (Differential), CGVA (Common Gate), CSVA (Common Source), CVA (Cascode), SFVA (Source Follower), IFVCO (Inductive- Feedback), CCVCO (Cross-Coupled), ColVCO (Colpitts), RVCO (Ring). 6 To account for component heterogeneity, we apply type-specific MLP encoders ϕ(t) enc to each edge feature vector, producing initial embeddings e(0) uv ϕ(t) enc(xuv), where t is the component type. These embeddings are updated via a 4-layer edge-centric message-passing GNN with shared weights. At each layer ℓ, for each node u, we first compute the node hidden state using the edge embeddings of all neighbors of the node u, N(u). Then, for each edge (u, v) in the circuit graph, we compute the edge embedding at the next layer ℓ 1 is using the edge embedding e(ℓ) uv and the hidden node states forming the edge (u, v) at the current layer ℓas follows: h(ℓ) u X w N(u) ϕMSG(e(ℓ) wu), e(ℓ 1) uv ϕUPD(e(ℓ) uv, h(ℓ) u , h(ℓ) v ), where ϕMSG, ϕUPD are the message and update parameters of message-passing GNN and h(ℓ) u , h(ℓ) v are the hidden states for the nodes forming the edge (u, v) respectively. After message passing [57], final edge embeddings e(L) uv are aggregated to form a graph-level representation zgraph P (u,v) e(L) uv , which is decoded by a fully connected MLP (hidden size 256) to predict the 16-dimensional performance vector ˆy R16. An overview of this GNN-based forward prediction pipeline is shown in Figure 4. To stabilize training, physical parameters are rescaled by their expected units (e.g. resistance by 103), and performance targets are normalized to z-scores using training statistics. We train the model using the Adam optimizer (learning rate 10 3, batch size 256) and a ReduceLROnPlateau scheduler. Xavier uniform initialization is used for all layers, and early stopping is based on validation loss. We adopt the same splits as in Section 4 for consistency in evaluation. Evaluation. We evaluate the accuracy of the GNN forward model fθ on a test set drawn from 19 of the 20 topologies. One topology RVCO is entirely excluded from training, validation, and test splits to assess generalization to unseen architectures. Prediction quality is measured using standard re- gression metrics: coefficient of determination (R2), root mean squared error (RMSE), and mean ab- solute error (MAE), computed independently for each of the 16 performance metrics. We also report the mean relative error per metric, computed as the average across all test samples where each metric is defined. As summarized in Table 2, the model achieves high accuracy across all dimensions, with an average R2 of 0.971. 0 5 10 15 20 25 30 35 Relative Error ( ) 0.000 0.025 0.050 0.075 0.100 0.125 0.150 0.175 Density Mean: 3.65 Median: 1.69 Mode: 1.38 Figure 5: Distribution of relative error ( ) across the test set for the GNN forward model. Plot is trimmed at the 95th percentile. To evaluate end-to-end prediction accuracy at the sample level, we compute the mean relative error per instance, defined as the average relative error across all valid (non-masked) performance metrics for each test sample. Figure 5 shows the distribution of this quantity across the test set (trimmed at the 95th percentile to reduce the impact of outliers). The distribution is sharply concentrated, indicating that most predictions closely match their corresponding target vectors. Without percentile trimming, the overall mean relative error across the full test set is 9.14 . Table 2: Prediction accuracy of the forward GNN on all 16 circuit performance metrics. Metric DCP VGain PGain CGain S11 S22 NF BW OscF TR OutP PSAT DE PAE PN VSwg Unit mW dB dB dB dB dB dB GHz GHz GHz dBm dBm dBc Hz mV R² 1.0 1.0 0.99 1.0 0.92 1.0 0.99 0.98 0.97 0.83 0.97 1.0 1.0 1.0 0.89 1.0 RMSE 0.289 0.107 0.536 0.84 1.517 0.206 0.534 0.969 0.721 0.293 0.908 0.1 0.232 0.144 2.541 0.07 MAE 0.212 0.077 0.208 0.188 0.554 0.116 0.202 0.369 0.181 0.097 0.232 0.069 0.168 0.104 1.167 0.046 Rel. Err. 11.5 2.7 18.6 7.8 11.4 1.8 4.5 5.6 0.6 6.5 4.4 4.5 4.5 11.7 1.3 1.48 6 Stage 3: Layout-Aware Parameter Inference via Gradient Reasoning Task Setup. Given a target performance vector ytarget and a selected topology T , the goal of Stage 3 is to recover a parameter vector x that minimizes a total loss combining performance error and 7 Figure 6: In Stage 3, gradient reasoning iteratively updates parameters to minimize a loss combining performance error and layout cost, computed via a differentiable analytical model. layout-aware penalties, using the learned forward model fθ from Stage 2. This formulation enables instance-wise inverse design without requiring circuit-level simulation. To initialize optimization, we perturb domain-specific scale factors (e.g., 10 12 for capacitors) to sample a plausible starting point x0. Parameters are iteratively updated via gradient descent, guided by both functional and physical objectives. Topology-specific constants are held fixed, and parameter values are clipped to remain within valid domain bounds throughout the process. Loss Function. The total loss follows the structure defined in Eqn 1, jointly minimizing performance mismatch and layout cost: Ltotal Lperf λarea Llayout g(Lperf), (3) where Lperf is the masked mean squared error (see Eqn 2) between predicted and target performance vectors, and Llayout is a normalized area penalty derived from analytical layout equations. To prioritize functionality, layout loss is softly gated by: g(Lperf) 1 σ (γ(Lperf τ)) , which attenuates layout penalties when performance error exceeds a threshold τ, encouraging the model to first achieve functionality before optimizing for layout compactness. We set τ 0.05, γ 50, and normalize layout area by 1 mm2 to stabilize gradients. The layout weight λarea 0.02 is chosen empirically to balance performance accuracy and physical realism without dominating the loss. This gated formulation supports manufacturable parameter recovery and reflects the broader paradigm of physics-informed learning [58]. Differentiable Layout Modeling. In mm-wave analog design, layout is not a downstream concern but a critical determinant of circuit performance particularly for passive components. Substrate coupling, proximity effects, and DRC-imposed geometries directly affect key metrics such as reso- nance frequency, quality factor, and impedance matching. To incorporate these effects, we introduce a differentiable layout model that computes total physical area analytically from circuit parameters. This enables layout constraints to directly guide parameter optimization during inverse design. By minimizing the layout area in distributed mm-wave circuits [59], unwanted signal loss [60] is reduced, the self-resonance frequency of passives can increase [61], and phase and amplitude mismatches across signal paths [62] can be reduced. The layout model is deterministic and non-learned. It estimates area contributions from passive components capacitors, inductors, and resistors as these dominate total area and exhibit layout- sensitive behavior. Active devices (e.g., MOSFETs) are excluded since their geometries are fixed by the PDK and are negligible [63]. For a given parameter vector x, the total layout loss is computed as: Llayout(x) X e Epassive Ae(x), where Epassive is the set of passive elements, and Ae(x) is the area of the created layout for the passive component based on analytical physics-based equations. The area of element e is estimated based on its 2D dimensions (e.g., A W L for resistors and capacitors). This area is normalized and used as a differentiable penalty in the optimization objective (see Eqn 3). Gradient Reasoning Procedure. Starting from the initialized parameter vector x, we iteratively update parameters via gradient reasoning. At each step, the frozen forward model fθ predicts the 8 (a) Designed DohPA schematic (b) Layout of designed DohPA Figure 7: Stage 3 results for a synthesized DohPA. The schematic (a) reflects optimized parameters to meet the target specification. The layout (b) is DRC-compliant and physically realizable. The final design achieves a mean relative error of 5.4 compared to the target performance. performance ˆy fθ(T, x), and the total loss Ltotal is evaluated. Gradients are backpropagated with respect to x, and updates are applied using the Adam optimizer. Optimization proceeds for a fixed number of steps, with early stopping triggered if the loss fails to improve over a predefined window. To handle varying circuit difficulty and initialization quality, we employ an adaptive learning rate strategy. Each instance begins with a moderate learning rate (10 6), refined during optimization via a ReduceLROnPlateau scheduler. If the solution fails to meet thresholds on performance error or layout area, optimization restarts with a more exploratory learning rate. This adjustment balances exploration and fine-tuning, enabling rapid convergence to physically valid solutions, typically within milliseconds to under one second per instance. An overview is shown in Figure 6. Evaluation. We evaluate Stage 3 on 9,500 test instances (500 per topology) using our gradient-based optimization pipeline. A design is considered converged if it meets both: (i) a predicted mean relative error below 10 , and (ii) a layout area under a topology-specific bound 1 mm2 for most circuits and 1.5 mm2 for DLNA, DohPA, and ClassBPA. The 10 error threshold reflects the forward model s 9 average prediction error (Section 5). A design is deemed successful if its final Cadence- simulated performance deviates from the target by less than 20 , confirming real-world viability. Our method achieves a success rate of 78.5 and a mean relative error of 17.7 across converged designs, with average inference time under 1 second on a MacBook CPU. Notably, success rate is coupled with the convergence threshold: tighter error bounds yield higher accuracy but require more iterations critical for large-scale design tasks. To illustrate the effectiveness of our pipeline, Figure 7 shows a representative result for the DohPA topology: the synthesized schematic is shown on the left, and the corresponding layout is on the right. These results confirm that the recovered parameters are both functionally accurate and physically realizable. Together, they demonstrate that FALCON enables layout-aware inverse design within a single differentiable pipeline a capability not supported by existing analog design frameworks. 7 Conclusion and Future Work We presented FALCON, a modular framework for end-to-end analog and RF circuit design that unifies topology selection, performance prediction, and layout-aware parameter optimization. Trained on over one million Cadence-simulated mm-wave circuits, FALCON combines a lightweight MLP, a generalizable GNN, and differentiable gradient reasoning to synthesize circuits from specification to layout-constrained parameters. FALCON achieves 99 topology selection accuracy, 10 predic- tion error, and efficient inverse design all within sub-second inference. The GNN forward model generalizes to unseen topologies with minimal fine-tuning, supporting broad practical deployment. In future work, we aim to expand the topology library and support hierarchical macroblocks for scalable design beyond the cell level. We also plan to extend the layout-aware optimization with learned parasitic models and EM-informed constraints for more accurate post-layout estimation. Fi- nally, integrating reinforcement learning or diffusion-based models for generative topology synthesis represents a promising step toward general-purpose analog design automation. 9 Acknowledgments We thank Andrea Villasenor and Tanqin He for their assistance with circuit data generation. We also thank Mohammad Shahab Sepehri for his insightful discussions and thoughtful feedback during the development of this work. References [1] Vilem Kledrowetz, Roman Prokop, Lukas Fujcik, and Jiri Haze. A fully differential analog front-end for signal processing from emg sensor in 28 nm fdsoi technology. Sensors, 23(7), 2023. [2] Wei Hong, Zhi Hao Jiang, Chao Yu, Debin Hou, Haiming Wang, Chong Guo, Yun Hu, Le Kuai, Yingrui Yu, Zhengbo Jiang, Zhe Chen, Jixin Chen, Zhiqiang Yu, Jianfeng Zhai, Nianzu Zhang, Ling Tian, Fan Wu, Guangqi Yang, Zhang-Cheng Hao, and Jian Yi Zhou. The role of millimeter-wave technologies in 5g 6g wireless communications. IEEE Journal of Microwaves, 1(1):101 122, 2021. [3] Yingying Chi, Haifeng Zhang, Zhe Zheng, Rui Liu, Lei Qiao, and Wenpeng Cui. Analog front-end circuit design for wireless sensor system-on-chip. In 2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC), volume 1, pages 38 42, 2020. [4] Xuyang Liu, Md. Hedayatullah Maktoomi, Mahdi Alesheikh, Payam Heydari, and Hamidreza Aghasi. A cmos 49 63-ghz phase-locked stepped-chirp fmcw radar transceiver. IEEE Journal of Solid-State Circuits, pages 1 15, 2025. [5] Med Nariman, Farid Shirinfar, Anna Papió Toda, Sudhakar Pamarti, Ahmadreza Rofougaran, and Franco De Flaviis. A compact 60-ghz wireless power transfer system. IEEE Transactions on Microwave Theory and Techniques, 64(8):2664 2677, 2016. [6] Phillip E Allen and Douglas R Holberg. CMOS analog circuit design. Elsevier, 2011. [7] Willy M. C. Sansen. analog design essentials. SpringerLink, 2011. [8] Shady A Abdelaal, Ahmed Hussein, and Hassan Mostafa. A bayesian optimization framework for analog circuits optimization. In 2020 15th International Conference on Computer Engineering and Systems (ICCES), pages 1 4. IEEE, 2020. [9] Zehao Dong, Weidong Cao, Muhan Zhang, Dacheng Tao, Yixin Chen, and Xuan Zhang. CktGNN: Circuit graph neural network for electronic design automation. In The Eleventh International Conference on Learning Representations, 2023. [10] Hanrui Wang, Kuan Wang, Jiacheng Yang, Linxiao Shen, Nan Sun, Hae-Seung Lee, and Song Han. Gcn-rl circuit designer: Transferable transistor sizing with graph neural networks and reinforcement learning. In 2020 57th ACM IEEE Design Automation Conference (DAC), pages 1 6, 2020. [11] Dmitrii Krylov, Pooya Khajeh, Junhan Ouyang, Thomas Reeves, Tongkai Liu, Hiba Ajmal, Hamidreza Aghasi, and Roy Fox. Learning to design analog circuits to meet threshold specifications. In Proceedings of the 40th International Conference on Machine Learning, ICML 23. JMLR.org, 2023. [12] Hanrui Wang, Jiacheng Yang, Hae-Seung Lee, and Song Han. Learning to design circuits. arXiv preprint arXiv:1812.02734, 2018. [13] Keertana Settaluri, Ameer Haj-Ali, Qijing Huang, Kourosh Hakhamaneshi, and Borivoje Nikolic. Autockt: deep reinforcement learning of analog circuit designs. In Proceedings of the 23rd Conference on Design, Automation and Test in Europe, DATE 20, page 490 495, San Jose, CA, USA, 2020. EDA Consortium. [14] Yaguang Li, Yishuang Lin, Meghna Madhusudan, Arvind Sharma, Sachin Sapatnekar, Ramesh Harjani, and Jiang Hu. A circuit attention network-based actor-critic learning approach to robust analog transistor sizing. In 2021 ACM IEEE 3rd Workshop on Machine Learning for CAD (MLCAD), pages 1 6, 2021. [15] Wenlong Lyu, Pan Xue, Fan Yang, Changhao Yan, Zhiliang Hong, Xuan Zeng, and Dian Zhou. An efficient bayesian optimization approach for automated optimization of analog circuits. IEEE Transactions on Circuits and Systems I: Regular Papers, 65(6):1954 1967, 2017. [16] Kourosh Hakhamaneshi, Marcel Nassar, Mariano Phielipp, Pieter Abbeel, and Vladimir Stojanovic. Pretraining graph neural networks for few-shot analog circuit modeling and design. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 42(7):2163 2173, 2022. 10 [17] Morteza Fayazi, Morteza Tavakoli Taba, Ehsan Afshari, and Ronald Dreslinski. Angel: Fully-automated analog circuit generator using a neural network assisted semi-supervised learning approach. IEEE Transac- tions on Circuits and Systems I: Regular Papers, 2023. [18] Jintao Li, Haochang Zhi, Ruiyu Lyu, Wangzhen Li, Zhaori Bi, Keren Zhu, Yanhan Zeng, Weiwei Shan, Changhao Yan, Fan Yang, Yun Li, and Xuan Zeng. Analoggym: An open and practical testing suite for analog circuit synthesis. In International Conference on Computer Aided Design, 2024. [19] Chen-Chia Chang, Yikang Shen, Shaoze Fan, Jing Li, Shun Zhang, Ningyuan Cao, Yiran Chen, and Xin Zhang. Lamagic: Language-model-based topology generation for analog integrated circuits. arXiv preprint arXiv:2407.18269, 2024. [20] Yao Lai, Sungyoung Lee, Guojin Chen, Souradip Poddar, Mengkang Hu, David Z Pan, and Ping Luo. Analogcoder: Analog circuit design via training-free code generation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 379 387, 2025. [21] Weidong Cao, Mouhacine Benosman, Xuan Zhang, and Rui Ma. Domain knowledge-based automated analog circuit design with deep reinforcement learning. arXiv preprint arXiv:2202.13185, 2022. [22] Ahmet Faruk Budak, Miguel Gandara, Wei Shi, David Z. Pan, Nan Sun, and Bo Liu. An efficient analog circuit sizing method based on machine learning assisted global optimization. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 41(5):1209 1221, 2022. [23] Asal Mehradfar, Xuzhe Zhao, Yue Niu, Sara Babakniya, Mahdi Alesheikh, Hamidreza Aghasi, and Salman Avestimehr. AICircuit: A Multi-Level Dataset and Benchmark for AI-Driven Analog Integrated Circuit Design. Machine Learning and the Physical Sciences Workshop NeurIPS, 2024. [24] Asal Mehradfar, Xuzhe Zhao, Yue Niu, Sara Babakniya, Mahdi Alesheikh, Hamidreza Aghasi, and Salman Avestimehr. Supervised learning for analog and rf circuit design: Benchmarks and comparative insights. arXiv preprint arXiv:2501.11839, 2025. [25] Mingjie Liu, Walker J. Turner, George F. Kokai, Brucek Khailany, David Z. Pan, and Haoxing Ren. Parasitic-aware analog circuit sizing with graph neural networks and bayesian optimization. In 2021 Design, Automation Test in Europe Conference Exhibition (DATE), pages 1372 1377, 2021. [26] Tonmoy Dhar, Kishor Kunal, Yaguang Li, Meghna Madhusudan, Jitesh Poojary, Arvind K Sharma, Wenbin Xu, Steven M Burns, Ramesh Harjani, Jiang Hu, et al. Align: A system for automating analog layout. IEEE Design Test, 38(2):8 18, 2020. [27] Bingyang Liu, Haoyi Zhang, Xiaohan Gao, Zichen Kong, Xiyuan Tang, Yibo Lin, Runsheng Wang, and Ru Huang. Layoutcopilot: An llm-powered multi-agent collaborative framework for interactive analog layout design. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2025. [28] Antonio J Lopez Martin. Cadence design environment. New Mexico State University, Tutorial paper, 35, 2002. [29] Sorin Voinigescu. High-frequency integrated circuits. Cambridge University Press, 2013. [30] Behzad Razavi. RF microelectronics, volume 2. Prentice hall New York, 2012. [31] Thomas H. Lee. The Design of CMOS Radio-Frequency Integrated Circuits. Cambridge University Press, 2nd edition, 2004. [32] John R. Long and Michael A. Copeland. The design of low-noise cmos rf amplifiers. IEEE Journal of Solid-State Circuits, 32(2):292 302, 1997. [33] Ali M. Niknejad. mm-Wave Silicon Technology: 60 GHz and Beyond. Springer, 2008. [34] Xiaohua Fan, Heng Zhang, and Edgar SÁnchez-Sinencio. A noise reduction and linearity improvement technique for a differential cascode lna. IEEE Journal of Solid-State Circuits, 43(3):588 599, 2008. [35] B. Henderson and E. Camargo. Microwave Mixer Technology and Applications. Microwave RF. Artech House, 2013. [36] B. Gilbert. A precise four-quadrant multiplier with subnanosecond response. IEEE Journal of Solid-State Circuits, 3(4):365 373, 1968. [37] Krenar Komoni, Sameer Sonkusale, and Geoff Dawe. Fundamental performance limits and scaling of a cmos passive double-balanced mixer. In 2008 Joint 6th International IEEE Northeast Workshop on Circuits and Systems and TAISA Conference, pages 297 300, 2008. 11 [38] S. Chehrazi, R. Bagheri, and A.A. Abidi. Noise in passive fet mixers: a simple physical model. In Proceedings of the IEEE 2004 Custom Integrated Circuits Conference (IEEE Cat. No.04CH37571), pages 375 378, 2004. [39] Hua Wang, Peter M. Asbeck, and Christian Fager. Millimeter-wave power amplifier integrated circuits for high dynamic range signals. IEEE Journal of Microwaves, 1(1):299 316, 2021. [40] M.K. Kazimierczuk. RF Power Amplifiers. Wiley, 2014. [41] F.H. Raab, P. Asbeck, S. Cripps, P.B. Kenington, Z.B. Popovic, N. Pothecary, J.F. Sevic, and N.O. Sokal. Power amplifiers and transmitters for rf and microwave. IEEE Transactions on Microwave Theory and Techniques, 50(3):814 826, 2002. [42] Narek Rostomyan, Mustafa Özen, and Peter Asbeck. 28 ghz doherty power amplifier in cmos soi with 28 IEEE Microwave and Wireless Components Letters, 28(5):446 448, 2018. [43] Morteza Abbasi, Torgil Kjellberg, Anton de Graauw, Edwin van der Heijden, Raf Roovers, and Herbert Zirath. A broadband differential cascode power amplifier in 45 nm cmos for high-speed 60 ghz system-on- chip. In 2010 IEEE Radio Frequency Integrated Circuits Symposium, pages 533 536, 2010. [44] Behzad Razavi. Design of Analog CMOS Integrated Circuits. McGraw-Hill Education, 2016. [45] S. Karthikeyan, S. Mortezapour, A. Tammineedi, and E.K.F. Lee. Low-voltage analog circuit design based on biased inverting opamp configuration. IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing, 47(3):176 184, 2000. [46] Tae Wook Kim. A common-gate amplifier with transconductance nonlinearity cancellation and its high- frequency analysis using the volterra series. IEEE Transactions on Microwave Theory and Techniques, 57 (6):1461 1469, 2009. [47] T. Lehmann and M. Cassia. 1-v power supply cmos cascode amplifier. IEEE Journal of Solid-State Circuits, 36(7):1082 1086, 2001. [48] H.-J. Song and C.-K. Kim. An mos four-quadrant analog multiplier using simple two-input squaring circuits with source followers. IEEE Journal of Solid-State Circuits, 25(3):841 848, 1990. [49] N. R. Sivaraaj and K. K. Abdul Majeed. A comparative study of ring vco and lc-vco: Design, performance analysis, and future trends. IEEE Access, 11:127987 128017, 2023. [50] Cao Wan, Taotao Xu, Xiang Yi, and Quan Xue. A current-reused vco with inductive-transformer feedback technique. IEEE Transactions on Microwave Theory and Techniques, 70(5):2680 2689, 2022. [51] Tuan Thanh Ta, Suguru Kameda, Tadashi Takagi, and Kazuo Tsubouchi. A 5ghz band low noise and wide tuning range si-cmos vco. In 2009 IEEE Radio Frequency Integrated Circuits Symposium, pages 571 574, 2009. [52] R. Aparicio and A. Hajimiri. A noise-shifting differential colpitts vco. IEEE Journal of Solid-State Circuits, 37(12):1728 1736, 2002. [53] Shruti Suman, K. G. Sharma, and P. K. Ghosh. Analysis and design of current starved ring vco. In 2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT), pages 3222 3227, 2016. [54] Sungyoung Lee, Ziyi Wang, Seunggeun Kim, Taekyun Lee, and David Z Pan. Self-supervised graph contrastive pretraining for device-level integrated circuits. arXiv preprint arXiv:2502.08949, 2025. [55] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. [56] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(11), 2008. [57] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In International conference on machine learning, pages 1263 1272. PMLR, 2017. [58] Maziar Raissi, Paris Perdikaris, and George Em Karniadakis. Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations. arXiv preprint arXiv:1711.10561, 2017. 12 [59] A. Dounavis, R. Achar, and M.S. Nakhla. Efficient passive circuit models for distributed networks with frequency-dependent parameters. IEEE Transactions on Advanced Packaging, 23(3):382 392, 2000. [60] Shen Wang, M.A. de Rooij, W.G. Odendaal, J.D. van Wyk, and D. Boroyevich. Reduction of high- frequency conduction losses using a planar litz structure. IEEE Transactions on Power Electronics, 20(2): 261 267, 2005. [61] Tejinder Singh and Raafat R Mansour. Miniaturized 6-bit phase-change capacitor bank with improved self-resonance frequency and q. In 2022 52nd European Microwave Conference (EuMC), pages 572 575. IEEE, 2022. [62] Chenxi Zhao, Xing Zeng, Lin Zhang, Huihua Liu, Yiming Yu, Yunqiu Wu, and Kai Kang. A 37 40-ghz low-phase-imbalance cmos attenuator with tail-capacitor compensation technique. IEEE Transactions on Circuits and Systems I: Regular Papers, 67(10):3400 3409, 2020. [63] Michele Spasaro and Domenico Zito. Millimeter-wave integrated silicon devices: Active versus pas- sive the eternal struggle between good and evil. In 2019 International Semiconductor Conference (CAS), pages 11 20. IEEE, 2019. 13 A Qualitative Comparison with Prior Work To contextualize FALCON within the broader landscape of analog circuit design automation, we provide a qualitative comparison against representative prior works in Table 3. This comparison spans key capabilities including topology selection, parameter inference, performance prediction, layout awareness, and simulator fidelity. We additionally assess reproducibility via dataset and code availability, and introduce a new axis RF mm-wave support to highlight methods evaluated on high-frequency circuit blocks such as LNAs, mixers, and VCOs. Compared to existing approaches, FALCON is the only framework that unifies all these dimensions while maintaining foundry-grade fidelity and open-source accessibility. Definitions for each comparison axis are provided in Table 4. Table 3: Qualitative comparison of FALCON with prior works across key capabilities in analog circuit design automation. Method Topology Selection Parameter Inference Performance Prediction Layout Awareness Foundry Grade RF mm-Wave Public Dataset Public Code CktGNN [9] (SPICE) LaMAGIC [19] (SPICE) AnalogCoder [20] (SPICE) GCN-RL [10] (SPICE Cadence) Cao et al. [21] (SPICE Cadence) BO-SPGP [15] (Cadence) ESSAB [22] (Cadence) AICircuit [23, 24] (Cadence) Krylov et al. [11] (SPICE) Deep-GEN [16] (SPICE) Liu et al. [25] (SPICE Parasitic Model) ALIGN [26] (Cadence) LayoutCopilot [27] (Cadence) AnalogGym [18] (SPICE) AutoCkt [13] (Cadence) (incomplete) L2DC [12] (Cadence) CAN-RL [14] (Cadence) AnGeL. [17] (SPICE) FALCON (This work) (Cadence) Table 4: Definitions of each comparison axis in Table 3. Column Definition Topology Selection Does the method automatically select or predict circuit topology given a target specification? Parameter Inference Does the method infer element-level parameters (e.g., transistor sizes, component values) as part of design generation? Performance Prediction Can the method predict circuit performance metrics (e.g., gain, bandwidth, noise) from topology and parameters? Layout Awareness Is layout considered during optimization or training (e.g., via area constraints, parasitics, or layout-informed loss)? Dataset Fidelity Does the dataset reflect realistic circuit behavior (e.g., SPICE Cadence simulations, PDK models)? RF mm-Wave Is the method evaluated on at least one RF or mm-wave circuit type that reflects high-frequency design challenges? Public Dataset Is the dataset used in the work publicly released for reproducibility and benchmarking? Public Code Is the implementation code publicly available and documented for reproducibility? B Dataset Details and Performance Metric Definitions During dataset generation, each simulated circuit instance is annotated with a set of performance metrics that capture its functional characteristics. All simulations are performed at a fixed frequency of 30 GHz, ensuring consistency across circuit types and relevance to mm-wave design. A total of 16 metrics are defined across all circuits spanning gain, efficiency, impedance matching, noise, and frequency-domain behavior though the specific metrics used vary by topology. For example, phase noise is only applicable to oscillators. An overview of all performance metrics is provided in Table 5. B.1 Low-Noise Amplifiers (LNAs) Low-noise amplifiers (LNAs) are critical components in receiver front-ends, responsible for amplify- ing weak antenna signals while introducing minimal additional noise. Their performance directly influences downstream blocks such as mixers and analog-to-digital converters (ADCs), ultimately de- termining system-level fidelity [31]. To capture the architectural diversity of practical radio-frequency (RF) designs, we include four widely used LNA topologies in this study common-source LNA (CSLNA), common-gate LNA (CGLNA), cascode LNA (CLNA), and differential LNA (DLNA) as shown in Figure 8. 14 Table 5: Overview of 16 performance metrics used during dataset generation. Performance Name Description DC Power Consumption (DCP) Total power drawn from the DC supply indicating energy consumption of the circuit Voltage Gain (VGain) Ratio of output voltage amplitude to input voltage amplitude Power Gain (PGain) Ratio of output power to input power Conversion Gain (CGain) Ratio of output power at the desired frequency to input power at the original frequency S11 Input reflection coefficient indicating impedance matching at the input terminal S22 Output reflection coefficient indicating impedance matching at the output terminal Noise Figure (NF) Ratio of input signal-to-noise ratio to output signal-to-noise ratio Bandwidth (BW) Frequency span over which the circuit maintains specified performance characteristics Oscillation Frequency (OscF) Steady-state frequency at which the oscillator generates a periodic signal Tuning Range (TR) Range of achievable oscillation frequencies through variation of control voltages Output Power (OutP) Power delivered to the load PSAT Maximum output power level beyond which gain compression begins to occur Drain Efficiency (DE) Ratio of RF output power to DC power consumption. Power-Added Efficiency (PAE) Ratio of the difference between output power and input power to DC power consumption Phase Noise (PN) Measure of oscillator stability represented in the frequency domain at a specified offset Voltage Swing (VSwg) Maximum peak voltage level achievable at the output node The CSLNA is valued for its simplicity and favorable gain noise trade-off, especially when paired with inductive source degeneration [30]. The CGLNA, often used in ultra-wideband systems, enables broadband input matching but typically suffers from a higher noise figure [32]. The CLNA improves gain bandwidth product and reverse isolation, making it ideal for high-frequency, high-linearity applications [33]. The DLNA exploits circuit symmetry to enhance linearity and reject common-mode noise, and is commonly found in high-performance RF front-end designs [34]. The design parameters and performance metrics associated with these topologies are summarized in Table 6. (a) CSLNA (b) CGLNA (c) CLNA (d) DLNA Figure 8: Schematic diagrams of the four LNA topologies. Table 6: LNA topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) LNA CGLNA (0) 52k C1 [100 600] fF DCP (W) PGain (dB) S11 (dB) NF (dB) BW (Hz) C2 [50 300] fF Cb [250 750] fF Ld [80 580] pH Ls [0.5 5.5] nH WN [12 23] µm CLNA (1) 62k C1, C2 [50 250] fF Ld [140 300] pH Lg [0.4 2] nH Ls [50 250] pH WN1 [3 5] µm WN2 [7 9] µm CSLNA (2) 39k C [100 300] fF Lg [4 6] nH Ls [100 200] pH WN [2.5 4] µm Vgs [0.5 0.9] V DLNA (3) 92k C1 [100 190] fF C2 [130 220] fF Ld [100 250] pH Lg [600 900] pH Ls [50 80] pH WN1 [4 9.4] µm WN2 [5 14] µm 15 B.2 Mixers Mixers are fundamental nonlinear components in RF systems, responsible for frequency translation by combining two input signals to produce outputs at the sum and difference of their frequencies. This functionality is essential for transferring signals across frequency domains and is widely used in both transmission and reception paths [35]. To capture diverse mixer architectures, we implement four representative topologies in this work double-balanced active mixer (DBAMixer), double-balanced passive mixer (DBPMixer), single-balanced active mixer (SBAMixer), and single-balanced passive mixer (SBPMixer) as shown in Figure 9. The DBAMixer integrates amplification and differential switching to achieve conversion gain and high port-to-port isolation. Despite its elevated power consumption and design complexity, it is well suited for systems requiring robust performance over varying conditions [36]. The DBPMixer features a fully differential structure that suppresses signal leakage and improves isolation, at the cost of signal loss and a strong local oscillator drive requirement [37]. The SBAMixer includes an amplification stage preceding the switching core to enhance signal strength and reduce noise, offering a balanced performance trade-off with increased power consumption and limited spurious rejection [30]. The SBPMixer employs a minimalist switching structure to perform frequency translation without active gain, enabling low power operation in applications with relaxed performance demands [38]. The parameters and performance metrics for these mixer topologies are listed in Table 7. (a) DPAMixer (b) DBPMixer (c) SBAMixer (d) SBPMixer Figure 9: Schematic diagrams of the four Mixer topologies. Table 7: Mixer topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) Mixer DBAMixer (4) 42k C [1 10] pF DCP (W) CGain (dB) NF (dB) VSwg (V) R [1 10] kΩ WN1 [10 30] µm WN2 [5 25] µm DBPMixer (5) 42k C [100 500] fF R [100 600] Ω WN [10 30] µm SBAMixer (6) 52k C [1 15] pF R [0.7 2.1] kΩ WN1 [10 30] µm WN2 [10 20] µm Itail [3 10] mA SBPMixer (7) 44k C [1 30] pF R [1 30] kΩ WN [5 29.5] µm B.3 Power Amplifiers (PAs) Power amplifiers (PAs) are the most power-intensive components in radio-frequency (RF) systems and serve as the final interface between transceiver electronics and the antenna. Given their widespread use and the stringent demands of modern communication standards, PA design requires careful trade-offs across key performance metrics [39]. Based on the transistor operating mode, PAs are typically grouped into several canonical classes [40]. In this work, we implement four representative topologies Class-B PA (ClassBPA), Class-E PA (ClassEPA), Doherty PA (DohPA), and differential PA (DPA) as shown in Figure 10. 16 The ClassBPA employs complementary transistors to deliver high gain with moderate efficiency, making it suitable for linear amplification scenarios [41]. The ClassEPA uses a single transistor configured as a switch, paired with a matching network. By minimizing the overlap between drain voltage and current, this topology enables high-efficiency operation and improved robustness to component variation [30]. The DohPA combines main and peaking amplifiers using symmetric two-stack transistors, maintaining consistent gain and efficiency under varying power levels [42]. The DPA features a two-stage cascode structure designed to maximize gain and linearity, offering a favorable trade-off between output power and power consumption [43]. For this topology, we replace the transformer with a T-equivalent network to simplify modeling and training of the graph neural network. Parameter sweeps and performance metrics for these PAs are listed in Table 8. (a) ClassBPA (b) ClassEPA (c) DohPA (d) DPA Figure 10: Schematic diagrams of the four PA topologies. Table 8: PA topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) PA ClassBPA (8) 35k C [55 205] fF DCP (W) PGain (dB) S11 (dB) S22 (dB) PSAT (dBm) DE ( ) PAE ( ) L1 [1 1.4] nH L2 [1 8.5] pH R [1.5 4] kΩ WN [10 20] µm WP [3 8] µm ClassEPA (9) 46k C1 [100 200] fF C2 [500 700] fF L1 [100 300] pH L2 [100 150] pH WN [15 30] µm DohPA (10) 120k C1 [2 3] pF C2 [200 300] fF C3, C5 [100 200] fF C4 [300 400] fF L1, L5 [100 200] pH L2 [350 450] pH L3 [500 600] pH L4 [150 250] pH L6 [300 400] pH WN1, WN2 [6 13] µm DPA (11) 80k Lip [100 500] pH Lis [300 700] pH Lop [0.8 1.2] nH Los [400 800] pH Lm [50 250] pH WN1 [6 31] µm WN2 [10 35] µm 17 B.4 Voltage Amplifiers (VAs) Voltage amplifiers (VAs) are fundamental components in analog circuit design, responsible for increasing signal amplitude while preserving waveform integrity. Effective VA design requires balancing key performance metrics tailored to both RF and baseband operating conditions [44]. In this work, we implement four widely used VA topologies common-source VA (CSVA), common- gate VA (CGVA), cascode VA (CVA), and source follower VA (SFVA) as shown in Figure 11. The CSVA remains the most widely adopted configuration due to its structural simplicity and high voltage gain. It is frequently used as the first gain stage in various analog systems [45]. The CGVA is suitable for applications requiring low input impedance and wide bandwidth, such as impedance transformation or broadband input matching [46]. The CVA, which cascades a common-source stage with a common-gate transistor, improves the gain bandwidth product and enhances stability, making it ideal for applications demanding wide dynamic range and robust gain control [47]. The SFVA, also known as a common-drain amplifier, provides near-unity voltage gain and low output impedance, making it well suited for interstage buffering, load driving, and impedance bridging [48]. Parameter ranges and performance specifications for these VA topologies are listed in Table 9. (a) CSVA (b) CGVA (c) CVA (d) SFVA Figure 11: Schematic diagrams of the four VA topologies. Table 9: VA topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) VA CGVA (12) 33k C [0.1 1.5] pF DCP (W) VGain (dB) BW (Hz) R [0.1 1.5] kΩ WN1 [5 30] µm WN2 [5 10] µm CSVA (13) 21k R [0.7 1.5] kΩ WN [3 15] µm VDD [1 1.8] V Vgate [0.6 0.9] V CVA (14) 22k R [1 3] kΩ WN1, WN2 [1 10] µm WN3 [10 15] µm SFVA (15) 28k WN1 [40 60] µm WN2 [2 8] µm VDD [1.1 1.8] V Vgate [0.6 1.2] V Vb [0.5 0.9] V B.5 Voltage-Controlled Oscillators (VCOs) Voltage-controlled oscillators (VCOs) are essential building blocks in analog and RF systems, responsible for generating periodic waveforms with frequencies modulated by a control voltage. These circuits rely on amplification, feedback, and resonance to sustain stable oscillations. Owing to their wide tuning range, low power consumption, and ease of integration, VCOs are broadly used in systems such as phase-locked loops (PLLs), frequency synthesizers, and clock recovery circuits [49]. In this work, we implement four representative VCO topologies inductive-feedback VCO (IFVCO), cross-coupled VCO (CCVCO), Colpitts VCO (ColVCO), and ring VCO (RVCO) as shown in Figure 12. 18 The IFVCO employs an NMOS differential pair with an inductor-based feedback path to sustain oscillations. This topology provides favorable noise performance and compact layout, making it well suited for low-voltage, low-power designs [50]. The CCVCO achieves negative resistance through cross-coupling, enabling low phase noise and high integration density, and is widely adopted in frequency synthesizers and PLLs [51]. The ColVCO uses an LC tank and capacitive feedback to achieve high frequency stability and low phase noise, making it ideal for precision RF communication and instrumentation [52]. The RVCO consists of cascaded delay stages forming a feedback loop, offering low power consumption, wide tuning range, and minimal area footprint, though at the cost of higher phase noise. It is commonly used in on-chip clock generation and low-power sensor applications [53]. Design parameters and performance metrics for these VCO topologies are presented in Table 10. (a) IFVCO (b) CCVCO (c) ColVCO (d) RVCO Figure 12: Schematic diagrams of the four VCO topologies. Table 10: VCO topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) VCO IFVCO (16) 43k C1 [700 900] fF DCP (W) OscF (Hz) TR (Hz) OutP (dBm) PN (dBc Hz) C2 [50 250] fF L1 [400 600] pH L2 [500 700] pH WN, Wvar [5 9] µm CCVCO (17) 54k L [200 400] pH WN [10 35] µm Wvar [5 30] µm ColVCO (18) 90k C [80 140] fF L [250 350] pH WN [30 50] µm Wvar [5 15] µm Vb [0.7 1.2] V Itail [5 15] mA RVCO (19) 46k C [300 700] fF L1 [300 500] pH L2 [50 250] pH WN [20 40] µm Wvar [5 25] µm C Graph-Based Circuit Representation To enable GNN-based modeling of analog circuits, we represent each netlist as a directed multigraph where nodes correspond to electrical nets and edges encode circuit components such as transistors, capacitors, inductors, and voltage sources. Each edge is labeled with its component type and terminal role (e.g., gate, source, drain), and component-specific attributes are stored as edge features. For transistors, labels such as GS, DS, and DG denote source-to-gate, drain-to-source, and drain-to-gate connections, respectively. Figure 13 illustrates two representative graph structures extracted from our dataset: an IFVCO and a ClassBPA. The visual encoding highlights the diversity of components and connectivity patterns across topologies. Edges corresponding to the same component type share a common color for visual consistency and semantic clarity. These structured graphs serve as the primary input to our GNN pipeline for performance prediction and inverse design. 19 V2 V0 L5 C2 L4 C1 L1 L0 N3_DG N3_GS N3_DS N2_DS N2_DG N2_GS N0_DG L3 N0_DS N1_DG L2 N1_DS N1_GS C0 N0_GS GND VDD Vcont Vout- Vout net9 net7 net15 net8 Components nmos capacitor vsource inductor (a) IFVCO N0_DG R0 N0_GS R4 C0 N0_DS V0 P0_DS P0_GS L2 PORT0 P0_DG R3 C6 PORT1 L0 R5 C1 net7 VDD net2 GND net1 net4 net3 net5 Vin Components nmos pmos resistor capacitor vsource port inductor (b) ClassBPA Figure 13: Graph representations of two analog circuit topologies from our dataset: (a) IFVCO and (b) ClassBPA. Nodes represent electrical nets, and colored edges denote circuit components such as transistors, capacitors, inductors, and sources. Each component type is visually distinguished by color and labeled with its name and terminal role (e.g., N2_GS, V0). These graphs serve as input to our GNN-based performance modeling and inverse design pipeline. D Generalizing to Unseen Topologies via Fine-Tuning To assess the generalization ability of our pretrained GNN, we evaluate it on the held-out RVCO topology, which was entirely excluded from the Stage 2 training, validation, and test splits (see Section 5). Notably, the RVCO training partition used here matches that of the Stage 1 experiments (Section 4), enabling consistent cross-stage evaluation. We fine-tune the GNN by freezing all encoder and message-passing layers and updating only the final output head (output_mlp). Fine-tuning is performed on the RVCO training set, which contains approximately 30,000 instances, and completes in under 30 minutes on a MacBook CPU. Even in the zero-shot setting where the model has never seen RVCO topologies the pretrained GNN achieves a nontrivial mean relative error of 33.1 , highlighting its strong cross-topology generalization. Fine-tuning reduces this error to just 0.8 , demonstrat- ing that the structural and parametric priors learned during pretraining are highly transfer- able. Table 11 reports detailed performance across five key metrics, confirming that the pre- trained GNN can be rapidly adapted to novel circuit families with minimal supervision. Table 11: Fine-tuning results on the held-out RVCO topology. Only the output head is updated using RVCO samples. Metric DCP OscF TR OutP PN Unit W GHz GHz dBm dBc Hz R² 1.0 1.0 1.0 0.97 0.99 RMSE 0.725 0.244 0.022 0.098 0.792 MAE 0.576 0.19 0.018 0.078 0.477 Rel. Err. 0.85 0.62 1.4 0.69 0.56 E Layout Design and DRC Compliance E.1 Design Rule Enforcement in 45 nm CMOS We implemented FALCON using a 45 nm CMOS technology node, applying rigorous Design Rule Checking (DRC) at both the cell and full-chip layout levels. At the cell level, our parameterized layout generators enforced foundry-specific constraints, including minimum feature width and length, contact and via spacing, and metal enclosure rules. At the circuit level, we incorporated physical verification to mitigate interconnect coupling, IR drop, and layout-dependent parasitic mismatches factors that are especially critical in high-frequency and precision analog design. 20 DRC plays a vital role in ensuring that layouts comply with process design rules defined by the semiconductor foundry. Adhering to these rules ensures not only physical manufacturability but also electrical reliability. Violations may lead to fabrication failures, including yield degradation, electrical shorts or opens, electromigration-induced issues, and parasitic mismatches. Moreover, DRC compliance is essential for compatibility with downstream fabrication steps such as photomask generation, optical lithography, and chemical-mechanical planarization (CMP), safeguarding the yield and fidelity of the final IC. Circuit-Level Layout Guidelines. We enforced several topology-aware layout constraints during full-circuit integration to preserve signal integrity and robustness: Inductor-to-inductor spacing: 35.0 µm to mitigate mutual inductive coupling and magnetic interference. Guardring placement: Sensitive analog blocks are enclosed by N-well or deep N-well guardrings with spacing 5.0 µm to suppress substrate noise coupling. Differential pair symmetry: Differential signal paths are layout-matched to ensure L 0.5 µm, minimizing mismatch and preserving phase balance. DRC Constraints and Layer Definitions. Table 12 summarizes the DRC constraints applied to key analog components across relevant process layers. Table 13 provides the abbreviations used for metal, contact, and via layers in the 45 nm CMOS process. Table 12: Design rule constraints for key analog components in 45 nm CMOS. Component Layer Physical Constraint Symbol Value Unit MIM Capacitor (QT, LD, VV, OB) QT LD Minimum Cap Width WMIN 6.05 µm QT LD Maximum Cap Width WMAX 150.0 µm QT LD Cap Length L 6.0 µm VV VV Square Size VV_SIZE 4.0 µm VV VV Spacing VV_SPACE 2.0 µm VV VV to Edge Spacing VV_EDGE_MIN 1.0 µm Resistor (RX, CA, M1) RX Minimum Width WMIN 0.462 µm RX Maximum Width WMAX 5.0 µm RX Minimum Length LMIN 0.4 µm RX Maximum Length LMAX 5.0 µm CA Contact Size CA_SIZE 0.06 µm CA Contact Spacing CA_SPACE 0.10 µm CA CA to Edge Spacing CA_EDGE 0.11 µm Inductor (M3) M3 Minimum Width M3_W_MIN 2.0 µm M3 Maximum Width M3_W_MAX 20.0 µm M3 Minimum Spacing M3_S_MIN 2.0 µm Grid All Layers Minimum Grid Min_Grid 0.005 µm Table 13: Process layer abbreviations in the 45 nm CMOS design flow. Layer Name Description RX Resistor implant or diffusion layer used to define integrated resistor geometries. CA Contact layer forming vias between diffusion poly and the first metal layer (M1). M1 First metal layer, typically used for local interconnects and resistor terminals. M3 Third metal layer, used for wider routing tracks and planar inductor layouts. QT Top metal plate in MIM capacitor structures, providing the upper electrode. LD Lower metal plate in MIM capacitor structures, acting as the bottom electrode. VV Via layer connecting different metal layers, especially in capacitor and dense routing regions. OB Opening blocking layer used to define restricted zones, often to exclude metal or for CMP mask clarity. E.2 MIM Capacitor Capacitance Model The total capacitance CN of a metal-insulator-metal (MIM) capacitor is modeled as: CN Ca L W Cp 2 (L W) [fF] 21 (a) MIM capacitor layout (b) Resistor layout (c) Inductor layout Figure 14: Layout views of passive components. (a) MIM capacitor with metal-insulator-metal stack. (b) Resistor layout with matching geometry. (c) Spiral inductor with octagonal turns for optimized area and Q-factor. where L and W are the layout length and width in µm, Ca is the area capacitance density, and Cp is the fringing field contribution per unit length. This model includes both area and perimeter contributions to more accurately reflect layout-dependent capacitance in IC design (see Figure 14(a)). 1. Area Capacitance Term: Ca L W Physical Concept: This term represents the primary (parallel-plate) capacitance formed between the overlapping top and bottom metal layers. It arises from the uniform electric field across the dielectric. Layer Physics Explanation: L W corresponds to the overlap area of the plates. Ca 0.335 fF µm2 is the area capacitance density, derived from: Dielectric permittivity ε of the insulating material. Dielectric thickness d, with C ε d. 2. Perimeter (Fringing) Capacitance Term: Cp 2 (L W) Physical Concept: This term models fringing fields at the plate edges, contributing additional capacitance particularly relevant in small geometries. Layer Physics Explanation: 2 (L W) is the physical perimeter of the capacitor. Cp 0.11 fF µm accounts for the fringing field contribution per unit length. Summary: This composite model enables accurate estimation of MIM capacitance by capturing both parallel-plate and fringing effects. The constants Ca and Cp are typically calibrated using process-specific measurements or electromagnetic simulations. For a fixed capacitor length L 20 µm and width W [6.05, 150.0] µm, the layout-aware capaci- tance is approximated by: C 6.92 W 4.4 [fF] (4) The corresponding bounding area is estimated from the component s geometric envelope: Bounding_Area 22W 44 [µm2] (5) E.3 N Silicided Polysilicon Resistor Model The resistance of a layout-defined resistor implemented using the ndslires layer is modeled as: R Rs L W W 2Rend δ [Ω] Physical Concept: This structure uses heavily doped N polysilicon overlaid with a silicide layer to reduce resistance. Current flows laterally through the poly-silicide film (see Figure 14(b)), and resistance is shaped by the aspect ratio of the layout as well as process-dependent corrections. Layer Physics Explanation: 22 Rs 17.6 Ω (ohm per square) is the sheet resistance of the silicided poly layer. W 5.0 µm is the drawn width; W 0.048 µm accounts for process-induced width bias. L is the drawn resistor length. Rend 1 Ωmodels terminal resistance due to contact diffusion and current crowding. δ 0.917 Ωaccounts for residual layout-dependent parasitics. Summary: The empirical layout relation used in parameterized generation is: R 3.5007 L 2.917 [Ω] (6) This model is valid for L [0.4, 5.0] µm with fixed width W 5.0 µm. The estimated layout area based on bounding box dimensions is: Bounding_Area 5.2L 8.362 [µm2] (7) E.4 Octagon Spiral Inductor Model Physical Concept: Accurate modeling and layout optimization of planar spiral inductors are critical in analog circuit design. Inductor performance is highly sensitive to parasitic elements, achievable quality factor (Q), and layout constraints imposed by process design rules. To support accurate performance prediction and inform layout choices, we adopt a modified power-law model that expresses inductance as a function of key geometric parameters. The model is validated against empirical measurements and shows strong agreement with classical analytical formulations. Numerous classical formulations relate inductance to geometric factors such as the number of turns, average diameter, trace width, and inter-turn spacing. Among these, the compact closed-form expressions in RF Microelectronics textbook [30] are widely adopted for their balance of simplicity and accuracy. Building on this foundation, we adopt a reparameterized monomial model that better fits our empirical measurement data: L 2.454 10 4 D 1.21 out W 0.163 D2.836 avg S 0.049 [nH] Layer Physics Explanation: Dout 2(R W 2 ) is the outer diameter, Din 2(R W 2 ) is the inner diameter, Davg (Dout Din) 2 2R is the aver- age diameter, R is the radius in µm, W is the trace width in µm, S is the spacing in µm. Table 14: Measured inductance for one-turn in- ductors with fixed W 10 µm and S 0.0 µm R (µm) 30 40 50 60 L (nH) 0.123 0.170 0.220 0.276 This expression is calibrated using measured data from a series of one-turn inductors fabricated with varying radius (R), while keeping the trace width fixed at W 10 µm and spacing at S 0.0 µm. Table 14 summarizes the measured inductance values used for model fitting. Summary: With W and S fixed, inductance simplifies to: L 2.337 10 3 R1.164 [nH] (8) The bounding area is estimated by: Bounding_Area 4R2 108R 440 [µm2] (9) The performance of on-chip inductors is fundamentally influenced by layout-dependent factors such as trace width, metal thickness, and inter-turn spacing. Increasing the trace width (Wind) reduces 23 series resistance by enlarging the conductor s cross-sectional area, thereby improving the quality factor, Q ωL Rseries. However, wider traces also increase parasitic capacitance to adjacent turns and the substrate, which lowers the self-resonance frequency. Metal thickness (Hind) also plays a crucial role in minimizing ohmic losses. At high frequencies, current is confined near the conductor surface due to the skin effect. For copper at 25 GHz, the skin depth δ is approximately 0.41 µm; thus, using a metal layer thicker than 4δ (i.e., 1.6 µm) ensures efficient current flow. However, increasing thickness beyond this threshold yields diminishing returns in Q due to saturation in current penetration. Turn-to-turn spacing (S) affects both inductance and quality factor (Q). Tighter spacing enhances magnetic coupling, thereby increasing inductance density. However, it also intensifies capacitive coupling and dielectric losses particularly in modern CMOS processes with high-k inter-metal dielectrics which can degrade Q. Conversely, excessive spacing reduces inductance without providing a proportionate benefit in loss reduction. As a result, one-turn spiral inductors are commonly favored in RF design due to their low series resistance, minimized parasitics, and improved modeling predictability. These insights guided our design choices for layout-aware inductor implementation. To balance the competing demands of Q optimization, parasitic control, and DRC compliance, we implemented inductors using Metal 3 and set W 10 µm as the default trace width. This width offers a low- resistance path that enhances Q while maintaining manageable parasitic capacitance and sufficient pitch for lithographic reliability. Metal 3 was selected for its favorable trade-off between thickness and routing density it is thick enough to mitigate skin-effect losses at high frequencies while offering sufficient flexibility for compact layout integration. The implemented spiral inductor geometry is shown in Figure 14(c). Table 15 summarizes the DRC-compliant tuning ranges, estimated layout areas, and decomposition strategies for single-cell passive components in our layout library. Table 15: Single-cell passive component limits based on DRC and associated layout area costs. Component Tunable Variable Value Range Area Range Decomposition Rule Resistor Length L 4.32 20.42 Ω 10.44 34.36 µm2 Series if max, parallel if min Capacitor Width W 46.32 1042.4 fF 176 3344 µm2 Parallel if max, series if min Inductor Radius R 0.1 nH 5640 µm2 Continuous radius scaling E.5 Layout Examples of Synthesized Circuits To illustrate the correspondence between schematic and layout representations, we present two representative synthesized circuits: an IFVCO and a DLNA, shown in Figure 15 and Figure 16, respectively. In the IFVCO example, the inductor labeled L3 functions as an RF choke and is excluded from the on-chip layout due to its large area requirement. Instead, it is intended for off-chip implementation at the PCB level and connected to the die via wire bonding. This external connection is indicated by the yellow pad in Figure 15(b), which serves as the wire-bonding interface. Since the current stage of system lacks automated routing, all interconnects in the layout were manually drawn to ensure accurate correspondence with the schematic connectivity. These examples demonstrate that synthesized circuit parameters can be successfully translated into DRC-compliant, physically realizable layouts, bridging the gap between high-level optimization and tapeout-ready design. F Practical Considerations and Limitations F.1 Training and Inference Efficiency Although our codebase supports GPU acceleration, all experiments in this work excluding initial dataset generation were conducted entirely on a MacBook CPU. This highlights the efficiency and accessibility of the FALCON pipeline, which can be executed on modest hardware without 24 (a) Designed IFVCO schematic (b) Layout of designed IFVCO Figure 15: Stage 3 results for a synthesized IFVCO. The schematic (a) reflects optimized parameters to meet the target specification. The layout (b) is DRC-compliant and physically realizable. The final design achieves a mean relative error of 1.3 compared to the target performance. (a) Designed DLNA schematic (b) Layout of designed DLNA Figure 16: Stage 3 results for a synthesized DLNA. The schematic (a) reflects optimized parameters to meet the target specification. The layout (b) is DRC-compliant and physically realizable. The final design achieves a mean relative error of 5.0 compared to the target performance. specialized infrastructure. Our MLP and GNN models contain 207k and 1.4M trainable parameters, respectively, with memory footprints of just 831 KB and 5.6 MB. In Stage 1, the MLP classifier trains in approximately 30 minutes with a batch size of 256 and performs inference in the order of milliseconds per batch. Stage 2 s GNN model takes around 3 days to train on the full dataset using the same batch size and hardware. Fine-tuning on an unseen topology (e.g., RVCO) using 30,000 samples completes in under 30 minutes. In Stage 3, the pretrained GNN is used without retraining to perform layout-constrained parameter inference via gradient-based optimization. Inference is conducted one instance at a time (batch size 1), with typical runtimes under 1 second per circuit. Runtime varies based on the convergence threshold and circuit complexity but remains below 2 3 seconds in the worst case across the full test set. A solution is considered successful if the predicted performance meets the target within a specified relative error threshold. While tighter thresholds (e.g., 5 ) improve accuracy, they require more optimization steps particularly over large datasets. As a result, both success rate and inference time in Stage 3 are directly influenced by this tolerance, which can be tuned based on design fidelity requirements. 25 F.2 Limitations This work focuses on a representative set of 20 curated analog topologies spanning five circuit families. While this enables rigorous evaluation and benchmarking, extending support to arbitrary user-defined netlists is a natural next step. Notably, our GNN demonstrates strong generalization even to topologies not seen during training (e.g., RVCO), suggesting broad applicability within this space. All interconnect routing in the layout phase is currently performed manually, as the flow does not yet integrate a full analog router. This decision allows precise control over parasitic management and DRC compliance but limits scalability for more complex designs. Integration with automated layout tools can further streamline this process. We do not perform repeated training runs for each model configuration, as the pipeline is designed to be computationally efficient and executable on CPU-only hardware. Unlike benchmarking-focused pipelines, our flow incorporates analog simulation and layout-aware inference, both of which are costly to rerun at scale. Moreover, simulation and layout processes are deterministic, eliminating the need for result averaging over multiple random seeds. 26\n\n=== SEGMENTS ===\n\n--- Segment 1 ---\nFALCON: An ML Framework for Fully Automated Layout-Constrained Analog Circuit Design Asal Mehradfar1 Xuzhe Zhao2 Yilun Huang2 Emir Ceyani1 Yankai Yang2 Shihao Han2 Hamidreza Aghasi2 Salman Avestimehr1 1University of Southern California 2University of California, Irvine Abstract Designing analog circuits from performance specifications is a complex, multi-stage process encompassing topology selection, parameter inference, and layout feasibil- ity. We introduce FALCON, a unified machine learning framework that enables fully automated, specification-driven analog circuit synthesis through topology se- lection and layout-constrained optimization. Given a target performance, FALCON first selects an appropriate circuit topology using a performance-driven classifier guided by human design heuristics. Next, it employs a custom, edge-centric graph neural network trained to map circuit topology and parameters to performance, enabling gradient-based parameter inference through the learned forward model. This inference is guided by a differentiable layout cost, derived from analytical equations capturing parasitic and frequency-dependent effects, and constrained by design rules. We train and evaluate FALCON on a large-scale custom dataset of 1M analog mm-wave circuits, generated and simulated using Cadence Spectre across 20 expert-designed topologies. Through this evaluation, FALCON demonstrates 99 accuracy in topology inference, 10 relative error in performance prediction, and efficient layout-aware design that completes in under 1 second per instance. Together, these results position FALCON as a practical and extensible foundation model for end-to-end analog circuit design automation. Our code and dataset are publicly available at 1 Introduction Analog radio frequency (RF) and millimeter-wave (mm-wave) circuits are essential to modern electronics, powering critical applications in signal processing [1], wireless communication [2], sensing [3], radar [4], and wireless power transfer systems [5]. Despite their importance, the design of analog circuits remains largely manual, iterative, and dependent on expert heuristics [6 8]. This inefficiency stems from several challenges: a vast and continuous design space that is difficult to explore systematically; tightly coupled performance metrics (e.g. gain, noise, bandwidth, and power) that create complex trade-offs; and physical and layout-dependent interactions that complicate design decisions.\n\n--- Segment 2 ---\nThis inefficiency stems from several challenges: a vast and continuous design space that is difficult to explore systematically; tightly coupled performance metrics (e.g. gain, noise, bandwidth, and power) that create complex trade-offs; and physical and layout-dependent interactions that complicate design decisions. As demand grows for customized, high-performance analog blocks, this slow, expert-driven design cycle has become a critical bottleneck. While machine learning (ML) has revolutionized digital design automation, analog and RF circuits still lack scalable frameworks for automating the full pipeline from specification to layout. While recent ML approaches have made progress in analog circuit design, they typically target isolated sub-tasks such as topology generation or component sizing [9, 10] at the schematic level, without addressing the full synthesis pipeline. Many efforts assume fixed topologies [11 14], limiting adaptability to new specifications or circuit families. Optimization strategies often rely on black-box methods that do not scale well to large, continuous design spaces [15]. Some methods predict Preprint. Under review. arXiv:2505.21923v1 [cs.LG] 28 May 2025 Figure 1: Our AI-based circuit design pipeline. Given a target performance specification, FALCON first selects a suitable topology, then generates design parameters through layout-aware gradient-based reasoning with GNN model. Then, the synthesized circuit is validated using Cadence simulations. performance metrics directly from netlists [16], but do not support inverse design, i.e., generating circuit parameters from target specifications. Furthermore, layout awareness is typically handled as a separate post-processing step [17], missing the opportunity to guide optimization with layout constraints. Finally, many available benchmarks are built on symbolic or synthetic simulations [18], lacking the fidelity and realism of the process of commercial grade design flows. As a result, current ML pipelines do not allow fully generalizable, layout-aware, and end-to-end analog circuit design. We propose FALCON (Fully Automated Layout-Constrained analOg circuit desigN), a scalable and modular machine learning framework for end-to-end analog and RF circuit design.\n\n--- Segment 3 ---\nAs a result, current ML pipelines do not allow fully generalizable, layout-aware, and end-to-end analog circuit design. We propose FALCON (Fully Automated Layout-Constrained analOg circuit desigN), a scalable and modular machine learning framework for end-to-end analog and RF circuit design. Built on a dataset of over one million Cadence-simulated circuits, FALCON comprises three core components (Figure 1): (1) a lightweight multilayer perceptron (MLP) selects the most appropriate topology given a target performance specification; (2) a generalizable graph neural network (GNN) maps circuit topology and element-level parameters to performance metrics, operating on a native graph representation derived from Cadence netlists; and (3) gradient-based optimization over the forward GNN model recovers design parameters that meet the target specification, guided by a differentiable layout-aware loss that encodes parasitic effects and physical constraints. Notably, the GNN model in FALCON generalizes effectively to unseen topologies, enabling inverse design across diverse circuit families, even in low-data regimes, with optional fine-tuning for improved accuracy. By integrating layout modeling directly into the optimization process, FALCON unifies schematic and physical considerations within a single differentiable learning framework. Our main contributions are as follows: We construct a large-scale analog RF circuit dataset comprising over one million Cadence- simulated datapoints across 20 expert-designed topologies and five circuit types. We introduce a native netlist-to-graph representation that preserves both structural and parametric fidelity, enabling accurate learning over physical circuit topologies. We develop a modular ML framework for end-to-end inverse design, incorporating performance-driven topology selection and layout-aware gradient-based optimization, with a differentiable loss that enforces area constraints, design-rule compliance, and frequency- dependent modeling of passive components. We design a generalizable GNN capable of accurate performance prediction and parameter inference across both seen and unseen topologies, with optional fine-tuning. 2 Related Work While recent ML-based approaches have advanced analog and RF circuit design, they typically target isolated stages of the design flow such as topology generation, parameter sizing, or schematic-level performance prediction without supporting unified, end-to-end synthesis. FALCON bridges this gap by jointly addressing aforementioned stages within a single framework.\n\n--- Segment 4 ---\n2 Related Work While recent ML-based approaches have advanced analog and RF circuit design, they typically target isolated stages of the design flow such as topology generation, parameter sizing, or schematic-level performance prediction without supporting unified, end-to-end synthesis. FALCON bridges this gap by jointly addressing aforementioned stages within a single framework. Topology generation methods aim to select or synthesize candidate circuit structures [9, 19, 20], often using discrete optimization or generative models to explore the circuit graph space. However, these approaches typically target low-frequency or simplified designs [9] and may produce physically invalid or non-manufacturable topologies. In contrast, FALCON leverages a curated set of netlists, ensuring manufacturable validity and eliminating the need to rediscover fundamental circuit structures. Parameter sizing and performance prediction have been explored through various learning paradigms. Reinforcement learning [10, 21] and Bayesian optimization [15, 22] optimize parameters 2 via trial-and-error, often requiring large simulation budgets. Supervised learning methods [23, 24, 11] regress parameter values from performance targets under fixed topologies. Graph-based models [16] incorporate topology-aware representations to predict performance metrics from netlists. However, these approaches focus on forward prediction or black-box sizing and do not support inverse design across varied topologies. In contrast, FALCON unifies forward modeling and parameter inference in a single differentiable architecture that generalizes to unseen netlists. Layout-aware sizing and parasitic modeling have been explored to mitigate schematic-to-layout mismatch. Parasitic-aware methods [25] integrate pre-trained parasitic estimators into Bayesian optimization loops for fixed schematics. While effective for estimation, these approaches rely on time-consuming black-box search and lack inverse design capabilities. Other methods, such as ALIGN [26] and LayoutCopilot [27], generate layouts from fully sized netlists using ML-based constraint extraction or scripted interactions, but assume fixed parameters and do not support co- optimization or differentiable inverse design. In contrast, FALCON embeds layout objectives directly into the learning loss, enabling joint optimization of sizing and layout without relying on external parasitic models. For mm-wave circuits, our layout-aware loss captures frequency-sensitive constraints via simplified models that implicitly reflect DRC rules, EM coupling, and performance- critical factors such as quality factor and self-resonance frequency.\n\n--- Segment 5 ---\nIn contrast, FALCON embeds layout objectives directly into the learning loss, enabling joint optimization of sizing and layout without relying on external parasitic models. For mm-wave circuits, our layout-aware loss captures frequency-sensitive constraints via simplified models that implicitly reflect DRC rules, EM coupling, and performance- critical factors such as quality factor and self-resonance frequency. Datasets for analog design are often limited to symbolic SPICE simulations or small-scale testbeds that do not reflect real-world design flows. AnalogGym [18] and AutoCkt [13] rely on synthetic circuits and symbolic simulators, lacking the process fidelity, noise characteristics, and layout- dependent behavior of foundry-calibrated flows. In contrast, FALCON is trained on a large-scale dataset constructed from over one million Cadence-simulated circuits across 20 topologies and five circuit categories, offering a substantially more realistic foundation for ML-driven analog design. To the best of our knowledge, FALCON is the first framework to unify topology selection, parameter inference, and layout-aware optimization in a single end-to-end pipeline, validated at scale using industrial-grade Cadence simulations for mm-wave analog circuits. 3 A Large-Scale Dataset and Inverse Design Problem Formulation 3.1 Dataset Overview We construct a large-scale dataset of analog and RF circuits simulated using industry-grade Cadence tools [28] with a 45nm CMOS process design kit (PDK). The dataset spans five widely used mm-wave circuit types for wireless applications [29, 30]: low-noise amplifiers (LNAs) [31 34], mixers [35 38], power amplifiers (PAs) [39 43], voltage amplifiers (VAs) [44 48], and voltage-controlled oscillators (VCOs) [49 53]. Each circuit type is instantiated in four distinct topologies, resulting in a total of 20 expert-designed architectures. For each topology, expert-designed schematics were implemented in Cadence Virtuoso, and key design parameters were manually identified based on their functional relevance. Parameter ranges were specified by domain experts and systematically swept using Cadence ADE XL, enabling parallelized Spectre simulations across the design space. For each configuration, performance metrics such as gain, bandwidth, and oscillation frequency were extracted and recorded.\n\n--- Segment 6 ---\nParameter ranges were specified by domain experts and systematically swept using Cadence ADE XL, enabling parallelized Spectre simulations across the design space. For each configuration, performance metrics such as gain, bandwidth, and oscillation frequency were extracted and recorded. Each datapoint therefore includes the full parameter vector, the corresponding Cadence netlist, and the simulated performance metrics. The resulting dataset comprises over one million datapoints, capturing a wide range of circuit behaviors and design trade-offs across diverse topologies. This large-scale, high-fidelity dataset forms the foundation for training and evaluating our inverse design pipeline. 3.2 Graph-Based Circuit Representation To enable flexible and topology-agnostic learning, we represent each analog circuit as a graph extracted from its corresponding Cadence netlist. Nodes correspond to voltage nets (i.e., electrical connection points), and edges represent circuit elements such as transistors, resistors, capacitors, or sources. Multi-terminal devices such as transistors and baluns are decomposed into multiple edges, and multiple components may connect the same node pair, resulting in heterogeneous, multi-edged graphs that preserve structural and functional diversity. 3 Recent works such as DICE [54] have explored transistor-level circuit-to-graph conversions for self-supervised learning, highlighting the challenges of faithfully capturing device structure and connectivity. In contrast, our approach maintains a native representation aligned with foundry- compatible netlists. Rather than flattening or reinterpreting device abstractions, we preserve symbolic parameters, multi-edge connections, and device-specific edge decomposition directly from the schematic source, enabling scalable learning across diverse analog circuit families. To support learning over such structured graphs, each edge is annotated with a rich set of attributes: (i) a categorical device type, specifying the component and connected terminal pair (e.g., NMOS drain gate, resistor); (ii) numeric attributes, such as channel length or port resistance, fixed by the schematic; (iii) parametric attributes, defined symbolically in the netlist (e.g., W1, R3) and resolved numerically during preprocessing; (iv) one-hot categorical features, such as source type (DC, AC, or none); and (v) computational attributes, such as diffusion areas (Ad, As) derived from sizing. This rule-based graph construction generalizes across circuit families without task-specific customization.\n\n--- Segment 7 ---\nTo support learning over such structured graphs, each edge is annotated with a rich set of attributes: (i) a categorical device type, specifying the component and connected terminal pair (e.g., NMOS drain gate, resistor); (ii) numeric attributes, such as channel length or port resistance, fixed by the schematic; (iii) parametric attributes, defined symbolically in the netlist (e.g., W1, R3) and resolved numerically during preprocessing; (iv) one-hot categorical features, such as source type (DC, AC, or none); and (v) computational attributes, such as diffusion areas (Ad, As) derived from sizing. This rule-based graph construction generalizes across circuit families without task-specific customization. Graphs in the FALCON dataset range from 4 40 nodes and 7 70 edges, reflecting the variability of practical analog designs. 3.3 Inverse Design Problem Definition In analog and RF circuit design, the traditional modeling process involves selecting a topology T and parameter vector x, then evaluating circuit behavior via simulation to obtain performance metrics y f(T, x). This forward workflow depends heavily on designer intuition, manual tuning, and exhaustive parameter sweeps. Engineers typically simulate many candidate (T, x) pairs and select the one that best satisfies the target specification a slow, costly, and unguided process. In contrast, our goal is to perform inverse design: given a target performance specification ytarget, we aim to directly infer a topology and parameter configuration (T, x) such that f(T, x) ytarget, without enumerating the full design space. This inverse problem is ill-posed and the search space is constrained by both device-level rules and layout-aware objectives. Formally, the task is to find the optimal topology T T and the optimal parameters x Rp such that f(T , x ) ytarget where f : T Rp Rd the true performance function implemented by expensive Cadence simulations. In practice, f is nonlinear and non-invertible, making direct inversion intractable. FALCON addresses this challenge through a modular, three-stage pipeline: Stage 1: Topology Selection. We frame topology selection as a classification problem over a curated set of K candidate topologies {T1, . . . , TK}.\n\n--- Segment 8 ---\n. , TK}. Given a target specification ytarget, a lightweight MLP selects the topology T T most likely to satisfy it, reducing the need for exhaustive search. Stage 2: Performance Prediction. Given a topology T and parameter vector x, we train a GNN fθ to predict the corresponding performance ˆy fθ(T, x). This model emulates the forward behavior of the simulator f, learning a continuous approximation of circuit performance across both seen and unseen topologies. By capturing the topology-conditioned mapping from parameters to performance, fθ serves as a differentiable surrogate that enables gradient-based inference in the next stage. Stage 3: Layout-Aware Gradient Reasoning. Given ytarget and a selected topology T , we infer a parameter vector x by minimizing a loss over the learned forward model fθ. Specifically, we solve: x arg min x Lperf(fθ(T , x), ytarget) λ Llayout(x), (1) where Lperf measures prediction error, and Llayout encodes differentiable layout-related constraints such as estimated area and soft design-rule penalties. Optimization is performed via gradient descent, allowing layout constraints to guide the search through a physically realistic parameter space. 4 Stage 1: Performance-Driven Topology Selection Task Setup. We formulate topology selection as a supervised classification task over a fixed library of 20 expert-designed circuit topologies T {T1, T2, . . . , T20}. Rather than generating netlists from scratch which often leads to invalid or impractical circuits we select from a vetted set of designer-verified topologies. This ensures that all candidates are functionally correct, layout-feasible, and manufacturable. While expanding the topology set requires retraining, our lightweight MLP classifier enables rapid updates, making the approach scalable. This formulation also aligns with practical design workflows, where quickly identifying a viable initial topology is critical. 4 Figure 2: In Stage 1, an MLP classifier selects the most suitable circuit topology from a library of human-designed netlists, conditioned on the target performance specification. Table 1: Classification performance on topology selection.\n\n--- Segment 9 ---\n4 Figure 2: In Stage 1, an MLP classifier selects the most suitable circuit topology from a library of human-designed netlists, conditioned on the target performance specification. Table 1: Classification performance on topology selection. Metric Score ( ) Accuracy 99.57 Balanced Accuracy 99.33 Macro Precision 99.27 Macro Recall 99.33 Macro F1 99.30 Micro F1 99.57 Each datapoint is represented by a 16-dimensional performance vector of key analog RF metrics1. We normalize features using z-scores computed from the training set. Missing metrics (e.g., oscillation frequency for amplifiers) are imputed with zeros, yielding zero-centered, fixed-length vectors that retain task-relevant variation. Dataset splits are stratified to preserve class balance across training, validation, and test sets. We assume each target vector is realizable by at least one topology in T , though the library can be extended with new designs. Model Architecture and Training. We train a 5-layer MLP with hidden size 256 and ReLU activations for this problem. The model takes the normalized performance vector ytarget R16 as input and outputs a probability distribution over 20 candidate topologies. The predicted topology is selected as T arg maxTk T MLP(ytarget)k. We train the model using a cross-entropy loss and the Adam optimizer [55], with a batch size of 256. An overview of this process is shown in Figure 2. Evaluation. We begin by assessing the quality of the input representation used for topology classifi- cation. Normalized performance vectors encode rich semantic information about circuit behavior. To validate this, we project them into a two-dimensional t-SNE space [56] (Figure 3(a)). The re- sulting clusters align closely with topology labels, indicating that performance specifications reflect underlying schematic structure and are effective inputs for supervised classification. We assess classification performance using accuracy, balanced accuracy, macro precision, macro recall, macro F1, and micro F1 scores on the test set. As summarized in Table 1, the classifier achieves an overall accuracy of 99.57 , with macro F1 of 99.30 and balanced accuracy of 99.33 , demon- strating strong generalization across all 20 circuit topologies.\n\n--- Segment 10 ---\nWe assess classification performance using accuracy, balanced accuracy, macro precision, macro recall, macro F1, and micro F1 scores on the test set. As summarized in Table 1, the classifier achieves an overall accuracy of 99.57 , with macro F1 of 99.30 and balanced accuracy of 99.33 , demon- strating strong generalization across all 20 circuit topologies. Micro F1 (identical to accuracy in the multiclass setting) reaches 99.57 , while macro metrics averaged equally across classes highlight robustness to class imbalance. These trends are reinforced by the per-class accuracy plot in Figure 3(c), where most topologies reach 100 accuracy. The confusion matrix in Figure 3(b) visualizes only the misclassified instances, as most classes achieve perfect accuracy. The few observed errors are primarily concentrated among the two voltage amplifier topologies common-gate (CGVA) and common-source (CSVA). These circuits operate near the gain-bandwidth limit of the transistor, and when the main amplifier transistor size is held constant, performance metrics such as power consumption, gain, and bandwidth can converge across these architectures. This occasional overlap in the performance space introduces ambiguity in classification for a small subset of instances. For other circuit categories, no significant confusion is expected or observed. These results validate our hypothesis that performance vectors contain sufficient semantic structure for accurate, scalable topology classification. 5 Stage 2: Generalizable Forward Modeling for Performance Prediction Task Setup. The goal of Stage 2 is to learn a differentiable approximation of the circuit simulator that maps a topology T and parameter vector x to a performance prediction ˆy fθ(T, x), where ˆy R16. Unlike black-box simulators, this learned forward model enables efficient performance estimation and supports gradient-based parameter inference in Stage 3. The model is trained to generalize across circuit families and can be reused on unseen topologies with minimal fine-tuning. 1DC power consumption (DCP), voltage gain (VGain), power gain (PGain), conversion gain (CGain), S11, S22, noise figure (NF), bandwidth (BW), oscillation frequency (OscF), tuning range (TR), output power (OutP), PSAT, drain efficiency (DE), power-added efficiency (PAE), phase noise (PN), voltage swing (VSwg).\n\n--- Segment 11 ---\nThe model is trained to generalize across circuit families and can be reused on unseen topologies with minimal fine-tuning. 1DC power consumption (DCP), voltage gain (VGain), power gain (PGain), conversion gain (CGain), S11, S22, noise figure (NF), bandwidth (BW), oscillation frequency (OscF), tuning range (TR), output power (OutP), PSAT, drain efficiency (DE), power-added efficiency (PAE), phase noise (PN), voltage swing (VSwg). 5 (a) t-SNE of performance vectors CGLNA DLNA DBPMixer SBPMixer CGVA CSVA CVA IFVCO RVCO Predicted Topology CGLNA DLNA DBPMixer SBPMixer CGVA CSVA CVA IFVCO RVCO True Topology 99.31 0.69 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.14 98.86 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.95 0.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 99.98 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 95.01 4.99 0.00 0.00 0.00 0.00 0.00 0.00 0.00 5.57 93.85 0.58 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.77 0.23 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 99.93 0 20 40 60 80 100 Percentage ( ) (b) Confusion matrix (errors only) CGLNA CLNA CSLNA DLNA DBAMixer DBPMixer SBAMixer SBPMixer ClassBPA ClassEPA DohPA DPA CGVA CSVA CVA SFVA IFVCO CCVCO ColVCO RVCO 0 20 40 60 80 100 Accuracy ( ) 99.3 100.0 100.0 98.9 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 95.0 93.9 100.0 100.0 99.8 100.0 100.0 99.9 (c) Per-class accuracy across circuit topologies Figure 3: Topology selection results.\n\n--- Segment 12 ---\n1DC power consumption (DCP), voltage gain (VGain), power gain (PGain), conversion gain (CGain), S11, S22, noise figure (NF), bandwidth (BW), oscillation frequency (OscF), tuning range (TR), output power (OutP), PSAT, drain efficiency (DE), power-added efficiency (PAE), phase noise (PN), voltage swing (VSwg). 5 (a) t-SNE of performance vectors CGLNA DLNA DBPMixer SBPMixer CGVA CSVA CVA IFVCO RVCO Predicted Topology CGLNA DLNA DBPMixer SBPMixer CGVA CSVA CVA IFVCO RVCO True Topology 99.31 0.69 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.14 98.86 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.95 0.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 99.98 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 95.01 4.99 0.00 0.00 0.00 0.00 0.00 0.00 0.00 5.57 93.85 0.58 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.77 0.23 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 99.93 0 20 40 60 80 100 Percentage ( ) (b) Confusion matrix (errors only) CGLNA CLNA CSLNA DLNA DBAMixer DBPMixer SBAMixer SBPMixer ClassBPA ClassEPA DohPA DPA CGVA CSVA CVA SFVA IFVCO CCVCO ColVCO RVCO 0 20 40 60 80 100 Accuracy ( ) 99.3 100.0 100.0 98.9 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 95.0 93.9 100.0 100.0 99.8 100.0 100.0 99.9 (c) Per-class accuracy across circuit topologies Figure 3: Topology selection results. (a) Performance vectors form well-separated clusters in t-SNE space, showing that circuit functionality is semantically predictive of topology.\n\n--- Segment 13 ---\n5 (a) t-SNE of performance vectors CGLNA DLNA DBPMixer SBPMixer CGVA CSVA CVA IFVCO RVCO Predicted Topology CGLNA DLNA DBPMixer SBPMixer CGVA CSVA CVA IFVCO RVCO True Topology 99.31 0.69 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.14 98.86 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.95 0.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 99.98 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 95.01 4.99 0.00 0.00 0.00 0.00 0.00 0.00 0.00 5.57 93.85 0.58 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.77 0.23 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 99.93 0 20 40 60 80 100 Percentage ( ) (b) Confusion matrix (errors only) CGLNA CLNA CSLNA DLNA DBAMixer DBPMixer SBAMixer SBPMixer ClassBPA ClassEPA DohPA DPA CGVA CSVA CVA SFVA IFVCO CCVCO ColVCO RVCO 0 20 40 60 80 100 Accuracy ( ) 99.3 100.0 100.0 98.9 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 95.0 93.9 100.0 100.0 99.8 100.0 100.0 99.9 (c) Per-class accuracy across circuit topologies Figure 3: Topology selection results. (a) Performance vectors form well-separated clusters in t-SNE space, showing that circuit functionality is semantically predictive of topology. (b) Misclassifications primarily occur among voltage amplifier variants with overlapping gain-bandwidth tradeoffs.\n\n--- Segment 14 ---\n(a) Performance vectors form well-separated clusters in t-SNE space, showing that circuit functionality is semantically predictive of topology. (b) Misclassifications primarily occur among voltage amplifier variants with overlapping gain-bandwidth tradeoffs. (c) Per-class test accuracy exceeds 93 across all 20 circuit topologies.2 Each datapoint consists of a graph-structured Cadence netlist annotated with resolved parameter values and the corresponding performance metrics. We frame the learning task as a supervised regression problem. Since not all performance metrics apply to every topology (e.g., oscillation frequency is undefined for amplifiers), we train the model using a masked mean squared error loss: Lmasked 1 P i mi d X i 1 mi (ˆyi yi)2, (2) where mi 1 if the i-th metric is defined for the current sample, and zero otherwise. Model Architecture and Training. Each cir- cuit is represented as an undirected multi- edge graph with voltage nets as nodes and cir- cuit components as edges. All circuit parame- ters both fixed and sweepable are assigned to edges, along with categorical device types and one-hot encoded indicators. For each edge (u, v), these attributes are concatenated to form a unified feature vector xuv. The feature set is consistent within each component type but varies across types (e.g., NMOS vs. inductor), reflect- ing the structure defined in Section 3.2. Figure 4: In Stage 2, a custom edge-centric GNN maps an undirected multi-edge graph constructed from the circuit netlist to a performance vector.\n\n--- Segment 15 ---\nThe feature set is consistent within each component type but varies across types (e.g., NMOS vs. inductor), reflect- ing the structure defined in Section 3.2. Figure 4: In Stage 2, a custom edge-centric GNN maps an undirected multi-edge graph constructed from the circuit netlist to a performance vector. 2The 20 circuit topologies listed in the same order as the numerical labels in Figure 3(a) are: CGLNA (Common Gate), CLNA (Cascode), CSLNA (Common Source), DLNA (Differential), DBAMixer (Double- Balanced Active), DBPMixer (Double-Balanced Passive), SBAMixer (Single-Balanced Active), SBPMixer (Single-Balanced Passive), ClassBPA (Class-B), ClassEPA (Class-E), DohPA (Doherty), DPA (Differential), CGVA (Common Gate), CSVA (Common Source), CVA (Cascode), SFVA (Source Follower), IFVCO (Inductive- Feedback), CCVCO (Cross-Coupled), ColVCO (Colpitts), RVCO (Ring). 6 To account for component heterogeneity, we apply type-specific MLP encoders ϕ(t) enc to each edge feature vector, producing initial embeddings e(0) uv ϕ(t) enc(xuv), where t is the component type. These embeddings are updated via a 4-layer edge-centric message-passing GNN with shared weights. At each layer ℓ, for each node u, we first compute the node hidden state using the edge embeddings of all neighbors of the node u, N(u).\n\n--- Segment 16 ---\nThese embeddings are updated via a 4-layer edge-centric message-passing GNN with shared weights. At each layer ℓ, for each node u, we first compute the node hidden state using the edge embeddings of all neighbors of the node u, N(u). Then, for each edge (u, v) in the circuit graph, we compute the edge embedding at the next layer ℓ 1 is using the edge embedding e(ℓ) uv and the hidden node states forming the edge (u, v) at the current layer ℓas follows: h(ℓ) u X w N(u) ϕMSG(e(ℓ) wu), e(ℓ 1) uv ϕUPD(e(ℓ) uv, h(ℓ) u , h(ℓ) v ), where ϕMSG, ϕUPD are the message and update parameters of message-passing GNN and h(ℓ) u , h(ℓ) v are the hidden states for the nodes forming the edge (u, v) respectively. After message passing [57], final edge embeddings e(L) uv are aggregated to form a graph-level representation zgraph P (u,v) e(L) uv , which is decoded by a fully connected MLP (hidden size 256) to predict the 16-dimensional performance vector ˆy R16. An overview of this GNN-based forward prediction pipeline is shown in Figure 4. To stabilize training, physical parameters are rescaled by their expected units (e.g. resistance by 103), and performance targets are normalized to z-scores using training statistics. We train the model using the Adam optimizer (learning rate 10 3, batch size 256) and a ReduceLROnPlateau scheduler. Xavier uniform initialization is used for all layers, and early stopping is based on validation loss. We adopt the same splits as in Section 4 for consistency in evaluation. Evaluation. We evaluate the accuracy of the GNN forward model fθ on a test set drawn from 19 of the 20 topologies. One topology RVCO is entirely excluded from training, validation, and test splits to assess generalization to unseen architectures.\n\n--- Segment 17 ---\nWe evaluate the accuracy of the GNN forward model fθ on a test set drawn from 19 of the 20 topologies. One topology RVCO is entirely excluded from training, validation, and test splits to assess generalization to unseen architectures. Prediction quality is measured using standard re- gression metrics: coefficient of determination (R2), root mean squared error (RMSE), and mean ab- solute error (MAE), computed independently for each of the 16 performance metrics. We also report the mean relative error per metric, computed as the average across all test samples where each metric is defined. As summarized in Table 2, the model achieves high accuracy across all dimensions, with an average R2 of 0.971. 0 5 10 15 20 25 30 35 Relative Error ( ) 0.000 0.025 0.050 0.075 0.100 0.125 0.150 0.175 Density Mean: 3.65 Median: 1.69 Mode: 1.38 Figure 5: Distribution of relative error ( ) across the test set for the GNN forward model. Plot is trimmed at the 95th percentile. To evaluate end-to-end prediction accuracy at the sample level, we compute the mean relative error per instance, defined as the average relative error across all valid (non-masked) performance metrics for each test sample. Figure 5 shows the distribution of this quantity across the test set (trimmed at the 95th percentile to reduce the impact of outliers). The distribution is sharply concentrated, indicating that most predictions closely match their corresponding target vectors. Without percentile trimming, the overall mean relative error across the full test set is 9.14 . Table 2: Prediction accuracy of the forward GNN on all 16 circuit performance metrics.\n\n--- Segment 18 ---\nWithout percentile trimming, the overall mean relative error across the full test set is 9.14 . Table 2: Prediction accuracy of the forward GNN on all 16 circuit performance metrics. Metric DCP VGain PGain CGain S11 S22 NF BW OscF TR OutP PSAT DE PAE PN VSwg Unit mW dB dB dB dB dB dB GHz GHz GHz dBm dBm dBc Hz mV R² 1.0 1.0 0.99 1.0 0.92 1.0 0.99 0.98 0.97 0.83 0.97 1.0 1.0 1.0 0.89 1.0 RMSE 0.289 0.107 0.536 0.84 1.517 0.206 0.534 0.969 0.721 0.293 0.908 0.1 0.232 0.144 2.541 0.07 MAE 0.212 0.077 0.208 0.188 0.554 0.116 0.202 0.369 0.181 0.097 0.232 0.069 0.168 0.104 1.167 0.046 Rel. Err. 11.5 2.7 18.6 7.8 11.4 1.8 4.5 5.6 0.6 6.5 4.4 4.5 4.5 11.7 1.3 1.48 6 Stage 3: Layout-Aware Parameter Inference via Gradient Reasoning Task Setup. Given a target performance vector ytarget and a selected topology T , the goal of Stage 3 is to recover a parameter vector x that minimizes a total loss combining performance error and 7 Figure 6: In Stage 3, gradient reasoning iteratively updates parameters to minimize a loss combining performance error and layout cost, computed via a differentiable analytical model. layout-aware penalties, using the learned forward model fθ from Stage 2. This formulation enables instance-wise inverse design without requiring circuit-level simulation. To initialize optimization, we perturb domain-specific scale factors (e.g., 10 12 for capacitors) to sample a plausible starting point x0. Parameters are iteratively updated via gradient descent, guided by both functional and physical objectives. Topology-specific constants are held fixed, and parameter values are clipped to remain within valid domain bounds throughout the process. Loss Function.\n\n--- Segment 19 ---\nTopology-specific constants are held fixed, and parameter values are clipped to remain within valid domain bounds throughout the process. Loss Function. The total loss follows the structure defined in Eqn 1, jointly minimizing performance mismatch and layout cost: Ltotal Lperf λarea Llayout g(Lperf), (3) where Lperf is the masked mean squared error (see Eqn 2) between predicted and target performance vectors, and Llayout is a normalized area penalty derived from analytical layout equations. To prioritize functionality, layout loss is softly gated by: g(Lperf) 1 σ (γ(Lperf τ)) , which attenuates layout penalties when performance error exceeds a threshold τ, encouraging the model to first achieve functionality before optimizing for layout compactness. We set τ 0.05, γ 50, and normalize layout area by 1 mm2 to stabilize gradients. The layout weight λarea 0.02 is chosen empirically to balance performance accuracy and physical realism without dominating the loss. This gated formulation supports manufacturable parameter recovery and reflects the broader paradigm of physics-informed learning [58]. Differentiable Layout Modeling. In mm-wave analog design, layout is not a downstream concern but a critical determinant of circuit performance particularly for passive components. Substrate coupling, proximity effects, and DRC-imposed geometries directly affect key metrics such as reso- nance frequency, quality factor, and impedance matching. To incorporate these effects, we introduce a differentiable layout model that computes total physical area analytically from circuit parameters. This enables layout constraints to directly guide parameter optimization during inverse design. By minimizing the layout area in distributed mm-wave circuits [59], unwanted signal loss [60] is reduced, the self-resonance frequency of passives can increase [61], and phase and amplitude mismatches across signal paths [62] can be reduced. The layout model is deterministic and non-learned. It estimates area contributions from passive components capacitors, inductors, and resistors as these dominate total area and exhibit layout- sensitive behavior. Active devices (e.g., MOSFETs) are excluded since their geometries are fixed by the PDK and are negligible [63].\n\n--- Segment 20 ---\nIt estimates area contributions from passive components capacitors, inductors, and resistors as these dominate total area and exhibit layout- sensitive behavior. Active devices (e.g., MOSFETs) are excluded since their geometries are fixed by the PDK and are negligible [63]. For a given parameter vector x, the total layout loss is computed as: Llayout(x) X e Epassive Ae(x), where Epassive is the set of passive elements, and Ae(x) is the area of the created layout for the passive component based on analytical physics-based equations. The area of element e is estimated based on its 2D dimensions (e.g., A W L for resistors and capacitors). This area is normalized and used as a differentiable penalty in the optimization objective (see Eqn 3). Gradient Reasoning Procedure. Starting from the initialized parameter vector x, we iteratively update parameters via gradient reasoning. At each step, the frozen forward model fθ predicts the 8 (a) Designed DohPA schematic (b) Layout of designed DohPA Figure 7: Stage 3 results for a synthesized DohPA. The schematic (a) reflects optimized parameters to meet the target specification. The layout (b) is DRC-compliant and physically realizable. The final design achieves a mean relative error of 5.4 compared to the target performance. performance ˆy fθ(T, x), and the total loss Ltotal is evaluated. Gradients are backpropagated with respect to x, and updates are applied using the Adam optimizer. Optimization proceeds for a fixed number of steps, with early stopping triggered if the loss fails to improve over a predefined window. To handle varying circuit difficulty and initialization quality, we employ an adaptive learning rate strategy. Each instance begins with a moderate learning rate (10 6), refined during optimization via a ReduceLROnPlateau scheduler. If the solution fails to meet thresholds on performance error or layout area, optimization restarts with a more exploratory learning rate. This adjustment balances exploration and fine-tuning, enabling rapid convergence to physically valid solutions, typically within milliseconds to under one second per instance. An overview is shown in Figure 6. Evaluation. We evaluate Stage 3 on 9,500 test instances (500 per topology) using our gradient-based optimization pipeline.\n\n--- Segment 21 ---\nEvaluation. We evaluate Stage 3 on 9,500 test instances (500 per topology) using our gradient-based optimization pipeline. A design is considered converged if it meets both: (i) a predicted mean relative error below 10 , and (ii) a layout area under a topology-specific bound 1 mm2 for most circuits and 1.5 mm2 for DLNA, DohPA, and ClassBPA. The 10 error threshold reflects the forward model s 9 average prediction error (Section 5). A design is deemed successful if its final Cadence- simulated performance deviates from the target by less than 20 , confirming real-world viability. Our method achieves a success rate of 78.5 and a mean relative error of 17.7 across converged designs, with average inference time under 1 second on a MacBook CPU. Notably, success rate is coupled with the convergence threshold: tighter error bounds yield higher accuracy but require more iterations critical for large-scale design tasks. To illustrate the effectiveness of our pipeline, Figure 7 shows a representative result for the DohPA topology: the synthesized schematic is shown on the left, and the corresponding layout is on the right. These results confirm that the recovered parameters are both functionally accurate and physically realizable. Together, they demonstrate that FALCON enables layout-aware inverse design within a single differentiable pipeline a capability not supported by existing analog design frameworks. 7 Conclusion and Future Work We presented FALCON, a modular framework for end-to-end analog and RF circuit design that unifies topology selection, performance prediction, and layout-aware parameter optimization. Trained on over one million Cadence-simulated mm-wave circuits, FALCON combines a lightweight MLP, a generalizable GNN, and differentiable gradient reasoning to synthesize circuits from specification to layout-constrained parameters. FALCON achieves 99 topology selection accuracy, 10 predic- tion error, and efficient inverse design all within sub-second inference. The GNN forward model generalizes to unseen topologies with minimal fine-tuning, supporting broad practical deployment. In future work, we aim to expand the topology library and support hierarchical macroblocks for scalable design beyond the cell level. We also plan to extend the layout-aware optimization with learned parasitic models and EM-informed constraints for more accurate post-layout estimation.\n\n--- Segment 22 ---\nIn future work, we aim to expand the topology library and support hierarchical macroblocks for scalable design beyond the cell level. We also plan to extend the layout-aware optimization with learned parasitic models and EM-informed constraints for more accurate post-layout estimation. Fi- nally, integrating reinforcement learning or diffusion-based models for generative topology synthesis represents a promising step toward general-purpose analog design automation. 9 Acknowledgments We thank Andrea Villasenor and Tanqin He for their assistance with circuit data generation. We also thank Mohammad Shahab Sepehri for his insightful discussions and thoughtful feedback during the development of this work. References [1] Vilem Kledrowetz, Roman Prokop, Lukas Fujcik, and Jiri Haze. A fully differential analog front-end for signal processing from emg sensor in 28 nm fdsoi technology. Sensors, 23(7), 2023. [2] Wei Hong, Zhi Hao Jiang, Chao Yu, Debin Hou, Haiming Wang, Chong Guo, Yun Hu, Le Kuai, Yingrui Yu, Zhengbo Jiang, Zhe Chen, Jixin Chen, Zhiqiang Yu, Jianfeng Zhai, Nianzu Zhang, Ling Tian, Fan Wu, Guangqi Yang, Zhang-Cheng Hao, and Jian Yi Zhou. The role of millimeter-wave technologies in 5g 6g wireless communications. IEEE Journal of Microwaves, 1(1):101 122, 2021. [3] Yingying Chi, Haifeng Zhang, Zhe Zheng, Rui Liu, Lei Qiao, and Wenpeng Cui. Analog front-end circuit design for wireless sensor system-on-chip. In 2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC), volume 1, pages 38 42, 2020. [4] Xuyang Liu, Md. Hedayatullah Maktoomi, Mahdi Alesheikh, Payam Heydari, and Hamidreza Aghasi. A cmos 49 63-ghz phase-locked stepped-chirp fmcw radar transceiver. IEEE Journal of Solid-State Circuits, pages 1 15, 2025.\n\n--- Segment 23 ---\nA cmos 49 63-ghz phase-locked stepped-chirp fmcw radar transceiver. IEEE Journal of Solid-State Circuits, pages 1 15, 2025. [5] Med Nariman, Farid Shirinfar, Anna Papió Toda, Sudhakar Pamarti, Ahmadreza Rofougaran, and Franco De Flaviis. A compact 60-ghz wireless power transfer system. IEEE Transactions on Microwave Theory and Techniques, 64(8):2664 2677, 2016. [6] Phillip E Allen and Douglas R Holberg. CMOS analog circuit design. Elsevier, 2011. [7] Willy M. C. Sansen. analog design essentials. SpringerLink, 2011. [8] Shady A Abdelaal, Ahmed Hussein, and Hassan Mostafa. A bayesian optimization framework for analog circuits optimization. In 2020 15th International Conference on Computer Engineering and Systems (ICCES), pages 1 4. IEEE, 2020. [9] Zehao Dong, Weidong Cao, Muhan Zhang, Dacheng Tao, Yixin Chen, and Xuan Zhang. CktGNN: Circuit graph neural network for electronic design automation. In The Eleventh International Conference on Learning Representations, 2023. [10] Hanrui Wang, Kuan Wang, Jiacheng Yang, Linxiao Shen, Nan Sun, Hae-Seung Lee, and Song Han. Gcn-rl circuit designer: Transferable transistor sizing with graph neural networks and reinforcement learning. In 2020 57th ACM IEEE Design Automation Conference (DAC), pages 1 6, 2020. [11] Dmitrii Krylov, Pooya Khajeh, Junhan Ouyang, Thomas Reeves, Tongkai Liu, Hiba Ajmal, Hamidreza Aghasi, and Roy Fox. Learning to design analog circuits to meet threshold specifications. In Proceedings of the 40th International Conference on Machine Learning, ICML 23. JMLR.org, 2023. [12] Hanrui Wang, Jiacheng Yang, Hae-Seung Lee, and Song Han. Learning to design circuits. arXiv preprint arXiv:1812.02734, 2018.\n\n--- Segment 24 ---\nLearning to design circuits. arXiv preprint arXiv:1812.02734, 2018. [13] Keertana Settaluri, Ameer Haj-Ali, Qijing Huang, Kourosh Hakhamaneshi, and Borivoje Nikolic. Autockt: deep reinforcement learning of analog circuit designs. In Proceedings of the 23rd Conference on Design, Automation and Test in Europe, DATE 20, page 490 495, San Jose, CA, USA, 2020. EDA Consortium. [14] Yaguang Li, Yishuang Lin, Meghna Madhusudan, Arvind Sharma, Sachin Sapatnekar, Ramesh Harjani, and Jiang Hu. A circuit attention network-based actor-critic learning approach to robust analog transistor sizing. In 2021 ACM IEEE 3rd Workshop on Machine Learning for CAD (MLCAD), pages 1 6, 2021. [15] Wenlong Lyu, Pan Xue, Fan Yang, Changhao Yan, Zhiliang Hong, Xuan Zeng, and Dian Zhou. An efficient bayesian optimization approach for automated optimization of analog circuits. IEEE Transactions on Circuits and Systems I: Regular Papers, 65(6):1954 1967, 2017. [16] Kourosh Hakhamaneshi, Marcel Nassar, Mariano Phielipp, Pieter Abbeel, and Vladimir Stojanovic. Pretraining graph neural networks for few-shot analog circuit modeling and design. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 42(7):2163 2173, 2022. 10 [17] Morteza Fayazi, Morteza Tavakoli Taba, Ehsan Afshari, and Ronald Dreslinski. Angel: Fully-automated analog circuit generator using a neural network assisted semi-supervised learning approach. IEEE Transac- tions on Circuits and Systems I: Regular Papers, 2023. [18] Jintao Li, Haochang Zhi, Ruiyu Lyu, Wangzhen Li, Zhaori Bi, Keren Zhu, Yanhan Zeng, Weiwei Shan, Changhao Yan, Fan Yang, Yun Li, and Xuan Zeng. Analoggym: An open and practical testing suite for analog circuit synthesis. In International Conference on Computer Aided Design, 2024.\n\n--- Segment 25 ---\nAnaloggym: An open and practical testing suite for analog circuit synthesis. In International Conference on Computer Aided Design, 2024. [19] Chen-Chia Chang, Yikang Shen, Shaoze Fan, Jing Li, Shun Zhang, Ningyuan Cao, Yiran Chen, and Xin Zhang. Lamagic: Language-model-based topology generation for analog integrated circuits. arXiv preprint arXiv:2407.18269, 2024. [20] Yao Lai, Sungyoung Lee, Guojin Chen, Souradip Poddar, Mengkang Hu, David Z Pan, and Ping Luo. Analogcoder: Analog circuit design via training-free code generation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 379 387, 2025. [21] Weidong Cao, Mouhacine Benosman, Xuan Zhang, and Rui Ma. Domain knowledge-based automated analog circuit design with deep reinforcement learning. arXiv preprint arXiv:2202.13185, 2022. [22] Ahmet Faruk Budak, Miguel Gandara, Wei Shi, David Z. Pan, Nan Sun, and Bo Liu. An efficient analog circuit sizing method based on machine learning assisted global optimization. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 41(5):1209 1221, 2022. [23] Asal Mehradfar, Xuzhe Zhao, Yue Niu, Sara Babakniya, Mahdi Alesheikh, Hamidreza Aghasi, and Salman Avestimehr. AICircuit: A Multi-Level Dataset and Benchmark for AI-Driven Analog Integrated Circuit Design. Machine Learning and the Physical Sciences Workshop NeurIPS, 2024. [24] Asal Mehradfar, Xuzhe Zhao, Yue Niu, Sara Babakniya, Mahdi Alesheikh, Hamidreza Aghasi, and Salman Avestimehr. Supervised learning for analog and rf circuit design: Benchmarks and comparative insights. arXiv preprint arXiv:2501.11839, 2025. [25] Mingjie Liu, Walker J. Turner, George F. Kokai, Brucek Khailany, David Z. Pan, and Haoxing Ren.\n\n--- Segment 26 ---\narXiv preprint arXiv:2501.11839, 2025. [25] Mingjie Liu, Walker J. Turner, George F. Kokai, Brucek Khailany, David Z. Pan, and Haoxing Ren. Parasitic-aware analog circuit sizing with graph neural networks and bayesian optimization. In 2021 Design, Automation Test in Europe Conference Exhibition (DATE), pages 1372 1377, 2021. [26] Tonmoy Dhar, Kishor Kunal, Yaguang Li, Meghna Madhusudan, Jitesh Poojary, Arvind K Sharma, Wenbin Xu, Steven M Burns, Ramesh Harjani, Jiang Hu, et al. Align: A system for automating analog layout. IEEE Design Test, 38(2):8 18, 2020. [27] Bingyang Liu, Haoyi Zhang, Xiaohan Gao, Zichen Kong, Xiyuan Tang, Yibo Lin, Runsheng Wang, and Ru Huang. Layoutcopilot: An llm-powered multi-agent collaborative framework for interactive analog layout design. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2025. [28] Antonio J Lopez Martin. Cadence design environment. New Mexico State University, Tutorial paper, 35, 2002. [29] Sorin Voinigescu. High-frequency integrated circuits. Cambridge University Press, 2013. [30] Behzad Razavi. RF microelectronics, volume 2. Prentice hall New York, 2012. [31] Thomas H. Lee. The Design of CMOS Radio-Frequency Integrated Circuits. Cambridge University Press, 2nd edition, 2004. [32] John R. Long and Michael A. Copeland. The design of low-noise cmos rf amplifiers. IEEE Journal of Solid-State Circuits, 32(2):292 302, 1997. [33] Ali M. Niknejad. mm-Wave Silicon Technology: 60 GHz and Beyond. Springer, 2008. [34] Xiaohua Fan, Heng Zhang, and Edgar SÁnchez-Sinencio. A noise reduction and linearity improvement technique for a differential cascode lna. IEEE Journal of Solid-State Circuits, 43(3):588 599, 2008.\n\n--- Segment 27 ---\nA noise reduction and linearity improvement technique for a differential cascode lna. IEEE Journal of Solid-State Circuits, 43(3):588 599, 2008. [35] B. Henderson and E. Camargo. Microwave Mixer Technology and Applications. Microwave RF. Artech House, 2013. [36] B. Gilbert. A precise four-quadrant multiplier with subnanosecond response. IEEE Journal of Solid-State Circuits, 3(4):365 373, 1968. [37] Krenar Komoni, Sameer Sonkusale, and Geoff Dawe. Fundamental performance limits and scaling of a cmos passive double-balanced mixer. In 2008 Joint 6th International IEEE Northeast Workshop on Circuits and Systems and TAISA Conference, pages 297 300, 2008. 11 [38] S. Chehrazi, R. Bagheri, and A.A. Abidi. Noise in passive fet mixers: a simple physical model. In Proceedings of the IEEE 2004 Custom Integrated Circuits Conference (IEEE Cat. No.04CH37571), pages 375 378, 2004. [39] Hua Wang, Peter M. Asbeck, and Christian Fager. Millimeter-wave power amplifier integrated circuits for high dynamic range signals. IEEE Journal of Microwaves, 1(1):299 316, 2021. [40] M.K. Kazimierczuk. RF Power Amplifiers. Wiley, 2014. [41] F.H. Raab, P. Asbeck, S. Cripps, P.B. Kenington, Z.B. Popovic, N. Pothecary, J.F. Sevic, and N.O. Sokal. Power amplifiers and transmitters for rf and microwave. IEEE Transactions on Microwave Theory and Techniques, 50(3):814 826, 2002. [42] Narek Rostomyan, Mustafa Özen, and Peter Asbeck. 28 ghz doherty power amplifier in cmos soi with 28 IEEE Microwave and Wireless Components Letters, 28(5):446 448, 2018. [43] Morteza Abbasi, Torgil Kjellberg, Anton de Graauw, Edwin van der Heijden, Raf Roovers, and Herbert Zirath.\n\n--- Segment 28 ---\n28 ghz doherty power amplifier in cmos soi with 28 IEEE Microwave and Wireless Components Letters, 28(5):446 448, 2018. [43] Morteza Abbasi, Torgil Kjellberg, Anton de Graauw, Edwin van der Heijden, Raf Roovers, and Herbert Zirath. A broadband differential cascode power amplifier in 45 nm cmos for high-speed 60 ghz system-on- chip. In 2010 IEEE Radio Frequency Integrated Circuits Symposium, pages 533 536, 2010. [44] Behzad Razavi. Design of Analog CMOS Integrated Circuits. McGraw-Hill Education, 2016. [45] S. Karthikeyan, S. Mortezapour, A. Tammineedi, and E.K.F. Lee. Low-voltage analog circuit design based on biased inverting opamp configuration. IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing, 47(3):176 184, 2000. [46] Tae Wook Kim. A common-gate amplifier with transconductance nonlinearity cancellation and its high- frequency analysis using the volterra series. IEEE Transactions on Microwave Theory and Techniques, 57 (6):1461 1469, 2009. [47] T. Lehmann and M. Cassia. 1-v power supply cmos cascode amplifier. IEEE Journal of Solid-State Circuits, 36(7):1082 1086, 2001. [48] H.-J. Song and C.-K. Kim. An mos four-quadrant analog multiplier using simple two-input squaring circuits with source followers. IEEE Journal of Solid-State Circuits, 25(3):841 848, 1990. [49] N. R. Sivaraaj and K. K. Abdul Majeed. A comparative study of ring vco and lc-vco: Design, performance analysis, and future trends. IEEE Access, 11:127987 128017, 2023. [50] Cao Wan, Taotao Xu, Xiang Yi, and Quan Xue. A current-reused vco with inductive-transformer feedback technique. IEEE Transactions on Microwave Theory and Techniques, 70(5):2680 2689, 2022.\n\n--- Segment 29 ---\nA current-reused vco with inductive-transformer feedback technique. IEEE Transactions on Microwave Theory and Techniques, 70(5):2680 2689, 2022. [51] Tuan Thanh Ta, Suguru Kameda, Tadashi Takagi, and Kazuo Tsubouchi. A 5ghz band low noise and wide tuning range si-cmos vco. In 2009 IEEE Radio Frequency Integrated Circuits Symposium, pages 571 574, 2009. [52] R. Aparicio and A. Hajimiri. A noise-shifting differential colpitts vco. IEEE Journal of Solid-State Circuits, 37(12):1728 1736, 2002. [53] Shruti Suman, K. G. Sharma, and P. K. Ghosh. Analysis and design of current starved ring vco. In 2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT), pages 3222 3227, 2016. [54] Sungyoung Lee, Ziyi Wang, Seunggeun Kim, Taekyun Lee, and David Z Pan. Self-supervised graph contrastive pretraining for device-level integrated circuits. arXiv preprint arXiv:2502.08949, 2025. [55] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. [56] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(11), 2008. [57] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In International conference on machine learning, pages 1263 1272. PMLR, 2017. [58] Maziar Raissi, Paris Perdikaris, and George Em Karniadakis. Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations. arXiv preprint arXiv:1711.10561, 2017. 12 [59] A. Dounavis, R. Achar, and M.S. Nakhla.\n\n--- Segment 30 ---\n12 [59] A. Dounavis, R. Achar, and M.S. Nakhla. Efficient passive circuit models for distributed networks with frequency-dependent parameters. IEEE Transactions on Advanced Packaging, 23(3):382 392, 2000. [60] Shen Wang, M.A. de Rooij, W.G. Odendaal, J.D. van Wyk, and D. Boroyevich. Reduction of high- frequency conduction losses using a planar litz structure. IEEE Transactions on Power Electronics, 20(2): 261 267, 2005. [61] Tejinder Singh and Raafat R Mansour. Miniaturized 6-bit phase-change capacitor bank with improved self-resonance frequency and q. In 2022 52nd European Microwave Conference (EuMC), pages 572 575. IEEE, 2022. [62] Chenxi Zhao, Xing Zeng, Lin Zhang, Huihua Liu, Yiming Yu, Yunqiu Wu, and Kai Kang. A 37 40-ghz low-phase-imbalance cmos attenuator with tail-capacitor compensation technique. IEEE Transactions on Circuits and Systems I: Regular Papers, 67(10):3400 3409, 2020. [63] Michele Spasaro and Domenico Zito. Millimeter-wave integrated silicon devices: Active versus pas- sive the eternal struggle between good and evil. In 2019 International Semiconductor Conference (CAS), pages 11 20. IEEE, 2019. 13 A Qualitative Comparison with Prior Work To contextualize FALCON within the broader landscape of analog circuit design automation, we provide a qualitative comparison against representative prior works in Table 3. This comparison spans key capabilities including topology selection, parameter inference, performance prediction, layout awareness, and simulator fidelity. We additionally assess reproducibility via dataset and code availability, and introduce a new axis RF mm-wave support to highlight methods evaluated on high-frequency circuit blocks such as LNAs, mixers, and VCOs. Compared to existing approaches, FALCON is the only framework that unifies all these dimensions while maintaining foundry-grade fidelity and open-source accessibility. Definitions for each comparison axis are provided in Table 4. Table 3: Qualitative comparison of FALCON with prior works across key capabilities in analog circuit design automation.\n\n--- Segment 31 ---\nDefinitions for each comparison axis are provided in Table 4. Table 3: Qualitative comparison of FALCON with prior works across key capabilities in analog circuit design automation. Method Topology Selection Parameter Inference Performance Prediction Layout Awareness Foundry Grade RF mm-Wave Public Dataset Public Code CktGNN [9] (SPICE) LaMAGIC [19] (SPICE) AnalogCoder [20] (SPICE) GCN-RL [10] (SPICE Cadence) Cao et al. [21] (SPICE Cadence) BO-SPGP [15] (Cadence) ESSAB [22] (Cadence) AICircuit [23, 24] (Cadence) Krylov et al. [11] (SPICE) Deep-GEN [16] (SPICE) Liu et al. [25] (SPICE Parasitic Model) ALIGN [26] (Cadence) LayoutCopilot [27] (Cadence) AnalogGym [18] (SPICE) AutoCkt [13] (Cadence) (incomplete) L2DC [12] (Cadence) CAN-RL [14] (Cadence) AnGeL. [17] (SPICE) FALCON (This work) (Cadence) Table 4: Definitions of each comparison axis in Table 3. Column Definition Topology Selection Does the method automatically select or predict circuit topology given a target specification? Parameter Inference Does the method infer element-level parameters (e.g., transistor sizes, component values) as part of design generation? Performance Prediction Can the method predict circuit performance metrics (e.g., gain, bandwidth, noise) from topology and parameters? Layout Awareness Is layout considered during optimization or training (e.g., via area constraints, parasitics, or layout-informed loss)? Dataset Fidelity Does the dataset reflect realistic circuit behavior (e.g., SPICE Cadence simulations, PDK models)? RF mm-Wave Is the method evaluated on at least one RF or mm-wave circuit type that reflects high-frequency design challenges? Public Dataset Is the dataset used in the work publicly released for reproducibility and benchmarking? Public Code Is the implementation code publicly available and documented for reproducibility?\n\n--- Segment 32 ---\nPublic Dataset Is the dataset used in the work publicly released for reproducibility and benchmarking? Public Code Is the implementation code publicly available and documented for reproducibility? B Dataset Details and Performance Metric Definitions During dataset generation, each simulated circuit instance is annotated with a set of performance metrics that capture its functional characteristics. All simulations are performed at a fixed frequency of 30 GHz, ensuring consistency across circuit types and relevance to mm-wave design. A total of 16 metrics are defined across all circuits spanning gain, efficiency, impedance matching, noise, and frequency-domain behavior though the specific metrics used vary by topology. For example, phase noise is only applicable to oscillators. An overview of all performance metrics is provided in Table 5. B.1 Low-Noise Amplifiers (LNAs) Low-noise amplifiers (LNAs) are critical components in receiver front-ends, responsible for amplify- ing weak antenna signals while introducing minimal additional noise. Their performance directly influences downstream blocks such as mixers and analog-to-digital converters (ADCs), ultimately de- termining system-level fidelity [31]. To capture the architectural diversity of practical radio-frequency (RF) designs, we include four widely used LNA topologies in this study common-source LNA (CSLNA), common-gate LNA (CGLNA), cascode LNA (CLNA), and differential LNA (DLNA) as shown in Figure 8. 14 Table 5: Overview of 16 performance metrics used during dataset generation.\n\n--- Segment 33 ---\nTo capture the architectural diversity of practical radio-frequency (RF) designs, we include four widely used LNA topologies in this study common-source LNA (CSLNA), common-gate LNA (CGLNA), cascode LNA (CLNA), and differential LNA (DLNA) as shown in Figure 8. 14 Table 5: Overview of 16 performance metrics used during dataset generation. Performance Name Description DC Power Consumption (DCP) Total power drawn from the DC supply indicating energy consumption of the circuit Voltage Gain (VGain) Ratio of output voltage amplitude to input voltage amplitude Power Gain (PGain) Ratio of output power to input power Conversion Gain (CGain) Ratio of output power at the desired frequency to input power at the original frequency S11 Input reflection coefficient indicating impedance matching at the input terminal S22 Output reflection coefficient indicating impedance matching at the output terminal Noise Figure (NF) Ratio of input signal-to-noise ratio to output signal-to-noise ratio Bandwidth (BW) Frequency span over which the circuit maintains specified performance characteristics Oscillation Frequency (OscF) Steady-state frequency at which the oscillator generates a periodic signal Tuning Range (TR) Range of achievable oscillation frequencies through variation of control voltages Output Power (OutP) Power delivered to the load PSAT Maximum output power level beyond which gain compression begins to occur Drain Efficiency (DE) Ratio of RF output power to DC power consumption. Power-Added Efficiency (PAE) Ratio of the difference between output power and input power to DC power consumption Phase Noise (PN) Measure of oscillator stability represented in the frequency domain at a specified offset Voltage Swing (VSwg) Maximum peak voltage level achievable at the output node The CSLNA is valued for its simplicity and favorable gain noise trade-off, especially when paired with inductive source degeneration [30]. The CGLNA, often used in ultra-wideband systems, enables broadband input matching but typically suffers from a higher noise figure [32]. The CLNA improves gain bandwidth product and reverse isolation, making it ideal for high-frequency, high-linearity applications [33]. The DLNA exploits circuit symmetry to enhance linearity and reject common-mode noise, and is commonly found in high-performance RF front-end designs [34]. The design parameters and performance metrics associated with these topologies are summarized in Table 6.\n\n--- Segment 34 ---\nThe DLNA exploits circuit symmetry to enhance linearity and reject common-mode noise, and is commonly found in high-performance RF front-end designs [34]. The design parameters and performance metrics associated with these topologies are summarized in Table 6. (a) CSLNA (b) CGLNA (c) CLNA (d) DLNA Figure 8: Schematic diagrams of the four LNA topologies. Table 6: LNA topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) LNA CGLNA (0) 52k C1 [100 600] fF DCP (W) PGain (dB) S11 (dB) NF (dB) BW (Hz) C2 [50 300] fF Cb [250 750] fF Ld [80 580] pH Ls [0.5 5.5] nH WN [12 23] µm CLNA (1) 62k C1, C2 [50 250] fF Ld [140 300] pH Lg [0.4 2] nH Ls [50 250] pH WN1 [3 5] µm WN2 [7 9] µm CSLNA (2) 39k C [100 300] fF Lg [4 6] nH Ls [100 200] pH WN [2.5 4] µm Vgs [0.5 0.9] V DLNA (3) 92k C1 [100 190] fF C2 [130 220] fF Ld [100 250] pH Lg [600 900] pH Ls [50 80] pH WN1 [4 9.4] µm WN2 [5 14] µm 15 B.2 Mixers Mixers are fundamental nonlinear components in RF systems, responsible for frequency translation by combining two input signals to produce outputs at the sum and difference of their frequencies. This functionality is essential for transferring signals across frequency domains and is widely used in both transmission and reception paths [35].\n\n--- Segment 35 ---\nDataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) LNA CGLNA (0) 52k C1 [100 600] fF DCP (W) PGain (dB) S11 (dB) NF (dB) BW (Hz) C2 [50 300] fF Cb [250 750] fF Ld [80 580] pH Ls [0.5 5.5] nH WN [12 23] µm CLNA (1) 62k C1, C2 [50 250] fF Ld [140 300] pH Lg [0.4 2] nH Ls [50 250] pH WN1 [3 5] µm WN2 [7 9] µm CSLNA (2) 39k C [100 300] fF Lg [4 6] nH Ls [100 200] pH WN [2.5 4] µm Vgs [0.5 0.9] V DLNA (3) 92k C1 [100 190] fF C2 [130 220] fF Ld [100 250] pH Lg [600 900] pH Ls [50 80] pH WN1 [4 9.4] µm WN2 [5 14] µm 15 B.2 Mixers Mixers are fundamental nonlinear components in RF systems, responsible for frequency translation by combining two input signals to produce outputs at the sum and difference of their frequencies. This functionality is essential for transferring signals across frequency domains and is widely used in both transmission and reception paths [35]. To capture diverse mixer architectures, we implement four representative topologies in this work double-balanced active mixer (DBAMixer), double-balanced passive mixer (DBPMixer), single-balanced active mixer (SBAMixer), and single-balanced passive mixer (SBPMixer) as shown in Figure 9. The DBAMixer integrates amplification and differential switching to achieve conversion gain and high port-to-port isolation. Despite its elevated power consumption and design complexity, it is well suited for systems requiring robust performance over varying conditions [36]. The DBPMixer features a fully differential structure that suppresses signal leakage and improves isolation, at the cost of signal loss and a strong local oscillator drive requirement [37].\n\n--- Segment 36 ---\nDespite its elevated power consumption and design complexity, it is well suited for systems requiring robust performance over varying conditions [36]. The DBPMixer features a fully differential structure that suppresses signal leakage and improves isolation, at the cost of signal loss and a strong local oscillator drive requirement [37]. The SBAMixer includes an amplification stage preceding the switching core to enhance signal strength and reduce noise, offering a balanced performance trade-off with increased power consumption and limited spurious rejection [30]. The SBPMixer employs a minimalist switching structure to perform frequency translation without active gain, enabling low power operation in applications with relaxed performance demands [38]. The parameters and performance metrics for these mixer topologies are listed in Table 7. (a) DPAMixer (b) DBPMixer (c) SBAMixer (d) SBPMixer Figure 9: Schematic diagrams of the four Mixer topologies. Table 7: Mixer topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) Mixer DBAMixer (4) 42k C [1 10] pF DCP (W) CGain (dB) NF (dB) VSwg (V) R [1 10] kΩ WN1 [10 30] µm WN2 [5 25] µm DBPMixer (5) 42k C [100 500] fF R [100 600] Ω WN [10 30] µm SBAMixer (6) 52k C [1 15] pF R [0.7 2.1] kΩ WN1 [10 30] µm WN2 [10 20] µm Itail [3 10] mA SBPMixer (7) 44k C [1 30] pF R [1 30] kΩ WN [5 29.5] µm B.3 Power Amplifiers (PAs) Power amplifiers (PAs) are the most power-intensive components in radio-frequency (RF) systems and serve as the final interface between transceiver electronics and the antenna. Given their widespread use and the stringent demands of modern communication standards, PA design requires careful trade-offs across key performance metrics [39].\n\n--- Segment 37 ---\nDataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) Mixer DBAMixer (4) 42k C [1 10] pF DCP (W) CGain (dB) NF (dB) VSwg (V) R [1 10] kΩ WN1 [10 30] µm WN2 [5 25] µm DBPMixer (5) 42k C [100 500] fF R [100 600] Ω WN [10 30] µm SBAMixer (6) 52k C [1 15] pF R [0.7 2.1] kΩ WN1 [10 30] µm WN2 [10 20] µm Itail [3 10] mA SBPMixer (7) 44k C [1 30] pF R [1 30] kΩ WN [5 29.5] µm B.3 Power Amplifiers (PAs) Power amplifiers (PAs) are the most power-intensive components in radio-frequency (RF) systems and serve as the final interface between transceiver electronics and the antenna. Given their widespread use and the stringent demands of modern communication standards, PA design requires careful trade-offs across key performance metrics [39]. Based on the transistor operating mode, PAs are typically grouped into several canonical classes [40]. In this work, we implement four representative topologies Class-B PA (ClassBPA), Class-E PA (ClassEPA), Doherty PA (DohPA), and differential PA (DPA) as shown in Figure 10. 16 The ClassBPA employs complementary transistors to deliver high gain with moderate efficiency, making it suitable for linear amplification scenarios [41]. The ClassEPA uses a single transistor configured as a switch, paired with a matching network. By minimizing the overlap between drain voltage and current, this topology enables high-efficiency operation and improved robustness to component variation [30]. The DohPA combines main and peaking amplifiers using symmetric two-stack transistors, maintaining consistent gain and efficiency under varying power levels [42]. The DPA features a two-stage cascode structure designed to maximize gain and linearity, offering a favorable trade-off between output power and power consumption [43].\n\n--- Segment 38 ---\nThe DohPA combines main and peaking amplifiers using symmetric two-stack transistors, maintaining consistent gain and efficiency under varying power levels [42]. The DPA features a two-stage cascode structure designed to maximize gain and linearity, offering a favorable trade-off between output power and power consumption [43]. For this topology, we replace the transformer with a T-equivalent network to simplify modeling and training of the graph neural network. Parameter sweeps and performance metrics for these PAs are listed in Table 8. (a) ClassBPA (b) ClassEPA (c) DohPA (d) DPA Figure 10: Schematic diagrams of the four PA topologies. Table 8: PA topologies with parameter sweep ranges, sample sizes, and performance metrics.\n\n--- Segment 39 ---\n(a) ClassBPA (b) ClassEPA (c) DohPA (d) DPA Figure 10: Schematic diagrams of the four PA topologies. Table 8: PA topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) PA ClassBPA (8) 35k C [55 205] fF DCP (W) PGain (dB) S11 (dB) S22 (dB) PSAT (dBm) DE ( ) PAE ( ) L1 [1 1.4] nH L2 [1 8.5] pH R [1.5 4] kΩ WN [10 20] µm WP [3 8] µm ClassEPA (9) 46k C1 [100 200] fF C2 [500 700] fF L1 [100 300] pH L2 [100 150] pH WN [15 30] µm DohPA (10) 120k C1 [2 3] pF C2 [200 300] fF C3, C5 [100 200] fF C4 [300 400] fF L1, L5 [100 200] pH L2 [350 450] pH L3 [500 600] pH L4 [150 250] pH L6 [300 400] pH WN1, WN2 [6 13] µm DPA (11) 80k Lip [100 500] pH Lis [300 700] pH Lop [0.8 1.2] nH Los [400 800] pH Lm [50 250] pH WN1 [6 31] µm WN2 [10 35] µm 17 B.4 Voltage Amplifiers (VAs) Voltage amplifiers (VAs) are fundamental components in analog circuit design, responsible for increasing signal amplitude while preserving waveform integrity. Effective VA design requires balancing key performance metrics tailored to both RF and baseband operating conditions [44]. In this work, we implement four widely used VA topologies common-source VA (CSVA), common- gate VA (CGVA), cascode VA (CVA), and source follower VA (SFVA) as shown in Figure 11. The CSVA remains the most widely adopted configuration due to its structural simplicity and high voltage gain.\n\n--- Segment 40 ---\nIn this work, we implement four widely used VA topologies common-source VA (CSVA), common- gate VA (CGVA), cascode VA (CVA), and source follower VA (SFVA) as shown in Figure 11. The CSVA remains the most widely adopted configuration due to its structural simplicity and high voltage gain. It is frequently used as the first gain stage in various analog systems [45]. The CGVA is suitable for applications requiring low input impedance and wide bandwidth, such as impedance transformation or broadband input matching [46]. The CVA, which cascades a common-source stage with a common-gate transistor, improves the gain bandwidth product and enhances stability, making it ideal for applications demanding wide dynamic range and robust gain control [47]. The SFVA, also known as a common-drain amplifier, provides near-unity voltage gain and low output impedance, making it well suited for interstage buffering, load driving, and impedance bridging [48]. Parameter ranges and performance specifications for these VA topologies are listed in Table 9. (a) CSVA (b) CGVA (c) CVA (d) SFVA Figure 11: Schematic diagrams of the four VA topologies. Table 9: VA topologies with parameter sweep ranges, sample sizes, and performance metrics.\n\n--- Segment 41 ---\n(a) CSVA (b) CGVA (c) CVA (d) SFVA Figure 11: Schematic diagrams of the four VA topologies. Table 9: VA topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) VA CGVA (12) 33k C [0.1 1.5] pF DCP (W) VGain (dB) BW (Hz) R [0.1 1.5] kΩ WN1 [5 30] µm WN2 [5 10] µm CSVA (13) 21k R [0.7 1.5] kΩ WN [3 15] µm VDD [1 1.8] V Vgate [0.6 0.9] V CVA (14) 22k R [1 3] kΩ WN1, WN2 [1 10] µm WN3 [10 15] µm SFVA (15) 28k WN1 [40 60] µm WN2 [2 8] µm VDD [1.1 1.8] V Vgate [0.6 1.2] V Vb [0.5 0.9] V B.5 Voltage-Controlled Oscillators (VCOs) Voltage-controlled oscillators (VCOs) are essential building blocks in analog and RF systems, responsible for generating periodic waveforms with frequencies modulated by a control voltage. These circuits rely on amplification, feedback, and resonance to sustain stable oscillations. Owing to their wide tuning range, low power consumption, and ease of integration, VCOs are broadly used in systems such as phase-locked loops (PLLs), frequency synthesizers, and clock recovery circuits [49]. In this work, we implement four representative VCO topologies inductive-feedback VCO (IFVCO), cross-coupled VCO (CCVCO), Colpitts VCO (ColVCO), and ring VCO (RVCO) as shown in Figure 12. 18 The IFVCO employs an NMOS differential pair with an inductor-based feedback path to sustain oscillations.\n\n--- Segment 42 ---\nIn this work, we implement four representative VCO topologies inductive-feedback VCO (IFVCO), cross-coupled VCO (CCVCO), Colpitts VCO (ColVCO), and ring VCO (RVCO) as shown in Figure 12. 18 The IFVCO employs an NMOS differential pair with an inductor-based feedback path to sustain oscillations. This topology provides favorable noise performance and compact layout, making it well suited for low-voltage, low-power designs [50]. The CCVCO achieves negative resistance through cross-coupling, enabling low phase noise and high integration density, and is widely adopted in frequency synthesizers and PLLs [51]. The ColVCO uses an LC tank and capacitive feedback to achieve high frequency stability and low phase noise, making it ideal for precision RF communication and instrumentation [52]. The RVCO consists of cascaded delay stages forming a feedback loop, offering low power consumption, wide tuning range, and minimal area footprint, though at the cost of higher phase noise. It is commonly used in on-chip clock generation and low-power sensor applications [53]. Design parameters and performance metrics for these VCO topologies are presented in Table 10. (a) IFVCO (b) CCVCO (c) ColVCO (d) RVCO Figure 12: Schematic diagrams of the four VCO topologies. Table 10: VCO topologies with parameter sweep ranges, sample sizes, and performance metrics.\n\n--- Segment 43 ---\n(a) IFVCO (b) CCVCO (c) ColVCO (d) RVCO Figure 12: Schematic diagrams of the four VCO topologies. Table 10: VCO topologies with parameter sweep ranges, sample sizes, and performance metrics. Dataset Type Topology (Code) of Samples Parameter Sweep Range Performance Metrics (Unit) VCO IFVCO (16) 43k C1 [700 900] fF DCP (W) OscF (Hz) TR (Hz) OutP (dBm) PN (dBc Hz) C2 [50 250] fF L1 [400 600] pH L2 [500 700] pH WN, Wvar [5 9] µm CCVCO (17) 54k L [200 400] pH WN [10 35] µm Wvar [5 30] µm ColVCO (18) 90k C [80 140] fF L [250 350] pH WN [30 50] µm Wvar [5 15] µm Vb [0.7 1.2] V Itail [5 15] mA RVCO (19) 46k C [300 700] fF L1 [300 500] pH L2 [50 250] pH WN [20 40] µm Wvar [5 25] µm C Graph-Based Circuit Representation To enable GNN-based modeling of analog circuits, we represent each netlist as a directed multigraph where nodes correspond to electrical nets and edges encode circuit components such as transistors, capacitors, inductors, and voltage sources. Each edge is labeled with its component type and terminal role (e.g., gate, source, drain), and component-specific attributes are stored as edge features. For transistors, labels such as GS, DS, and DG denote source-to-gate, drain-to-source, and drain-to-gate connections, respectively. Figure 13 illustrates two representative graph structures extracted from our dataset: an IFVCO and a ClassBPA. The visual encoding highlights the diversity of components and connectivity patterns across topologies. Edges corresponding to the same component type share a common color for visual consistency and semantic clarity. These structured graphs serve as the primary input to our GNN pipeline for performance prediction and inverse design.\n\n--- Segment 44 ---\nEdges corresponding to the same component type share a common color for visual consistency and semantic clarity. These structured graphs serve as the primary input to our GNN pipeline for performance prediction and inverse design. 19 V2 V0 L5 C2 L4 C1 L1 L0 N3_DG N3_GS N3_DS N2_DS N2_DG N2_GS N0_DG L3 N0_DS N1_DG L2 N1_DS N1_GS C0 N0_GS GND VDD Vcont Vout- Vout net9 net7 net15 net8 Components nmos capacitor vsource inductor (a) IFVCO N0_DG R0 N0_GS R4 C0 N0_DS V0 P0_DS P0_GS L2 PORT0 P0_DG R3 C6 PORT1 L0 R5 C1 net7 VDD net2 GND net1 net4 net3 net5 Vin Components nmos pmos resistor capacitor vsource port inductor (b) ClassBPA Figure 13: Graph representations of two analog circuit topologies from our dataset: (a) IFVCO and (b) ClassBPA. Nodes represent electrical nets, and colored edges denote circuit components such as transistors, capacitors, inductors, and sources. Each component type is visually distinguished by color and labeled with its name and terminal role (e.g., N2_GS, V0). These graphs serve as input to our GNN-based performance modeling and inverse design pipeline. D Generalizing to Unseen Topologies via Fine-Tuning To assess the generalization ability of our pretrained GNN, we evaluate it on the held-out RVCO topology, which was entirely excluded from the Stage 2 training, validation, and test splits (see Section 5). Notably, the RVCO training partition used here matches that of the Stage 1 experiments (Section 4), enabling consistent cross-stage evaluation. We fine-tune the GNN by freezing all encoder and message-passing layers and updating only the final output head (output_mlp). Fine-tuning is performed on the RVCO training set, which contains approximately 30,000 instances, and completes in under 30 minutes on a MacBook CPU.\n\n--- Segment 45 ---\nWe fine-tune the GNN by freezing all encoder and message-passing layers and updating only the final output head (output_mlp). Fine-tuning is performed on the RVCO training set, which contains approximately 30,000 instances, and completes in under 30 minutes on a MacBook CPU. Even in the zero-shot setting where the model has never seen RVCO topologies the pretrained GNN achieves a nontrivial mean relative error of 33.1 , highlighting its strong cross-topology generalization. Fine-tuning reduces this error to just 0.8 , demonstrat- ing that the structural and parametric priors learned during pretraining are highly transfer- able. Table 11 reports detailed performance across five key metrics, confirming that the pre- trained GNN can be rapidly adapted to novel circuit families with minimal supervision. Table 11: Fine-tuning results on the held-out RVCO topology. Only the output head is updated using RVCO samples. Metric DCP OscF TR OutP PN Unit W GHz GHz dBm dBc Hz R² 1.0 1.0 1.0 0.97 0.99 RMSE 0.725 0.244 0.022 0.098 0.792 MAE 0.576 0.19 0.018 0.078 0.477 Rel. Err. 0.85 0.62 1.4 0.69 0.56 E Layout Design and DRC Compliance E.1 Design Rule Enforcement in 45 nm CMOS We implemented FALCON using a 45 nm CMOS technology node, applying rigorous Design Rule Checking (DRC) at both the cell and full-chip layout levels. At the cell level, our parameterized layout generators enforced foundry-specific constraints, including minimum feature width and length, contact and via spacing, and metal enclosure rules. At the circuit level, we incorporated physical verification to mitigate interconnect coupling, IR drop, and layout-dependent parasitic mismatches factors that are especially critical in high-frequency and precision analog design. 20 DRC plays a vital role in ensuring that layouts comply with process design rules defined by the semiconductor foundry. Adhering to these rules ensures not only physical manufacturability but also electrical reliability. Violations may lead to fabrication failures, including yield degradation, electrical shorts or opens, electromigration-induced issues, and parasitic mismatches.\n\n--- Segment 46 ---\nAdhering to these rules ensures not only physical manufacturability but also electrical reliability. Violations may lead to fabrication failures, including yield degradation, electrical shorts or opens, electromigration-induced issues, and parasitic mismatches. Moreover, DRC compliance is essential for compatibility with downstream fabrication steps such as photomask generation, optical lithography, and chemical-mechanical planarization (CMP), safeguarding the yield and fidelity of the final IC. Circuit-Level Layout Guidelines. We enforced several topology-aware layout constraints during full-circuit integration to preserve signal integrity and robustness: Inductor-to-inductor spacing: 35.0 µm to mitigate mutual inductive coupling and magnetic interference. Guardring placement: Sensitive analog blocks are enclosed by N-well or deep N-well guardrings with spacing 5.0 µm to suppress substrate noise coupling. Differential pair symmetry: Differential signal paths are layout-matched to ensure L 0.5 µm, minimizing mismatch and preserving phase balance. DRC Constraints and Layer Definitions. Table 12 summarizes the DRC constraints applied to key analog components across relevant process layers. Table 13 provides the abbreviations used for metal, contact, and via layers in the 45 nm CMOS process. Table 12: Design rule constraints for key analog components in 45 nm CMOS.\n\n--- Segment 47 ---\nTable 13 provides the abbreviations used for metal, contact, and via layers in the 45 nm CMOS process. Table 12: Design rule constraints for key analog components in 45 nm CMOS. Component Layer Physical Constraint Symbol Value Unit MIM Capacitor (QT, LD, VV, OB) QT LD Minimum Cap Width WMIN 6.05 µm QT LD Maximum Cap Width WMAX 150.0 µm QT LD Cap Length L 6.0 µm VV VV Square Size VV_SIZE 4.0 µm VV VV Spacing VV_SPACE 2.0 µm VV VV to Edge Spacing VV_EDGE_MIN 1.0 µm Resistor (RX, CA, M1) RX Minimum Width WMIN 0.462 µm RX Maximum Width WMAX 5.0 µm RX Minimum Length LMIN 0.4 µm RX Maximum Length LMAX 5.0 µm CA Contact Size CA_SIZE 0.06 µm CA Contact Spacing CA_SPACE 0.10 µm CA CA to Edge Spacing CA_EDGE 0.11 µm Inductor (M3) M3 Minimum Width M3_W_MIN 2.0 µm M3 Maximum Width M3_W_MAX 20.0 µm M3 Minimum Spacing M3_S_MIN 2.0 µm Grid All Layers Minimum Grid Min_Grid 0.005 µm Table 13: Process layer abbreviations in the 45 nm CMOS design flow. Layer Name Description RX Resistor implant or diffusion layer used to define integrated resistor geometries. CA Contact layer forming vias between diffusion poly and the first metal layer (M1). M1 First metal layer, typically used for local interconnects and resistor terminals. M3 Third metal layer, used for wider routing tracks and planar inductor layouts. QT Top metal plate in MIM capacitor structures, providing the upper electrode. LD Lower metal plate in MIM capacitor structures, acting as the bottom electrode. VV Via layer connecting different metal layers, especially in capacitor and dense routing regions. OB Opening blocking layer used to define restricted zones, often to exclude metal or for CMP mask clarity.\n\n--- Segment 48 ---\nVV Via layer connecting different metal layers, especially in capacitor and dense routing regions. OB Opening blocking layer used to define restricted zones, often to exclude metal or for CMP mask clarity. E.2 MIM Capacitor Capacitance Model The total capacitance CN of a metal-insulator-metal (MIM) capacitor is modeled as: CN Ca L W Cp 2 (L W) [fF] 21 (a) MIM capacitor layout (b) Resistor layout (c) Inductor layout Figure 14: Layout views of passive components. (a) MIM capacitor with metal-insulator-metal stack. (b) Resistor layout with matching geometry. (c) Spiral inductor with octagonal turns for optimized area and Q-factor. where L and W are the layout length and width in µm, Ca is the area capacitance density, and Cp is the fringing field contribution per unit length. This model includes both area and perimeter contributions to more accurately reflect layout-dependent capacitance in IC design (see Figure 14(a)). 1. Area Capacitance Term: Ca L W Physical Concept: This term represents the primary (parallel-plate) capacitance formed between the overlapping top and bottom metal layers. It arises from the uniform electric field across the dielectric. Layer Physics Explanation: L W corresponds to the overlap area of the plates. Ca 0.335 fF µm2 is the area capacitance density, derived from: Dielectric permittivity ε of the insulating material. Dielectric thickness d, with C ε d. 2. Perimeter (Fringing) Capacitance Term: Cp 2 (L W) Physical Concept: This term models fringing fields at the plate edges, contributing additional capacitance particularly relevant in small geometries. Layer Physics Explanation: 2 (L W) is the physical perimeter of the capacitor. Cp 0.11 fF µm accounts for the fringing field contribution per unit length. Summary: This composite model enables accurate estimation of MIM capacitance by capturing both parallel-plate and fringing effects. The constants Ca and Cp are typically calibrated using process-specific measurements or electromagnetic simulations.\n\n--- Segment 49 ---\nSummary: This composite model enables accurate estimation of MIM capacitance by capturing both parallel-plate and fringing effects. The constants Ca and Cp are typically calibrated using process-specific measurements or electromagnetic simulations. For a fixed capacitor length L 20 µm and width W [6.05, 150.0] µm, the layout-aware capaci- tance is approximated by: C 6.92 W 4.4 [fF] (4) The corresponding bounding area is estimated from the component s geometric envelope: Bounding_Area 22W 44 [µm2] (5) E.3 N Silicided Polysilicon Resistor Model The resistance of a layout-defined resistor implemented using the ndslires layer is modeled as: R Rs L W W 2Rend δ [Ω] Physical Concept: This structure uses heavily doped N polysilicon overlaid with a silicide layer to reduce resistance. Current flows laterally through the poly-silicide film (see Figure 14(b)), and resistance is shaped by the aspect ratio of the layout as well as process-dependent corrections. Layer Physics Explanation: 22 Rs 17.6 Ω (ohm per square) is the sheet resistance of the silicided poly layer. W 5.0 µm is the drawn width; W 0.048 µm accounts for process-induced width bias. L is the drawn resistor length. Rend 1 Ωmodels terminal resistance due to contact diffusion and current crowding. δ 0.917 Ωaccounts for residual layout-dependent parasitics. Summary: The empirical layout relation used in parameterized generation is: R 3.5007 L 2.917 [Ω] (6) This model is valid for L [0.4, 5.0] µm with fixed width W 5.0 µm. The estimated layout area based on bounding box dimensions is: Bounding_Area 5.2L 8.362 [µm2] (7) E.4 Octagon Spiral Inductor Model Physical Concept: Accurate modeling and layout optimization of planar spiral inductors are critical in analog circuit design. Inductor performance is highly sensitive to parasitic elements, achievable quality factor (Q), and layout constraints imposed by process design rules.\n\n--- Segment 50 ---\nThe estimated layout area based on bounding box dimensions is: Bounding_Area 5.2L 8.362 [µm2] (7) E.4 Octagon Spiral Inductor Model Physical Concept: Accurate modeling and layout optimization of planar spiral inductors are critical in analog circuit design. Inductor performance is highly sensitive to parasitic elements, achievable quality factor (Q), and layout constraints imposed by process design rules. To support accurate performance prediction and inform layout choices, we adopt a modified power-law model that expresses inductance as a function of key geometric parameters. The model is validated against empirical measurements and shows strong agreement with classical analytical formulations. Numerous classical formulations relate inductance to geometric factors such as the number of turns, average diameter, trace width, and inter-turn spacing. Among these, the compact closed-form expressions in RF Microelectronics textbook [30] are widely adopted for their balance of simplicity and accuracy. Building on this foundation, we adopt a reparameterized monomial model that better fits our empirical measurement data: L 2.454 10 4 D 1.21 out W 0.163 D2.836 avg S 0.049 [nH] Layer Physics Explanation: Dout 2(R W 2 ) is the outer diameter, Din 2(R W 2 ) is the inner diameter, Davg (Dout Din) 2 2R is the aver- age diameter, R is the radius in µm, W is the trace width in µm, S is the spacing in µm. Table 14: Measured inductance for one-turn in- ductors with fixed W 10 µm and S 0.0 µm R (µm) 30 40 50 60 L (nH) 0.123 0.170 0.220 0.276 This expression is calibrated using measured data from a series of one-turn inductors fabricated with varying radius (R), while keeping the trace width fixed at W 10 µm and spacing at S 0.0 µm. Table 14 summarizes the measured inductance values used for model fitting.\n\n--- Segment 51 ---\nTable 14: Measured inductance for one-turn in- ductors with fixed W 10 µm and S 0.0 µm R (µm) 30 40 50 60 L (nH) 0.123 0.170 0.220 0.276 This expression is calibrated using measured data from a series of one-turn inductors fabricated with varying radius (R), while keeping the trace width fixed at W 10 µm and spacing at S 0.0 µm. Table 14 summarizes the measured inductance values used for model fitting. Summary: With W and S fixed, inductance simplifies to: L 2.337 10 3 R1.164 [nH] (8) The bounding area is estimated by: Bounding_Area 4R2 108R 440 [µm2] (9) The performance of on-chip inductors is fundamentally influenced by layout-dependent factors such as trace width, metal thickness, and inter-turn spacing. Increasing the trace width (Wind) reduces 23 series resistance by enlarging the conductor s cross-sectional area, thereby improving the quality factor, Q ωL Rseries. However, wider traces also increase parasitic capacitance to adjacent turns and the substrate, which lowers the self-resonance frequency. Metal thickness (Hind) also plays a crucial role in minimizing ohmic losses. At high frequencies, current is confined near the conductor surface due to the skin effect. For copper at 25 GHz, the skin depth δ is approximately 0.41 µm; thus, using a metal layer thicker than 4δ (i.e., 1.6 µm) ensures efficient current flow. However, increasing thickness beyond this threshold yields diminishing returns in Q due to saturation in current penetration. Turn-to-turn spacing (S) affects both inductance and quality factor (Q). Tighter spacing enhances magnetic coupling, thereby increasing inductance density. However, it also intensifies capacitive coupling and dielectric losses particularly in modern CMOS processes with high-k inter-metal dielectrics which can degrade Q. Conversely, excessive spacing reduces inductance without providing a proportionate benefit in loss reduction. As a result, one-turn spiral inductors are commonly favored in RF design due to their low series resistance, minimized parasitics, and improved modeling predictability. These insights guided our design choices for layout-aware inductor implementation.\n\n--- Segment 52 ---\nAs a result, one-turn spiral inductors are commonly favored in RF design due to their low series resistance, minimized parasitics, and improved modeling predictability. These insights guided our design choices for layout-aware inductor implementation. To balance the competing demands of Q optimization, parasitic control, and DRC compliance, we implemented inductors using Metal 3 and set W 10 µm as the default trace width. This width offers a low- resistance path that enhances Q while maintaining manageable parasitic capacitance and sufficient pitch for lithographic reliability. Metal 3 was selected for its favorable trade-off between thickness and routing density it is thick enough to mitigate skin-effect losses at high frequencies while offering sufficient flexibility for compact layout integration. The implemented spiral inductor geometry is shown in Figure 14(c). Table 15 summarizes the DRC-compliant tuning ranges, estimated layout areas, and decomposition strategies for single-cell passive components in our layout library. Table 15: Single-cell passive component limits based on DRC and associated layout area costs. Component Tunable Variable Value Range Area Range Decomposition Rule Resistor Length L 4.32 20.42 Ω 10.44 34.36 µm2 Series if max, parallel if min Capacitor Width W 46.32 1042.4 fF 176 3344 µm2 Parallel if max, series if min Inductor Radius R 0.1 nH 5640 µm2 Continuous radius scaling E.5 Layout Examples of Synthesized Circuits To illustrate the correspondence between schematic and layout representations, we present two representative synthesized circuits: an IFVCO and a DLNA, shown in Figure 15 and Figure 16, respectively. In the IFVCO example, the inductor labeled L3 functions as an RF choke and is excluded from the on-chip layout due to its large area requirement. Instead, it is intended for off-chip implementation at the PCB level and connected to the die via wire bonding. This external connection is indicated by the yellow pad in Figure 15(b), which serves as the wire-bonding interface. Since the current stage of system lacks automated routing, all interconnects in the layout were manually drawn to ensure accurate correspondence with the schematic connectivity. These examples demonstrate that synthesized circuit parameters can be successfully translated into DRC-compliant, physically realizable layouts, bridging the gap between high-level optimization and tapeout-ready design.\n\n--- Segment 53 ---\nSince the current stage of system lacks automated routing, all interconnects in the layout were manually drawn to ensure accurate correspondence with the schematic connectivity. These examples demonstrate that synthesized circuit parameters can be successfully translated into DRC-compliant, physically realizable layouts, bridging the gap between high-level optimization and tapeout-ready design. F Practical Considerations and Limitations F.1 Training and Inference Efficiency Although our codebase supports GPU acceleration, all experiments in this work excluding initial dataset generation were conducted entirely on a MacBook CPU. This highlights the efficiency and accessibility of the FALCON pipeline, which can be executed on modest hardware without 24 (a) Designed IFVCO schematic (b) Layout of designed IFVCO Figure 15: Stage 3 results for a synthesized IFVCO. The schematic (a) reflects optimized parameters to meet the target specification. The layout (b) is DRC-compliant and physically realizable. The final design achieves a mean relative error of 1.3 compared to the target performance. (a) Designed DLNA schematic (b) Layout of designed DLNA Figure 16: Stage 3 results for a synthesized DLNA. The schematic (a) reflects optimized parameters to meet the target specification. The layout (b) is DRC-compliant and physically realizable. The final design achieves a mean relative error of 5.0 compared to the target performance. specialized infrastructure. Our MLP and GNN models contain 207k and 1.4M trainable parameters, respectively, with memory footprints of just 831 KB and 5.6 MB. In Stage 1, the MLP classifier trains in approximately 30 minutes with a batch size of 256 and performs inference in the order of milliseconds per batch. Stage 2 s GNN model takes around 3 days to train on the full dataset using the same batch size and hardware. Fine-tuning on an unseen topology (e.g., RVCO) using 30,000 samples completes in under 30 minutes. In Stage 3, the pretrained GNN is used without retraining to perform layout-constrained parameter inference via gradient-based optimization. Inference is conducted one instance at a time (batch size 1), with typical runtimes under 1 second per circuit. Runtime varies based on the convergence threshold and circuit complexity but remains below 2 3 seconds in the worst case across the full test set.\n\n--- Segment 54 ---\nInference is conducted one instance at a time (batch size 1), with typical runtimes under 1 second per circuit. Runtime varies based on the convergence threshold and circuit complexity but remains below 2 3 seconds in the worst case across the full test set. A solution is considered successful if the predicted performance meets the target within a specified relative error threshold. While tighter thresholds (e.g., 5 ) improve accuracy, they require more optimization steps particularly over large datasets. As a result, both success rate and inference time in Stage 3 are directly influenced by this tolerance, which can be tuned based on design fidelity requirements. 25 F.2 Limitations This work focuses on a representative set of 20 curated analog topologies spanning five circuit families. While this enables rigorous evaluation and benchmarking, extending support to arbitrary user-defined netlists is a natural next step. Notably, our GNN demonstrates strong generalization even to topologies not seen during training (e.g., RVCO), suggesting broad applicability within this space. All interconnect routing in the layout phase is currently performed manually, as the flow does not yet integrate a full analog router. This decision allows precise control over parasitic management and DRC compliance but limits scalability for more complex designs. Integration with automated layout tools can further streamline this process. We do not perform repeated training runs for each model configuration, as the pipeline is designed to be computationally efficient and executable on CPU-only hardware. Unlike benchmarking-focused pipelines, our flow incorporates analog simulation and layout-aware inference, both of which are costly to rerun at scale. Moreover, simulation and layout processes are deterministic, eliminating the need for result averaging over multiple random seeds. 26\n\n