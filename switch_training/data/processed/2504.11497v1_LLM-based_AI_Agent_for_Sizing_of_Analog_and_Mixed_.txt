=== ORIGINAL PDF: 2504.11497v1_LLM-based_AI_Agent_for_Sizing_of_Analog_and_Mixed_.pdf ===\n\nRaw text length: 24316 characters\nCleaned text length: 24043 characters\nNumber of segments: 17\n\n=== CLEANED TEXT ===\n\nLLM-based AI Agent for Sizing of Analog and Mixed Signal Circuit Chang Liu School of Engineering The University of Edinburgh Edinburgh, UK Emmanuel A. Olowe School of Engineering The University of Edinburgh Edinburgh, UK Danial Chitnis School of Engineering The University of Edinburgh Edinburgh, UK Abstract The design of Analog and Mixed-Signal (AMS) in- tegrated circuits (ICs) often involves significant manual effort, especially during the transistor sizing process. While Machine Learning techniques in Electronic Design Automation (EDA) have shown promise in reducing complexity and minimizing human intervention, they still face challenges such as numerous iterations and a lack of knowledge about AMS circuit design. Recently, Large Language Models (LLMs) have demonstrated significant potential across various fields, showing a certain level of knowledge in circuit design and indicating their potential to automate the transistor sizing process. In this work, we propose an LLM-based AI agent for AMS circuit design to assist in the sizing process. By integrating LLMs with external circuit simulation tools and data analysis functions and employing prompt engineering strategies, the agent successfully optimized multiple circuits to achieve target performance metrics. We evaluated the performance of different LLMs to assess their applicability and optimization effectiveness across seven basic circuits, and selected the best-performing model Claude 3.5 Sonnet for further exploration on an operational amplifier, with complementary input stage and class AB output stage. This circuit was evaluated against nine performance metrics, and we conducted experiments under three distinct performance requirement groups. A success rate of up to 60 was achieved for reaching the target requirements. Overall, this work demonstrates the potential of LLMs to improve AMS circuit design. Index Terms Analogue and Mixed-Signal (AMS), Large Lan- guage Models (LLMs), Prompt Engineering. I. INTRODUCTION Analog and mixed-signal (AMS) integrated circuits, such as Analog-to-Digital Converters (ADCs) [1], filters [2], and Power Management Integrated Circuits (PMICs) [3], play a vital role in communication systems and consumer electron- ics. The design process of AMS circuits typically follows a structured flow, beginning with the front-end stages of topology selection and circuit sizing, followed by the back-end tasks of placement and routing, as illustrated in Fig. 1. Among these stages, circuit sizing remains particularly challenging due to its high-dimensional design space and complex trade-offs between performance metrics. This complexity often demands significant human expertise and iterative fine-tuning. Therefore, as a crucial aspect of Electronic Design Automation (EDA), au- tomatic circuit sizing has garnered increasing research interest. [4], [5]. Chang Liu is sponsored by Peter Denyer s Scholarship at The University of Edinburgh Circuit Specification Topology Design Circuit Sizing Topology Design Circuit Sizing Placement Routing Placement Routing Routed Layout Front-end Back-end Fig. 1: Typical circuit design flow The rapid expansion of Machine Learning (ML) techniques has increasingly highlighted its potential for automating circuit design, offering new possibilities for achieving automation in the circuit sizing process. Bayesian Optimization (BO) models transistor sizing as a black-box optimization problem, em- ploying Gaussian Process (GP) regression to efficiently guide the search for optimal solutions [4], [6]. Deep Reinforcement Learning (DRL) further improves sizing efficiency by leverag- ing rewards from iterative simulations, enabling adaptation to complex design spaces [7]. However, these methods operate without domain-specific analog design knowledge, leading to high computational costs and inconsistent performance across varying circuit designs and performance metrics. [8]. Recently, large language models (LLMs) such as Claude 3.5 [9], GPT-4 [10], and Llama 3 [11] have demonstrated excep- tional capabilities in tasks such as natural language processing, code generation, and reasoning. Several studies have explored the use of LLMs to enable automated schematic design for analog circuits. However, few of them focus on sizing. For example, Artisan leverages domain-specific LLMs to auto- mate operational amplifier netlist generation and utilize gm Id method for transistor sizing [12]. Another tool, AmpAgent uti- lizes Retrieval Augmented Generation (RAG) to address LLM s knowledge gaps in multi-stage amplifiers and use conventional algorithms to size the device [13]. LEDRO combined LLMs with optimization techniques TuRBO to iteratively reduce the design space [14]. While these approaches achieve higher suc- cess rates and shorten execution time compared to conventional algorithms, their scope remains limited to basic performance metrics, which are insufficient for addressing the complex and diverse requirements of modern AMS circuit design. In this paper, we propose an LLM-based AI agent to opti- mize the transistor sizing process in AMS circuit design. Our approach integrates large language models (LLMs) with the arXiv:2504.11497v1 [cs.LG] 14 Apr 2025 Output Comparison User input Function Results Function Results VS Modified netlist Reason for changes Modified netlist Reason for changes Read function results Observation Initial Task Update parameters Update parameters in netlist User User Function Calling Prompt for function calling Tool Description Sizing prompt generation Match Match Functions Not match Not match System Prompt Previous and current results Previous and current results Execute Execute Netlist: .title Basic Amplifier Vdd vdd 0 1.8V .end This is a circuit SPICE netlist, please optimise this circuit with a gain , bandwidth... Based on the current results and ..., I'll make the following modifications: 1. Increase the gain: To achieve a gain above... 2. The current bandwidth is already above ... 3. The current phase margin is good , we'll try to maintain it above by Here's the modified netlist: ... LLM dc_simulation ac_simulation trans_simulation run_ngspice Simulation: Analysis: Gm derive operating_point Gain bandwidth delay peak_to_peak phase_margin frequency ... dc_simulation ac_simulation trans_simulation run_ngspice Simulation: Analysis: Gm derive operating_point Gain bandwidth delay peak_to_peak phase_margin frequency ... Task1: Detect circuit type Task2: Nodes extraction Task3: Detect target value Task4: Prompt for function calling Initialize simulation settings or Circuit Type Target Call Call Action Fig. 2: The entire process for circuit sizing with the proposed AI Agent. The process begins with the task decomposition stage, generating four tasks for different stages. Action, observation and comparison formed a ReAct optimization loop. Finally, the agent generates output consisting of reasons for changes and modifications of the netlist for the user. Ngspice simulator and custom data analysis functions, enabling automated in-loop simulations that significantly reduce manual intervention. We evaluate the performance of various LLM APIs across seven basic circuits to assess their applicability in the field of circuit design. Based on this comparison, we select the top-performing model, Claude 3.5 Sonnet, to explore more complex circuit configurations with stricter performance metrics. II. METHODOLOGY The proposed agent takes a circuit netlist and expected performance metrics as user inputs and ultimately generates an optimized netlist that meets the target performance, along with the reasons for parameter adjustments. A. LLM-Based AI Agent The entire process for circuit sizing with the proposed AI Agent begins with task decomposition based on user input. In the optimization process, action, observation, and comparison create a Reasoning and Acting (ReAct) loop [15], where the agent cycles through reasoning (analyzing) and taking action based on its insights. It starts with sizing prompt generation. The agent then selects appropriate functions based on perfor- mance metrics. After executing these functions, it reviews the results and compares them with the user s input to check for alignment. The final output is produced if the results meet the performance criteria. To improve the agent s interpretability, this agent will provide not only the modified netlist but also the reasoning behind each parameter adjustment in every iteration. The entire process for circuit sizing with the proposed AI Agent is shown in Fig. 2. B. Prompt Engineering For optimizing AMS circuits, prompt engineering enables the customization of LLM responses to meet specific design requirements through carefully crafted instructions. In this work, we employ Chain-of-Thought (CoT), a technique that enhances the model s decision-making process by generating intermediate reasoning steps [16]. This approach streamlines the transistor sizing process and ensures more efficient and accurate design optimization. To achieve a COT, we developed a prompt template that consisted of a system prompt, four parameters, and CoT instructions. The system prompt includes constraints such as maintaining the power supply voltage and using the same transistor model. The four main parameters: circuit type, pre- vious results, current results and target performance provide highly relevant context for LLMs, enabling effective in-context learning, which helps LLMs better understand the relationship between performance and parameters. The CoT instructions guide the LLMs to think step by step based on their observation to prompt them to generate new, potentially optimal design points. These points are then simulated, and the results are used to further enrich the context history. C. Simulation in-loop We set up the simulation in-loop by function calling. The functions used for optimization are complex and highly inter- connected, creating a workflow where each step relies on the outputs of the previous one, ensuring a seamless optimization process. Therefore, we utilized CoT to guide the LLM thinking step by step to choose required functions like a human AMS cir- cuit designer, taking into account the entire optimization flow, including selecting the appropriate simulation type based on the required performance metrics, running simulations tool, and analyzing the performance with the corresponding functions. All the functions are pre-defined in the agent by the developer. III. RESULTS A. The Performance of Different LLMs Initially, We evaluate the performance of five LLM APIs Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Haiku, GPT-4o, and GPT-4o mini by optimizing seven different types of circuits. The assessment uses a consistent set of performance metrics and focuses on the number of iterations each LLM needs to successfully optimize a circuit, with a maximum limit of 20 iterations. The results are shown in Fig. 3. Claude 3.5 Sonnet out- performed other LLMs, achieving the highest success rate, the fewest iterations, and the lowest variation, demonstrating strong stability in circuit sizing. GPT-4o showed comparable R-load Diode-load INV NAND OSC XOR 5T-OTA 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 Iterations 58.3 90.0 77.8 42.9 90.9 20.0 90.9 44.4 20.0 Claude 3.5 Sonnet Claude 3 Sonnet Claude 3 Haiku GPT 4o GPT 4o mini Fig. 3: Performance comparison of different LLMs. This chart compares the performance of various LLMs across different circuits within 20 iterations. The height of the bars represents the average number of iterations, with lower values indicating better optimization performance. Error bars show the range of iterations observed across ten attempts. In each attempt, exceeding 20 iterations is considered a failure. The success rate smaller than 100 is labelled on the bar. Hatched bars indicate that the model failed to optimize specific circuits in all ten attempts. All the tests were performed in September of 2024. VDD M1 M2 Vout CL Vinn Vinp Vinp Vinn Vbias2 RL CC2 CC1 M7 M8 M9 M10 M11 M12 Vbias1 Vbias3 Vbias5 Vbias4 M13 M14 M15 M16 M17 M18 M19 M20 M3 M4 M5 M6 Vbias6 Fig. 4: Schematic of the tested opamp, featuring a complementary input stage and a class AB output stage. performance but failed on the 5T-OTA. Claude 3 Sonnet and GPT-4o mini exhibited similar results, with lower success rates and higher variability, especially for NAND and XOR gates. Claude 3 Haiku performed well on digital circuits but failed on the oscillator and 5T-OTA. Therefore, we use Claude 3.5 Sonnet for further exploration in more complex circuit design tasks. B. An Operational Amplifier The agent is employed to optimize an opamp with a comple- mentary input stage and class AB output stage, which is consist of 20 transistors [17]. The schematic is shown in Fig. 4. We consider nine performance metrics of opamps in three configuration groups. These three groups, named G1, G2, and G3 differ in bandwidth, output load, and power. In all groups, the supply voltage is 1.8 V, and the transistor model is PTM 180 nm [18]. Table. I shows the performance metrics of each group, including the passed and failed attempts and success rate among five independent trials. The optimization process of the opamp under G1 is illus- trated in Fig. 5. Fig. 5 (e) and Fig. 5 (f) underscore the challenges in achieving low input offset voltage and high output voltage range targets. Power consumption increases due to the high drive requirements for wide output swing. Despite TABLE I: Performance evaluation for 5 attempts across three groups (G1, G2 and G3). A 5 tolerance is applied to all metrics; deviations beyond this tolerance are marked in red. Different targets for G1 and G2, G1 and G3 are marked in bold. If the 25 iteration is reached without meeting any target, it is marked as a failure. Group Gain (dB) UGBW (MHz) PM ( ) Power (mW) CMRR (dB) THD (dB) CL (F) RL(Ω) Offset (V) Output Range (V) Iter G1 Target 65 10 55 10 100 26 10P, 1k 1 1.75 25 G1-1 67.91 19.95 61.59 4.8 110.76 -26.06 10P, 1k 0.98 1.68 13 G1-2 68.63 19.95 72.26 13.22 97.63 -26.09 10P, 1k 5.30 1.24 fail G1-3 68.57 15.85 71.75 4.53 118.61 -26.02 10P, 1k 0.16 1.32 fail G1-4 66.07 12.58 54.50 7.69 124.13 -25.42 10P, 1k 0.40 1.68 20 G1-5 66.45 50.12 60.59 7.43 105.62 -26.24 10P, 1k 0.69 1.67 23 G2 Target 65 5 45 5 100 26 50P, 100k 1 1.75 25 G2-1 58.73 5.01 78.98 4.2 100.89 -25.89 50P, 100k 1.80 1.67 fail G2-2 66.76 12.59 34.14 1.2 131.64 -24.75 50P, 100k 4.50 1.77 fail G2-3 63.27 9.99 52.34 1.5 111.34 -25.98 50P, 100k 0.99 1.69 16 G2-4 62.19 7.94 55.19 0.7 131.19 -26.29 50P, 100k 0.42 1.70 25 G2-5 66.74 15.85 63.44 4.9 112.01 -26.29 50P, 100k 0.86 1.70 24 G3 Target 65 50 55 50 100 26 10P, 1k 5 1.7 25 G3-1 50.97 99.99 56.04 15.83 93.70 -30.16 10P, 1k 5.16 1.66 fail G3-2 68.91 63.09 64.55 20.27 96.77 -24.68 10P, 1k 4.30 1.39 fail G3-3 58.97 50.12 73.84 4.12 95.74 -41.57 10P, 1k 42.25 0.68 fail G3-4 69.33 63.09 67.82 10.08 108.78 -27.22 10P, 1k 2.70 1.65 11 G3-5 68.38 79.43 51.21 47.01 81.73 -32.62 10P, 1k 14.27 1.69 fail fluctuations in all the figures, the agent succeeds in 3 out of 5 attempts within 25 iterations, proving the effectiveness of in-context learning and our prompt strategy. For G2, targeting low power and a higher load capacitor, unity-gain bandwidth and phase margin constraints were re- laxed to account for trade-offs with the load. The agent achieved a 60 success rate within 25 iterations. For G3, it prioritized a higher bandwidth and power relative to G1 and G2. The transistor sizes and bias voltages belonging to a successful attempt of each configuration group are shown in Table II. To further verify the applicability of the optimized circuit, we conducted various tests, including DC, transient and parametric variations on circuit G1-5. These variations include transistor sizes and bias voltages. The results from these tests are shown in Fig. 6, which confirm design robustness and suitability for practical use under varying conditions. IV. DISCUSSION This work found that the proposed LLM-based agent can effectively propose circuit optimization strategies based on 25 0 25 50 75 Gain (dB) (a) 50 75 100 125 150 UGBW (dB) (b) 0 25 50 75 100 Phase Margin ( ) (c) 0.000 0.005 0.010 0.015 Power (W) (d) 0.0 0.5 1.0 1.5 Output Voltage (V) (e) 0.000 0.005 0.010 0.015 Offset (V) (f) 0 5 10 15 20 25 Iterations 50 75 100 125 150 CMRR (dB) (g) 0 5 10 15 20 25 Iterations 40 35 30 25 20 15 THD (dB) (h) Attempt 1 Attempt 2 Attempt 3 Attempt 4 Attempt 5 Target Range Fig. 5: Optimization results for the opamp. (a) Gain (b) Unity-Gain Bandwidth (c) Phase Margin (d) Power (e) Input Offset (f) Output Voltage Range (g) CMRR (h) THD. (b) and (e) are tested under unity gain configuration, others are tested open loop. (a), (b), (c), (d) and (g) are tested at Vin,cm 0.9 V, (e), (f), (h) are tested across the Vin from 0 to 1.8 V. Those already in the target range initially or after a few iterations may still fluctuate or even get worse due to the optimization process prioritizing other performance metrics. This occurs because the agent has not yet achieved a balance between all required performance criteria. TABLE II: Transistor size and bias voltages for G1-5, G2-4 and G3-4 after optimization Transistor G1-5 (W L, µm µm) G2-4 (W L, µm µm) G3-4 (W L, µm µm) M1, M2 53 1.85 65 0.48 23 0.2 M3, M4 53 1.85 32 0.48 11.5 0.2 M5 9 0.45 2.5 0.46 15 0.6 M6 9 0.45 5 0.46 15 0.6 M7, M8 80 1.8 25.5 0.46 20 0.22 M9, M10 80 1.8 25.5 0.46 20 0.22 M11, M12 6 0.45 4.3 0.42 8 0.2 M13, M14 5 0.45 3.7 0.385 8 0.2 M15, M17 15 0.9 5.8 0.51 11 0.18 M16, M18 30 0.9 11.6 0.51 22 0.18 M19 340 0.43 90 0.53 100 0.18 M20 170 0.43 45 0.53 50 0.18 bias1 0.88 0.89 0.75 bias2 1.05 0.95 1.1 bias3 0.46 0.71 1.13 bias4 1.15 1.20 0.93 bias5 1.36 1.22 0.92 bias6 0.17 0.55 1.22 previous and current performance to balance various metrics, demonstrating the potential of LLMs in the circuit sizing process. However, some limitations remain. Firstly, the circuit under test relies on bias voltages due to the complexity of biasing circuits, which needs to be replaced with a current mirror network. The overall area of transistors is excluded in this study as the focus remains on performance optimization. Future work should integrate area and layout considerations for a holistic PPA trade-off. Secondly, the open-loop and closed-loop configurations of 0.0 0.5 1.0 1.5 Vin (V) 0.000 0.002 0.004 Voffset (V) (a) 0.0 0.5 1.0 1.5 Vout (V) 0 20 40 60 DC Gain (dB) (b) 102 103 104 105 RL ( ) 58 60 62 64 66 DC Gain (dB) (c) 0.0 0.5 1.0 1.5 Vin,cm (V) 80 100 120 140 CMRR (dB) (d) Variation 0 Variation 1 Variation 2 Variation 3 Variation 4 Variation 5 Variation 6 Variation 7 Variation 8 Variation 9 Fig. 6: Variation results for G1-5. (a) Input Offset Voltage vs. Common-Mode Input. (b) DC Gain vs. Output Voltage (c) DC Gain vs. Load Resistor. (d) CMRR vs. Common Mode Input. Random variations following a Gaussian distribution with a mean (µ) of 0 and a standard deviation (σ) of 0.1 are added to bias voltages and σ of 0.01 for transistor size. the op-amp are tested with a common-mode voltage at half- rail. While the design targets rail-to-rail output with a 1.75 V output range, the input common-mode range is not targeted and optimized, leading to variations in CMRR and DC gain across the input range. Future work should simulate dynamic parameters across the full range for true rail-to-rail input output performance. Additionally, high variations can be seen in the variation test, especially in Fig. 6 (c) and (d). A true Monte Carlo simulations with accurate device models are needed for the agent to ensure the design robustness. Moreover, opti- mization was limited to 25 iterations and 5 trials due to rate limits, potentially restricting performance insights and affecting the reliability of the results. However, more iterations don t ensure convergence, as LLMs may oscillate between solutions. A feedback mechanism should be introduced to prompt diverse solutions and improve reliability. V. CONCLUSION This work utilizes LLMs to build an AI Agent for the AMS circuit sizing process. By employing function-calling techniques, the LLMs are integrated with the external simulator Ngspice and data analysis functions, Additionally, using prompt engineering strategies, such as CoT and in-context learning, the agent leverages contextual information from previous iterations to guide the LLMs in sizing, leading to a reduced the number of iterations. As a result, the proposed agent optimized seven small-sized circuits, including a twenty-transistor rail-to-rail opamp. This agent demonstrates the potential for optimizing more complex circuits and systems in the future. The source code for this project is available on ACKNOWLEDGEMENTS The authors thank EDINA and of Edin- burgh for their support in accessing OpenAI services. REFERENCES [1] R. H. Walden, Analog-to-digital converter survey and analysis, IEEE Journal on selected areas in communications, vol. 17, no. 4, pp. 539 550, 1999. [2] S. Winder, Analog and digital filter design. Elsevier, 2002. [3] A. Ballo, M. Bottaro, and A. D. Grasso, A review of power management integrated circuits for ultrasound-based energy harvesting in implantable medical devices, Applied Sciences, vol. 11, no. 6, p. 2487, 2021. [4] W. Lyu, F. Yang, C. Yan et al., Batch bayesian optimization via multi- objective acquisition ensemble for automated analog circuit design, in International conference on machine learning. PMLR, 2018, pp. 3306 3314. [5] T. Liao and L. Zhang, Parasitic-aware gp-based many-objective sizing methodology for analog and rf integrated circuits, in 2017 22nd Asia and South Pacific Design Automation Conference (ASP-DAC). IEEE, 2017, pp. 475 480. [6] K. Touloupas, N. Chouridis, and P. P. Sotiriadis, Local Bayesian op- timization for analog circuit sizing, in 2021 58th ACM IEEE Design Automation Conference (DAC). IEEE, 2021, pp. 1237 1242. [7] Z. Zhao and L. Zhang, Analog integrated circuit topology synthesis with deep reinforcement learning, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 41, no. 12, pp. 5138 5151, 2022. [8] K. Settaluri, A. Haj-Ali, and e. a. Huang, Qijing, Autockt: Deep rein- forcement learning of analog circuit designs, in 2020 Design, Automation Test in Europe Conference Exhibition (DATE). IEEE, 2020, pp. 490 495. [9] The Claude 3 Model Family: Opus, Sonnet, Haiku. [Online]. Available: [10] J. Achiam, S. Adler, S. Agarwal et al., Gpt-4 technical report, arXiv preprint arXiv:2303.08774, 2023. [11] H. Touvron, T. Lavril, G. Izacard et al., Llama: Open and efficient foundation language models, arXiv preprint arXiv:2302.13971, 2023. [12] Z. Chen, J. Huang, Y. Liu, and others., Artisan: Automated operational amplifier design via domain-specific large language model, in Proceed- ings of the 61st ACM IEEE Design Automation Conference, 2024, pp. 1 6. [13] C. Liu, W. Chen, A. Peng et al., Ampagent: An llm-based multi- agent system for multi-stage amplifier schematic design from literature for process and performance porting, arXiv preprint arXiv:2409.14739, 2024. [14] D. V. Kochar, H. Wang, A. Chandrakasan et al., Ledro: Llm-enhanced design space reduction and optimization for analog circuits, arXiv preprint arXiv:2411.12930, 2024. [15] S. Yao, J. Zhao, D. Yu et al., React: Synergizing reasoning and acting in language models, arXiv preprint arXiv:2210.03629, 2022. [16] J. Wei, X. Wang, D. Schuurmans et al., Chain-of-thought prompting elic- its reasoning in large language models, Advances in neural information processing systems, vol. 35, pp. 24 824 24 837, 2022. [17] R. Hogervorst, J. P. Tero, R. G. Eschauzier et al., A compact power- efficient 3 v cmos rail-to-rail input output operational amplifier for vlsi cell libraries, IEEE journal of solid-state circuits, vol. 29, no. 12, pp. 1505 1513, 1994. [18] Y. Cao, Predictive technology model for robust nanoelectronic design. Springer Science Business Media, 2011.\n\n=== SEGMENTS ===\n\n--- Segment 1 ---\nLLM-based AI Agent for Sizing of Analog and Mixed Signal Circuit Chang Liu School of Engineering The University of Edinburgh Edinburgh, UK Emmanuel A. Olowe School of Engineering The University of Edinburgh Edinburgh, UK Danial Chitnis School of Engineering The University of Edinburgh Edinburgh, UK Abstract The design of Analog and Mixed-Signal (AMS) in- tegrated circuits (ICs) often involves significant manual effort, especially during the transistor sizing process. While Machine Learning techniques in Electronic Design Automation (EDA) have shown promise in reducing complexity and minimizing human intervention, they still face challenges such as numerous iterations and a lack of knowledge about AMS circuit design. Recently, Large Language Models (LLMs) have demonstrated significant potential across various fields, showing a certain level of knowledge in circuit design and indicating their potential to automate the transistor sizing process. In this work, we propose an LLM-based AI agent for AMS circuit design to assist in the sizing process. By integrating LLMs with external circuit simulation tools and data analysis functions and employing prompt engineering strategies, the agent successfully optimized multiple circuits to achieve target performance metrics. We evaluated the performance of different LLMs to assess their applicability and optimization effectiveness across seven basic circuits, and selected the best-performing model Claude 3.5 Sonnet for further exploration on an operational amplifier, with complementary input stage and class AB output stage. This circuit was evaluated against nine performance metrics, and we conducted experiments under three distinct performance requirement groups. A success rate of up to 60 was achieved for reaching the target requirements. Overall, this work demonstrates the potential of LLMs to improve AMS circuit design. Index Terms Analogue and Mixed-Signal (AMS), Large Lan- guage Models (LLMs), Prompt Engineering. I. INTRODUCTION Analog and mixed-signal (AMS) integrated circuits, such as Analog-to-Digital Converters (ADCs) [1], filters [2], and Power Management Integrated Circuits (PMICs) [3], play a vital role in communication systems and consumer electron- ics. The design process of AMS circuits typically follows a structured flow, beginning with the front-end stages of topology selection and circuit sizing, followed by the back-end tasks of placement and routing, as illustrated in Fig. 1. Among these stages, circuit sizing remains particularly challenging due to its high-dimensional design space and complex trade-offs between performance metrics.\n\n--- Segment 2 ---\n1. Among these stages, circuit sizing remains particularly challenging due to its high-dimensional design space and complex trade-offs between performance metrics. This complexity often demands significant human expertise and iterative fine-tuning. Therefore, as a crucial aspect of Electronic Design Automation (EDA), au- tomatic circuit sizing has garnered increasing research interest. [4], [5]. Chang Liu is sponsored by Peter Denyer s Scholarship at The University of Edinburgh Circuit Specification Topology Design Circuit Sizing Topology Design Circuit Sizing Placement Routing Placement Routing Routed Layout Front-end Back-end Fig. 1: Typical circuit design flow The rapid expansion of Machine Learning (ML) techniques has increasingly highlighted its potential for automating circuit design, offering new possibilities for achieving automation in the circuit sizing process. Bayesian Optimization (BO) models transistor sizing as a black-box optimization problem, em- ploying Gaussian Process (GP) regression to efficiently guide the search for optimal solutions [4], [6]. Deep Reinforcement Learning (DRL) further improves sizing efficiency by leverag- ing rewards from iterative simulations, enabling adaptation to complex design spaces [7]. However, these methods operate without domain-specific analog design knowledge, leading to high computational costs and inconsistent performance across varying circuit designs and performance metrics. [8]. Recently, large language models (LLMs) such as Claude 3.5 [9], GPT-4 [10], and Llama 3 [11] have demonstrated excep- tional capabilities in tasks such as natural language processing, code generation, and reasoning. Several studies have explored the use of LLMs to enable automated schematic design for analog circuits. However, few of them focus on sizing. For example, Artisan leverages domain-specific LLMs to auto- mate operational amplifier netlist generation and utilize gm Id method for transistor sizing [12]. Another tool, AmpAgent uti- lizes Retrieval Augmented Generation (RAG) to address LLM s knowledge gaps in multi-stage amplifiers and use conventional algorithms to size the device [13]. LEDRO combined LLMs with optimization techniques TuRBO to iteratively reduce the design space [14]. While these approaches achieve higher suc- cess rates and shorten execution time compared to conventional algorithms, their scope remains limited to basic performance metrics, which are insufficient for addressing the complex and diverse requirements of modern AMS circuit design.\n\n--- Segment 3 ---\nLEDRO combined LLMs with optimization techniques TuRBO to iteratively reduce the design space [14]. While these approaches achieve higher suc- cess rates and shorten execution time compared to conventional algorithms, their scope remains limited to basic performance metrics, which are insufficient for addressing the complex and diverse requirements of modern AMS circuit design. In this paper, we propose an LLM-based AI agent to opti- mize the transistor sizing process in AMS circuit design. Our approach integrates large language models (LLMs) with the arXiv:2504.11497v1 [cs.LG] 14 Apr 2025 Output Comparison User input Function Results Function Results VS Modified netlist Reason for changes Modified netlist Reason for changes Read function results Observation Initial Task Update parameters Update parameters in netlist User User Function Calling Prompt for function calling Tool Description Sizing prompt generation Match Match Functions Not match Not match System Prompt Previous and current results Previous and current results Execute Execute Netlist: .title Basic Amplifier Vdd vdd 0 1.8V .end This is a circuit SPICE netlist, please optimise this circuit with a gain , bandwidth... Based on the current results and ..., I'll make the following modifications: 1. Increase the gain: To achieve a gain above... 2. The current bandwidth is already above ... 3. The current phase margin is good , we'll try to maintain it above by Here's the modified netlist: ... LLM dc_simulation ac_simulation trans_simulation run_ngspice Simulation: Analysis: Gm derive operating_point Gain bandwidth delay peak_to_peak phase_margin frequency ... dc_simulation ac_simulation trans_simulation run_ngspice Simulation: Analysis: Gm derive operating_point Gain bandwidth delay peak_to_peak phase_margin frequency ... Task1: Detect circuit type Task2: Nodes extraction Task3: Detect target value Task4: Prompt for function calling Initialize simulation settings or Circuit Type Target Call Call Action Fig. 2: The entire process for circuit sizing with the proposed AI Agent. The process begins with the task decomposition stage, generating four tasks for different stages. Action, observation and comparison formed a ReAct optimization loop. Finally, the agent generates output consisting of reasons for changes and modifications of the netlist for the user. Ngspice simulator and custom data analysis functions, enabling automated in-loop simulations that significantly reduce manual intervention.\n\n--- Segment 4 ---\nFinally, the agent generates output consisting of reasons for changes and modifications of the netlist for the user. Ngspice simulator and custom data analysis functions, enabling automated in-loop simulations that significantly reduce manual intervention. We evaluate the performance of various LLM APIs across seven basic circuits to assess their applicability in the field of circuit design. Based on this comparison, we select the top-performing model, Claude 3.5 Sonnet, to explore more complex circuit configurations with stricter performance metrics. II. METHODOLOGY The proposed agent takes a circuit netlist and expected performance metrics as user inputs and ultimately generates an optimized netlist that meets the target performance, along with the reasons for parameter adjustments. A. LLM-Based AI Agent The entire process for circuit sizing with the proposed AI Agent begins with task decomposition based on user input. In the optimization process, action, observation, and comparison create a Reasoning and Acting (ReAct) loop [15], where the agent cycles through reasoning (analyzing) and taking action based on its insights. It starts with sizing prompt generation. The agent then selects appropriate functions based on perfor- mance metrics. After executing these functions, it reviews the results and compares them with the user s input to check for alignment. The final output is produced if the results meet the performance criteria. To improve the agent s interpretability, this agent will provide not only the modified netlist but also the reasoning behind each parameter adjustment in every iteration. The entire process for circuit sizing with the proposed AI Agent is shown in Fig. 2. B. Prompt Engineering For optimizing AMS circuits, prompt engineering enables the customization of LLM responses to meet specific design requirements through carefully crafted instructions. In this work, we employ Chain-of-Thought (CoT), a technique that enhances the model s decision-making process by generating intermediate reasoning steps [16]. This approach streamlines the transistor sizing process and ensures more efficient and accurate design optimization. To achieve a COT, we developed a prompt template that consisted of a system prompt, four parameters, and CoT instructions. The system prompt includes constraints such as maintaining the power supply voltage and using the same transistor model. The four main parameters: circuit type, pre- vious results, current results and target performance provide highly relevant context for LLMs, enabling effective in-context learning, which helps LLMs better understand the relationship between performance and parameters.\n\n--- Segment 5 ---\nThe system prompt includes constraints such as maintaining the power supply voltage and using the same transistor model. The four main parameters: circuit type, pre- vious results, current results and target performance provide highly relevant context for LLMs, enabling effective in-context learning, which helps LLMs better understand the relationship between performance and parameters. The CoT instructions guide the LLMs to think step by step based on their observation to prompt them to generate new, potentially optimal design points. These points are then simulated, and the results are used to further enrich the context history. C. Simulation in-loop We set up the simulation in-loop by function calling. The functions used for optimization are complex and highly inter- connected, creating a workflow where each step relies on the outputs of the previous one, ensuring a seamless optimization process. Therefore, we utilized CoT to guide the LLM thinking step by step to choose required functions like a human AMS cir- cuit designer, taking into account the entire optimization flow, including selecting the appropriate simulation type based on the required performance metrics, running simulations tool, and analyzing the performance with the corresponding functions. All the functions are pre-defined in the agent by the developer. III. RESULTS A. The Performance of Different LLMs Initially, We evaluate the performance of five LLM APIs Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Haiku, GPT-4o, and GPT-4o mini by optimizing seven different types of circuits. The assessment uses a consistent set of performance metrics and focuses on the number of iterations each LLM needs to successfully optimize a circuit, with a maximum limit of 20 iterations. The results are shown in Fig. 3. Claude 3.5 Sonnet out- performed other LLMs, achieving the highest success rate, the fewest iterations, and the lowest variation, demonstrating strong stability in circuit sizing. GPT-4o showed comparable R-load Diode-load INV NAND OSC XOR 5T-OTA 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 Iterations 58.3 90.0 77.8 42.9 90.9 20.0 90.9 44.4 20.0 Claude 3.5 Sonnet Claude 3 Sonnet Claude 3 Haiku GPT 4o GPT 4o mini Fig. 3: Performance comparison of different LLMs.\n\n--- Segment 6 ---\nGPT-4o showed comparable R-load Diode-load INV NAND OSC XOR 5T-OTA 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 Iterations 58.3 90.0 77.8 42.9 90.9 20.0 90.9 44.4 20.0 Claude 3.5 Sonnet Claude 3 Sonnet Claude 3 Haiku GPT 4o GPT 4o mini Fig. 3: Performance comparison of different LLMs. This chart compares the performance of various LLMs across different circuits within 20 iterations. The height of the bars represents the average number of iterations, with lower values indicating better optimization performance. Error bars show the range of iterations observed across ten attempts. In each attempt, exceeding 20 iterations is considered a failure. The success rate smaller than 100 is labelled on the bar. Hatched bars indicate that the model failed to optimize specific circuits in all ten attempts. All the tests were performed in September of 2024. VDD M1 M2 Vout CL Vinn Vinp Vinp Vinn Vbias2 RL CC2 CC1 M7 M8 M9 M10 M11 M12 Vbias1 Vbias3 Vbias5 Vbias4 M13 M14 M15 M16 M17 M18 M19 M20 M3 M4 M5 M6 Vbias6 Fig. 4: Schematic of the tested opamp, featuring a complementary input stage and a class AB output stage. performance but failed on the 5T-OTA. Claude 3 Sonnet and GPT-4o mini exhibited similar results, with lower success rates and higher variability, especially for NAND and XOR gates. Claude 3 Haiku performed well on digital circuits but failed on the oscillator and 5T-OTA. Therefore, we use Claude 3.5 Sonnet for further exploration in more complex circuit design tasks. B. An Operational Amplifier The agent is employed to optimize an opamp with a comple- mentary input stage and class AB output stage, which is consist of 20 transistors [17]. The schematic is shown in Fig. 4. We consider nine performance metrics of opamps in three configuration groups. These three groups, named G1, G2, and G3 differ in bandwidth, output load, and power.\n\n--- Segment 7 ---\nWe consider nine performance metrics of opamps in three configuration groups. These three groups, named G1, G2, and G3 differ in bandwidth, output load, and power. In all groups, the supply voltage is 1.8 V, and the transistor model is PTM 180 nm [18]. Table. I shows the performance metrics of each group, including the passed and failed attempts and success rate among five independent trials. The optimization process of the opamp under G1 is illus- trated in Fig. 5. Fig. 5 (e) and Fig. 5 (f) underscore the challenges in achieving low input offset voltage and high output voltage range targets. Power consumption increases due to the high drive requirements for wide output swing. Despite TABLE I: Performance evaluation for 5 attempts across three groups (G1, G2 and G3). A 5 tolerance is applied to all metrics; deviations beyond this tolerance are marked in red. Different targets for G1 and G2, G1 and G3 are marked in bold. If the 25 iteration is reached without meeting any target, it is marked as a failure.\n\n--- Segment 8 ---\nDifferent targets for G1 and G2, G1 and G3 are marked in bold. If the 25 iteration is reached without meeting any target, it is marked as a failure. Group Gain (dB) UGBW (MHz) PM ( ) Power (mW) CMRR (dB) THD (dB) CL (F) RL(Ω) Offset (V) Output Range (V) Iter G1 Target 65 10 55 10 100 26 10P, 1k 1 1.75 25 G1-1 67.91 19.95 61.59 4.8 110.76 -26.06 10P, 1k 0.98 1.68 13 G1-2 68.63 19.95 72.26 13.22 97.63 -26.09 10P, 1k 5.30 1.24 fail G1-3 68.57 15.85 71.75 4.53 118.61 -26.02 10P, 1k 0.16 1.32 fail G1-4 66.07 12.58 54.50 7.69 124.13 -25.42 10P, 1k 0.40 1.68 20 G1-5 66.45 50.12 60.59 7.43 105.62 -26.24 10P, 1k 0.69 1.67 23 G2 Target 65 5 45 5 100 26 50P, 100k 1 1.75 25 G2-1 58.73 5.01 78.98 4.2 100.89 -25.89 50P, 100k 1.80 1.67 fail G2-2 66.76 12.59 34.14 1.2 131.64 -24.75 50P, 100k 4.50 1.77 fail G2-3 63.27 9.99 52.34 1.5 111.34 -25.98 50P, 100k 0.99 1.69 16 G2-4 62.19 7.94 55.19 0.7 131.19 -26.29 50P, 100k 0.42 1.70 25 G2-5 66.74 15.85 63.44 4.9 112.01 -26.29 50P, 100k 0.86 1.70 24 G3 Target 65 50 55 50 100 26 10P, 1k 5 1.7 25 G3-1 50.97 99.99 56.04 15.83 93.70 -30.16 10P, 1k 5.16 1.66 fail G3-2 68.91 63.09 64.55 20.27 96.77 -24.68 10P, 1k 4.30 1.39 fail G3-3 58.97 50.12 73.84 4.12 95.74 -41.57 10P, 1k 42.25 0.68 fail G3-4 69.33 63.09 67.82 10.08 108.78 -27.22 10P, 1k 2.70 1.65 11 G3-5 68.38 79.43 51.21 47.01 81.73 -32.62 10P, 1k 14.27 1.69 fail fluctuations in all the figures, the agent succeeds in 3 out of 5 attempts within 25 iterations, proving the effectiveness of in-context learning and our prompt strategy.\n\n--- Segment 9 ---\nIf the 25 iteration is reached without meeting any target, it is marked as a failure. Group Gain (dB) UGBW (MHz) PM ( ) Power (mW) CMRR (dB) THD (dB) CL (F) RL(Ω) Offset (V) Output Range (V) Iter G1 Target 65 10 55 10 100 26 10P, 1k 1 1.75 25 G1-1 67.91 19.95 61.59 4.8 110.76 -26.06 10P, 1k 0.98 1.68 13 G1-2 68.63 19.95 72.26 13.22 97.63 -26.09 10P, 1k 5.30 1.24 fail G1-3 68.57 15.85 71.75 4.53 118.61 -26.02 10P, 1k 0.16 1.32 fail G1-4 66.07 12.58 54.50 7.69 124.13 -25.42 10P, 1k 0.40 1.68 20 G1-5 66.45 50.12 60.59 7.43 105.62 -26.24 10P, 1k 0.69 1.67 23 G2 Target 65 5 45 5 100 26 50P, 100k 1 1.75 25 G2-1 58.73 5.01 78.98 4.2 100.89 -25.89 50P, 100k 1.80 1.67 fail G2-2 66.76 12.59 34.14 1.2 131.64 -24.75 50P, 100k 4.50 1.77 fail G2-3 63.27 9.99 52.34 1.5 111.34 -25.98 50P, 100k 0.99 1.69 16 G2-4 62.19 7.94 55.19 0.7 131.19 -26.29 50P, 100k 0.42 1.70 25 G2-5 66.74 15.85 63.44 4.9 112.01 -26.29 50P, 100k 0.86 1.70 24 G3 Target 65 50 55 50 100 26 10P, 1k 5 1.7 25 G3-1 50.97 99.99 56.04 15.83 93.70 -30.16 10P, 1k 5.16 1.66 fail G3-2 68.91 63.09 64.55 20.27 96.77 -24.68 10P, 1k 4.30 1.39 fail G3-3 58.97 50.12 73.84 4.12 95.74 -41.57 10P, 1k 42.25 0.68 fail G3-4 69.33 63.09 67.82 10.08 108.78 -27.22 10P, 1k 2.70 1.65 11 G3-5 68.38 79.43 51.21 47.01 81.73 -32.62 10P, 1k 14.27 1.69 fail fluctuations in all the figures, the agent succeeds in 3 out of 5 attempts within 25 iterations, proving the effectiveness of in-context learning and our prompt strategy. For G2, targeting low power and a higher load capacitor, unity-gain bandwidth and phase margin constraints were re- laxed to account for trade-offs with the load.\n\n--- Segment 10 ---\nGroup Gain (dB) UGBW (MHz) PM ( ) Power (mW) CMRR (dB) THD (dB) CL (F) RL(Ω) Offset (V) Output Range (V) Iter G1 Target 65 10 55 10 100 26 10P, 1k 1 1.75 25 G1-1 67.91 19.95 61.59 4.8 110.76 -26.06 10P, 1k 0.98 1.68 13 G1-2 68.63 19.95 72.26 13.22 97.63 -26.09 10P, 1k 5.30 1.24 fail G1-3 68.57 15.85 71.75 4.53 118.61 -26.02 10P, 1k 0.16 1.32 fail G1-4 66.07 12.58 54.50 7.69 124.13 -25.42 10P, 1k 0.40 1.68 20 G1-5 66.45 50.12 60.59 7.43 105.62 -26.24 10P, 1k 0.69 1.67 23 G2 Target 65 5 45 5 100 26 50P, 100k 1 1.75 25 G2-1 58.73 5.01 78.98 4.2 100.89 -25.89 50P, 100k 1.80 1.67 fail G2-2 66.76 12.59 34.14 1.2 131.64 -24.75 50P, 100k 4.50 1.77 fail G2-3 63.27 9.99 52.34 1.5 111.34 -25.98 50P, 100k 0.99 1.69 16 G2-4 62.19 7.94 55.19 0.7 131.19 -26.29 50P, 100k 0.42 1.70 25 G2-5 66.74 15.85 63.44 4.9 112.01 -26.29 50P, 100k 0.86 1.70 24 G3 Target 65 50 55 50 100 26 10P, 1k 5 1.7 25 G3-1 50.97 99.99 56.04 15.83 93.70 -30.16 10P, 1k 5.16 1.66 fail G3-2 68.91 63.09 64.55 20.27 96.77 -24.68 10P, 1k 4.30 1.39 fail G3-3 58.97 50.12 73.84 4.12 95.74 -41.57 10P, 1k 42.25 0.68 fail G3-4 69.33 63.09 67.82 10.08 108.78 -27.22 10P, 1k 2.70 1.65 11 G3-5 68.38 79.43 51.21 47.01 81.73 -32.62 10P, 1k 14.27 1.69 fail fluctuations in all the figures, the agent succeeds in 3 out of 5 attempts within 25 iterations, proving the effectiveness of in-context learning and our prompt strategy. For G2, targeting low power and a higher load capacitor, unity-gain bandwidth and phase margin constraints were re- laxed to account for trade-offs with the load. The agent achieved a 60 success rate within 25 iterations.\n\n--- Segment 11 ---\nFor G2, targeting low power and a higher load capacitor, unity-gain bandwidth and phase margin constraints were re- laxed to account for trade-offs with the load. The agent achieved a 60 success rate within 25 iterations. For G3, it prioritized a higher bandwidth and power relative to G1 and G2. The transistor sizes and bias voltages belonging to a successful attempt of each configuration group are shown in Table II. To further verify the applicability of the optimized circuit, we conducted various tests, including DC, transient and parametric variations on circuit G1-5. These variations include transistor sizes and bias voltages. The results from these tests are shown in Fig. 6, which confirm design robustness and suitability for practical use under varying conditions. IV. DISCUSSION This work found that the proposed LLM-based agent can effectively propose circuit optimization strategies based on 25 0 25 50 75 Gain (dB) (a) 50 75 100 125 150 UGBW (dB) (b) 0 25 50 75 100 Phase Margin ( ) (c) 0.000 0.005 0.010 0.015 Power (W) (d) 0.0 0.5 1.0 1.5 Output Voltage (V) (e) 0.000 0.005 0.010 0.015 Offset (V) (f) 0 5 10 15 20 25 Iterations 50 75 100 125 150 CMRR (dB) (g) 0 5 10 15 20 25 Iterations 40 35 30 25 20 15 THD (dB) (h) Attempt 1 Attempt 2 Attempt 3 Attempt 4 Attempt 5 Target Range Fig. 5: Optimization results for the opamp. (a) Gain (b) Unity-Gain Bandwidth (c) Phase Margin (d) Power (e) Input Offset (f) Output Voltage Range (g) CMRR (h) THD. (b) and (e) are tested under unity gain configuration, others are tested open loop. (a), (b), (c), (d) and (g) are tested at Vin,cm 0.9 V, (e), (f), (h) are tested across the Vin from 0 to 1.8 V. Those already in the target range initially or after a few iterations may still fluctuate or even get worse due to the optimization process prioritizing other performance metrics.\n\n--- Segment 12 ---\n(b) and (e) are tested under unity gain configuration, others are tested open loop. (a), (b), (c), (d) and (g) are tested at Vin,cm 0.9 V, (e), (f), (h) are tested across the Vin from 0 to 1.8 V. Those already in the target range initially or after a few iterations may still fluctuate or even get worse due to the optimization process prioritizing other performance metrics. This occurs because the agent has not yet achieved a balance between all required performance criteria. TABLE II: Transistor size and bias voltages for G1-5, G2-4 and G3-4 after optimization Transistor G1-5 (W L, µm µm) G2-4 (W L, µm µm) G3-4 (W L, µm µm) M1, M2 53 1.85 65 0.48 23 0.2 M3, M4 53 1.85 32 0.48 11.5 0.2 M5 9 0.45 2.5 0.46 15 0.6 M6 9 0.45 5 0.46 15 0.6 M7, M8 80 1.8 25.5 0.46 20 0.22 M9, M10 80 1.8 25.5 0.46 20 0.22 M11, M12 6 0.45 4.3 0.42 8 0.2 M13, M14 5 0.45 3.7 0.385 8 0.2 M15, M17 15 0.9 5.8 0.51 11 0.18 M16, M18 30 0.9 11.6 0.51 22 0.18 M19 340 0.43 90 0.53 100 0.18 M20 170 0.43 45 0.53 50 0.18 bias1 0.88 0.89 0.75 bias2 1.05 0.95 1.1 bias3 0.46 0.71 1.13 bias4 1.15 1.20 0.93 bias5 1.36 1.22 0.92 bias6 0.17 0.55 1.22 previous and current performance to balance various metrics, demonstrating the potential of LLMs in the circuit sizing process. However, some limitations remain.\n\n--- Segment 13 ---\nTABLE II: Transistor size and bias voltages for G1-5, G2-4 and G3-4 after optimization Transistor G1-5 (W L, µm µm) G2-4 (W L, µm µm) G3-4 (W L, µm µm) M1, M2 53 1.85 65 0.48 23 0.2 M3, M4 53 1.85 32 0.48 11.5 0.2 M5 9 0.45 2.5 0.46 15 0.6 M6 9 0.45 5 0.46 15 0.6 M7, M8 80 1.8 25.5 0.46 20 0.22 M9, M10 80 1.8 25.5 0.46 20 0.22 M11, M12 6 0.45 4.3 0.42 8 0.2 M13, M14 5 0.45 3.7 0.385 8 0.2 M15, M17 15 0.9 5.8 0.51 11 0.18 M16, M18 30 0.9 11.6 0.51 22 0.18 M19 340 0.43 90 0.53 100 0.18 M20 170 0.43 45 0.53 50 0.18 bias1 0.88 0.89 0.75 bias2 1.05 0.95 1.1 bias3 0.46 0.71 1.13 bias4 1.15 1.20 0.93 bias5 1.36 1.22 0.92 bias6 0.17 0.55 1.22 previous and current performance to balance various metrics, demonstrating the potential of LLMs in the circuit sizing process. However, some limitations remain. Firstly, the circuit under test relies on bias voltages due to the complexity of biasing circuits, which needs to be replaced with a current mirror network. The overall area of transistors is excluded in this study as the focus remains on performance optimization. Future work should integrate area and layout considerations for a holistic PPA trade-off.\n\n--- Segment 14 ---\nThe overall area of transistors is excluded in this study as the focus remains on performance optimization. Future work should integrate area and layout considerations for a holistic PPA trade-off. Secondly, the open-loop and closed-loop configurations of 0.0 0.5 1.0 1.5 Vin (V) 0.000 0.002 0.004 Voffset (V) (a) 0.0 0.5 1.0 1.5 Vout (V) 0 20 40 60 DC Gain (dB) (b) 102 103 104 105 RL ( ) 58 60 62 64 66 DC Gain (dB) (c) 0.0 0.5 1.0 1.5 Vin,cm (V) 80 100 120 140 CMRR (dB) (d) Variation 0 Variation 1 Variation 2 Variation 3 Variation 4 Variation 5 Variation 6 Variation 7 Variation 8 Variation 9 Fig. 6: Variation results for G1-5. (a) Input Offset Voltage vs. Common-Mode Input. (b) DC Gain vs. Output Voltage (c) DC Gain vs. Load Resistor. (d) CMRR vs. Common Mode Input. Random variations following a Gaussian distribution with a mean (µ) of 0 and a standard deviation (σ) of 0.1 are added to bias voltages and σ of 0.01 for transistor size. the op-amp are tested with a common-mode voltage at half- rail. While the design targets rail-to-rail output with a 1.75 V output range, the input common-mode range is not targeted and optimized, leading to variations in CMRR and DC gain across the input range. Future work should simulate dynamic parameters across the full range for true rail-to-rail input output performance. Additionally, high variations can be seen in the variation test, especially in Fig. 6 (c) and (d). A true Monte Carlo simulations with accurate device models are needed for the agent to ensure the design robustness. Moreover, opti- mization was limited to 25 iterations and 5 trials due to rate limits, potentially restricting performance insights and affecting the reliability of the results. However, more iterations don t ensure convergence, as LLMs may oscillate between solutions. A feedback mechanism should be introduced to prompt diverse solutions and improve reliability.\n\n--- Segment 15 ---\nHowever, more iterations don t ensure convergence, as LLMs may oscillate between solutions. A feedback mechanism should be introduced to prompt diverse solutions and improve reliability. V. CONCLUSION This work utilizes LLMs to build an AI Agent for the AMS circuit sizing process. By employing function-calling techniques, the LLMs are integrated with the external simulator Ngspice and data analysis functions, Additionally, using prompt engineering strategies, such as CoT and in-context learning, the agent leverages contextual information from previous iterations to guide the LLMs in sizing, leading to a reduced the number of iterations. As a result, the proposed agent optimized seven small-sized circuits, including a twenty-transistor rail-to-rail opamp. This agent demonstrates the potential for optimizing more complex circuits and systems in the future. The source code for this project is available on ACKNOWLEDGEMENTS The authors thank EDINA and of Edin- burgh for their support in accessing OpenAI services. REFERENCES [1] R. H. Walden, Analog-to-digital converter survey and analysis, IEEE Journal on selected areas in communications, vol. 17, no. 4, pp. 539 550, 1999. [2] S. Winder, Analog and digital filter design. Elsevier, 2002. [3] A. Ballo, M. Bottaro, and A. D. Grasso, A review of power management integrated circuits for ultrasound-based energy harvesting in implantable medical devices, Applied Sciences, vol. 11, no. 6, p. 2487, 2021. [4] W. Lyu, F. Yang, C. Yan et al., Batch bayesian optimization via multi- objective acquisition ensemble for automated analog circuit design, in International conference on machine learning. PMLR, 2018, pp. 3306 3314. [5] T. Liao and L. Zhang, Parasitic-aware gp-based many-objective sizing methodology for analog and rf integrated circuits, in 2017 22nd Asia and South Pacific Design Automation Conference (ASP-DAC). IEEE, 2017, pp. 475 480. [6] K. Touloupas, N. Chouridis, and P. P. Sotiriadis, Local Bayesian op- timization for analog circuit sizing, in 2021 58th ACM IEEE Design Automation Conference (DAC).\n\n--- Segment 16 ---\n475 480. [6] K. Touloupas, N. Chouridis, and P. P. Sotiriadis, Local Bayesian op- timization for analog circuit sizing, in 2021 58th ACM IEEE Design Automation Conference (DAC). IEEE, 2021, pp. 1237 1242. [7] Z. Zhao and L. Zhang, Analog integrated circuit topology synthesis with deep reinforcement learning, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 41, no. 12, pp. 5138 5151, 2022. [8] K. Settaluri, A. Haj-Ali, and e. a. Huang, Qijing, Autockt: Deep rein- forcement learning of analog circuit designs, in 2020 Design, Automation Test in Europe Conference Exhibition (DATE). IEEE, 2020, pp. 490 495. [9] The Claude 3 Model Family: Opus, Sonnet, Haiku. [Online]. Available: [10] J. Achiam, S. Adler, S. Agarwal et al., Gpt-4 technical report, arXiv preprint arXiv:2303.08774, 2023. [11] H. Touvron, T. Lavril, G. Izacard et al., Llama: Open and efficient foundation language models, arXiv preprint arXiv:2302.13971, 2023. [12] Z. Chen, J. Huang, Y. Liu, and others., Artisan: Automated operational amplifier design via domain-specific large language model, in Proceed- ings of the 61st ACM IEEE Design Automation Conference, 2024, pp. 1 6. [13] C. Liu, W. Chen, A. Peng et al., Ampagent: An llm-based multi- agent system for multi-stage amplifier schematic design from literature for process and performance porting, arXiv preprint arXiv:2409.14739, 2024. [14] D. V. Kochar, H. Wang, A. Chandrakasan et al., Ledro: Llm-enhanced design space reduction and optimization for analog circuits, arXiv preprint arXiv:2411.12930, 2024.\n\n--- Segment 17 ---\n[13] C. Liu, W. Chen, A. Peng et al., Ampagent: An llm-based multi- agent system for multi-stage amplifier schematic design from literature for process and performance porting, arXiv preprint arXiv:2409.14739, 2024. [14] D. V. Kochar, H. Wang, A. Chandrakasan et al., Ledro: Llm-enhanced design space reduction and optimization for analog circuits, arXiv preprint arXiv:2411.12930, 2024. [15] S. Yao, J. Zhao, D. Yu et al., React: Synergizing reasoning and acting in language models, arXiv preprint arXiv:2210.03629, 2022. [16] J. Wei, X. Wang, D. Schuurmans et al., Chain-of-thought prompting elic- its reasoning in large language models, Advances in neural information processing systems, vol. 35, pp. 24 824 24 837, 2022. [17] R. Hogervorst, J. P. Tero, R. G. Eschauzier et al., A compact power- efficient 3 v cmos rail-to-rail input output operational amplifier for vlsi cell libraries, IEEE journal of solid-state circuits, vol. 29, no. 12, pp. 1505 1513, 1994. [18] Y. Cao, Predictive technology model for robust nanoelectronic design. Springer Science Business Media, 2011.\n\n