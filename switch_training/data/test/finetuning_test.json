[
  {
    "text": "The latency numbers for the baseline models and the corresponding ensemble models along with the size of the ensemble are shown in Table  3 . For a given baseline model, we combine all models whose latency is lower than that of the baseline, and call it full- ensemble. We perform ensembling on the predictions using a simple majority voting policy.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "Overall,  Cocktail  was able to deliver an accuracy of 83% and 79.5% on average for the  Strict  and  Relaxed  workloads, respectively. We do not plot the results for Clipper-X , which achieves similar accuracy to  Cocktail , but uses more models as explained in Section  6.2.1 . This translates to 1.5% and 1% better accuracy than  Clipper  and  InFaas .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "16 \n0 \n2 \n4 \n6 \n8 \n10 \n12 \n14 \nKittiVision nuScenes CHIME Cityscapes Waymo \nRelative Latecny \n2 Nodes 3 Nodes 4 Nodes 5 Nodes 6 Nodes \nFigure 10: Change of data movement latency with respect to the number of storage servers. 0 \n2 \n4 \n6 \n8 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nRelative Latency \n2 to 1 4 to 1 6 to 1 \nFigure 11: Impact of increasing the number of CSDs in the system (the baseline system has a SSD-to-CSD ratio 8 to 1). Similarly, Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "Note that the latency is the raw model execution latency, and does not include the addi- tional network-transfer overheads incurred. We picked the constraints using a similar procedure by ordering constraints across ﬁve different categories for  CIFAR-100 ,  SST-2  and SemEval  (twitter tweets) datasets. The list of models used for them are given in the Appendix.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "2020. \"https://github.com/ google-research-datasets/Objectron/blob/master/index/bottle_annotations\". [41]  Objectron.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "15 \n0 \n20 \n40 \n60 \n0 \n0.1 \n0.2 \n0.3 \n0.4 \n1 \n4 \n7 \n10 \n13 \n16 \n19 \n22 \n25 \n28 \n31 \n34 \n37 \n40 \n43 \n46 \n49 \n% Reconstruction Error \nFFT Amplitude \nFrequency (Hz) Reconstructed Original % Error \nFigure 14: An example of generator based coreset re- covery \nFigure 15: % completion of the inference at the edge for bearing fault data with different EH source. Figure 16: Communication data volume with different number of clusters. Component Spec Power Area(mm 2 ) \nSRAM Buffers \n1kB*256+ 8kB*256+ 64kB+16*256kB \n10.372W 117.164 \nMAC Unit (8*8) 256 8.46W 32.72 \nAdder Tree and Comparator 16*16bit + 256 2.4W 21.556 \nControl – 0.96W 12.2 Host ∼ Cortex A78 series 11W – Design at 592MHz with Synopsys AED 32nm library \nTotal 256 tiles 33.192W 183.64 Table 3: Area and power estimation of our design.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 251,
    "augmented": false
  },
  {
    "text": "Proceedings of the VLDB Endowment , 12(2):128–140, 2018. [81]  Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface’s transformers: State-of- \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1055 \nthe-art natural language processing.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Keboola, the platform that automates data lineage. https://www.keboola.com/ product/data-lineage . (Accessed on 09/12/2023).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "8097. International Society for Optics and Photonics, 80971H. [50]  Victor Adrian Prisacariu, Olaf Kähler, Stuart Golodetz, Michael Sapienza, Tom- maso Cavallari, Philip H. S. Torr, and David William Murray. 2017.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "[25] N. Global Monitoring Laboratory, “Solrad network,”  https://gml.noaa. [26] G. Gobieski, B. Lucia, and N. Beckmann, “Intelligence beyond the \nedge: Inference on intermittent embedded systems,” in  ASPLOS . gov/grad/solrad/index.html , (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference. With a power predictor [ 36 ], we can estimate the power level of the next power cycle in advance. We call this smooth transition strategy as  Transition Keep .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Although, these techniques can potentially save memory usage/energy for  360 ° VR videos, as discussed in earlier sections, due to inherent nature of  360 ° video processing, which introduces additional overheads for projection computation, we identify compute  to be the major energy bottleneck. Hence, these memory optimizations are not applicable to reduce compute energy on  360 ° VR videos. VII.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "Unlike prior works targeting at optimizing the efficiency of the hologram program- ming itself by proposing alternative hardware [ 32 ,  35 ], we primarily focus on exploring the intrinsic approximation opportunities (dis- cussed in Sec. 2.2.3) ignored in the current implementation of the AR applications, but can be embedded into the existing hardware such as GPUs, to speedup the holographic execution and improve power/energy efficiency with negligible quality loss. 4.1 Exploring the Entire Design Space in AR Hologram Processing \nExploring the entire design space for the AR hologram processing is a non-trivial task.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "When compared to the OD price , they were up to 70% cheaper. This price gap is cap- italized in  Cocktail  to reduce the cost of instances consumed by ensembling. Note that, we set the bidding price conser- vatively to 40% of OD.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "|N| [ L ( S  ∪{ i } )  −L ( S )] \nwhere  N  is the set of all neurons,  S  is a subset of neurons not containing  i , and  L ( · )  denotes the loss function. X \nS ⊆N\\{ i } \n| S | ! ( |N| −| S | − 1)!",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "This stability is crucial for maintaining long-term network per- formance without necessitating continuous recalibration or extensive communication overhead. 4.2. Utility Function Definition \nWe define a utility function  U i ( t )  for each sensor  s i  that en- capsulates the trade-off between accuracy gains and energy \nexpenditures, as well as future opportunities.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Computational storage: an efficient and scalable platform for big data and hpc applications. Journal of Big Data , 6:1–29, 2019b. Min-Han Tsai, Nalini Venkatasubramanian, and Cheng-Hsin Hsu.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Amazon, google, microsoft turn to nuclear energy. https : / / www.nytimes.com/2024/10/16/business/energy- environment/amazon- google- microsoft-nuclear-energy.html , 2024. Accessed: 2024-10-20.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "32–40, 2015. [10] K. Ma, X. Li, J. Li, Y. Liu, Y. Xie, J. Sampson, M. T. Kandemir, and V. Narayanan, “Incidental computing on iot nonvolatile processors,” in MICRO , 2017. [11] S. Ha and S. Choi, “Convolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors,” in IJCNN , 2016.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "•  Furthermore, a software-only approach may not give us the desired solution as some of these additional execution cycles, control and data path manipulations may need ar- chitectural support, especially to reduce memory and power overheads on edge VRs. All these are possible avenues for optimization and demand a detailed study of the computa- \ntion pipeline, the workloads, user behavior, etc., to ﬁnd a way to further improve the state-of-the-art. Therefore, we believe that, achiev- ing beneﬁts by exploiting the  EA  and  AE  opportunities needs an extensive study and a careful design, especially from an architectural perspective, to maximize the beneﬁts.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "[9] Y. Zhu, A. Samajdar, M. Mattina, and P. Whatmough, “Euphrates: Algorithm-SoC Co-Design for Low-Power Mobile Continuous Vision,” in  Proceedings of the International Symposium on Computer Architec- ture , 2018, p. 547–560. [10] M. Riera, J.-M. Arnau, and A. Gonz´alez, “Computation Reuse in DNNs by Exploiting Input Similarity,” in  Proceedings of the International Symposium on Computer Architecture , 2018, p. 57–68. [8] M. Xu, M. Zhu, Y. Liu, F. X. Lin, and X. Liu, “DeepCache: Principled Cache for Mobile Deep Vision,” in  Proceedings of the Annual Interna- tional Conference on Mobile Computing and Networking (MobiCom) , 2018, p. 129–144.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 230,
    "augmented": true
  },
  {
    "text": "´as is always conservative, and the solar power predictor has a mean accuracy of 92%, limiting false positives and helping the control unit select appropriate tile counts. The system needs at least 512 cycles of advanced notice to ﬂush compute and enable a compute migration. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "https://developer.nvidia.com/rtx/dlss , 2024. Ac- cessed: 2024-08-02. James Jie Pan, Jianguo Wang, and Guoliang Li.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "2020. Objectron Dataset Annotation: book. \"https://github.com/ google-research-datasets/Objectron/blob/master/index/book_annotations\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "storage stack archi- tects often abstract the computational processes, neglecting considerations such as data movement cost, compute cost, and power requirements. Conversely, architects of storage drives, including CSDs, tend to overlook the broader application requirements, such as data prioritization, potential offloading of computational tasks to storage, and application-specific data compression and encryption strategies. Our research aims to  bridge  this gap, focusing specifically on the exigencies of continuous learning applications.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Our training infrastructure utilizes NVIDIA A6000 GPUs with 48 GiB of memory, supported by a 24-core Intel Xeon Gold 6336Y CPU. To assess the computational overhead introduced by DynFit, a component of NExUME, we use NVIDIA Nsight Compute. We employ PyTorch v2.3.0 coupled with CUDA version 11.8 as our primary training framework.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Our research aims to  bridge  this gap, focusing specifically on the exigencies of continuous learning applications. 2.2 The Problem: Understanding the Data Flow \nChallenges in Data Movement:  In both consumer applications and high-performance computing (HPC) programs, the process of data collection followed by analytics is a critical operation (Cao et al., 2020; Mailthody et al., 2019; Chapman et al., 2019; Li et al., 2023). The efficiency of data movement significantly influences the performance and energy consumption of large-scale systems (Park et al.).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 135,
    "augmented": false
  },
  {
    "text": "We develop a non-volatile hardware accelerator, with mul- tiple quantization support, for efficient DNN inference. •  Adaptability:  Although  Seeker  is meant for EH-WSNs, the coreset based data representation can easily be used in any commercial device for efficient communication. •  Detailed Evaluation:  We provide a detailed evaluation of our system and the proposed hardware design.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "However, a higher reuse ratio can be achieved by relaxing the precision of the IMU output. Furthermore, we study the  V3  (i.e.,  Rollercoaster ) video and examine the trade-offs between (i) quantizing/approximat- ing the head orientation (thus compromising video quality) with more reuse, vs. (ii) maintaining the lossless video quality but with a lower reuse ratio, in Fig. 5c, to provide an intuitive comparison in different scenarios.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "[4] The state of ai in early 2024: Gen ai adoption spikes and starts to generate value. https://www. mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai , Febru- ary 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Sensors participate \nin training rounds based on their equilibrium-driven de- cisions, ensuring that gradient updates are contributed by those sensors most capable and willing to improve the global model. This alignment minimizes unnecessary energy ex- penditure and maximizes the efficacy of each training round. Algorithm 2  Periodic Equilibrium-Aware Training Algo- rithm \n1:  Initialization:  Initialize  θ 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "James Jie Pan, Jianguo Wang, and Guoliang Li. Vector database management techniques and systems. In  Companion of the 2024 International Conference on Management of Data , pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "In  European Conference on Parallel Processing , pp. 304–319. Springer, 2023.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "Especially,  interactive volumetric video streaming  is starting to become mainstream, as edge devices (e.g., iPhones) facilitate recording and streaming the PC video which provide end-users with real-time 6-degrees of freedom (6-DoF) experiences. Streaming such PC videos in real-time involves capturing both the attributes and geometry data making it a challenging task even without user-object interaction. Towards this, Han et al.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "The regularizers  Ω SNR  and  Ω complexity  are convex in  θ , and their gradients are bounded. Convexity and boundedness of regularizers. 3.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "2) Model Compression and Pruning:  To make DNNs mo- bile friendly, there have been several works in compressing and pruning large models. While model compression [27]–[29] tries to compress the entire weight matrix while preserving accuracy, pruning goes over individual weights/kernels and drops the unimportant ones. Model compression is typically achieved by tensor decomposition or low rank compression, i.e., by representing the higher dimensional parameter matrix in a compressed low rank form.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "Zhiyu Huang, Haochen Liu, and Chen Lv. Gameformer: Game-theoretic modeling and learning of transformer-based interactive prediction and planning for autonomous driving, 2023. URL https://arxiv.org/abs/2303.05760 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "3. Convexity and boundedness of regularizers. The regularizers  Ω SNR  and  Ω complexity  are convex in  θ , and their gradients are bounded.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "21, no. [41] C.-K. Kang, H. R. Mendis, C.-H. Lin, M.-S. Chen, and P.-C. Hsiu, \n“More is less: Model augmentation for intermittent deep inference,” ACM Transactions on Embedded Computing Systems (TECS) , vol. 3479–3491, 2020.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "Conclusion \nThis should finish at 8 pages. Impact Statement \nAuthors are  required  to include a statement of the potential broader impact of their work, including its ethical aspects and future societal consequences. This statement should be in an unnumbered section at the end of the paper (co- located with Acknowledgments – the two may appear in either order, but both must be before References), and does not count toward the paper page limit.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 93,
    "augmented": false
  },
  {
    "text": "We would also like to point that capturing these opportunities is not trivial and cannot be efﬁciently done by just optimizing the existing application layer and software stack. We describe the underlying issues to address and emphasize the non-trivialities: •  To ease development efforts, state-of-the-art VR applica- tions reuse APIs provided by OpenGL [24], [42], and whenever a new frame is decoded, they always invoke the glDrawFrame  twice for both eyes (see line number  257  in googlevr-video360 application [12]). They do not seem to leverage the fact that the transformation matrices are unique for each head orientation and memoizing them will save re-calculating the transformation matrix ( T  ) as well as the projection matrix ( P ).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 177,
    "augmented": false
  },
  {
    "text": "Specifically, improvements ranging from 6.10% to 17.13% over existing methods highlight NExUME’s capability to adapt dynamically to fluctuating energy conditions, ensuring both operational longevity and computational integrity. The broader implication of this work extends beyond technological advancements, suggesting a paradigm shift in how the machine learning community approaches the design and deployment of systems in energy-limited environments. By prioritizing energy efficiency and system adaptability, NExUME contributes to the sustainability and accessibility of machine learning solutions, enabling their deployment in regions where power infrastructure is absent or unreliable.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "By enabling plug-and-play functionality, our design should empower users to customize and extend the model by adding new experts, dropping existing experts and changing the connections among experts, routers and composition functions, fostering collaboration and in- novation within the community. To support this modularity, we also propose a flexible system architecture and runtime that efficiently handles queries. This approach defines a large set of different expert types, routers and composition functions that can be used to build an “ensemble” (model) that is customized for the application at hand, and allows for independent training and updating of experts, fa- cilitating continual learning and adaptability.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "[88]  C.-H. Wu, C.-F. Hsu, T.-K. Hung, C. Griwodz, W. T. Ooi, and C.-H. Hsu, “Quantitative comparison of point cloud compression algorithms with pcc arena,”  IEEE Transactions on Multimedia , pp. 1–1, 2022. 298 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "For such scenarios, due to the prevailing relationship between the left and right eye transformation matrices ( T L  and  T R ), we can further avail the spatial compute reuse opportunity shown in b in Fig. 4, by reconstructing the computation needed for one eye ( P R ) from the other ( P L ). •  In  AA , the input and output mapping are unique, that is, no two input coordinates in  360 ° frame map to the same coordinates in the 2D FoV frame, thereby eliminating any compute reuse scope.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems , CHI ’23, New York, NY, USA, 2023. The halting problem: Video analysis of self- driving cars in traffic. Barry Brown, Mathias Broth, and Erik Vinkhuyzen.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "However, deploying such architectures on ultra-low-power, energy-harvesting devices presents significant challenges due to their substantial \n9 \n200 250 300 350 400 450 500 550 600 \nLatency (ms) \n78 80 82 84 86 88 90 92 94 \nAccuracy (%) \nAccuracy vs. Latency for Different Classes \nR1 R2 R3 SJ SI \n(a) Accuracy vs Latency \n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 Capacitance (F) \n78 \n80 \n82 \n84 \n86 \n88 \n90 \n92 \nAccuracy (%) \nAccuracy vs. Capacitance for Different Classes \nR1 R2 R3 SJ SI \n(b) Accuracy vs Capacitance \nFMNIST CIFAR10 MHEALTH PAMAP AudioMNISTMachine Dataset \n0 \n20 \n40 \n60 \n80 \n100 \nAccuracy (%) \nAbalation Study \nDN DN+DF DN+DF+DI \n(c) Ablation Study Figure 3: Sensitivity and ablation study. Although iNAS enhances network selection, its lack of intermittency awareness significantly impacts accuracy. 4.5 Limitations and Discussion \nWe recognize that modern architectures like Transformers have become prevalent in the ML commu- nity due to their superior performance on large-scale datasets.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 308,
    "augmented": true
  },
  {
    "text": "905 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "From these results, we can make the following observations. 1) Overall Execution Latency: On average, our FI+SI scheme can reduce  52%  of the execution time for YOLOv3, and  53%  for YOLOv4-tiny, compared to the baseline. On the other hand, our FI+SI+PI scheme can save  55% / 61%  of the execution time for YOLOv3/YOLOv4-tiny.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "07] . Both the models have classiﬁed the input to be of class  o 1 . The accuracy of both system might be identical (over a large number of test sets), yet for the current test case, both the models are not equally conﬁdent about the classiﬁcation.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "1041– 1044. [79] A. Samajdar, Y. Zhu, P. Whatmough, M. Mattina, and T. Kr- \nishna, “Scale-sim: Systolic cnn accelerator simulator,”  arXiv preprint arXiv:1811.02883 , 2018. [80] A. Sarma, S. Singh, H. Jiang, A. Pattnaik, A. K. Mishra, V. Narayanan, \nM. T. Kandemir, and C. R. Das, “Exploiting activation based gradient output sparsity to accelerate backpropagation in cnns,”  arXiv preprint arXiv:2109.07710 , 2021.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 189,
    "augmented": false
  },
  {
    "text": "All these videos used are captured at 30fps, and voxelized into  1024 × 1024 × 1024  voxels (3D points), with each point containing three  ﬂoat-pointing  coordinates and three  unsigned char  RGBs. Table I: Six videos in 8iVFB [ 18 ] and MVUB [ 8 ] datasets used in this paper. Video Redandblack Longdress Loot Soldier Andrew10 Phil10 #Frames 300 300 300 300 318 245 #Points/Frame 727070 834315 793821 1075299 1298699 1486648 \nB. PCC Design Conﬁgurations \nTo demonstrate the effectiveness of our proposal, we evaluate the following ﬁve PCC designs: •  TMC13  [ 56 ]: We use TMC13 (G-PCC codec from MPEG), as the  state-of-the-art  approach for  intra-frame compression .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 211,
    "augmented": false
  },
  {
    "text": "Looking ahead, the role of storage systems is poised to become even more pivotal as ML applications continue to evolve and generate larger, more complex datasets. The ongoing innovation in the design and optimization of CSDs will be crucial in meeting these challenges. In summary, our research presents a comprehensive vision for the future of storage systems in ML, where computational storage \n17 \ndevices play a key role in advancing the, performance, efficiency, and capabilities of storage servers, thereby contributing significantly to the broader field of ML.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "If the tiling sizes of output solutions are the same, we choose larger  m because larger  m  implies fewer partial sum adds. D. Activation transition \nThe power instability of energy harvesting implies that the activation solution needs to change dynamically as power level changes. Figure 7 shows the ﬁnite state machine (FSM) directing transition strategy.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "The next power cycle’s level information cannot be known with certainty. In order to not discard the acquired results, we can search the maximal   ∗ Tile count 1   where   ∗ Tile count 1   ≤ Tile count 1   to make the expression  n 2  |  ( ∗ Tile count 1   ×  n 1) conservatively true for each layer, and then transfer the tile count ∗ Tile count 1  to accommodate to the new activation solution. This means that only a portion of computation results from   ∗ Tile count 1   to  Tile count 1   will be discarded.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Calculate the gradients of the loss with respect to the weights: \n∂ L ∂W ij \nFor each layer  L  and loop  i  within the layer, estimate the energy  E i  required for the current quanta size  l i : E i  ← DynAgent.estimateEnergy ( L, i, l i ) \n16 \nIf  E i  > E b , fuse tasks to reduce the overhead: \nFuseTasks ( L, i, l i , E b ) \nUpdate  E i  after task fusion: \nE i  ← DynAgent.estimateEnergy ( L, i, l i ) \nUpdate the dropout mask  m  based on the L2 norm of the weights: \np i  = α ∥ W i ∥ 2  +  ϵ \nm i  = \u001a 0 if Bernoulli (1  − p i ) = 0 1 otherwise Perform the backward pass to update the network weights, considering the dropout mask: \nW  ← W  − η  ∂ L \n∂ W   ⊙ m \nwhere  η  is the learning rate and  ⊙ denotes element-wise multiplication. Inference with L2 Dynamic Dropout and QuantaTask Optimization:  Check the available energy using DynAgent. If energy is below a threshold, increase the dropout rate to ensure the inference can be completed within the energy budget.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 336,
    "augmented": false
  },
  {
    "text": "We zeroed in on the choice of using DeepARest by conducting (Table  4 ) an in-depth com- parison of the accuracy loss when compared with other state-of-the-art traditional and ML-based prediction models used in prior works [ 47 ,  86 ]. As shown in Algorithm  2 , for every model under a periodic scheduling interval of 1 minute ( T s ), we use the  Predicted _load ( L p ) at time  T  +  T p  and compare it with the  current_load  to determine the number of instances ( I n ). different load arrival patterns, we design a DeepAR- estimator (DeepARest) based prediction model.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 163,
    "augmented": true
  },
  {
    "text": "Experimental results show that  D´ej`a View  can provide  34%  computation reduction and  17%  energy saving, compared to the state-of-the-art design. Index Terms —Virtual Reality, Edge Computing, IoT,  360 ° Video Processing \nI. I NTRODUCTION \nRecent developments in technology, computing and com- munication have brought signiﬁcant changes to the lifestyle of common people by providing them access to increasingly sophisticated devices. Especially, VR and AR are now gaining traction because of their versatile nature of providing an immersive sensory experience, which is not possible with the conventional systems – especially in the domain of video streaming.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. 51% \n32% \n17% \n2-Norm Attri.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "[5] Discovery, “Elephants on the Brink.” ”https://www.youtube.com/watch? v=2bpICIClAIg”, 2019. [6] T. El-Ganainy and M. Hefeeda, “Streaming Virtual Reality Content,” CoRR , vol.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "This makes it possible to find a sweet spot, given specific needs, in efficiency and accuracy trade offs. Figure 4d shows that inference time will increase linearly with the number of estimators whereas it has a very small impact on correlation. The number of estimators also needs to be customized for different datasets.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "2012. Creating and benchmarking a new dataset for physical activity monitoring. In  PETRA , Fillia Makedon (Ed.).",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "I, DeepCache does not take advantage of frame-wise data reuse opportunities (e.g., reuse the inference result for similar frames). Thus, the latency improvement and energy saving po- tential of DeepCache can be limited. Additionally, as the step- size of full-inference is ﬁxed, it cannot adaptively update its cache based on the video content.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "[76] G. V. Research, “Consumer iot market size, share and trends \nanalysis report by component (hardware, services), by connectivity technology (wired, wireless), by application (healthcare, wearable devices), and segment forecasts, 2023 - 2030,” https://www.grandviewresearch.com/industry-analysis/consumer- iot-market-report#: ∼ :text=The%20global%20consumer%20IoT% 20market,advanced%20devices%20and%20home%20appliances. , July 2022, (Accessed on 08/04/2023). [77] M. S. rutgers.edu, “Support for trafﬁc cameras increases if used as a tool to limit interactions with police,” https://www.rutgers.edu/news/support-trafﬁc-cameras-increases-if- used-tool-limit-interactions-police , (Accessed on 04/28/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 245,
    "augmented": false
  },
  {
    "text": "Zstandard compression and the application/zstd media type. Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Scharwächter, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. Technical report, 2018.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "These datasets represent typical use cases in embedded systems where energy efficiency and minimal computational overhead are crucial. In this section, we discuss the effectiveness of NExUME across two distinct types of environments, highlighting its versatility and broad applicability. Firstly, we evaluate NExUME using publicly available datasets (§4.2) commonly utilized in embedded applications across multiple modalities—including image, time series sensor, and audio data.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "-5 5 15 25 \n1 225 449 673 897 1121 1345 1569 1793 2017 2241 \nDistance \nPixel ID \ndistanceY distanceX \n-10 \n-5 \n0 \n5 \n10 \n0 10 20 \nDistance-x \nDistance-y \n(b) (0.00, 1.57, -0.73) \n-20 0 20 40 60 \n1 202 403 604 805 1006 1207 1408 1609 1810 2011 2212 \nDistance \nPixel ID \ndistanceY distanceX \n-10 -5 0 5 10 \n0 20 40 60 \nDistance-x \nDistance-y \n(c) (0.52, 1.05, -0.73) \nFig. 6: In  AE , distance vector (a) patterns with two different head orientations  ( Y aw, Pitch, Roll )  in (b) and (c). is mapped from position  [( x 360 ) 0 r ,  ( y 360 ) 0 r ]  on the  360 ° frame.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 212,
    "augmented": true
  },
  {
    "text": "Restrictions apply. a bottleneck in data movement and sharing, creating hurdles in high quality-low latency streaming/analysis. Therefore, there have been several works focusing on compressing the PC, as discussed next.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "2018. Bin-Packing. In  Combinatorial Optimization .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 14,
    "augmented": true
  },
  {
    "text": "V ) – and reached the following  conclusions : the primary reason behind their performance inefﬁciencies is what can be termed as “under-parallelism”, i.e., not being able to fully exploit parallelism during compression. Especially, many levels of dependencies (i.e, various regularities of locks) exist in their pipelines – e.g., the entire octree needs to acquire a “macro lock” before inserting a point and updating the tree (as shown in Fig. (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "[57]  New Farmer Blogger, “3D points clouds for immersive real es- tate and telepresence experiences,”  ”https://bit.ly/3AhWQR5” , 2015. [55]  MPEG, “Point Cloud Video: Redandblack,”  ”https://bit.ly/ 3NyQq2R” , 2022. [56]  MPEGGroup, “Geometry based point cloud compression (G- PCC) test model,”  ”https://github.com/MPEGGroup/mpeg-pcc- tmc13” , 2021.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "4. Since  E [ b ∇ L ( θ k )] = ∇ L ( θ k ) , we also have E [ b ∇ J ( θ k )] =  ∇ J ( θ k ) . Aggregation:  The aggregator averages the received gradients: b ∇ J ( θ k ) =  b ∇ L ( θ k )+ λ 1 ∇ Ω SNR ( θ k )+ λ 2 ∇ Ω complexity ( θ k ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "Pytorch: An imperative style, high-performance deep learning library. https://pytorch.org/ , 2019. Accessed: 2024-04-27.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "the raw PC frame) and the quality (PSNR), we  reconﬁgured  the number of “direct-reuse” blocks \ni iii iv ii \n(a) Original vs. decoded PCs with our proposals. 37 39 41 43 45 \n7 8 9 10 11 12 \n31%58%69%79%82% \nPSNR(dB) \nCompressed Size  w.r.t. To study how the inter-compressed frames/blocks would affect the compression efﬁciency (the compressed size w.r.t.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "[162] Zhuang Wang, Zhen Jia, Shuai Zheng, Zhen Zhang, Xinwei Fu, T. S. Eugene Ng, and Yida Wang. In  Proceedings of the 29th Symposium on Operating Systems Principles , SOSP ’23, page 364–381, New York, NY, USA, 2023. Gemini: Fast failure recovery in distributed training with in-memory checkpoints.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 104,
    "augmented": true
  },
  {
    "text": "Typically, there is an inverse correlation of the convergence of the stochastic gradient descent (SGD) algorithm, the most popular training algorithm for DNNs, over the number of iterations ( n i ) [ 68 ]: l  ∝ O ( 1 / n i )  and  l  = 1 β 0 . n i + β 1   +  β 2 , where  l  is the loss of the SGD and  β i  is an non-negative real number. Therefore, by running a few iterations of the SGD algorithms with various other hyperparameters, we can easily  predict  the con- vergence of the models.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "[33]  Naoya Muramatsu, Chun Wei Ooi, Yuta Itoh, and Yoichi Ochiai. 2017. Deep- Holo: Recognizing 3D Objects Using a Binary-Weighted Computer-Generated Hologram.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Consequently, the only regions of interest (RoIs) should be the change between successive frames. In special cases, like remote surveillance, most frames can even be identical, avoiding the need to process them. Furthermore, these changes between consecutive frames need not be explicitly calculated as they can be extracted from the hardware codecs directly, giving us a chance to capitalize on an existing funda- mental component, instead of adding new hardware blindly.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "5.5 Future Work \nDespite the hardware-agnostic nature of  HoloAR , it is still in- teresting to study how to deploy our idea on an ASIC hardware, and co-design the next-generation accelerator on edge for the AR hologram. Towards this, we plan to explore three critical questions in our future work: First, how many processing units (PUs) are required and just sufficient for most of the cases in a typical AR holographic application? To answer this, we plan to characterize the number of depth planes needed in various AR applications, and guide the optimal design choices (i.e., number of PUs, frequency, input and output buffer size, etc.)",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "7). The  EA  block is placed before the original compute engine (OCE, e.g., GPU) to opportunistically bypass the projection computation. However, when  AE  cannot take advantage of memoization due to a head orientation change, then the compute is distributed across the OCE ( 51% ) and  AE block ( 49% ); to be precise, only the entire coordinates on the left screen and the ﬁrst row on the right-screen are processed by the OCE – the remaining rows on the right screen are reconstructed by the less power-hungry  AE  block.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "Depending on the available energy, the task (vector inner product) can be divided into multiple iterations such that each QuantaTask is guaranteed to finish given the energy availability. E  is available energy, and  E b  is the energy required to finish one inner product. Optimization Variables, Constraints, and Objective Function:  The optimization problem is formulated with variables: the weights  W , dropout rates  d , quantization levels  q , and QuantaTask sizes  ℓ .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "Q-hitter: A better token oracle for efficient llm inference via sparse-quantized kv cache. [188] Zhenyu Zhang, Shiwei Liu, Runjin Chen, Bhavya Kailkhura, Beidi Chen, and Atlas Wang. In  Advances in Neural Information Process- ing Systems , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "The approaches in the ﬁrst category employ precision-conservative high power consuming ReRAM circuits and organize numerous large scale ReRAMs [ 3 ], [ 4 ], [ 5 ], whereas those in the second category adopt simple ReRAM organizations that constrain their execution style (e.g., parallelism granularity), which disadvantages them in coping with both variances across different ReRAMs and changing power supply [ 6 ], [ 8 ]. However, neither of them is a good ﬁt for energy-harvesting scenarios. To address these challenges, this paper proposes and experi- mentally evaluates  ResiRCA , a resilient ReRAM crossbar-based CNN accelerator.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "[72]  R. B. Rusu and S. Cousins, “3D is here: Point Cloud Library (PCL),” in  IEEE International Conference on Robotics and Automation (ICRA) , 2011. [73]  C. Santos, M. Gon c¸ alves, G. Corr ˆ ea, and M. Porto, “Block- based inter-frame prediction for dynamic point cloud com- pression,” in  2021 IEEE International Conference on Image Processing (ICIP) , 2021, pp. 3388–3392.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "To address this, energy harvesting (EH) technolo- gies have emerged as a viable solution, enabling sensors to convert ambient energy (e.g., solar, thermal, or vibration) into electrical power. This approach promises perpetual, maintenance-free operation, significantly reducing environ- mental impact and long-term operational costs. 1 Anonymous Institution, Anonymous City, Anonymous Region, Anonymous Country.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the 50th Annual International Symposium on Computer Architecture , pages 1–15, 2023. [72] Natalie Enright Jerger, Ajaykumar Kannan, Zimo Li, and Gabriel H Loh. Optimizing cpu performance for recommendation systems at-scale.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "The queries consist of images or sentences, which are randomly picked from the test dataset. In our experiments, we use ﬁve different types of these constraints. As an example for the  Imagenet  dataset shown in Figure  6 , each constraint is a representative of <latency, accuracy> com- bination offered by single models (shown in Table  1 ).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "1% \n0 20 40 60 80 100 All Succeed Atleast one succeed Failed \n9% 90% \n(a)  Inference completion breakdown when three EH sensors are working together to ﬁnish the incoming inferences. In only 1% of the cases all of the sensors ﬁnished inference, while 9% of the time at least one of them ﬁnished. 90% of the time the inference could not start because of lack of energy.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "The conventional \nmethod, where the sensors collect the data and send it to the cloud or any other host device (such as connected mobile phones) is not an effective option as communicating large data demands more power, which is both highly variable and scarce in EH systems. M OTIVATION \nA major challenge while executing a DNN inference on an energy harvesting sensor is the power budget. II.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "The occupied DRAM size is mainly determined by  P buff . Since this puts a high demand on memory, one edge VR headset cannot afford to memoize for all possible head orientations. In fact, with a VR screen size of  1 ,  000 × 1 ,  000 , one  P buff  occupies  ≈ 8 MB  in DRAM.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Putting together, these above observa- tions indicate that, with very little change (to capture the row- dependent information) in our original  AE  design, our idea is able to work with any representation format. This motivates us to target on further improving quality across video formats by capturing the information related to row numbers in future. VI.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "While the overhead in streaming multi-processor (SM) utilization was marginal (within 5%), there was a noticeable increase in memory bandwidth usage, ranging from 6% to 17%. To assess the computational overhead introduced by DynFit, a component of NExUME, we use NVIDIA Nsight Compute. During the training sessions enhanced by DynFit, we observed an increase in the number of instructions ranging from a minimum of 11.4% to a maximum of 34.2%.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "[69] J. F. Peters, M. Baumann, B. Zimmermann, J. Braun, and M. Weil, “The \nenvironmental impact of li-ion batteries and the role of key parameters– a review,”  Renewable and Sustainable Energy Reviews , vol. 1–14. 67, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "https://mikhail.io/ serverless/coldstarts/azure/. Intel Power Gadget. [16]  Feb 24, 2020.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "4) Finally, we provide a detailed evaluation of  Origin , and show that, even when powered by an unreliable EH source, the efﬁciency achieved by the this system results in better accuracy than that of a fully powered system running state of the art classiﬁers optimized for energy efﬁciency. II. Origin reaches 83.88% top-1 accuracy compared to the 81.16% accuracy of the baseline system.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "Each chip can potentially contain a set of homogeneous or heterogeneous chiplets including accelerator engines, reconfigurable engines, CPUs, GPUs, and various types of memory modules. cally create an  Expert Execution Attribute Database  containing metrics such as latency, compute utiliza- tion, memory utilization, accuracy, and power contribution, and minimum HBM needed. This database will help in various intelligent decisions such as using the most ideal hardware for an expert and dropping an expert if it does not meet the minimum required accuracy/SLO for an application.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "2018. Peeking Behind the Curtains of Serverless Plat- forms. In  ATC .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "This process involves “representation learning” (Rebuffi et al., 2017), where data is transformed into “feature vectors” using deep neural networks, followed by unsupervised learning techniques like k-means clustering. The goal is to identify unique or new classes of data for training while archiving known classes. In exemplar selection, the entire dataset is analyzed to detect classes with unique features, i.e., the images that are much different from the training data distribution or new classes that were not included in the training data.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Recall that, in the AR holographic application discussed above in Fig. While such approaches im- prove the hologram execution to some extent, they do not consider the unique features of the AR applications. These prior approaches either incorpo- rate additional memory for maintaining a lookup table for compu- tation reduction, or build an application-specific integrated circuit (ASIC) chip specifically for holographic processing, which is more power-efficient than generic processors.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "[40]  Rui Han, Moustafa M. Ghanem, Li Guo, Yike Guo, and Michelle Osmond. In  2020 ACM/IEEE 47th Annual International Symposium on Computer Archi- tecture (ISCA) , pages 982–995, 2020. Deeprecsys: A system for optimiz- ing end-to-end at-scale neural recommendation inference.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "In  16th USENIX Conference on File and Storage Technologies (FAST 18) , pages 49–66, Oakland, CA, February 2018. MQSim: A framework for enabling realistic studies of modern Multi-Queue SSD devices. USENIX Association.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "8a . Execution Latency:  We ﬁrst compare two SOTA schemes (TMC13 [ 56 ] for intra-frame compression, and CWIPC [ 13 ] for inter-frame compression) with our three proposals (intra- only, (better) quality-oriented Intra-Inter-V1, and (better) compression-oriented Intra-Inter-V2), and present the col- lected execution latencies in Fig. Then, we discuss and present the validity of our results on the smartphones.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "In the  i th   kernel scheduling iteration, given the power budget and power prediction, the \nmicro-proﬁler decides the required training conﬁguration, and the control logic (conservatively) enables suitable number of tiles (say  t i  tiles of the 256 tiles). Those  t i  tiles fetch  t i unique kernels from the 1Byte wide, 256 deep global kernel dispatch queue (GKDQ,  t i  kernels scheduled in parallel ). Note that the power requirement of each tile is known in advance (please refer to § V , TABLE  I  for details).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "Note that this step is also amenable to parallelism. In our proposal shown in the lower ﬁgure, instead of constructing the octree in a point-by-point fashion, we process all three points as one “batch” in the  Morton Code Generation step in parallel, and output the ﬁnal bounding box cuboid with side lengths 4 × 3 × 3 (x-axis: 3-(-1) =4, y-axis: 3-0 =3, and z-axis  3 - 0  = 3 ). With the Morton code in place, next we invoke the parallel octree construction technique (for more details, please refer to [ 31 ], [ 64 ]) to construct the octree.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "Accessed: 2024-10-20. https:// www.reuters.com/business/energy/meta-strikes-geothermal-energy-deal-with- sage-geosystems-power-data-centers-2024-08-26/ , 2024. Meta strikes geothermal energy deal with sage geosystems to power data centers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "18, pp. 6869–6898, Jan. 2017. [33]  M. Courbariaux, Y. Bengio, and J.-P. David, “Binaryconnect: Training deep neural networks with binary weights during propagations,” in Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 , NIPS’15, pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "3. Voltage Regulation : After rectification, the power might not be at the right voltage for the device it needs to support. A matching circuit, including components like buck or boost converters, adjusts the voltage to the appropriate level, ensuring the device receives the correct current and voltage.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "As the coreset for- mation algorithms are fairly simple [ 7 ,  8 ,  36 ,  37 ], it does not take much latency or energy to convert the raw sensor data into the coreset form even while using a commercial-off- the-shelf micro-controller (like TI MSP430FR5969 [ 66 ]). This allows the EH-sensor to opt for coreset formation followed by data communication to the host device as an energy-viable alternative to local DNN inference on the original data. In our example case, transmitting the raw data (60 data points, 32bit floating point data type) needs  240 Byte s of data trans- fer, and with coreset construction and quantization we can limit it to  36 Bytes  (for 12 clusters, each cluster center is represented by 2 Bytes of data, and radius represented by 1 Byte data), thereby  reducing the data communication volume by 85% .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 214,
    "augmented": false
  },
  {
    "text": "Despite using multiple models for a single inference, importance sampling combined with aggressive model pruning, greatly reduces the resource foot- print which directly translates to the cost savings in  Cocktail . 6.2.3 Beneﬁts of Transient VMs \nThe cost-reductions in  Cocktail  are akin to cost-savings of transient VMs compared to On-Demand (OD) VMs. We pro- ﬁle the spot price of 4 types of  C5  EC2 VMs over a 2-week period in August 2020.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "443–461, 2011. [13]  M. Mangrulkar and S. G. Akojwar, “A simple and efﬁcient solar energy harvesting for wireless sensor node,” in  2016 Second International Con- ference on Research in Computational Intelligence and Communication Networks (ICRCICN) , pp. 95–99, 2016.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Prior to deployment, a global inference model  f θ  is trained offline on representative data and distributed to each sensor. This model maps sensor observations to inference outputs. Although parameters  θ  can theoretically be updated through on-edge training, we assume that frequent retraining in situ is prohibitively expensive given energy constraints.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "This stage mostly comprises of memory operations, and thus is not a compute bottleneck. The  Projection Mapping  stage (  c  in Fig. 3) takes the projection matrices for both the eyes ( P L ,  P R ) of Equation 2 as well as the pixel values of the  360 ° video frame ( F 360 ), to obtain the  2 D  FoV frames ( F L  and  F R ), which can be further displayed on the HMD.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "). ). While federated learning has gained significant attention in mobile and IoT devices, applying it to EH-WSNs presents unique challenges due to intermittent participation, limited computational capabilities, and variable data quality ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Otherwise, maintain or reduce the dropout rate to improve accuracy. Perform the forward pass with the updated dropout mask to obtain the output  Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the Shapley values of the neurons, along with the QuantaTask optimization to handle energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "360 ° V IDEO  P ROJECTION \nTo leverage the opportunities in the  360 ° video projection, we need to understand the execution of the entire projection processing in a  360 ° VR system. We illustrate the details of  360 ° video projection in Fig. 3 as three stages (detailed background of this projection transformation can be found in [21], [27]).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Using the equation above we ﬁnd the probability to be \nP head  = 10 ∑ i = ⌊ 10 \n2   ⌋ + 1 = 6 \n\u0012 10 i \n\u0013 0 . 7 i   ( 1 − 0 . 7 ) ( 10 − i )   =  0 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "1941–1953, 2017. [16] Aashish Chaubey, “Downsampling and Upsampling of Images - Demys- tifying the Theory,” ”shorturl.at/rCMPU”, 2020. [17] L. Liu, H. Li, and M. Gruteser, “Edge Assisted Real-Time Object Detection for Mobile Augmented Reality,” in  Proceedings of the An- nual International Conference on Mobile Computing and Networking (MobiCom) , 2019.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "D. Comparison against Prior Work \nAs discussed in Sec. II, DeepCache [8] also exploits the sim- ilarity between continuous frames at runtime, and decreases the computation via memory copies. However, it misses the opportunities of frame-level data reuse, and hence needs to perform inference for each and every frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "Although, multiple task-dedicated models are typically deployed to enhance accuracy and reduce sampling bias [ 70 ], particularly in scenarios like trafﬁc monitoring, where different time periods exhibit distinct trafﬁc patterns, they are not immune to data drift. As depicted in Fig. 1 , our experiments, on different modalities, shows the accuracy degradation due to data drift.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "Choosing  NP  con- serves energy but forfeits any contribution or associated reward. Because sensors have limited energy and the net- work may operate for extended periods, each sensor must consider the future implications of its current actions. The interplay of multiple sensors making similar decisions un- der uncertainty and energy constraints naturally suggests a game-theoretic framework for modeling their interactions.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "[30]  Xiaoxu Meng, Ruofei Du, and Amitabh Varshney. 2020. Eye-dominance-guided Foveated Rendering.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "III, the transformation matrix ( T  ) is determined by the head orientation, which is sampled from the built-in IMU sensors. We observe that, if the head orientation does not change across two frames, the ﬁve transforms and the  360 ° coordinate inputs remain the same, thereby providing ample opportunities for directly  reusing \n245 \nthe compute results from the previous frame ( P 1 ), as shown in  a  in Fig. 4.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "2.4. ). However, integrating game-theoretic participation strategies with machine learn- ing tasks, particularly in energy-harvesting environments, remains an area with limited exploration.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 41,
    "augmented": true
  },
  {
    "text": "This is particularly crucial in developing regions where such technology can drive innovation in healthcare, agriculture, and education. Furthermore, the development of energy-efficient, adaptive systems like NExUME is aligned with the growing need for sustainable computing practices across all disciplines of technology. By prioritizing energy efficiency and system adaptability, NExUME contributes to the sustainability and accessibility of machine learning solutions, enabling their deployment in regions where power infrastructure is absent or unreliable.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "News , 39(2):1–7, August 2011. [21] Jingwei Cai, Zuotong Wu, Sen Peng, Yuchen Wei, Zhanhong Tan, Guiming Shi, Mingyu Gao, and Kaisheng Ma. Gemini: Mapping and architecture co-exploration for large-scale dnn chiplet accelera- tors.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "Initialize the loop iteration parameters  l . Define the energy budget  E b  for a single quanta and for the entire inference. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ·  m i \nTraining with Taylor Expansion Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  λ .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "2 is invoked to decide how to process this frame (FI, PI, or SI). IV-A, the bounding boxes (BBoxes, in red) are extracted by the “full-inferenced” previous frame, and the MVs are obtained from the current frame (Frame-3). Next, based on these inputs including the BBoxes as well as MVs, Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Each user has unique expressions of behaviour classes reﬂected in the sensor data. The next challenge is to adapt the conﬁdence matrix for individual users. This table, which we call the  conﬁdence matrix , gives us the conﬁdence of each sensor for each class, and can be used as a weight for majority voting.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Note that, given an arbitrary FoV frame, these transformation matrices remain the same for all the pixel \n5 A Viewport Transformation is the process of transforming a 2D coordinate objects to device coordinates [27]. T L = T 5  ×  T 4  ×  T   L 3   ×  T 2   ×  T 1 T R = T 5  ×  T 4  ×  T   R 3   ×  T 2   ×  T 1 (1) \nThese ﬁve transforms are of dimension of  4 × 4  ( 3  dimensions for rotation;  1  for translation), thus producing  4  ×  4  T L  and T R  matrices [27]. 244 \ncoordinates in that frame, thus are evaluated only  once  for that frame, and account for only  4 .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "It delivers the promise of scaling LLMs through many smaller, specialized, independently trained expert language models. We will maintain a repository of LLM experts that are independently trained, from which we can select and modify to form an ecosystem of LLM experts for complex tasks in continually evolving usage scenarios. This repository can constantly expand in types and sizes by welcoming open- sourced, community-contributed models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "E XPERIMENTAL  R ESULTS \nIn this section, we compare our proposed intra-frame and inter-frame designs against two different PCC techniques, by evaluating four metrics critical for the PC-based applications – execution latency, energy consumption, video quality, and compression ratio. Towards this, we ﬁrst describe the conﬁg- urations (Sec. VI-A ) used for our analyses, e.g., experimental platform, dataset, and different designs (Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "All these applications rely on high quality PC capturing, processing and displaying for a more realistic experience. Additionally, with the new generation mobile phones, capable of capturing PC and then streaming them into an AR/VR enabled head mounted displays (HMDs), capturing 3D PC now is becoming as common as capturing a photograph. With this trend, the PC business is expected to reach a 10 Billion dollar industry by 2024 [ 71 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Other \n3 These results are not shown in any graph. 164 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ’21, November 1–4, 2021, Seattle, WA, USA \n98.80% \n99.20% \n99.60% \n100.00% \n0 \n10000 \n20000 \n30000 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(a) Social Network. 98.50% \n99.00% \n99.50% \n100.00% \n0 \n10000 \n20000 \n30000 \nArch Fifer DProb Kraken SProb Xanadu \nPercentage \n# Containers \n# Containers SLO Guarantees \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 167,
    "augmented": false
  },
  {
    "text": "1.1 EoE Design Space Exploration 1.2 Constructing Morphology  \nof EoE \n1.3 Continual Adaptation of  \nExperts \nExperts \nExpert Routing  Functions \nComposition  \nfunctions Independent training possible \nExplore \nStore \nExplore Morphologies \nTree EoE Graph EoE \nChain EoE \nSplitting \nMerging \nGrowing Shrinking \nMinimal Retrain Overheads \n1.4 Algorithmic Choices informed  \nby System & Hardware  \nConstraints MORPH (Graph Pruning/ \nGraph  Reconstruction/  \nExpert  Selection) \nBased  \non \n... \nSystem/Resource  Constraints \n2.2 Router  Retraining \nSystems Constraints/Decisions \n? Architectural Constraints/Suitability \nHot Experts \n2.3 Caching/Prefetching  \nHot Experts  \nCold Experts \nStorage \nRAM \nL3 $ \nL2 $ \nMem. Hierarchy \nL1 $ \n2.4 KV Cache  Management \nCompression \nHardware-aware policies \nTailored Token  Eviction \nEnsuring Coherence \nThrust 4:  \nEvaluation &  \nFine Tuning \n2.5 Runtime  \nSupport \nSLO  Guarantee \nAccuracy \n2.6 Fault Tolerant  \nExpert Training \nIsolated  Training Redundancy \nCheckpoint /Recovery \nAlgorithmic Characteristics \nDynamic Re-routing \nCross-Layer Evaluation \n3.1 Expert/Hardware  \nCo-Characterization \nExperts Hardware \nProfile  Expert Execution Attribute Database \n3.2 Chiplet-based Modular  \nHardware Platform \n3.3 Reconfiguration 3.4 Hardware-Software  \nCo-Optimization \n4.1 Evaluation Infrastructure 4.2 Methodology \nExpert,  EoE Chiplet,  Chip Chiplet, Chip Reconfigure Chiplet,  Network \nMonitor & Control \nExposed Hardware Knobs \nPath Frequency \nAccelerator Availabililty \nExperiments on  Testbeds \nAnalytical Model \nSimulation \nTraining  Dataset \nMetrics of  Interest \n• Latency • Power • Accuracy • Cost \nMemory  Constraints \nGPU \nCPU \nAccel \nAccel \nReconfig \nPlug-n-Play  \nChiplets \nExpert-to-Chiplet  \nMapping Homogeneous and  Heterogeneous Chips \nCustom  Interconnection  \nNetwork \nFigure 2 :  Overview of the proposed project.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 466,
    "augmented": false
  },
  {
    "text": "In the  Inter-Holo  scenario shown in Fig. 5b, such a region of focus is just a subset of the entire viewing window, and thus contains a small number of objects that need to be computed with rich information (as it needs 16 depth planes). However, for the objects outside of the current RoF, since the user is not cur- rently focusing on them, a reasonable approximation would not affect the user experience that much (which implies we do not need 16 depth planes for all of them).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "167 173– 186. In  2018 USENIX Annual Technical Conference .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 20,
    "augmented": true
  },
  {
    "text": "Activation solution under power level  l: <m l , n l , aG l > \nActivation solution under power level  h: <m h , n h , aG h > \nSmooth transition l->h without power prediction \nSmooth transition l->h \nwith power prediction \nSmooth transition h->l without power prediction \nSmooth transition h->l \nwith power prediction \n1 \n2 \n3 \n4 \nFig. 7. Activation solution transition FSM \nThe convolution computations of one inference may not be completed while transitioning to a new power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "DeepThings: Distributed adaptive deep learning inference on resource-constrained IoT edge clusters. IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems  37, 11 (2018), 2348– 2359. [70]  Tiago Zonta, Cristiano André da Costa, Rodrigo da Rosa Righi, Miro- mar Jose de Lima, Eduardo Silveira da Trindade, and Guann Pyng Li.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Furthermore, incorporating more advanced compute hardware, such as FPGAs, GPGPUs and other accelerators, would lead to underutilized I/O slots and memory, consequently escalating the cost of storage systems. These algorithms already consume substantial compute and memory resources, often to the extent of fully occupying the storage controller system, with a portion of resources being allocated for essential system stack operations. Current storage stacks are outfitted with robust CPUs and memory systems, which are heavily tasked with state-of-the-art storage management algorithms, as evidenced by the resource utilization outlined in TABLE 1.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "To further prove this, we also change the compute mode of Jetson AGX Xavier board to 10W, and measure the execution latency for loot video [ 54 ]. We observe that the total execution latency when using 10W mode is 1.29x of that when using 15W mode (the mode for collecting the main results). Such similar performance demonstrates that our proposal is expected to work well for low-power edge devices like smartphones as well.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Intuitively, as mentioned earlier in Sec. III (Fig. 3),  a  Transformation and  b  Projec- tion Computation remain unchanged.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "3b. Following the multiplication, the two 18-bit products undergo separate modular reductions. A Modular Reduction (MR) circuitry based on approximation (Kundi et al., 2020).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "[9]  Neeraja J. Yadwadkar, Francisco Romero, Qian Li, and Christos Kozyrakis. 2019. A Case for Managed and Model-Less Inference Serv- ing.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "These tailored models enable accurate inference with high throughput and reduced resource footprint, with some compressed models having approximately 50 ×  fewer parameters [ 30 ], but with a greater susceptibility to data drift [ 42 ], [ 55 ]. Data drift emerges as a signiﬁcant concern in real-world systems as the live data diverges from the original training data, and the environment undergoes rapid changes [ 12 ]. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "CSE Department Resources: The Department of Computer Science and Engineering (CSE) at Penn State uses a network of Linux, OS X, and Windows workstations and servers to support academic com- puting needs. Instruction is supported by highly virtualized services providing file, application, and li- cense servers for approximately 350 workstations in labs, graduate student offices, and faculty. Six student teaching labs are equipped to host digital design, FPGA, circuit design, programming, robotics/drone, and related curricula.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "Figure 10: Real System: Comparison of Total Number of Containers spawned VS SLOs satisfied by each policy. The Primary Y-Axis denotes the number of containers spawned, The secondary Y-axis indicates the percentage of SLOs met and the X-axis represents each policy. 0 \n300 \n600 \n900 \n1200 \n1500 \nArch Fifer DProb Kraken SProb Xanadu \nJobs per Container \nFigure 11: Real System: Comparison of Container Utilization (a.k.a.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "AMD and Xilinx. (Accessed on 07/13/2023). https://www.xilinx.com/applications/ data-center/computational-storage/smartssd.html , b.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Under each type, there can be subtypes of ex- perts. Expert Repository. For expert types, as shown in Figure 3, we will cover different do- mains such as scientific, medi- cal, legal, and education, skills such as math reasoning, cod- ing, question answering, and summarization, data modal- ity such as structured data (ta- bles, databases), unstructured data (documents, speech tran- scripts), semi-structured data (XML, JSON), and images, and languages such as En- glish, Chinese, Turkish, and many other low-source lan- guages.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 151,
    "augmented": true
  },
  {
    "text": "In our EoE , two unique KV cache challenges arise: i) Loading experts and their KV caches onto GPUs for a user can cause high latency and memory consumption due to the initial “prefill” stage, leading to a  cold start  problem. Task-2.4: KV Cache Management Key-Value (KV) caches in LLMs store past activations to  accelerate  inference by avoiding redundant com- putations [7, 35, 43, 73, 99, 146, 148, 163, 167, 168, 171, 172, 188, 189, 193]. In large models with billions of parameters, and close to a million context length [27, 124, 149], the KV cache size could grow to hundreds of gigabytes needing careful management.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 189,
    "augmented": true
  },
  {
    "text": "Appliance Energy Prediction \nThe appliance energy prediction data-set predicts the energy usage of home appliances, given the environmental parameters, \n3 \nAlgorithm 1:  Training and Inference Pseudocode \nfunction  T RAIN (Sensor Data, NodeID, CloudID) @Edge for  each node  do \nprep data(data,node); ▷ pre-process the data at edge if  Privacy Aware  then \ntrain model() ▷ Locally train the model send model(cloudID) \nelse \nsend data(cloudID); ▷ Send raw data to cloud \n@Cloud for  each node  do \nif  Privacy Aware  then \nsample trees(nodeID);  ▷ Sample trees from each node \nelse \nmerge data(); ▷ merge raw data from all nodes train(); end function function  I NFERENCE (Data, NodeID) @Edge for  each node  do \nPredict() if  Accuracy  ≤ Threshold  then \nSend data(CloudID); ▷ Send data to cloud for accuracy \nelse \nSend results(CloudID); ▷ Send the inference result Predict@Cloud ▷ Run Prediction at Cloud \nend function \n0 \n0.02 \n0.04 \n0.06 \n0.08 \n0.1 \n0.12 \n0.6 \n0.62 \n0.64 \n0.66 \n0.68 \n0.7 \n0.72 \n0.74 \nEdge Cloud (Shared) Cloud (Privacy) \nlatency (ms) \nCorrelation \nPearson Correlation Latency (ms) \n(a) Data from 2 homes \n0 \n0.02 \n0.04 \n0.06 \n0.08 \n0.1 \n0.5 \n0.55 \n0.6 \n0.65 \n0.7 \n0.75 \nEdge Cloud (Shared) Cloud (Privacy) \nLatency (ms) \nCorrelation \nPearson Correlation Latency (ms) \n(b) Data from 4 homes \nFig. 2: Accuracy comparison of different policies on a simulated distributed setup. The data set is divided into 2 chunks creating a two home set up and the similar is done for a 4 home setup.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 428,
    "augmented": false
  },
  {
    "text": "Thus, we can compute the probability of any function in the DAG by varying the depth,  𝑑 , using this equation. In order to apply this to proactive container allocation decisions, we can adopt the following procedure. Iterating this process for  𝑑 time steps would yield the proba- bilities of functions at a depth of  𝑑 from the start function, given by  𝑃 𝑑 =  𝑇 𝑑 ·  𝑃 0 .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "2019. \"https://github.com/google- research-datasets/Objectron/blob/master/index/shoe_annotations\". [44]  OpenCV.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "Fig. ´as  accelerator design is to ensure proper “compute place- ment” even under a power emergency or power scaling. 6 : Accelerator level  provides a high-level overview of the compute scheduling (where the redacted part of the hard- ware is turned off because of the lack of power).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "These jobs form the functional program execution DAG. For ex- ample, for a DNN execution, the jobs could be CONV2D (  C1  ), batch normalization (  C2  ), etc. However, certain jobs could be too big to execute atomically on harvested en- ergy.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Fig. 2 gives the accuracy of these DNNs on MHEALTH dataset [12], [13]. A detailed description of the setup is explained in Section IV.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "We explore the impact of privacy-preserving random forest training mechanisms to help protect sensitive data generated by the sensors. (2) Design of a threshold based edge-cloud partitioning policy which intelligently decides when to offload an inference to the cloud while maximizing the prediction accuracy and mini- mizing the communication overheads. (3) Evaluation of these policies on a publicly-available data set and also on data from real industrial grinding machines.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "With the addition of  recall , we have a fully functional ensemble learning system on a EH-WSN. AASR thus bridges the major gaps in the design that we intend to achieve. AASR intelligently takes advantage of multiple DNNs (by bringing in activity aware scheduling), leverages the workload (by considering the activity continuity via recall and extended round-robin strategies), and also poses minimal overhead on the host device for running aggregation.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "5 fps, and the battery life can be as short as just 1 hour. This motivates us to investigate which component is the major perfor- mance and energy bottleneck, charging most of the “performance- and/or energy-taxes” from the battery-backed AR headsets. 2.2 Motivation \n2.2.1 What is the Major Bottleneck?",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pp. 891–907. IEEE, 2024.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "This stability is critical for maintaining consistent network performance and energy sustainability over time. The algorithm operates as follows: \nAlgorithm 1  Distributed Best-Response Participation Algo- rithm \n1:  Input: Current energies  B i ( t ) , predicted harvest ˆ E i ( t  + 1) , parameters  γ, δ, η, β , and energy costs e cap ( · ) , e inf , e comm . Distributed Best-Response Algorithm: To realize the NE, we propose a distributed best-response algorithm where each sensor iteratively adjusts its action based on the current state and the expected actions of others.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 173,
    "augmented": true
  },
  {
    "text": "Towards this, we propose  Seeker , a novel approach that leverages and extends coresets to efficiently execute DNN inference across a set of EH sensor nodes and a host mobile device. Seeker  fo- cuses on building an efficient EH-WSN which can collabora- tively work to maximize the inferences performed at the EH- edge nodes. Furthermore, it then applies innovative coreset techniques to efficiently and intelligently offload unfinished compute tasks to a more capable host to further increase the inferences that can be performed.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Next, we consider a model where multiple devices from multiple deployments participate in cooperative data sharing. The cloud server, to accommodate data drift, periodically (but infrequently) accumulates all the data from different deployments to train a larger model which can generalize better than the local, edge specific, models. In both cases, due to the resource limitation of the edge devices, edge-specific model size may be reduced at the expense of accuracy.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "[6] T. El-Ganainy and M. Hefeeda, “Streaming Virtual Reality Content,” CoRR , vol. abs/1612.08350, 2016. [Online].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Furthermore, it the relative weight of each sensor is likely to shift from user to user. A simple solution is to assign the accuracy of each of the sensors for every class as its weight. Although accuracy is a close measurement of the conﬁdence of the classiﬁcation, it does not truly reﬂect it.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "657–669. [65] D. Zhou, S. Wang, H. Sun, J. Zhou, J. Zhu, Y. Zhao, J. Zhou, S. Zhang, S. Kimura, T. Yoshimura, and S. Goto, “14.7 a 4gpixel/s 8/10b h.265/hevc video decoder chip for 8k ultra hd applications,” in 2016 IEEE International Solid-State Circuits Conference (ISSCC) , 2016, pp. [64] H. Zhang, S. Zhao, A. Pattnaik, M. T. Kandemir, A. Sivasubramaniam, and C. R. Das, “Distilling the Essence of Raw Video to Reduce Memory Usage and Energy at Edge Devices,” in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2019, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 208,
    "augmented": true
  },
  {
    "text": "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. MICRO ’21, October 18–22, 2021, Virtual Event, Greece © 2021 Association for Computing Machinery.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Specifically,  Seeker  reaches 86.8% top-1 accuracy in com- parison to the 81.2% accuracy of the baseline system. 2 BACKGROUND AND MOTIVATION \nIn this section, we provide a background of the current state- of-the-art in performing sensing and computations on EH- WSNs. We also describe the challenges in enabling complex compute on such devices and the need for hardware-software co-design to enable specialized intermittent computing in EH-WSNs.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "C. Results \nWe present and compare the execution latency and energy consumption (via BatteryManager API in Android Studio) when performing inference for each video under the three conﬁgurations described in Sec. V-A, as well as the mAP \n3 We experimentally set  T moving  = 0 . 8 , T missed  = 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "HPG ’16, 2016, pp. [47] Tom’s HARDWARE, “Nvidia’s Jetson TX2 Powers GameFace Labs’ Standalone VR Headset.” ”https://www.tomshardware.com/news/ gameface-labs-standalone-steamvr-headset,37112.html”, 2019. [48] R. Toth, J. Nilsson, and T. Akenine-M¨oller, “Comparison of Projection Methods for Rendering Virtual Reality,” in  Proceedings of High Perfor- mance Graphics , ser.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 150,
    "augmented": true
  },
  {
    "text": "The above guidelines and the explo- ration algorithm provide a structured approach to selecting and refining  γ, δ,  and  η . By starting from theoretically in- formed baseline conditions and iteratively refining through simulation-based feedback, it is possible to reach a stable set of parameters that promotes balanced participation, discour- ages perpetual abstention, and prevents excessive energy expenditure. Regular re-tuning may be warranted as oper- ating conditions, energy harvesting patterns, or accuracy requirements evolve over the network’s lifetime.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Springer, 2020, pp. [35]  G. G. Langdon, “An introduction to arithmetic coding,”  IBM Journal of Research and Development , pp. 929–945.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 48,
    "augmented": true
  },
  {
    "text": "Associa- tion for Computing Machinery. 494–506, New York, NY, USA, 2021. In  MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture , MICRO ’21, pp.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "Informatics , 11(3):57, 2024. [131] Raghu Prabhakar, Ram Sivaramakrishnan, Darshan Gandhi, Yun Du, Mingran Wang, Xiangyu Song, Kejie Zhang, Tianren Gao, Angela Wang, Karen Li, Yongning Sheng, Joshua Brot, Denis Sokolov, Apurv Vivek, Calvin Leung, Arjun Sabnis, Jiayu Bai, Tuowen Zhao, Mark Gottscho, David Jackson, Mark Luttrell, Manish K. Shah, Edison Chen, Kaizhao Liang, Swayambhoo Jain, Urmish Thakker, Dawei Huang, Sumti Jairath, Kevin J. Large language models in healthcare and medical domain: A review.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 196,
    "augmented": true
  },
  {
    "text": "Note that  ExecTime (f)  is estimated by aver- aging the execution times of the function obtained through \n159 \nSoCC ’21, November 1–4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. 0 \n200 \n400 \n600 \nTime (ms) \nExec Time(ms) Stage-wise SLO(ms) \n(a) Social Network. 0 \nTime (ms) \nExec Time (ms) Stage-wise SLO (ms) \n600 \n450 \n300 \n150 \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 136,
    "augmented": false
  },
  {
    "text": "Swift machine learning model serving scheduling: a region \nbased reinforcement learning approach. In  Proceedings of the Inter- national Conference for High Performance Computing, Networking, Storage and Analysis , pages 1–23, 2019. [64]  Xueheng Qiu, Le Zhang, Ye Ren, Ponnuthurai N Suganthan, and Gehan Amaratunga.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "[13] Z. Lai, Y. C. Hu, Y. Cui, L. Sun, and N. Dai, “Furion: Engineering High-Quality Immersive Virtual Reality on Today’s Mobile Devices,” in  Proceedings of the Annual International Conference on Mobile Computing and Networking (MobiCom) , 2017, p. 409–421. [12] P. Guo and W. Hu, “Potluck: Cross-application approximate deduplica- tion for computation-intensive mobile applications,” p. 271–284, 2018. [14] L. Gong, C. Wang, X. Li, H. Chen, and X. Zhou, “A Power-Efﬁcient and High Performance FPGA Accelerator for Convolutional Neural Net- works: Work-in-Progress,” in  Proceedings of the Twelfth IEEE/ACM/I- FIP International Conference on Hardware/Software Codesign and System Synthesis Companion , 2017.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 224,
    "augmented": true
  },
  {
    "text": "We evaluated  Us. ´as  against DaDian- Nao, a power-efﬁcient DNN training accelerator, with some modiﬁcations for comparison. Using the Seattle SOLRAD power trace for January 1, 2022, we simulated 40 hours of continuous learning with 5 different models on Urban Trafﬁc data [ 97 ] and  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "For accuracy greater than 80%, the ensemble size drops with higher latencies. the accuracy, while short latency models need to be ensem- bled to reach the same accuracy. This is because the models which offer higher accuracy are typically dense and hence, smaller ensembles are sufﬁcient.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Integrating more number of CSDs into the standard storage server will significantly increase the cost of the server. Moreover, in large-scale systems where failure is common, replacing failed CSDs would further increase the cost. From our evaluation, we found an 8:1 ratio of SSD to CSD (capacity ratio) provides the best possible cost-to-acceleration benefit.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Additionally, storage solutions that are optimized for I/O throughput tend to lose their specialized efficiency when repurposed for general compute tasks (Haynes et al., 2021). Furthermore, incorporating more advanced compute hardware, such as FPGAs, GPGPUs and other accelerators, would lead to underutilized I/O slots and memory, consequently escalating the cost of storage systems. While the previous research has suggested the idea of integrating analytics into storage systems, these discussions usually revolve around system architecture, scheduling, and data management, without delving into the requisite compute capabilities (Haynes et al., 2021; Daum et al., 2021; Tsai et al., 2020; Xu et al., 2019).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 179,
    "augmented": true
  },
  {
    "text": "Several works have explored adaptive participation strate- gies that consider energy harvesting rates, energy consump- tion patterns, and application-specific requirements ( ? ). These strategies aim to balance energy expenditure with the need for timely and accurate data, often using heuristic or optimization-based approaches.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "However, existing MoE and CoE models have significant limita- tions. The MoEs themselves are still monolithic models albeit having intra-model sparsity, and parameter-bloating [134] in MoE leads to large training resources. Furthermore, the implications of training these MoEs in terms of required architectural and system support, overall training time, accuracy, and dynamic adaption in different application domains have not been systematically investigated.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "´as  in achieving continuous forward progress compared to other approaches. It completed more training tasks while consuming less power and minimizing wastage. The results, summarized in Table  IV , demonstrate the effectiveness of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 49,
    "augmented": true
  },
  {
    "text": "and improve its energy efficiency, with “approximation” as the core idea. Starting from investigating and evaluating the existing foveated rendering techniques, this work further explores the entire design space for potential opportunities and optimizations unique in AR applications, for speedup as well as energy savings. The major  contributions  of this work can be summarized as follows: •  We first conduct a detailed characterization of a generic AR processing pipeline to identify the major bottlenecks in current state-of-the-art AR headsets, and set our optimization target as the  hologram computation .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "Intel Power Gadget. [17]  February 2018. https://github.com/sosy-lab/cpu- energy-meter.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Thus, in order to harvest most of the speedup beneﬁts ( 42 ms  vs  1 . 55 s ), in our design, we discard the entropy encoding and still achieve reasonable compressed size, which is  ≈ 0 . 5 ×  larger than that of TMC13 [ 56 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "[ 56 ] demon- strates the possibility of performing complex DNN inference at the EH-Sensor itself. This reduces software overheads and latencies for handling power emergencies and hence can guarantee better QoS for complex and longer tasks even when power is deeply unreliable. Using an NVP and multiple harvested energy sources Qiu et al.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "The results, summarized in Table  IV , demonstrate the effectiveness of  Us. Using the Seattle SOLRAD power trace for January 1, 2022, we simulated 40 hours of continuous learning with 5 different models on Urban Trafﬁc data [ 97 ] and  Us. ´as  hardware.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "These frames are then buffered in a memory buffer, waiting for the next stage – NN Inference. NN Inference:  In this stage, the neural network (NN) pipeline takes the decoded video data to perform the inference tasks with the available compute engines (e.g., CPU, GPU, NPU, or any dedicated ASICs). Numerous prior studies (e.g., see [21]– [23] and the references therein) have clearly shown that, regardless of the type of the compute hardware employed, the NN inferences are both compute and memory intensive.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "2.2 (Fig. To capture the current RoF, an additional eye track- ing step is introduced before the hologram computations, as shown in Fig. 3b).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "Palm: Scaling language modeling with pathways. Journal of Machine Learning Research , 24(240):1–113, 2023. [28] Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "[14] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, \nA. Krishnan, Y. Pan, G. Baldan, and O. Beijbom, “nuscenes: A multimodal dataset for autonomous driving,” in  Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2020, pp. [13] R. Bird, Z. J. Baum, X. Yu, and J. Ma, “The regulatory environment \nfor lithium-ion battery recycling,” 2022. 11 621–11 631.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "Prioritizing essential tasks and deferring non-critical computations. Implementing a minimum viable model configuration that operates at the lowest acceptable energy consumption, achieved by maximizing dropout rates and using the lowest quantization bit-widths. 2.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Specifically, the weights are arranged in a way that mimics the convolution operation, such that each weight corresponds to a specific location in the input signal. To perform the convolution operation, the input signal is applied to the rows of the x-bar, and the weights are applied to the columns in a structured way. The output signal is obtained by summing the weighted input signals over a sliding window, which moves across the input signal to compute the convolution.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "Scale-sim: Systolic cnn accelerator simulator. arXiv preprint arXiv:1811.02883 , 2018. [139] Warren S Sarle.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Observation 4:  It is important to note that, the request arrival pattern plays a key role in determining if mixed procurement can be cost effective. 2.5 Challenges with  serverless functions \nApart from arrival rates, memory allocation to  serverless functions  play a non-trivial role in terms of cost. In our exper- iments we configure the memory allocation to the lambda function such that individual query latency is within the user-specified latency constraint.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Cambridge University Press, 2011, p. 41–76. [60]  W. A. Pearlman and A. Said,  Entropy coding techniques .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "496 \nMICRO ’21, October 18–22, 2021, Virtual Event, Greece Shulin and Haibo, et al. 0.2 8.0 13.8 4.4 \n120.0 \n6.0 \n341.7 \n0 100 200 300 400 \nIMU/IR \nCamera \nPose \nEstimate \nEye Track \nScene \nReconstruct \nReproject \nHologram \nInputs Perception Visual \nLatency (ms) \nOur  focus \nFigure 2: A comparison of latency requirements results col- lected from our practical setting and ideal cases shown in Table 1. 2.2.2 What are the Prior Optimization Efforts?",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks. 1414–1419. In  2021 Design, Automation & Test in Europe Conference & Exhibition (DATE) , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "To expedite the process, where it makes sense, the PIs will team up the new students with the older ones in paper writing process. Publications and Presentations \nThe PhD students will receive guidance and training in the preparation of manuscripts for scientific journals and presentations at conferences and workshops. They will have access to courses on Effective Communi- cation and Presentation Skills.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "2004. On Prediction Using Variable Order Markov Models. Journal of Artificial Intelligence Research  22 (2004), 385–421.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Tbp-former: Learning temporal bird’s-eye-view pyramid for joint perception and prediction in vision-centric autonomous driving, 2023. IEEE, 2018. Shaoheng Fang, Zi Wang, Yiqi Zhong, Junhao Ge, Siheng Chen, and Yanfeng Wang.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "[29] U. Gupta, Y. G. Kim, S. Lee, J. Tse, H.-H. S. Lee, G.-Y. Wei, \nD. Brooks, and C.-J. Wu, “Chasing carbon: The elusive environmental footprint of computing,”  IEEE Micro , vol.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "4  a  ) include the following: •  Morton Code Generation:  Given the raw PC, instead of constructing the octree point-by-point, now the ﬁrst step is to generate the Morton codes in one shot (note that this can be performed in parallel and only takes 0.5 ms ). 4  c  , the modiﬁed components in our pipeline compared to the previously-proposed geometry compression approach (depicted in Fig. This additional pre-processing step can draw an overall layout for all the points, which will further help to parallelize the octree construction.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "Area with different duplication granularity \nVII. R ELATED  W ORK \nThe previous RCA related work can be divided into the following two categories: High Performance RCA Architectures: PRIME [ 4 ] uses 6-bit inputs and 8-bit weights and targets 6-bit output precision. A composition scheme is proposed, which uses two 3-bit input signals to construct one 6-bit input signal and two 4-bit cells representing one 8-bit synaptic weight.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "However, the overhead this scheme brings when applied to YOLOv3 ( 0 . 5%  w.r.t. the baseline) is smaller than that in YOLOv4-tiny ( 4 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "3. We show that uniformly scaling resources for all models in the ensemble leads to over-provisioning of resources and towards minimizing it, we build a distributed weighted auto-scaling policy that utilizes the  importance sampling technique to proactively allocate resources to every model. In  Cocktail , we employ a per-class weighted majority voting policy, that makes it scalable and effec- tively breaks ties when compared to traditional weighted averaging, thereby minimizing the accuracy loss.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "However, one power cycle of the other power sources can usually process thousands or hundreds of inferences. For Piezo , saving the intermediate results of one incomplete inference is meaningful. However, a very small fraction is observed with the other, stronger power sources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "2), ER-r might lead to lower accuracy in many cases. A better approach is to prioritize performing inferences on the sensor that has the highest local accuracy for the current activity. However, this poses a chicken and egg problem – to know which sensor is the best for classifying an activity we need to know what activity is going to be performed beforehand.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "ISBN 978-1-939133-27-4. URL  https://www.usenix.org/ conference/nsdi22/presentation/dasari . Maureen Daum, Brandon Haynes, Dong He, Amrita Mazumdar, and Magdalena Balazinska.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Available at:  https://youtu. be/gofI47kfD28?t=685  [Accessed: 10/24/2024]. [31] Reetuparna Das, Onur Mutlu, Thomas Moscibroda, and Chita R Das.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "[75]  S. Schwarz, M. Preda, V. Baroncini, M. Budagavi, P. Cesar, P. A. Chou, R. A. Cohen, M. Krivoku ´ ca, S. Lasserre, Z. Li, J. Llach, K. Mammou, R. Mekuria, O. Nakagami, E. Siahaan, A. Tabatabai, A. M. Tourapis, and V. Zakharchenko, “Emerging mpeg standards for point cloud compression,”  IEEE Journal on Emerging and Selected Topics in Circuits and Systems , pp. [74]  R. Schnabel and R. Klein, “Octree-based point-cloud compres- sion,” in  Proceedings of the 3rd Eurographics / IEEE VGTC Conference on Point-Based Graphics , 2006, p. 111–121. 3388–3392.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 225,
    "augmented": true
  },
  {
    "text": "5%  of the end-to-end execution latency (the baseline YOLOv3 inference). Also, the PI technique consumes  23%  of the execution time in YOLOv3. Similarly, the overhead introduced by Algo.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "As shown in Algorithm  2 , for every model under a periodic scheduling interval of 1 minute ( T s ), we use the  Predicted _load ( L p ) at time  T  +  T p  and compare it with the  current_load  to determine the number of instances ( I n ). T p  is deﬁned as the average launch time for new instances. ( T s ) is set to 1 minute as it is the typical instance provisioning time for EC2 VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "Figure  3a , shows the accuracy comparison of the baseline (single) and static ensemble (ex- plained in Section  3 ) compared to the full-ensemble. It is evident that full-ensemble can achieve up to 1.65% better accuracy than single models. Besides accuracy again, ensembling can also achieve lower latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 76,
    "augmented": false
  },
  {
    "text": "Incorrect exemplar selection might lead to non-IID training data distri- bution, leading to catastrophic forgetting or over-ﬁtting. are then further reﬁned and classiﬁed by the teacher models. To improve the conﬁdence of the teacher models, we employ an ensemble learning based weighted majority voting policy [ 28 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911 , 2024. Ac- cessed: 2024-10-20. [45] Giorgio Franceschelli and Mirco Musolesi.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "The intuition is that any importance sampling scheme produces an unbiased estimator [ 8 ]. To preserve the temporal and frequency features, we ensure sampling data which are far enough from each other to build a better representation. The entire process of importance sampling uses simple arithmetic operations and is therefore viable in energy-scarce situations.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "The bars are all normalized to  ResiSchedule . The results show that ResiRCA and ResiSched- ule combine to achieve an average throughput improvement of 8 ×  compared to a baseline RCA with intermittency-unaware scheduling. The included table gives the absolute values of throughput by ResiSchedule.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "2004. [56]  Jeffrey H. Shuhaiber. Augmented Reality in Surgery.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 20,
    "augmented": true
  },
  {
    "text": "[62]  Point Cloud Library Contributors, “Module kdtree - Point Cloud Library (PCL),”  ”https://pointclouds.org/documentation/ group kdtree.html” , 2022. [63]  Point Cloud Library Contributors, “Module octree - Point Cloud Library (PCL),”  ”https://pointclouds.org/documentation/ group octree.html” , 2022. [64]  Point Cloud Library Contributors, “Pcl gpu octree,”  ”https: //github.com/PointCloudLibrary/pcl/tree/master/gpu/octree” , 2022.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 174,
    "augmented": false
  },
  {
    "text": "0 20000 40000 60000 80000 100000 120000 140000 160000 \nPV HG LeNet FR G1 G2 G3 G4 (default) G5 \nArea in ­ m 2 \n<2, 2, 2, 2, 2> <4, 3, 2, 3, 5> <6, 4, 3, 4, 7> <8, 5, 4, 5, 9> \n<12, 7, 6, 7, 13> \n<2, 2> <6, 2> <9, 3> <11, 5> <16, 7> \n<2, 2> <5, 2> <8, 3> <11, 4> <16, 6> \n<2, 2> <7, 2> <13, 3> <17, 4> <22, 6> \nFig. Area with different duplication granularity \nVII. 13.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 186,
    "augmented": true
  },
  {
    "text": "He, M. A. Qureshi, L. Qiu, J. Li, F. Li, and L. Han, “Rubiks: Practical 360-Degree Streaming for Smartphones,” in  Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services , 2018, pp. [18] J. 1192–1205, 2018.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "701–717, 2020. [41]  H. Liu, H. Yuan, Q. Liu, J. Hou, and J. Liu, “A comprehensive study and comparison of core technologies for mpeg 3-d point cloud compression,”  IEEE Transactions on Broadcasting , pp. [42]  M. Liu, “Robotic online path planning on point cloud,”  IEEE transactions on cybernetics , vol.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "´as , a sustainable continuous learning platform, which can perform video analytics by using an inter- mittent power source like solar power. The learning algorithm of  Us. ´as  delivers 4.96% more accurate classiﬁcation compared to a na¨ıve learner, and the morphable hardware design uses intermittent computing to maintain forward progress even while running on lower power budget.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "[39]  L. Li, Z. Li, V. Zakharchenko, J. Chen, and H. Li, “Advanced 3d motion prediction for video-based dynamic point cloud compression,”  IEEE Transactions on Image Processing , pp. 289–302, 2020. [40]  Y. Lin, Z. Zhang, H. Tang, H. Wang, and S. Han, “Pointacc: Efﬁcient point cloud accelerator,” in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2021, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "0 \n0.5 \n1 \n1.5 \n2 \n2.5 \n3 \n3.5 \nKittiVision nuScenes CHIME Cityscapes Waymo \nNormazed Compute Latency \nCompute Server VSS Storage Server \n(b) Latency. 0 \n2 \n4 \n6 \n8 \nKitti Vision nuScenes CHIME Cityscapes Waymo \nNormalized Data Volume \nCompute Server VSS Storage Server \n(c) Data Volume. Figure 5: Performance of  Salient Store  on larger compute and storage nodes.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "Consequently, higher weights have to be assigned to such functions to ensure resilience in the presence of varying application usage patterns. Hence, rather than simply measuring the weights only in terms of function invocation frequency, we also need to account for DAG specific factors like  Commonality  and  Con- nectivity . Opportunity 2:  Although proactive provisioning combined with probability-based scaling is useful, it is essential to iden- tify critical and common functions in each DDA and assign them higher weights in comparison to standard functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Push- ing mixture of experts to the limit: Extremely parameter efficient moe for instruction tuning. arXiv preprint arXiv:2309.05444 , 2023. [178] Ted Zadouri, Ahmet Üstün, Arash Ahmadian, Beyza Ermi¸s, Acyr Locatelli, and Sara Hooker.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "1–13. In  Proceedings of the ACM/IEEE International Conference on Mobile Computing and Networking (MobiCom) . ViVo: Visibility-aware Mobile Volumetric Video Streaming.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 46,
    "augmented": true
  },
  {
    "text": "Xanadu: Mitigating cascading cold starts in serverless function chain deploy- ments. 2020. [27]  Nilanjan Daw, Umesh Bellur, and Purushottam Kulkarni.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "[85]  Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V Le. CoRR , abs/1804.03230, 2018. Xlnet: Generalized autoregressive pre- training for language understanding.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Due to bounded  γ, δ,  and  η , and the fact that  ∆ A i ( t )  and energy costs are bounded, each  U i ( t ) is finite. Thus,  Φ( a ( t ))  is also finite for all feasible action profiles. Monotonicity of the Potential Function \nConsider a unilateral deviation by a single sensor  s j  from an action  a j ( t )  to a different action  a ′ j ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "5: Back-tracing from  out  to  in  for CONV. As discussed in Sec. IV-B2, the RoIs are essen- tial to the out- put results.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "The deployment costs differ based on the provisioning times and longevity of the resource pro- cured. WoSC’20, December 7ś11, 2020, Delft, Netherlands J.R. Gunasekaran, et al. Unlike accuracy and latency, which depends on the right model, cost is dictated by the type of deployment used to host them in a public cloud.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "[84] Dominik Kreuzberger, Niklas Kühl, and Sebastian Hirschl. IEEE Access , 11:31866–31879, 2023. Machine learning operations (mlops): Overview, definition, and architecture.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "To give an example, we selected a segment of frames (i.e.,  Frame#6750  to  Frame#6850 ) from V1 [33], in which the objects move more aggressively than other segments. In this scenario, our scheme ﬁgures out that more movements exist from large MV blocks, and dynam- ically adjusts the inference decisions. Hence, our scheme does not lose any accuracy, and still saves  43%  energy.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Since  head movement  and  cor- relations between the left and right eye projections  are the two critical components of the projection computation, we analyze and study them to explore possible opportunities to exploit these relations. Speciﬁcally, we analyze four scenarios, \n241 \n2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA) \n978-1-7281-4661-4/20/$31.00 ©2020 IEEE DOI 10.1109/ISCA45697.2020.00030 \namely,  InterFrame-IntraEye (EA) ,  IntraFrame-InterEye (AE) , IntraFrame-IntraEye (AA) , and  InterFrame-InterEye (EE) , that are critical in capturing the head movement and eye correlation for projection computation. Out of these four scenarios, we observe that  EA  computation for head orientation can be exploited for  temporal reuse/memoization  since there is little difference between two previous head orientations, and  AE computation for exploiting the correlation between both the eyes by  spatial reuse – correlating the coordinate relationship between both eyes .",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 250,
    "augmented": false
  },
  {
    "text": "Compression Pipeline:  \nTMC13 \n0 \n200 \n400 \n600 \n800 \nConst. Entropy Other Attri. 0 \n500 \n1000 \n1500 \n2000 \nTrans.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "As a result, these points can processed in  parallel . In fact, there is a mathematical concept called  Morton Code  [ 30 ] (essentially, a space ﬁlling curve that maps a multidimensional data to one dimension while preserving the locality of the data points), which describes the geometrical location relationships between points, and thus can serve this purpose perfectly. There have been prior works like N-body application [ 5 ] which utilize the Morton code for parallel octree construction 4 ; however, we believe ours is the ﬁrst work that tries to apply such technique in the PCC pipeline.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "Seeker  uses a  store-and-execute approach to complete a subset of inferences on the EH sensor node, reducing communication with the mobile host. Fur- ther, for those inferences unfinished because of the harvested energy constraints, it leverages task-aware coreset construc- tion to efficiently communicate compact features to the host device. To address these chal- lenges, we propose  Seeker , a hardware-software co-design approach for increasing on-sensor computation, reducing communication volume, and maximizing inference comple- tion, without violating the quality of service, in EH-WSNs co- ordinated by a mobile device.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "Mixture of Experts (MoE) [145] and Composition of Experts (CoE) [131, 151] models have been proposed to distribute computational loads across mul- tiple specialized networks. The new CoE architectures, which use a combination of small mono- lithic or MoE models, introduce new opportunities by allowing experts to be trained indepen- dently and incrementally, thereby reducing computational resource requirements, while enhancing fault-tolerance, and enabling the use of custom accelerators. However, existing MoE and CoE models have significant limita- tions.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "As shown in Algo. 1 , to obtain the occupy bits for one branch node, we ﬁrst calculate which branches its children should be on (e.g.,  C [  j ] %8  in Line #5), and then merge all of its occupied branches via the “ | ” operation. Therefore, an extra post-processing step is needed to merge these two arrays in the “occupy bits” style.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "These methods introduce various techniques such as embedding state information into the DNN, multi-resolution inference, multi-exit architectures, and runtime reconfig- urability to handle intermittency in energy-harvesting devices. We have faithfully re-implemented these methods as per the descriptions and adjusted them for a fair comparison under our setup. Results:  Table 1 shows the accuracy of our approach against the baselines and the recent state-of-the- art methods using the TI MSP board powered by piezoelectric energy harvesting.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "Xanadu  has only a 34% misprediction rate for  Hotel Reservation , due to the lower number of workflows, and is seen to match  Kraken  in terms of SLOs satisfied (99.87%). The breakdown of the average response times in Figure 9 shows that both  Arch  and  Xanadu  do not suffer from queue- ing delays. This is because both policies spawn a container per request, resulting in almost zero queueing.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks. In  2021 Design, Automation Test in Europe Conference Exhibition (DATE) , pages 1414–1419, 2021. [58]  Soo-Jin Moon, Jeffrey Helt, Yifei Yuan, Yves Bieri, Sujata Banerjee, Vyas Sekar, Wenfei Wu, Mihalis Yannakakis, and Ying Zhang.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "6b and 6c, the  i th-row’s pattern may not be exactly the same as the  j th-row. This is due to the ﬂoating- point hardware rounding (to ﬁnd the nearest-neighbor integer coordinates) and the transformation matrix’s various weights are dependent on the row numbers. To simplify our  AE  design, we simply reuse the pattern captured in the  1 st row, and do not consider the deeper information related to the row numbers.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "6c retain the same ellipse behavior but different shapes. Furthermore, by exacting the x (or y) coordinate in the distance vector, the above  ellipse  pattern can be represented as  Δ x  =  a  ·  cos ( θ )  and  Δ y  =  b  ·  sin ( θ ) +  c , where  θ  ∈ [0 , π ] , and  a, b, c  vary with head orientation change but remain same \nfor each row in the same frame. Additionally, there are few pixel positions at the frame edges which can only be viewed by one eye (denoted as  exclusive ), which cannot be captured by the above pattern.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 162,
    "augmented": true
  },
  {
    "text": "This prediction involves translating the blocks of  F t − 1  according to  M t  and serves as the predicted frame. The residual frame  R t  for each frame is calculated as: R t  =  F t  − predict ( F t − 1 , M t ) where  predict ( · )  is a function that reconstructs  F t  from  F t − 1  using the motion vector field  M t . Each frame  F t  is divided into blocks B t,i , where  i  indexes the block within the frame.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "Historically, researchers have investigated these components individually, often focusing on high- performance computing, scientific computing, and database applications. storage stack archi- tects often abstract the computational processes, neglecting considerations such as data movement cost, compute cost, and power requirements. However, the specific demands of ML applications on storage systems have largely been overlooked.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": ", n , we merge them into one model  θ m  by computing a weighted average of parameters where the weight is each parameter’s Fisher information:  θ m  =   P n i =1   F i θ i /  P n i =1   F i , where  F i  is the Fisher Information for  θ i . . .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "baseline InterHolo IntraHolo InterIntraHolo \nEnergy (J) \nHoloCompute Overhead \n3.68 \n1.40 1.28 \n(c) Energy consumption (J). Figure 7: (a) Average power consumption, (b) execution latency, and (c) energy consumption with different configurations and video inputs. 0 \n2000 \n4000 \n6000 \n2 4 6 8 10 12 14 16 \nPower (mW) \n# Depth-planes \nCPU SoC GPU Mem \n(a) Power breakdown.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "In Fig- ure 6(a), a naive scheduling strategy is employed on a  Simple architecture . In this scheduling strategy, the RCA is only active when the harvested power is adequate to support the maximal power requirement among all the convolution layers and, in the “simple” architecture, one convolution layer can only be mapped to one ReRAM (no ReRAM duplication). In the remainder of this paper, this execution strategy is referred to as  Naive1 .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "However, our goal is to go beyond just optimizing the geometry compression. There have been prior works like N-body application [ 5 ] which utilize the Morton code for parallel octree construction 4 ; however, we believe ours is the ﬁrst work that tries to apply such technique in the PCC pipeline. Morton Code Can Also Assist Attribute Compression: As discussed above, Morton code naturally describes the geometrical relations among points; thus, intuitively, it makes sense to utilize the Morton code to improve the geometry compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Despite high latency, prior works in this domain are crucially limited by the accu- racy offered by individual models. Abstract With a growing demand for adopting ML models for a variety of application services, it is vital that the frameworks serving these models are capable of delivering highly accurate predic- tions with minimal latency along with reduced deployment costs in a public cloud environment. Intuitively, model ensem- bling can address the accuracy gap by intelligently combining different models in parallel.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "Thus, it is important to keep learning and adapting to the user behavior. Each user has unique expressions of behaviour classes reﬂected in the sensor data. For example, gaits of two different people may signiﬁcantly vary, and might be entirely different from the training data.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Other recent works [9], [5], [7], [8] have proposed using energy harvesting (EH) solutions to provide additional energy and increase the battery life in IoT devices. These works provide software, hardware and compiler-level solutions, which can be applied to build a battery-less system working entirely on harvested energy. Moreover, in addition to prolonging device lifetime, energy harvesting can help us reduce the environmen- tal impact of batteries [10].",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Energy Storage : Finally, to ensure a continuous power supply even when the immediate energy source is inconsistent (like when a cloud passes over a solar panel), the system includes a temporary storage unit, such as a super-capacitor. This component helps smooth out the supply, providing steady power to the compute circuit. By integrating these components, an EH system can sustainably power devices without relying on traditional power grids, making it ideal for remote or mobile applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "The full training objective is formulated as: \nJ ( θ ) =  L ( θ ) +  λ 1 Ω SNR ( θ ) +  λ 2 Ω complexity ( θ ) , \nwhere L ( θ ) =  E ( x,y ) ∼D [ ℓ ( f θ ( x ) , y )] , \nand  λ 1 , λ 2  ≥ 0  are hyperparameters that balance accuracy, robustness, and efficiency. Specifically, we intro- duce two regularizers:  (1)  Ω SNR ( θ ) : Encourages the model to maintain performance across varying SNR levels, pre- venting over-reliance on high-SNR data. (2)  Ω complexity ( θ ) : Controls model complexity, reducing computational and communication overheads by discouraging overly intricate models.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 203,
    "augmented": true
  },
  {
    "text": "). The unreliability of individual EH sensors, due to fluctua- tions in energy availability, necessitates the deployment of a large number of inexpensive and potentially unreliable de- vices to ensure network robustness. However, the intermittent and unpredictable nature of harvested energy introduces significant challenges in maintaining reliable and consistent network performance ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Surv. , p. 433–466, 1995. [36] S. S. Beauchemin and J. L. Barron, “The Computation of Optical Flow,” ACM Comput.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "The ”appeared“ line represents the percentage of the frames in which the corresponding class is present, e.g. Fire hydrant, in the taken scene, is present in 100% of the frames. Incorrect exemplar selection might lead to non-IID training data distri- bution, leading to catastrophic forgetting or over-ﬁtting.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "Accessed: 2024-10-20. Graphcore intelligence processing unit (ipu). [54] Graphcore.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 26,
    "augmented": true
  },
  {
    "text": "[85] Shadi Noghabi, Landon Cox, Sharad Agarwal, Ganesh Anantha- \narayanan, “The emerging landscape of edge-computing,” in  ACM SIGMOBILE GetMobile , 2020. [86] Si Young Jang, Yoonhyung Lee, Byoungheon Shin, Dongman Lee, \nDionisio Vendrell Jacinto , “Application-aware iot camera virtualization for video analytics edge computing,” in  ACM/IEEE SEC , 2018. [87] K. Simonyan and A. Zisserman, “Very deep convolutional networks for \nlarge-scale image recognition,”  arXiv preprint arXiv:1409.1556 , 2014.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 180,
    "augmented": false
  },
  {
    "text": "Considering that a lot of motivated undergrad- uate students at Penn State are interested in ML and AI, we plan to assign well-defined projects from this research as “honors theses”. We will team an undergraduate with one graduate student for regular men- toring. We have advised several Penn State honors students (including women and minorities) through our prior NSF projects.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "2019. [46]  Nitish Padmanaban, Yifan Peng, and Gordon Wetzstein. \"http://openholo.org/database/depth\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "6.3 Sensitivity Analysis \nIn this section, we analyze the sensitivity of  Cocktail  with respect to various design choices which include (i) sampling interval of the accuracy measurements, (ii) spot-instance fail- ure rate and (iii) type of datasets and applications. 6.3.1 Sampling Interval \nTo study the sensitivity with respect to the sampling interval for measure accuracy loss/gain, we use four different intervals of 10s, 30s, 60s and 120s. Figure  13  plots the average number of models (bar- left y-axis) and cumulative accuracy (line- right y-axis) for the different sampling intervals for queries with three different constraints.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "BL indicates the baseline models. techniques combined with efﬁcient scheduling occasionally gives more accuracy than a larger and unpruned centralized DNN that is more failure-prone and power hungry. D. Adaptive Ensemble Learner \nAs discussed earlier in Section III-D, origin uses a lightweight and adaptive ensemble learner that performs weighted majority voting based on a conﬁdence matrix.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "14 347–14 357, 2017. 906 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "This can help us identify and isolate proper memoization candidates for carefully tweaking our design decisions to maximize the reuse beneﬁts. 3),  a  Transformation and  b  Projec- tion Computation remain unchanged. To understand all the contributing factors which affect computations, we further investigate the important inputs of the VR headset.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Using burstable instances in the public cloud: Why, when and how? SIGMETRICS , June 2017. [80]  Wei Wang, Jinyang Gao, Meihui Zhang, Sheng Wang, Gang Chen, Teck Khim Ng, Beng Chin Ooi, Jie Shao, and Moaz Reyad.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "Quip: 2-bit quantization of large language models with guarantees. Advances in Neural Information Processing Systems , 36, 2024. [23] Guangyu Chen and Feihui Li.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "V ), given the points sorted in the Morton code order, the search space for block matching in our proposal is minimized (in the I-frame, now, we only need to search the neighboring regions for the current P-block); 2). for the matched macro block, instead of executing the complex iterative closest point (ICP) [ 7 ] algorithm for the translation and rotation matrix, we only need to record a pointer to the matched block in I-frame, without any extra computation overhead. •  Our Intra-Inter-V2 (Compression efﬁciency-oriented):  Sim- ilarly, our Intra-Inter-V2 scheme (oriented towards high \n293 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "7 shows the comparison of our FPGA-accelerated lattice-based encryption against other state-of-the-art-techniques. RSA, the most popular encryption algorithm, when implemented using FPGA, outperforms our proposed hardware solution. However, our proposed solution offers  ≈ 3 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "However, even after preserving important fea- tures, the constructed corests are lossy representation of the original data. 3.2 Communication vs Accuracy We can tune the aforementioned coreset construction tech- niques allow a variable number of features depending on the available energy, i.e. for importance sampling, we can limit the number of points to choose, and similarly, for clustering we can limit both the number of clusters and the number of iterations.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "Prior to scaling-up instances, we need to estimate the cost  4b of running them along with existing instances. At any given time  T , based on the predicted load ( L p ) and running instances R N , we use a cost-aware greedy policy to determine the num- ber of additional instances required to serve as  A n  =  L p  − C r , where  C r  =  ∑ N i = 1   P f i , is the request load which can be handled with  R N . To procure  A n  instances, we greedily calculate the least cost instance as  min ∀ i ∈ instances Cost i  × A n / P f i .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 164,
    "augmented": true
  },
  {
    "text": "Prior works have contributed towards reducing the parameter count and the compute complexity through model pruning [63, 98, 198], knowledge distillation [55,93,113], quantization [22,46,95] along with mixture of experts (MoE) [69], includ- ing dense MoE [37,117,126,166], sparse MoE [42,74,89,145], soft MoE [111,132,178,194], and composition of experts (CoE) [59, 131, 196, 197]. Differentiating from prior art, our approach introduces a novel modu- lar, collaborative framework of LLM experts, where individual experts can be trained independently and connected in various configurations. This enables flexible, diverse ways of expert adaptation and localized training to keep pace with rapidly changing knowledge and user needs, while also facilitating cross-layer optimization for system and architecture design.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 203,
    "augmented": true
  },
  {
    "text": "To boost the inference of DNNs, some existing works employ compression (model pruning or quantization) or enhanced hardware. How- ever, most prior works focus on improving model structure and implementing custom accelerators. As opposed to the prior work, in this paper, we target the video data that are processed by edge devices, and study the similarity between frames.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "For certain baselines like IRV2, ensemble-spot is also 1.5 × cheaper than single-OD. However, the crucial downside of using transient VMs is that they can be unilaterally preempted by the cloud provider at any given point due to reasons like in- crease in bid-price or provider-induced random interruptions. Figure  3b  shows that ensemble-spot can re- duce the cost by up to 3.3 ×  when compared to ensemble-OD.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. locality opportunities (i.e., the smaller area, the better).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "The ﬁrst stage,  Transformation  (denoted  a in Fig. 3, is to determine a transformation matrix by com- bining ﬁve different transforms. 3 as three stages (detailed background of this projection transformation can be found in [21], [27]).",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "[199] Yang Zhu, Luke Zettlemoyer, and Jimmy Ba. In  Proceedings of the 2015 Conference on Em- pirical Methods in Natural Language Processing (EMNLP) , pages 58–68. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 74,
    "augmented": true
  },
  {
    "text": "[19]  Muhammad Huzaifa, Rishi Desai, Samuel Grayson, Xutao Jiang, Ying Jing, Jae Lee, Fang Lu, Yihan Pang, Joseph Ravichandran, Finn Sinclair, Boyuan Tian, Hengzhi Yuan, Jeffrey Zhang, and Sarita V. Adve. In  Imaging and Applied Optics Congress . Optical Society of America, HF3G.1.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "[67] D. Patterson, J. Gonzalez, Q. Le, C. Liang, L.-M. Munguia, \nD. Rothchild, D. So, M. Texier, and J. Dean, “Carbon emissions and large neural network training,”  arXiv preprint arXiv:2104.10350 , 2021.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "292 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "´as  uses a super-capacitor assisted voltage regulation circuit. To properly model the energy harvesting, losses during conversion, and leakage, we built a rectiﬁcation circuit with 4  ×  5 . Energy Buffering and Power-Predictor:  To regulate, manage and ensure a stable power supply to the circuitry,  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Post-loading, each SDMM \n11 \n6bit shift  register \nSDMM SDMM \n13bit register \nControl logic \na \nb \nc \nb c \nd \n(a) HSPM micro-architecture. - \nt << n + - - MR logic \n- \nt << n + - - \nDSP  Unit \na i \nb 0 \nb 1 \nS \nMR logic \nd 0 \nd 1 \n(b) Pipeline SDMM Structure micro-architecture. Figure 3: Microarchitectural designs of HSPM and SDMM: Hardware modules for polynomial multiplication in LBC.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "A CKNOWLEDGMENTS \nWe would like to offer our thanks to the anonymous reviewers for their detailed feedback, which has greatly helped to improve and reﬁne this paper. This work was supported in part by Semiconductor Research Corporation (SRC), Cen- ter for Brain-inspired Computing (C-BRIC) and NSF Grant #1822923 (SPX: SOPHIA). We acknowledge that all product names used are for identiﬁcation purposes only and may be trademarks of their respective companies.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "Since, all the deployments are working on the same task, and have trained on similar data, we will be able to perform the analytics task within a reasonable accuracy bound. However, if the confidence bound at the peer is not met, the cloud is contacted, at higher latency than having directly contacted the cloud to begin with. In our experiments, we observe that, in most cases, the accuracy of the peers are similar to that of the edge node.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "For each frame, this computation is processed twice – one for left eye and the other for right eye – to reinforce users’ sense of depth. Display:  After the projection, the two generated FoV frames are stored in 2D format in the video buffer. The head orientation is sensed by an inertial measurement unit (IMU) on the HMD as a triple [ Y aw ,  Pitch ,  Roll ] for projection computation 2 .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the 10th ACM con- ference on recommender systems , pages 191–198, 2016. [25]  Daniel Crankshaw, Peter Bailis, Joseph E Gonzalez, Haoyuan Li, Zhao Zhang, Michael J Franklin, Ali Ghodsi, and Michael I Jordan. The missing piece in complex analytics: Low latency, scalable model man- agement and serving with velox.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Labels: MN – MobileNet-V2, BL – Baseline, Teacher – the ensemble of teacher models, MN–#: targeted MobileNet-V2 model for the particular time of day. A. Continuous Learning: Accuracy \nFig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "Springer, 2016, pp. 630–645. [33] IBM, “Data labeling,”  https://www.ibm.com/cloud/learn/data-labeling , \n(Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "[34] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms. Association for Computational Linguistics.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "2: Overview of  360 °  video projection. (a) Power breakdown consuming 3.4 Watts; (b) Projection pipeline taking head orientation and pupillary distance to compute projection matrices for both the eyes, which map  360 °  coordinates to 2D coordinates for generating stereoscopic frames. (c) Reusing projection matrices by exploiting relation between both eyes and fusing it with head orientation.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "The main reason for this is that the  ResiSchedule  policy can efﬁciently organize more hardware resources than the  Sequential  policy when hardware resources are limited. As expected, the throughput increases as  G  grows for every benchmark. Another interesting observation is that the results of  ResiSchedule  policy can be competitive to that of  Sequential policy when  G  is small and vice versa.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Using the predicted load  6a  ,  Cocktail  spawns additional instances, if necessary, for every instance pool. In  Cocktail , we use a load prediction model that can accurately forecast the anticipated load for a given time interval. In addition, we sample SLO violations for every 10s interval and reactively spawn additional instances to every pool based on aggregate resource utilization of all instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "Megatron-lm: Training multi-billion parameter language models using model parallelism, 2020. [150] Sonali Singh, Anup Sarma, Sen Lu, Abhronil Sengupta, Mahmut T. Kandemir, Emre Neftci, Vijaykr- ishnan Narayanan, and Chita R. Das. Skipper: Enabling efficient snn training through activation- checkpointing and time-skipping.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "[68]  F. Qian, B. Han, J. Pair, and V. Gopalakrishnan, “Toward prac- tical volumetric video streaming on commodity smartphones,” in  Proceedings of the 20th International Workshop on Mobile Computing Systems and Applications , 2019, p. 135–140. [69]  Z. Que, G. Lu, and D. Xu, “Voxelcontext-net: An octree based framework for point cloud compression,” in  CVPR , 2021, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "This point-by-point “update” makes this stage difﬁcult to parallelize. •  Octree Serialization:  After the octree has been constructed, the tree is traversed in a top-to-bottom manner, in order to extract the  occupy  bits for each node, and record them in a predeﬁned order (e.g., via depth-ﬁrst traversal), such that the decoder can recover the octree with these occupy bits as well as the serialization order. Note that this step is also time-consuming, as shown in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "Motivated by this, we further optimize the attribute compression pipeline for a given frame, as shown in Fig. 4  d  . Speciﬁcally, our proposed new pipeline includes the following three steps: \nFigure 5: Intra-Frame geometry compression example.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "Plan of Activities:  Aligned with the departmental BPC plan, we plan to pursue several activities related to this proposed research as summarized below: •  Customized Graduate Student Recruiting and Training:  We will recruit graduate women and students from populations underrepresented in computing to work on this project. For this, we will collabo- rate with the Multicultural Engineering Graduate Student Association (MEGA) and Graduate Women in Engineering (GradWIE) programs. Moreover, the CoE (College of Engineering) is a partner with the National GEM Consortium that leads the Grad Lab, which facilitates the participation of populations underrepresented in computing for graduate studies in engineering and science.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 143,
    "augmented": false
  },
  {
    "text": "Using Scene Viewer to Display Interactive 3D Models in AR from an Android App or Browser. 2020. [3]  ARCore.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "2.2 (Fig. 3b). To capture the current RoF, an additional eye track- ing step is introduced before the hologram computations, as shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "For example: \nγ  ·  ∆ A max  < η  +  margin , \nwhere  margin  accounts for future opportunities and energy savings. Practical Hyperparameter Tuning Strategies \n1. A small  margin  ensures sensors do not always expend maximal energy for short-term gains.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "[103] Eitan Medina and Eran Dagan. Habana labs purpose-built ai inference and training processor ar- chitectures: Scaling ai training systems using standard ethernet with gaudi processor. IEEE Micro , 40(2):17–24, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Vichar: A dynamic virtual channel regulator for network-on-chip routers. In  2006 39th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO’06) , pages 333–346. IEEE, 2006.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 50,
    "augmented": true
  },
  {
    "text": "Several recent efforts have been put into optimizing the 3D CNN to increase the compression ratio and/or decrease the number of parameters in the neural network model [ 27 ], [ 69 ]. However, based on the results reported in [ 40 ], even with a custom 3D-CNN accelerator, only 2.5 ×  speedup could be achieved for 3D-CNN compared to edge GPU. Considering that NN-PCC can take thousands of seconds to compress one PC frame [ 88 ], such a huge gap between the long execution latency of NN-PCC and the \n2 Although V-PCC and NN-PCC have high compression efﬁciencies, they are compute-intensive [ 41 ], [ 88 ], and consequently, are not the best option for mobile devices and are not considered in this work.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 182,
    "augmented": false
  },
  {
    "text": "The backpropagation is applied only to the layers of the autoencoder, ensuring that the feature extractor’s parameters remain intact. The training process is designed to optimize the autoencoder’s ability to compress and decompress video sequences efficiently, without altering the pretrained feature extractor, thereby providing a stable, high-performance baseline for feature representation. The mathematical formulation for this training process is centered around minimizing the reconstruction loss,  L  =   P N t =1   ∥ F t  − ˆ F t ∥ 2 2 ; where  F t   is the original frame at time  t , and  ˆ F t   is the reconstructed frame, obtained by decoding the compressed representation that was encoded using features extracted via MobileNet and refined by the motion vector-informed autoencoder.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 184,
    "augmented": true
  },
  {
    "text": "4.3) and found to reduce around 23% execution latency (in Sec. More recently, another foveated rendering based CGH reconstruction technique has been proposed to accelerate calculations with negligible effect for the viewer [ 22 ]. We implemented such foveated rendering idea (de- noted as  Inter-Holo  design in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "It also provides us access to new contacts and additional recruitment opportunities of diverse students. For example, we have performed demonstration events at the local Science Museum for kids and the regional arts festival based on interaction with individuals who visited our exhibits. The PIs and their students are passionate about the broader outreach and in kindling interest in the K-12 students to pursue STEM careers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "or by developing an application speciﬁc model from scratch along with the said optimizations. These student models, thanks to their lack of robustness (which is often, but not always, related to the smaller footprint they have, and thereby lacking the parameter space to generalize better), are susceptible to data drift and hence are continuously retrained. However, the teacher models are typically large, and with a wide parameter space can generalize the learning process better than the students.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "It can be seen that for ﬁxed accuracy of 72%, 78% and 80%, the average number of models increase with increase in latency, but drops to 1 for the highest latency. Intuitively, singe large models with higher latency can satisfy \n0 2 4 6 8 10 \n0 \n100 \n200 \n300 \n400 \n72 78 80 81.5 83.5 85 \nAvegae #Models \nLatency (ms) \nAccuracy (%) \nLatency Average #Models \n(a)  Fixed Accuracy. 0 \n2 \n4 \n6 \n8 \n60 \n70 \n80 \n90 \n60 70 100 120 150 350 \nAverage #Models \nAccuracy (%) \nLatency (ms) \naccuracy Average #Model \n(b)  Fixed Latency.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 153,
    "augmented": false
  },
  {
    "text": "Accuracy Saving Adaptivity Custom HW DM MCDNN [7] \u0017 \u0013 \u0013 \u0013 Resource Budget Potluck [12] \u0013 \u0017 \u0013 \u0013 Feature Vector Euphrates [9] \u0013 \u0013 \u0017 \u0017 Reuse Distance DeepCache [8] \u0013 \u0017 \u0017 \u0013 Reuse Distance This Work \u0013 \u0013 \u0013 \u0013 Motion Vector \ncan be relatively low (as in Potluck [12] and DeepCache [8]). A check-mark in the Custom HW column indicates that the corresponding approach does not need custom hardware, whereas a cross means it needs. Additionally, sometimes sudden changes in subsequent frames (e.g., with a new object in the frame), require adaptive decisions, which cannot be achieved by Euphrates [9] and DeepCache [8].",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "In  The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays , pp. 262–272, 2021. Sahand Salamat, Hui Zhang, Yang Seok Ki, and Tajana Rosing.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "We collect the display traces from a 5-inch (130 mm) 16:9 1080p (1920 × 1080) AMOLED display [54], which is similar to the Samsung Gear VR display [45]. Fig. 8: Evaluation proto- type – Nvidia Jetson TX2 GPU board [36] (PMU: Power Management Unit).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "733–747, 2019. T260–T261, 2017. [9]  Y. Ji, Y. Zhang, X. Xie, S. Li, P. Wang, X. Hu, Y. Zhang, and Y. Xie, “FPSA: A full system stack solution for reconﬁgurable reram-based NN accelerator architecture,” in  Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 117,
    "augmented": true
  },
  {
    "text": "[82]  Carole-Jean Wu, David Brooks, Kevin Chen, Douglas Chen, Sy Choud- hury, Marat Dukhan, Kim Hazelwood, Eldad Isaac, Yangqing Jia, Bill Jia, et al. arXiv preprint arXiv:1910.03771 , 2019. Huggingface’s transformers: State-of- \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1055 \nthe-art natural language processing.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "This re- search is supported by NSF grant #1822923 and Clean Energy Smart Manufacturing Innovation Institute award #136067. R EFERENCES \n[1] Automating the grinding process, 2013. https://www.sme.org/technologies/articles/2013/january/automating-the- grinding-process/. [2] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Koneˇcn`y, Stefano Mazzocchi, Brendan McMahan, et al.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 146,
    "augmented": false
  },
  {
    "text": "Instead, our chip creation strategy can quickly and frugally take advantage of upcoming accelerators not only from industrial sources but also from academic institutions. Using the expert execu- tion attribute database, we can extract the expert-hardware affinity, corresponding to which the equivalent chiplet versions are integrated to design a chip (in this regard, we will also consider existing and upcoming hardware accelerators [47, 61, 115, 131, 173]). Although datacenters also try to take leverage of the diversity of heterogeneous computing platforms, they are much slower and very expensive during adop- tion [50,104,105].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "A significant amount of research [ 18 ,  22 ,  24 ,  38 ,  39 ,  43 ,  52 ] has been focused to- wards reducing cold-start overheads (in particular, proactive container provisioning [ 3 ,  32 ,  44 ,  46 ]). While probability-based container provisioning can significantly reduce the number of containers, the presence of container cold-starts leads to SLO violations (requests not meeting their expected response latency). This is because cold starts can take up a significant proportion of a function’s response time (up to 10s of seconds [ 13 ,  14 ]).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "To achieve the dual modes of FF subarrays and maximize reusability, custom peripheral circuits are designed. In the ISAAC design [ 3 ], the inputs, weights and outputs are all 16 bits, where the DAC, ReRAM cell and ADC resolutions are, respectively, 1-bit, 2-bit and 8-bit. Also, a similar composition scheme is employed to organize the input, weight and output data.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "To cater towards this, in this work, we propose  Salient Store  – a mini computational storage server (we call it “edge storage server”) stack for managing the data archival in edge servers. Salient Store  provides adaptive data compression using neural codecs and further enhances the data security by providing an accelerated quantum safe data encryption policy, protecting these vulnerable edge storage servers against the store now decrypt later (National Cybersecurity Center of Excellence (NCCoE), 2023) attacks. 3 Data Compression using Neural Codec \nIn this section we go over the overall design and design choices for the neural codec design of Salient Store  .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "Unlike conventional networks, where an entire end-to-end training of the experts and routers needs to be done alike, our scheme makes use of a more targeted approach that can sig- nificantly reduce the training complexity of the routers. In our methodology, the router only needs to be fine-tuned on the dataset of the expert that it interfaces with, which is much smaller than the entire dataset. As has been highlighted in Table 2, we plan to exploit the expert-router affinity to reduce the training com- plexity of the router at initial training time and even while fine-tuning as the ensemble of experts evolve.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "). In the context of EH-WSNs, game-theoretic models have been employed to design dis- tributed algorithms for resource allocation, power control, and cooperative communication ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Abstract \nThe advent of transformer-based architectures [157] has revolutionized the field of natural language pro- cessing (NLP), exhibiting unprecedented capabilities in understanding the nuances of human language, maintaining rich context, and generating human-like responses. At the forefront of these transformative advancements are Large Language Models (LLMs), which have led to a paradigm shift in NLP and artifi- cial intelligence (AI) at large. Their seamless integration into everyday life across diverse domains—such as virtual assistants [12,16,51], customer service chatbots [6,121], code generation tools like GitHub Copi- lot [48], and knowledge management systems like NotebookLM [52]—has profoundly impacted how we interact with technology.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 166,
    "augmented": true
  },
  {
    "text": "\"https: //www.businessofapps.com/data/pokemon-go-statistics/\". [6]  Chenliang Chang, Kiseung Bang, Gordon Wetzstein, Byoungho Lee, and Liang Gao. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "By loading these selected potentially useful and relevant experts into the main memory, we propose to optimize the response time and computational efficiency. This dynamic allocation allows for a flexible working set of experts hosted in the main memory, tailored to the specific needs of the batch of requests currently being processed. When a new batch of requests is introduced into the system, an initial selection of the top-k experts is conducted for each request in the initial layer of processing.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "This would lead to a reduction in cold-start latencies incurred for users with the same type of requests. 3.2.4 Configuring Serverless Functions  In keeping with  Observation 5 , it is quintessential to configure the mem- ory allocation of  serverless functions  to meet the application SLOs. Through offline profiling or initial runs, we can de- termine the right memory allocation for a given response latency.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Compared to a state-of-the-art scheme [28], our design provides  34%  reduction in projection computations, which translates to  17%  additional energy savings. Fig. 1: A  360 °  video processing pipeline on a battery-backed stereoscopic HMD with an Inertial Measurement Unit (IMU) and an SoC equipped with a GPU [28], [39].",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "1 and Algo. 8d, the overheads (due to the decision making module in Algo. 8b and Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "These mismatches can lead to the following two “nonideal” working scenarios: (i) Unutilized energy:  As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive. (ii) Underutilized energy:  When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level. In this case, the harvested energy will leak away and cannot be recovered.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Ties occur when two sets of equal number of models predict a different result. The effectiveness \n1046    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nAlgorithm 2  Predictive Weighted Instance Auto Scaling \n1:  procedure  W EIGHTED _A UTOSCALING ( Stages ) 2: Predicted_load  ← DeepARN_Predict (load) 3: for  every Interval  do 4: for  model in  ∀ Models  do 5: model weight  ← get _ popularity ( model ) 6: Weight . append ( model weight ) 7: end for 8: end for 9: if  Predicted_load  ≥ Current_load  then 10: for  model in  ∀ Models  do 11: I_n  ← (Predicted_load - Current_load) × model weight 12: launch_workers ( est_VMs ) 13: model.workers.append ( est_VMs ) 14: end for 15: end if 16:  end procedure \nof weighted voting in breaking ties is discussed in Section  6 .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 253,
    "augmented": true
  },
  {
    "text": "Speciﬁcally, our proposed new pipeline includes the following three steps: \nFigure 5: Intra-Frame geometry compression example. •  Sort and Segment Points:  Unlike the prior works which utilize the octree to capture the spatial locality between the points when compressing the attributes, we use the Morton codes to cluster the points which are spatially close to each other. Speciﬁcally, with the Morton codes for all the points (i.e., the intermediate results from geometry compression without any additional overhead), we ﬁrst sort these points in the Morton code order, and then segment these sorted points into several blocks which can help to gather the points with similar positions/coordinates into one segment.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 151,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. frame (or skip the current frame).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "However, it is  not  desirable to execute the infer- ence on the mid- dle part, since, in order to do so, one needs to prepare an input larger than the inner region (due to the various kernel sizes in the convolution, e.g.,  3  ×  3 ,  5  ×  5  [38]), which eventually turns out to be the FI. Rather than computing, we \n2 Since CONV layers dominate total computation in DNN inference [8], our partial inference technique is applied only to the CONV layers; the other layers employ full inference. Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "Unlike prior works, we suggest that the input and output parameters can be any linear combination of the three primary parameters men- tioned above, depending on the application constraints. Note that, in contrast to cost and response-latency, accuracy can- not be determined just from the previous runs. We need some feedback from the end-user to make a correct estimate of accuracy.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 81,
    "augmented": false
  },
  {
    "text": "[140] Anup Sarma, Sonali Singh, Huaipan Jiang, Rui Zhang, Mahmut Kandemir, and Chita Das. [139] Warren S Sarle. Finding groups in data: An introduction to cluster analysis., 1991.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "Office Space:  Each PI has an office that is approximately 75 sq. ft., including desks with workstations and peripherals. Finally, our partnership with ANL (see the attached collaboration letter) allows us to access ANL re- sources, including hardware accelerators for LLM.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "Thus, to further improve the attribute compression efﬁciency, in the next section, we investigate the inter-frame similarity opportunity. Similar to the intra- frame proposals discussed in Sec. V. I NTER -F RAME  A TTRIBUTE  C OMPRESSION  D ESIGN \nMotivated by the above discussion, in an attempt to further improve the compression efﬁciency from an inter- frame perspective, in this section we explore the ”attribute similarity” that exists across consequent frames in a PC video, and explain the design details of our proposed inter- frame attribute compression scheme.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "As discussed above in Sec. 1b), such as IMU sensors, eye tracking or IR sensors, hand motion sensors, RGB-D im- age sensors, etc. To improve the hologram approximation, we need to first identify the set of inputs that affect the hologram computing the most.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "Also, Kandemir was a co-PI on a recent MRI award. The PIs also have access to NSF CloudBank, ACCESS and various NERSC resources. This grant enables the PIs as well as the project team to access, among other resources, hundreds of Intel Xeon nodes, various types of NVIDIA GPUs (A100 and V100), and two large storage arrays consisting of various types of HDDs, SSDs, FPGAs, as well as 4 computational storage devices (Samsung SmartSSD).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "More is less: Model augmentation for intermittent deep inference. ACM Transactions on Embedded Computing Systems (TECS) , 21(5):1–26, 2022. Heiner Lasi, Peter Fettke, Hans-Georg Kemper, Thomas Feld, and Michael Hoffmann.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Considering the cheap commodity use storage devices are often plug and play, they are often vulnerable for data leak, especially if they are deployed in public, like urban mobility setting. Unlike secure data centers, these federated, distributed and public deployment could be susceptible to direct physical attacks for data breach. Although modern encryption algorithms like RSA are secure, there is still a threat of  store now decrypt later 2   kind of attack (National Cybersecurity Center of Excellence (NCCoE), 2023).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "Autonomous driving and urban mobility applications, generating over 400TB of data annually (Wright\"; \"premioinc\"; Bhardwaj et al., 2022), predominantly comprise video and 3D point cloud data, making them ideal for our evaluation. The  Cityscapes data-set (Cordts et al., 2015) is a comprehensive collection of urban street scenes from 50 different cities, providing a rich source of annotated video data for semantic urban scene understanding. This data-set is particularly suited for evaluating the performance of  Salient Store  in dense, urban environments.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "To gather input data, we plan to utilize publicly available datasets such as Wikipedia [164], Common Crawl [29], BookCorpus [199] and OpenWebText [49], along with our proprietary repositories. After necessary post-processing, these data points will be employed to train, validate, and evaluate our expert models. The insights gained from these simulations and modeling efforts will be instrumental in refining run- time performance and providing informed estimates regarding the system and hardware demands of emerging applications.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "IV-B  and Sec. Figure 4: Intra-frame PCC pipelines. IV-C .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 24,
    "augmented": true
  },
  {
    "text": "The reduction in the number of containers spawned by Kraken  in comparison to other policies is roughly propor- tional to the total number of application workflows and the slack available for each function within a workflow (see Ta- ble 2 and Figure 7). For instance, Figure 8 indicates that the Social Network ,  Media Service  and  Hotel Reservation  applica- tions show the highest (73%, 53% and 36%), moderate (40%, 28% and 7%) and least (at most 33%) reductions in the number of containers spawned with respect to existing policies,  Arch , Fifer  and  Xanadu , respectively. Both  Social Network  and  Me- dia Service  have a high number of workflows, but the former has more functions with higher slack, leading to increased batching, thereby resulting in the most reduction in con- tainers spawned.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 202,
    "augmented": false
  },
  {
    "text": "This amounts to about  2.3 GFLOPS , which represents a substantial amount of computation, given the limited compute capabilities and power in such edge devices. Note that, even though theoretically one represents the  360 ° frame coordinates as quaternions, in practice, they are typically represented using speciﬁc projection formats, e.g., equirectangular, cube map, equi-angular cubemap, pyramid format, etc. The details of these formats are in the purview of cartography and computer graphics domain, and hence we do not evaluate all of the aforementioned formats.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 132,
    "augmented": true
  },
  {
    "text": "chooses a set of single or ensemble models required to meet the developer speciﬁed constraints. Discussion:  Our accuracy and latency constraints are limited to the measurements from the available pretrained models. Note that changing the models or/and framework would lead to minor deviations.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Note that, within the LBC algorithm, certain components, specifically polynomial multiplications, exhibit similarities to operations performed in CNNs. This quantum resilience is vital for protecting large data-sets on machine learning storage servers, particularly from ’store now, decrypt later’ threats. Algorithm 3  Lattice-Based Encryption Process \n1:  procedure  L ATTICE _B ASED _E NCRYPT (message, public_key) 2: PM  ← ConvertToPolynomial(message) 3: (PA, PE)  ← GenerateRandomPolynomials() 4: C1  ← PolynomialMultiply(PA, public_key) ▷ Utilizing HSPM 5: C2  ← PolynomialMultiply(PA, PM) ▷ Employing SDMM 6: return  (C1, C2) 7:  end procedure \nAt the heart of LBC lies the Ring-Learning with Errors (R-LWE) algorithm, which translates plaintext messages into polynomial representations and intertwines them with random polynomials using complex multiplications and additions, as delineated in Algorithm 3.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 274,
    "augmented": true
  },
  {
    "text": "The method includes targeted fine-tuning that not only regularizes the model but also pre- vents overfitting, enhancing robustness to fluctuations in resource availability. This involves an innovative strategy of learning instantaneous energy-aware dynamic dropout and quantization selection during training, and an intermittency-aware task scheduler during inference. NExUME uniquely integrates energy variability awareness directly into both the training ( DynFit ) and inference ( DynInfer ) processes, enabling DNNs to dynamically adapt computations based on real-time energy availability.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "8697–8710. 907 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "The output currents I1 and I2 are the result of the multiplication-addition operation, and are obtained by summing the currents flowing through the ReRAM devices. In practice, ReRAM crossbar arrays can have many more cells, and can be used to perform more complex multiplication-addition and convolution operations. However, the basic principle remains the same, where the input signals are applied to the rows, the weights are applied to the columns, and the output signals are obtained by summing the currents flowing through the ReRAM devices.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "In our setup, one I-frame(intra-compressed frame) is followed by two P-frames(predicted frames), and the number of threads for MB matching is set to 4. •  CWIPC  [ 13 ], [ 48 ]: CWIPC is a PCC library that supports the inter-frame compression (encoding the predicted frame via macro block (MB)-based motion estimation). We use CWIPC as the  state-of-the-art  approach for  inter-frame compression  and build it with multi-thread option.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "The ﬁrst step towards making model ensembling cost effective is to minimize the \n1044    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \number of models by pruning the ensemble, which reduces the overall resource footprint. In order to estimate the right number of models to participate in a given ensemble, we conduct an experiment where we chose top   N \n2   accurate models (static) from the full-ensemble of size  N . From Figure  3a , it can be seen that the static policy has an accuracy loss of up to 1.45% when compared to full-ensemble, but is still better than single models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 139,
    "augmented": false
  },
  {
    "text": "the state-of-the-art techniques ( 1 . 55 s latency in prior works vs.  42 ms latency in ours). To better understand where the beneﬁt comes from, next we go over a simple example, given in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "To study how these approximation decisions affect the hologram video quality, we next want to reconstruct/render the hologram from our design based on the real-time eye move- ments and head orientations, and compare the quality of the recon- structed images against the baseline using the peak signal-to-noise ratio (PSNR) [ 21 ,  44 ] metric. Given the lack of the physical optical holographic displays (e.g., the prototype built in Tensor Holog- raphy project [ 54 ]), we numerically generate the reconstructed holographic images on top of the OpenHolo library [ 18 ]. Three demo examples of reconstructed images by OpenHolo are shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 172,
    "augmented": false
  },
  {
    "text": "6.2 Key Sources of Improvements \nThe major improvements in terms of cost, latency, and accu- \nracy in  Cocktail  are explained below. This is because the twitter workload is bursty, thereby leading to intermittent over-provisioned VMs. For brevity in explana- tion, the results are averaged across Wiki and Twitter traces for strict workload.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "[38]  Synopsis, “HSPICE.” https://www.synopsys.com/veriﬁcation/ams- veriﬁcation/hspice.html/. 39, pp. 1–7, Aug. 2011.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "Each task, represented in the queue, corresponds to the execu- tion of speciﬁc CNN kernels, feature tiles and operations. As deep neural network models often have a complex interplay of layers, each with distinct computational needs, the work queue ensures a systematic, prioritized approach to handle these oper- ations. Two distinct scheduling strategies, each complemented by its own type of work queue, govern the computational ﬂow: Conservative Scheduling and Eager Scheduling.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "´as  an excellent solution for continuous learning across diverse application sizes. As data and model dimensions decrease, the hardware assistance’s impact becomes more pronounced, making  Us. Along with morphable hardware, the exemplar selection and the micro-proﬁler play an important role for the success of  Us.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Therefore, it is important to choose a threshold that optimizes the trade off between efficiency and accuracy. Similar to the data on inference time, the effect from the increasing threshold on prediction accuracy will be more pronounced when there are more devices available and the overall trend seen in Figure 4c is the inverse of that in Figure 4a. This makes it possible to find a sweet spot, given specific needs, in efficiency and accuracy trade offs.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Pushing point cloud compression to the edge. In  2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp. 282–299, 2022a.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "[28] Y. Leng, C.-C. Chen, Q. edu/vr/vrch3.pdf”, 2019. [27] S. M. LaValle, “The Geometry of Virtual Worlds.” ”http://msl.cs.uiuc.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "(Accessed on 11/13/2023). www.dlapiperdataprotection.com. Sweden data collection & processing.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "Task-3.4: Going beyond with Hardware Software Co-optimization Achieving 100% effectiveness in SLO metrics will not be possible just with the algorithms and system tech- niques mentioned in Thrusts 1 and 2 unless the underlying hardware is  co-designed  with the software. In this design space, we plan to expose various “knobs” from hardware via which software can better monitor and control the execution. Further, based on our profiling of the communication behavior across chiplets and chips, we will consider performant and adaptive interconnect designs [80, 81, 110, 116, 127] to co-optimize for latency, bandwidth, and fault tolerance.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 146,
    "augmented": true
  },
  {
    "text": "7. Activation solution under power level  l: <m l , n l , aG l > \nActivation solution under power level  h: <m h , n h , aG h > \nSmooth transition l->h without power prediction \nSmooth transition l->h \nwith power prediction \nSmooth transition h->l without power prediction \nSmooth transition h->l \nwith power prediction \n1 \n2 \n3 \n4 \nFig. Activation solution transition FSM \nThe convolution computations of one inference may not be completed while transitioning to a new power level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 133,
    "augmented": true
  },
  {
    "text": "We believe that our solution can be easily deployed and be beneficial for random forest based distributed sensing-computing platforms. A CKNOWLEDGEMENTS \nWe thank the reviewers for their helpful feedback. This re- search is supported by NSF grant #1822923 and Clean Energy Smart Manufacturing Innovation Institute award #136067.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "2017. InfiniTAM v3: A Framework for Large-Scale 3D Reconstruction with Loop Closure. CoRR (2017).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 32,
    "augmented": false
  },
  {
    "text": "Diminishing Step-Size and Convergence Results \nClassical convex optimization theory (see Bottou et al. (2018) or Nemirovski et al. (2009)) states that for con- vex, Lipschitz-smooth objectives and unbiased gradient oracles, SGD converges to a stationary point if the step sizes  { α k }  decrease at an appropriate rate.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Post-quantum cryptography. National Institute of Standards and Technology, 2024. URL  https://csrc.nist.gov/projects/ post-quantum-cryptography .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "[8]  F. Su, W. Chen, L. Xia, C. Lo, T. Tang, Z. Wang, K. Hsu, M. Cheng, J. Li, Y. Xie, Y. Wang, M. Chang, H. Yang, and Y. Liu, “A 462gops/j RRAM-based nonvolatile intelligent processor for energy harvesting ioe system featuring nonvolatile logics and processing-in-memory,” in  2017 Symposium on VLSI Technology , pp. T260–T261, 2017. 494–496, 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "Based on Table  1 , if we had statically taken the top  N / 2 most accurate models, NasNetmobile would not have been included in the ensemble. Further, the other 5 models are used by up to 25% of the images. However, based on the input im- ages sent in each query, our model selection policy has been able to identify NasNetMobile to be a signiﬁcantly contribut- ing model in the ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Now, the  football  needs the full depth planes’ information, while the soccer ball  can be approximated. To take advantage of this opportunity, the  football  object (which is inside the RoF in this example scenario) requires all of the 16 depth planes to compute its dense hologram, whereas the other objects (the  soccer ball in this case) can be approximated with a pre-defined sparse sam- pling factor (e.g.,   1 \n2 ; more details provided later in Algo. 2 and Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 116,
    "augmented": false
  },
  {
    "text": "The parallelism in this context is of two types:  intra layer parallelism via layer duplication  and  inter layer parallelism via layer pipelining . Further, tiling and parallelization can also be combined to generate ﬁne-grained scales of computations to efﬁciently ﬁt into the changing harvested power. 1) Computation tiling:  In this work, we use loop tiling [ 35 ] to decompose large parallel MAC operations into smaller parallel blocks and execute the resulting blocks one by one.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "2021. Kraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms. In  ACM Symposium on Cloud Computing (SoCC ’21), November 1–4, 2021, Seattle, WA, USA.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "Rather, storing the data in a compressed and encrypted format (with redundancies) is more efficient and therefore is the focus of our work. Why Not the Usual Process? Now that we know Classical approach of video data storage involves encoding and encrypting the video data before storing them in a redundant storage array (Huang & Xu, 2014; Fan et al., 2022; Korkiakangas, 2014; Yue et al., 2016) which consumes significant resources (refer Table 1).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "The ability to capture diverse conditions from the different nodes, with or without sharing data, can lead to more robust models. We focus on extending random forests models that have been deployed in smart manufacturing [7] to explore edge-cloud partitioning strategies when multiple machines cooperate in contributing to better models. Constructing an accurate random forest model, while respecting data privacy of a distributed multi user sensor network is also challenging.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "A matching circuit, including components like buck or boost converters, adjusts the voltage to the appropriate level, ensuring the device receives the correct current and voltage. 4. Energy Storage : Finally, to ensure a continuous power supply even when the immediate energy source is inconsistent (like when a cloud passes over a solar panel), the system includes a temporary storage unit, such as a super-capacitor.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "1–28. [96] A. Technologies, “Aeromine technologies,” https://www.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 23,
    "augmented": false
  },
  {
    "text": "[46]  Patrick Hunt, Mahadev Konar, Flavio Paiva Junqueira, and Benjamin Reed. Zookeeper: Wait-free coordination for internet-scale systems. In  USENIX annual technical conference , 2010.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "https://ai.googleblog.com/2018/05/custom-on-device-ml-models. html . (Accessed on 11/21/2022).",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "The class with the maximum weight ( P class ) is the output of the majority vote. Hence, classes that did not get the highest votes can still be the ﬁnal output if the models associated with that class has a higher weight, than the combined weights of highest voted class. For instance, if there are 3 unique classes predicted by all the ensemble models, we sum the weights for all models of the same class.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "heterogeneous resource availability from the public cloud. Towards this, we make the following  key contributions . 1.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 26,
    "augmented": true
  },
  {
    "text": "In this section, we will explain, in detail, the overall execution workflow of the  Seeker  system, followed by the the detailed design of the hardware support to maximize its energy efficiency. The host, after obtaining information from multiple sensors, per- forms any further required computation and uses ensemble learning [ 47 ] to give an accurate classification result. Note that, unlike prior EH-WSN systems [ 47 ], the role of the host device here is not limited to just result aggregation; rather, the host participates and performs inference when the sen- sors do not have enough energy and choose to communicate the data (in the form of coresets) to the host.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "68 ×  when employ- ing  Inter-Intra-Holo  (with only 0 . 14% overhead). Recall that the number of depth planes for each hologram object affects the ex- ecution latency dramatically as shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Training compute- optimal large language models. arXiv preprint arXiv:2203.15556 , 2022. [65] Connor Holmes, Masahiro Tanaka, Michael Wyatt, Ammar Ahmad Awan, Jeff Rasley, Samyam Ra- jbhandari, Reza Yazdani Aminabadi, Heyang Qin, Arash Bakhtiari, Lev Kurilenko, and Yuxiong He.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "Sensitivity Study:  To better understand the relationship be- tween the inference quality and the threshold, we run our model with different parameter settings, shown in Figure 4, over the cases of edge-peer and edge-cloud structures with device counts of two and four. 3) The latency difference between the data shared model and privacy preserved model is not so prominent due to the lower data volume. The models generated are simple, and hence does not have significant difference in execution time at the cloud.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "3. The lineage data will use the formats required by the underlying data lineage tools. These will be stored in XML and web formats.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "However, in the case of InFaas , this would lead to 1% failed requests due to requests being dropped from the failed instances. An alternate solution would be to restart the queries in running instances but that leads to increased latencies for the 1% requests. Beyond 800 s , they quickly recover back to the required accuracy because additional instances are spawned in place of failed instances.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "7c, our  HoloAR  design running on the edge GPU [ 36 ] still saves 25% more energy than the custom HORN-8 accelerator. 5.4 Sensitivity Study \nImpact on Quality:  The prior  Inter-Holo  scheme captures the small-region of eye focus to approximate the hologram outside of RoF, and the proposed  Intra-Holo  takes advantage of the sparse computation required for the far objects to reduce the number of depth planes. To study how these approximation decisions affect the hologram video quality, we next want to reconstruct/render the hologram from our design based on the real-time eye move- ments and head orientations, and compare the quality of the recon- structed images against the baseline using the peak signal-to-noise ratio (PSNR) [ 21 ,  44 ] metric.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 193,
    "augmented": false
  },
  {
    "text": "Immediate Rewards and Penalties: Let  γ >  0  be a scal- ing factor that translates accuracy gains into utility rewards. Here,  δ >  0  penalizes incorrect participation, discourag- ing sensors from submitting low-quality data, while  η >  0 penalizes non-participation to prevent perpetual abstention. When sensor  s i  participates ( a i ( t ) =  P ) and contributes cor- rectly to the inference task, it receives a reward proportional to the improvement in global accuracy, denoted by  ∆ A i ( t ) : \nR i ( t ) = \n   \n  \nγ  ·  ∆ A i ( t ) , if  a i ( t ) =  P and correct inference , − δ, if  a i ( t ) =  P and incorrect inference , − η, if  a i ( t ) =  NP .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 251,
    "augmented": true
  },
  {
    "text": "Tools, Platforms and Frameworks for LLM Evaluation:  Although they do not capture system insights, a few mathematical models [133] have been proposed to estimate the complexity of LLM training process. Additionally, a few simulators [9, 180] have been proposed to estimate time and cost of inferences. In this direction, we plan to use/augment these models by investigating microarchitectural, architectural and system level impacts on training and inference processes.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Under the assumptions that ∆ A i ( t )  is non-decreasing and that sensors have consistent energy and accuracy estimates, no cyclical behavior can persist. Our argument shows that profitable deviations must terminate. Since each sensor’s best-response update seeks to maximize its own utility, sensors will continue to deviate as long as prof- itable deviations exist.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Note that these probabilities are not visible to  Kraken , but are only used to model function invocation patterns. Metrics and Resource Management Policies:  We use the following metrics for evaluation: (i) average number of containers spawned, (ii) percentage of requests satisfy- ing the SLO (SLO guarantees), (iii) average application re- sponse times, (iv) end-to-end request latency percentiles, (v) container utilization, and (vi) cluster-wide energy sav- ings. We set the SLO at 1000ms.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Energy Savings : Overall, our software implementation EA+AE on GPU can save 54% computation, which translates to 28% total energy savings, compared to the baseline. Com- pared to the state-of-the-art hardware-modiﬁed PTU, our soft- ware implementation can still provide 16% computation and 8% total energy savings. In addition, we also discuss the  our design’s versatility  on other 360 ° video representation formats.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "https://store-usa.arduino.cc/products/ arduino-nano-33-ble-sense-with-headers , 2024. Accessed on 05/19/2024. Oresti Banos, Rafael Garcia, Juan A Holgado-Terriza, Miguel Damas, Hector Pomares, Ignacio Rojas, Alejandro Saez, and Claudia Villalonga.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "These mismatches can lead to the following two “nonideal” working scenarios: (i) Unutilized energy:  As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive. Comparisons on power consumption and throughput with tile-size over full-size activation \nFrom the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property. Under this context, if the power dominant RCA works in a ﬁxed high-power mode, as in traditional RCA designs, there would be large mismatches between the harvested power and the consumed power.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "2c: Head Orientation Proximity:  In a short period of time, the user’s head orientation is usually stable in a small space range (3D) or even still. following two properties from a published  360 ° VR dataset [3], as shown in Fig. In fact, from this dataset we have found that, the head orientation for users does not often change within around  150 ms  period of time.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "This would ostensibly allow for the selective transfer of only pertinent exemplar data to compute servers, thereby optimizing data movement costs. Theoretically, storage stacks could handle operations like unRAID and decryption, and extend their functionality to data inflation and \n6 \nfeature extraction. Integrating additional compute capabilities within storage stacks to offload certain computational tasks may seem an intuitive solution to the problem at hand.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "15 ×  speedup compared to the baseline. Further, a 2 . 42 ×  speedup is achieved when employing Intra-Holo  (with only 0 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Ω SNR ( θ )  encourages the model to perform reasonably well across varying SNR levels, while  Ω complexity ( θ )  penalizes overly complex models that might demand excessive energy or communication costs. Both are assumed convex and have bounded gradients. The final training objective is: \nJ ( θ ) =  L ( θ ) +  λ 1 Ω SNR ( θ ) +  λ 2 Ω complexity ( θ ) , \nwhere  λ 1 , λ 2  ≥ 0  are hyperparameters controlling the influ- ence of the regularizers.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "The regularizers  Ω SNR  and  Ω complexity  are convex in  θ , and their gradients are bounded. Let \n∥∇ Ω SNR ( θ ) ∥≤ G 1 , ∥∇ Ω complexity ( θ ) ∥≤ G 2 ∀ θ. 4.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Additionally, the experimental analysis indicates that our approach outperforms the state-of-the-art work with respect to accuracy and/or performance/energy savings. Index Terms —Mobile Computing, DNN Inference, Energy Efﬁcient, Video Analysis, Motion Vector, Object Detection \nI. I NTRODUCTION \nWhile video processing has become extremely popular on mobile devices, the next wave of emerging applications are likely to be those that analyze videos in a  faster  and  more efﬁcient  fashion, to provide sophisticated intelligence. Such an- alytics are critical for virtual/augmented reality, object recog- nition/detection for surveillance, commercial advertisement insertion/deletion, synopsis extraction, and video querying.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 161,
    "augmented": false
  },
  {
    "text": "3), uses the transformation matrix and the 2D FoV coordinates for both eyes to obtain \n4 We used an averaged pupillary distance in our evaluations [27], [37]. TABLE I: Projection Computation description. Label Description HO dependent?",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "[73] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Re- nard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Tim- othée Lacroix, and William El Sayed. In  2014 47th Annual IEEE/ACM International Symposium on Microarchitecture , pages 458–470. IEEE, 2014.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 148,
    "augmented": true
  },
  {
    "text": "In order to effectively handle mis-predictions in load,  Kraken  also employs a Reactive Scaler (RS)  7  that consists of two major components. Subsequently, it triggers container scaling  6  by calculating the additional containers needed to mitigate the delay. First, is an Overload De- tector  7a  that keeps track of request overloading at functions by monitoring queuing delays at containers.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "The left y-axis shows the compute energy consumption normalized to the compute energy consumption in Baseline (the lower, the better). The right y-axis shows the amount of energy savings compared to the end-to-end total energy consumption in Baseline (the higher, the better). 0 \n20 \n40 \n60 \n80 \nV1 V2 V3 V4 V5 Avg.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "In particular,  Arch ,  Fifer and  Kraken  show comparable latencies, with P99 values re- maining well within the SLO of 1000ms. However,  Arch  and Fifer  use 3.51x and 2.1x more containers than  Kraken  to \n0 \n0.25 \n0.5 \n0.75 \n1 \nArch Fifer DProb Kraken SProb Xanadu \nEnergy Consumption Rate \n(a) Energy Consumption Rate. 0 \n300 \n600 \n900 \n1200 \n0.25 0.5 0.75 0.98 0.99 \nLatency (ms) \nCDF Kraken Comm Only \nConn Only SLO \n(b) Response Time Distribution.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Furthermore, it can be seen that Xanadu  provisions a relatively high number of containers for a particular group of functions as compared to the rest. This is because it allocates containers to serve the predicted load along only the Most Likely Path (MLP) of a request. The rest of the containers are a result of  reactive scaling  that follows from MLP mispredictions, which accounts for 34% of the total number of containers spawned.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Putting all these together, in this scenario, both Frame-1 and Frame-3 employ full inference, whereas the inference for Frame-2 can be skipped, with very little overhead (only  0 . 5%  of the time that full inference takes, refer to Sec. V for more details).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "As the RoIs size increases along the video (e.g., ratio of RoIs/whole frame increases from  8%  in frame20 to  53%  in frame2470), the beneﬁts from PI become increasingly lower, resulting in similar patterns for FI+SI and FI+SI+PI. Besides these six videos, we also picked two  slices from V1 and V2 (i.e., V1P and V2P) to show the effectiveness of our PI technique. In these two slices, the objects keep moving.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "´as  will be limited either by the live of the harvesting source ( ≈ 20 – 30 years for solar, ≈ 10 – 12 years for portable wind turbines), or the training hardware (typical life cycle of embedded devices are of range of 7 – 10 years). We agree that a limitation of our work comes from the choice of solar energy: unavailability during night and bad weather makes the deployment harder. However, there has been signiﬁcant recent development in portable wind turbines [ 96 ], which can be deployed on rooftops, can work with  ≥ 5 mph  wind speed, and can provide power equivalent of 15 solar cells.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "Springer, 489–507. [37]  Jörn Kuhlenkamp, Sebastian Werner, and Stefan Tai. In  Combinatorial Optimization .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 35,
    "augmented": true
  },
  {
    "text": "[104] C.-H. Yen, H. R. Mendis, T.-W. Kuo, and P.-C. Hsiu, “Stateful neural \networks for intermittent systems,”  IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems , vol. 41, no.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "ACM. https://doi.org/10.1145/3317550.3321443 [10]  Chengliang Zhang, Minchen Yu, Wei Wang, and Feng Yan. 2019.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "685–696, 2021. Qunying Huang and Chen Xu. A data-driven framework for archiving and exploring social media data.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 34,
    "augmented": false
  },
  {
    "text": "Streaming such PC videos in real-time involves capturing both the attributes and geometry data making it a challenging task even without user-object interaction. Towards this, Han et al. Especially,  interactive volumetric video streaming  is starting to become mainstream, as edge devices (e.g., iPhones) facilitate recording and streaming the PC video which provide end-users with real-time 6-degrees of freedom (6-DoF) experiences.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "The configuration of the server with Xilinx CSD has a 12-core Xeon bronze CPU with 128GB memory,  2 × 3.84TB CSDs, and  2 × 2TB SSDs. We use Vitis 2022.2 along with Xilinx Runtime Library (AMD & Xilinx) for programming the FPGAs in both computational storage drives and the Alveo card. 5 Implementation and Evaluation \nTo implement and evaluate  Salient Store  , we chose two different platforms – 1) Using a server- grade system with two Xilinx-Samsung computational storage drive (AMD, b), and 2) Using amazon web services (AWS) F1 instances, which have AMD Alveo FPGA which can work as the compute capable of peer-to-peer communication and thereby enabling a computational storage platform.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 197,
    "augmented": true
  },
  {
    "text": "[143] Akbar Sharifi, Emre Kultursay, Mahmut Kandemir, and Chita R Das. Large language models in healthcare: Breakthroughs, use cases, and challenges. Shaip , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Temporal Locality for the User Interests:  As also established by prior foveated rendering proposals, the foveal vision (or Region of Focus, RoF) is only a small region in the current scene and can be traced by eye tracking techniques [ 26 ]. As can be observed from three users’ eye tracking shown in Fig. 3b, all focus only on a portion of the entire viewing window within a short period of time (10 seconds in this case).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "In addition, our  Intra-Holo  scheme is more power efficient than  Inter- Holo , translating to 27 . 72% power reduction with respect to the baseline. This indicates that the optimization scope of the distance- based  Intra-Holo  is larger than that of the RoF-based  Inter-Holo , which provides more sparsity in the hologram computing.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "2 ×  performance efﬁcient compared to the conventional scheme, which performs full inference, while losing less than  2%  accuracy. Our experimental evaluations using six different videos reveal that the proposed schemes are up to  80%  ( 56%  on average) energy efﬁcient and  2 . Additionally, the experimental analysis indicates that our approach outperforms the state-of-the-art work with respect to accuracy and/or performance/energy savings.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Existence of a Nash Equilibrium \nSince no infinite sequence of profitable unilateral deviations can occur, the best-response dynamics must terminate in a state where no sensor can unilaterally improve its utility. By definition, this state is a Nash equilibrium  a ∗ ( t ) : \nU i ( a ∗ i   ( t ) ,  a ∗ − i ( t ))  ≥ U i ( a i ( t ) ,  a ∗ − i ( t )) ∀ a i ( t ) ,  ∀ i. Thus, the existence of a Nash equilibrium follows directly from the finiteness of utilities, the monotonicity of  Φ , and the impossibility of infinite improvement sequences.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 191,
    "augmented": false
  },
  {
    "text": "\"https://www.microsoft.com/en- us/p/holoLens-2/91pnzzznzwcp/?activetab=pivot:techspecstab\". HoloLens 2 Tech Specs. [32]  Microsoft Research Blog.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Three demo examples of reconstructed images by OpenHolo are shown in Fig. To study how these approximation decisions affect the hologram video quality, we next want to reconstruct/render the hologram from our design based on the real-time eye move- ments and head orientations, and compare the quality of the recon- structed images against the baseline using the peak signal-to-noise ratio (PSNR) [ 21 ,  44 ] metric. Given the lack of the physical optical holographic displays (e.g., the prototype built in Tensor Holog- raphy project [ 54 ]), we numerically generate the reconstructed holographic images on top of the OpenHolo library [ 18 ].",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 172,
    "augmented": true
  },
  {
    "text": "Out of these four scenarios, we observe that  EA  computation for head orientation can be exploited for  temporal reuse/memoization  since there is little difference between two previous head orientations, and  AE computation for exploiting the correlation between both the eyes by  spatial reuse – correlating the coordinate relationship between both eyes . Based on this observation, we develop computation optimization mechanisms for facilitating temporal reuse/memoization and spatial reuse that can be integrated with a VR projection computation pipeline to signiﬁcantly reduce energy consumption of the device. The proposed ar- chitecture is named  D´ej`a View , a play on the word D´ej`a vu, as it uses previous or  already seen  views.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "Initialize the loop iteration parameters  l . Compute the activations  a  and apply the dropout mask: \na dropout i =  a i  ·  m i \nCompute the loss  L ( Y ,   ˆ Y )  where  Y  is the output of the network and   ˆ Y  is the target output. Calculate the Shapley values  ϕ i  for each neuron based on their contribution to the network’s perfor- mance.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "To enable sustainable machine status monitoring with energy harvesting (from machine vibrations or Wifi signals) we evaluate our setup using Bridgeport machines for monitoring their status. Prior works (Center, 2018) majorly focused on fault analysis but there are little to no datasets on predictive maintenance. Setup and Sensor Arrangement:  Two different types of 3-axis accelerometers (with 100Hz and 200Hz sampling rate) were placed in three different locations of a Bridgeport machine to collect and analyze data under different operating status.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "The absence of comprehensive library functions along with the need for computational efficiency frequently necessitates the development of in-line assembly code for certain computational kernels. DynFit tends to introduce multiple intermediate states during the training process, resulting in approximately 14% additional wall-time on average. The development of DynInfer requires an in-depth understanding of microcontroller programming and compiler directives.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "IEEE Micro , 36(3):72–83, 2016. Kaisheng Ma, Xueqing Li, Jinyang Li, Yongpan Liu, Yuan Xie, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Nonvolatile processor architectures: Efficient, reliable progress with unstable power.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "However, naively integrating such an RCA renders its activation power requirement so high that the system will likely have very low duty-cycle on an intermittent supply and may never activate at all for weaker power sources unless a substantial energy store were added, which could be burdensome for form factor constraints in a system that already employs a battery for sensing and other non-inference tasks. TABLE I A N EXAMPLE OF DIFFERENT ACTIVATION SCHEMES FOR AN EIGHT - CYCLE POWER TRACE . It is known that RCAs achieve their highest efﬁciency when every cell participates in the MAC computations simul- taneously [ 20 ].",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 160,
    "augmented": true
  },
  {
    "text": "The autoscaler further employs an importance sam- pling  6b  algorithm to estimate the importance of each model pool by calculating percentage of request served by it in a given time interval. We also design an autoscaler  6  , which utilizes a prediction pol- icy  6a  to forecast the request load and scale instances for every model pool, thereby minimizing over-provisioning of resources. The key components of the design are explained in detail below.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "This inherent inefficiency stems from their design which does not allow incremental improvements in video quality and often leads to either over-utilization or under-utilization of bandwidth. Traditional neural codecs, while innovative, typically encode and decode video streams in a monolithic fashion, which often results in suboptimal utilization of computational resources and inflexibility (Ma et al., 2019). To address these shortcomings, the advent of layered neural codecs marks a significant advancement (Dasari et al., 2022a).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "The primary y-axis (left) shows the latency in  ms  for SOTAs, whereas the secondary y-axis (right) gives the latency in  ms  for our proposals. From this plot, the following observations can be made: •  TMC13:  TMC13 takes around  4152 ms  to compress one PC frame, including  1552 ms  for geometry compression and 2600 ms  for attribute compression. •  CWIPC:  CWIPC takes about  4229 ms  (mainly for geometry compression as the attributes are directly entropy-encoded without any other efforts, as mentioned in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 142,
    "augmented": false
  },
  {
    "text": "[81]  Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface’s transformers: State-of- \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1055 \nthe-art natural language processing. Proceedings of the VLDB Endowment , 12(2):128–140, 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "Similarly, if the \nImplications of Public Cloud Resource Heterogeneity for Inference Serving WoSC’20, December 7ś11, 2020, Delft, Netherlands \n0 \n10 \n20 \nCost($) \nVM cost \nLambda Cost \ninception                   nasnet densenet mobilenet \n(a)  Cost for ISO-latency models. As shown in Figure  2a , four differ- ent models can satisfy the response latency, but each model comes with a different prediction accuracy. 0 \n10 \n20 \nCost($) \nVM cost \nLambda Cost \ninception          resnet-200 resnext-50 nasnet \n(b)  Cost for ISO-accuracy models.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "Computational storage: Where are we today? Antonio Barbalace and Jaeyoung Do. In  CIDR , 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "[197] Yanqi Zhou, Tao Lei, Hanxiao Liu, Nan Du, Yanping Huang, Vincent Zhao, Andrew Dai, Zhifeng Chen, Quoc Le, and James Laudon. Mixture-of-experts with expert choice routing. Advances in Neural Information Processing Systems , 35:7103–7114, 2022.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Salient Store  employs a “hybrid model”, integrating Computational Storage Drives (CSDs) with Field-Programmable Gate Arrays (FPGAs) (AMD, b) and classical storage drives. 3.1 Salient Store  Storage Architecture: \nSalient Store  edge storage architecture is crafted to optimize data-flow and computational effi- ciency in continuous learning edge servers. This design, depicted in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Suppose, for contradiction, that there exists an infinite se- quence of unilateral profitable deviations. Each such de- viation strictly increases  Φ( a ( t )) . Because  Φ  is bounded above by  Φ max , only a finite number of increments can occur before no further improvements are possible.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "The number of containers to be deployed is jointly determined by the estimation model and function weights. These weights are assigned by the PWS by taking into account function invocation probabilities and parameters pertaining to the DAG structure, namely,  Commonality  (functions common to multiple workflows) and  Connectivity  (number of descen- dant functions), (ii) In addition to the PWS,  Kraken  employs a Reactive Scaler (RS) to scale containers appropriately to re- cover from potential resource mismanagement by the PWS, (iii) Further, we batch multiple requests to each container in order to minimize resource consumption. We have developed a prototype of  Kraken  using  OpenFaaS , an open source serverless framework [ 11 ], and extensively evaluated it using real-world datacenter traces on a 160 core Kubernetes  cluster.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 193,
    "augmented": false
  },
  {
    "text": "In the proposed  AE  scheme, one can observe that for the left-eye computation, the energy consumption is the same as in the  Baseline . Recall from the  AE  design logic in Fig. 7 that, the results of the left-eye are generated by the Original Compute Engine (GPU in this case) and fed into the  AE  block with the ﬁrst row for the right-eye, to store the pattern into the Delta Buffer.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply. compression (PCC) pipeline which is  fast  (within or close to real-time),  accurate  (with good quality), and  efﬁcient (with high compression ratio).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 62,
    "augmented": false
  },
  {
    "text": "Human creativity in the age of llms: Randomized experiments on divergent and convergent thinking. IEEE Access , 11:31866–31879, 2023. [85] Harsh Kumar, Jonathan Vincentius, Ewan Jordan, and Ashton Anderson.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Modern and upcoming applications like urban mobility and autonomous driving are predicted to be generating hundreds of exabytes of data (Urban Traffic Dataset; Corporation; Wright\"; \"premioinc\") per year while increasingly being deployed at the edge calling for a robust, secure, and efficient infrastructure for storing data at the edge while needing occasional human intervention for maintenance. Using State-of-the-Art Video Data Storage? Therefore, managing and storing the hefty volume of video data brings more challenge due to the energy, compute and form-factor limitations.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "In  Computer Architecture News . [52]  Yiming Zhang, Jon Crowcroft, Dongsheng Li, Chengfen Zhang, Huiba Li, Yaozheng Wang, Kai Yu, Yongqiang Xiong, and Guihai Chen. 2018.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Furthermore, each server performs more remote accesses, increasing the contention even more. As the number of storage servers increases, the network contention and data orchestration challenges exponentially increase. This leads to an exponential growth in latency with the increase in the number of storage servers used per application.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "Upon closer examination, we see that this is due to functions having different degrees of  Commonality and  Connectivity . Moreover, the majority of functions whose Commonality  and  Connectivity  differ, have a high batch size, thereby reducing the variation in the number of containers spawned. Following this, we observe that the variation in the number of containers in  Social Network  is mainly due to the significant difference in the  Commonality  and  Connectivity of the  Compose Post  function whose batch size is only one.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Cocktail , by coalescing these beneﬁts, is capable of operating in a region of optimal cost, accuracy and latency (shown in Figure  1 ) that prior works cannot achieve. Towards this, the key contributions  of the paper are summarized below: \n1. By characterizing accuracy  vs.  latency of ensemble models, we identify that prudently selecting a subset of available models under a given latency can achieve the target ac- curacy.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "Edge Server \nPCIe Root COmplex \nFPGA \nCSD \nCSD \nFPGA \nAccelerator \nFigure 2: High-level design of the  Salient Store  edge server - it consists of the accelerated video analytics compute along with computational storage and classical storage drives. Data-flow Reorganization in  Salient Store  : At the core of  Salient Store  ’s design is the “data-aware” reorganization of compute processes. Unlike conventional storage servers,  Salient Store  discerns between the “data path” and the “resource path” for system I/O calls, translating these requests into CSD-specific functions.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 136,
    "augmented": false
  },
  {
    "text": "IEEE, 2020. [20] Nathan Binkert, Bradford Beckmann, Gabriel Black, Steven K. Reinhardt, Ali Saidi, Arkaprava Basu, Joel Hestness, Derek R. Hower, Tushar Krishna, Somayeh Sardashti, Rathijit Sen, Korey Sewell, Muhammad Shoaib, Nilay Vaish, Mark D. Hill, and David A. Wood.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Curriculum Development Activities : As we have done in our prior NSF projects, we will integrate our research results from this project with educational activities and graduate and undergraduate student train- ing for nurturing the future workforce in science and engineering. Our curriculum development activities include the development of two courses related two this project – (i) an undergraduate course on “Genera- tive AI” (drawing mainly from Thrust 1 of this project and focusing on training students to develop skills like language model creation other generative AI applications) that will be used for our CS curriculum and the new AI degree, and (ii) a graduate course on “System and Architectural Support for LLMs”, which will draw from the contents of Thrusts 2 and 3. Also, where possible, the research material from this project will be integrated into the ML, architecture, and systems courses the PIs are regularly teaching at Penn State.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 193,
    "augmented": false
  },
  {
    "text": "Though reactive policies (used in Clipper and InFaas) can be employed which take into account metrics like CPU utilization [ 83 ], these policies are slow to react when there is dynamism in request rates. In  Cocktail , we use a load prediction model that can accurately forecast the anticipated load for a given time interval. Proactive policies with request prediction are know to have superior performance [ 86 ] and can co-exist with reactive policies.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Baselines:  We take the combination of best available approaches for DNN inference on intermittent environment as baselines. All these DNNs are executed with the state-of-the-art checkpointing and scheduling approach (Maeng & Lucia, 2018). The host device is used for data logging—collecting SLOs, violations, power failures, etc., along with running the “baseline” inferences without intermittency.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 98,
    "augmented": true
  },
  {
    "text": "The federated learning framework ac- commodates intermittent participation and vari- able data quality, ensuring robust model training despite sensor unreliability. Our game-theoretic model enables sensors to make optimal participation de- cisions based on energy levels, data quality, and collective inference impact, fostering cooperative behavior while managing individual energy con- straints. Simulation results demonstrate that our integrated approach signif- icantly enhances inference accuracy and energy efficiency compared to traditional participation strategies.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "VI , our proposal drops the quality a little bit (PSNR  ≈ 80 dB in our design). This quality degradation comes as a result of the parallel algorithm, and we argue that the PSNR values resulting from our proposal are still very good for most video and AR/VR applications [ 6 ], [ 77 ]. Another comparison parameter is the  compression ra- tio .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "The dawn after the dark: An empirical study on factuality hallucination in large language models. arXiv preprint arXiv:2401.03205 , 2024. [93] Lei Li, Yankai Lin, Shuhuai Ren, Peng Li, Jie Zhou, and Xu Sun.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "As a result, the data size becomes 5%  less than our intra-only design (e.g., only 12 %  of the original size), while dropping the quality by  6 . 1 dB due to the block-level approximations in the inter-frame compression. •  Our Intra-Inter-V2 (Compression efﬁciency-oriented):  Sim- ilarly, this design further reduces the compressed data size by 2 % , by adjusting the threshold for “direct-reuse decision making”, as discussed in Sec.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "In  Companion of the 2024 International Conference on Management of Data , pp. 597–604, 2024. 21 \nInhyuk Park, Qing Zheng, Dominic Manno, Soonyeal Yang, Jason Lee, David Bonnie, Bradley Settlemyer, Youngjae Kim, Woosuk Chung, and Gary Grider.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "2). Small-size tiles share signiﬁcant similarities across consecutive frames. E.g., nearly 50% of the tiles are identical in successive frames with a tile size of 8 × 8.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "7 , the ﬁrst frame, I- Frame, contains three points –  P 0  with geometry data  [ 0 , 0 , 0 ] and an attribute value  50 ,  P 1  with  [ 12 , 8 , 13 ]  for geometry and 52  for attribute, and  P 2  with  [ 19 , 26 , 58 ]  for geometry and 20  for attribute. Moreover, the two  P 1  points are located closely (i.e.,  [ 12 , 8 , 13 ]  vs  [ 12 , 8 , 12 ] ), and contain very similar attribute values ( 52  vs  51 ). Obviously, the two  P 0  points in I-Frame and P-Frame are exactly the same, which could be completely reused during the compression of the P-Frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 184,
    "augmented": true
  },
  {
    "text": "Tiantu Xu, Luis Materon Botelho, and Felix Xiaozhu Lin. (Accessed on 11/21/2022). dlapiperdataprotection.com/index.html?t=collection-and-processing&c=SE .",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "Prior works on PCC acceleration [ 19 ], [ 33 ] only consider the PC with geometry data and/or have limited parallelism, and thus, could neither leverage GPU nor beneﬁt from other types of accelerators. Moreover, there has been little effort in parallelizing them on the state-of-the-art commercial systems, let alone on any edge/mobile devices. To address this, we study the SOTA compression pipelines and observe that the main reason behind their performance inefﬁciencies is their  sequential updates  to the global result with each intermediate local runtime state  in a  point-by-point fashion.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "However, it results in almost twice the latency and energy consumption with respect to our approach. This high latency/energy consumption is due to the imprecise down-sampled feature vector, and this further indicates that, a strategy that is based on feature vector memoization can still miss a lot of optimization opportunities. Different from the three prior works discussed above, which mainly focus on one model, MCDNN targets a multi-model system and proposes a runtime scheduler to improve the accuracy as much as possible within a limited energy budget.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 122,
    "augmented": false
  },
  {
    "text": "Therefore, this weight duplication- based execution style built upon ﬁne-granularity activation can effectively combat  Nonideal scenario 2 . Figure 1 also shows the throughput under the full-size activation mode and the tile-size activation mode. The ﬂexible working mode based on the loop tiling technique can achieve more forward progress and higher power utilization.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "We prototyped our proposed  EA  and  AE  design blocks using System Verilog in Xilinx Vivado 2019.2 [58], targeting the Xil- \ninx Zynq-7000 SoC ZC706 board running at 100MHz (same as state-of-the-art EVR [28]). After the pattern between left eye and right eye is captured, an external signal is propagated to the OCE to bypass the further original projection computations. Consequently, the projection computation results ( Result [2 :  n ] .R ) for the remaining rows of the right eye can be easily reconstructed by adding  Result [2 :  n ] .L  and the  Δ .",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 166,
    "augmented": true
  },
  {
    "text": "The hardware design of  Us. The systolic array structure of the DNN accelerators is well suited for this as we can change the com- pute size, as well as the number of memory channels feeding to those compute units as per the power availability. However, we need to be innovative in terms of designing and placing the compute hierarchy to ensure minimum data movement and re-computations when compute scaling.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 91,
    "augmented": true
  },
  {
    "text": "•  Existing ensemble weight estimation [ 87 ] has  high com- putational complexity  and in practice is limited to a small set of off-the-shelf models. This leads to signiﬁcant loss in accuracy. Besides, employing linear ensembling techniques such as model averaging are compute intensive [ 80 ] and not scalable for a large number of available models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "The state-of-the-art PCC pipeline typically utilizes tree structures like  Octree  [ 63 ] or kd-tree  [ 62 ] for compression, and often, the tree construction becomes a bottleneck due to lack of parallelization. Moreover, the conventional PC typically stores the geometry, while a wide array of applications, especially the ones meant for content consumption, infotainment and gaming, need the attributes to be stored as well, hence making the compres- sion even more complex. compression (PCC) pipeline which is  fast  (within or close to real-time),  accurate  (with good quality), and  efﬁcient (with high compression ratio).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "Besides using dense models, ensembling [ 15 ] techniques have been used to achieve higher accuracy. However, denser models tend to have up to 6 ×  the size and twice the latency of smaller models to achieve increased accuracy of about 2-3%. For instance, InFaas [ 83 ] can choose variants among a same model to maintain accu- racy and latency requirements.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "2016. Image Quality Evaluation and Control of Computer-generated Holograms. In  Practical Hologra- phy XXX: Materials and Applications , Hans I. Bjelkhagen and V. Michael Bove Jr.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 49,
    "augmented": false
  },
  {
    "text": "Third, it minimizes the cost of deploying ensembles in a public cloud by taking advan- tage of transient VMs, as they can be 70-90% cheaper [ 3 ] than traditional VMs. Second, it utilizes dis- tributed autoscaling poli- cies to reduce the la- tency variability and re- source consumption of hosting ensemble mod- els. Cocktail , by coalescing these beneﬁts, is capable of operating in a region of optimal cost, accuracy and latency (shown in Figure  1 ) that prior works cannot achieve.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 134,
    "augmented": true
  },
  {
    "text": "[31]  Jashwant Raj Gunasekaran, Prashanth Thinakaran, Mahmut Tay- lan Kandemir, Bhuvan Urgaonkar, George Kesidis, and Chita Das. 2019. Spock: Exploiting Serverless Functions for SLO and Cost Aware Resource Procurement in Public Cloud.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 84,
    "augmented": false
  },
  {
    "text": "Pushing point cloud compression to the edge. Ziyu Ying, Shulin Zhao, Sandeepa Bhuyan, Cyan Subhra Mishra, Mahmut T. Kandemir, and Chita R. Das. Springer, 2015.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "These functions leverage FPGA kernels for efficient data processing. Unlike conventional storage servers,  Salient Store  discerns between the “data path” and the “resource path” for system I/O calls, translating these requests into CSD-specific functions. As discussed earlier, Salient Store  edge storage implements a video archival by using neural compression followed by a quantum safe encryption (refer Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "[58] Rakesh Gupta, Anil Singh, and Deepak Kumar. Adaptive load balancing in distributed machine learning systems. Journal of Parallel and Distributed Computing , 145:45–58, 2020.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "Thus, any unilateral profitable deviation increases  Φ( a ( t )) . If this deviation is profitable for sensor s j , we have: \nU j ( a ′ j ( t ) ,  a − j ( t ))  > U j ( a j ( t ) ,  a − j ( t )) . Because the other sensors’ utilities do not change instan- taneously by  s j ’s unilateral action, the increment in  U j ( t ) results in: \nΦ( a − j ( t ) , a ′ j ( t ))  − Φ( a ( t )) = \nU j ( a ′ j ( t ) ,  a − j ( t ))  − U j ( a j ( t ) ,  a − j ( t ))  >  0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 243,
    "augmented": true
  },
  {
    "text": "5. Archiving and Preservation Policies \nData will be archived on our departmental machines at Penn State as long as necessary for possible aca- demic publications and at least until the end of the project. The main documentation that will accom- \npany the data are project reports and research publications.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "The VLDB Journal  17, 3 (2008), 401–417. [20]  M. A. Awad and I. Khalil. 2012.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 35,
    "augmented": false
  },
  {
    "text": "[12] P. Guo and W. Hu, “Potluck: Cross-application approximate deduplica- tion for computation-intensive mobile applications,” p. 271–284, 2018. [13] Z. Lai, Y. C. Hu, Y. Cui, L. Sun, and N. Dai, “Furion: Engineering High-Quality Immersive Virtual Reality on Today’s Mobile Devices,” in  Proceedings of the Annual International Conference on Mobile Computing and Networking (MobiCom) , 2017, p. 409–421. [14] L. Gong, C. Wang, X. Li, H. Chen, and X. Zhou, “A Power-Efﬁcient and High Performance FPGA Accelerator for Convolutional Neural Net- works: Work-in-Progress,” in  Proceedings of the Twelfth IEEE/ACM/I- FIP International Conference on Hardware/Software Codesign and System Synthesis Companion , 2017.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 224,
    "augmented": false
  },
  {
    "text": "[28] Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva. Evaluating the ripple effects of knowledge editing in language models. Transactions of the Association for Computational Linguistics , 12:283–298, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "The obvious solution is to reduce the communication data volume by compress- ing the data before transmitting. The ’Baseline’ model is a fully powered system with no energy restrictions, and the quantized model runs on harvested energy using a RR12 policy. the data efficiently , since communication is an expensive task and especially challenging for EH-WSNs [ 22 ] thanks to their fickle and ultra-low energy budget.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "A complete formal proof, including all technical conditions, is provided in Appendix  B . Guidelines for Hyperparameter Selection: The param- eters  γ ,  δ , and  η  critically influence sensor behavior by dictating the trade-offs between participation rewards, penal- ties for incorrect submissions, and deterrents against non- participation. Detailed guidelines for selecting these hy- perparameters are provided in Appendix  A .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "Like the first step, this step also involves synchronizations between planes (in  Line#12 ), which can again impact parallelization and slow down the entire execution. Intuitively, the execution performance is mainly determined by the number of depth planes (the outer for-loop in the algorithm) as well as the number of pixels in each depth plane (the inner for-loop in the algorithm). To study how the number of depth planes affects the hologram performance, we profile the execution latency from a typical edge GPU device [ 36 ], generating holograms with different number of depth planes (assuming the same number of pixels in each plane), and the results are plotted in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 158,
    "augmented": false
  },
  {
    "text": "To cope with this, we introduce a parameter called  Commonality , which is defined as the fraction of number of unique paths that the function can be a part of with respect to the total number of unique paths. This is how the procedure  𝐶𝑜𝑚𝑚 calculates Commonality  in Algorithm 1. For example, in Figure 1a, the Commonality  of the function  𝐶𝑜𝑚𝑝𝑜𝑠𝑒 _ 𝑃𝑜𝑠𝑡 in the  Social Network  application is given by the fraction   4 \n7   as it is present in four out of the seven possible paths in the DAG.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "0 \n300 \n600 \n900 \n1200 \n0.25 0.5 0.75 0.98 0.99 \nLatency (ms) \nCDF Kraken Comm Only \nConn Only SLO \n(b) Response Time Distribution. Figure 13: Real System: Normalized Energy Consumption of all Schemes and Response Time Distribution of  Kraken ,  Comm Only and  Conn Only achieve this. The tail latency (measured at P99) for  DProb almost exceeds the SLO, whereas it does so for  SProb .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "They will have access to courses on Effective Communi- cation and Presentation Skills. Improving Skills \nThe students will participate in regular research group meetings, where they will describe their work to colleagues and collaborate on solving research problems, fostering communication, programming skills, and other types of technical skills. Instruction in Responsible Professional Practices \nThe PhD students will receive instruction in responsible and ethical professional practices regularly within the context of their work.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "D Formulation of Dynamic Dropouts: \nD.1 L2 Dynamic Dropout with QuantaTask Optimization \nL2 Dynamic Dropout leverages the L2 norm of the weights to influence dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems. This state is used to continue the computation exactly where it left off, minimizing redundant operations and ensuring efficiency. Mathematical Formulation:  Let  W  be the weight matrix of a layer.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "T260–T261, 2017. [9]  Y. Ji, Y. Zhang, X. Xie, S. Li, P. Wang, X. Hu, Y. Zhang, and Y. Xie, “FPSA: A full system stack solution for reconﬁgurable reram-based NN accelerator architecture,” in  Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) , pp. 733–747, 2019.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "42 ×  speedup is achieved when employing Intra-Holo  (with only 0 . 44% overhead), and 2 . 68 ×  when employ- ing  Inter-Intra-Holo  (with only 0 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "If no match is found, the OCE is invoked for the entire left eye and only the ﬁrst row for the right eye, and then terminates by an external signal sent from our  AE  block, and bypasses the computation for rest rows. In the proposed AE  design, the  Δ  pattern buffer is ﬁrst initialized by subtract- ing  Result [1] .R  from  Result [1] .L , as shown in the  AE  block in Fig. If a match is detected, then the corresponding  P i − 2 buff   or  P i − 2 buff   buffer address pointer is directly returned.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "Proof of Theorem  4.1 : The proof constructs a potential function  Φ( a ( t )) =   P N i =1   U i ( a i ( t ) ,  a − i ( t ))  that strictly in- creases whenever a sensor makes a profitable unilateral deviation. Then, the iterative best-response updates described in Algorithm  1  converge to a Nash equi- librium action profile  a ∗ ( t ) . Since utilities are bounded (due to finite en- ergy and limited accuracy gains) and returns diminish over time, no infinite sequence of profitable deviations is possi- ble.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 177,
    "augmented": true
  },
  {
    "text": "[167] Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han. Mixture of lora experts. arXiv preprint arXiv:2404.13628 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": ", “In-datacenter performance analysis of a tensor processing unit,” in  Proceedings of the 44th annual international symposium on computer architecture , 2017, pp. [37] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, \nS. Bates, S. Bhatia, N. Boden, A. Borchers  et al. 1–12.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Following are the key observations from our experiments. 1) The data sharing with the cloud increases the accuracy of the power prediction significantly (11.94% increase in correlation for a 2-home setup and about 25.62% increase in \n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 \n0.8 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.9 \nEdge \nCloud (Shared) \nCloud (Privacy) \nEdge \nCloud (Shared) \nCloud (Privacy) \nEdge \nCloud (Shared) \nCloud (Privacy) \nEdge \nCloud (Shared) \nCloud (Privacy) \n#Devices=2 #Devices=3 #Devices=4 #Devices=5 \nLatency (ms) \nPearson Correlation \nPearson Correlation Latency (ms) \nFig. 3: Accuracy-latency comparison of different policies with differ- ent distributed setup.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 206,
    "augmented": false
  },
  {
    "text": "This allows us to perform flexible and efficient “neighborhood training” by localizing  the training parameters and  freezing  the rest of the parameters as much as possible to save cost. To this end, we propose a method for continual adaptation of EoE systems by  LLM expert split, merge, grow, and shrink . For example, as shown in Figure 3, we can split a large expert model into smaller domain-specific models and train them on smaller, focused datasets in corresponding domains.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "WoSC’20, December 7ś11, 2020, Delft, Netherlands J.R. Gunasekaran, et al. Unlike accuracy and latency, which depends on the right model, cost is dictated by the type of deployment used to host them in a public cloud. The deployment costs differ based on the provisioning times and longevity of the resource pro- cured.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "A deep dive into 7 th   iteration reveals that the micro-proﬁler chose a higher learning rate (compared to the oracle), which biased the convergence curve ﬁtting and extrapolation (as discussed in § III-C ) and hence suggested a larger number of layers to be trained to achieve the required convergence. Similarly, the micro-proﬁler shows consistent behaviour while choosing the right number of batches. Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "5a ) incorporates all the aforementioned points. The hardware design of  Us. ´as  (Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "Since the data size is limited, with increasing numbers of machines, the training data-per-machine decreases, and hence gives us the opportunity to also study the impact of data availability. The goal of our study was to correctly predict the surface roughness from sensor data. We divided the data into multiple chunks to emulate a multi machine setup (varying from 2 to 5).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Speciﬁcally, to compute the 2-norm attribute distance, two kernel functions are invoked ( Diff Squared  and Squared Sum ), which consume 35 %  and 16 % , respectively of the total energy. Such high energy consumption of these two kernels can be attributed to two reasons. First, these are the most frequently invoked kernels during the block matching stage.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Thus, the RS  7  , in combination with the PWS  2  and re- quest batching  5  , helps  Kraken  remain SLO compliant while using minimum resources. 5 Implementation and Evaluation We have implemented a prototype of  Kraken  using open- source tools for evaluation with synthetic and real-world traces. The details are described below.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "E CIFAR-100 and BERT Models \nTable  8  shows the different models available for image predic- tion, that are pretrained on Keras using  CIFAR-100  dataset. Model Params (M) \nTop-1 Accuracy(%) \nLatency (ms) P f \nAlbert-base [ 51 ] 11 91.4 55 7 CodeBert [ 32 ] 125 89 79 6 DistilBert [ 67 ] 66 90.6 92 5 Albert-large 17 92.5 120 4 XLNet [ 85 ] 110 94.6 165 3 Bert [ 30 ] 110 92 185 3 Roberta [ 55 ] 355 94.3 200 2 Albert-xlarge 58 93.8 220 1 Albert-xxlarge 223 95.9 350 1 \nTable 9:  Pretrained models for Sentiment Analysis using BERT. Similarly Table  9  shows the different models trained for BERT-based sentiment analysis on twitter dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 213,
    "augmented": true
  },
  {
    "text": "28%  ( Paris video). By applying the  EA  optimization itself, on an average, the energy beneﬁt is translated to  14%  end-to-end energy savings, as shown on the right y-axis in Fig. 9.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "IEEE, 2014, pp. 609–622. [17] P. Chi, S. Li, Y. Cheng, Y. Lu, S. H. Kang, and Y. Xie, “Architecture \ndesign with stt-ram: Opportunities and challenges,” in  2016 21st Asia and South Paciﬁc design automation conference (ASP-DAC) .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "F Spot Instance Price Variation \nWe proﬁle the spot price of 4 types of  C5  EC2 VMs over a 2-week period in August 2020. Model Params (M) Top1 Accuracy % Latency (ms) Pf Squeezenet 4,253,864 70.10 43.45 10 MobileNEt V2 4,253,864 68.20 41.5 10 Inception V4 23,851,784 76.74 74 6 Resnet50 95,154,159 79.20 98.22 5 ResNet18 44,964,665 76.26 35 6 DenseNet-201 20,242,984 79.80 152.21 2 DenseNet-121 8,062,504 78.72 102.35 3 Xxception 22,910,480 77.80 119.2 4 NasNet 5,326,716 77.90 120 3 InceptionResnetV2 2,510,000 80.30 251.96 1 \nTable 8:  Pretrained models for CIFAR-100 using Imagenet. Similarly Table  9  shows the different models trained for BERT-based sentiment analysis on twitter dataset.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 264,
    "augmented": true
  },
  {
    "text": "Note that, this projection process is quite compute-intensive. Furthermore, in a typical VR headset, the above computation needs to repeat millions of times, for processing just one  360 ° frame. Our characterization indicates that, on average, around 2.3 GFLOPS is required for this projection transformation (details are discussed in Sec.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Output:  Following the inference stage, the resulting Feature- Maps (FMs) are used to generate the ﬁnal tags/bounding-boxes and ﬁnally report to the application (e.g., a cow has been identiﬁed in the image with 95% conﬁdence). Fig. 1: A DNN inference pipeline on an edge device with optimizations in the application, system, and hardware levels.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "By the end of the project, the entire framework along with sample expert models, algorithms, system support and documentation will be in the public domain. Around mid-way in the third year, we will have all three main pieces of the project (algorithmic enhancements, system support and architectural support) ready. By the end of the second year, the preliminary system support will be finalized and we will have the initial expert-to-chiplet mappings ready.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 97,
    "augmented": true
  },
  {
    "text": "Note that, changing the target accuracy to tolerate a 0.5% loss, increases the percentage of requests that meet accuracy to 81% for  Cocktail , when compared to 61% for  InFaas . The requests meeting accuracy are generally higher for the Relaxed  workload because the target accuracy is much lower. Overall,  Cocktail  was able to deliver an accuracy of 83% and 79.5% on average for the  Strict  and  Relaxed  workloads, respectively.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Xlnet: Generalized autoregressive pre- training for language understanding. arXiv preprint arXiv:1906.08237 , 2019. [86]  Chengliang Zhang, Minchen Yu, Wei Wang, and Feng Yan.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "Folio: Natural language reasoning with first-order logic. In  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , 2024. [63] Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, and Alexandra Peste.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "After the initial meetings with the PhD students, the students will be asked to complete a worksheet to ensure alignment on objectives. Mentoring Plan \nThis project will accommodate a total of 4 PhD students, as discussed in our Management and Coordi- nation Plan. The PIs will perform the following mentoring activities for these PhD students: \nOrientation and Expectation Setting \nThe PIs will engage in in-depth conversations with PhD students, to set clear expectations, goals, and deliverables for the project period.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Minillm: Knowledge distillation of large language models. In  The Twelfth International Conference on Learning Representations , 2024. [56] Yanchu Guan, Dong Wang, Zhixuan Chu, Shiyu Wang, Feiyue Ni, Ruihua Song, Longfei Li, Jinjie Gu, and Chenyi Zhuang.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 89,
    "augmented": false
  },
  {
    "text": "This makes  Origin  versatile and suitable for systems whose intermittence comes from either or both of power or device reliability limitations, both of which will be key factors in real-world IoT deployments. Moreover, ensemble learning \nActivity Policy Comparision RR12 Origin BL-2 BL-1 vs BL-2 vs BL-1 Walking 81.60896 84.46 91.56 -2.85104 -9.95104 Climbing 83.10679 77.93 83.24 5.176789 -0.13321 Cycling 85.88992 85.81 94.27 0.079918 -8.38008 Running 87.13474 81.29 86.91 5.844736 0.224736 Jogging 81.81809 78.04 83.17 3.778086 -1.35191 Jumping 83.69378 79.42 84.26 4.273776 -0.56622 \nTABLE I:  Comparing RR12 Origin with both the baselines on MHELATH dataset. BL indicates the baseline models.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 242,
    "augmented": false
  },
  {
    "text": "Overallo- cation of containers in case of  Arch  is due to two reasons: (i) it assumes that all functions in the application will be invoked at runtime; and (ii) it spawns one container per in- vocation request. On the other hand,  Fifer  improves upon this by reducing the total number of containers spawned using request batching. However, it does not take workflow activation patterns into consideration while spawning con- tainers, leading to container overprovisioning.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "Integrating additional compute capabilities within storage stacks to offload certain computational tasks may seem an intuitive solution to the problem at hand. Theoretically, storage stacks could handle operations like unRAID and decryption, and extend their functionality to data inflation and \n6 \nfeature extraction. This would ostensibly allow for the selective transfer of only pertinent exemplar data to compute servers, thereby optimizing data movement costs.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 91,
    "augmented": false
  },
  {
    "text": "This repre- sents  𝑁𝐶 𝑑 𝑡 (Section 3) for all possible depths,  𝑑 . We have also verified that  Kraken (as well as the other schemes) yield similar results (within 2%) when multiple applications are run concurrently. 6.1 Real System Results 6.1.1 Containers Spawned : Figure 8 depicts the function- wise breakdown of the number of containers provisioned across all policies for individual applications.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "[3] Exploring llms - real-world case studies in ai-generated art & literature. https://www. tome01.com/exploring-llms-real-world-case-studies-in-ai-generated-art- literature , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Since the ex- perts are pivotal in the way the prompt/query is being answered, it is equally imperative for the routers to fully utilize the expert network by directing the rel- evant queries to the right expert(s) dynamically depending on the current ex- perts being involved in the network. We will develop techniques that can help us identify which routers need retraining and when, and schedule such retraining in a data locality and parallelism aware fashion. All these activities may require  retraining  the routers.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Types of Data and Storage \nThe project will generate seven types of data: (i) the codes and executables for the compiler that performs expert-to-chiplet mapping; (ii) source codes for scheduling support and simulator; (iii) expert repository that will hold the LLMs/expert models generated during the project; (iv) detailed LLM/expert algorithms as well as workload characterization and experimental data; (v) educational materials; (vi) a document detailing how to use the software developed during the project; and (vii) finally, lineage (provenance) data (more on this below). The source codes for the compiler and systems software support, as well as simulator source code will be maintained in Penn State as long as they are needed. They will be made available to the broad research community and other interested parties via a GitHub license.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 187,
    "augmented": false
  },
  {
    "text": "Going beyond RR-12 might lead to missing an activity window for high intensity or rapid activities, and going below RR-12 might lead to energy scarcity at times. Further evaluations suggest Origin  with RR-12 to be the best ﬁt for HAR. In case of abundant energy supply, one can use a round robin policy ﬁt for the given EH source.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "In  Databricks Data Intelligence Platform: Unlocking the GenAI Revolution , pages 311–330. Springer, 2024. [58] Rakesh Gupta, Anil Singh, and Deepak Kumar.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "2020. Objectron: A Large Scale Dataset of Object-Centric Videos in the Wild with Pose Annotations. arXiv preprint arXiv:2012.09988  (2020).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "These software-based solutions exhibit inefficiencies with respect to energy and time due to performing multiple save- and-restore cycles [ 23 ,  56 ]: while some of these operations are necessary, unnecessary checkpoints will also be conser- vatively performed to ensure forward-progress. multi-sensor HAR, predictive maintenance etc.). While these software optimizations and judicious use of persistent storage works for smaller workloads like keyword spotting (e.g  \"Ok Google\" detection), they are inefficient for complex workloads (e.g.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:1910.01108 , 2019. [68]  Prateek Sharma, David Irwin, and Prashant Shenoy. Portfolio-driven resource management for transient cloud servers.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Towards designing a self-managed machine learning inference serving system inpublic cloud, 2020. [39]  U. Gupta, S. Hsia, V. Saraph, X. Wang, B. Reagen, G. Wei, H. S. Lee, D. Brooks, and C. Wu. Deeprecsys: A system for optimiz- ing end-to-end at-scale neural recommendation inference.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "In  2008 15th IEEE International Conference on Image Processing , pages 277–280. Appendix \nA Modeling of Ensembling \nWhile performing an ensemble it is important to be sure that we can reach the desired accuracy by combining more models. IEEE, 2008.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "However, our proposed solution offers  ≈ 3 . 2 ×  speedup compared to its software counterpart and a  ≈ 2 . 5 × speedup compared to the software based RSA algorithm.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "Further, as mentioned in Sec. VI-B , 4 CPU threads are invoked to perform the macro-block matching in CWIPC, this results in even higher CPU power. For example, the average CPU power for TMC13 is  1687 mW whereas  3622 mW  for CWIPC.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "It can be seen that virtual machines are always cheaper compared to using  serverless functions for all constant request rates. A similar trend is observed for the iso-accuracy model types, which is shown in Figure  3b . It is also possible to use bigger VMs, which can handle more concurrent requests compared to m4-large, thus mini- mizing the total number of VMs used.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ·  m i \nTraining with Taylor Expansion Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  λ . Define the energy budget  E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": ". . , n , we merge them into one model  θ m  by computing a weighted average of parameters where the weight is each parameter’s Fisher information:  θ m  =   P n i =1   F i θ i /  P n i =1   F i , where  F i  is the Fisher Information for  θ i .",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "The mask values are determined using a sigmoid function to ensure they lie between 0 and 1: m i  =  σ ( z i ) where  z i  are learnable parameters and  σ ( · )  is the sigmoid function. , m n ]  where  m i  ∈{ 0 ,  1 } . In Learning Sparse Masks Dropout, the dropout masks are treated as learnable parameters.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 109,
    "augmented": true
  },
  {
    "text": "C ONCLUDING  R EMARKS \nPushing DNN-assisted video analysis into edge is the cur- rent trend in applications like surveillance, assisted surgery, and VR/AR [23]. VI. If we can deploy the decision making logic on a  custom hardware  with negligible overhead, our proposed techniques would be more effective when targeting light DNN models.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "Moreover, NN-PCC mainly focuses on compressing the geometry data and hence is not very useful for the PC with attributes [ 88 ]. real-time refresh requirement of vision applications is yet to close and prevents the deployment of NN-PCC on edge devices. To the best of our knowledge, most of these works focusing on PCC with attributes target the compression ratio, and overlook the latency or energy consumption.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "[50] Z. Li and D. Hoiem, “Learning without forgetting,”  IEEE transactions \non pattern analysis and machine intelligence , vol. 106–109, 2020. 2, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "In  Proceedings of the Workshop on Hot Topics in Operating Systems , New York, NY, USA, 2019. [84]  Tien-Ju Yang, Andrew G. Howard, Bo Chen, Xiao Zhang, Alec Go, Vivienne Sze, and Hartwig Adam. Association for Computing Machinery.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "The sec- ond step,  Backward-Propagate  (denoted  ❷ in Fig. 4a), accumulates the results of each depth plane, backpropagates it to the hologram plane via the  DP2HP  procedure (in  Line#11 ), and generates the final hologram for this depthmap input. Like the first step, this step also involves synchronizations between planes (in  Line#12 ), which can again impact parallelization and slow down the entire execution.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "In these two slices, the objects keep moving. Thus, most of the frames will perform FI under FI+SI, as shown in Fig. 8b.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 37,
    "augmented": false
  },
  {
    "text": "Visual precis generation using coresets. 2014. [55]  Rohan Paul, Dan Feldman, Daniela Rus, and Paul Newman.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Over repeated iterations, under suitable conditions, this process converges to a Nash equilibrium where participation strategies are mutually optimal. Sensors employ this best-response mechanism, continuously updating their participation decisions based on the evolving network state and the actions of other sensors. Existence and Convergence of Equilibrium: \nTheorem 4.1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "In fact, the existing state-of-the-art software stack, such as GoogleVR-SDK [11], simply uses the IMU sensor inputs to calculate the updated transformation matrices, then passes them to the OpenGL [42] engine to process the projection computation, as shown in Fig. 2b. We would also like to point that capturing these opportunities is not trivial and cannot be efﬁciently done by just optimizing the existing application layer and software stack.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 102,
    "augmented": false
  },
  {
    "text": "This allows for dynamic adaptation to network fluctuations and client-side computational capabilities, thereby optimizing the streaming experience. Layered neural codecs, by design, encode video into multiple, distinct layers of data, each enhancing the video quality incrementally. To address these shortcomings, the advent of layered neural codecs marks a significant advancement (Dasari et al., 2022a).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Here, each expert is specialized to solve tasks in specific domains, languages, or skills. Expert models are also “composable”, so that they can be chosen dynamically according to inputs and then grouped together to solve difficult tasks, which require a combination of skills and knowledge sources. Experts can be trained individually and continually adapted to generate new experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "). Recent studies have begun to address federated learning in resource-constrained and unreliable networks. Strategies in- clude adaptive aggregation methods, energy-aware training schedules, and robustness to device dropouts ( ?",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Antonio Barbalace and Jaeyoung Do. Computational storage: Where are we today? In  CIDR , 2021.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 31,
    "augmented": false
  },
  {
    "text": "As shown by  Line#5  and  Line#7  in Algo. 2, our proposal can actually reuse the original hologram execution engine without any architectural modifications or reprogramming. In fact, only one input argument, i.e., the number of depth planes, requires to be changed based on the approximation factor  α , when the object is outside of RoF.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "[60] Suchin Gururangan, Margaret Li, Mike Lewis, Weijia Shi, Tim Althoff, Noah A Smith, and Luke Zettlemoyer. Demix layers: Disentangling domains for modular language modeling. arXiv preprint arXiv:2108.05036 , 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "2.1 AR Holographic Applications and Pipeline \nThe holographic display technique enables a large body of aug- mented applications in real life [ 14 ]. One such application is illus- trated in Fig. 1a, where a physical car being driven on a highway is replaced by the corresponding virtual/augmented holographic car in a real-time fashion such that, instead of viewing the real cars, the AR user views the virtual ones.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "Restrictions apply. as described in Sec. IV , and then treat the obtained delta values as new attributes, and ﬁnally feed them again to the encoder to further increase the compression efﬁciency).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 41,
    "augmented": false
  },
  {
    "text": "Figure  4  shows the class-wise accuracy for three models on 5 distinct classes. It can be seen that for simpler classes like Slug,  MNetV2  can achieve similar accuracy as the bigger models, while for difﬁcult classes, like Cup and Quill, it experiences up to 3% loss in accuracy. Since the model participation for ensembling can vary based on the class of input images being classiﬁed, there is a scope to develop a dy- namic model selection policy that can leverage this class-wise variability to intelligently determine the number of models required for a given input.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "Clearly, the current solution is  not  sustainable, neither in terms of the load on the power grid, nor in terms of the  CO 2  footprint (1.1 × 10 9 lbs); reducing the power budget for continuous learning is essential, as the carbon footprint of DNN training has emerged as a prominent concern [ 21 ], [ 57 ], [ 67 ], [ 89 ], demanding careful consideration as a primary design metric. Although green data centers [ 58 ], [ 59 ] provide partial mit- igation, they fail to address data privacy and communication bandwidth challenges in the current context. Similarly, other applications with diverse data modalities, such as LiDAR and Camera for autonomous driving, IMU, bio-sensors, and Speech for IoT, face similar issues.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "[70]  Shulin Zhao, Haibo Zhang, Sandeepa Bhuyan, Cyan Subhra Mishra, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 657–669.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "[57] Nikhil Gupta and Jason Yip. Dbrx: Creating an llm from scratch using databricks. In  Databricks Data Intelligence Platform: Unlocking the GenAI Revolution , pages 311–330.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "315–327. [57]  Attila Reiss and Didier Stricker. 2012.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 25,
    "augmented": true
  },
  {
    "text": "Innovations in this domain include the latest GPUs optimized for LLM use-cases [1, 2], TPUs [76], domain-specific accelerators like Cerebras Systems Wafer-Scale Engine (WSE) [86], Graphcore Intelligence Processing Units (IPUs) [54], Habana Lab’s Gaudi and Goya accel- erators [87, 103], SambaNova’s SN40L reconfigurable dataflow unit (RDU) [131], and Groq [61]. These aforementioned hardware equivocally echo the need of highly parallel computation with bigger and faster memory hierarchy to contain the pool of data for high-scale deployments. LLM Hardware and Accelerators:  These sophisticated system level strategies require the use of equally high-performing hardware to complement for faster, efficient and economic implementation for both train- ing and inferring from these models.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 207,
    "augmented": true
  },
  {
    "text": "Efficient healthcare with large language models: optimizing clinical workflow and enhancing patient care. Oxford Academic , 2024. [123] OpenAI.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 33,
    "augmented": false
  },
  {
    "text": "Consequently, the stochastic gradient descent (SGD) updates retain their convergence properties, ensuring that the training process reliably optimizes  J ( θ ) . 6 \n330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 \n6. Implementation and Evaluation \n6.1.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 155,
    "augmented": false
  },
  {
    "text": "Considering the scale, scope and workload of our problem, limits direct comparisons, except for comparing their exemplar selection method (refer Fig. 9 ). Similarly, Ekya [ 12 ] only focuses on co-location of computation, and it’s efﬁciency on ﬁnishing compute even on custom hardware is shown in Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "In our future work, we would like to further explore the beneﬁts by incorporating them into our design. 251 \nOur proposed  EA  and  AE  designs focus on these intensive projection computations, and as such are orthogonal to these prior efforts. Head Orientation Prediction for  360 °  Video Streaming: To optimize both performance and energy, researchers have leveraged the powerful remote rendering engines on cloud to predict the next head orientation for the VR clients [2], [6], [18], [23], [30]–[32].",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Optica  (2021), 143–146. Optimizing image quality for holographic near-eye displays with Michelson Holography. 2021.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Towards this, we plan to design a system-level scheduler which can efficiently partition the hologram tasks between the heterogeneous accelerator and original execution engines such as CPUs or GPUs. 6 RELATED WORK \nIn this section, we summarize prior work related to different aspects of holographic processing. Optimizations in Holographic Processing:  Holographic pro- cessing has been optimized in various domains [ 33 ,  35 ,  52 ,  54 ], to improve power efficiency or execution performance.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "[140] Anup Sarma, Sonali Singh, Huaipan Jiang, Rui Zhang, Mahmut Kandemir, and Chita Das. Struc- tured in space, randomized in time: Leveraging dropout in rnns for efficient training. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "Restrictions apply. VI. D ISCUSSION \nKey insights:  Compared to other systems, the ratio of energy requirement of task vs the harvested energy is much higher here.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 40,
    "augmented": false
  },
  {
    "text": "IEEE Transactions on Big Data , 2020. [6] Cyan Subhra Mishra, Jack Sampson, Mahmut Taylan Kandemir, and Vijaykrishnan Narayanan. Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor net- works.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 77,
    "augmented": false
  },
  {
    "text": "By integrating multiple Chain and Tree EoE structures, we can create complex Graph Ensemble-of-Experts (GEoE), facilitating communication and collaboration among experts. Modeling Expert Collaboration with Graph Ensemble-of-Experts. For example, each expert in chains and trees can produce intermediate results, and they can be aggregated into the final manager expert to produce the ultimate result.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 83,
    "augmented": true
  },
  {
    "text": "CCS Concepts:  ·  Computer systems organization  → Real-time system architecture . Towards this, we discuss the design implications of a self-managed inference serving system, which can optimize for application requirements based on public cloud resource characteristics. Hence, to holistically address this problem, we need to solve the issues that arise from combining both model and resource heterogeneity towards optimizing for application constraints.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "Figure  1  shows the candidate models which can be used for a given latency and accuracy. Our  Paragon  scheme optimizes the model selection for workload-2 such that, it chooses the least cost-effective model for the given accuracy and latency constraint. The naive model selection policy would not choose the models as its oblivious to user requirements and model characteristics.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 80,
    "augmented": false
  },
  {
    "text": "While this approach is beneficial to minimize SLO violations, comparable performance can be achieved by using fewer containers by leveraging the notion of slack [ 32 ,  34 ]. Slack refers to the difference in expected response time and actual execution time of functions within a function chain. 4.2 Request Batching Many serverless frameworks [ 5 ,  10 ,  17 ,  27 ,  44 ,  46 ,  50 ] spawn a single container to serve each incoming request to a function.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "In this case, the found leaf  L 1 - I , which contains two points ( P 0 and  P 1 ), is a perfect match; however, no match can be found for the  L 2 - P  leaf. This processing can be quite time-consuming, and our proﬁling shows that it usually takes  ≈ 5 . This process is repeated for  O ( N )  times, where  N  is the number of macro-blocks in the P-Frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "A CKNOWLEDGMENTS This work was supported in part by Semiconductor Research Corporation (SRC), Center for Brain-inspired Computing (C- BRIC) and NSF Grant #1822923 (SPX: SOPHIA). R EFERENCES \n[1] “Taking an ecg with the ecg app on apple watch series 4 or later,” 2020, https://support.apple.com/en-us/HT208955. [2] “Use fall detection with apple watch,” 2020, https://support.apple.com/en- us/HT208944.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 137,
    "augmented": false
  },
  {
    "text": "The requests are served as independent parallel threads to ensure timely predictions. We use  Python Sanic  web-server for commu- nication with the master and worker VMs. Each worker VMs runs a client process to serve its corresponding model.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 58,
    "augmented": true
  },
  {
    "text": "•  We implement both the designs on an edge GPU platform [ 36 ], without the need for any hardware modification. We evaluate these designs using the NVPROF tool [ 37 ] and hardware power management unit on the edge GPU platform [ 36 ]. Our exper- imental results reveal that,  HoloAR  provides 29% reduction in power consumption and 2 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "In  16th USENIX Symposium on Networked Systems Design and Implementa- tion (NSDI 19) , pages 699–718, Boston, MA, February 2019. USENIX Association. [59]  Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gregory R Ganger, Phillip B Gibbons, and Matei Zaharia.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "[114] Naveen Muralimanohar, Rajeev Balasubramonian, and Norman P. Jouppi. Cacti 6.0: A tool to model large caches. 2009.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "[14] K. Han, Z. Fang, P. Diefenbaugh, R. Forand, R. R. Iyer, and D. Newell, “Using Checksum to Reduce Power Consumption of Display Systems for Low-motion Content,” in  2009 IEEE International Conference on Computer Design , 2009, pp. 587–598. [13] M. Ham, I. Dae, and C. Choi, “LPD: Low Power Display Mechanism for Mobile and Wearable Devices,” in  Proceedings of the USENIX Conference on Usenix Annual Technical Conference (ATC) , 2015, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 140,
    "augmented": true
  },
  {
    "text": "Garnet: A detailed network-on-chip simulator. In  Proceedings of the 2012 International Sym- posium on High Performance Computer Architecture (HPCA) , pages 507–518. IEEE, 2012.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Texas Instruments. Msp430fr5994 mixed-signal microcontrollers. https://www.ti.com/ product/MSP430FR5994 , 2024a.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 45,
    "augmented": false
  },
  {
    "text": "Accelerating hpc applications using computational storage devices. 22 \nMahdi Torabzadehkashi, Ali Heydarigorji, Siavash Rezaei, Hosein Bobarshad, Vladimir Alves, and Nader Bagherzadeh. IEEE Transactions on Knowledge and Data Engineering , 2023.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "While such an approach improved the computational efficiency and reduced power consumption to some extent, rethinking the design of hologram software/hardware con- sidering the unique features of the AR holographic applications (as discussed in Sec. 2.2) as well as the characteristics of the underlying hardware can potentially open up further opportunities. 498 \nMICRO ’21, October 18–22, 2021, Virtual Event, Greece Shulin and Haibo, et al.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Our modular, plug-and-play based approach not only allows for targeted research within individual elements of the en- semble, but also supports contributions from the broader research community. Such incremental growth epitomizes the democratization of large-scale design efforts. Thus, we believe our proposal is ambitious as its potential to revolutionize the training and deployment of LLMs is profound.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "292–308, 2019. [16] Y. Chen, T. Luo, S. Liu, S. Zhang, L. He, J. Wang, L. Li, T. Chen, \nZ. Xu, N. Sun  et al. 2, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Archipelago: A scalable low-latency serverless platform. arXiv preprint arXiv:1911.09849  (2019). [45]  Davide Taibi, Nabil El Ioini, Claus Pahl, and Jan Raphael Schmid Niederkofler.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "4:  Set  η 0  > δ 0 . Start with  η 0  =  δ 0  +  c , where  c  is a small positive number. If preliminary tests show insufficient participation, slightly increase  η 0 .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "4:  For each action candidate  a i ( t )  ∈{ P ,  NP } , the sensor computes the expected utility: \nU   a i ( t ) i =  E [ R i ( t )]  − E [ e i ( t )]  − β E [ V i ( t  + 1)] , \nwhere the expectations are taken over uncertainties in correctness, SNR impact, and future energy. 5:  If  U   P i   ≥ U  NP i and  B i ( t )  ≥ e cap ( SNR i ( t ))+ e inf + e comm , then  s i  chooses P. Otherwise, it chooses NP. 6:  After all sensors decide, the action profile  a ( t )  is real- ized, and energies are updated: \nB i ( t  + 1) =  B i ( t ) +  E i ( t )  − e i ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 246,
    "augmented": false
  },
  {
    "text": "This ensures that no computation is lost when the power goes out. C.1.5 Resumption Mechanism \nUpon resuming, the algorithm loads the saved state using the  LOAD_STATE  function. This state is used to continue the computation exactly where it left off, minimizing redundant operations and ensuring efficiency.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "It also demonstrates that the proposed ResiRCA has total area requirements smaller than previously proposed “smart dust” solutions [ 8 ]. 12. Throughput normalized to G4 with  Naive2  vs. ReRAM duplication granularity \nThe RCA area is impacted from the parallelism granularity G , as shown in Figure 13.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 78,
    "augmented": true
  },
  {
    "text": "However, the huge data volume of the PC still remains \n284 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore. Restrictions apply.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "For instance, complex sentences are more accurately classiﬁed by denser models compared to smaller. However, the model selection policy effectively switches between differ- ent models based on the structure of input text (equivalent to classes in images). Despite the lower accuracy gains,  Cocktail  is able to reduce the cost (Figure  17 ) of model-serving by 1.45 ×  and 1.37 × for Wiki trace compared to  InFaaS  and  Clipper , respectively.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Moreover, streaming requires two projections for both the eyes. Thus, unlike planar videos, in  360 ° videos, speciﬁcally the projection computations for capturing the head movements and eye correlations, are sig- niﬁcantly computation-heavy, amounting to  59%  of the overall VR (headset) power budget. As the 360 ° video is not in a planar format, the VR ecosystem converts it to a conformal 2D format by passing it through multiple stages of transformations.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "In  14th  { USENIX }  Symposium on Operating Systems Design and Imple- mentation ( { OSDI }  20) . 805–825. 166 \nKraken : Adaptive Container Provisioning for Deploying Dynamic DAGs in Serverless Platforms SoCC ’21, November 1–4, 2021, Seattle, WA, USA \n[41]  Mohammad Shahrad, Jonathan Balkind, and David Wentzlaff.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "Driven by these observations, we investigate the reasons behind such inefﬁciencies, and further explore the potential opportunities for speeding up the PC compression. Towards this, we studied three state-of- the-art PCC pipelines – octree-based pipeline for intra-frame geometry compression (Sec. Before delving into the details of our approach which aims to close the performance gap between “seconds” in practical and “hundreds of milliseconds” in ideal settings, we ﬁrst investigate the reasons behind the inefﬁciencies of the prior techniques.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "However, our design objective is to minimize  data movements in the case of compute reconﬁgura- tion. Most large-scale accelerators use the output stationary imple- mentations to minimize the output feature map movement [ 81 ], and some of available hardware even supports multiple types of mappings [ 15 ], [ 37 ]. stationary; 2. input stationary; and 3. weight stationary [ 79 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": ". At any given time  t , the available energy is denoted as  E b ( t ) . , T N } , where each task  T i  is characterized by its energy requirement  E i , execution time  τ i , priority  p i , deadline  D i , and criticality level  c i .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "To overcome these limitations,  Us. ´as  employs an ensembled teacher-student method, wherein multiple teachers annotate student data. A hierarchical K-means+ (or DBSCAN) clustering approach learns representations for exemplar se- lection.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "Implementation Details:  We abstract the  EA  and  AE  design blocks irrespective of the underlying hardware SoCs, and plot them in Fig. 7. However, when  AE  cannot take advantage of memoization due to a head orientation change, then the compute is distributed across the OCE ( 51% ) and  AE block ( 49% ); to be precise, only the entire coordinates on the left screen and the ﬁrst row on the right-screen are processed by the OCE – the remaining rows on the right screen are reconstructed by the less power-hungry  AE  block.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "[49] C.-H. Tsai, H.-T. Wang, C.-L. Liu, Y. Li, and C.-Y. 305–308. Lee, “A 446.6 K-gates 0.55–1.2 V H. 265/HEVC decoder for next generation video applications,” in  2013 IEEE Asian Solid-State Circuits Conference (A- SSCC) , 2013, pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "10: Contribution of different components of  Us. ´as  on other applications, data modalities, and power environments. the learner classiﬁed  ≈ 4.5 frames/100-frames (on an average) as exemplar data.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "[27] S. M. LaValle, “The Geometry of Virtual Worlds.” ”http://msl.cs.uiuc. edu/vr/vrch3.pdf”, 2019. [28] Y. Leng, C.-C. Chen, Q.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "As discussed above in Sec. Further, in many cases, these inputs are dynamically changing at the same frequency (e.g., the image sensors) as the frame-rate, which needs to be captured and updated at runtime, or even at a faster rate (e.g., the IMU and IR sensors). 3, both the user’s pose and the gaze position, as well as the targeted objects (intended to be re- placed by the virtual holograms) shape the hologram computation.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "Sweden data collection & processing. https://www. dlapiperdataprotection.com/index.html?t=collection-and-processing&c=SE .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "For smaller DNNs without 256 kernels in any layer, a batching mode is operational with a batch size of  B  =  ⌊ A / L ⌋ images, where  L  denotes the layer with the fewest channels, and  A  the number of active tiles. This generic design is adaptable for various workloads. In DNN training, meticulous compute mapping, mem- ory access strategies, and operational formulas are instru- mental for the forward and backward passes.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 106,
    "augmented": false
  },
  {
    "text": "Figure 1 illustrates QuantaTask execution with a simple example. Each QuantaTask ensures that execution proceeds without partial computation, which would otherwise lead to overhead from checkpointing and potential data corruption. The main properties of QuantaTasks are atomicity and respect for energy constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "3274–3280. 96, no. [83]  D. Valenzuela-Urrutia, R. Mu ˜ noz-Riffo, and J. Ruiz-del Solar, “Virtual reality-based time-delayed haptic teleoperation using point cloud data,”  Journal of Intelligent & Robotic Systems , vol.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "This, in turn, triggers autoscaling to provision extra containers to service the load surge. We disable this Alert Manager and deploy the Proactive Weighted Scaler (PWS) and Reactive Scaler (RS) to carry out our container provisioning policies. Both the PWS and RS collect metrics, such as the current container count, load history and request rate for a function for a given time window, from  Prometheus  and the  Kubernetes system log, using the Replica Tracker and Load Monitor mod- ules.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "MobiSys ’18, 2018, pp. 68–80. [31] X. Liu, Q. Xiao, V. Gopalakrishnan, B. Han, F. Qian, and M. Varvello, “360° Innovations for Panoramic Video Streaming,” in  Proceedings of the 16th ACM Workshop on Hot Topics in Networks , ser.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "Speciﬁcally, our proposal consists of the following 4 steps: PC sorting:  As shown in Fig. 7 , compared to the irregular raw PC, after sorting the PC via Morton-code, the adjacent points are more “regular” and geometrically closer, and thus share rich attribute similarities. Segmentation:  The next step is to partition the sorted PCs (i.e., I-frame and P-frame) into several blocks/segments (similar to the term “macro-blocks” in 2D image encoding).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "B. To summarize, the performance inefﬁciencies in prior works can be primarily attributed to the lack of parallelism of these algorithms. Motivated by this observation, we next plan to improve the compression performance by exploiting various parallelism opportunities, which have been ignored, to the best of our knowledge, by the prior research but are essential in employing PCC in edge device settings.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "Takeaway:  The prior octree-based works for both geometry and attribute compression suffer from performance inefﬁcien- cies, mainly because the octree construction, serialization and attribute transformations involve sequential computations. Note that, this step also needs to be performed sequentially across the tree layers. To improve the performance, next we want to explore the hidden spatio-temporal locality opportunities (missed by the prior works), and speed up  both  the geometry and attribute compression from  both  the intra- and inter-frame perspectives.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "IEEE Micro , 43(3):18–30, 2023. [97] Zi Lin, Diana Jin, and Saurabh Singh. Truthfulqa: Measuring how models mimic human falsehoods.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 47,
    "augmented": false
  },
  {
    "text": "Resiliency at scale: Managing  { Google’s }{ TPUv4 }  machine learning supercomputer. [200] Yazhou Zu, Alireza Ghaffarkhah, Hoang-Vu Dang, Brian Towles, Steven Hand, Safeen Huda, Adekunle Bello, Alexander Kolbasov, Arash Rezaei, Dayou Du, Steve Lacy, Hang Wang, Aaron Wis- ner, Chris Lewis, and Henri Bahini. In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pages 761–774, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 152,
    "augmented": true
  },
  {
    "text": "Otherwise, if the expression  Condition trans \nis not satisﬁed, with power prediction, we can still speculatively attempt to perform a smooth transition. Still, with Condition trans   satisﬁed, the smooth transition can be achieved in a similar way. In this way, we can, when accurate, make a much smoother transition when transferring the results of an incomplete inference.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 80,
    "augmented": true
  },
  {
    "text": "Hang Yue, Laurence R Rilett, and Peter Z Revesz. Spatio-temporal traffic video data archiving and retrieval system. GeoInformatica , 20:59–94, 2016.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "2022.00031. doi: 10.1109/MICRO56248. 282–299, 2022a.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "In  Advances in Neural Information Processing Systems , pages 5998–6008, 2017. [158] Shyam Venkataramani, Suresh Cherian, Sergio DeRose, Karthik Sankaralingam, and Sek Ching Wong. Garnet: A detailed network-on-chip simulator.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 75,
    "augmented": false
  },
  {
    "text": "12 \nTien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. Designing energy-efficient convolutional neural networks using energy-aware pruning. In  Proceedings of the IEEE conference on computer vision and pattern recognition , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Eye-dominance-guided Foveated Rendering. IEEE Transactions on Visualization and Computer Graphics (2020), 1972–1980. [31]  Microsoft.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "In this case, the current sensor chooses the next best sensor for the job and signals it. The other sensor receives this as an external signal and activates itself to classify the activity. To incorporate the ER-r, we induce delays between sending the external signal and starting the inference on the same sensor.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Note that, the  product  of these ﬁve transforms gives us the ﬁnal transformation matrices ( T L  and  T R ), which together convert the  3 D  coordinates of the  360 ° frame to the  2 D  coordinates suitable for HMD. T L = T 5  ×  T 4  ×  T   L 3   ×  T 2   ×  T 1 T R = T 5  ×  T 4  ×  T   R 3   ×  T 2   ×  T 1 (1) \nThese ﬁve transforms are of dimension of  4 × 4  ( 3  dimensions for rotation;  1  for translation), thus producing  4  ×  4  T L  and T R  matrices [27]. Mathematically, the transformation matrix for each eye is shown in Equation 1.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "First, we will implement different KV cache management policies for different experts, depending on their accuracy requirements, context lengths, and latency tolerances. We plan to address this in two ways. And second, we will explore EoE-specific KV cache compression strategies to optimize memory usage including quantization and sparsity optimization tech- niques.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "This work proposes a novel policy,  Origin , which enables energy harvesting wireless sensors to perform efﬁcient and accurate DNN inference. Speciﬁcally, Origin targets inherent features of sensor data from distributed body area networks in human activity recognition (HAR) tasks and leverages non- volatile processing, intelligent scheduling for energy-harvesting sensor nodes, and ensemble leaning to classify human activity with minimum accuracy loss compared to a state-of-the-art battery powered system. Therefore, this work proposes an intelligent scheduler along with efﬁcient ensemble learning to enable DNN inference in a distributed energy harvesting wireless sensor network (EH- WSN).",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "[7]  Akshitha Sriraman, Abhishek Dhanotia, and Thomas Wenisch. Softsku: Optimizing server architectures for microservice diversity@ scale. 2019.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "1–4, 2013. [14]  R. Grezaud and J. Willemin, “A self-starting fully integrated auto-adaptive converter for battery-less thermal energy harvesting,” in  2013 IEEE 11th International New Circuits and Systems Conference (NEWCAS) , pp. 95–99, 2016.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "), and the compute mode of Jetson AGX Xavier board is set to be 15W. 2) Point Cloud Dataset:  We use two dynamic PC video datasets – the 8i Voxelized Full Bodies (8iVFB) [ 18 ] and the Microsoft Voxelized Upper Bodies (MVUB) [ 8 ] datasets in our evaluations. Speciﬁcally, we pick four videos from 8iVFB, and two videos from MVUB.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "It is obvious that the raw data sensed by each sensor would be different, even for the same activity, because of the difference in move- ment and dynamics. For example, while cycling, the data sensed by the ankle, chest and wrist sensors would be en- tirely different because of the nature of the motion. Thus, the DNN architectures to infer these data are also different.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 85,
    "augmented": false
  },
  {
    "text": "4.2. Utility Function Definition \nWe define a utility function  U i ( t )  for each sensor  s i  that en- capsulates the trade-off between accuracy gains and energy \nexpenditures, as well as future opportunities. This stability is crucial for maintaining long-term network per- formance without necessitating continuous recalibration or extensive communication overhead.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "9. Energy efﬁciency of CNNs across the power sources normalized to ResiSchedule \nis higher than that of  Pipelining  solution for a signiﬁcant fraction of the active power cycles. That is, the selection ratio of  Sequential  is much higher than the ratio of  Pipelining  in ResiSchedule  solutions in the whole power trace.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Compact language models via pruning and knowledge distillation. arXiv preprint arXiv:2407.14679 , 2024. [114] Naveen Muralimanohar, Rajeev Balasubramonian, and Norman P. Jouppi.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "0 200 400 600 \nArch \nFifer \nDProb \nKraken \nSProb \nXanadu \n# Containers \nNGINX Check_Reservation \nGet_Profiles Search \nMake_Reservation \n(c) Hotel Reservation. Figure 8: Real System: Stage-wise Breakdown of Containers spawned by each policy. The reduction in the number of containers spawned by Kraken  in comparison to other policies is roughly propor- tional to the total number of application workflows and the slack available for each function within a workflow (see Ta- ble 2 and Figure 7).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "Application Kraken Comm Only Conn Only Social Network (99.94%, 284) (99.91%, 276) (99.89%, 256) Media Service (99.73%, 572) (99.66%, 561) (99.64%, 552) Hotel Reservation (99.87%, 316) (99.77%, 290) (99.74%, 282) Table 5: Real System: Comparing (SLO Guarantees,#Containers Spawned) against  Comm Only  and  Conn Only . schemes that exclude  Commonality  and  Connectivity  com- ponents from  Kraken , respectively. From Table 5, it can be seen that  Comm Only  spawns 8% more containers than  Conn Only  for  Social Network .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 175,
    "augmented": false
  },
  {
    "text": "https://community.intel.com/t5/Blogs/Tech-Innovation/Data-Center/ Intel-Labs-Showcases-Multi-Vendor-Computational-Storage-Platform/post/ 1404651 , August 2022. (Accessed on 11/13/2023). Daniele Micciancio and Oded Regev.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 90,
    "augmented": true
  },
  {
    "text": "Challenges in archiving and sharing video data: Considering moral, pragmatic and substantial arguments. Journal of Research Practice , 10(1), 2014. Dur E Shahwar Kundi, Song Bian, Ayesha Khalid, Chenghua Wang, Máire O’Neill, and Weiqiang Liu.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "4:  Set  η 0  > δ 0 . If preliminary tests show insufficient participation, slightly increase  η 0 . Start with  η 0  =  δ 0  +  c , where  c  is a small positive number.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 57,
    "augmented": true
  },
  {
    "text": "To prune, or not to prune: exploring the efficacy of pruning for model compression. arXiv preprint arXiv:1710.01878 , 2017. [199] Yang Zhu, Luke Zettlemoyer, and Jimmy Ba.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 58,
    "augmented": false
  },
  {
    "text": "arXiv preprint arXiv:2002.08155 , 2020. A review on ensembles for the class imbalance problem: Bagging-, boosting-, and hybrid-based ap- proaches. [33]  Mikel Galar, Alberto Fernandez, Edurne Barrenechea, Humberto Bustince, and Francisco Herrera.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 86,
    "augmented": true
  },
  {
    "text": "Index Terms —edge computing, random forest, edge-cloud par- titioning, sensor network \nI. I NTRODUCTION R Etrofitting intelligent sensors nodes on legacy manufac- turing systems provides cost-effective smart manufac- turing upgrades. However, reliably meeting real-time analyt- ics demands entirely within the limited compute and power budgets of these sensor nodes is challenging, especially for complex computational models such as DNNs. Therefore, simpler paradigms, like random forests, still remain popular for embedded sensors [7].",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 133,
    "augmented": false
  },
  {
    "text": "2018. In USENIX ATC . SOCK: Rapid Task Provisioning with Serverless-Optimized Containers.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "Sustainable  Continuous Learning at the Edge:  Even given such advancements in continuous learning on edge servers, provisioning training resources at the edge for every sensing- to-analytics application entails sustainability questions. For ex- ample, a popular AWS outpost, a g4dn.12xlarge instance [ 83 ], consists of a 24 core Intel Xeon CPU (150W TDP) [ 71 ] with 192GB of memory and 4 NVIDIA T4 (with tensor cores, 70W TDP) [ 65 ] with 64GB GPU memory. A standard offering with 2 × g4dn.12xlarge instances need 4kW power [ 7 ] (the compute units have a TDP of  ≈ 1 kW  [ 65 ], [ 71 ]) for \nperforming analytics.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 191,
    "augmented": false
  },
  {
    "text": "Salient Store  , with its intelligent data orchestration and acceleration, can provide up to  6 . 18 ×  latency and  6 . 13 ×  data movement reduction, compared to classical systems.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "2.3.1 Ensembling Compared to Single Models \nTo analyze the accuracy offered by ensemble models, we con- duct an experiment using 10000 images from  ImageNet  [ 29 ] test dataset, on a  C5.xlarge  [ 8 ] instances in AWS EC2 [ 5 ]. While ensembling is applicable in other classiﬁcation workloads like product recommendations [ 24 , 53 ], text classiﬁcation [ 71 ] etc, the observations drawn are generic and applicable to other applications. For a given baseline model, we combine all models whose latency is lower than that of the baseline, and call it full- ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 138,
    "augmented": true
  },
  {
    "text": "This equation infers that the Proba- bility Vector at the next time step is obtained by performing a transition operation across all possible current states. Repeatedly carrying out this transition process, starting from the initial Probability Vector, enables the estimation of probabilities of each function along all possible workflows. Iterating this process for  𝑑 time steps would yield the proba- bilities of functions at a depth of  𝑑 from the start function, given by  𝑃 𝑑 =  𝑇 𝑑 ·  𝑃 0 .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "3b. In this scenario, the area of the MV  S mv  is similar to or even larger than the area of the smallest bounding box  S sbb  from the previous frame (in this case,  S mv  = 1 . 3  ×  S sbb ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "keeps up with the accuracy of the traditional compression system thanks to the robust layered coding algorithm. Additionally, as shown in Fig. 5b,  Salient Store  has  4 .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "Furthermore, constructing core- sets do not need any application information, i.e. they are application/data agnostic and can represent any form of data (IMU [ 36 ], Image [ 55 ], DNN feature map [ 17 ,  38 ,  46 ,  52 ]). This fulfils requirement  4  .",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "[58]  Soo-Jin Moon, Jeffrey Helt, Yifei Yuan, Yves Bieri, Sujata Banerjee, Vyas Sekar, Wenfei Wu, Mihalis Yannakakis, and Ying Zhang. Origin: Enabling on-device intelligence for human activity recognition using energy harvesting wireless sensor networks. In  2021 Design, Automation Test in Europe Conference Exhibition (DATE) , pages 1414–1419, 2021.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 118,
    "augmented": true
  },
  {
    "text": "Graham Gobieski, Brandon Lucia, and Nathan Beckmann. Intelligence beyond the edge: Inference on intermittent embedded systems. In  Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems , pp.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 56,
    "augmented": false
  },
  {
    "text": "[25] Tianqi Chen, Benjamin Moreau, Chunting Zheng, Yutian Tang, Zijian Yan, Yanan Song, Yuhao Jia, Maximilian Seeger, Lingfeng Wang, and Hai Bian. ACM SIGPLAN Notices , 42(7):155–157, 2007. Compiler-directed application mapping for noc based chip multiprocessors.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "[79] Jihye Kim, Sungho Lee, and Minseok Park. Optimizing resource allocation in gpu clusters for deep learning training. (Accessed on 09/12/2023).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Apart from that, the generated \n1079 \nAuthorized licensed use limited to: Penn State University. In this case, the current frame is processed on the CPU to report the ﬁnal result.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "The bearing fault data is sampled at a much higher frequency (48KHz) than the HAR data, and hence require a larger DNN, larger num- ber of importance sampling, and more number of clusters. A.2 More Results on Bearing Fault Data We repeated our experiments with similar experimental setup on the bearing fault data set [ 53 ]. We took the learning from multiple domain specific litera- tures [ 19 ,  29 ,  53 ] to isolate the frequency regions specific to the fault pattern to minimize the computations.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 119,
    "augmented": true
  },
  {
    "text": "1 ×  larger) when exploiting the entropy en- coding. However, this entropy encoding consumes  ≈ 100 ms , which halves our performance gains. Thus, in order to harvest most of the speedup beneﬁts ( 42 ms  vs  1 .",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "2 and Sec. Now, the  football  needs the full depth planes’ information, while the soccer ball  can be approximated. To take advantage of this opportunity, the  football  object (which is inside the RoF in this example scenario) requires all of the 16 depth planes to compute its dense hologram, whereas the other objects (the  soccer ball in this case) can be approximated with a pre-defined sparse sam- pling factor (e.g.,   1 \n2 ; more details provided later in Algo.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 116,
    "augmented": true
  },
  {
    "text": "[59]  Stereolabs. 1–9. ACM Interna- tional Symposium on Eye Tracking Research and Applications (ETRA) .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 34,
    "augmented": true
  },
  {
    "text": "References \n[1]  Omid Alipourfard, Hongqiang Harry Liu, Jianshu Chen, Shivaram Venkataraman, Minlan Yu, and Ming Zhang. 2017. CherryPick: Adap- tively Unearthing the Best Cloud Configurations for Big Data Analytics.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Perform the forward pass with the updated dropout mask to obtain the output Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the sensitivity of the weights, along with the QuantaTask optimization to handle energy constraints. D.3 Feature Map Reconstruction Error Dropout with QuantaTask Optimization \nFeature Map Reconstruction Error Dropout leverages the reconstruction error of feature maps to adjust dropout rates, combined with the QuantaTask optimization to handle energy constraints in intermittent systems.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 128,
    "augmented": false
  },
  {
    "text": "23–25, 2015. [13]  CWI-DIS Group, “cwipc-CWI Point Clouds software suite,” \n”https://github.com/cwi-dis/cwipc” , 2021. [14]  R. L. de Queiroz and P. A. Chou, “Compression of 3d point clouds using a region-adaptive hierarchical transform,”  IEEE Transactions on Image Processing , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 108,
    "augmented": false
  },
  {
    "text": "This is partly because we need a very high compres- sion ratio with very low power. Secondly, these compression algorithms are not context-aware, and hence lose relevant \n4 \nfeatures during the process of compression resulting in de- graded inference accuracy (refer Table 1 for details). Challenges with Data Compression: Using standard compression algorithms, like discrete cosine transform, dis- crete wavelet transform, and Fourier decomposition etc., to minimize the communication overhead is not a viable solu- tion [ 45 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 123,
    "augmented": true
  },
  {
    "text": "Proteus: Agile ML Elasticity Through Tiered Reliability in Dynamic Resource Markets. In  Eurosys , 2017. [43]  Johann Hauswald, Michael A. Laurenzano, Yunqi Zhang, Cheng Li, Austin Rovinski, Arjun Khurana, Ronald G. Dreslinski, Trevor Mudge, Vinicius Petrucci, Lingjia Tang, and Jason Mars.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "2012. Introducing a New Benchmarked Dataset for Activity Monitoring. [58]  Attila Reiss and Didier Stricker.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "181–192. Patterns for Serverless Functions (Function-as- a-Service): A Multivocal Literature Review.. In  CLOSER .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "[29]  Magic Leap. 145–152. In  2008 IEEE Virtual Reality Conference .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 22,
    "augmented": true
  },
  {
    "text": "•  We evaluate our integrated design, including both  EA  and AE , using an open-source 360° VR video dataset [3] with the traces of 20 users watching 5 different VR videos. Over- all, our experimental results show that, on an average,  D´ej`a View  can provide  54%  compute reduction, which translates to  28%  total energy savings compared to the baseline setup. Compared to a state-of-the-art scheme [28], our design provides  34%  reduction in projection computations, which translates to  17%  additional energy savings.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "Table 6 shows the median and tail latencies of each policy averaged across all appli- cations for the three traces. Container overprovisioning is inflated 15% more than the corresponding real system re- sult, due to the large-scale traces. The trend we observe is that traces with higher variability, such as the Twitter trace, af- fect the tail latencies of policies more harshly than the other, more predictable, traces.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "Holographic 3-D Displays - Electro-holography Within the Grasp of Commercialization . IntechOpen. shorturl.at/jmnpD [53]  Antoni Rosinol, Marcus Abate, Yun Chang, and Luca Carlone.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 63,
    "augmented": false
  },
  {
    "text": "[190] Shulin Zhao, Prasanna Venkatesh Rengasamy, Haibo Zhang, Sandeepa Bhuyan, Nachiappan Chi- dambaram Nachiappan, Anand Sivasubramaniam, Mahmut Taylan Kandemir, and Chita Das. Un- derstanding energy efficiency in iot app executions. In  2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS) , pages 742–755, 2019.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 113,
    "augmented": false
  },
  {
    "text": "10 30 60 120 Sampling-Interval \n0 \n2 \n4 \n6 \n#Models \n79.0 \n79.2 \n79.4 \nAccuracy \n(c)  Queries under Constraint-3. Figure 13:  Sensitivity analysis of model selection with respect to sampling interval. The average number of models is in primary axis and cumulative accuracy in secondary axis.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "If so, can we leverage Morton code (containing location information) to capture such similarities as well? This observation motivates us to ask the question:  Do such similarities also exist in the PC streams? Spatial Locality in Attributes:  Towards exploring the attribute similarity within one frame, we partition a frame (whose points are ﬁrst sorted in Morton-code order) from the 8iVFB dataset [ 18 ] into  10 ,  10 2 ,  10 4   and  10 5   macro blocks , plot the CDF of the range for attribute delta ( Max red  − Min red ) within one segment/macro block in Fig.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 141,
    "augmented": true
  },
  {
    "text": "Chih-Kai Kang, Hashan Roshantha Mendis, Chun-Han Lin, Ming-Syan Chen, and Pi-Cheng Hsiu. Everything leaves footprints: Hardware accelerated intermittent deep inference. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , 39(11):3479–3491, 2020.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 90,
    "augmented": false
  },
  {
    "text": "5687–5695, 2017. In  Proceedings of the IEEE conference on computer vision and pattern recognition , pp. Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, and Hartwig Adam.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "2009. Wikipedia workload analysis for decentralized hosting. Computer Networks  (2009).",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 16,
    "augmented": false
  },
  {
    "text": "Prior literature [ 5 ,  10 ] tries to hide the model load latency by pre-warming serverless function in- stances through periodically issuing dummy requests. How- ever, such hacks can fail if the cloud service provider decides to change the idle timeout of function instances or change the overall mechanism to recycle idle function instances. Rather than capitalizing on such design hacks, we need to develop prediction policies to estimate load correctly.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "(c): View- ing the S-CGH from different focal distances. 41.48 31.79 30.74 \n0 10 20 30 40 50 60 \nbike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg. bike \nbook \nbottle \ncup \nlaptop \nshoe \nAvg.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 57,
    "augmented": false
  },
  {
    "text": "Such similar performance demonstrates that our proposal is expected to work well for low-power edge devices like smartphones as well. D. Architectural Insights: \nIn this section, we further investigate the energy efﬁciency characteristics of the proposed optimizations by dissecting the total energy consumption for the inter-frame attribute compression proposal (which is the most time- and energy- \n294 \nAuthorized licensed use limited to: Penn State University. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 111,
    "augmented": false
  },
  {
    "text": "Prior Work \nPrior work for enabling inferences on edge devices have focused on hardware as well as software optimizations, which can be further classiﬁed into model compression and pruning, and compiler and runtime support. Al- though DNN inference is highly structured and embarrassingly parallel, the limited resources on the mobile devices, alongside \nthe required off-chip data movements, poses a signiﬁcant challenge leading to higher latency. 1) Hardware Optimizations:  Traditionally, CPUs and GPUs have been recruited for DNN inference on mobile phones.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 111,
    "augmented": true
  },
  {
    "text": ". REPLICA TRACKER \nLOAD MONITOR \nOVERLOAD DETECTOR \nFUNCTION \nIDLER \nPROACTIVE WEIGHTED SCALER \nREACTIVE SCALER \nWEIGHT ESTIMATOR \nLOAD PREDICTOR \nDev-Provided  DAG Descriptor \nScrape Metrics \nAPPLICATIONS \nDECISION \nSCALE \n2a \n2 \n7 \n7a 7b \n1 \n3 \n2b \n4 \n5 \n3a \n3b \n6 \nPROBABILITY CONNECTIVITY COMMONALITY \nKRAKEN \nFigure 6: High-level View of Kraken Architecture incoming load and uses this in conjunction with the calcu- lated function weights to determine the number of function containers to be spawned by the underlying resource orches- trator  6  . However, only a fraction of these containers are actually spawned, as determined by the function’s batch size.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 200,
    "augmented": false
  },
  {
    "text": "Post-quantum cryptography. Accessed: 2024-08-01. National Institute of Standards and Technology (NIST).",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 27,
    "augmented": true
  },
  {
    "text": "Both  Social Network  and  Me- dia Service  have a high number of workflows, but the former has more functions with higher slack, leading to increased batching, thereby resulting in the most reduction in con- tainers spawned. On the other hand,  DProb  and  SProb  spawn fewer containers than  Kraken  as a consequence of not using  Commonality  and Connectivity  to augment function weights, while making container allocation decisions. Hotel Reservation  has the least number of workflows as well as the lowest overall slack for all functions, resulting in the least reduction in the number of containers.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "REPLICA TRACKER \nLOAD MONITOR \nOVERLOAD DETECTOR \nFUNCTION \nIDLER \nPROACTIVE WEIGHTED SCALER \nREACTIVE SCALER \nWEIGHT ESTIMATOR \nLOAD PREDICTOR \nDev-Provided  DAG Descriptor \nScrape Metrics \nAPPLICATIONS \nDECISION \nSCALE \n2a \n2 \n7 \n7a 7b \n1 \n3 \n2b \n4 \n5 \n3a \n3b \n6 \nPROBABILITY CONNECTIVITY COMMONALITY \nKRAKEN \nFigure 6: High-level View of Kraken Architecture incoming load and uses this in conjunction with the calcu- lated function weights to determine the number of function containers to be spawned by the underlying resource orches- trator  6  . However, only a fraction of these containers are actually spawned, as determined by the function’s batch size. .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 200,
    "augmented": true
  },
  {
    "text": "[195] Zeyang Zhong, Urvashi Khandelwal, Omer Levy, and Dan Jurafsky. Beyond common sense: The story of hellaswag. In  Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 4599–4604.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "However, due to this reduced accuracy, the sensor only takes this option iff it does not have enough energy to perform the inference at the edge device (either in the 16bit or 12bit variant of the DNN - more details on DNN design is presented in Sec- tion 4). This raises a question:  is it possible to generate a more useful  approximation, via reconstruction, of the data that we lost while forming the coresets? This problem has not been explored in details, as coresets are typically considered as an  𝛼 − approximate representation of the data ( 𝛼 being the error/approximation parameter) [ 7 ] and never needed proper recovery.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 152,
    "augmented": false
  },
  {
    "text": "Additionally, it helps compare the resource footprint of  Kraken  against a clairvoyant policy (Oracle) that has 100% load prediction accuracy. 6 Analysis of Results This section presents experimental results for single ap- plications run in isolation for all schemes on the real system and simulation platform. We have also verified that  Kraken (as well as the other schemes) yield similar results (within 2%) when multiple applications are run concurrently.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "2278–2324, Nov 1998. [44]  H. Lin, M. Hsu, and W. Chen, “Human hand gesture recognition using a convolution neural network,” in  2014 IEEE International Conference on Automation Science and Engineering (CASE) , pp. 1038–1043, 2014.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Data streaming and partial compute storage are facilitated by four double buffered SRAM structures, with the \nweights residing in a double buffered multi-banked SRAM. The ﬁlter SRAM has 256 banks (one per tile), each with a size of 1kB (double buffered, 512B per buffer per bank). Input data broadcast to all tiles is managed by a 64kB double- buffered input feature map SRAM (32kB each), requiring ⌈ [ X  × Y  × Z ] / 1024 ⌉ iterations for full input loading, with each buffer loaded  [ X  × Y  ×  Z ] / 2048 times.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 160,
    "augmented": false
  },
  {
    "text": "Reuse:  for blocks for which the reference blocks are similar enough (e.g., the 2-norm differences are less than the pre- deﬁned thresholds), only the pointers to their reference blocks will be recorded (in our proposal, for each P-block, we set the number of candidate blocks as 100, thus, 6 bits are sufﬁcient for encoding one P-block). On the other hand, if the “best matched I-block” is not as similar as the P-block (e.g., the 2-norm differences are larger than the threshold), simply approximating the P-block with its reference block will signiﬁcantly degrade the quality; instead, we compute and store the deltas for such block pairs, and then invoke the  Base+Deltas  technique, as mentioned in Sec. IV-A 2  for intra-frame compression, to further compress these deltas.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 195,
    "augmented": false
  },
  {
    "text": "[27]  Nilanjan Daw, Umesh Bellur, and Purushottam Kulkarni. IEEE, \n1–10. In  2019 IEEE/ACM Fourth International Parallel Data Systems Workshop (PDSW) .",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 51,
    "augmented": true
  },
  {
    "text": "We have developed a prototype of  Kraken  using  OpenFaaS , an open source serverless framework [ 11 ], and extensively evaluated it using real-world datacenter traces on a 160 core Kubernetes  cluster. Our results show that  Kraken  spawns up to 76% fewer containers on average, thereby improving container utilization and cluster-wide energy savings by up to 4 ×  and 48%, respectively, when compared to state-of-the art serverless schedulers. Furthermore,  Kraken  guarantees SLO requirements for up to 99.97% of requests.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 128,
    "augmented": true
  },
  {
    "text": "This entails that only models trained or adapted to low-precision implementations can be used with ResiRCA. Similarly, total model size, including any granularity overheads (e.g., from the partitioning used to store both positive and negative weights by having the kernels of one layer mapped to two crossbars, one each for positive and negative weights, which share the same input port) must ﬁt within the allocated RCAs of a particular ResiRCA design. Fine-grained reconﬁguration:  The ResiRCA architecture supports not only partial activation for one ReRAM or multiple ReRAMs, but also sequential and pipelining execution modes.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 148,
    "augmented": false
  },
  {
    "text": "We explain in detail the resource procurement and autoscaling policy employed in  Cocktail . 4.2.1 Resource Controller \nResource controller determines the cost-effective combina- tion of instances to be procured. We explain the details below.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 50,
    "augmented": false
  },
  {
    "text": "Green Algorithms 4 HPC, August 2024. [12] Amazon. Alexa. \"",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 24,
    "augmented": false
  },
  {
    "text": "E.1.1 Simple Single Cell Example: \nconsider a simple example of a ReRAM crossbar array with two cells, where V1 and V2 are the input voltages, G1 and G2 are the conductance values of the ReRAM devices, and I1 and I2 are the resulting output currents. To perform multiplication-addition, we first apply the input voltages V1 and V2 to the rows of the crossbar array. Moreover, these devices can also be used for performing convolution operations, which are widely used in image and signal processing applications.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "The specific responsibilities of the PIs and their complementary expertise are explained below: Chitaranjan Das (PI):  Das is the PI of the project and will be responsible for the overall coordination and progress as planned in the project schedule. His expertise includes multicore architectures, architectural op- timization of ML kernels, on-chip and chip-to-chip interconnect design, cloud computing, and performance evaluation. He will lead Thrust-3 and also co-lead Thrust-4 with Co-PIs Zhang and Kandemir.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "Spotcheck: Designing a derivative iaas cloud on the spot market. In  Proceedings of the Tenth European Conference on Computer Systems , pages 1–15, 2015. [70]  Steven A Shaya, Neal Matheson, John Anthony Singarayar, Nikiforos Kollias, and Jeffrey Adam Bloom.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Inadequately provisioning containers for such functions causes requests to queue up as containers are spawned in the background. The Primary Y-axis denotes the Av- erage End-to-End Response Time, the Secondary Y-axis represents the percentage of SLOs satisfied and the X-axis indicates the Appli- cation under consideration. term  Connectivity  to denote the ratio of number of descen- dant functions to the total number of functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 114,
    "augmented": true
  },
  {
    "text": "[17]  Rich Caruana, Alexandru Niculescu-Mizil, Geoff Crew, and Alex Ksikes. Manning Publications Co., 2013. Redis in action .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "ResiRCA supports smooth transi- tions among different activation solutions against computation loss. This paper proposes ResiRCA, a resilient energy harvesting accelerator. We propose a lightweight and ﬂexibly tuning RCA architecture and a ResiSchedule scheme to dynamically activate various scaled MAC operations so as to fully translate the “harvested energy” into “computation progress”.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "9. Throughput of CNNs across the power sources normalized to ResiSchedule \nPiezo WiFi-home WiFi-office Thermal TV-RF \nFig. 8.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 37,
    "augmented": true
  },
  {
    "text": "0 0.2 0.4 0.6 0.8 \n1 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nMN-1 \nMN-2 \nMN-3 \nMN-4 \nMn-5 \nA6000 w/DVFS RTX3090 w/DVFS Non-intermittent Custom HW w/Ekya \nOur Custom HW \nCompleted/Scheduled \nC/S Win-1 C/S Win-2 C/S Win-3 C/S Win-4 C/S Win-5 C/S mean \nFig. 4: Impact of DVFS on completion (average power budget 70W). Note that, even with DVFS, most scheduled compute could not be ﬁnished.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 179,
    "augmented": false
  },
  {
    "text": "The codec’s autoencoder component, which is trainable, is then tasked with compressing these enriched features. This setup not only streamlines the encoding process by utilizing high-quality \n10 \nfeatures but also significantly enhances compression efficiency by exploiting both intra-frame richness and inter-frame continuity. The training process is designed to optimize the autoencoder’s ability to compress and decompress video sequences efficiently, without altering the pretrained feature extractor, thereby providing a stable, high-performance baseline for feature representation.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 122,
    "augmented": true
  },
  {
    "text": "5.3 Evaluation of Lattice Based Encryption \nOne of the major contribution of  Salient Store  is accelerating the lattice-based encryption with the help of FPGAs on the storage nodes. Fig. 7 shows the comparison of our FPGA-accelerated lattice-based encryption against other state-of-the-art-techniques.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "We plan to address these questions using 6 different tasks. . To enhance the performance of EoE , we propose system optimizations that exploit the spatio-temporal locality/affinity of its components – data, experts, routers, composition functions, and hardware.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "Trace Arch Fifer Kraken Xanadu Comm Only Conn Only Wiki (99.91%, 2737) (99.90%, 2092) (99.86%, 1396) (99.66%, 1737) (99.78%, ) (99.75%, ) Twitter (99.72%, 45,107) (99.63%, 34,210) (99.50%, 22,377) (99.10%, 25,132) (99.22%, ) (99.15%, ) Table 7: Simulator: Comparing (% SLO met,# Containers Spawned) against Existing Policies after Varying the Target SLOs. Figure 16: Simulator: Comparison of End-to-End (E2E) Response Times and Containers Spawned Over Time (60 minutes) of  Kraken and  Oracle . existing policies such as  Arch  and  Fifer  exhibit similar perfor- mance and resource usage when their prediction models and keep-alive times are similarly adjusted.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 239,
    "augmented": true
  },
  {
    "text": "2019. Step Functions. In The Definitive Guide to AWS Application Integration .",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 19,
    "augmented": false
  },
  {
    "text": "0 \n20 \n40 \n60 \n80 \nV1 V2 V3 V4 V5 Avg. PSNR (dB) \n-10 \n-5 \n0 \n5 \n10 \n1 224 447 670 893 1116 1339 1562 1785 2008 2231 2454 2677 2900 3123 3346 3569 3792 \nDistance \nPixel ID \nDelta-y Delta-x \n(a): PSNR (b): Pattern in CubeMap format \nFig. 10: Sensitivity study.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 105,
    "augmented": false
  },
  {
    "text": "PSNR (dB) \nSize(MB) \nVideo \nSize(Geometry) Size(Attribute) PSNR (dB) \n40dB \n(c) Compressed size & PSNR \nFigure 8: Results: (a) Latency breakdown. (b) Energy consumption. Energy (J) [Our scheme] \nEnergy (J) [SOTA] \nVideo \nSOTA Energy \nOur Energy \nSOTAs \n(b) Energy consumption \n0 \n15 \n30 \n45 \n60 \n0.00 5.00 10.00 15.00 20.00 \nRaw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 Raw TMC13 CWIPC Intra-Only Intra-Inter-V1 Intra-Inter-V2 \nRedandblack Longdress Loot Soldier Andrew10 Phil10 Avg.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 309,
    "augmented": true
  },
  {
    "text": "Holistic Approach:  Unlike other methods that focus on either training or inference optimizations, NExUME provides a comprehensive solution that addresses both phases, leading to superior overall performance. 4.3 NExUME on Machine Status Monitoring  [Our New Dataset] \nAutomation and monitoring and analytics are the key ingredients in the upcoming Industry 4.0. To enable sustainable machine status monitoring with energy harvesting (from machine vibrations or Wifi signals) we evaluate our setup using Bridgeport machines for monitoring their status.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 107,
    "augmented": false
  },
  {
    "text": "Considering the global control always enqueues any idle tile with work, whenever the tile has no work left, it steals a kernel from the most \n899 \nAuthorized licensed use limited to: Penn State University. Downloaded on April 02,2025 at 23:57:52 UTC from IEEE Xplore. Restrictions apply.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "Second, for applications, which are motion-sensitive \nsuch as the spaceship simulation [ 34 ], the hologram computation process is required to complete faster, in order to correctly reflect the current user’s eye movement and head pose in real-time. In this case, offloading computations to a resource-rich cluster/cloud system would be a more reasonable design choice (instead of approximating on the edge). The proposed  HoloAR  on the edge GPU cannot achieve such strict la- tency requirement, and can cause lagging, e.g., the eye could move to another area, while the hologram is still being computed for the previous focus region.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "One example is the Science-U camp at Penn State, which is designed to take K-12 students through a one-week journey that investigates an area of STEM in an exciting way. We will also outreach to researchers in other disciplines by giving project-related talks at different departments at Penn State (e.g., math and statistics). The PIs are involved in several K-12 activities such as the summer CS program for girls (funded by CSE and led by Das).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 101,
    "augmented": false
  },
  {
    "text": "Memory-efficient nllb-200: Language-specific expert pruning of a massively multilingual machine translation model. arXiv preprint arXiv:2212.09811 , 2022. [84] Dominik Kreuzberger, Niklas Kühl, and Sebastian Hirschl.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "[106] R. Zhang, H. Tao, L. Wu, and Y. Guan, “Transfer learning with neural \networks for bearing fault diagnosis in changing working conditions,” Ieee Access , vol. 14 347–14 357, 2017. 5, pp.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "The provisioning latency, instance permanence and packing factor of these resources have a direct impact on the latency and cost of hosting model-serving. We explain instance “pack- ing factor” and its relationship with latency in Section  2.3.2 . In this paper, we focus on improving the accuracy and latency from the model selection perspective and consider instances types from a cost perspective.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "As shown in Figure 5, one way of utilizing this hot/cold expert separa- tion is to store their respective model parameters at different levels in the memory hierarchy, dictated by the degree of hotness, so as to optimize the response generation pipeline. Specifically, the various experts are typically stored on SSDs or HDDs, and are on-demand loaded into the main memory as required by incoming queries. This dynamic allocation allows for a flexible working set of experts hosted in the main memory, tailored to the specific needs of the batch of requests currently being processed.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "However, regulations, resource limitations and privacy concerns often mandate these applications (both learning and inference) to be performed at the edge (Bhardwaj et al., 2022; Mishra et al., 2024). For example, many of the European cities restrict the traffic video data to be streamed to the cloud (www.dlapiperdataprotection.com; Achieving Compliant Data Residency and Security with Azure; Bhardwaj et al., 2022), which enforces performing video \nPreprint. Under review.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 129,
    "augmented": false
  },
  {
    "text": "[52]  Yunseong Lee, Alberto Scolari, Byung-Gon Chun, Marco Domenico Santambrogio, Markus Weimer, and Matteo Interlandi. PRETZEL: Opening the black box of machine learning prediction serving systems. In  13th USENIX Symposium on Operating Systems Design and Imple- mentation (OSDI 18) , pages 611–626, Carlsbad, CA, October 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "2.4.1–2.4.4, 2017. [39]  H. Lv, X. Xu, P. Yuan, D. Dong, T. Gong, J. Liu, Z. Yu, P. Huang, K. Zhang, C. Huo, C. Chen, Y. Xie, Q. Luo, S. Long, Q. Liu, J. Kang, D. Yang, S. Yin, S. Chiu, and M. Liu, “BEOL based RRAM with one extra-mask for low cost, highly reliable embedded application in 28 nm node and beyond,” in  2017 IEEE International Electron Devices Meeting (IEDM) , pp. [38]  Synopsis, “HSPICE.” https://www.synopsys.com/veriﬁcation/ams- veriﬁcation/hspice.html/.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 202,
    "augmented": true
  },
  {
    "text": "0 \n5 \n10 \n0 \n1 \n2 \nBerkley WITS Twitter Wiki \nSLO Violations \nNormalized Cost \nreactive util_aware exascale mixed \nFigure 5. Cost of using  mixed  compared to  util_aware  and  exascale , normalized to a baseline  reactive  scheme for four traces. WoSC’20, December 7ś11, 2020, Delft, Netherlands J.R. Gunasekaran, et al.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Note that, these additional containers are necessary to reduce SLO violations. 6.1.2 End-to-End Response Times and SLO Compli- ance : Figure 9 shows the breakdown of the average end-to- end response times and Figure 10 juxtaposes the total number of containers provisioned against the SLO Guarantees for all policies and applications, averaged across all traces. From these graphs, it is evident that  Kraken  exhibits comparable performance to existing policies while having a minimal re- source footprint.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "(b) Viewing W-CGH from different focal distances. Focal distance from left to right:  0.3m ,  0.4m ,  0.5m , and  0.6m . (c) Viewing S-CGH from different focal distances.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "Incorrect exemplar selection might lead to non-IID training data distri- bution, leading to catastrophic forgetting or over-ﬁtting. are then further reﬁned and classiﬁed by the teacher models. To improve the conﬁdence of the teacher models, we employ an ensemble learning based weighted majority voting policy [ 28 ].",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 70,
    "augmented": false
  },
  {
    "text": "For every monitoring interval, we keep track of the accuracy obtained from predicting all input images within the interval. If the accuracy of the interval reaches the threshold accuracy (target + error_margin), we scale down the num- ber of available models in the ensemble. For consecutive sampling intervals, we calculate the  Mode  (most frequently occurring) of the majority vote received for every input.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "•  In  EA , as discussed in Sec. 4. III, the transformation matrix ( T  ) is determined by the head orientation, which is sampled from the built-in IMU sensors.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "6) Tradeoffs between Accuracy and Energy Consumption: So far in our evaluation, we wanted to minimize the accuracy impact (see Table III). However, as an alternate design princi- ple, one may want to relax this accuracy constraint and thus save more energy. We used Pytorch [46] to proﬁle the accuracy behavior of two videos picked from VIRAT [33] dataset, and show that our proposal can adaptively support such alternate design choices.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 102,
    "augmented": true
  },
  {
    "text": "(Giga MACs/s) /Power utilization \n1 50 0/Power failure/0/0% 0/Power failure/0/0% 2 100 0/Power failure/0/0% 80/25 × 1 × 1/0.312/80% 3 500 480/25 × 6 × 1/1.872/96% 480/25 × 6 × 1/1.872/96% 4 200 0/Power failure/0/0% 160/25 × 2 × 1/0.624/80% 5 250 0/Power failure/0/0% 240/25 × 3 × 1/0.936/96% 6 750 480/25 × 6 × 1/1.872/64% 720/25 × 3 × 3/2.808/96% 7 650 480/25 × 6 × 1/1.872/74% 640/25 × 2 × 4/2.496/98% 8 350 0/Power failure/0/0% 320/25 × 2 × 2/1.248/91% \n100 \n0.4 \n1.2 \n1.6 \n2.0 \n2.4 \n2.8 \nPower ( ­ W) \nThroughput (Giga MACs/s) \nPower consumption with full-size activation \nPower consumption with tile-size activation \nThroughput with full-size activation Throughput with tile-size activation \nPower trace \nAverage harvested power Average power consumption with full-size activation Average power consumption with tile-size activation \nAverage throughput with full-size activation \nAverage throughput with tile-size activation \n356.3 \n180 \n330 \n1.3 \n200 \n300 \n400 \n500 \n600 \n700 \n800 \n0.8 0.7 \nPC1 \nPC2 \nPC3 \nPC4 \nPC5 \nPC6 \nPC7 \nPC8 \n0 \n0 0 0 80 480 480 0 160 0 240 480 \n480 640 0 320 \n0 0 0 0.312 1.872 1.872 0 0.624 0 0.936 1.872 2.808 1.872 2.496 0 1.248 \nFig. 1. Comparisons on power consumption and throughput with tile-size over full-size activation \nFrom the perspective of an intelligent embedded system, the dominant power consuming part, the RCA, exhibits a highly parallel and uniform execution property.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 501,
    "augmented": false
  },
  {
    "text": "[4]  Amazon. Deepar estimator. https://docs.aws.amazon.com/ sagemaker/latest/dg/deepar.html,February2020 .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 46,
    "augmented": false
  },
  {
    "text": "Figure  16b  plots the latency reduction and accuracy gain, compared to  InFaaS  (baseline). While being able to reduce 50% of the models used in the ensemble,  Cocktail  also re- duces latency by up to 50% and improves accuracy by up to 1.3%. Both  Cocktail  and  Clipper  deliver the same overall accuracy (96%, 94.5%, 93.5%, and 92%)).",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 92,
    "augmented": false
  },
  {
    "text": "Thus, while the MoE/CoE design paradigm is promising, the overall solution space is little explored, especially for complex compositions of smaller experts. Therefore, it is imperative to investigate the modular LLM design space in depth not only to mitigate the above issues, but also to facilitate democratization by allowing anyone to use and contribute in a “plug-and-play” fashion. These observations call for a holistic hardware-software “co-design” that integrates efficient expert models with custom system support and reconfigurable hardware architectures, to optimize performance, while minimizing resource consumption.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  },
  {
    "text": "[53] Wikipedia, “Pixel 2,” ”https://en.wikipedia.org/wiki/Pixel 2”. [54] Wikipedia, “Active-Matrix Organic Light-Emitting Diode,” ”https://en. wikipedia.org/wiki/AMOLED”, 2019.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "Thus, improving the computational efﬁciency of the video processing pipeline in a VR is critical. While prior efforts have attempted to address this problem through acceleration using a GPU or FPGA, none of them has analyzed the  360 °  VR pipeline to examine if there is any scope to optimize the computation with known techniques such as memoization. Thus, in this paper, we analyze the VR computation pipeline and observe that there is signiﬁcant scope to skip computations by leveraging the temporal and spatial locality in head orienta- tion and eye correlations, respectively, resulting in computation reduction and energy efﬁciency.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "This allows us to perform flexible and efficient “neighborhood training” by localizing  the training parameters and  freezing  the rest of the parameters as much as possible to save cost. By contrast, our proposed EoE paradigm is inherently modular , requiring updates of only a small subset of experts to accom- modate new usage scenarios. How- ever, traditional monolithic LLMs are not well-suited for frequent updates, because training monolithic LLMs often involves wholesale replacement which is prohibitively expensive and challenging.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 115,
    "augmented": true
  },
  {
    "text": "M OTIVATION \nTo avoid negatively impacting the underlying system’s QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available. II. In addition, we discuss how to keep the partial results in appropriate computation points with or without power prediction.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "One can observe from this figure that, when the number of depth planes is increased, the power consumptions of  SoC  and  CPU  do not change much, while, in contrast, both the GPU  and  Mem  consume more power. This is due to the fact that, to process a denser hologram with more depth planes, additional GPU cores are scheduled to launch the per-plane CUDA kernel (as discussed in Algo. 1) with more holographic data accesses (fetched from the host-side memory).",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "6 \n•  Intra-Only : We apply our intra-frame compression method discussed in Sec. IV  to each of the PC frames. Speciﬁcally, we choose to segment each PC frame into 30000 blocks 7 , and use a 2-layer encoder (more speciﬁcally, we ﬁrst encode the attributes via the proposed intra-frame encoder \n6 Based on our proﬁling, the provided attribute compression APIs (e.g., JPEG- Turbo-based) would degrade the quality of PC signiﬁcantly; thus, we do not use such APIs/Libs in our evaluations.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 125,
    "augmented": false
  },
  {
    "text": "Motivated by this, we designed a GANs to regenerate the lost data points while performing importance sampling. A similar problem, in terms of generating faces, paintings etc. given some latent space has already been solved using GANs [ 54 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "AMD and Xilinx have intro- duced specialized tools and libraries designed to harness CSDs (AMD, a; AMD & Xilinx), enabling peer-to-peer PCIe transactions that bypass the CPU (AMD & Xilinx). Recent advances in both commercial (Newsroom; AMD, b; Mesnier, 2022; ScaleFlux, a,b; Eideticom & Laboratory; Laboratory) and academic sectors (Torabzadehkashi et al., 2019b; Barbalace & Do, 2021; Lukken & Trivedi, 2021; Torabzadehkashi et al., 2019a; Sala- mat et al., 2021, 2022; Do et al., 2013) advocate the use of computational storage drives (CSDs) across databases, high-performance computing (HPC), and analytics. Storage controllers, typically constrained by I/O bandwidth, are now being complemented by the vast internal bandwidth of solid-state drives (SSDs), making them prime candi- dates for near-data processing.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 264,
    "augmented": true
  },
  {
    "text": "With the FI+SI+PI scheme on the other hand, the mAP drops  1 . 4%  in YOLOv3, and  0 . 4%  for YOLOv4-tiny.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Figure 3: Dataset study. (a) Depthmap hologram algorithm. 0 200 400 600 800 1000 1200 \n1 2 4 8 16 32 64 \nExec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "If the student (or the edge model) is conﬁdent about the classiﬁcation (e.g. For each sampled frame, the classiﬁcation results and the conﬁdence matrix (output of the last layer) are sent for annotation. As they are less prone to drift, they need occasional updates.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 60,
    "augmented": true
  },
  {
    "text": "How does the new tile get any kernel to work on? 2. Over multiple iterations of such asynchronous scheduling, the kernel queue for each tile will be of different size creating a load imbalance; how to tackle this?",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "[134] Samyam Rajbhandari, Conglong Li, Zhewei Yao, Minjia Zhang, Reza Yazdani Aminabadi, Am- mar Ahmad Awan, Jeff Rasley, and Yuxiong He. Deepspeed-moe: Advancing mixture-of-experts inference and training to power next-generation ai scale. Quantifying generalization complexity for large language models, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Hashan Roshantha Mendis, Chih-Kai Kang, and Pi-cheng Hsiu. Intermittent-aware neural architecture search. ACM Transactions on Embedded Computing Systems (TECS) , 20(5s):1–27, 2021.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 70,
    "augmented": true
  },
  {
    "text": "6 \nThe meta information of these VR videos are listed in Tab. II. C. Experimental Results \nWe present and compare the energy consumption of the pro- jection computation and the cor- responding video quality impact, when running the ﬁve VR videos described in Tab.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 53,
    "augmented": false
  },
  {
    "text": "These mismatches can lead to the following two “nonideal” working scenarios: (i) Unutilized energy:  As long as the harvested power is less than the activation power requirement of one ReRAM, it is regarded as a power failure because the RCA is inactive. In this case, the harvested energy will leak away and cannot be recovered. (ii) Underutilized energy:  When the harvested power is much higher than the activation power of the RCA, the RCA can only work in the default lower energy consuming level.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 121,
    "augmented": false
  },
  {
    "text": "MICRO ’21, October 18–22, 2021, Virtual Event, Greece © 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8557-2/21/10...$15.00 https://doi.org/10.1145/3466752.3480056 \nKEYWORDS \nAugmented Reality, Holographic Processing, Approximation, Energy-efficiency \nACM Reference Format: Shulin Zhao, Haibo Zhang, Cyan S. Mishra, Sandeepa Bhuyan, Ziyu Ying, Mahmut T. Kandemir, Anand Sivasubramaniam, and Chita R. Das. 2021.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 154,
    "augmented": true
  },
  {
    "text": "Here, the redundant experts should ideally be distributed across multiple nodes; ii) Isolated Training : In the event of changes to experts, our approach enables retraining by accounting for min- imum number of neighboring experts/routers; this will inherently facilitate fault tolerance, thereby allow- ing retraining of the EoE with minimum overhead in the event of expert failures; iii)  Checkpointing/Rollback Recovery : Techniques such as checkpointing weights/gradients periodically with rollback recovery in the event of expert failures can allow training to progress from the latest checkpoint (versus restarting the en- tire training); and finally, iv)  Dynamic Expert Re-routing:  In the event that an expert on one node fails, our system-level framework will communicate with the algorithm-level routers to dynamically decide which experts (on which node) should be used instead. Note that such system level fault-tolerant techniques will be augmented with hardware (chiplet)-level fault-tolerant techniques, described later in Task 3.4. 2.3 Thrust-3: A Chiplet-based Adaptive and Reconfigurable Hardware Platform Our proposed EoE-based LLM algorithm consists of a diverse set of building blocks with routers, experts, and composition functions, entailing heterogeneity in different stages of the application execution.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 305,
    "augmented": true
  },
  {
    "text": "SemEval-2017 task 4: Sentiment analysis in Twitter. In  Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) , pages 502–518, Vancouver, Canada, August 2017. [66]  Sara Rosenthal, Noura Farra, and Preslav Nakov.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 71,
    "augmented": true
  },
  {
    "text": "Energy Buffering and Power-Predictor:  To regulate, manage and ensure a stable power supply to the circuitry,  Us. ´as  uses a super-capacitor assisted voltage regulation circuit. To properly model the energy harvesting, losses during conversion, and leakage, we built a rectiﬁcation circuit with 4  ×  5 .",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "5. With the help of the pose estimation, now the AR hologram pipeline has the knowledge about the range/size of each object as well as its relative distance from the user. Therefore, the overhead introduced due to the additional pose estimation step is negligible compared to the baseline latency, thereby opening up opportunities for significant energy savings and performance speedup as demonstrated later in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "Tigris: Architecture and Algorithms for 3D Perception in Point Clouds. In  Proceedings of the International Symposium on Microarchitecture (MICRO) . 629–642.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 42,
    "augmented": false
  },
  {
    "text": "Percentage of SLO violations for each scheme are shown in the line graph (the corresponding color in the bar-graph is used for all the schemes.) 0 \n200 \n400 \n600 \n0 \n0.6 \n1.2 \n1.8 \n2.4 \n3 \nCost ($) \nModel Type \nexec_time(ms) \nMemory(GB) Cost($) \nFigure 7. Cost of using  mixed  compared to  util_aware  and  exascale , normalized to a baseline  reactive  scheme for four traces.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 105,
    "augmented": true
  },
  {
    "text": "To simplify our  AE  design, we simply reuse the pattern captured in the  1 st row, and do not consider the deeper information related to the row numbers. To study how this decision affects the video quality, we report \n250 \n0% 20% 40% 60% 80% 100% \n0% 20% 40% 60% 80% 100% \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nBaseline \nEA \nAE \nEA+AE \nPTU \nPTU+EA+AE \nRhinos Timelapse Rollercoaster Paris Elephants Avg. % Total Energy Saving \nCompute Energy  Consumption \nL \nR %TotalEnergySaving \nFig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 221,
    "augmented": false
  },
  {
    "text": "Restrictions apply. heavily loaded tiles. We implemented a counter (local kernel counter) to keep track of the size of the remaining local work queue of each of the tile.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "However, these node-level optimizations are not entirely sufﬁcient for sensor networks with multiple sensors collectively working together to achieve a goal, which are very common. To tackle this, recent works [9], [6] use a non-volatile processor (NVP) to ensure sufﬁcient forward progress in the face of frequent power emergencies. The combination of EH, NVPs and other architectural and compiler optimizations have enabled the use of sensors as smart inference engines.",
    "source": "Origin.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 101,
    "augmented": true
  },
  {
    "text": "Second, for different head orientations, their distance vectors plotted in Fig. The intuitive reason behind this  ellipse  pattern is related to the built-in features of the equirectangular format. On plotting the distance vectors for each row of the FoV frames, we observe a recurring  ellipse  pattern.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 77,
    "augmented": true
  },
  {
    "text": "https://aws.amazon.com/ec2/pricing/. EC2 pricing. [6]  Amazon.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 31,
    "augmented": true
  },
  {
    "text": "Note however that, this comes at the cost of longer processing latency, as shown in Fig. 8a . •  CWIPC:  Overall, when employing the CWIPC, the output frame size reduces to around  14%  of the original input frame (including 63 %  of geometry and 37 %  of attribute data).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Google gemini. \" https://gemini.google.com/app \", 2024. [52] Google.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 28,
    "augmented": false
  },
  {
    "text": "Const1 Const2 Const3 Const4 \nBaseline \n0 \n10 \n20 \n30 \nLatency-reduction \n0.6 \n0.8 \n1.0 \n1.2 \nAccuracy-Gain \n(b)  Sentiment Analysis. Cocktail  was also able to deliver modest accuracy gain \n1052    19th USENIX Symposium on Networked Systems Design and Implementation USENIX Association \nConst1 Const2 Const3 Const4 \nBaseline \n0 \n20 \n40 \nLatency-reduction \n0.50 \n0.75 \n1.00 \nAccuracy-Gain \n(a)  Image Classiﬁcation:Cifar100. Figure 16:  Latency reduction (%) plotted as bar graph(primary y- axis) and accuracy gains (%) plotted as line graph (secondary y-axis) over InFaaS.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 178,
    "augmented": true
  },
  {
    "text": "Mixture of Experts (MoE) [145] and Composition of Experts (CoE) [131, 151] models have been proposed to distribute computational loads across mul- tiple specialized networks. The new CoE architectures, which use a combination of small mono- lithic or MoE models, introduce new opportunities by allowing experts to be trained indepen- dently and incrementally, thereby reducing computational resource requirements, while enhancing fault-tolerance, and enabling the use of custom accelerators. However, existing MoE and CoE models have significant limita- tions.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "With these sensors and compute resources in place, an AR head- set executes a set of software tasks, either entirely or selectively based on the applications’ requirements [ 19 ]. Without loss of gener- ality, a typical AR pipeline [ 19 ] is shown in Fig. 1c.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "In addition, we design a scheme named Paragon on top of AWS platform, which incorporates some of the proposed design choices. Our initial results show that Paragon can reduce cost of hosting ML prediction serving by up to 20% when compared to the state-of-the-art prior works, for diverse accuracy and latency constraints. 2 Characterization and Motivation \n2.1 Variability across model types \nDepending on the accuracy and latency requirements of an end-user application, multiple models (shown in Figure  1 ) might satisfy a given constraint.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "Even with minimal accuracy improvement of 3.5% (see Figure 3, where the 5 machines belong to 5 different owners and not sharing data), one grinding machine can save up to  ≈ 27 . 4 k  parts per year. 3) The latency difference between the data shared model and privacy preserved model is not so prominent due to the lower data volume.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "Many of these real-world services often comprise of tens or even hundreds of loosely-coupled microservices [ 42 ] (e.g. Ex- pedia [ 15 ] and Airbnb [ 2 ]). Typically, these online service ap- plications are user-facing and hence, are administered under strict Service Level Objectives (SLOs) [ 47 ,  48 ] and response latency requirements.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 96,
    "augmented": false
  },
  {
    "text": "1–6, 2018. [29]  N. Wang, J. Choi, D. Brand, C. Chen, and K. Gopalakrishnan, “Training deep neural networks with 8-bit ﬂoating point numbers,” in  Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018, Montr´eal, Canada. , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Recent studies have begun to address federated learning in resource-constrained and unreliable networks. Strategies in- clude adaptive aggregation methods, energy-aware training schedules, and robustness to device dropouts ( ? ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "From Figure 16b, it is observed that  Oracle , being clairvoyant, spawns containers in accor- dance with the peaks and valleys of the request arrival trace. Kraken , while spawning more containers, also is seen to lag behind the trend of the trace due to load prediction errors. This may be due to Media Service  having higher path unpredictability than  Hotel Reservation  (Table 2) as well as lower slack per function than Social Network  (Figure 7).",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "Fig. 6: Partial-inference steps for Frame-3 in Scenario-1. memoize  the feature maps of the middle part in the previous frame, and reuse the data for the current frame.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "NGINX ID \nMOVIE_ID \nTEXT_SERVICE \nUSER_SERVICE \nRATING \nCOMPOSE_REVIEW \nMOVIE_REVIEW \nUSER_REVIEW \nREVIEW_STORAGE \n(b) Media Service. NGINX \nCHECK_RESERVATION GET_PROFILES SEARCH \nMAKE_RESERVATION \n(c) Hotel Reservation. Figure 1: DAGs of Dynamic Function Chains.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Ekya: Continuous learning of video analytics models on edge compute servers. In  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , pp. 119–135, 2022.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 52,
    "augmented": false
  },
  {
    "text": "Define the energy budget  E b  for a single quanta and for the entire inference. Let  a i  denote the activation of neuron  i : \na dropout i =  a i  ·  m i \nTraining with Optimal Brain Damage Dropout and QuantaTask Optimization:  Initialize the network parameters  W , dropout mask  m , and scaling factor  β . Initialize the loop iteration parameters  l .",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "In addition to these, we will also use LLM/application-level metrics such as LLMOps (an extension of MLOps [84] tailored for LLMs). To gather input data, we plan to utilize publicly available datasets such as Wikipedia [164], Common Crawl [29], BookCorpus [199] and OpenWebText [49], along with our proprietary repositories. To evaluate the effectiveness of our optimizations and compare them against state- of-the-art, in addition to the standalone LLM/EoE systems, we will use various applications that employ LLMs (e.g., text generation, summarization, chatbot, language translation, and sentiment analysis) as well as emerging benchmarks like HellaSwag [195], TruthfulQA [97], GLUE [159], and MMLU [191].",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 190,
    "augmented": true
  },
  {
    "text": "experts are equally relevant, we will prioritize those with available accelerators to improve performance. EoE Graph Pruning for Memory Constraint. Given a memory budget that limits the number of experts the system can host, the EoE network must  adapt  its structure to meet user needs.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 62,
    "augmented": true
  },
  {
    "text": "Moreover, while the DNN is designed to operate within a specific power window, it is  not  trained to adapt to these fluctuations. Consequently, during extended periods of energy scarcity, the system lacks mechanisms for computational approximation, such as dynamic dropouts (neuron skipping) and dynamic quantization. Essentially, the DNN is trained to manage within a static resource budget, ignoring the “dynamism” of the resources .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "Keith Chapman, Mehdi Nik, Behnam Robatmili, Shahrzad Mirkhani, and Maysam Lavasani. Com- putational storage for big data analytics. In  Proceedings of 10th International Workshop on Accelerating Analytics and Data Management Systems (ADMS’19) , 2019.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "(c) Scenario3: entering/existing. (b) Scenario2: capturing a previously missed object. Fig.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 33,
    "augmented": true
  },
  {
    "text": "Speciﬁcally, with our current “sub-optimal” implementation (e.g., the codes are not fully optimized), the de-compression stage (including both geometry and attribute de-compression) for Redandblack video [ 55 ] only takes ≈ 70 ms  per PC frame, which is less then the PC compression latency as we will discuss later in Sec. IV-C 1 and Sec. V ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 92,
    "augmented": true
  },
  {
    "text": "There are three cases: Case-1:  If the data is close to one of the cluster centers and belongs to its cluster boundary, then it falls into the bucket of that particular class. This typically happens if the data are very similar to the training samples. Case-2:  If the data belongs to a known class, but is signif- icantly different from the training samples, it falls not too far from one of the clusters.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Figure 4: Depthmap hologram algorithm details. more intuitive opportunities could exist in the AR application do- main, from  both  the object and user perspectives. To identify them, we studied two published AR datasets (Objectron [ 1 ] for objects shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 60,
    "augmented": false
  },
  {
    "text": "1545–1553, 2018. 50–56. [32] B. Luo, F. Xu, C. Richardt, and J. Yong, “Parallax360: Stereoscopic 360° Scene Representation for Head-Motion Parallax,”  IEEE Transactions on Visualization and Computer Graphics , pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 79,
    "augmented": true
  },
  {
    "text": "Solar energy harvesting for smart farming using nanomaterial and machine learning. [67]  Rambabu Vatti, Nagarjuna Vatti, K Mahender, Prasanna Lakshmi Vatti, and B Krishnaveni. 2020.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 54,
    "augmented": true
  },
  {
    "text": "[162] Zhuang Wang, Zhen Jia, Shuai Zheng, Zhen Zhang, Xinwei Fu, T. S. Eugene Ng, and Yida Wang. Gemini: Fast failure recovery in distributed training with in-memory checkpoints. In  Proceedings of the 29th Symposium on Operating Systems Principles , SOSP ’23, page 364–381, New York, NY, USA, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "The reason for such low compression ratio is because –  1  for intra-attribute compression, only entropy encoder is applied; and  2  even with the inter-frame compression, only few macro blocks are matched and inter-encoded, which limits the beneﬁts from inter-frame compression. As for \n8 The geometry PSNR are excellent for all designs (e.g.,  >  70dB), so we only compare the PSNR for attributes in the evaluations. •  CWIPC:  Overall, when employing the CWIPC, the output frame size reduces to around  14%  of the original input frame (including 63 %  of geometry and 37 %  of attribute data).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 149,
    "augmented": true
  },
  {
    "text": "With complex and high dimensional video data, HEVC computation complexity increases exponentially, and is more pronounced because of lack of hardware support. However, it is noteworthy that at higher bitrates,  Salient Store  consistently achieves high quality recovery with PSNR reaching  ≈ 47 dB. Furthermore, as we can see in Fig.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 73,
    "augmented": false
  },
  {
    "text": "Similarly, Figure 3b demonstrates that, while increasing capacitance should theoretically stabilize the system, its charging characteristics can lead to extended charging times, thus exceeding the latency SLO. An ablation study evaluates the contributions of individual components within NExUME. Notably, some anomalies in the data were attributed to abrupt power failures, a common challenge in intermittent energy harvesting systems.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 87,
    "augmented": true
  },
  {
    "text": "The challenge here is to  send \n1 Throughout the paper we evaluate many of our motivation results using HAR as a workload as it is one such application, where the (EH-)WSN, used as body area network, fits perfectly with RF or body movement as the har- vesting source. HAR has the nuances of human introduced unpredictability and sensor induced noises. HAR has been pervasive enough given the rise of smart wearables and has been studied well enough to have ample access to resources to make a judicious evaluation.",
    "source": "Seeker.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "•  Dynamic DAGs, where only a subset of functions within each DAG are invoked per request type, necessitate the ap- portioning of containers to each function. This results in container provisioning along a single function chain. Recent frame- works like Xanadu [ 27 ], predict the most likely functions to be used in the DAG.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 85,
    "augmented": true
  },
  {
    "text": "M OTIVATION \nTo avoid negatively impacting the underlying system’s QoS, we consider RCA-based acceleration for ULP IoT nodes as an opportunistic computation knob, operating solely on ambiently harvested energy, when available. In energy harvesting systems, there are two critical features, namely,  power strength  and power window length . First, the variance of input power strength can be quite large: peak power can be hundreds or thousands of times larger than average power.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 109,
    "augmented": false
  },
  {
    "text": "However, the intermittent and unpredictable nature of harvested energy introduces significant challenges in maintaining reliable and consistent network performance ( ? By harnessing ambient energy sources such as solar, thermal, or kinetic energy, EH sensors can operate indefinitely without the need for battery replace- ment or external power supplies. ).",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "We refer to such functions as Dynamic Branch Points (DBPs), and the chains they are a part of as Dynamic Function Chains. Figure 1 shows the DAGs for three Dynamic Function Chains. In such cases, deploying containers without prior knowledge about the possible paths in the workflow leads to sub-optimal con- tainer provisioning for individual functions.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "While, we will start all four thrusts in year 1, by the middle of the second year, we expect to have our initial expert models and system support to be in place. Project Timeline \nFigure 8 despicts a tentative projected timeline for the proposed work. By the end of the second year, the preliminary system support will be finalized and we will have the initial expert-to-chiplet mappings ready.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 88,
    "augmented": true
  },
  {
    "text": "There are two major problems with performing DNN inference under intermittent power. (I) Energy Variability : Even though DNNs can be tailored to match the average energy income of the energy harvesting (EH) source through pruning, quantization, distillation, or network architecture search \nPreprint. Under review.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "Figure 9:  Beneﬁts of dynamic model selection policy. Note that, changing the target accuracy to tolerate a 0.5% loss, increases the percentage of requests that meet accuracy to 81% for  Cocktail , when compared to 61% for  InFaas . IRV2 \nDNet201 \nNASMob \nDNet121 \nXcep \nMNet \nIncep \nMNetV2 \nRNet50V2 \nRNet50 \nModel \n0 \n50 \n100 \nImportance(%) \n(b)  Distribution of requests served by each individual model.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "(c) Reusing projection matrices by exploiting relation between both eyes and fusing it with head orientation. the video buffer to present the  decoded  frames, the  360 ° video frames require “additional rendering effort” to get displayed. More speciﬁcally, the rendering process is a projection from the  360 ° frame pixels’ 3D coordinates to the 2D frame pixels’ 2D coordinates on HMDs.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "[24] A. Inc., “Rendering Omni-directional Stereo Content.” ”https:// developers.google.com/vr/jump/rendering-ods-content.pdf”, 2019. 37–44, 2017. [23] J. Huang, Z. Chen, D. Ceylan, and H. Jin, “6-DOF VR Videos with a Single 360-camera,”  2017 IEEE Virtual Reality (VR) , pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 106,
    "augmented": true
  },
  {
    "text": "Motivation \nTo understand the energy proﬁle in the current VR devices, we characterize the energy consumption of  360 ° video pro- cessing on a prototype [36] (conﬁgured similar to a com- mercial VR device [39], discussed in Sec. V) in Fig. 2a.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 66,
    "augmented": true
  },
  {
    "text": "Hottiles: Ac- celerating spmm with heterogeneous accelerator architectures. IEEE, 2024. In  2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA) , pages 1012–1028.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 55,
    "augmented": true
  },
  {
    "text": "Such signiﬁcant speedup comes with a reduction in quality. In the example shown in Fig. 5 , the octree constructed based on the Morton codes is slightly different from the one generated by the sequential algorithm (which is lossless).",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "4. •  AE  comes to play when there is a change in head orientation in consecutive frames, and we cannot enjoy the oppor- tunities in  EA . For such scenarios, due to the prevailing relationship between the left and right eye transformation matrices ( T L  and  T R ), we can further avail the spatial compute reuse opportunity shown in b in Fig.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 83,
    "augmented": false
  },
  {
    "text": "The final polynomial product  p  is sequentially read out by the address signal  addr ab , combined with the coefficient of  c , thereby producing the final output  d  as d  =  a  ·  b  +  c . This output is then transmitted serially over  n  clock cycles. Designing SDMM Hardware on CSD FPGA:  The SDMM hardware is innovatively designed to perform two modular multiplications per DSP Slice.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "; and vii)  What are the performance, power and accuracy tradeoffs in training or inference, given hyper-parameters like the size of training dataset and the length of prompt? Task-4.1: Evaluation Infrastructure: Experiments + Simulation + Analytical Modeling To compare and contrast the training complexity, training duration, accuracy, and suitability to the cus- tom hardware (utilization) of our proposed EoE-based LLM approach, we need an integrated framework that takes into account the size of the training dataset, hyper-parameters of the smaller expert model and the given hardware resource configuration to estimate the aforementioned parameters. Given extremely long training latencies, we cannot rely on simulation alone as it would take extremely long running times.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 164,
    "augmented": false
  },
  {
    "text": "[10]  K. Qiu, W. Chen, Y. Xu, L. Xia, Y. Wang, and Z. Shao, “A peripheral circuit reuse structure integrated with a retimed data ﬂow for low power rram crossbar-based cnn,” in  2018 Design, Automation Test in Europe Conference Exhibition (DATE) , pp. 733–747, 2019. 1057–1062, March 2018.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Hence, there is an opportunity to also improve the ensemble technique. C. Designing an Adaptive Ensemble Learner AASR scheduling solves most of the issues on the sensor side without burdening host device, yet the host device still per- forms a na¨ıve majority voting-based ensemble. Designing any sophisticated ensemble learning technique will either consume more resources of the host device, or need more information and computation at the edge, thus making our effort of ﬁnishing the inference at the edge not viable.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "Further, we also observed in Sec. 3 that, the main reason behind this is that the number of depth planes affects the number of synchronizations between parallel executions, and determines the amount of com- putation required to generate the holograms. Unlike prior works targeting at optimizing the efficiency of the hologram program- ming itself by proposing alternative hardware [ 32 ,  35 ], we primarily focus on exploring the intrinsic approximation opportunities (dis- cussed in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 115,
    "augmented": false
  },
  {
    "text": "•  T 1  serves as a  rigid body transformation  matrix which ap- plies 3D rotation ( Y aw, Pitch, Roll ) and translation so that, the objects do not get distorted. 3  a  for compu- tation of the  Transformation Matrix , is used for projecting the 360 ° frame pixels onto the  2 D  FoV plane in the subsequent stages. This matrix is calculated by applying ﬁve different transforms –  T 1 ,  T 2 ,  T 3 ,  T 4 , and  T 5  – in a serial fashion.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "Therefore, we adapt a “student-teacher paradigm” [ 46 ], where a more \nClassify \nLow Conf \nFrame? This requires the data to be present at a central location for manual inspection, both of which are not possible because of communication and privacy constraints. Classically, once data is collected, it is classiﬁed, labeled, and bounded by borders (bounding box) mostly using manual labor (at times with software assistance) or crowd sourcing [ 33 ], [ 82 ], [ 88 ].",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 113,
    "augmented": true
  },
  {
    "text": "We ensure data diversity between different partitions to ensure similarities with the real-world. We divide the data into training and testing sets, and to simulate a distributed environment, the training data is further divided into multiple different chunks (starting from 2 to 4, each part representing a household in the same neighbourhood). Further, we apply our policies to the distributed data and train random forest models (both for the edge and the cloud).",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 89,
    "augmented": true
  },
  {
    "text": "DeepFovea: Neural Reconstruction for Foveated Rendering and Video Compression using Learned Statistics of Natural Videos. 2019. ACM Trans.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 36,
    "augmented": true
  },
  {
    "text": "Implementation Methodology:  We developed a proto- type on top of Amazon EC2 and Lambda services to evaluate the some of the benefits of our proposed design choices. We design three different experiments to study the effects on cost of ML servings due to (i) varying SLOs and (ii) varying application constraints. 4 Evaluation and Initial Results \nThis section introduces how an ML-serving framework can capitalize on the design choices discussed in Section  3 .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "119–135, 2022. In  19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22) , pp. Ekya: Continuous learning of video analytics models on edge compute servers.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "The accuracy improvement in the 4-home setup is significant and the reason for the lower edge accuracy of the 4-home setup is the limitation in number of training samples (2 home setup has twice the amount of data than the 4 home setup to train with). The 2-home setup, albeit more accurate, has a more complex model (#splitting points 10501) at the cloud thanks to the large volume of training samples, leading to more execution time compared to the relatively simpler model for the 4-home setup. 2) However, the cloud execution latency also increases for the 2-home setup due to the model complexity.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 126,
    "augmented": true
  },
  {
    "text": "[63] Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, and Alexandra Peste. Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks. Journal of Ma- chine Learning Research , 22(241):1–124, 2021.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 79,
    "augmented": false
  },
  {
    "text": "Copyrights for components of this work owned by others than ACM must be honored. CCS Concepts •  Computer systems organization  → Cloud Comput- ing ;  Resource-Management ; Scheduling. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Relating this to our problem, each coin represents a model, and an occurrence of head represents the model giving the correct classiﬁcation. Hence, the problem boils down to ﬁnd the probability of at least  ⌊ N / 2 ⌋ + 1  heads when all N coins are tossed together. This is a standard binomial distribution problem and can be solved by using the following formula: \nP head  = N ∑ i = ⌊ N \n2   ⌋ + 1 \n\u0012 N i \n\u0013 a i   ( 1 − a ) ( N − i ) .",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 127,
    "augmented": false
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. However, it misses the opportunities of frame-level data reuse, and hence needs to perform inference for each and every frame. Thus, as shown \n1082 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "Making ai less “thirsty”: Uncovering and addressing the secret water footprint of ai models. arXiv preprint arXiv:2304.03271 , April 2023. Accessed: 2023-10-20.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "However,  T 2  can change at runtime, and if any element in  T 2 is changed, the transformation matrix needs re-computation \nFig. 4: InterFrame-IntraEye ( EA ) and IntraFrame-InterEye ( AE ) reuse opportunities. This example illustrates 3 consecutive frames processing, each of which consists of two projection matrices ( P L and  P R ) for both eyes.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 103,
    "augmented": false
  },
  {
    "text": "In  ACM SIGGRAPH 2020 Emerging Technologies (SIGGRAPH ’20) . Association for Computing Machinery. [49]  Martin Persson, David Engström, and Mattias Goksör.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "By integrating these components, an EH system can sustainably power devices without relying on traditional power grids, making it ideal for remote or mobile applications. C Intermittent Computing and Check-pointing \nC.1 Intermittency-Aware General Matrix Multiplication (GeMM) \nHere we explain the operation of an energy-aware algorithm for performing General Matrix Multipli- cation (GeMM). The algorithm is designed to operate in environments where energy availability is intermittent, such as in devices powered by energy harvesting.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 118,
    "augmented": false
  },
  {
    "text": "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WoSC’20, December 7ś11, 2020, Delft, Netherlands © 2020 Association for Computing Machinery.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 73,
    "augmented": true
  },
  {
    "text": "In  21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24) , pages 761–774, 2024. Data Management and Sharing Plan \nThis section describes “data” – in its most general definition that includes, compiler, scheduler, and simu- lation source codes and executables, LLM/expert models/algorithms, educational materials, benchmarks, and experimental data – that will be produced during the project; how this data will be managed, stored and shared, what standards will be used for different types of data, and how data will be handled and protected during and after the project. It also describes our plans for ensuring data integrity and reproducibility.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 157,
    "augmented": false
  },
  {
    "text": "The work queue schedule, intermediate result, network and layer information are saved on predicted power failure, and data from the DRAM (the working set of IF/OF/ﬁlter and model state) are moved to an NV-RAM using STT-RAM based buffers in the memory hierarchy (parallel to the IF/OF/ﬁlter). The dual-scheduling mechanism, bolstered by the work queue’s ﬂexible architecture, not only optimizes compute performance but also offers resilience against power uncertainties. Two distinct scheduling strategies, each complemented by its own type of work queue, govern the computational ﬂow: Conservative Scheduling and Eager Scheduling.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 145,
    "augmented": true
  },
  {
    "text": "4. We implement a prototype of  Cocktail  using both CPU and GPU instances on AWS EC2 [ 5 ] platform and ex- tensively evaluate it using different request-arrival traces. Our results from exhaustive experimental analysis demon- strate that  Cocktail  can minimize deployment cost by 1.4 × while meeting the accuracy for up-to 96% of the requests and providing 2 ×  reduction in latency, when compared to state-of-the-art model serving systems.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 104,
    "augmented": false
  },
  {
    "text": "In  Proceedings of the twenty-ﬁrst international conference on Machine learning , page 18, 2004. [18]  Jesús Cerquides and Ramon López De Mántaras. Robust bayesian linear classiﬁer ensembles.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 55,
    "augmented": false
  },
  {
    "text": "Chipper: A low-complexity bufferless deflection router. [41] Chris Fallin, Chris Craik, and Onur Mutlu. In  2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) , pages 1–10, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "[17] A. Reiss and D. Stricker, “Creating and benchmarking a new dataset for physical activity monitoring,” in  PETRA , F. Makedon, Ed. ACM, 2012. [18] F. Chollet  et al.",
    "source": "Origin.pdf",
    "type": "sliding_window",
    "tokens": 59,
    "augmented": false
  },
  {
    "text": "For the sequential computation mode, the throughput for Layer  Lk  can be expressed as below: \nThr sequ Lk =  ( m  ×  n ) Lk  ×  aG Lk \nLat Lk (6) \nThe average throughput with a  LC -convolution CNN infer- ence can be expressed as shown below. Thr sequ ave   = P Lk = LC Lk =1 ( m  ×  n ) Lk  ×  aG Lk P Lk = C Lk =1   Lat Lk (7) \nFor the pipelining computation mode, all the  LC  layers are executed in parallel. The throughput can be expressed as follows: \nThr pipe ave   = P Lk = LC Lk =1 ( m  ×  n ) Lk  ×  aG Lk \nLat pipe (8) \n2) Activation strategy formulation :  The activation strategy for the sequential mode can be described as shown below.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 217,
    "augmented": false
  },
  {
    "text": "IEEE, 2015, pp. 1–5. [24] A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous \ndriving?",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 43,
    "augmented": false
  },
  {
    "text": "Truthfulqa: Measuring how models mimic human falsehoods. ACM, 2022. In  Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (CCS) , pages 465–482.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "In terms of cost, utilization, power, and area require- ments, we expect several inefficiencies with existing off-the-shelf hardware like CPUs and GPUs when executing our models for training, inference, and re-training purposes, thus exacerbating the gap towards democratization. In addition, for supporting morphable network structures that change over time with continual learning, the underlying interconnect should be dynamically reconfigurable. Moreover, the experts could differ in their size and thus in their compute and memory requirements.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "[29] Common Crawl. Common crawl corpus. Transactions of the Association for Computational Linguistics , 12:283–298, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 39,
    "augmented": true
  },
  {
    "text": "In  IOP Conference Series: Materials Science and Engineering , Vol. Solar energy harvesting for smart farming using nanomaterial and machine learning. 981.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "Define the energy budget E b  for a single quanta and for the entire inference. Initialize the loop iteration parameters  l . Compute the activations  a  and apply the dropout mask: \nm i  =  σ ( z i ) \na dropout i =  a i  ·  m i \nCompute the loss  L ( Y ,   ˆ Y ) .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Nature communications , 13(1):5546, 2022. Learning multiple layers of features from tiny images. Krizhevsky Alex.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 30,
    "augmented": true
  },
  {
    "text": "•  EE  offers little chance of reuse, and can only be leveraged in rare occasions, where we have oracular knowledge of head movements. Furthermore, in such cases of head movement, there is likely to be some reuse from inter-eye reusability within a frame, rather than inter-frame reusability. B.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "Apart from neural network techniques, foveated rendering is another promising performance optimization for reducing computational costs [ 2 ,  22 ,  24 ,  25 ,  30 ,  47 ,  62 ], as summarized in Sec. 2.2.2. In this paper, the foveated rendering idea (denoted as  Inter-Holo  design) has been implemented (in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 82,
    "augmented": false
  },
  {
    "text": "Appendix \nA Modeling of Ensembling \nWhile performing an ensemble it is important to be sure that we can reach the desired accuracy by combining more models. In our design, we solve our ﬁrst objective function (described in Section  4.1 ) by combining all available models which meet the latency SLO. To be sure that the combination will give us the desired accuracy of the larger model, we try to theoretically analyse the scenario.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "Overall Utility Function: Combining immediate rewards and costs, the overall utility function for sensor  s i  at time  t is: U i ( t ) =  R i ( t )  − C i ( t ) . This utility function effectively balances the benefits of participation against the associated costs and future oppor- tunities, guiding sensors to make strategic decisions that optimize their long-term contributions to the network. Nash Equilibrium and Stability: A Nash equilibrium (NE) represents a stable action profile  a ∗ ( t )  where no sensor can unilaterally improve its utility by deviating from its current strategy: \nU i ( a ∗ i   ( t ) ,  a ∗ − i ( t ))  ≥ U i ( a i ( t ) ,  a ∗ − i ( t )) ∀ a i ( t ) ,  ∀ i.",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 227,
    "augmented": true
  },
  {
    "text": "First of all, a large number of sensor inputs are fed into the hologram pipeline (as shown in Fig. 4.1 Exploring the Entire Design Space in AR Hologram Processing \nExploring the entire design space for the AR hologram processing is a non-trivial task. 1b), such as IMU sensors, eye tracking or IR sensors, hand motion sensors, RGB-D im- age sensors, etc.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 96,
    "augmented": true
  },
  {
    "text": "It is evident that full-ensemble can achieve up to 1.65% better accuracy than single models. Besides accuracy again, ensembling can also achieve lower latency. Figure  3a , shows the accuracy comparison of the baseline (single) and static ensemble (ex- plained in Section  3 ) compared to the full-ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 76,
    "augmented": true
  },
  {
    "text": "IEEE, 2015, pp. [24] A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous \ndriving? 1–5.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "In  2014 IEEE symposium on computational intelligence in ensemble learning (CIEL) , pages 1–6. [65]  Atul Rahman, Jongeun Lee, and Kiyoung Choi. IEEE, 2014.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 45,
    "augmented": true
  },
  {
    "text": "However, the crucial downside of using transient VMs is that they can be unilaterally preempted by the cloud provider at any given point due to reasons like in- crease in bid-price or provider-induced random interruptions. As we will discuss further,  Cocktail  is resilient to instance failures owing to the fault-tolerance of ensembling by com- puting multiple inferences for a single request. Key takeaway :  The cost-effectiveness of transient instances, is naturally suitable for hosting ensemble models.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 120,
    "augmented": false
  },
  {
    "text": "While such an approach improved the computational efficiency and reduced power consumption to some extent, rethinking the design of hologram software/hardware con- sidering the unique features of the AR holographic applications (as discussed in Sec. Because of this, recently, alternate hardware-based solutions have been proposed to improve the com- putational efficiency by replacing the expensive transcendental cal- culations with lookup table (LUT) based memoization [ 35 ], or miti- gating the data movement overheads by employing a customized buffer on-chip [ 32 ], or simply offloading computations to cloud then streaming back [ 16 ,  27 ,  67 ]. 1.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 155,
    "augmented": true
  },
  {
    "text": "URL  https://csrc.nist.gov/projects/ post-quantum-cryptography . Accessed: 2024-08-01. Samsung Newsroom.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 39,
    "augmented": false
  },
  {
    "text": "The main parameters of our simulations are given in Table VI. Load/store parameters of the ReRAM memory are from NVSim [ 40 ]. Four practical CNNs listed in Table VI are evaluated on the ﬁve power traces illustrated in Figure 4 for each of the ﬁve execution strategies from Section  V-A 3:  Naive1 ;  Naive2 ;  Sequential ; Pipelining ; and  ResiSchedule .",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 95,
    "augmented": true
  },
  {
    "text": "Define the dropout probability  p i  for neuron  i  based on the Taylor expansion approximation of its impact on the loss: \np i  = λ \f\f\f  ∂ L \n∂ a i   a i \f\f\f  +  ϵ \nwhere  λ  is a scaling factor to adjust the overall dropout rate, and  ϵ  is a small constant to avoid division by zero. Define a binary dropout mask  m  = [ m 1 , m 2 , . .",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "0 \n1 \n2 \n3 \n4 \n0 \n0.5 \n1 \n1.5 \nutil_aware exascale mixed paragon \nSLO Violations \nNormalized Cost \nCost SLO violations \n(a)  Workload-1: Berkeley Trace. 0 \n5 \n10 \n0 \n0.5 \n1 \n1.5 \nutil_aware exascale mixed paragon \nSLO Violations \nNormalized Cost \nCost SLO violations \n(b)  Workload-1: WITS Trace. Figure 8.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "291 \nAuthorized licensed use limited to: Penn State University. Restrictions apply. Downloaded on August 10,2023 at 18:50:20 UTC from IEEE Xplore.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "In this context, we plan to show them how Generative AI are being used in different application domains (e.g., LLM-powered story generation and creative writing, interactive chatbots for math learning and problem solving, etc). A selected group of undergraduate students and volunteers from CRA-W, ACM, and Girls Who Code programs will be trained to go to these schools and talk to students. We have also participated in the annual Exploration-U Science day events, organized by Penn State.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 107,
    "augmented": true
  },
  {
    "text": "2020. CUDA Toolkit Documentation: Nvprof. \"shorturl.at/zEFU5\".",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 28,
    "augmented": true
  },
  {
    "text": "For many WSNs, their participation in inference tasks has traditionally been limited to data collection and transmission, sometimes with modest preprocessing. While several studies have shown the benefits of performing more inference closer to the point of data collection [ 23 ,  30 ,  31 ,  40 ,  56 ] and have ap- plied these techniques to more powerful edge devices, their form-factor-imposed limited energy storage, low-power op- eration points, and deployment scenarios have been a major impediment in executing compute-intensive inference tasks directly on such platforms. This represents a particularly challenging tension between energy availability and desired functionality, because the form factor constraints of the WSNs fundamentally limit active power, energy re- serves, compute and communication capabilities.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "Swayam [ 34 ] is relatively similar to our work as it han- \nUSENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1043 \nBaseline(BL) NASLarge IRV2 Xception DNet121 NASMob #Models 10 8 7 5 2 BL_Latency 311(ms) 152(ms) 120(ms) 100(ms) 98(ms) E_Latency 152(ms) 120(ms) 103(ms) 89(ms) 44(ms) \nTable 3:  Comparing latency of Ensembling (E_Latency) with single (baseline) models. Cocktail’s  autoscaling policy strikes parallels with Swayam’s distributed autoscaling; however, we further incorporate novel importance sampling techniques to reduce over-provisioning for under-used models. dles container provisioning and load-balancing, speciﬁcally catered for single model inferences.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 234,
    "augmented": true
  },
  {
    "text": "Henceforth, we refer to such Dynamic DAG Applications as DDAs. 2.2 Motivation Two specific challenges in the context of DDAs along with potential opportunities to resolve them are described below: Challenge 1: Path Prediction in DDAs. the start function  NGINX , any one of  Search ,  Make_Post , Read_Timeline  and  Follow  can be taken.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 84,
    "augmented": true
  },
  {
    "text": "In \n246 \nTABLE II: Video workloads. No. Video Type (Cam movement/focus of attention direction) \nFrame Rate (fps) \n#Frames Bit Rate (kbps) \nV1 Rhinos [4] Stationary cam, no focus direction 30 3280 13462 \nV2 Timelapse [56] \nStationary cam, fast-moving objects, no focus direction \n30 2730 15581 \nV3 Rollercoaster [35] \nFast-moving cam hooked in front of a rollercoaster, uni-direction focus \n29.97 6194 16075 \nV4 Paris [51] \nStationary cam, smooth scene cuts, no focus direction \n59.94 14629 14268 \nV5 Elephants [5] Stationary cam, uni-direction focus 30 5510 16522 \nthis work, we are focusing on reusing computation results rather than reducing the content maintenance/transfer, and hence do not consider that optimization.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 210,
    "augmented": false
  },
  {
    "text": "IEEE, 2020, pp. [107] S. Zhao, H. Zhang, S. Bhuyan, C. S. Mishra, Z. Ying, M. T. Kandemir, \nA. Sivasubramaniam, and C. R. Das, “D´eja view: Spatio-temporal compute reuse for ‘energy-efﬁcient 360 vr video streaming,” in  2020 ACM/IEEE 47th Annual International Symposium on Computer Archi- tecture (ISCA) . 241–253.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 124,
    "augmented": true
  },
  {
    "text": "2023. [37] Shihan Dou, Enyu Zhou, Yan Liu, Songyang Gao, Jun Zhao, Wei Shen, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, and Xuanjing Huang. The art of balancing: Revolutionizing mixture of experts for maintaining world knowledge in language model alignment.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "[69] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. Adaptive mixtures of local experts. Rapidchiplet: A toolchain for rapid design space exploration of chiplet architectures, 2023.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 56,
    "augmented": true
  },
  {
    "text": "IEEE, 2005. In  2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05) , volume 2, pages 568–573. Recognizing facial expression: machine learning and application to spontaneous behavior.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 47,
    "augmented": true
  },
  {
    "text": "[3]  Andrew Chung, Jun Woo Park, and Gregory R. Ganger. 2018. Stratus: Cost-aware Container Scheduling in the Public Cloud.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 38,
    "augmented": false
  },
  {
    "text": "The method includes targeted fine-tuning that not only regularizes the model but also pre- vents overfitting, enhancing robustness to fluctuations in resource availability. Our key contributions can be summarized as follows: \n•  DynFit : A novel training optimizer that embeds energy variability awareness directly into the DNN training process. This optimizer allows for dynamic adjustments of dropout rates and quantization levels based on real-time energy availability, thus maintaining learning stability and improving model accuracy under power constraints.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 110,
    "augmented": false
  },
  {
    "text": "From these graphs, it is evident that  Kraken  exhibits comparable performance to existing policies while having a minimal re- source footprint. 6.1.2 End-to-End Response Times and SLO Compli- ance : Figure 9 shows the breakdown of the average end-to- end response times and Figure 10 juxtaposes the total number of containers provisioned against the SLO Guarantees for all policies and applications, averaged across all traces. Note that, these additional containers are necessary to reduce SLO violations.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "E. Future Work \nAs shown in Sections IV-A and IV-B, our inference decision (FI, SI, or PI) is made by comparing the overlap between the MVs and the previous frame’s BBoxes, or the ratio of the MVs size to the previous BBoxes, with a preset thresholds. Although we have an intuitive feeling on the how the thresholds in Algo. This is mainly because, in MCDNN, the scheduler tends to choose YOLOv4-tiny due to the low energy budget.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 130,
    "augmented": true
  },
  {
    "text": "IEEE Micro , 40(2):17–24, 2020. Building meta’s genai infrastructure, 2024. [104] Meta.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 32,
    "augmented": true
  },
  {
    "text": "AMD and Xilinx. Xilinx runtime library (xrt). https://www.xilinx.com/products/ design-tools/vitis/xrt.html .",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 51,
    "augmented": false
  },
  {
    "text": "[53]  Romain Lerallut, Diane Gasselin, and Nicolas Le Roux. Large-scale real-time product recommendation at criteo. In  Proceedings of the 9th ACM Conference on Recommender Systems , pages 232–232, 2015.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 61,
    "augmented": false
  },
  {
    "text": "This design, depicted in Fig. It leverages the PCIe interface for efficient “peer-to-peer communication”, substantially reducing communication latency and energy requirements. 2, gives the programmable computational capa- \n7 \nbilities of CSDs along with the cost-effectiveness and durability of the classical HDDs.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 75,
    "augmented": true
  },
  {
    "text": "Relying on how different the answers from each estimators are, we can quantify the prediction quality of the random-forest. Peer-Before-Server:  Although sharing data with the cloud helps us build robust models, the communication latency is significantly higher than local computation, prompting several \nworks [6] to push compute to the edge. For latency-sensitive applications, offloading to peers may be more viable than offloading to the cloud.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window",
    "tokens": 99,
    "augmented": false
  },
  {
    "text": "The constraints are deﬁned as  <latency,accuracy>  pair. The queries arriving with similar constraints can read the model cache to avoid re-computation for selecting the models. The model cache is implemented as a hash-map using  Redis  [ 16 ] in-memory key-value store for fast access.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "[40]  Y. Lin, Z. Zhang, H. Tang, H. Wang, and S. Han, “Pointacc: Efﬁcient point cloud accelerator,” in  Proceedings of the International Symposium on Microarchitecture (MICRO) , 2021, pp. 449–461. [41]  H. Liu, H. Yuan, Q. Liu, J. Hou, and J. Liu, “A comprehensive study and comparison of core technologies for mpeg 3-d point cloud compression,”  IEEE Transactions on Broadcasting , pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 124,
    "augmented": false
  },
  {
    "text": "The power of ensembles for active learning in image classiﬁ- cation. [15]  William H Beluch, Tim Genewein, Andreas Nürnberger, and Jan M Köhler. In  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 9368–9377, 2018.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "Curriculum Development Activities : As we have done in our prior NSF projects, we will integrate our research results from this project with educational activities and graduate and undergraduate student train- ing for nurturing the future workforce in science and engineering. Our curriculum development activities include the development of two courses related two this project – (i) an undergraduate course on “Genera- tive AI” (drawing mainly from Thrust 1 of this project and focusing on training students to develop skills like language model creation other generative AI applications) that will be used for our CS curriculum and the new AI degree, and (ii) a graduate course on “System and Architectural Support for LLMs”, which will draw from the contents of Thrusts 2 and 3. Also, where possible, the research material from this project will be integrated into the ML, architecture, and systems courses the PIs are regularly teaching at Penn State.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 193,
    "augmented": true
  },
  {
    "text": "•  Summer Research Opportunities for High School Students and Science Teachers:  The PIs has been participating in the organization of various summer activities with high school students and teachers. For example, PI Kandemir has previously participated in the organization of a workshop targeting high school teachers and gave a talk on ML and high-performance computing. The research team is planning to organize summer activities with high school students and teachers in the context of this project as well.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 94,
    "augmented": false
  },
  {
    "text": "5b, such a region of focus is just a subset of the entire viewing window, and thus contains a small number of objects that need to be computed with rich information (as it needs 16 depth planes). However, for the objects outside of the current RoF, since the user is not cur- rently focusing on them, a reasonable approximation would not affect the user experience that much (which implies we do not need 16 depth planes for all of them). In the  Inter-Holo  scenario shown in Fig.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 120,
    "augmented": true
  },
  {
    "text": "; iv)  How can we identify hot experts and cold experts in LLM inference and how can such information be utilized? ; vi) What are the additional complexities and opportunities KV-caches bring in an EoE environment? ; v)  How should available memory space be managed during training and inference?",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "27–39, 2016. 14–26, 2016. [4]  P. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang, and Y. Xie, “PRIME: A novel processing-in-memory architecture for neural network computation in reram-based main memory,” in  2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA) , pp.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 108,
    "augmented": true
  },
  {
    "text": "[10]  Yu Feng, Boyuan Tian, Tiancheng Xu, Paul Whatmough, and Yuhao Zhu. 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)  (2020), 10766–10773. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "The resulting power needs have recently triggered data center providers to install their own power plants [44,53,136,155]. Current hardware accel- erators like GPUs, and even specialized processors like Groq [61], Cerebras [86,96], Graphcore [54,115], and SambaNova [131], are not efficiently utilized due to limitations in memory bandwidth, interconnects, and data handling capabilities. These hardware inefficiencies lead to suboptimal performance and increased energy consumption.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "2017. Phoenix: A \nConstraint-Aware Scheduler for Heterogeneous Datacenters. [47]  Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut Taylan Kandemir, and Chita R. Das.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 69,
    "augmented": true
  },
  {
    "text": "This task dynamically adapts to changing traffic patterns and environmental conditions. In urban mobility, high-volume data streams from multiple sources, such as high-resolution traffic cameras, are first compressed then analyzed for exemplar selection. This process involves “representation learning” (Rebuffi et al., 2017), where data is transformed into “feature vectors” using deep neural networks, followed by unsupervised learning techniques like k-means clustering.",
    "source": "SaLT.pdf",
    "type": "sliding_window",
    "tokens": 100,
    "augmented": false
  },
  {
    "text": "Under review. (I) Energy Variability : Even though DNNs can be tailored to match the average energy income of the energy harvesting (EH) source through pruning, quantization, distillation, or network architecture search \nPreprint. There are two major problems with performing DNN inference under intermittent power.",
    "source": "NexUME.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 67,
    "augmented": true
  },
  {
    "text": "arXiv preprint arXiv:2006.16668 , 2020. [90] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. Gshard: Scaling giant models with conditional computation and automatic sharding.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 98,
    "augmented": false
  },
  {
    "text": "2, respectively, for an ILLIXR playground scenario [15, 19]. Comparing the ideal latencies with practical latencies, we make the following conclusions: In our practical setting,  Pose Estimation tracks user’s motion and viewing scene to estimate the current body pose [ 53 ], and it takes around 13 . 8 ms .",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "3, pp. 1–13, 2016. [5] W. Amit Katwala, “The spiralling environmental cost of our lithium \nbattery addiction,” https://www.wired.co.uk/article/lithium-batteries- environment-impact , May 2018, (Accessed on 07/08/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "(2016). [48]  Yifan Peng, Suyeon Choi, Nitish Padmanaban, Jonghyun Kim, and Gordon Wet- zstein. 2020.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 44,
    "augmented": true
  },
  {
    "text": "In this context, this paper explores the following three  opportunities : \n1  The points can be processed  in parallel  by using Morton codes [ 30 ] (which mathematically represent the geometry relationship among points) to identify the spatial-locality 1 \nwithin one frame for geometry compression. 2  Further, this locality also exists in attributes (RGB pixels), i.e., spatial locality leads to attribute similarities, and hence opening opportunities for fast attribute compression. Prior works on PCC acceleration [ 19 ], [ 33 ] only consider the PC with geometry data and/or have limited parallelism, and thus, could neither leverage GPU nor beneﬁt from other types of accelerators.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 142,
    "augmented": true
  },
  {
    "text": "1–8. Springer, 2020, pp. [34]  A. Kuntz, C. Bowen, and R. Alterovitz, “Fast anytime motion planning in point clouds by interleaving sampling and interior point optimization,” in  Robotics Research .",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "stationary; 2. input stationary; and 3. weight stationary [ 79 ]. Most large-scale accelerators use the output stationary imple- mentations to minimize the output feature map movement [ 81 ], and some of available hardware even supports multiple types of mappings [ 15 ], [ 37 ]. However, our design objective is to minimize  data movements in the case of compute reconﬁgura- tion.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 86,
    "augmented": false
  },
  {
    "text": "As deep neural network models often have a complex interplay of layers, each with distinct computational needs, the work queue ensures a systematic, prioritized approach to handle these oper- ations. Each task, represented in the queue, corresponds to the execu- tion of speciﬁc CNN kernels, feature tiles and operations. Two distinct scheduling strategies, each complemented by its own type of work queue, govern the computational ﬂow: Conservative Scheduling and Eager Scheduling.",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "4.2 Resource Management \nBesides model selection, it is crucial to design an optimized resource provisioning and management scheme to host the models cost-effectively. append ( model weight ) 7: end for 8: end for 9: if  Predicted_load  ≥ Current_load  then 10: for  model in  ∀ Models  do 11: I_n  ← (Predicted_load - Current_load) × model weight 12: launch_workers ( est_VMs ) 13: model.workers.append ( est_VMs ) 14: end for 15: end if 16:  end procedure \nof weighted voting in breaking ties is discussed in Section  6 . We explain in detail the resource procurement and autoscaling policy employed in  Cocktail .",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "As a result, the data size becomes 5%  less than our intra-only design (e.g., only 12 %  of the original size), while dropping the quality by  6 . •  Our Intra-Inter-V2 (Compression efﬁciency-oriented):  Sim- ilarly, this design further reduces the compressed data size by 2 % , by adjusting the threshold for “direct-reuse decision making”, as discussed in Sec. 1 dB due to the block-level approximations in the inter-frame compression.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 121,
    "augmented": true
  },
  {
    "text": "Existing Approaches:  Although there has been signiﬁcant re- search [ 40 ], [ 41 ], [ 47 ], [ 52 ], [ 56 ], [ 61 ], [ 72 ], [ 104 ] on enabling machine learning in intermittently powered devices, a major- ity of it focuses on performing inference. Only intermittent learning [ 47 ] focuses on performing on-device training, but with very small workloads and models. Considering the scale, scope and workload of our problem, limits direct comparisons, except for comparing their exemplar selection method (refer Fig.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 134,
    "augmented": false
  },
  {
    "text": "Therefore the case of consulting a peer only becomes beneficial when the communication latency and energy to the peer is much less than to the cloud. In our experiments, we observe that, in most cases, the accuracy of the peers are similar to that of the edge node. B.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 59,
    "augmented": true
  },
  {
    "text": "We took a history (years 2019 and 2020; from Seattle, WA; Sterling, VA; and Oak Ridge, TN) of solar energy traces from SOLRAD [ 25 ], [ 91 ] and built a weight matrix which looks into a window of 1 hour at 1 minute (average power) intervals to predict the power for next 10 minutes (1 minute granularity). We have adjusted the time window size. Note that the power predictors used in prior works are meant for ﬁckle energy harvesting scenarios like piezoelectric (movement), or RF (WiFi).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "rel.gov/gis/solar-resource-maps.html , (Accessed on 11/21/2022). [67] D. Patterson, J. Gonzalez, Q. [65] NVIDIA T4 for Virtualization, “http://bit.ly/3EﬁuWg.” [66] I. of Energy Research, “The environmental impact of lithium \nbatteries,” https://www.instituteforenergyresearch.org/renewable/the- environmental-impact-of-lithium-batteries/ , November 2020, (Accessed on 07/08/2023).",
    "source": "Usas.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 131,
    "augmented": true
  },
  {
    "text": "Finally,  HoloAR \n499 \nHoloAR: On-the-fly Optimization of 3D Holographic Processing for Augmented Reality MICRO ’21, October 18–22, 2021, Virtual Event, Greece \n(a) Viewing-Window scenario [52]. (b) Inter-Holo scenario. (c) Intra-Holo scenario.",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 81,
    "augmented": true
  },
  {
    "text": "A systematic methodology for characterizing scalability of dnn accelerators using scale-sim. IEEE, 2020. In  2020 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) , pages 58–68.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 52,
    "augmented": true
  },
  {
    "text": "The host receives the data in compressed form for the unfinished portion, decompresses it, runs inference and finally ensembles the results from multiple sensors to improve accuracy and robustness. 3 DESIGN SPACE EXPLORATION Since data communication in a sensor host ecosystem (Fig- ure 3) consumes substantial power, we rely on coresets as an efficient way to lossily communicate the features with minimal information degradation. H S/C \nM \nH: Harvest\n S/C: Sense & \nCompute\n M: Communicate \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nEH + Sense \n+ Compute \nDecompress + Infer \n+ Ensemble  \nSensor state transition sensor \nHost Legend: \nFigure 3: An example of EH Sensor-Host ecosystem - the sensor transitions between multiple states and executes the compute as store and execute fashion [ 47 ].",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 193,
    "augmented": true
  },
  {
    "text": "These schemes are modeled after state-of-the-art prior works as explained earlier in Section  2.3 . The  Paragon scheme does not offload to lambdas for relaxed latency queries. We compare the execution of this workload against the following resource procure- ment schemes: (i)  util_aware , (ii)  exascale , (iii)  mixed  and (iv) Paragon .",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Advances in Neural Information Processing Systems , 36:53038–53075, 2023. Fine-tuning language models with just forward passes. [102] Avinash Maurya, Robert Underwood, M. Mustafa Rafique, Franck Cappello, and Bogdan Nicolae.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 68,
    "augmented": true
  },
  {
    "text": "400–414. IEEE, 2020. Ali Saffari, Sin Yong Tan, Mohamad Katanbaf, Homagni Saha, Joshua R Smith, and Soumik Sarkar.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 48,
    "augmented": false
  },
  {
    "text": "Importantly, they are of- ten incapable of transmitting the raw data due to a lack of sufficient energy; for sensing tasks with modest inference requirements, performing inference and transmitting the result can take  less  energy than transmitting raw data. Given the limitations of the EH budget, such approaches typically end up dropping many samples and not inferring from them locally. How- ever, to unleash the remote deployment, and sustainable, yet pervasive, computing capabilities WSNs, development of ef- ficient  energy harvesting WSNs  (EH-WSNs), both for sensing and edge-analytics, plays an essential role.",
    "source": "Seeker.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 143,
    "augmented": true
  },
  {
    "text": "These autoscaling mechanisms can be of two types: (i) spawn VMs if the resource utilization of existing VMs reaches a certain threshold (80% in most cases) [ 9 ], and (ii) spawn additional VMs than predicted request demand [ 6 ]. We name the former autoscaling scheme as  util_aware  and the later as  exascale . Both these schemes suffer from over- provisioning VMs because (i) we cannot always accurately predict the future load, and (ii) resource utilization is not always the right indicator for increased load.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 131,
    "augmented": false
  },
  {
    "text": "[119] Nvidia. Nvidia nvlink. \" https://www.nvidia.com/en-us/data-center/nvlink/ \", 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 44,
    "augmented": false
  },
  {
    "text": "Cocktail is open-sourced at  https:// github.com/jashwantraj92/cocktail \n5.1 Cocktail Prototype Implementation \nCocktail  is implemented using 10KLOC of  Python . We de- signed  Cocktail  as a client-server architecture, where one master VM receives all the incoming requests which are sent to individual model worker VMs. Master-Worker Architecture : The master node handles the major tasks such as (i) concord model selection policy, (ii) request dispatch to workers VMs as asynchronous future tasks using  Python asyncio  library, and (iii) ensembling the pre- diction from the worker VMs.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "V , only part of the blocks/segments can be directly approximated by the reference block. Therefore, we add one more parameter to control the ratio of such blocks. Especially, for each P-block, we ﬁrst calculate its 2-Norm distance to its  best matched block  in I-frame.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 66,
    "augmented": false
  },
  {
    "text": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. [67]  Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. arXiv preprint arXiv:1910.01108 , 2019.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 63,
    "augmented": true
  },
  {
    "text": "Table  4  shows the root mean squared error (RMSE) in- curred by all the models. The ML models used in these experiments are pre-trained with 60% of the Twitter arrival trace. It is evident that the LSTM and DeepAREst have lowest RMSE value.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 64,
    "augmented": false
  },
  {
    "text": "5.1 Evaluation of Encoding, Scaling and Accuracy \nIn evaluating the  Salient Store  storage system, particularly for continuous learning scenarios video analytics applications, we selected data-sets that are not only dense but also necessitate continuous learning due to their dynamic nature. Autonomous driving and urban mobility applications, generating over 400TB of data annually (Wright\"; \"premioinc\"; Bhardwaj et al., 2022), predominantly comprise video and 3D point cloud data, making them ideal for our evaluation. Compute server indicates a software only classical storage solution without CSDs.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 137,
    "augmented": true
  },
  {
    "text": "To address this, we need to carefully decide how much his- tory is to be memoized for leveraging computation reuse. We performed a study on the VR video dataset [3] to investigate the head orientation traces of 20 users watching 5 widely- variant  360 ° VR videos (summarized in Tab. II).",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 69,
    "augmented": false
  },
  {
    "text": "Perform the forward pass with the updated dropout mask to obtain the output Y . This approach ensures that the network is robust to varying energy conditions by incorporating dynamic dropout influenced by the Taylor expansion approximation of the neurons’ impact on the loss, along with the QuantaTask optimization to handle energy constraints. E Workings of Re-RAM Crossbar \nE.1 Re-RAM cross-bar for DNN inference: \nReRAM x-bars are an emerging class of computing devices that leverage resistive random-access memory (ReRAM) technology for efficient and low-power computing.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 132,
    "augmented": false
  },
  {
    "text": "King, C. Lin, R. Liu, C. Hsieh, K. Tang, and M. Chang, “24.1 a 1mb multibit ReRAM computing-in-memory macro with 14.6ns parallel mac computing time for CNN based AI edge processors,” in  2019 IEEE International Solid- State Circuits Conference - (ISSCC) , pp. 541–552, 2017. [6]  C. Xue, W. Chen, J. Liu, J. Li, W. Lin, W. Lin, J. Wang, W. Wei, T. Chang, T. Chang, T. Huang, H. Kao, S. Wei, Y. Chiu, C. Lee, C. Lo, Y.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 171,
    "augmented": true
  },
  {
    "text": "To handle dynamic load variations, a load-monitor can be designed such that it constantly moni- tors different periods of static load and peak load. We propose to plug-in intelligent peak-to-median prediction policies (in accordance to  Observation 4 ) , which can aid the load-monitor to estimate the duration of static load. Furthermore, it can measure the peak-to-median ratio in sampling windows, which can be used to decide if  serverless functions  are re- quired to balance the load.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 119,
    "augmented": false
  },
  {
    "text": "[60]  W. A. Pearlman and A. Said,  Entropy coding techniques . Cambridge University Press, 2011, p. 41–76.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "[125] Will Orwig and Daniel Schacter. Creative writing in humans and large language models. In  Harvard Brain Science Initiative , Boston, MA, 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "Speciﬁcally, our proposal consists of the following 4 steps: PC sorting:  As shown in Fig. Instead, our proposal takes advantage of the Morton code generated in the geometry compression, which is a good indicator for attribute similarity (as discussed earlier in Sec. III-B ).",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 64,
    "augmented": true
  },
  {
    "text": "Two distinct scheduling strategies, each complemented by its own type of work queue, govern the computational ﬂow: Conservative Scheduling and Eager Scheduling. The dual-scheduling mechanism, bolstered by the work queue’s ﬂexible architecture, not only optimizes compute performance but also offers resilience against power uncertainties. The work queue schedule, intermediate result, network and layer information are saved on predicted power failure, and data from the DRAM (the working set of IF/OF/ﬁlter and model state) are moved to an NV-RAM using STT-RAM based buffers in the memory hierarchy (parallel to the IF/OF/ﬁlter).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 145,
    "augmented": false
  },
  {
    "text": "The llama 3 herd of models. [40] Murali Emani, Sam Foreman, Varuni Sastry, Zhen Xie, Siddhisanket Raskar, William Arnold, Rajeev Thakur, Venkatram Vishwanath, Michael E. Papka, Sanjif Shanmugavelu, Darshan Gandhi, Hengyu Zhao, Dun Ma, Kiran Ranganath, Rick Weisner, Jiunn-yeu Chen, Yuting Yang, Natalia Vassilieva, Bin C. Zhang, Sylvia Howland, and Alexander Tsyplikhin. arXiv preprint arXiv:2407.21783 , 2024.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 169,
    "augmented": true
  },
  {
    "text": "Downloaded on June 29,2023 at 18:36:04 UTC from IEEE Xplore. Restrictions apply. 1081 \nAuthorized licensed use limited to: Penn State University.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 42,
    "augmented": true
  },
  {
    "text": "Hence, nor- malized by number of requests, bigger VMs would still incur similar costs as smaller VMs. Observation 2:  VMs should be used to handle requests during constant arrival rates. Also, the number of concurrent requests which can be executed in VMs should be accurately determined to meet response latency.",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 72,
    "augmented": false
  },
  {
    "text": "[66]  Sara Rosenthal, Noura Farra, and Preslav Nakov. SemEval-2017 task 4: Sentiment analysis in Twitter. In  Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017) , pages 502–518, Vancouver, Canada, August 2017.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 71,
    "augmented": false
  },
  {
    "text": "Due to bounded  γ, δ,  and  η , and the fact that  ∆ A i ( t )  and energy costs are bounded, each  U i ( t ) is finite. Thus,  Φ( a ( t ))  is also finite for all feasible action profiles. Monotonicity of the Potential Function \nConsider a unilateral deviation by a single sensor  s j  from an action  a j ( t )  to a different action  a ′ j ( t ) .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 127,
    "augmented": true
  },
  {
    "text": "In  2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA) , pages 1080–1096, 2024. [181] Nan Zhang, Yanchi Liu, Xujiang Zhao, Wei Cheng, Runxue Bao, Rui Zhang, Prasenjit Mitra, and Haifeng Chen. Llmcompass: En- abling efficient hardware design for large language model inference.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 103,
    "augmented": true
  },
  {
    "text": "Go, M. Sandler, V. Sze, \nand H. Adam, “Netadapt: Platform-aware neural network adaptation for mobile applications,” in  Proceedings of the European Conference on Computer Vision (ECCV) , 2018, pp. 285–300. [104] C.-H.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 65,
    "augmented": false
  },
  {
    "text": "NASLarge IRV2 XceptionDNet121 NASMob 0 \n2 \n4 \n6 \nCost($) \nSingle-OD Ensemble-OD Ensemble-spot \n(b)  Cost of full-ensembling hosted on OD and Spot instances. Figure 3:  Cost and accuracy of ensembling vs single models. accuracies (< 75%) because single models can reach those accuracies.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "ResiRCA for the ﬁrst time supports harvested energy, expecting to initialize deeper researches on intelligent energy harvesting IoTs in the future. IX. A CKNOWLEDGEMENTS \nThis work was supported in part by Semiconductor Re- search Corporation (SRC), Center for Brain-inspired Com- puting (C-BRIC), Center for Research in Intelligent Storage and Processing in Memory (CRISP), NSF Grants #1822923 \n(SPX: SOPHIA), #1763681, #1629915, #1629129, #1317560, #1526750, National Natural Science Foundation of China [NSFC Project No.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 147,
    "augmented": false
  },
  {
    "text": "Exploiting Intermittent Computing:  An obvious solution to the power problem is to run the training in a self-sustained way, i.e., without depending on the power grid and by relying on a renewable energy source like solar power; opportunities for harvesting renewables naturally scale alongside a greater number of deployment locations and solar power, even though not always available, is in abundance. In the United States, a typical 12% efﬁcient solar panel [ 91 ], can provide an annual average of 50 W / m 2   − 150 W / m 2   of power [ 64 ]. Furthermore, solar power has reasonably predictability characteristics.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 144,
    "augmented": false
  },
  {
    "text": "We show that, by considering various parameters like region of interest and depth of view, we can approximate the ren- dering of the virtual object to minimize the amount of computation without affecting the user experience. Furthermore, by optimizing the software design flow, we propose  HoloAR , which intelligently renders the most important object in sight to the clearest detail, while approximating the computations for the others, thereby sig- nificantly reducing the amount of computation, saving energy, and gaining performance at the same time. We implement our design in an edge GPU platform to demonstrate the real-world applicability of our research.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 141,
    "augmented": false
  },
  {
    "text": "the baseline) is smaller than that in YOLOv4-tiny ( 4 . 5%  w.r.t. However, the overhead this scheme brings when applied to YOLOv3 ( 0 .",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 53,
    "augmented": true
  },
  {
    "text": "Both the PWS and RS collect metrics, such as the current container count, load history and request rate for a function for a given time window, from  Prometheus  and the  Kubernetes system log, using the Replica Tracker and Load Monitor mod- ules. We disable this Alert Manager and deploy the Proactive Weighted Scaler (PWS) and Reactive Scaler (RS) to carry out our container provisioning policies. This, in turn, triggers autoscaling to provision extra containers to service the load surge.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 125,
    "augmented": true
  },
  {
    "text": "8b. The latency is only decreased about  18% , while the energy saving is  22%  and  13% , as shown in Fig. 8a.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 36,
    "augmented": false
  },
  {
    "text": "Further, in many cases, these inputs are dynamically changing at the same frequency (e.g., the image sensors) as the frame-rate, which needs to be captured and updated at runtime, or even at a faster rate (e.g., the IMU and IR sensors). Thus, to systematically explore the potential opportunities of approximation in the AR hologram applications, we start by distinguishing between three fundamental scenarios, where the  objects ,  head pose , and  eye tracking  provide different opportunities, as depicted in Fig. 5.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 123,
    "augmented": false
  },
  {
    "text": "2) Optimizing the Intra-Frame Compression: Driven by the observations above, next we relax the “sequential update” approach that exists in the prior works, and employ the (intermediate) generated  Morton Codes  to reveal the “hidden parallelism” opportunities for compressing a PC frame (shown in Figs. 4  c  and  4  d  for the geometry and attribute compression, respectively). To improve the performance, next we want to explore the hidden spatio-temporal locality opportunities (missed by the prior works), and speed up  both  the geometry and attribute compression from  both  the intra- and inter-frame perspectives.",
    "source": "PCcompress.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 144,
    "augmented": true
  },
  {
    "text": "1b), such as IMU sensors, eye tracking or IR sensors, hand motion sensors, RGB-D im- age sensors, etc. To improve the hologram approximation, we need to first identify the set of inputs that affect the hologram computing the most. As discussed above in Sec.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "If that is the case, then full inference needs to be invoked. More speciﬁcally, if the MV block is relatively large, then we examine whether the object is moving in the current frame or has been missed by the previous frame (in Line  27-28 ). Next, we iterate each MV block for Scenario-1, Scenario-2 and Scenario-3 (shown from Line  22  to Line  31 ).",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 94,
    "augmented": true
  },
  {
    "text": "Let  D  denote the effective data distribution induced by the equilibrium strategies of the sensors. Under equilibrium conditions, the distribution  D  is stationary or at least sta- tionary over sufficiently large timescales. The expected loss is L ( θ ) =  E ( x,y ) ∼D [ ℓ ( f θ ( x ) , y )] .",
    "source": "ParticipationGamesICML25.pdf",
    "type": "sliding_window",
    "tokens": 87,
    "augmented": false
  },
  {
    "text": "[6]  M. Beg, Y. C. Chang, and T. F. Tang, “Performance evaluation of error resilient tools for mpeg-4 video transmission over a mobile channel,” in  2002 IEEE International Conference on Personal Wireless Communications , 2002, pp. 285–289. [7]  P. J. Besl and N. D. McKay, “Method for registration of 3-d shapes,” in  Sensor fusion IV: control paradigms and data structures , 1992, pp.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 117,
    "augmented": false
  },
  {
    "text": "as in ISAAC [ 3 ]). To meet our power constraints while preserving reasonable accuracy, we adopt a 4-bit input with a resolution of 1-bit, a cell resolution of 1-bit and a 4-bit output. With this design setting, the ReRAM size only needs to be equal to the kernel size, and the ReRAM scale does not need to be extended using a bit composing scheme (e.g.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 93,
    "augmented": true
  },
  {
    "text": "Finally, our partnership with ANL (see the attached collaboration letter) allows us to access ANL re- sources, including hardware accelerators for LLM. The PIs will also have access to the Argonne National Laboratory Aurora Exascale Supercomputer – a collection of LLM accelerators for our testbed and experimental evaluations. This grant enables the PIs as well as the project team to access, among other resources, hundreds of Intel Xeon nodes, various types of NVIDIA GPUs (A100 and V100), and two large storage arrays consisting of various types of HDDs, SSDs, FPGAs, as well as 4 computational storage devices (Samsung SmartSSD).",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 159,
    "augmented": true
  },
  {
    "text": "4.2 Request Batching Many serverless frameworks [ 5 ,  10 ,  17 ,  27 ,  44 ,  46 ,  50 ] spawn a single container to serve each incoming request to a function. While this approach is beneficial to minimize SLO violations, comparable performance can be achieved by using fewer containers by leveraging the notion of slack [ 32 ,  34 ]. Slack refers to the difference in expected response time and actual execution time of functions within a function chain.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 112,
    "augmented": false
  },
  {
    "text": "1545–1553, 2018. [33] A. Mazumdar, T. Moreau, S. Kim, M. Cowan, A. Alaghi, L. Ceze, M. Oskin, and V. Sathe, “Exploring Computation-communication Trade- offs in Camera Systems,” in  2017 IEEE International Symposium on Workload Characterization (IISWC) , 2017, pp. 177–186.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 95,
    "augmented": false
  },
  {
    "text": "Note that  ExecTime (f)  is estimated by aver- aging the execution times of the function obtained through \n159 \nSoCC ’21, November 1–4, 2021, Seattle, WA, USA V. Bhasi, J.R. Gunasekaran et al. 0 \n200 \n400 \n600 \nTime (ms) \nExec Time(ms) Stage-wise SLO(ms) \n(a) Social Network. 0 \nTime (ms) \nExec Time (ms) Stage-wise SLO (ms) \n600 \n450 \n300 \n150 \n(b) Media Service.",
    "source": "kraken.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 136,
    "augmented": true
  },
  {
    "text": "Each frame  F t  is divided into blocks B t,i , where  i  indexes the block within the frame. The motion vector field  M t  between  F t and  F t − 1  is computed to capture the displacement of pixels. Let  F t represent the frame at time  t , and  F t − 1  be the anchor frame.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 82,
    "augmented": true
  },
  {
    "text": "An edge between a dataset and an expert indicates that the ex- pert is trained on that dataset (i.e., expert-data affinity). and the other represent experts (E1, E2, etc.). Given memory capacity constraints, we frame the problem as identifying sets of experts to train together such that the data reuse among the selected experts, in a training step, is maximized and the combined data and parameter requirements of the set fit within the available memory.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 99,
    "augmented": true
  },
  {
    "text": "Park, N. Suda, L. Lai, B. Chau, V. Chandra, and H. Esmaeilzadeh, “Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Networks,” in  Proceedings of the International Symposium on Computer Architecture , 2018, p. 764–775. [26] H. Sharma, J. [27] S. Han, H. Mao, and W. J. Dally, “Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding,”  arXiv preprint arXiv:1510.00149 , 2015.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 156,
    "augmented": true
  },
  {
    "text": "[24] A. Inc., “Rendering Omni-directional Stereo Content.” ”https:// developers.google.com/vr/jump/rendering-ods-content.pdf”, 2019. [25] N. INSTRUMENTS, “Peak Signal-to-Noise Ratio as an Image Quality Metric.” ”https://www.ni.com/en-us/innovations/white-papers/11/peak- signal-to-noise-ratio-as-an-image-quality-metric.html”, 2019. [26] B. C. Kim and C. E. Rhee, “Compression Efﬁciency Evaluation for Virtual Reality Videos by Projection Scheme,”  IEIE Transactions on Smart Processing & Computing , pp.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 182,
    "augmented": false
  },
  {
    "text": "USENIX Association 19th USENIX Symposium on Networked Systems Design and Implementation    1041 \nselection and procurement play a pivotal role in minimizing the latency and deployment costs. Further, the resource provi- sioning strategies employed in single model-serving systems are  not directly extendable  to ensemble systems. These shortcomings collectively motivate the central premise of this work:  how to solve the complex optimiza- tion problem of cost, accuracy and latency for an ensem- bling framework?",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 112,
    "augmented": true
  },
  {
    "text": "7, when processing the six videos listed in Tab. 2, with the first four config- urations described earlier in Sec. 5.1.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 30,
    "augmented": false
  },
  {
    "text": "Results:  Table 1 shows the accuracy of our approach against the baselines and the recent state-of-the- art methods using the TI MSP board powered by piezoelectric energy harvesting. The inferences meeting the SLO requirements are the only ones considered for accuracy; i.e., a correct classification violating the latency SLO is considered as “incorrect”. Datasets Full Power AP PT iNAS+PT Stateful ePerceptive DynBal NExUME \nFMNIST 98.70 71.90 79.72 83.68 85.40 86.25 87.50 88.90 CIFAR10 89.81 55.05 62.00 66.98 68.50 70.20 71.75 76.29 MHEALTH 89.62 59.76 65.40 71.56 73.80 74.95 76.10 80.75 PAMAP 87.30 57.38 65.77 70.33 72.20 73.35 74.50 75.16 AudioMNIST 88.20 67.29 73.16 75.41 76.80 77.95 78.60 80.01 Table 1: Accuracy comparison on TI MSP board using piezoelectric energy harvesting.",
    "source": "NexUME.pdf",
    "type": "sliding_window",
    "tokens": 300,
    "augmented": false
  },
  {
    "text": "[5] W. Amit Katwala, “The spiralling environmental cost of our lithium \nbattery addiction,” https://www.wired.co.uk/article/lithium-batteries- environment-impact , May 2018, (Accessed on 07/08/2023). [6] G. Ananthanarayanan, V. Bahl, P. Bod´ık, K. Chintalapudi, M. Philipose, \nL. R. Sivalingam, and S. Sinha, “Real-time Video Analytics – the killer app for edge computing,”  IEEE Computer , 2017. [7] AWS Outposts, “https://aws.amazon.com/outposts/rack/hardware- specs/?nc=sn&loc=4.” [8] Azure Stack Edge, “https://azure.microsoft.com/en- us/services/databox/edge/.” [9] O. Banos, C. Villalonga, R. Garc´ıa, A. Saez, M. Damas, J. Holgado- \nTerriza, S. Lee, H. Pomares, and I. Rojas, “Design, implementation and validation of a novel open framework for agile development of mobile health applications,”  BioMedical Engineering OnLine , 2015.",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 308,
    "augmented": false
  },
  {
    "text": "In  International Conference on Machine Learning , pages 5547–5569. PMLR, 2022. Glam: Efficient scaling of language models with mixture-of-experts.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 40,
    "augmented": true
  },
  {
    "text": "The queries arriving with similar constraints can read the model cache to avoid re-computation for selecting the models. The model cache is implemented as a hash-map using  Redis  [ 16 ] in-memory key-value store for fast access. The constraints are deﬁned as  <latency,accuracy>  pair.",
    "source": "cocktail.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 72,
    "augmented": true
  },
  {
    "text": "From the dataset, we report the average reuse distance, i.e., the average number of preceding frames with same head orientation to be memoized, and show it in Fig. 5a. It can be concluded from these results that, memoizing the last  two  frames is sufﬁcient for most of the cases.",
    "source": "DejaView.pdf",
    "type": "sliding_window",
    "tokens": 67,
    "augmented": false
  },
  {
    "text": "•  EA+AE:  With both  EA  and  AE  optimizations deployed, as shown in Fig. Therefore, as shown in Fig. 9, our proposed  AE  optimization alone saves  37% compute energy compared to the  Baseline , translating to 19%  total energy saving.",
    "source": "DejaView.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 61,
    "augmented": true
  },
  {
    "text": "While ensembling is applicable in other classiﬁcation workloads like product recommendations [ 24 , 53 ], text classiﬁcation [ 71 ] etc, the observations drawn are generic and applicable to other applications. 2.3.1 Ensembling Compared to Single Models \nTo analyze the accuracy offered by ensemble models, we con- duct an experiment using 10000 images from  ImageNet  [ 29 ] test dataset, on a  C5.xlarge  [ 8 ] instances in AWS EC2 [ 5 ]. For a given baseline model, we combine all models whose latency is lower than that of the baseline, and call it full- ensemble.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 138,
    "augmented": false
  },
  {
    "text": "Further, \n1 To give a quantitative estimation of the popularity of the game, a Pokémon GO event at Safari Zone New Taipei City, Taiwan in October 2019 had a total of 327,000 attendees and they walked around 4.5 million kilometers to catch 50 Million Pokémons [5]. 494 \nMICRO ’21, October 18–22, 2021, Virtual Event, Greece Shulin and Haibo, et al. the limited battery capacity prevents users from enjoying their AR devices for extended periods of time.",
    "source": "HoloAR.pdf",
    "type": "sliding_window",
    "tokens": 114,
    "augmented": false
  },
  {
    "text": "II-B3. We acknowledge that, compared to our proposal, Euphrates yields around  10% additional energy savings when the window size is set to be as large as  8  (i.e., always skipping  7  frames). We want to emphasize however that, such static (pre-deﬁned) window-size works well only when there are few movements in the videos.",
    "source": "PCframeSim.pdf",
    "type": "sliding_window",
    "tokens": 78,
    "augmented": false
  },
  {
    "text": "7 ms on an edge GPU 3 . Note that such maps are not necessarily required to be generated for each frame (typically computed once per two or three frames [ 28 ,  50 ], thus 67 − 100 ms  in Table 1); hence, we argue that the state-of-the-art InfiniTAM technique, which implements a framework for real-time depth fusion and learning of 3D scenes [ 50 ], is already close to the ideal case. However,  Hologram , which takes depthmap, point-cloud, or light field as its input [ 18 ] 2   to create arbitrary 3D configurations of optical traps useful for capturing, moving and transforming mesoscopic objects freely in the world [ 4 ], takes as long as 341 .",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 174,
    "augmented": true
  },
  {
    "text": "[199] Yang Zhu, Luke Zettlemoyer, and Jimmy Ba. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In  Proceedings of the 2015 Conference on Em- pirical Methods in Natural Language Processing (EMNLP) , pages 58–68.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window",
    "tokens": 74,
    "augmented": false
  },
  {
    "text": "This makes hard- ware parallelization and pipelining easier on a block/tensor type of architecture such as GPUs. Note, however, that, this step also requires sequential barriers within each plane ( Line#6  synchro- nizes the threads in a warp/block for one depth plane) and across planes ( Line#7  synchronizes the results from all the depth planes, before moving forward to the second step). Each depth plane processes the forward-propagation from the hologram plane independently, and each pixel on a particular depth plane goes through the exact processing sequence ( HP2DP in  Line#5 ; more details can be found in [ 4 ,  18 ]).",
    "source": "HoloAR.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 157,
    "augmented": true
  },
  {
    "text": "Therefore, these apparent deficiencies of choosing the appropriate resource type and model type for a given user re- quirement motivates the central question of this work:  Does there exist an optimal resource procurement system which can balance the goals of diverse user requirements for accuracy, latency and cost, by efficiently mapping model parameters to heterogeneous resource specifications? Our preliminary results suggest that using a combination of VMs and serverless func- tions could potentially provide a solution to this problem. As opposed to prior works [ 5 ,  10 ], which try to combine serverless functions with VMs to hide the start-up latencies of VMs, our primary interest lies in exploring the different key aspects  to address when hosting DNN-based ML pre- diction serving systems in public cloud, as given below: •  Diverse Models:  How to make the users oblivious of model selection from the extensive pool of models, for satis- fying the accuracy, and latency requirements?",
    "source": "PubCloudHet.pdf",
    "type": "sliding_window",
    "tokens": 217,
    "augmented": false
  },
  {
    "text": "Further, all the points are processed in parallel; 3). we discard the entropy encoding for further speedup. •  Our Intra-Inter-V1 (Quality-oriented):  This design favors the quality over compression efﬁciency, and it only takes  124 ms  ( 41 ms  for geometry compression, and  83 ms for attribute compression), contributing to around  34 × speedup w.r.t.",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 97,
    "augmented": false
  },
  {
    "text": "Further, the other 5 models are used by up to 25% of the images. Not including them in the ensemble would have led to severe loss in accuracy. But, our dynamic policy with the class-based weighted voting, adapts to input images in a given interval by accurately selecting the best performing model for each class.",
    "source": "cocktail.pdf",
    "type": "sliding_window",
    "tokens": 68,
    "augmented": false
  },
  {
    "text": "Fpga acceleration of zstd compression algorithm. In  2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) , pp. 188–191.",
    "source": "SaLT.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 43,
    "augmented": true
  },
  {
    "text": "https://aws.amazon.com/ lambda/. [6]  2020. Azure Durable Functions.",
    "source": "kraken.pdf",
    "type": "sliding_window",
    "tokens": 29,
    "augmented": false
  },
  {
    "text": "What is the Solution Space? Addressing these challenges ne- cessitates a fresh look beyond the current monolithic design for providing a democratic platform for contributing to cost-effective innovations in LLMs. See our timeline (Figure 8) for time-span of the individual tasks.",
    "source": "NSF_LLM_Medium_Proposal.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 65,
    "augmented": true
  },
  {
    "text": "[97] Urban Trafﬁc Dataset, “https://github.com/edge-video- services/ekya#urban-trafﬁc-dataset.” [98] O. Wayman, “How urban mobility will change by 2030,” https://www.oliverwyman.com/our-expertise/insights/2022/jun/how- urban-mobility-will-change-by-2030.html , 2022, (Accessed on 08/04/2023). [99] P. with Code, “Object detection on coco test-dev,” https://paperswithcode.com/sota/object-detection-on-coco , (Accessed on 11/21/2022). [100] www.dlapiperdataprotection.com, “Sweden data collection & process- \ning,”  https://www.dlapiperdataprotection.com/index.html?t=collection- and-processing&c=SE , (Accessed on 11/21/2022).",
    "source": "Usas.pdf",
    "type": "sliding_window",
    "tokens": 233,
    "augmented": false
  },
  {
    "text": "ResiSchedule power efﬁciency analysis \nD. Transition efﬁciency Table  VI-D  shows the ratio of inferences using smooth- transitioned partial results and total inference count number. These results indicate that the smooth transition strategy Transition Keep   enables a signiﬁcant fraction of the inferences for all workloads on  Piezo . However, a very small fraction is observed with the other, stronger power sources.",
    "source": "ResiRCA.pdf",
    "type": "sliding_window",
    "tokens": 88,
    "augmented": false
  },
  {
    "text": "Since, all the deployments are working on the same task, and have trained on similar data, we will be able to perform the analytics task within a reasonable accuracy bound. In our experiments, we observe that, in most cases, the accuracy of the peers are similar to that of the edge node. However, if the confidence bound at the peer is not met, the cloud is contacted, at higher latency than having directly contacted the cloud to begin with.",
    "source": "EdgeClourRF.pdf",
    "type": "sliding_window_shuffled",
    "tokens": 100,
    "augmented": true
  },
  {
    "text": "Our extensive experimental results show that, compared to a state-of-the-art intra-frame PCC technique [ 56 ], our intra- frame proposal can accelerate the PCC by  43 . 7 ×  and save 96.6 %  energy. While with our inter-frame compression design, the compression ratio can be further improved (increasing from 5.95 in intra-frame design to 10.43) with 35 ×  speedup and 97.4 %  energy savings with respect to a state-of-the-art inter-frame PCC scheme [ 13 ].",
    "source": "PCcompress.pdf",
    "type": "sliding_window",
    "tokens": 126,
    "augmented": false
  }
]